Issue_id,Type,Priority,Component,Title,Description,Status,Resolution,Duplicated_issue,Assignee,Reporter,Created_time,Updated_time,Resolved_time,Fix_version,Affects_version,Labels,Blocked_issue,Related_issue,Link
MAPREDUCE-1,Bug,Major,,Hadoop  mapreduce should always ship the jar file(s) specified by the user,when I run a hadoop job like:      bin hadoop jar myjar org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob other_args  myjar is not shipped. The job failed because the class loader cannot find the classes specified in myjar.,Resolved,Duplicate,HADOOP-6103,Enis Soztutar,Runping Qi,Fri; 22 Jun 2007 06:23:24 +0000,Fri; 8 May 2015 17:55:02 +0000,Fri; 8 May 2015 17:55:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1
MAPREDUCE-2,Bug,Major,,ArrayOutOfIndex error in KeyFieldBasedPartitioner on empty key,When using KeyFieldBasedPartitioner; if the record doesn't contain the specified field; the endChar would equal with array.length; which throw ArrayOutOfIndex exception; losing that record!,Resolved,Fixed,,Amar Kamat,Amar Kamat,Tue; 16 Jun 2009 08:37:07 +0000,Wed; 8 Jul 2009 05:44:40 +0000,Fri; 26 Jun 2009 08:42:04 +0000,,,,MAPREDUCE-735,,https://issues.apache.org/jira/browse/MAPREDUCE-2
MAPREDUCE-3,Bug,Major,,Set mapred.child.ulimit automatically to the value of the RAM limits for a job; if they are set,Memory based monitoring and scheduling allow users to set memory limits for the tasks of their jobs. This parameter is the total memory taken by the task; and any children it may launch (for e.g. in the case of streaming). A related parameter is mapred.child.ulimit which is a hard limit on the memory used by a single process of the entire task tree. For user convenience; it would be sensible for the system to set the ulimit to atleast the memory required by the task; if the user has specified the latter.,Resolved,Fixed,,Unassigned,Hemanth Yamijala,Sat; 13 Jun 2009 05:14:52 +0000,Tue; 22 Jul 2014 21:12:30 +0000,Tue; 22 Jul 2014 21:12:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3
MAPREDUCE-4,Bug,Major,,TestJobTrackerRestart.testJobRecoveryWithEmptyHistory doesnt test the expected,"The test uses TestEmptyJob.CommitterWithDelayCleanup to delay cleanup. But the committer requires configuration property ""share"" to be set; which is not done in the test. So; cleanup fails in the test instead of getting delayed.  Test should have an assert for Job is successful in the end.",Resolved,Duplicate,MAPREDUCE-237,Amar Kamat,Amareshwari Sriramadasu,Tue; 16 Jun 2009 10:46:09 +0000,Thu; 2 May 2013 02:29:25 +0000,Wed; 1 Jul 2009 09:29:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4
MAPREDUCE-5,Bug,Major,,Shuffle's getMapOutput() fails with EofException; followed by IllegalStateException,During the shuffle phase; I'm seeing a large sequence of the following actions:  1) WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(attempt_200905181452_0002_m_000010_0;0) failed : org.mortbay.jetty.EofException 2) WARN org.mortbay.log: Committed before 410 getMapOutput(attempt_200905181452_0002_m_000010_0;0) failed : org.mortbay.jetty.EofException 3) ERROR org.mortbay.log:  mapOutput  lang.IllegalStateException: Committed  The map phase completes with 100%; and then the reduce phase crawls along with the above errors in each of the TaskTracker logs.  None of the tasktrackers get lost.  When I run non-data jobs like the 'pi' test from the example jar; everything works fine.,Resolved,Not A Problem,,Unassigned,George Porter,Mon; 18 May 2009 22:12:54 +0000,Tue; 31 Mar 2015 00:24:18 +0000,Tue; 3 Sep 2013 06:45:43 +0000,,0.20.2;1.1.1,,,MAPREDUCE-163,https://issues.apache.org/jira/browse/MAPREDUCE-5
MAPREDUCE-6,Bug,Major,,Task attempt stopped shuffling and hung the job,I was running a job and one of the reducer task tempt process after 20 minutes of seeing it frozen; it restarted on another machine and succeeded just fine.,Resolved,Not A Problem,,Unassigned,Nathan Marz,Wed; 29 Apr 2009 22:30:00 +0000,Sat; 31 Dec 2011 08:46:35 +0000,Sat; 31 Dec 2011 08:46:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6
MAPREDUCE-7,Bug,Major,,Reduce progress in the Reducer crosses 1,I printed the progress in the Progress. for every progress made and I found this scenario   Following are the lines I added to get this      This needs investigation and will also explain why occasionally users see jobs that are complete and their progress less that 100%.,Resolved,Duplicate,MAPREDUCE-5210,Unassigned,Amar Kamat,Fri; 22 Aug 2008 09:52:16 +0000,Thu; 2 May 2013 02:29:17 +0000,Wed; 7 Oct 2009 06:28:00 +0000,,,,,HADOOP-5210;MAPREDUCE-141,https://issues.apache.org/jira/browse/MAPREDUCE-7
MAPREDUCE-8,Bug,Major,,Bad File Descriptor in closing local file,Running the sort benchmark; I had a map fail with this exception:  2006-11-28 17:59:36;770 INFO org.apache.hadoop.mapred.TaskInProgress: Error from task_0001_m_001906_0: Map output lost; rescheduling: getMapOutput(task_0001_m_001906_0;786) failed :  534),Resolved,Not A Problem,,Owen O'Malley,Nigel Daley,Wed; 29 Nov 2006 19:06:25 +0000,Sat; 31 Dec 2011 08:47:31 +0000,Sat; 31 Dec 2011 08:47:30 +0000,,,,,HADOOP-757;HADOOP-758,https://issues.apache.org/jira/browse/MAPREDUCE-8
MAPREDUCE-9,Bug,Major,,Path separator in DistributedCache does not work between windows and unix,"DistributedCache.addfileToClassPath adds the files to mapred.job.classpath.files which can be seen in the jobs xml description. When the job is created and submitted from a windows machine the path separator is "";"". This can be seen in the configuration: mapred.job.classpath.files	  utils.jar  When the job is submitted over network to a Hadoop cluster running on Linux the path separator is "":"". This affects the DistributedCache.getFileClassPath method which separates the mapred.job.classpath.files configuration using the system path separator; which is "":"". This renders all classpath additions invalid using DistributedCache.addFileToClassPath.  Temporary sollution: I've simply added "";"" to the StringTokenizer in DistributedCache.getFileClassPath; but I'm not certain if it's a good sollution.",Resolved,Duplicate,HADOOP-4864,Unassigned,Juho M  kinen,Fri; 22 Aug 2008 12:00:02 +0000,Tue; 11 Aug 2009 07:28:08 +0000,Tue; 11 Aug 2009 07:28:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-9
MAPREDUCE-10,Bug,Major,,NPE in SocketChannelOutputStream during large sort benchmark,Running sort benchmark; I saw this NPE trace in the JobTracker log  ... 2007-02-04 02:07:23;753 INFO org.apache.hadoop.mapred.JobInProgress: Already complete TIP tip_0002_m_032689 has completed task task_0002_m_032689_2 2007-02-04 02:07:23;753 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_m_032689_2' has completed. 2007-02-04 02:07:24;566 WARN org.apache.hadoop.ipc.Server: handler output error 556) 2007-02-04 02:07:32;510 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_m_077715_2' has completed tip_0002_m_077715 successfully. ...,Resolved,Not A Problem,,Unassigned,Nigel Daley,Mon; 5 Feb 2007 07:43:48 +0000,Sat; 31 Dec 2011 08:48:45 +0000,Sat; 31 Dec 2011 08:48:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-10
MAPREDUCE-11,Bug,Major,,Cleanup JobHistory file naming to do with job recovery,The JobTracker uses the job history files for doing job recovery upon startup. To handle cases where JobTracker goes down again while the recovered job is running; there is some logic th we remove the .recover file logic and base the recovery on only the original job history file.,Resolved,Invalid,,Unassigned,Devaraj Das,Thu; 28 May 2009 02:57:30 +0000,Mon; 5 Oct 2009 06:25:56 +0000,Mon; 5 Oct 2009 06:25:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-11
MAPREDUCE-12,Bug,Major,,Tasks execed by the task controller shouldn't inherit tasktracker groups,Mapred tasks process seem to inherit the group list from the TaskTracker daemon instead of the task owner.   tom   26633 15736  0 21:33 ?        00:00:02  status Groups: 100 20001  hadoop1:~$ id tom uid=47765(tom) gid=100(users) groups=100(users);10764(ninjas)  org.apache.hadoop.mapred.LinuxTaskController should set the user supplimentary group list.,Resolved,Fixed,,Sreekanth Ramakrishnan,Rajiv Chittajallu,Wed; 15 Apr 2009 22:59:17 +0000,Wed; 29 Jul 2009 08:50:13 +0000,Wed; 29 Jul 2009 08:50:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-12
MAPREDUCE-13,Bug,Major,,Mapper failed due to out of memory,When a map reduce job takes block compressed sequence files as input;  the input data may be expanded significantly in size (a few to tens X; depending on the compression ratio of the particular data blocks in the files). This may cause out of memory problem in mappers.  In my case; I set heap space to 1GB. The mappers started to fail when the accumulated expanded input size reaches above 300MB,Resolved,Not A Problem,,Unassigned,Runping Qi,Tue; 2 Oct 2007 21:26:28 +0000,Sat; 31 Dec 2011 08:54:28 +0000,Sat; 31 Dec 2011 08:54:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-13
MAPREDUCE-14,Bug,Major,,extensive map tasks failures because of SocketTimeoutException during statusUpdate,A job with 3600 tasks on a cluster of 1350 nodes (up 3 tasks per node) shows extensive map tasks failures because of connection timeouts   1142)  2007-10-18 17:45:40;258 WARN org.apache.hadoop.mapred.TaskRunner: Last retry; killing task_200710172336_0016_m_000071_0   Log of task that could not start: 2007-10-18 17:43:55;766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server:  127.0.0.1:53972. Already tried 10 time(s).,Resolved,Not A Problem,,Unassigned,Christian Kunz,Thu; 18 Oct 2007 18:33:39 +0000,Sat; 31 Dec 2011 08:56:15 +0000,Sat; 31 Dec 2011 08:56:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-14
MAPREDUCE-15,Bug,Major,,SequenceFile RecordReader should skip bad records,Currently a bad record in a sequencefile leads to entire job being failed. the best workaround is to skip an errant file manually (by looking  org.apache.hadoop.mapred.MapTask$1.next(MapTask. 176)  Ideally the recordreader should just skip the entire chunk if it gets an unrecoverable error while reading.  This was the consensus in hadoop-153 as well (that data corruptions should be handled by recordreaders) and hadoop-3144 did something similar for textinputformat.,Reopened,Unresolved,,Unassigned,Joydeep Sen Sarma,Mon; 30 Jun 2008 01:32:06 +0000,Fri; 6 Nov 2015 15:17:59 +0000,,,,,,MAPREDUCE-21,https://issues.apache.org/jira/browse/MAPREDUCE-15
MAPREDUCE-16,Bug,Major,,Reduce task failed at shuffling time; throwing null pointer exception,This happened for 0.17.0 branch.  Here is the stack trace:  2008-04-11 13:45:54;171 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure:  777),Resolved,Not A Problem,,Unassigned,Runping Qi,Fri; 11 Apr 2008 13:50:35 +0000,Sat; 31 Dec 2011 08:49:28 +0000,Sat; 31 Dec 2011 08:49:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-16
MAPREDUCE-17,Bug,Major,,Changing priority of a completed job causes problems in JobInProgressListeners,If the priority of a completed job is changed; a JobChangeEvent is raised and the JobInProgressListeneners; like the capacity scheduler; are notified. Most implementations handle the event by re-sorting their data structures; and thus could end up re-inserting the completed job into their lists.,Resolved,Not A Problem,,Unassigned,Hemanth Yamijala,Thu; 13 Nov 2008 11:39:06 +0000,Sat; 31 Dec 2011 08:52:04 +0000,Sat; 31 Dec 2011 08:52:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-17
MAPREDUCE-18,Bug,Blocker,,Under load the shuffle sometimes gets incorrect data,While testing HADOOP-5223 under load; we found reduces receiving completely incorrect data. It was often random; but sometimes was the output of the wrong map for the wrong map. It appears to either be a Jetty or JVM bug; but it is clearly happening on the server side. In the HADOOP-5223 code; I added information about the map and reduce that were included and we should add similar protection to 0.20 and trunk.,Resolved,Fixed,,Ravi Gummadi,Owen O'Malley,Fri; 8 May 2009 07:06:36 +0000,Wed; 22 Jul 2009 09:33:25 +0000,Thu; 16 Jul 2009 11:48:44 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-18
MAPREDUCE-19,Bug,Major,,TaskMemoryMonitorThread is not stopped in close,The task memory monitor thread is created in initialize; but is not stopped in close. So; if there's a reinit; this can result in a thread becoming a zombie as the thread variable is replaced in initialize.,Resolved,Not A Problem,,Unassigned,Hemanth Yamijala,Fri; 29 May 2009 11:27:30 +0000,Sat; 31 Dec 2011 09:03:58 +0000,Sat; 31 Dec 2011 09:03:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-19
MAPREDUCE-20,Bug,Major,,If a mapper of a map/reduce job with combiner has to spill the map output; the performance degrades significantly,I have a map reduce job whose reducers combine a group of values into a single value. The average reduction rate is about 3 to 1. The execution time for the job with the reducer as its combiner ;  is twice of that for the case without using combiner. This is completely counter-intuitive. When I looked at the job execution more carefully; I noticed that this longer execution time for the  job was mainly due to a few mappers that generated spills. The final merge of the spills seems  took a much longer time with combiner than without combiner.,Resolved,Duplicate,HADOOP-2399,Unassigned,Runping Qi,Wed; 5 Mar 2008 05:05:39 +0000,Sat; 31 Dec 2011 08:50:36 +0000,Sat; 31 Dec 2011 08:50:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-20
MAPREDUCE-21,Bug,Major,task,NegativeArraySizeException in reducer with new api,I observed one of the reducers failing with NegativeArraySizeException with new api. The exception trace:   159)  The corresponding line in ReduceContext is,Resolved,Duplicate,HADOOP-11901,Unassigned,Amareshwari Sriramadasu,Mon; 25 May 2009 11:12:57 +0000,Mon; 27 Jun 2016 05:05:01 +0000,Mon; 27 Jun 2016 05:05:01 +0000,,,,,MAPREDUCE-15,https://issues.apache.org/jira/browse/MAPREDUCE-21
MAPREDUCE-22,Bug,Major,,Per task memory usage stats from TaskMemoryManager on mapred web ui,It would be good to have per-task memory usage statistics from the TaskMemoryManager displayed on the web ui  as the task progresses on. This would make it easy for users to (roughly) track their tasks' memory usage.,Resolved,Invalid,,Unassigned,Vinod Kumar Vavilapalli,Fri; 20 Mar 2009 16:13:09 +0000,Sat; 31 Dec 2011 09:00:57 +0000,Sat; 31 Dec 2011 09:00:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-22
MAPREDUCE-23,Bug,Major,,Start times for some tasks are missing from task reports after job tracker restart,When a JobTracker with the mapred.jobtracker.restart.recover option turned on; restarts; it recovers task statuses from all tasks recorded in the history for running jobs. Task trackers rejoin the restarted JobTracker and report the statuses of the tasks they had last run. These tasks' start time is set to 0 in the task reports on the restarted JobTracker. This is as seen in the web UI; or from the value of TaskReport.startTime retrieved from the job client.,Resolved,Not A Problem,,Amar Kamat,Hemanth Yamijala,Wed; 1 Oct 2008 10:52:38 +0000,Sat; 31 Dec 2011 08:53:25 +0000,Sat; 31 Dec 2011 08:53:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-23
MAPREDUCE-24,Bug,Major,,Reduce stuck in pending state for ever even though the job tracker shows a lot of free slots,A job with 38 mappers and 38 reducers running on a cluster with 36 slots. All mapper tasks completed. 17 reducer tasks completed. 11 reducers are still in the running state and one is in the oending state and stay there forever.,Resolved,Not A Problem,,Unassigned,Runping Qi,Thu; 13 Nov 2008 00:18:59 +0000,Sat; 31 Dec 2011 08:58:16 +0000,Sat; 31 Dec 2011 08:58:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-24
MAPREDUCE-25,Bug,Major,,Non-speculative and speculative tasks for a TIP start at the same time.,I ran into a situation where the non-speculative task and the speculative task were started at the same time. Ideally there should be a 1 min gap for speculation. One possible reason would be the usage of startTime in deciding whether there is a speculative lag.,Resolved,Invalid,,Amar Kamat,Amar Kamat,Fri; 8 Feb 2008 16:32:29 +0000,Wed; 7 Oct 2009 06:29:39 +0000,Wed; 7 Oct 2009 06:29:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-25
MAPREDUCE-26,Bug,Major,,The shuffle keeps the ReduceTask locked while doing a FileSystem.rename leading to task timeouts,The shuffle in ReduceTask.ReduceCopier.MapOutputCopier.copyOutput locks the entire ReduceTask while doing a FileSystem.rename operation. Unfortunately the RawLocalFileSystem implements rename as a copy and delete; which can take a long time. As a result the reduce is being killed as not reporting progress for 10 minutes.,Resolved,Not A Problem,,Owen O'Malley,Owen O'Malley,Fri; 24 Aug 2007 18:31:43 +0000,Sat; 31 Dec 2011 09:10:59 +0000,Sat; 31 Dec 2011 09:10:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-26
MAPREDUCE-27,Bug,Major,,Jobs with 0 maps will never get removed from the default scheduler,Jobs' with 0 maps finish succeed in the init phase i.e while the job is in the PREP state. EagerTaskInitializationListener removes the job after initing but JobQueueJobInProgressListener waits for a job-state change event to be raised and aonly then removes the job from the queue and hence the job will stay forever with the JobQueueJobInProgressListener. Looks like FairScheduler periodically scans the job list and removes completed jobs. CapacityScheduler has a concept of waiting jobs and scans waiting queue for completed jobs and purges them.,Resolved,Duplicate,MAPREDUCE-805,Amar Kamat,Amar Kamat,Thu; 15 Jan 2009 08:56:17 +0000,Thu; 20 Aug 2009 11:37:35 +0000,Wed; 19 Aug 2009 11:16:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-27
MAPREDUCE-28,Bug,Major,jobtracker;test,TestQueueManager takes too long and times out some times,TestQueueManager takes long time for the run and timeouts sometimes. See the failure at http: . Looking at the console output; before the test finsihes; it was timed-out. On my machine; the test takes about 5 minutes.,Closed,Fixed,,V.V.Chaitanya Krishna,Amareshwari Sriramadasu,Thu; 19 Feb 2009 06:47:40 +0000,Tue; 24 Aug 2010 21:13:17 +0000,Fri; 27 Nov 2009 04:51:37 +0000,,0.21.0,,MAPREDUCE-1075,,https://issues.apache.org/jira/browse/MAPREDUCE-28
MAPREDUCE-29,Bug,Major,,JVM reuse across task types,Currently; JVM-reuse is across tasks of same type of the same job; i.e. JVMs are kind of marked as map-JVMs and reduce JVMs. May be we can reuse JVMs across tasks of different types but of the same job.,Resolved,Invalid,,Devaraj Das,Vinod Kumar Vavilapalli,Fri; 6 Mar 2009 11:41:54 +0000,Sat; 31 Dec 2011 09:12:14 +0000,Sat; 31 Dec 2011 09:12:14 +0000,,,,MAPREDUCE-138,,https://issues.apache.org/jira/browse/MAPREDUCE-29
MAPREDUCE-30,Bug,Major,,setting io.sort.factor does not have effect?,I have a m r job with 84000 mappers. I set io.sort.factor to 200.  The reducers still generates 800+ merged files; not  400+ I expected.,Resolved,Invalid,,Unassigned,Runping Qi,Fri; 9 Feb 2007 01:52:11 +0000,Sat; 31 Dec 2011 09:09:05 +0000,Sat; 31 Dec 2011 09:09:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-30
MAPREDUCE-31,Bug,Major,,Have a better shutdown and cleanup mechanism in JobTracker,The main() of JobTracker waits for offerSerice() to complete. offerService() does a Thread.join() on interTrackerServer.  JobTracker.close() stops interTrackerServer pretty early and hence there is a fair chance of JobTracker exiting before other threads are stopped properly.,Resolved,Not A Problem,,Unassigned,Amar Kamat,Tue; 8 Jul 2008 05:08:48 +0000,Sat; 31 Dec 2011 09:08:20 +0000,Sat; 31 Dec 2011 09:08:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-31
MAPREDUCE-32,Bug,Major,,Killed task is logged as Failed upon a lost tracker,Upon a lost tracker; the successful attempt is killed but the tip is marked as failed.,Resolved,Not A Problem,,Unassigned,Amar Kamat,Thu; 19 Feb 2009 14:03:05 +0000,Sat; 31 Dec 2011 09:18:19 +0000,Sat; 31 Dec 2011 09:18:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-32
MAPREDUCE-33,Bug,Major,,Avoid using deprecated api's,There are code paths in mapred that use deprecated apis.,Resolved,Not A Problem,,Unassigned,Amar Kamat,Fri; 24 Oct 2008 04:57:43 +0000,Sat; 31 Dec 2011 09:17:08 +0000,Sat; 31 Dec 2011 09:17:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-33
MAPREDUCE-34,Bug,Major,,Reduce step hangs while recovering a block from bad datanode,The reduce step hangs infinitely when its trying to recover a block from a bad datanode. The node from which the block is being retrieved is alive and TT and DN are up and running.,Resolved,Not A Problem,,Unassigned,Ramya Sunil,Wed; 25 Feb 2009 11:11:23 +0000,Sat; 31 Dec 2011 09:14:52 +0000,Sat; 31 Dec 2011 09:14:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-34
MAPREDUCE-35,Bug,Major,,There can be more than 'mapred.jobtracker.completeuserjobs.maximum' jobs for a user in the jobtracker,The check for max-completed-jobs-per-user is made in finalize job and hence there can be a case where the user finishes more than 'mapred.jobtracker.completeuserjobs.maximum' jobs within  JobTracker.MIN_TIME_BEFORE_RETIRE units of time and doesnt submit any job after that which can cause more number of jobs to be in memory than allowed. There is no check made for this limit anywhere else.,Resolved,Invalid,,Unassigned,Amar Kamat,Fri; 13 Feb 2009 09:56:36 +0000,Wed; 7 Oct 2009 06:35:02 +0000,Wed; 7 Oct 2009 06:35:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-35
MAPREDUCE-36,Bug,Major,,LInks in http://jobtracker/machines.jsp are broken while running hadoop locally,While running hadoop locally; the tasktracker information on machines.jsp is represented as http: localhost:50060.,Resolved,Cannot Reproduce,,Unassigned,Amar Kamat,Sat; 9 Feb 2008 14:28:08 +0000,Sat; 31 Dec 2011 09:15:57 +0000,Sat; 31 Dec 2011 09:15:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-36
MAPREDUCE-37,Bug,Major,,MAP_OUTPUT_BYTES counter is not recorded in Job history log for Map only jobs,"Here is an example Map task entry in job history log; it has MAP_OUTPUT_RECORDS but no MAP_OUTPUT_BYTES  Task TASKID=""task_200905250540_0578_m_000000"" TASK_TYPE=""MAP"" TASK_STATUS=""SUCCESS"" FINISH_TIME=""1243294056346"" COUNTERS="" {(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(56630)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(28327)]} {(org .Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2634)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_INPUT_BYTES)(Map input bytes)(28303)][(MAP_OUTPUT_RECORDS)(Map output records)(2634)]} "" .",Resolved,Not A Problem,,Unassigned,Suhas Gogate,Thu; 28 May 2009 21:05:07 +0000,Sat; 31 Dec 2011 09:34:47 +0000,Sat; 31 Dec 2011 09:34:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-37
MAPREDUCE-38,Bug,Major,,TaskCompletionEvents do not distinguish between FAILED and KILLED task-attempts,It is very disconcerting to see KILLED task-attempts (e.g. speculative tasks) on the user-console showing up as FAILED; it would be nice to ignore them and only print the FAILED ones (and add a filter for KILLED if need be...),Resolved,Not A Problem,,Unassigned,Arun C Murthy,Wed; 11 Jul 2007 15:18:49 +0000,Sat; 31 Dec 2011 09:25:22 +0000,Sat; 31 Dec 2011 09:25:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-38
MAPREDUCE-39,Bug,Major,,Task tracker should wait for the process to exit before declaring the task successful or failed.,Currently when a task declares it is done; the status in the task tracker is changed immediately. Instead it should wait for the subprocess to actually be done before it moves to one of the final states. This lead to a race condition where the task was still generating log data after the job tracker had reported the task as done.,Resolved,Invalid,,Devaraj Das,Owen O'Malley,Fri; 7 Dec 2007 07:36:02 +0000,Sat; 31 Dec 2011 09:26:57 +0000,Sat; 31 Dec 2011 09:26:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-39
MAPREDUCE-40,Bug,Blocker,,Memory management variables need a backwards compatibility option after HADOOP-5881,HADOOP-5881 modified variables related to memory management without looking at the backwards compatibility angle. This JIRA is to adress the gap. Marking it a blocker for 0.20.1,Resolved,Fixed,,rahul k singh,Hemanth Yamijala,Wed; 27 May 2009 05:45:17 +0000,Fri; 4 Sep 2009 11:07:06 +0000,Mon; 3 Aug 2009 11:25:18 +0000,,,,,MAPREDUCE-1018,https://issues.apache.org/jira/browse/MAPREDUCE-40
MAPREDUCE-41,Bug,Major,,Write unit tests to verify  the fix for HADOOP-5349,nan,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Mon; 11 May 2009 06:02:48 +0000,Fri; 8 May 2015 18:01:21 +0000,Fri; 8 May 2015 18:01:21 +0000,,,,,HADOOP-5349,https://issues.apache.org/jira/browse/MAPREDUCE-41
MAPREDUCE-42,Bug,Major,,task trackers should not restart for having a late heartbeat,TaskTrackers should not close and restart themselves for having a late heartbeat. The JobTracker should just accept their current status.,Resolved,Invalid,HADOOP-43,Devaraj Das,Owen O'Malley,Tue; 2 May 2006 01:45:01 +0000,Sat; 31 Dec 2011 09:21:16 +0000,Sat; 31 Dec 2011 09:21:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-42
MAPREDUCE-43,Bug,Major,,Retired jobs are not present in the job list returned to the job-client.,"After mapred.jobtracker.retirejob.interval elapses; completed jobs are no longer maintained by the JT; but instead when job-client ask for job status; counters or task completion events; the relevant information is picked up from completed job store. But a retired job is not listed in the output of ""hadoop job -list all""; without which other information from completed job store isn't quite useful unless a job-id is known from elsewhere.",Resolved,Invalid,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 28 Aug 2008 04:13:20 +0000,Sat; 31 Dec 2011 09:30:09 +0000,Sat; 31 Dec 2011 09:30:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-43
MAPREDUCE-44,Bug,Major,,Hang JobTracker; running out of memory,This may be expected.  Hang JobTracker with 1G heapsize; top showed 99% cpu.   Ran about 80 jobs.  Each with 2500 mappers 200 reducers.  They finish quite fast.  3-4 mins avg per job. (200k tasks)   How much memory does JobTracker use for 'completed'  (but not expired) jobs ?  jmap -heap showed      jmap -histo showed      Log showing many heartbeat discarded messages     Is the solution either to increase the jobtracker heapsize or set shorter 'mapred.userlog.retain.hours'  ?,Resolved,Not A Problem,,Unassigned,Koji Noguchi,Tue; 30 Oct 2007 23:01:17 +0000,Mon; 27 Sep 2010 05:04:56 +0000,Mon; 27 Sep 2010 05:04:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-44
MAPREDUCE-45,Bug,Major,,JobStatus should contain user name and carry forward start time when job is killed.,If an initialized job is killed; the jobs start time is set to zero. Job status don't seem to have user name set properly.,Resolved,Cannot Reproduce,,Amar Kamat,Sreekanth Ramakrishnan,Tue; 13 Jan 2009 10:18:55 +0000,Sat; 31 Dec 2011 09:31:21 +0000,Sat; 31 Dec 2011 09:31:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-45
MAPREDUCE-46,Bug,Major,,mapred/local/jobTracker is not cleanup correctly,Jobtracker store 1.jar file and 1 .xml per job in  jobTracker.  They seems to be correctly delete in most cases BUT not when a job is launch with  Map total: 0 and Reduce total: 0 This happen when the job doesn't find any input file to process.  After few months; lots of disk space is lost because of that.  This issue is different from HADOOP-2427 since it's on the jobtracker; not on the nodes; but it may be related in some way in the code (my 2 cents).,Resolved,Cannot Reproduce,,Unassigned,Benjamin Francisoud,Thu; 3 Jan 2008 15:45:19 +0000,Sat; 31 Dec 2011 09:27:59 +0000,Sat; 31 Dec 2011 09:27:59 +0000,,,,,HADOOP-2427,https://issues.apache.org/jira/browse/MAPREDUCE-46
MAPREDUCE-47,Bug,Major,,Tasklog servlet doesn't display any logs when logs are short,After running a job that died after only writing a little bit of logs; the tasklog servlet shows an empty log.  In the log directory; however; there are non-empty stderr and stdout logs:  $ ls -la total 92 drwxrwsr-x  2 mapreduce mapreduce  4096 Mar 19 16:24 . drwxrwsr-x 95 mapreduce mapreduce 69632 Mar 19 16:24 .. rw-rr-  1 mapreduce mapreduce    78 Mar 19 16:24 log.index rw-rw-r-  1 mapreduce mapreduce   350 Mar 19 16:24 stderr rw-rw-r-  1 mapreduce mapreduce  4413 Mar 19 16:24 stdout $ cat log.index  LOG_DIR:attempt_200902160142_0040_m_000000_3 stdout:0 0 stderr:0 0 syslog:0 0,Resolved,Duplicate,HADOOP-4374,Unassigned,Michael Bieniosek,Thu; 19 Mar 2009 16:42:43 +0000,Sat; 31 Dec 2011 09:33:34 +0000,Sat; 31 Dec 2011 09:33:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-47
MAPREDUCE-48,Bug,Major,,Expired launching tasks affect small jobs' execution time,Currently when a task is given to a TT; the JT doesn't mark the task as running till the TT responds back to the JT. And within 10 mins(hard-coded); if the task doesn't come back; then only the task gets relaunched. For small jobs; this is a lot of time.,Resolved,Not A Problem,,Unassigned,Vinod Kumar Vavilapalli,Fri; 6 Mar 2009 11:38:09 +0000,Sat; 31 Dec 2011 09:20:00 +0000,Sat; 31 Dec 2011 09:20:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-48
MAPREDUCE-49,Bug,Major,,JobTracker UI shows Incorrect reporter progress.,Hadoop UI is showing a Job in completed box where the reducer progress percentage is 99.97 % .   The job have no exceptions and was successfully completed.,Resolved,Duplicate,HADOOP-5210,Unassigned,bhupesh bansal,Sat; 2 May 2009 21:12:32 +0000,Sat; 31 Dec 2011 09:34:08 +0000,Sat; 31 Dec 2011 09:34:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-49
HADOOP-10867,Bug,Major,,NPE in heartbeat when the configured topology script doesn't exist,nan,Open,Unresolved,MAPREDUCE-820,Mauro Murari,Vinod Kumar Vavilapalli,Thu; 26 Feb 2009 11:12:53 +0000,Mon; 2 Feb 2015 22:14:18 +0000,,,1.0.3,newbie,,HADOOP-8049,https://issues.apache.org/jira/browse/HADOOP-10867
MAPREDUCE-51,Bug,Major,,TestTaskLimits fails occassionally,When I run TestTaskLimits locally; it fails sometimes with a timeout. This is with trunk.,Resolved,Not A Problem,,Unassigned,Hemanth Yamijala,Wed; 17 Jun 2009 06:09:56 +0000,Sat; 31 Dec 2011 09:36:33 +0000,Sat; 31 Dec 2011 09:36:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-51
MAPREDUCE-52,Bug,Major,,KeyFieldBasedPartitioner would lost data if specifed field not exist; and it should encode free not only support utf8,1) Currently;  KeyFieldBasedPartitioner only support utf8 encoded recored;  we should use text or byteswriteable data types.  2) when using KeyFieldBasedPartitioner; if the record doesn't contain the specified field; the endChar would equal with array.length; which throw ArrayOutOfIndex exception; losting that record!,Open,Unresolved,,Unassigned,ZhuGuanyin,Wed; 6 May 2009 11:10:09 +0000,Mon; 29 Jun 2009 11:06:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-52
MAPREDUCE-53,Bug,Major,,JUnit tests should not create directories in the current directory,"PiEstimator. create test directories in the current directory. I think that a better place is directory "". test"".",Resolved,Not A Problem,,Unassigned,Hairong Kuang,Tue; 10 Apr 2007 19:18:33 +0000,Sat; 31 Dec 2011 09:35:52 +0000,Sat; 31 Dec 2011 09:35:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-53
MAPREDUCE-54,Bug,Major,,distcp failed due to problem in creating files,When I run a distcp program to copy files from one dfs to another; my job failed with the mappers throwing the following exception:  org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.AlreadyBeingCreatedException: failed to create file  part-00007 for DFSClient_task_200710122302_0002_m_000456_2 on client 72.30.43.23 because current leaseholder is trying to recreate file.  temp failed.,Resolved,Not A Problem,,Unassigned,Runping Qi,Sat; 13 Oct 2007 03:32:31 +0000,Sat; 31 Dec 2011 09:38:04 +0000,Sat; 31 Dec 2011 09:38:04 +0000,,,,,HADOOP-2087,https://issues.apache.org/jira/browse/MAPREDUCE-54
MAPREDUCE-55,Bug,Major,,Reduce task should stop shuffle-retrying in case of out-of-memory errors,In ReduceTask; MapOutputCopier threads catch Throwble and retry happens for the shuffle. It should not retry incase of Errors suchas OutOfMemoryError etc.  May be it should retry only in case of Connect Read failures and die in all other cases. Thoughts?,Resolved,Duplicate,MAPREDUCE-318,Unassigned,Amareshwari Sriramadasu,Tue; 17 Feb 2009 05:44:37 +0000,Wed; 7 Oct 2009 06:16:12 +0000,Wed; 7 Oct 2009 06:16:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-55
MAPREDUCE-56,Bug,Major,,Client recovery from Job tracker restarts and connectivity failures,This Jira addresses the client side recovery from Jobtracker restarts; fail overs and network connectivity issues. This does not address Jobtracker high availability and tracks only the client side recovery.,Resolved,Not A Problem,,Unassigned,Suresh Srinivas,Fri; 16 Jan 2009 02:33:37 +0000,Sat; 31 Dec 2011 09:40:20 +0000,Sat; 31 Dec 2011 09:40:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-56
MAPREDUCE-58,Bug,Major,,Duplicate metric name getTask,I've been seeing the following error in some tasks:,Resolved,Not A Problem,,Unassigned,Owen O'Malley,Tue; 14 Apr 2009 22:29:14 +0000,Sat; 31 Dec 2011 09:40:58 +0000,Sat; 31 Dec 2011 09:40:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-58
MAPREDUCE-59,Bug,Major,,'job -kill' from command line should inform if the job doesn't exist,"Killing an invalid job from command line succeeds with a message stating ""job killed"".",Resolved,Invalid,,Unassigned,Amar Kamat,Fri; 9 Jan 2009 15:22:26 +0000,Sat; 7 Jul 2012 16:21:20 +0000,Sat; 7 Jul 2012 16:21:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-59
MAPREDUCE-60,Bug,Major,,Nested class TaskTracker.TaskInProgress needs additional synchronization,"The nested class TaskTracker.TaskInProgress needs additional synchronization to work properly with the Java Memory Model.  Presumably this class is accessed by more than one thread; because it already contains synchronization.  However; it needs additional synchronization; especially to protect access to the long fields lastProgressReport and taskTimeOut.  Long fields are not guaranteed to be read written atomically; so not only do you risk reading stale values; but you risk reading corrupted values.  The field wasKilled also needs synchronization; as it is polled from within the TaskTracker class.    I suggest the following improvements to the class  	Make the fields task and taskStatus final.  They are used this way already.  Making them final clarifies there behavior in a current environment. 	Add the synchronized modifier to the methods getLastProgressReport() and getTaskTimeout(). 	Make the field wasKilled private and add a new public synchronized wasKilled() getter method.  Replace the use of the field with this method in TaskTracker. 	Add a comment to localizeTask() indicating that the caller must be synchronized on this.",Resolved,Incomplete,,Unassigned,Aaron Greenhouse,Fri; 13 Jun 2008 14:15:12 +0000,Fri; 18 Jul 2014 05:34:08 +0000,Fri; 18 Jul 2014 05:34:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-60
MAPREDUCE-61,Bug,Major,,Counters value of  reduce input records do not match map output records,Counters value of  reduce input records do not match map output records under certain circumstances.  somehow reproducable,Resolved,Not A Problem,,Daniel Udatny,Daniel Udatny,Thu; 17 Apr 2008 13:46:53 +0000,Sat; 31 Dec 2011 09:44:12 +0000,Sat; 31 Dec 2011 09:44:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-61
MAPREDUCE-62,Bug,Major,,job.xml should have high replication factor by default,job.xml is set the default replication factor of 3 by the JobClient. The same config file is accessed from the DFS by JT as well as all the TTs. Hence it should be set a high replication factor say 10; just like the job.jar.,Resolved,Not A Problem,,Unassigned,Vinod Kumar Vavilapalli,Mon; 23 Feb 2009 05:52:46 +0000,Sat; 31 Dec 2011 09:54:43 +0000,Sat; 31 Dec 2011 09:54:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-62
MAPREDUCE-63,Bug,Major,,TaskTracker falls into an infinite loop.,All maps had been completed successfully. I had only one reduce task during which TaskTracker infinitely outputs:    INFO mapred.JobTracker: Adding task 'task_0001_r_000000_0' to tip tip_0001_r_000000; for tracker 'tracker_my-host.com:50050',Open,Unresolved,HADOOP-1862,Arun C Murthy,Konstantin Shvachko,Wed; 16 May 2007 02:59:18 +0000,Thu; 26 Jul 2012 07:57:26 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-63
MAPREDUCE-64,Bug,Major,performance;task,Map-side sort is hampered by io.sort.record.percent,Currently io.sort.record.percent is a fairly obscure; per-job configurable; expert-level parameter which controls how much accounting space is available for records in the map-side sort buffer (io.sort.mb). Typically values for io.sort.mb (100) and io.sort.record.percent (0.05) imply that we can store ~350;000 records in the buffer before necessitating a sort deserialization of records too...  Sure; jobs can configure io.sort.record.percent; but it's tedious and obscure; we really can do better by getting the framework to automagically pick it by using all available memory (upto io.sort.mb) for either the data or accounting.,Closed,Fixed,,Chris Douglas,Arun C Murthy,Thu; 22 Jan 2009 22:02:22 +0000,Sat; 30 Mar 2013 00:22:12 +0000,Fri; 5 Feb 2010 05:43:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-64
MAPREDUCE-65,Bug,Major,,TaskTrackers never (re)connect back to the JobTracker if the JobTracker node/machine is changed,I tried the following  1) Started a hadoop cluster. 2) Killed the JT 3) Selected a new node for starting JT.  4) Changed the entry on the tasktracker to reflect the new (old) hostname to (new) ip mapping. Checked if the tracker node correctly resolves the hostname to the new ip. 5) Start the JT on the new node The tasktracker fails to connect to the new jobtracker. It seems that the hostname resolution remains stale and is never updated.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Mon; 25 Aug 2008 18:22:11 +0000,Wed; 30 Jul 2014 17:05:12 +0000,Wed; 30 Jul 2014 17:05:12 +0000,,,,,MAPREDUCE-2288,https://issues.apache.org/jira/browse/MAPREDUCE-65
MAPREDUCE-66,Bug,Major,,The local bytes read of Mapper tasks are too high than bytes written,"The local bytes read are 6 times that of local bytes written. This is very hard to explain.  Here is the relevant counters:  Counters for tip_200810170704_0044_m_000001  File Systems 	Local bytes read 	6;684;486;486 	Local bytes written 	1;007;113;506 	HDFS bytes read 	147;200;700  Map-Reduce Framework 	Map input records 	3;588;883 	Map output records 	3;588;883 	Map input bytes 	147;200;579 	Map output bytes 	464;822;403 	Combine input records 	0 	Combine output records 	0",Resolved,Not A Problem,,Unassigned,Runping Qi,Fri; 17 Oct 2008 22:44:42 +0000,Sat; 31 Dec 2011 09:46:20 +0000,Sat; 31 Dec 2011 09:46:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-66
MAPREDUCE-67,Bug,Major,,Few tasks failed while creating the work directory for a job; when job tracker was restarted,A randomwriter job was running when the job tracker restarted. After the jobtracker restarted; some tasktrackers were sent a reinit action. After this; some new tasks of the random writer were scheduled to be run on the same task trackers. These failed in the job localization while creating the work directory. However; the next attempts of the same job ran successfully and the job succeeded. This happened in about 1% of the total number of tasks.,Resolved,Invalid,,Amareshwari Sriramadasu,Hemanth Yamijala,Fri; 13 Mar 2009 13:04:33 +0000,Tue; 11 Aug 2009 05:39:48 +0000,Tue; 11 Aug 2009 05:39:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-67
MAPREDUCE-68,Bug,Major,,Hadoop reduce scheduler sometimes leaves machines idle,I have a MapReduce application with number of reducers equal to the number of machines in the cluster (and with speculative execution turned off). However; Hadoop schedules multiple reduces to run on single machines and leaves other machines idle. This causes contention and seriously slows down the job. Hadoop should employ the simple heuristic of utilizing as many machines as possible when scheduling reduces.,Resolved,Not A Problem,,Unassigned,Nathan Marz,Tue; 3 Feb 2009 03:22:55 +0000,Sat; 31 Dec 2011 09:53:21 +0000,Sat; 31 Dec 2011 09:53:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-68
MAPREDUCE-69,Bug,Major,,NPE in TaskTracker RenitTrackerAction ,TaskTracker log shows =============  2007-03-28 02:32:18;076 INFO org.apache.hadoop.mapred.TaskTracker: Recieved RenitTrackerAction from JobTracker 2007-03-28 02:32:18;494 ERROR org.apache.hadoop.mapred.TaskTracker: Can not start task tracker because  1589)  JobTracker log shows ============== 2007-03-28 02:31:18;977 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker '___.___.com' ... 2007-03-28 02:31:18;977 INFO org.apache.hadoop.mapred.JobInProgress: TaskTracker at 'tracker___.__.com' turned 'flaky' ... 2007-03-28 02:32:18;075 WARN org.apache.hadoop.mapred.JobTracker: Status from unknown Tracker : tracker___.__.com:#####,Resolved,Cannot Reproduce,,Unassigned,Koji Noguchi,Wed; 28 Mar 2007 07:18:57 +0000,Sat; 31 Dec 2011 09:45:15 +0000,Sat; 31 Dec 2011 09:45:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-69
MAPREDUCE-70,Bug,Major,,Unify  the way job history filename is parsed,"Job history filename has the following meta-info :  	jobtracker's hostname 	job id 	username 	jobname    HistoryViewer. and jobhistory.jsp are required to parse the history filename to extract the meta-info. It makes more sense to provide a common utility in JobHistory to do it.",Resolved,Fixed,,Amar Kamat,Amar Kamat,Mon; 25 Aug 2008 18:37:10 +0000,Wed; 15 Jul 2009 15:40:33 +0000,Wed; 15 Jul 2009 15:40:33 +0000,,,,MAPREDUCE-323,HADOOP-4498,https://issues.apache.org/jira/browse/MAPREDUCE-70
MAPREDUCE-71,Bug,Major,,JobClient can be constructed without initializing object state,The JobClient class has a no-arg constructor that does nothing.  This leaves critical object state uninitialized.,Resolved,Not A Problem,,Owen O'Malley,Nigel Daley,Wed; 8 Nov 2006 18:57:16 +0000,Sat; 31 Dec 2011 09:43:16 +0000,Sat; 31 Dec 2011 09:43:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-71
MAPREDUCE-72,Bug,Major,,Move handling of Task debugging out of TaskTracker,Currently TaskTracker.TaskInProgress.taskFinished handles the responsibility of executing the debug scripts for Map post processing classes.  The current situation leads to bugs like HADOOP-3696.,Resolved,Invalid,,Unassigned,Arun C Murthy,Mon; 21 Jul 2008 21:02:32 +0000,Sat; 7 Jul 2012 16:12:47 +0000,Sat; 7 Jul 2012 16:12:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-72
MAPREDUCE-73,Bug,Critical,,Deadlock in JobTracker initJobs,"Found one Java-level deadlock: ============================= ""SocketListener0-26"":   waiting to lock monitor 0x08ed5ce4 (object 0x567924c0; a org.apache.hadoop.mapred.JobTracker);   which is held by ""IPC Server handler 1 on 9001"" ""IPC Server handler 1 on 9001"":   waiting to lock monitor 0x08f7da88 (object 0x5744f5b8; a org.apache.hadoop.mapred.JobInProgress);   which is held by ""initJobs"" ""initJobs"":   waiting to lock monitor 0x08ed5ce4 (object 0x567924c0; a org.apache.hadoop.mapred.JobTracker);   which is held by ""IPC Server handler 1 on 9001""  Java stack information for the threads listed above: =================================================== ""SocketListener0-26"":          org.apache.hadoop.mapred.EagerTaskInitializationListener$JobInitThread.run(EagerTaskInitializationListener. 55)    Found 1 deadlock.",Resolved,Duplicate,MAPREDUCE-805,Unassigned,Dave Latham,Mon; 4 May 2009 22:48:12 +0000,Mon; 9 Nov 2009 04:34:02 +0000,Mon; 9 Nov 2009 04:34:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-73
MAPREDUCE-74,Bug,Major,,JobClient hangs when getting map-task reports,a call to JobClient.getMapTaskReports() has been hung for 6+ days,Resolved,Not A Problem,,Unassigned,sam rash,Thu; 5 Feb 2009 22:44:39 +0000,Sat; 31 Dec 2011 09:54:01 +0000,Sat; 31 Dec 2011 09:54:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-74
MAPREDUCE-75,Bug,Major,,Job history log does not output final counters if job is failed or killed,The last log entry in job history contains important counters. This information is missing if the job is killed or failed.,Resolved,Cannot Reproduce,,Unassigned,Mac Yang,Mon; 20 Apr 2009 17:33:11 +0000,Sat; 7 Jul 2012 17:37:09 +0000,Sat; 7 Jul 2012 17:37:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-75
MAPREDUCE-76,Bug,Major,,JobControl should handle exceptions,If the JobControl encounters non IOExceptions; then JobControl fails without reporting failures. JobControl should handle all exceptions and report the failure to launch jobs. In addition; an API to support the querying of failure to launch jobs should be supported.,Resolved,Not A Problem,,Unassigned,Santhosh Srinivasan,Mon; 9 Feb 2009 17:28:46 +0000,Wed; 11 Jul 2012 03:19:05 +0000,Wed; 11 Jul 2012 03:19:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-76
MAPREDUCE-77,Bug,Critical,,JobConf is deprecated but Job does not support a constructor for Configuration,JobConf has been deprecated but Job does not support any constructor for Configuration which is replacing JobConf.,Resolved,Invalid,,Unassigned,Santhosh Srinivasan,Thu; 26 Feb 2009 23:37:13 +0000,Tue; 11 Aug 2009 06:13:05 +0000,Tue; 11 Aug 2009 06:13:05 +0000,,,,HADOOP-5867,,https://issues.apache.org/jira/browse/MAPREDUCE-77
MAPREDUCE-78,Bug,Major,,tasks should not run on nodes where they were previously lost,We had a case where a task tracker was getting lost every 15 minutes and the same reduce kept getting scheduled on it (15 times). Tasks that are killed should not reschedule on the node where they were previously killed.,Resolved,Fixed,,Unassigned,Owen O'Malley,Fri; 1 Feb 2008 23:34:28 +0000,Thu; 17 Jul 2014 20:07:43 +0000,Thu; 17 Jul 2014 20:07:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-78
MAPREDUCE-79,Bug,Major,,Ignored IOExceptions from MapOutputLocation.java:getFile lead to hung reduces,Ignoring IOExceptions during fetching of map outputs in MapOutputLocation. getFile (e.g. content-length doesn't match actual data recieved) leads to hung reduces since the MapOutputCopier puts the host in the penalty box and retries forever.  Possible steps: a) Distinguish between failure to fetch output v s lost maps. (related to HADOOP-1158) b) Ensure the reduce doesn't keep fetching from 'lost maps'. (related to HADOOP-1183) c) On detection of 'failure to fetch' we probably should have exponential back-offs (versus the same order back-offs as currently) for hosts in the 'penalty box'. d) If fetches still fail for say 4 times (after exponential backoffs); we should declare the Reduce as 'failed'.  This situation could also arise from situations like full-disks on the reducer; whereby it isn't possible to save the map output on the local disk (say for large map outputs).  Thoughts?,Open,Unresolved,,Unassigned,Arun C Murthy,Wed; 11 Apr 2007 13:02:47 +0000,Sat; 20 Jun 2009 07:50:52 +0000,,,,,,HADOOP-1183;HADOOP-1158,https://issues.apache.org/jira/browse/MAPREDUCE-79
MAPREDUCE-80,Bug,Major,,Counter formatting for the user logs should be pulled out of the public Counters API,Currently the mapred.Counters class includes an obsolete format (makeCompactString) and a format that is only used by the user logs (makeEscapeCompactString). makeCompactString should be deprecated and later removed.The makeEscapeCompactString should be refactored to a non-public class.,Resolved,Not A Problem,,Unassigned,Owen O'Malley,Fri; 24 Oct 2008 16:49:35 +0000,Sat; 31 Dec 2011 09:56:36 +0000,Sat; 31 Dec 2011 09:56:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-80
MAPREDUCE-81,Bug,Major,,missing userlogs,I noticed that a long-running job taking more than 1 day can have reduce tasks with missing stderr and stdout log directories (the syslog files exist).  I wonder whether it has to do with the default value of 12 hours for mapred.userlog.retain.hours; resulting in deletion of the stderr stdout directories for reduce tasks idling till they start to actually reduce.,Resolved,Duplicate,MAPREDUCE-927,Unassigned,Christian Kunz,Sat; 21 Apr 2007 21:17:53 +0000,Thu; 18 Mar 2010 05:40:24 +0000,Thu; 18 Mar 2010 05:40:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-81
MAPREDUCE-82,Bug,Major,,Revert the temporary change made to collection of Job's metrics done by HADOOP-3521,HADOOP-3521 is a temporary fix; it needs to be reverted.,Resolved,Incomplete,,Arun C Murthy,Arun C Murthy,Thu; 24 Jul 2008 22:19:51 +0000,Fri; 18 Jul 2014 18:22:38 +0000,Fri; 18 Jul 2014 18:22:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-82
MAPREDUCE-83,Bug,Major,,Job completion delayed,A job with all reduces completed but with some incomplete re-executed maps is not declared complete till all tasks are complete. Couldn't the incomplete maps just be killed off? Even if maps write to dfs directly; these incomplete maps must have been successful before; so there should be no reason to wait for them.,Resolved,Duplicate,MAPREDUCE-114,Unassigned,Christian Kunz,Tue; 22 Jul 2008 22:26:12 +0000,Sun; 18 Oct 2009 00:50:31 +0000,Fri; 16 Oct 2009 17:33:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-83
MAPREDUCE-84,Bug,Major,,JobClient waitForCompletion() method sometimes throws an NPE, 128)  Does someone have an idea why this happens ? Thanks for any help.,Resolved,Not A Problem,,Owen O'Malley,Thomas Friol,Fri; 27 Oct 2006 06:51:10 +0000,Mon; 16 Jan 2012 10:13:24 +0000,Mon; 16 Jan 2012 10:13:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-84
MAPREDUCE-85,Bug,Major,,Setting lastProgressReport time in TIP's constructor causes TT to wrongly kill tasks.,nan,Resolved,Cannot Reproduce,,Unassigned,Vinod Kumar Vavilapalli,Fri; 27 Feb 2009 14:25:20 +0000,Sat; 7 Jul 2012 16:36:09 +0000,Sat; 7 Jul 2012 16:36:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-85
MAPREDUCE-86,Bug,Major,,Custom FileSystem class not found during child process initialization,If a custom FileSystem class is used for Reducer output; initialization of the child task fails with an uncaught ClassNotFoundException. Trace follows.   lang.ClassNotFoundException: cascading.tap.hadoop.S3HttpFileSystem        least explicitly catch the CNFE. On a catch; can continue to return the original Path instance passed.,Resolved,Not A Problem,,Unassigned,Chris K Wensel,Fri; 14 Mar 2008 18:55:13 +0000,Sat; 7 Jul 2012 16:26:05 +0000,Sat; 7 Jul 2012 16:26:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-86
MAPREDUCE-87,Bug,Major,,exporting pid doesn't work if the user's shell is not bash,"HADOOP-5488 added exporting of pid using  ""export JVM_PID=`echo $$` ""  for saving pid of task JVM. This exporting of pid wouldn't work if the user's shell is not bash when running the MR job.",Resolved,Invalid,,Ravi Gummadi,Ravi Gummadi,Wed; 29 Apr 2009 04:13:28 +0000,Wed; 7 Oct 2009 06:14:58 +0000,Wed; 7 Oct 2009 06:14:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-87
MAPREDUCE-88,Bug,Major,,Illegal state exception in printTaskLog -> sendError,This error shows up in my logs:  2007-08-23 16:40:08;028 WARN  tasklog?taskid=task_200708212126_0043_m_000100_0all=true:   534),Resolved,Cannot Reproduce,,Unassigned,Michael Bieniosek,Thu; 23 Aug 2007 17:55:39 +0000,Sat; 7 Jul 2012 16:23:06 +0000,Sat; 7 Jul 2012 16:23:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-88
MAPREDUCE-90,Bug,Major,,incrementing counters should not be used for triggering record skipping,The following code is really problematic:     In particular; if the user updates a counter with the wrong name; bad things will presumably happen...,Resolved,Won't Fix,,Unassigned,Owen O'Malley,Mon; 24 Nov 2008 21:56:29 +0000,Sat; 7 Jul 2012 16:16:13 +0000,Sat; 7 Jul 2012 16:16:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-90
MAPREDUCE-91,Bug,Major,task,task attempt failing to report status just after the intialization,In sort500 runs; I noticed task tempt_200807220707_0002_r_000336_1. Ignored.,Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Tue; 22 Jul 2008 08:58:57 +0000,Fri; 18 Jul 2014 18:17:57 +0000,Fri; 18 Jul 2014 18:17:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-91
MAPREDUCE-92,Bug,Major,,Reduce task stuck at 95.71% for a long time and the speculative execution does not kick in,I have a job with speculative execution set on. However; its last reduce task has been stuck for a long time at 95.71%; and no speculative execution was started. I did see speculative executions for other tasks started and killed though.,Resolved,Duplicate,HADOOP-2141,Unassigned,Runping Qi,Tue; 4 Mar 2008 03:04:41 +0000,Sat; 7 Jul 2012 18:17:35 +0000,Sat; 7 Jul 2012 18:17:34 +0000,,,,,HADOOP-2141,https://issues.apache.org/jira/browse/MAPREDUCE-92
MAPREDUCE-93,Bug,Major,,Job Tracker should prefer input-splits from overloaded racks,Currently; when the Job Tracker assigns a mapper task to a task tracker and there is no local split to the task tracker; the job tracker will find the first runable task in the mast task list  and assign the task to the task tracker. The split for the task is not local to the task tracker; of course. However; the split may be local to other task trackers. Assigning the th number with the the actual number of  data local mappers launched; we can know the effectiveness of the job tracker scheduling.  When we introduce rack locality; we should apply the same principle.,Open,Unresolved,,Devaraj Das,Runping Qi,Tue; 9 Oct 2007 14:08:10 +0000,Sat; 20 Jun 2009 07:50:53 +0000,,,,,,HADOOP-2560;HADOOP-2119,https://issues.apache.org/jira/browse/MAPREDUCE-93
MAPREDUCE-94,Bug,Major,,Speculative execution does not work properly,One mapper of my job stuck when it reached 87.7%. Speculative execution was set to true. But no speculative execution was fired for that task. The whole job was stalled.,Resolved,Duplicate,HADOOP-2141,Unassigned,Runping Qi,Fri; 9 Nov 2007 03:07:34 +0000,Sat; 7 Jul 2012 18:18:13 +0000,Sat; 7 Jul 2012 18:18:13 +0000,,,,,HADOOP-2141,https://issues.apache.org/jira/browse/MAPREDUCE-94
MAPREDUCE-95,Bug,Major,contrib/streaming,In PipeMarRed.java; log related fields seems useless,In PipeMapRed. line 352. Also; the field mapRedKey_ in the same file is always null and might cause issues if the getContext() method is ever invoked (it is never invoked in the current code).  We possibly can remove references to these fields.,Resolved,Duplicate,MAPREDUCE-1864,Unassigned,Devaraj Das,Fri; 18 May 2007 17:11:51 +0000,Fri; 2 Jul 2010 06:24:46 +0000,Fri; 2 Jul 2010 06:24:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-95
MAPREDUCE-96,Bug,Major,,mapper failed due to exceptions,From time to time; I observed th org.apache.hadoop.mapred.TaskRunner.run(TaskRunner. 292)  The re-run of the task succeeded. The machine where the task failed seemed to be normal.,Resolved,Cannot Reproduce,,Unassigned,Runping Qi,Tue; 6 Nov 2007 20:05:38 +0000,Sat; 7 Jul 2012 18:35:25 +0000,Sat; 7 Jul 2012 18:35:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-96
MAPREDUCE-97,Bug,Major,,Increase map/reduce child tasks' heapsize from current default of 200M to 512M,I guess we should look to check why we get OOMs with 200M; I'd suspect io.sort.mb hogs a lot of the default 200M. However; HADOOP-1867 should be the right way to solve it.   For now; I propose we bump up the child-vm default heapsize to 512M; too many people are getting burnt by 200M.,Resolved,Invalid,,Arun C Murthy,Arun C Murthy,Wed; 30 Jan 2008 23:53:38 +0000,Fri; 8 May 2015 17:51:19 +0000,Fri; 8 May 2015 17:51:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-97
MAPREDUCE-98,Bug,Major,,NullPointerException when retrieving task reports,It appears as thought Counters is null for a given task which causes an NPE in the logs (and clients to hang),Resolved,Cannot Reproduce,,Unassigned,sam rash,Wed; 1 Apr 2009 17:42:04 +0000,Sat; 7 Jul 2012 18:31:01 +0000,Sat; 7 Jul 2012 18:31:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-98
MAPREDUCE-99,Bug,Major,,Reducers throw oom exceptions during fetching map outputs,I have a job that ran fine if the flag for compressing the map output data to false. However; if the flag is set to true and the compression type set to block; then  the reducers all died due to out of memory exceptions. The heap size was set to 512M. The problem persists even when the heapsize set to 1000M.,Resolved,Cannot Reproduce,,Unassigned,Runping Qi,Sat; 23 Feb 2008 21:51:01 +0000,Sat; 7 Jul 2012 16:57:19 +0000,Sat; 7 Jul 2012 16:57:19 +0000,,,,HADOOP-2095,,https://issues.apache.org/jira/browse/MAPREDUCE-99
MAPREDUCE-100,Bug,Major,,Sporadic TestEmptyJobWithDFS failure due to NPE is JobTracker.submitJob(),org.apache.hadoop.mapred.TestEmptyJobWithDFS has failed a couple of times (low reproducibility) with the following exception:  2006-10-17 21:48:24;875 INFO  ipc.Server (Server. lang.NullPointerException         tached.,Resolved,Not A Problem,,Owen O'Malley,Nigel Daley,Wed; 18 Oct 2006 22:34:35 +0000,Mon; 16 Jan 2012 10:09:54 +0000,Mon; 16 Jan 2012 10:09:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-100
MAPREDUCE-101,Bug,Major,,Deserialize interface to support mechanism for supporting progress method in RecordReader,If the deserializer buffers the inputstream; there's no way for the record reader to support progress or even know when EOF is coming without directly catching EOFException from the deserialize() method.  so; theRecordReader.next(key;value) method could catch EOFException to return false when needed;but  the progress method cannot know where in the inputstream it is without an API from the deserializer in the case where the deserializer does buffering.  An example of this would be implementing LineRecordReader.LineReader as a deserializer since it reads data into its own buffer.,Open,Unresolved,,Unassigned,Pete Wyckoff,Fri; 12 Sep 2008 17:54:57 +0000,Sat; 20 Jun 2009 07:50:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-101
MAPREDUCE-102,Bug,Major,,NPE in tracker expiry thread.,I see NullPointerExceptions in Task Expiry thread of the JobTracker. Exception log in JT:,Resolved,Not A Problem,,Unassigned,Vinod Kumar Vavilapalli,Mon; 2 Mar 2009 11:19:19 +0000,Tue; 3 Sep 2013 07:32:23 +0000,Tue; 3 Sep 2013 07:32:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-102
MAPREDUCE-103,Bug,Major,security,The TaskTracker's shell environment should not be passed to the children.,HADOOP-2838 and HADOOP-5981 added support to make the TaskTracker's shell environment available to the tasks. This has two problems:   1. It makes the task tracker's environment part of the interface to the task; which is fairly brittle.   2. Security code typically only passes along whitelisted environment variables instead of everything to prevent accidental leakage from the administrator's account.,Resolved,Fixed,,Unassigned,Owen O'Malley,Tue; 16 Jun 2009 20:46:41 +0000,Tue; 22 Jul 2014 21:33:32 +0000,Tue; 22 Jul 2014 21:33:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-103
MAPREDUCE-104,Bug,Major,,Not able to refresh file cache,I ran a map reduce job with file caching. When I reran it with an updated file jar; I got the following error :   108),Resolved,Cannot Reproduce,,Mahadev konar,Hairong Kuang,Wed; 28 Mar 2007 00:23:10 +0000,Tue; 3 Sep 2013 09:12:57 +0000,Tue; 3 Sep 2013 09:12:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-104
MAPREDUCE-105,Bug,Major,,Handling of mapred.task.profile.params is hprof specific,"TaskRunner does hprof specific handling of the mapred.task.profile.params; specifically it assumes the ""file=%s"" which is hprof specific. It would be nice to generalise it to allow using yourkit and other profilers. Similarly JobClient tries to fetch 'profile.out' which is again hprof specific.",Open,Unresolved,MAPREDUCE-420,Arun C Murthy,Arun C Murthy,Fri; 13 Jun 2008 07:40:10 +0000,Thu; 22 Oct 2009 12:57:54 +0000,,,,,,MAPREDUCE-1131,https://issues.apache.org/jira/browse/MAPREDUCE-105
MAPREDUCE-106,Bug,Major,,The temporary disk space limits should not skip jobs,In HADOOP-657; we added disk space modeling and throttling. The scheduler currently picks the next job if there isn't enough space; which can lead to starvation of jobs that require a lot of space. It should not schedule any task if the first job can't use the space.,Resolved,Incomplete,,Unassigned,Owen O'Malley,Mon; 29 Sep 2008 16:49:01 +0000,Fri; 18 Jul 2014 23:49:53 +0000,Fri; 18 Jul 2014 23:49:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-106
MAPREDUCE-107,Bug,Major,,Tasks fail due to lost mapout,When I ran a job; each map task of which generates Gbytes of map output; I saw many tasks failed with following errors: Map output lost; rescheduling: getMapOutput(task_0993_m_000013_0;140) failed :  534),Resolved,Fixed,,Unassigned,Hairong Kuang,Thu; 17 May 2007 18:15:58 +0000,Thu; 17 Jul 2014 17:11:27 +0000,Thu; 17 Jul 2014 17:11:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-107
MAPREDUCE-108,Bug,Major,,Blacklisted hosts may not be able to serve map outputs,After a node fails 4 mappers (tasks); it is added to blacklist thus it will no longer accept tasks. But; it will continue serve the map outputs of any mappers that ran successfully there.  However; the node may not be able serve the map outputs either.  This will cause the reducers to mark the corresponding map outputs as from slow hosts;  but continue to try to get the map outputs from that node. This may lead to waiting forever.,Resolved,Incomplete,,Amar Kamat,Runping Qi,Thu; 8 Nov 2007 23:26:08 +0000,Thu; 17 Jul 2014 18:23:30 +0000,Thu; 17 Jul 2014 18:23:30 +0000,,,,,HADOOP-4305,https://issues.apache.org/jira/browse/MAPREDUCE-108
HADOOP-7542,Improvement,Major,conf,Change XML format to 1.1 to add support for serializing additional characters,"Feature added by this Jira has a problem while setting up some of the invalid xml characters e.g. ctrl-A e.g. mapred.textoutputformat.separator = "" u0001"" (ctrl-A) and problem happens when it is de-serialized (read back) by job tracker; where it encounters invalid xml character.  The test for this feature public : testFormatWithCustomSeparator() does not serialize the jobconf after adding the separator as ctrl-A and hence does not detect the specific problem.  Here is an exception:    INFO mapred.FileInputFormat: Total input paths to process : 1 org.apache.hadoop.ipc.RemoteException:  lang.RuntimeException: org.xml.sax.SAXParseException: Character reference ""#1"" is an invalid XML character. ",Resolved,Won't Fix,,Michael Katzenellenbogen,Suhas Gogate,Sat; 13 Dec 2008 00:36:36 +0000,Sun; 23 Sep 2012 10:54:56 +0000,Sun; 23 Sep 2012 10:54:21 +0000,,0.20.2,,,HADOOP-3295,https://issues.apache.org/jira/browse/HADOOP-7542
MAPREDUCE-110,Bug,Major,,Unit tests for LinuxTaskController binary,We should have unit tests in C for various functions used by LinuxTaskController binary. These would help a lot in maintaining the code and easy spotting of bugs.,Resolved,Duplicate,HADOOP-4491,Unassigned,Vinod Kumar Vavilapalli,Thu; 4 Jun 2009 07:43:25 +0000,Tue; 7 Jul 2009 08:26:56 +0000,Tue; 7 Jul 2009 08:26:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-110
MAPREDUCE-111,Bug,Major,jobtracker,JobTracker.getSystemDir throws NPE if it is called during intialization,JobTracker.getSystemDir throws NPE if it is called during intialization. It should check if fileSystem is null and throw IllegalStateException; as in getFilesystemName method.,Resolved,Not A Problem,,Unassigned,Amareshwari Sriramadasu,Fri; 22 May 2009 05:29:44 +0000,Tue; 22 Jul 2014 19:53:43 +0000,Tue; 22 Jul 2014 19:53:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-111
MAPREDUCE-112,Bug,Blocker,,Reduce Input Records and Reduce Output Records counters are not being set when using the new Mapreduce reducer API,After running the examples wordcount (which uses the new API); the reduce input and output record counters always show 0. This is because these counters are not getting updated in the new API,Resolved,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Fri; 13 Feb 2009 05:55:25 +0000,Thu; 1 Oct 2009 08:04:01 +0000,Tue; 15 Sep 2009 06:31:22 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-112
MAPREDUCE-113,Bug,Major,,[mapred] Job submission to an invalid queue should fail.,If ACLs are enabled; this case is handled; though not with a clear message to the user. Job submission to an invalid queue should be detected and dealt with. Irrespective of ACLs.,Resolved,Not A Problem,,Amar Kamat,Vinod Kumar Vavilapalli,Mon; 22 Sep 2008 11:54:47 +0000,Tue; 3 Sep 2013 09:19:47 +0000,Tue; 3 Sep 2013 09:19:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-113
MAPREDUCE-114,Bug,Major,,All reducer tasks are finished; while some mapper tasks are still running,In a high load environment (i.e. multiple jobs are queued up to be executed); when all reducer tasks of a job are finished; some mapper tasks of the same job may still running (possibly re-executed due to lost task tracker; etc).  This should not happen when a job has at least one reducer task. When all reducer tasks are in SUCCEEDED state; the Hadoop JobTracker should kill all running mapper tasks; since execution would be meaningless. The job should also switch to SUCCEEDED state when all reducer tasks of that job succeeded successfully.,Resolved,Won't Fix,MAPREDUCE-83,Unassigned,Qi Liu,Mon; 13 Apr 2009 00:52:26 +0000,Thu; 11 Apr 2013 19:47:40 +0000,Thu; 11 Apr 2013 19:47:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-114
MAPREDUCE-115,Bug,Major,,Map tasks are receiving FileNotFound Exceptions for spill files on a regular basis and are getting killed,The following is the log  Map tasks are unable to locate the spill files when they are doing the final merge (mergeParts).    2208),Resolved,Cannot Reproduce,,Unassigned,Jothi Padmanabhan,Tue; 19 Aug 2008 10:23:37 +0000,Fri; 24 Sep 2010 08:23:16 +0000,Fri; 27 Aug 2010 23:31:55 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-115
MAPREDUCE-116,Bug,Major,,Have a test to verify that descendent processes of tasks that ignore SIGTERM are eventually cleaned up by a SIGKILL,HADOOP-2721 added TestKillSubProcesses to test that all the processes descending from a task are cleaned up with a SIGTERM when task finishes. The functionality to eventually send a SIGKILL to processes that ignore SIGTERM is already in place; but we don't have a test verifying this yet.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Fri; 6 Mar 2009 12:08:39 +0000,Fri; 8 May 2015 18:04:10 +0000,Fri; 8 May 2015 18:04:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-116
MAPREDUCE-117,Bug,Major,,ReduceCopier sleeps for a hardcoded interval of 5secs,Currently the ReduceCopier.run has a hard-coded 5s sleep which hurts jobs where latency is important; we really should have a mechanism where the thread fetching task-completion events should notify the ReduceCopier.run.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Tue; 27 Jan 2009 08:34:55 +0000,Sat; 20 Jun 2009 07:50:54 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-117
MAPREDUCE-118,Bug,Blocker,client,Job.getJobID() will always return null,JobContext is used for a read-only view of job's info. Hence all the readonly fields in JobContext are set in the constructor. Job extends JobContext. When a Job is created; jobid is not known and hence there is no way to set JobID once Job is created. JobID is obtained only when the JobClient queries the jobTracker for a job-id.; which happens later i.e upon job submission.,Closed,Fixed,,Amareshwari Sriramadasu,Amar Kamat,Tue; 20 Jan 2009 07:34:21 +0000,Fri; 2 Sep 2011 22:13:20 +0000,Tue; 1 Jun 2010 05:26:10 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-118
MAPREDUCE-119,Bug,Major,,JobTracker and TaskTracker enter infinite loop when TaskTracker reports bad taskid,If the TaskTracker somehow gets into a state where it has a task in COMMIT_PENDING state that the JobTracker does not know about; the JobTracker will throw NPEs while processing heartbeats. Due to HADOOP-3987; this causes the JT and TT to enter an infinite heartbeat loop with no delays; and the TT fails to make progress.,Resolved,Cannot Reproduce,,Unassigned,Todd Lipcon,Thu; 30 Apr 2009 18:58:34 +0000,Thu; 11 Feb 2010 07:04:44 +0000,Thu; 11 Feb 2010 07:04:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-119
MAPREDUCE-120,Bug,Major,,Reducer sort failed due to wrong key class,"One of my job's reducers failed due to the following exception:   io.IOException: wrong key class: class org.apache.hadoop.io.LongWritable is not class org.apache.hadoop.io.Text 	 happened? My job conf specified Text as the map output key class; and other map output files had  the correct key class!",Open,Unresolved,,Unassigned,Runping Qi,Tue; 6 Nov 2007 21:47:56 +0000,Thu; 22 Mar 2012 13:44:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-120
MAPREDUCE-121,Bug,Major,distributed-cache,DistributedCache parses Paths with sheme or port components incorrectly,"When passing paths with scheme or port components set up (like  ""hdfs: hello"").  Other DistributedCache methods need to be reviewed to.",Open,Unresolved,,Unassigned,Andrew Gudkov,Mon; 21 Jul 2008 10:49:42 +0000,Mon; 17 Jan 2011 23:18:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-121
MAPREDUCE-122,Bug,Major,,JobTracker.addNewTracker() unnecessarily resolves already resolved nodes,hostnameToNodeMap maintains a map from hostname to resolved-address. JobTracker.addNewTracker() resolves a node's address if the node is not present in hostnameToNodeMap but uses tracker-name to index into hostnameToNodeMap instead of hostname.,Resolved,Incomplete,,Unassigned,Amar Kamat,Thu; 13 Nov 2008 08:12:05 +0000,Sat; 19 Jul 2014 00:08:36 +0000,Sat; 19 Jul 2014 00:08:36 +0000,,,,,HADOOP-3780,https://issues.apache.org/jira/browse/MAPREDUCE-122
MAPREDUCE-123,Bug,Major,,HistoryViewer usage string is misleading.,$ hadoop job -history Usage: JobClient -history jobOutputDir&#93;  The input is actually a history-location (for e.g.; specified by hadoop.job.history.user.location) which happens to default to a jobOutputDir. The usage string should reflect this.  Also the restriction for history files to be in a _logs history is only intended to be used in conjuction with jobOutputDir; as a default location.,Resolved,Implemented,,Unassigned,Vinod Kumar Vavilapalli,Tue; 9 Sep 2008 06:40:02 +0000,Tue; 12 May 2015 09:52:25 +0000,Tue; 12 May 2015 09:52:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-123
MAPREDUCE-124,Bug,Major,,When abortTask of OutputCommitter fails with an Exception for a map-only job; the task is marked as success,Running TestTaskFail with numreduces = 0 demonstrates this problem.,Resolved,Fixed,,Amareshwari Sriramadasu,Jothi Padmanabhan,Thu; 11 Jun 2009 11:04:42 +0000,Tue; 7 Jul 2009 17:34:21 +0000,Thu; 2 Jul 2009 10:52:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-124
MAPREDUCE-125,Bug,Major,,JobTracker might wrongly log a tip as failed,Consider the following case 1) tempt and log the TIP as failed.,Resolved,Incomplete,,Unassigned,Amar Kamat,Thu; 4 Sep 2008 09:43:10 +0000,Fri; 18 Jul 2014 22:48:18 +0000,Fri; 18 Jul 2014 22:48:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-125
MAPREDUCE-126,Bug,Major,,Job history analysis showing wrong job runtime,Analysis of completed jobs shows wrong runtime. Here is the faulty code    I think it should be,Resolved,Incomplete,,Unassigned,Amar Kamat,Wed; 8 Apr 2009 11:37:41 +0000,Tue; 22 Jul 2014 18:37:50 +0000,Tue; 22 Jul 2014 18:37:50 +0000,,0.20.1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-126
MAPREDUCE-127,Bug,Major,,Task trackers don't register with the job tracker until after they clean out their working directory,"When TaskTrackers are started; they immediately start deleting their working directory; which can take 30+ minutes. Unfortunately; that means they don't register themselves with the JobTracker for a long time; so it looks like the cluster is ""missing"".",Resolved,Invalid,,Owen O'Malley,Owen O'Malley,Tue; 24 Oct 2006 16:35:05 +0000,Mon; 16 Jan 2012 10:12:17 +0000,Mon; 16 Jan 2012 10:12:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-127
MAPREDUCE-128,Bug,Major,,JobTracker Startup failed with java.net.BindException,We have seen one case where JobTracker failed with IOException but later retries of startup fails with BindException going into loop before failing. Here is the stacktrace.  stack trace 2007-10-23 05:51:19;374 WARN org.apache.hadoop.mapred.JobTracker: Error starting tracker:  1788)  stack trace,Open,Unresolved,,Unassigned,Lohit Vijayarenu,Thu; 25 Oct 2007 20:53:08 +0000,Sat; 12 Jan 2013 19:26:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-128
MAPREDUCE-129,Bug,Major,,job_null_0001 in jobid,When I submit a job before jobtracker is fully up; I occasionally get  jobid of job_null_0001.  knoguchi $ hadoop -jar ...   INFO mapred.JobClient:  map 0% reduce 0%,Resolved,Fixed,,Owen O'Malley,Koji Noguchi,Fri; 12 Oct 2007 00:24:56 +0000,Thu; 17 Jul 2014 18:10:18 +0000,Thu; 17 Jul 2014 18:10:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-129
MAPREDUCE-130,Bug,Major,,Delete the jobconf copy from the log directory of the JobTracker when the job is retired,The JobTracker (for web-ui viewing purposes); copies the jobconf from the hdfs and store it in the log directory. The file should be deleted when the job is retired (removed from memory).,Resolved,Fixed,,Amar Kamat,Devaraj Das,Tue; 9 Jun 2009 05:53:51 +0000,Wed; 20 Jul 2011 08:03:16 +0000,Fri; 26 Jun 2009 09:01:12 +0000,,,,,MAPREDUCE-2714,https://issues.apache.org/jira/browse/MAPREDUCE-130
MAPREDUCE-131,Bug,Major,,After HADOOP-5420; tasks hang when the taskcontroller.cfg has multiple entries for mapred.local.dir,HADOOP-5420 refactored code from taskcontroller.c - check_tt_root() to configuration.c for reuse. While doing this; this bug got introduced because of which all tasks hang when a cluster is configured with multiple mapred local directories. This happens because of the latest code in check_tt_root() which never advances the mapred_local_dir pointer and gets stuck in an infinite loop.,Resolved,Duplicate,MAPREDUCE-842,Unassigned,Vinod Kumar Vavilapalli,Fri; 12 Jun 2009 12:59:33 +0000,Tue; 23 Jun 2009 08:26:51 +0000,Tue; 23 Jun 2009 08:26:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-131
MAPREDUCE-132,Bug,Major,jobtracker,getSetupAndCleanupTasks should return multiple tasks in a heartbeat,getSetupAndCleanupTasks in JobTracker returns one task per heartbeat. With HADOOP-3136; schedulers give multiple tasks  per heartbeat; getSetupAndCleanupTasks should also give multiple tasks per heartbeat.,Resolved,Incomplete,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 4 Feb 2009 03:24:50 +0000,Mon; 21 Jul 2014 19:38:17 +0000,Mon; 21 Jul 2014 19:38:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-132
MAPREDUCE-133,Bug,Major,,Getting errors in reading the output files of a map/reduce job immediately after the job is complete,"I have an app that fire up map reduce jobs sequentially. The output of one job if the input of the next. I observe that many map tasks failed due to file read errors:   709)   Those tasks succeeded in the second or third try.  After interting 10 seconds sleep between consecutive jobs; the problem disappear.  Here is my code to detect whether a job is completed:        try {         running = jc.submitJob(job);         String jobId = running.getJobID();         System.out.println(""start job: t"" + jobId);         while (!running.isComplete()) {           try  {             Thread.sleep(1000);           }  catch (InterruptedException e) {}           running = jc.getJob(jobId);         }         sucess = running.isSuccessful();       } finally {         if (!sucess &amp; (running != null))  {           running.killJob();         }         jc.close();       }",Resolved,Cannot Reproduce,,Owen O'Malley,Runping Qi,Tue; 25 Apr 2006 05:01:13 +0000,Sun; 17 Jul 2011 20:50:14 +0000,Sun; 17 Jul 2011 20:50:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-133
MAPREDUCE-134,Bug,Major,,TaskTracker startup fails if any mapred.local.dir entries don't exist,"This appears to have been introduced with the ""check for enough free space"" before startup.  It's debatable how best to fix this bug. I will submit a patch which ignores directories for which the DF utility fails. This is letting me continue operation on my cluster (where the number of drives varies; so there are entries in mapred.local.dir for drives that aren't on all cluster nodes); but a cleaner solution is probably better. I'd lean towards ""check for existence""; and ignore the dir if it doesn't  - but don't depend on DF to fail; since DF could fail for other reasons without meaning you're out of disk space. I argue that a TaskTracker should start up if all directories that can be written to in the list have enough space. Otherwise; a failed drive per cluster machine means no work ever gets done.",Resolved,Duplicate,MAPREDUCE-2413,Ravi Gummadi,Bryan Pendleton,Tue; 18 Jul 2006 18:10:53 +0000,Mon; 16 Jan 2012 09:21:39 +0000,Mon; 16 Jan 2012 09:21:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-134
MAPREDUCE-135,Bug,Major,,speculative task failure can kill jobs,We had a case where the random writer example was killed by speculative execution. It happened like:  task_0001_m_000123_0 - starts task_0001_m_000123_1 - starts and fails because attempt 0 is creating the file task_0001_m_000123_2 - starts and fails because attempt 0 is creating the file task_0001_m_000123_3 - starts and fails because attempt 0 is creating the file task_0001_m_000123_4 - starts and fails because attempt 0 is creating the file  job_0001 is killed because map_000123 failed 4 times. From this experience; I think we should change the scheduling so that:    1. Tasks are only allowed 1 speculative attempt.   2. TIPs don't kill jobs until they have 4 failures AND the last task under that tip fails.  Thoughts?,Resolved,Incomplete,,Unassigned,Owen O'Malley,Mon; 5 Feb 2007 21:49:36 +0000,Thu; 17 Jul 2014 16:46:13 +0000,Thu; 17 Jul 2014 16:46:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-135
MAPREDUCE-136,Bug,Major,,Incorrect DBInputFormat transaction context,In my Map  transaction isolation since we are in DBInputFormat? and why I can't overwrite it in my jdbc call even if explicitly set autocommit to false and transaction isolation type to default (repeat-read).,Open,Unresolved,,Unassigned,Yuchen,Tue; 2 Jun 2009 20:37:04 +0000,Sat; 20 Jun 2009 07:50:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-136
MAPREDUCE-137,Bug,Major,test,org.apache.hadoop.mapred.TestJobDirCleanup.testJobDirCleanup timesout occasionally ,org.apache.hadoop.mapred.TestJobDirCleanup.testJobDirCleanup timesout occasionally in hudson builds. One such build @ http: ,Resolved,Duplicate,MAPREDUCE-1494,Unassigned,Amareshwari Sriramadasu,Mon; 15 Jun 2009 03:36:27 +0000,Mon; 7 Jun 2010 07:41:15 +0000,Mon; 7 Jun 2010 07:41:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-137
MAPREDUCE-138,Bug,Major,,Rework job-setup and job-cleanup tasks,Currently we have a notion of map- {setup|cleanup} TIP and reduce-{setup|cleanup}  TIP of which only 1 setup and cleanup tasks are picked by the JobInProgress. Also a lot of state-maintenence of these TIPs are done by the JobInProgress itself; outside of the more logical place i.e. TaskInProgress.  We really should rework this to have a single setup and cleanup task which isn't associated with a map or reduce task i.e. into separate task types. What we have currently is quite ungainly and hard to maintain.,Resolved,Won't Fix,,Devaraj Das,Arun C Murthy,Wed; 15 Oct 2008 21:05:27 +0000,Sat; 19 Jul 2014 19:00:49 +0000,Sat; 19 Jul 2014 19:00:49 +0000,,,,MAPREDUCE-29,MAPREDUCE-251,https://issues.apache.org/jira/browse/MAPREDUCE-138
MAPREDUCE-139,Bug,Major,,JobTracker crashes Sun JVM,"From our jobtacker's .out file:  #  	An unexpected error has been detected by HotSpot Virtual Machine: # 	SIGSEGV (0xb) at pc=0xf27bf825; pid=24028; tid=1856498608 # 	Java VM: Java HotSpot(TM) Server VM (1.5.0_06-b05 mixed mode) 	Problematic frame: 	J  org.mortbay.util.ByteArrayPool.getByteArray(I)[B # 	An error report file with more information is saved as hs_err_pid24028.log # 	If you would like to submit a bug report; please visit: 	http: tcsh HOSTTYPE=x86_64-linux OSTYPE=linux MACHTYPE=x86_64",Resolved,Cannot Reproduce,,Owen O'Malley,Marco Nicosia,Fri; 28 Jul 2006 23:03:22 +0000,Mon; 16 Jan 2012 09:43:22 +0000,Mon; 16 Jan 2012 09:43:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-139
MAPREDUCE-140,Bug,Major,,TaskMemoryManager not enforcing memory limits in the presence of rogue tasks,nan,Resolved,Duplicate,HADOOP-5881,Unassigned,Vinod Kumar Vavilapalli,Wed; 25 Mar 2009 08:03:20 +0000,Tue; 22 Sep 2009 06:08:52 +0000,Tue; 22 Sep 2009 06:08:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-140
MAPREDUCE-141,Bug,Major,,reduce % complete incorrect in webui,"I have a running job that has 1002 reduces.  Currently the JobTracker WebUI has the following:  Kind	 %Complete	Num Tasks	Pending	Running	Complete  Killed  Failures map snip reduce  100.00%	1002	0	2	1000	0	10  So 2 reduces are still running but the % complete is 100%.",Resolved,Duplicate,HADOOP-5210,Unassigned,Nigel Daley,Fri; 22 Dec 2006 21:47:40 +0000,Mon; 16 Jan 2012 10:23:52 +0000,Mon; 16 Jan 2012 10:23:52 +0000,,,,,MAPREDUCE-7,https://issues.apache.org/jira/browse/MAPREDUCE-141
MAPREDUCE-142,Bug,Major,,Race condition in DistributedCache,"When an older version of a file in DistributedCache exists locally and multiple tasks per node start; they can run into a race condition:  dir filename is in use and cannot be refreshed 	at org.apache.hadoop.filecache.DistributedCache.localizeCache(DistributedCache. 134)  We ran a job with the wrong file; then around 50 minutes later we put the fixed version into DFS; and ran the same job again. The job had 11;000 maps ~ about 4-5 waves of map tasks and produced 3;500 failed tasks with above error. We eventually killed it and restarted the same job again; with no problems this time.",Resolved,Cannot Reproduce,,Mahadev konar,Christian Kunz,Sat; 9 Feb 2008 01:26:16 +0000,Fri; 2 Apr 2010 23:08:22 +0000,Fri; 2 Apr 2010 23:08:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-142
MAPREDUCE-143,Bug,Major,,OOM in the TaskTracker while serving map outputs,Saw this exception in the TT logs:  2009-02-06 06:18:08;553 ERROR org.mortbay.log: EXCEPTION  2879),Resolved,Incomplete,,Unassigned,Devaraj Das,Fri; 6 Feb 2009 07:49:45 +0000,Mon; 21 Jul 2014 19:44:43 +0000,Mon; 21 Jul 2014 19:44:43 +0000,,,,MAPREDUCE-2510,,https://issues.apache.org/jira/browse/MAPREDUCE-143
MAPREDUCE-144,Bug,Major,tasktracker,TaskMemoryManager should log process-tree's status while killing tasks.,This helps a lot in debugging why a particular task has gone beyond memory limits.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 25 Mar 2009 10:14:02 +0000,Tue; 24 Aug 2010 21:13:18 +0000,Tue; 8 Sep 2009 14:56:12 +0000,,,,HADOOP-6230,,https://issues.apache.org/jira/browse/MAPREDUCE-144
MAPREDUCE-145,Bug,Major,,DiskChecker$DiskErrorException when 'reduce > reduce',We have  9900 maptasks and 60 reducetasks in the job. When all the other 59 reducetasks have finished; the last reducetask runs so slow and finally finished after throwing out a lot of DiskErrorExceptions.  The following is the tasktracker log on which the reducetask is running.   2009-03-18 14:39:52;025 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker file.out in any of the configured local directories,Resolved,Cannot Reproduce,,Unassigned,Leitao Guo,Wed; 18 Mar 2009 07:19:40 +0000,Mon; 21 Jul 2014 22:03:32 +0000,Mon; 21 Jul 2014 22:03:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-145
MAPREDUCE-146,Bug,Major,,Stale job files in mapred system directory,In one scenario; job client uploaded the job split file and job jar onto the mapred system directory but got killed before the actual job got submitted and or before the job got known to the JT. In such situations; the split and jar files are left as garbage as JT doesn't know of the job yet. On a long running JT; this garbage can accumulate.,Resolved,Not A Problem,,Unassigned,Vinod Kumar Vavilapalli,Thu; 26 Feb 2009 11:09:00 +0000,Mon; 21 Jul 2014 21:07:44 +0000,Mon; 21 Jul 2014 21:07:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-146
MAPREDUCE-147,Bug,Major,,server can't set username in JobClient.submitJob for jobs submitted on behalf of other users,I have a rpc server that sits in front of hadoop and submits mapreduce jobs on behalf of users (humans).  However; because hadoop gets username information from the unix username of the submitting process; all my jobs appear to be from the unix account used by the webserver.  I tried to fix it by doing this:  JobConf conf = ... JobClient client = ... conf.setUser(username); client.submitJob(conf);  But that doesn't work because submitJob overwrites the username I wrote with setUser.  Instead; submitJob should only insert a username into the job if it is not in the config already.  Alternately; the username might be inserted at the time of creation of the JobConf; so that I have an opportunity to overwrite it; or the JobConf could supply some hook for me to insert some alternate username.,Resolved,Won't Fix,,Unassigned,Michael Bieniosek,Tue; 16 Dec 2008 02:13:02 +0000,Mon; 21 Jul 2014 17:27:29 +0000,Mon; 21 Jul 2014 17:27:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-147
MAPREDUCE-148,Bug,Major,,A successful tip can fail unnecessarily,Consider the following sequence of events 1. tip t has 5 tempt_4 reports failure and the tip t is failed based on the call to TaskInProgress.incompleteSubTask(). Here the tip t is failed unnecessarily.,Resolved,Incomplete,,Unassigned,Amar Kamat,Tue; 19 Aug 2008 19:23:57 +0000,Fri; 18 Jul 2014 20:59:08 +0000,Fri; 18 Jul 2014 20:59:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-148
MAPREDUCE-149,Bug,Major,,Class JobControl needs to be rewritten for safe concurrency,"The use of concurrency control and synchronization in JobControl is broken.  Consider   	The locking in addToQueue() and toArrayList() is supposed to create per-queue locking for the queues referenced by the fields readyJobs; runningJobs; successfulJobs; waitingJobs; and failedJobs.  But this is compromised by the fact th change the state of the queues or runnerState should set stateChanged to true and call notifyAll().     	Ideally; allFinished() should be changed to use wait() as well. This would change the public interface of the class and break existing clients.  So this method should be @Deprecated; and a new waitForAllFinished() method should be added.     	The queue fields should be assigned HashMap objects instead of Hashtable objects. There is no advantage to using the synchronization provided by Hashtable.",Resolved,Incomplete,,Unassigned,Aaron Greenhouse,Fri; 13 Jun 2008 16:04:56 +0000,Fri; 18 Jul 2014 05:35:07 +0000,Fri; 18 Jul 2014 05:35:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-149
MAPREDUCE-150,Bug,Major,,speculative reduce should touch output files only through OutputFormat,HADOOP-1127 introduced speculative reduce.  This was implemented by having the MapReduce kernel directly manipulate a job's output files.  This is inconsistent with the architecture of the InputFormat and OutputFormat interfaces.  The kernel should never directly operate on job input or output; always instead deferring to these interfaces.  To correct this; we will need to add some new methods to OutputFormat; something like:    void cleanupOutput(JobConf job; String tempName);  These should be implemented in OutputFormatBase; which should be renamed FileOutputFormat.  To prevent this happening again; we should also move JobConf#getInputPath(); #setInputPath(); #getOutputPath(); and #setOutputPath() to static methods on FileInputFormat and FileOutputFormat; since these methods are specific to jobs with file inputs and outputs (and not; e.g.; HBase tables).,Open,Unresolved,,Unassigned,Doug Cutting,Tue; 22 May 2007 18:47:37 +0000,Sat; 20 Jun 2009 07:50:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-150
MAPREDUCE-151,Bug,Major,,JobClient doesn't wait for all task completion events before exiting,The JobClient should pull all of the task completion events from the JobTracker before exiting the loop and returning to the application. Otherwise the failing task may be lost in the backlog since only 10 task events are fetched per a second.,Resolved,Incomplete,,Owen O'Malley,Owen O'Malley,Wed; 30 Jul 2008 00:05:29 +0000,Fri; 18 Jul 2014 19:55:34 +0000,Fri; 18 Jul 2014 19:55:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-151
MAPREDUCE-152,Bug,Major,,getMapOutput() keeps failing too many times before the tasktracker fails,We are running a big job on our cluster. There are about 400 reducers. Around 361 reducers finished successfully while the last batch of 39 reducers all failed roughly around the same time. After examining the log files; the following error info was found 858 times for a single tasktracker:  2008-04-21 02:42:45;368 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_200804101742_0001_m_032077_2;396) failed : 2008-04-21 02:42:49;468 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_200804101742_0001_m_032077_2;396) failed : 2008-04-21 02:43:03;717 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_200804101742_0001_m_032077_2;396) failed :   Shouldn't the task tracker failed early without trying so many times?,Resolved,Incomplete,,Unassigned,Yiping Han,Mon; 28 Apr 2008 21:43:13 +0000,Thu; 17 Jul 2014 22:12:01 +0000,Thu; 17 Jul 2014 22:12:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-152
MAPREDUCE-153,Bug,Major,,TestJobInProgressListener sometimes timesout,"It times out with ""Could not find  work in any of the configured local directories"".",Closed,Fixed,MAPREDUCE-631,Amar Kamat,Amar Kamat,Tue; 5 May 2009 19:50:04 +0000,Tue; 24 Aug 2010 21:13:19 +0000,Fri; 10 Jul 2009 11:48:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-153
MAPREDUCE-154,Bug,Major,,Mapper runs out of memory,The hadoop job has the task of processing 4 directories in HDFS; each with 15 files.  This is sample data; a test run; before I go to the needed 5 directories of about 800 documents each.  The mapper takes in nearly 200 pages (not files) and throws an OutOfMemory exception.  The largest file is 17 MB.  If this problem is something on my end and not truly a bug; I apologize.  However; after Googling a bit; I did see many threads of people running out of memory with small data sets.,Resolved,Cannot Reproduce,,Unassigned,Richard J. Zak,Fri; 2 Jan 2009 17:31:32 +0000,Mon; 21 Jul 2014 17:54:32 +0000,Mon; 21 Jul 2014 17:54:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-154
MAPREDUCE-155,Bug,Major,,Each task tracker should not execute more than one speculative task,I noticed that sometimes; a tasktracker started 2 or three speculative mapper tasks. That seems counter productive. You want to speculative execution complete as soon as possible. Thus; it is better to spread speculative execution over multiple trackers. A simple way to  achieve that is to limit the number of speculative eecution concurrently.,Resolved,Incomplete,,Unassigned,Runping Qi,Fri; 9 Nov 2007 17:39:48 +0000,Thu; 17 Jul 2014 18:24:51 +0000,Thu; 17 Jul 2014 18:24:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-155
MAPREDUCE-156,Bug,Major,,ProcessTree.destroy() is sleeping for 5 seconds holding the task slot,Currently; in ProcessTree.destroy(); after sending SIGTERM to the task JVM; TT sleeps for 5 seconds(default value of mapred.tasktracker.tasks.sleeptime-before-sigkill) before sending SIGKILL. This seems to be blocking the task slot(not getting released) for 5 seconds. We should avoid this so that another task could be launched in that slot immediately.,Resolved,Won't Fix,,Unassigned,Ravi Gummadi,Mon; 27 Apr 2009 10:20:13 +0000,Tue; 22 Jul 2014 19:14:12 +0000,Tue; 22 Jul 2014 19:14:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-156
MAPREDUCE-157,Sub-task,Major,,Job History log file format is not friendly for external tools.,Currently; parsing the job history logs with external tools is very difficult because of the format. The most critical problem is that newlines aren't escaped in the strings. That makes using tools like grep; sed; and awk very tricky.,Closed,Fixed,,Jothi Padmanabhan,Owen O'Malley,Thu; 14 May 2009 16:38:10 +0000,Wed; 12 Jan 2011 04:45:07 +0000,Thu; 17 Sep 2009 05:10:49 +0000,,0.20.1,,MAPREDUCE-864;MAPREDUCE-975;MAPREDUCE-198;MAPREDUCE-980;MAPREDUCE-277,MAPREDUCE-2251,https://issues.apache.org/jira/browse/MAPREDUCE-157
MAPREDUCE-158,Bug,Major,tasktracker,mapred.userlog.retain.hours killing long running tasks,One can reproduce the scenario by configuring mapred.userlog.retain.hours to 1hr; and running tasks that take more than an hour.  More info on closed ticket HADOOP-5591.,Resolved,Duplicate,MAPREDUCE-927,Unassigned,Billy Pearson,Tue; 31 Mar 2009 17:02:47 +0000,Thu; 18 Mar 2010 05:42:35 +0000,Thu; 18 Mar 2010 05:42:35 +0000,,,,,HADOOP-5591,https://issues.apache.org/jira/browse/MAPREDUCE-158
MAPREDUCE-159,Bug,Major,,Reduce the number of progress calls in the merge code,The number of Progressable.progress calls in the merge code should be reduced. Specifically; MergeQueue.lessThan has a progress call that accounts for ~8% of the CPU of a running reducer.,Open,Unresolved,,Devaraj Das,Devaraj Das,Tue; 6 May 2008 12:45:59 +0000,Sat; 20 Jun 2009 07:50:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-159
MAPREDUCE-160,Bug,Critical,,Final map task gets stuck,I've seen numerous jobs lately where the final map task gets stuck; never finishing. The jobtracker doesn't reassign the task. A restart of the tasktracker solves the issue and the job can finish. In the web interface it turns up as:  task_0028_m_000534_0 node17.herd1 RUNNING 0.00%    10-Nov-2006 12:21:12 10-Nov-2006 12:22:19 (1mins; 6sec) Task failed to report status for 604 seconds. Killing.  Only exception I find in that tasktracker log is this (a few times):  532),Resolved,Not A Problem,,Owen O'Malley,Johan Oskarsson,Fri; 10 Nov 2006 14:31:40 +0000,Mon; 16 Jan 2012 10:16:48 +0000,Mon; 16 Jan 2012 10:16:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-160
MAPREDUCE-161,Bug,Major,,Tasks are not scheduled even though task trackers have extra slots,I ran a job with 51 reduce tasks on a cluster with 13 task trackers running Hadoop 0.19. Each task tracker has 5 reduce slots. Initially; each task tracker accepted 4 reduce tasks as expected. However;  3 task trackers were put into blacklist because many tasks failed on them. However; those failed tasks stayed in pending state; not being scheduled to other task trackers; even though each of the other healthy tracker has one free slot.,Resolved,Incomplete,,Unassigned,Runping Qi,Thu; 19 Feb 2009 19:44:04 +0000,Mon; 21 Jul 2014 20:29:07 +0000,Mon; 21 Jul 2014 20:29:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-161
MAPREDUCE-162,Bug,Major,,[mapred] Change TaskMemoryManager to use JvmIDs instead of TaskIDs for memory-tracking.,To monitor tasks; TaskMemoryManager uses taskIDs to find pidFiles of the tasks. HADOOP-249 introduced jvm re-use because of which multiple tasks can run in a single JVM; and so will share the same pid(pidFile). HADOOP-249 works on a new task by creating a symlink to the pid-file of the task that ran first in the same jvm. Also; the process(jvm) is repeatedly added and removed from monitoring when tasks(under same jvm) come and go. The symlinks and the repetitive addition removal from monitoring can be avoided if TaskMemoryManager uses JvmIDs instead of TaskIDs.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Fri; 19 Sep 2008 12:46:49 +0000,Fri; 18 Jul 2014 23:41:38 +0000,Fri; 18 Jul 2014 23:41:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-162
MAPREDUCE-163,Bug,Major,,TaskTracker's Jetty throws SocketException followed by IllegalStateException,"When running the sort benchmark; these exceptions (271 pairs of them) were noted in the log of the task tracker that was ""lost"".  2007-01-05 19:02:28;663 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_0001_m_009177_0;2415) failed :  534)",Resolved,Duplicate,MAPREDUCE-5,Unassigned,Nigel Daley,Sat; 6 Jan 2007 01:50:06 +0000,Mon; 16 Jan 2012 10:27:42 +0000,Mon; 16 Jan 2012 10:27:42 +0000,,,,,MAPREDUCE-5,https://issues.apache.org/jira/browse/MAPREDUCE-163
MAPREDUCE-164,Bug,Major,,JobHistory should also support searching with special characters,"Today the jobhistory searches a single keyword in jobname. Searching for multiple keywords should also be allowed.  Example : For searching all jobs with ""sleep job"" in them the search string would be "":sleep job"". But it doesnt work because the filename is not decoded before searching.",Open,Unresolved,,Amar Kamat,Amar Kamat,Tue; 24 Mar 2009 03:47:41 +0000,Mon; 21 Jul 2014 22:10:17 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-164
MAPREDUCE-165,Bug,Major,,"the map task output servlet doesn't protect against "".."" attacks","The servlet we use to export the map outputs doesn't protect itself against "".."" attacks. However; because the code adds a  file.out to it; it can only be used to read files with those names.",Open,Unresolved,,Unassigned,Owen O'Malley,Wed; 16 Jan 2008 18:07:34 +0000,Fri; 1 May 2015 07:55:38 +0000,,,,newbie;security,,,https://issues.apache.org/jira/browse/MAPREDUCE-165
MAPREDUCE-166,Bug,Critical,,Remove distcp from hadoop core libraries; and publish documentation,Every time we want to ship a change in distcp; not only do we have to replace the entire version of map-reduce deployed to the clusters; we also have to update internal documentation to reflect those changes.,Resolved,Won't Fix,,Unassigned,Marco Nicosia,Mon; 17 Mar 2008 16:14:38 +0000,Thu; 12 Aug 2010 01:51:21 +0000,Thu; 12 Aug 2010 01:51:21 +0000,,,,,HADOOP-1815,https://issues.apache.org/jira/browse/MAPREDUCE-166
MAPREDUCE-167,Bug,Major,,SAXParseException causes test to run forever,Occassionally; while running TestMiniMRClasspath; I get a SAXParseException that causes the test to run forever.  Two questions I have:  1) what is the underlying cause of the SAXParseException?  2) does the JobTracker realize that a task got lost?  Here's the pertinent test trace:     junit 2007-02-13 19:26:56;058 INFO  mapred.JobClient (JobClient. prepare(450)) - task_0001_r_000000_0 Need 1 map output location(s),Resolved,Incomplete,,Unassigned,Nigel Daley,Wed; 14 Feb 2007 23:40:46 +0000,Thu; 17 Jul 2014 16:49:46 +0000,Thu; 17 Jul 2014 16:49:46 +0000,,,,,HADOOP-1036,https://issues.apache.org/jira/browse/MAPREDUCE-167
MAPREDUCE-168,Bug,Major,,mapred job -list all should display the code for Killed also.,mapred job -list all shows a legend for the states: PREP; SUCCEEDED; FAILED and RUNNING. It should also display the state for KILLED (as 5).,Open,Unresolved,,Unassigned,Hemanth Yamijala,Mon; 4 May 2009 13:16:04 +0000,Tue; 22 Jul 2014 19:22:21 +0000,,,,newbie,,MAPREDUCE-197,https://issues.apache.org/jira/browse/MAPREDUCE-168
MAPREDUCE-169,Bug,Major,,JobHistory should log everything when a job fails or gets killed.,nan,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 6 Mar 2009 11:44:09 +0000,Mon; 21 Jul 2014 21:32:32 +0000,Mon; 21 Jul 2014 21:32:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-169
MAPREDUCE-170,Bug,Major,,JobTracker doesn't need to download job's jar file onto its local filesystem.,nan,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 20 Feb 2009 13:39:21 +0000,Mon; 21 Jul 2014 20:52:35 +0000,Mon; 21 Jul 2014 20:52:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-170
MAPREDUCE-171,Bug,Major,jobtracker;test,TestJobTrackerRestartWithLostTracker sometimes fails while validating history.,TestJobTrackerRestartWithLostTracker fails with following error Duplicate START_TIME seen for task task_200906151249_0001_m_000001 in history file  org.apache.hadoop.mapred.TestJobTrackerRestartWithLostTracker.testRestartWithLostTracker(TestJobTrackerRestartWithLostTracker. 162),Resolved,Fixed,,Unassigned,Amareshwari Sriramadasu,Mon; 15 Jun 2009 08:18:00 +0000,Tue; 22 Jul 2014 21:17:37 +0000,Tue; 22 Jul 2014 21:17:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-171
MAPREDUCE-172,Bug,Major,,Reducers stuck in 'sort',A couple of reduces seem stuck on a small 20-node cluster in the 'sort' phase for almost an hour:  TaskTracker logs: ------------------------ 2007-03-28 14:13:46;471 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce  sort 2007-03-28 14:13:46;478 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce  sort 2007-03-28 14:13:47;476 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce  sort 2007-03-28 14:13:47;483 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce  sort ... ... ... 2007-03-28 15:06:04;376 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce  sort 2007-03-28 15:06:04;411 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce  sort 2007-03-28 15:06:05;379 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce  sort 2007-03-28 15:06:05;414 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce  sort   Eventually the JobTracker declared the same TT 'lost' (presumably for no heartbeats):  2007-03-28 15:18:20;341 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_XXX:9020',Resolved,Fixed,,Unassigned,Arun C Murthy,Wed; 28 Mar 2007 18:32:23 +0000,Thu; 17 Jul 2014 16:56:53 +0000,Thu; 17 Jul 2014 16:56:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-172
MAPREDUCE-173,Bug,Major,,JobConf should also load resources from hdfs (or other filesystems),JobConf conf = new JobConf(path) doesnt load the configuration if path points to a resource on hdfs.,Resolved,Fixed,,Unassigned,Amar Kamat,Thu; 16 Apr 2009 12:07:15 +0000,Tue; 22 Jul 2014 18:50:59 +0000,Tue; 22 Jul 2014 18:50:59 +0000,,,,MAPREDUCE-181;MAPREDUCE-700,,https://issues.apache.org/jira/browse/MAPREDUCE-173
MAPREDUCE-174,Bug,Major,,JobTracker.close() gets stuck occasionally,JobTracker.close() shuts down all the worker threads by interrupting them and then doing a join. This will work if the thread is in WAITING state. Most of the time the worker threads are in the RUNNING state and the JT waits forever on the join().,Resolved,Incomplete,,Unassigned,Amar Kamat,Wed; 20 Aug 2008 07:51:56 +0000,Fri; 18 Jul 2014 22:12:25 +0000,Fri; 18 Jul 2014 22:12:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-174
MAPREDUCE-175,Bug,Major,,Sometimes; Reduce tasks hang    State is unassigned,Hi; all  When our cluster runs for a long time; some reduce tasks running on some tasktrackers hang. Their states are UNASSIGNED.  Then; all reduce tasks on these tasktracker will hang.  We kill the hang reduce task; then the reduce task attempt is re-scheduled to this tasktracker; the attempt task continues to hang. We fail it; it goes to another tasktracker; it is executed successfully.   Tasktracker which has hang reduce task will receive new reduce task; but the reduce  task continue to hang for ever.  When we reboot the tasktracker machine; reduce task no longer hangs.,Resolved,Incomplete,,Unassigned,ZhuGuanyin,Thu; 5 Mar 2009 06:36:05 +0000,Mon; 21 Jul 2014 21:29:52 +0000,Mon; 21 Jul 2014 21:29:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-175
MAPREDUCE-176,Bug,Major,,listing of an output directory shortly after job completion fails,Sometimes; after a job finishes; and another application wants to rename dfs files created by that job; listing of the output directory containing the newly created files fails. File creation and directory listing is done via libhdfs; but it is unlikely that this makes any difference; therefore; I add this to the mapred component.  It might be a race condition: does the job complete before the files in the output directory are promoted?,Reopened,Unresolved,,Arun C Murthy,Christian Kunz,Fri; 13 Jul 2007 20:26:31 +0000,Sat; 20 Jun 2009 07:50:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-176
MAPREDUCE-177,Bug,Major,,Hadoop performance degrades significantly as more and more jobs complete,When I ran the gridmix 2 benchmark load on a fresh cluster of 500 nodes with hadoop trunk;  the gridmix load; consisting of 202 map 0.19 have the similar behavior.    I believe 0.18 and 0.18 also have the similar behavior.,Resolved,Won't Fix,,Ioannis Koltsidas,Runping Qi,Wed; 3 Dec 2008 23:40:34 +0000,Mon; 21 Jul 2014 17:00:46 +0000,Mon; 21 Jul 2014 17:00:46 +0000,,,,,MAPREDUCE-291,https://issues.apache.org/jira/browse/MAPREDUCE-177
MAPREDUCE-178,Bug,Major,,Inconsistency in handling lost trackers upon jobtracker restart,"If a tasktracker is lost; the jobtracker kills all the tasks that were successful on that tracker and re-executes it somewhere else. In-memory datastructures are all cleared up for the lost tracker. Now if the jobtracker restarts; the new jobtracker has no clue about the trackers that were lost and hence if the lost tracker join back; they will be accepted and all the tasks on those tracker will join back. Following are the issues  	If the running task on the lost tracker is killed; its cleanup attempt will be launched. Now the new jobtracker has no idea about this attempt. Also the lost tracker can join back and hence there are 2 attempts that are running with the same id; one which can move the tip to success and other which moves the tip to killed state. 	Ideally; the lost tracker should be asked to re-init which wont happen now.",Resolved,Invalid,,Unassigned,Amar Kamat,Tue; 24 Feb 2009 10:54:59 +0000,Wed; 7 Oct 2009 10:27:52 +0000,Wed; 7 Oct 2009 10:27:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-178
MAPREDUCE-179,Bug,Blocker,,setProgress not called for new RecordReaders,NewTrackingRecordReader does not call setProgress in nextKeyValue; as the old API did,Resolved,Fixed,,Chris Douglas,Chris Douglas,Mon; 11 May 2009 18:29:03 +0000,Tue; 7 Jul 2009 17:34:20 +0000,Mon; 29 Jun 2009 06:44:57 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-179
MAPREDUCE-180,Bug,Major,,task tracker cannot find mapoutput files,I ran a large job on our cluster over the weekend. At some point; some map tasks were re-run successfully. However; when trying to handle the reducers requests to fetch mapoutput files of those map tasks; the http server complained file not found.  This happened multiple times on different machines for the same map task until the job tracker aborted the job.,Resolved,Not A Problem,,Owen O'Malley,Runping Qi,Mon; 25 Sep 2006 19:51:47 +0000,Mon; 16 Jan 2012 10:01:16 +0000,Mon; 16 Jan 2012 10:01:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-180
MAPREDUCE-181,Sub-task,Major,,Secure job submission ,Currently the jobclient accesses the mapred.system.dir to add job details. Hence the mapred.system.dir has the permissions of rwx-wx-wx. This could be a security loophole where the job files might get overwritten tampered after the job submission.,Closed,Fixed,,Devaraj Das,Amar Kamat,Tue; 17 Jun 2008 06:08:48 +0000,Tue; 24 Aug 2010 21:13:21 +0000,Mon; 21 Dec 2009 17:38:46 +0000,,,,HADOOP-4991;MAPREDUCE-246;MAPREDUCE-173;HADOOP-5737,MAPREDUCE-1322;HADOOP-4487;HADOOP-8984,https://issues.apache.org/jira/browse/MAPREDUCE-181
MAPREDUCE-182,Bug,Major,,Text class constructor and setCopacity method,A couple of problems.  1. setCapacity may cause loss of the existing data; if the new len is bigger than the old len of the byte array.  2. Text should provide a constructor like:  Text(byte[] data;  int len) { }  Text(byte[] data; int start; int len) { }  Text(byte[] data;  int len; boolean noCopying) { }  The last one above allows to save the cost of data copy if the user wants the ownership of data to be transferred to Text object,Open,Unresolved,,Owen O'Malley,Runping Qi,Wed; 25 Oct 2006 23:39:23 +0000,Mon; 16 Jan 2012 10:12:48 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-182
MAPREDUCE-183,Bug,Major,,The description for some of the configuration entries in the default xml files are outdated and needs to be updated,Description for some configuration entries in mapred-default.xml are outdated. For example; io.sort.mb. This file needs to be revisited and descriptions updated. The same is probably true for the other defaults as well (core-defaults and hdfs-defaults),Resolved,Fixed,,Unassigned,Jothi Padmanabhan,Mon; 2 Feb 2009 07:02:52 +0000,Mon; 21 Jul 2014 19:25:09 +0000,Mon; 21 Jul 2014 19:25:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-183
MAPREDUCE-184,Bug,Major,,Submitted jobs on jobtracker.jsp,Sometimes initTasks;job-setup task and the subsequent change of job state to RUNNING takes a while and a newly submitted job is not displayed on jobtracker.jsp till then. It would be good to have submitted jobs also on the ui.,Resolved,Won't Fix,HADOOP-6043,Unassigned,Vinod Kumar Vavilapalli,Fri; 20 Mar 2009 16:09:55 +0000,Mon; 21 Jul 2014 22:06:50 +0000,Mon; 21 Jul 2014 22:06:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-184
MAPREDUCE-185,Bug,Major,,Checksum error during sorting in reducer,Many reduce tasks got killed due to checksum error. The strange thing is that the file was generated by the sort function; and was on a local disk. Here is the stack:   Checksum error:  .. all.2.1  org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker. 1066),Resolved,Invalid,,Owen O'Malley,Runping Qi,Tue; 3 Oct 2006 05:11:15 +0000,Mon; 16 Jan 2012 10:03:03 +0000,Mon; 16 Jan 2012 10:03:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-185
MAPREDUCE-186,Bug,Major,,TaskLogServlet returns 410 when trying to access log early in task life,Early in a map task life; or for tasks that died quickly; the file $task syslog might not exist.  In this case; the TaskLogServlet gives a status 410.,Resolved,Incomplete,,Unassigned,Michael Bieniosek,Thu; 10 Jan 2008 00:53:29 +0000,Thu; 17 Jul 2014 19:35:43 +0000,Thu; 17 Jul 2014 19:35:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-186
MAPREDUCE-187,Bug,Major,,Generalize mapred.child.ulimit so as to help setting up other limits.,Currently mapred.child.ulimit cannot be used for anything other than for setting virtual limits. It is hardcoded to set virtual mem limits (ulimit -v) only. This should be changed so that other limits like open file descriptors; max user processes etc can be set.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Wed; 20 Aug 2008 04:45:31 +0000,Fri; 18 Jul 2014 22:11:53 +0000,Fri; 18 Jul 2014 22:11:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-187
MAPREDUCE-188,Bug,Major,,Web UI JSP: need to HTML-Escape log file contents,"Web UI JSP: need to HTML-Escape log (file) contents  Displaying the task's error log or the mapred.Reporter status String:  the content should  have all """" and """" converted to """" and """";  or use ""pre"" tag.  Otherwise; ant HTML taskdetails.jsp?jobid=job_0009taskid=tip_0009_m_000000 Other jsp pages may also need a change.",Resolved,Not A Problem,,Owen O'Malley,Michel Tourn,Wed; 2 Aug 2006 02:19:08 +0000,Mon; 16 Jan 2012 09:44:06 +0000,Mon; 16 Jan 2012 09:44:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-188
MAPREDUCE-189,Sub-task,Major,,Change Map-Reduce framework to use JAAS instead of UGI,Hadoop embraced JAAS via HADOOP-4348.  We need to fix Map-Reduce to use JAAS concepts such as Subject; Principal; Permission etc. rather than UserGroupInformation for user identification; queue-acls etc.,Resolved,Incomplete,,Arun C Murthy,Arun C Murthy,Fri; 12 Dec 2008 02:35:35 +0000,Mon; 21 Jul 2014 17:16:04 +0000,Mon; 21 Jul 2014 17:16:04 +0000,,,,,HADOOP-4487,https://issues.apache.org/jira/browse/MAPREDUCE-189
MAPREDUCE-190,Bug,Major,,MultipleOutputs should use newer Hadoop serialization interface since 0.19,We have a system based on Hadoop 0.18   Cascading 1.0. The first serious problem I've got into that we're extensively using MultipleOutputs in our jobs dealing with sequence files that store Cascading's Tuples.  Since Cascading 0.9; Tuples stopped being WritableComparable and implemented generic Hadoop serialization interface and framework. However; in Hadoop 0.19; MultipleOutputs require use of older WritableComparable interface. Thus; trying to do something like:      yields an error:     MultipleOutputs should eventually be ported to use more generic Hadoop serialization; as I understand.,Resolved,Incomplete,,Unassigned,Mikhail Yakshin,Wed; 4 Feb 2009 17:16:18 +0000,Mon; 21 Jul 2014 19:40:00 +0000,Mon; 21 Jul 2014 19:40:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-190
MAPREDUCE-191,Bug,Major,,Mapper fail rate increases significantly as the number of reduces increase,I ran a large sort job; with about 8400 mappers. In the first run; I used 301 reducers. About 600 mapper tasks failed. In another run; I used 607 reducers. More than 3800 mapper tasks failed.,Resolved,Cannot Reproduce,,Unassigned,Runping Qi,Wed; 28 Mar 2007 16:51:14 +0000,Thu; 17 Jul 2014 16:56:20 +0000,Thu; 17 Jul 2014 16:56:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-191
MAPREDUCE-192,Bug,Major,,In TaskTracker; the notification for waking up the completion-events fetcher thread may be lost,In the TaskTracker; there is a completion events fetcher thread that fetches new events from the JobTracker. Normally; the fetcher thread would sleep for heartbeatInterval amount of time per cycle. When a reduce task asks for completion events from the corresponding TaskTracker and the TaskTracker currently doesn't have anything to hand out; a notification is sent to the completion events fetcher thread to wake up and fetch new events if any. Sometimes this notification could be lost and the reduce task would be idle for a few seconds. This hurts the performance of jobs like terasort.,Resolved,Incomplete,,Devaraj Das,Devaraj Das,Fri; 13 Feb 2009 04:31:04 +0000,Mon; 21 Jul 2014 20:03:59 +0000,Mon; 21 Jul 2014 20:03:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-192
MAPREDUCE-193,Bug,Major,,NPEs in JobClient when mapred.jobtracker.completeuserjobs.maximum is set to zero.,Throwing NPEs is not enough of information for the user. Proper exceptions should be thrown with relevant messages.,Resolved,Incomplete,,Unassigned,Vinod Kumar Vavilapalli,Fri; 20 Feb 2009 13:12:43 +0000,Mon; 21 Jul 2014 20:52:07 +0000,Mon; 21 Jul 2014 20:52:07 +0000,,,,,HADOOP-5247,https://issues.apache.org/jira/browse/MAPREDUCE-193
MAPREDUCE-194,Bug,Major,,Split Information errors when input data volumn is trivial,The mapreduce input is a text file with only 8 lines ( filepath:  pretty:32+4,Resolved,Fixed,,Unassigned,Leitao Guo,Thu; 12 Mar 2009 08:53:36 +0000,Mon; 21 Jul 2014 21:54:02 +0000,Mon; 21 Jul 2014 21:54:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-194
MAPREDUCE-195,Bug,Major,,Distinguish between 'failed' and 'killed' tips,When a 'tip' fails since more than MAX_TASK_FAILURES are exceeded; the tip is marked 'killed' and 'failed' (via a call to TaskInProgress.kill from JobInProgress.incompleteSubTask) which makes it hard to distinguish from 'killed' tips (since for e.g. the job itself got killed).  Straight-forward fix is to add a TaskInProgress.fail() and use that instead.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Wed; 2 May 2007 21:49:12 +0000,Sat; 20 Jun 2009 07:51:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-195
MAPREDUCE-196,Sub-task,Major,,Create enum for the TaskTypes (Map; Reduce; JobSetup; JobCleanup; TaskCleanup),Create enum for the TaskTypes - Map; Reduce; JobSetup; JobCleanup; TaskCleanup. Change the framework to use these enum constants and remove usages of booleans like isMap.,Resolved,Fixed,,Devaraj Das,Devaraj Das,Wed; 22 Apr 2009 09:00:38 +0000,Sat; 20 Jun 2009 07:51:00 +0000,Thu; 30 Apr 2009 11:16:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-196
MAPREDUCE-197,New Feature,Major,,add new options to mapred job -list-attempt-ids to dump counters and diagnostic messages,It would be very nice when tracking down tasks that have strange values for their counters; if there was a command line tool to print out the task attempts and their counters and diagnostic messages. I propose adding switches to -list-attempt-ids to accomplish that:   mapred job -list-attempt-ids -counters -diagnostics job type state,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Mon; 4 May 2009 16:13:15 +0000,Tue; 22 Jul 2014 19:21:59 +0000,,,,newbie,,MAPREDUCE-168,https://issues.apache.org/jira/browse/MAPREDUCE-197
MAPREDUCE-198,New Feature,Major,,Log job history events to a common dump file,As of today all the jobhistory events are logged to separate files. It would be nice to also dump all this info into a common file so that external tools (e.g Chukwa) can harvest history info. Job configuration should also be dumped. Whether to use a same log file for history dumps and configuration dumps should be configurable (by default everything goes to one file).,Resolved,Won't Fix,,Amar Kamat,Amar Kamat,Fri; 15 May 2009 08:15:01 +0000,Thu; 20 Aug 2009 01:56:44 +0000,Thu; 20 Aug 2009 01:56:44 +0000,,,,MAPREDUCE-157,,https://issues.apache.org/jira/browse/MAPREDUCE-198
MAPREDUCE-199,New Feature,Major,applicationmaster;mrv2,Locality hints for Reduce,It would be nice if we could add method to OutputFormat that would allow a job to indicate where a reducer for a given partition should should run. This is similar to the getSplits() method on InputFormat. In our application the reducer is using other data in addition to the map outputs during processing and data accesses could be made more efficient if the JobTracker scheduled the reducers to run on specific hosts.,Reopened,Unresolved,,Unassigned,Benjamin Reed,Tue; 10 Oct 2006 14:21:06 +0000,Wed; 26 Oct 2016 14:49:38 +0000,,,,,HBASE-1199,,https://issues.apache.org/jira/browse/MAPREDUCE-199
MAPREDUCE-200,New Feature,Major,,mapred.map.tasks and mapred.reduce.tasks should be determined automatically by default,The default values for mapred.map.tasks and mapred.reduce.tasks should be empty or -1; signalling that the framework should use an dynamically-determined default.  An appropriate default is perhaps the number of map and reduce slots in the cluster; since FileInputFormat interprets mapred.map.tasks as a minimum.  This would remove a common area of misconfiguration.,Open,Unresolved,,Unassigned,Doug Cutting,Wed; 26 Mar 2008 18:31:33 +0000,Tue; 29 Sep 2009 20:05:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-200
MAPREDUCE-201,New Feature,Major,,Map directly to HDFS or reduce(),For situations where you know that the output of the Map phase is already aggregated (e.g. the input is the output of another Map-reduce job and map() preserves the aggregation); then there should be a way to tell the framework that this is the case so that it can pipe the map() output directly to the reduce() function; or HDFS in the case of IdentityReducer.  This will probably require forcing the number of map tasks to equal the number of reduce tasks.  This will save the disk I O required to generate intermediate files.,Resolved,Not A Problem,,Unassigned,Doug Judd,Mon; 29 Jan 2007 18:54:32 +0000,Mon; 16 Jan 2012 10:37:43 +0000,Mon; 16 Jan 2012 10:37:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-201
MAPREDUCE-202,New Feature,Major,,should dump stacks before timing out task,When a task process times out and is killed it is often difficult to determine why.  If its stack was dumped prior to killing it; then debugging would be vastly simplified.  Ideally the stack dump would be available through the web ui; but even the log would be sufficient.,Resolved,Duplicate,MAPREDUCE-1119,Owen O'Malley,Doug Cutting,Thu; 26 Oct 2006 17:33:05 +0000,Mon; 9 Nov 2009 04:36:20 +0000,Mon; 9 Nov 2009 04:36:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-202
MAPREDUCE-203,New Feature,Major,,counters: want rates and averages; and phase-level sums,It would be nice if the web ui displayed; for each counter; not just its total; but also its rate (counts second for a job.,Open,Unresolved,,Unassigned,Doug Cutting,Fri; 23 Feb 2007 20:23:46 +0000,Sat; 20 Jun 2009 07:51:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-203
MAPREDUCE-204,New Feature,Major,,ability to configure gap/lag parameters for speculative execution for maps/reduces,"Motivation is obvious:   	sometimes reduces have side-effects - but maps don't (for example reduces compute something and write it somewhere) 	want to turn ON speculative for maps (because maps are usually way less expensive. map progress counters are reliable etc.) - but OFF for reduces (very expensive to run two reducers instead of one).    It's also likely that in future you may want different setting for speculative triggers for maps and reduces ... (but that's a different issue).  I will submit a patch (since we are putting this into effect on our cluster - and it seems simple enough ).",Reopened,Unresolved,,Unassigned,Joydeep Sen Sarma,Thu; 31 Jan 2008 01:52:30 +0000,Sat; 20 Jun 2009 07:51:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-204
MAPREDUCE-205,New Feature,Major,,"Add ability to send ""signals"" to jobs and tasks","In some cases it would be useful to be able to ""signal"" a job and its tasks about some external condition; or to broadcast a specific message to all tasks in a job. Currently we can only send  a single pseudo-signal; that is to kill a job.  Example 1: some jobs may be gracefully terminated even if they didn't complete all their work; e.g. Fetcher in Nutch may be running for a very long time if it blocks on relatively few sites left over from the fetchlist. In such case it would be very useful to send it a message requesting that it discards the rest of its input and gracefully completes its map tasks.  Example 2: available bandwidth for fetching may be different at different times of day; e.g. daytime vs. nighttime; or total external link usage by other applications. Fetcher jobs often run for several hours. It would be good to be able to send a ""signal"" to the Fetcher to throttle or un-throttle its bandwidth usage depending on external conditions.  Job implementations could react to these messages either by implementing a method; or by registering a listener; whichever seems more natural.  I'm not quite sure how to go about implementing it; I guess this would have to be a part of  TaskUmbilicalProtocol but my knowledge here is a bit fuzzy ...  Comments are welcome.",Reopened,Unresolved,,Unassigned,Andrzej Bialecki,Tue; 29 Aug 2006 20:06:37 +0000,Sat; 22 Oct 2016 22:20:55 +0000,,,,,,NUTCH-368,https://issues.apache.org/jira/browse/MAPREDUCE-205
MAPREDUCE-206,New Feature,Major,,Implement a generic DFA ,Owen alluded to it HADOOP-1183 and Devaraj talked about this in HADOOP-1337 ... I believe this will be a generally useful feature in other parts of hadoop too...  The proposal is to implement a generic state machine which can be configured as needed and could be used to track states result of the transition.   State doTransition(State state; Event event; Object cause; Object victim)    throws IllegalStateTransitionException; }   -  Thoughts?,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Sun; 20 May 2007 19:31:48 +0000,Sat; 20 Jun 2009 07:51:01 +0000,,,,,,MAPREDUCE-278,https://issues.apache.org/jira/browse/MAPREDUCE-206
MAPREDUCE-207,New Feature,Major,applicationmaster;mrv2,Computing Input Splits on the MR Cluster,"Instead of computing the input splits as part of job submission; Hadoop could have a separate ""job task type"" that computes the input splits; therefore allowing that computation to happen on the cluster.",Open,Unresolved,MAPREDUCE-5887,Gera Shegalov,Philip Zeyliger,Sun; 14 Jun 2009 22:46:22 +0000,Sat; 7 Jan 2017 01:59:50 +0000,,,,,MAPREDUCE-1227;MAPREDUCE-1484,,https://issues.apache.org/jira/browse/MAPREDUCE-207
MAPREDUCE-208,New Feature,Major,,Provide an admin page displaying events in the cluster along with cluster status/health,"Here are few things that will help admins understand whats happening in the cluster  	Events updates 	 		recently added tracker 		lost trackers 		recently submitted jobs 		user updates 		killed success history 		 		 		space on the box where the jt is running 		etc 	 	 	Config : 	 		slot info 		acl info 		etc 	 	     Graphical views and auto updation would be cool. Raising alarms upon certain events would be super cool.",Resolved,Won't Fix,,Unassigned,Amar Kamat,Wed; 18 Mar 2009 11:29:44 +0000,Mon; 21 Jul 2014 22:04:47 +0000,Mon; 21 Jul 2014 22:04:47 +0000,,,,,MAPREDUCE-1027,https://issues.apache.org/jira/browse/MAPREDUCE-208
MAPREDUCE-209,New Feature,Major,,Support for metrics aggregation module in JobTracker,JobTracker should support starting up and shutting down a generic metrics aggregation module. We are currently thinking about plugging in a module that gets time series data from the task trackers; aggregates it and log this data into a global DFS so that it is analysed later (even after the map reduce cluster is shutdown). Some of this data can also be plotted on the JobTracker UI in realtime. This is particulary useful for analyzing data from dynamic mapreduce cluster like the ones deployed using HOD.,Resolved,Fixed,,Unassigned,Senthil Subramanian,Tue; 18 Sep 2007 20:58:50 +0000,Thu; 17 Jul 2014 17:58:33 +0000,Thu; 17 Jul 2014 17:58:33 +0000,,,,HADOOP-1901,,https://issues.apache.org/jira/browse/MAPREDUCE-209
MAPREDUCE-210,New Feature,Major,,want InputFormat for zip files,HDFS is inefficient with large numbers of small files.  Thus one might pack many small files into large; compressed; archives.  But; for efficient map-reduce operation; it is desireable to be able to split inputs into smaller chunks; with one or more small original file per split.  The zip format; unlike tar; permits enumeration of files in the archive without scanning the entire archive.  Thus a zip InputFormat could efficiently permit splitting large archives into splits that contain one or more archived files.,In Progress,Unresolved,,indrajit,Doug Cutting,Fri; 31 Aug 2007 19:01:32 +0000,Wed; 11 Mar 2015 12:14:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-210
MAPREDUCE-211,New Feature,Major,,Provide a node health check script and run it periodically to check the node health status,Hadoop must have some mechanism to find the health status of a node . It should run the health check script periodically and if there is any errors; it should black list the node. This will be really helpful when we run static mapred clusters. Else we may have to run some scripts daemons periodically to find the node status and take it offline manually.,Closed,Fixed,,Sreekanth Ramakrishnan,Aroop Maliakkal,Thu; 12 Mar 2009 15:18:12 +0000,Tue; 24 Aug 2010 21:13:21 +0000,Tue; 30 Jun 2009 14:01:11 +0000,,,,HADOOP-6106,,https://issues.apache.org/jira/browse/MAPREDUCE-211
MAPREDUCE-212,New Feature,Major,,want InputFormat for task logs,We should provide an InputFormat implementation that includes all the task logs from a job. Folks should be able to do something like:  job = new JobConf(); job.setInputFormatClass(TaskLogInputFormat.class); TaskLogInputFormat.setJobId(jobId); ...  Tasks should ideally be localized to the node that each log is on.  Examining logs should be as lightweight as possible; to facilitate debugging. It should not require a copy to HDFS. A faster debug loop is like a faster search engine: it makes people more productive. The sooner one can find that; e.g.; most tasks failed with a NullPointerException on line 723; the better.,Resolved,Won't Fix,,Unassigned,Doug Cutting,Tue; 3 Apr 2007 18:00:03 +0000,Fri; 18 Jul 2014 05:06:42 +0000,Fri; 18 Jul 2014 05:06:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-212
MAPREDUCE-213,New Feature,Major,jobtracker,Provide a way to query job tracker about its daemon thread's status,Admin needs to know the status of all threads in JobTracker (whether they are alive or not) at any point of time. This helps alot in debugging crashes.,Resolved,Incomplete,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 18 Mar 2009 08:57:18 +0000,Mon; 21 Jul 2014 22:04:09 +0000,Mon; 21 Jul 2014 22:04:09 +0000,,,,HDFS-326,,https://issues.apache.org/jira/browse/MAPREDUCE-213
MAPREDUCE-214,New Feature,Major,,Concrete implementation of MultiFileInputFormat ,There has been a demand for a concrete implementation for MultiFileInputFormat. We should include one as a library.,Open,Unresolved,,Enis Soztutar,Enis Soztutar,Fri; 28 Nov 2008 16:23:01 +0000,Thu; 2 May 2013 02:29:18 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-214
MAPREDUCE-215,New Feature,Major,,Improve facilities for job-control; job-queues etc.,Today; Map-Reduce has some support for job-control - basically JobClient provides a facility to monitor jobs; one can setup a job-ending notification and there is JobControl.  Links: http: mapred_tutorial.html#JobControl  Looks like users could do more with better facilities for job-control and maybe more advanced features like job-queues etc.  Lets discuss...,Resolved,Fixed,,Unassigned,Arun C Murthy,Fri; 21 Dec 2007 21:20:13 +0000,Thu; 17 Jul 2014 19:19:08 +0000,Thu; 17 Jul 2014 19:19:08 +0000,,,,,PIG-195,https://issues.apache.org/jira/browse/MAPREDUCE-215
MAPREDUCE-216,New Feature,Major,,Job setup and take down on Nodes,It would be nice if there was a hook for doing job provisioning and cleanup on compute nodes. The TaskTracker implicitly knows when a job starts (a task for the job is received) and pollForTaskWithClosedJob() will explicitly say that a job is finished if a Map task has been run (If only Reduce tasks have run and are finished I don't think pollForTaskWithClosedJob() will return anything will it?); but child Tasks do not get this information.  It would be nice if there was a hook so that programmers could do some provisioning when a job starts and cleanup when a job ends. Caching addresses some of the provisioning; but in some cases a helper daemon may need to be started or the results of queries need to be retrieved and having startJob(); finishJob() callbacks that happen exactly once for each node that runs part of the job would be wonderful.,Resolved,Not A Problem,,Owen O'Malley,Benjamin Reed,Thu; 5 Oct 2006 22:39:43 +0000,Mon; 16 Jan 2012 10:04:45 +0000,Mon; 16 Jan 2012 10:04:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-216
MAPREDUCE-217,New Feature,Major,,Tasks to run on a different jvm version than the TaskTracker,We use 32-bit jvm for TaskTrackers.  Sometimes our users want to call 64-bit JNI libraries from their tasks. This requires tasks to be running on 64-bit jvm. On Solaris; you can simply use -d32 -d64 to choose; but on Linux; it's on a completely different package.  So far; tasks run on the same jvm version as the TaskTracker.    Is it possible to let users provide a  home path  or let them choose from a pre-selected list of paths?,Resolved,Fixed,,Amar Kamat,Koji Noguchi,Tue; 2 Dec 2008 16:42:20 +0000,Sun; 26 Apr 2015 01:39:53 +0000,Sun; 26 Apr 2015 01:39:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-217
MAPREDUCE-218,New Feature,Major,,Map/Reduce job with SequenceFileOutputFormat should be able to add user specified metadata to the output file,When creating a map value pair of the metadata. This way; the output files will be self describing:  When an application that tries to use the files may not have the value class with it.  But the application can use Jute tool to generate the classes on demand. Or better yet; the SequenceFile record reader may be able to do that automatically.,Resolved,Fixed,,Unassigned,Runping Qi,Mon; 29 Jan 2007 23:45:43 +0000,Tue; 17 Jan 2012 03:51:11 +0000,Tue; 17 Jan 2012 03:51:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-218
MAPREDUCE-219,New Feature,Major,,JT should remember blacklisted TT after restart,Currently; when JT is restarted ; it does not remember any TT(s) which was blacklisted across the cluster before the restart. It would be useful if a new feature could be added for JT to remember blacklisted TT(s) even after restart. This would avoid JT from assigning tasks to faulty TT(s) each time after restart.,Resolved,Won't Fix,,Unassigned,Ramya Sunil,Sat; 7 Mar 2009 07:29:41 +0000,Mon; 21 Jul 2014 21:36:47 +0000,Mon; 21 Jul 2014 21:36:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-219
MAPREDUCE-220,New Feature,Major,task;tasktracker,Collecting cpu and memory usage for MapReduce tasks,It would be nice for TaskTracker to collect cpu and memory usage for individual Map or Reduce tasks over time.,Closed,Fixed,,Scott Chen,Hong Tang,Mon; 27 Apr 2009 23:19:54 +0000,Thu; 2 May 2013 02:29:34 +0000,Fri; 20 Aug 2010 17:42:45 +0000,,,,MAPREDUCE-901;MAPREDUCE-1762,MAPREDUCE-2777,https://issues.apache.org/jira/browse/MAPREDUCE-220
MAPREDUCE-221,New Feature,Major,,Generic 'Sort' Infrastructure for Map-Reduce framework.,It would be useful to add a generic sort infrastructure to the Map-Reduce framework to ease usage. Specifically the idea to add a fairly generic and powerful comparator which can be configured by the user to meet his specific needs.  Spec: --------    The proposal is to model generic (uber) comparator along the lines of the the standard unix sort command. The comparator provides the following (configurable) functionality:    a) Separator for breaking up the data (stream) into 'columns'.   b) Multiple key ranges for specifying priorities of 'columns'. (ala --keys less?  thanks; Arun,Resolved,Incomplete,,Arun C Murthy,Arun C Murthy,Thu; 6 Jul 2006 12:57:13 +0000,Mon; 16 Jan 2012 09:16:08 +0000,Mon; 16 Jan 2012 09:16:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-221
MAPREDUCE-222,New Feature,Major,,Shuffle should be refactored to a separate task by itself,"Currently; shuffle phase is part of the reduce task. The idea here is to move out the shuffle as a first-class task. This will improve the usage of the network since we will then be able to schedule shuffle tasks independently; and later on pin reduce tasks to those nodes. This will make most sense for apps where there are multiple waves of reduces (the second wave of reduces can directly start off doing the ""reducer"" phase).",Open,Unresolved,,Unassigned,Devaraj Das,Tue; 8 May 2007 06:23:50 +0000,Tue; 1 Dec 2009 05:53:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-222
MAPREDUCE-223,New Feature,Major,,JobClient should work with -1/+1 version of JobTracker,Currently there is version check on the RPC calls that enforces the same Hadoop version on the client and the server.  To enable phased upgrades of systems using Hadoop and Hadoop itself the JobClient should be able to interact with a JobTracker of the previous and the next version of Hadoop (or with a range).,Resolved,Incomplete,,Unassigned,Alejandro Abdelnur,Tue; 12 Aug 2008 11:22:43 +0000,Fri; 18 Jul 2014 20:53:44 +0000,Fri; 18 Jul 2014 20:53:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-223
MAPREDUCE-224,New Feature,Major,,limit running tasks per job,It should be possible to specify a limit to the number of tasks per job permitted to run simultaneously.  If; for example; you have a cluster of 50 nodes; with 100 map task slots and 100 reduce task slots; and the configured limit is 25 simultaneous tasks job; then four or more jobs will be able to run at a time.  This will permit short jobs to pass longer-running jobs.  This also avoids some problems we've seen with HOD; where nodes are underutilized in their tail; and it should permit improved input locality.,Resolved,Duplicate,MAPREDEUCE-5583,Unassigned,Doug Cutting,Thu; 10 Jan 2008 17:47:04 +0000,Thu; 17 Jul 2014 19:38:20 +0000,Thu; 17 Jul 2014 19:38:20 +0000,,,,,MAPREDUCE-5583,https://issues.apache.org/jira/browse/MAPREDUCE-224
MAPREDUCE-225,New Feature,Major,,Fault tolerant Hadoop Job Tracker,The Hadoop framework has been designed; in an eort to enhance perfor- mances; with a single JobTracker (master node). It's responsibilities varies from managing job submission process; compute the input splits; schedule the tasks to the slave nodes (TaskTrackers) and monitor their health. In some environments; like the IBM and Google's Internet-scale com- puting initiative; there is the need for high-availability; and performances becomes a secondary issue. In this environments; having a system with a Single Point of Failure (such as Hadoop's single JobTracker) is a major concern. My proposal is to provide a redundant version of Hadoop by adding support for multiple replicated JobTrackers. This design can be approached in many dierent ways.   In the document at: http: FaultTolerantHadoop.pdf?attredirects=0  I wrote an overview of the problem and some approaches to solve it.  I post this to the community to gather feedback on the best way to proceed in my work.  Thank you!,Resolved,Incomplete,YARN-149,Francesco Salbaroli,Francesco Salbaroli,Tue; 4 Nov 2008 11:23:27 +0000,Fri; 18 Jul 2014 22:27:11 +0000,Fri; 18 Jul 2014 22:27:11 +0000,,,,,MAPREDUCE-2288,https://issues.apache.org/jira/browse/MAPREDUCE-225
MAPREDUCE-226,New Feature,Major,,Support detailed timing for MapReduce job,It would be nice to break down the time each individual Map task or Reduce task spends on reading input; writing output; and executing the map() or reduce() calls.,Open,Unresolved,,Unassigned,Hong Tang,Wed; 21 Jan 2009 22:52:53 +0000,Sat; 20 Jun 2009 07:51:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-226
MAPREDUCE-227,New Feature,Major,,Ability to pause/resume jobs,Consider a case where the user job depends on some external entity command line) etc.,Resolved,Duplicate,MAPREDUCE-828,Amar Kamat,Amar Kamat,Mon; 6 Oct 2008 07:46:33 +0000,Thu; 6 Aug 2009 06:33:16 +0000,Thu; 6 Aug 2009 06:18:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-227
MAPREDUCE-228,New Feature,Major,,want InputFormat and OutputFormat for zip archives,An InputForm may be efficiently read when constructing splits.)  Input splits could thus be sent to a node where they are stored locally for the map phase; providing good performance.  This would thus permit applications to (1) use a standard file format; (2) keep data compressed; and (3) efficiently split input into chunks substantially smaller than HDFS blocks.  This is not available today.,Open,Unresolved,,Unassigned,Doug Cutting,Mon; 9 Apr 2007 18:01:24 +0000,Thu; 20 Jan 2011 15:32:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-228
MAPREDUCE-229,New Feature,Major,,Provide a command line option to check if a Hadoop jobtracker is idle,This is an RFE for providing a way to determine from the hadoop command line whether a jobtracker is idle. One possibility is to have something like hadoop jobtracker -idle time. Hadoop would return true (maybe via some stdout output) if the jobtracker had no work to do (jobs running   provisioning systems like Hadoop-On-Demand HADOOP-1301; which can then deallocate the idle; provisioned clusters automatically; and release resources.,Resolved,Fixed,,Unassigned,Hemanth Yamijala,Fri; 23 Nov 2007 05:04:51 +0000,Thu; 17 Jul 2014 18:42:08 +0000,Thu; 17 Jul 2014 18:42:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-229
MAPREDUCE-230,Task,Major,,Need to document the controls for sorting and grouping into the reduce,The JavaDoc for the Reducer should document how to control the sort order of keys and values via the JobConf methods:     Both methods desperately need better names. (I'd vote for setKeySortingComparator and setKeyGroupingComparator.),Resolved,Won't Fix,,Arun C Murthy,Owen O'Malley,Tue; 2 Oct 2007 04:22:44 +0000,Thu; 17 Jul 2014 18:04:52 +0000,Thu; 17 Jul 2014 18:04:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-230
MAPREDUCE-231,Task,Major,,Split map/reduce into sub-project,nan,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Wed; 19 Nov 2008 18:48:45 +0000,Mon; 12 Dec 2011 06:19:40 +0000,Mon; 11 Oct 2010 06:22:36 +0000,,,,HADOOP-5102;HADOOP-3750;HADOOP-4631;HADOOP-4868;HADOOP-5107;HADOOP-5898,,https://issues.apache.org/jira/browse/MAPREDUCE-231
MAPREDUCE-232,Improvement,Major,,TextInputFormat should support character encoding settings,"I need to read text files in different character encoding from UTF-8; but I think TextInputFormat doesn't support such character encoding.  I suggest the TextInputFormat to support encoding settings like this.   conf.set(""io.file.defaultEncoding""; ""MS932"");  I will submit a patch candidate.",Open,Unresolved,,Unassigned,NOMURA Yoshihide,Tue; 3 Jun 2008 01:00:05 +0000,Tue; 10 Jan 2012 21:39:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-232
MAPREDUCE-233,Improvement,Major,,Integrate TaskTracker with the Service base class,Following on from the initial service patch; we need to bring TaskTracker into the fold. This separate issue  does this activity,Resolved,Incomplete,,Unassigned,Steve Loughran,Wed; 9 Jul 2008 16:53:15 +0000,Fri; 18 Jul 2014 17:48:07 +0000,Fri; 18 Jul 2014 17:48:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-233
MAPREDUCE-234,Improvement,Major,,Isolation runner needs a testcase,I think there is no way to know if IsolationRunner breaks. A testcase can be added to run IsolationRunner.,Resolved,Duplicate,HADOOP-4041,Unassigned,Amareshwari Sriramadasu,Mon; 17 Mar 2008 06:09:53 +0000,Mon; 9 Nov 2009 04:48:20 +0000,Mon; 9 Nov 2009 04:48:20 +0000,,,,,HADOOP-4041,https://issues.apache.org/jira/browse/MAPREDUCE-234
MAPREDUCE-235,Improvement,Major,,Custom Splitter for handling many small files,Hadoop by default allocates a Map to a file irrespective of size. This is not optimal if you have a large number of small files; for e.g:- If you 2000 100KB files; 2000 Maps will be allocated for the job.  The Custom Multi File Splitter collapses all the small files to a single split till the DFS Block Size is hit.  It also take care of handling big files by splitting them on Block Size and adding up all the reminders(if any) to a further splits of Block Size.,Resolved,Not A Problem,,Subru Krishnan,Subru Krishnan,Wed; 14 May 2008 07:31:01 +0000,Fri; 18 Jul 2014 05:21:37 +0000,Fri; 18 Jul 2014 05:21:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-235
MAPREDUCE-236,Improvement,Major,,mapred.jar property in a job configuration file handles only absolute path into the local file system,Why does this property does not handle URL ? I think it could be more comfortable to specify the URL of a jar instead of an absolute path in the local file system. It also could be great to be able to specify a path relative to the job configuration file.  WDYT ?,Resolved,Not A Problem,,Owen O'Malley,Thomas Friol,Wed; 6 Sep 2006 06:57:32 +0000,Mon; 16 Jan 2012 10:00:07 +0000,Mon; 16 Jan 2012 10:00:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-236
MAPREDUCE-237,Improvement,Major,,Runtimes of TestJobTrackerRestart* testcases are high again,junit Running org.apache.hadoop.mapred.TestJobTrackerRestart junit Tests run: 1; Failures: 0; Errors: 0; Time elapsed: 575.887 sec junit Running org.apache.hadoop.mapred.TestJobTrackerRestartWithLostTracker junit Tests run: 1; Failures: 0; Errors: 0; Time elapsed: 864.319 sec  Something I saw on trunk.,Resolved,Invalid,,Amar Kamat,Amar Kamat,Wed; 17 Jun 2009 06:16:05 +0000,Thu; 2 May 2013 02:29:25 +0000,Wed; 7 Oct 2009 06:10:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-237
MAPREDUCE-238,Improvement,Major,,OutputFormat should be given the reduce id directly rather than a filename,The OutputFormat API should be changed to be more evolution proof:  public interface OutputFormatContext {   JobConf getJobConf();   Progressable getProgress(); }  public interface OutputFormat {   RecordWriter getRecordWriter(int reduce; OutputFormatContext context) throws IOException;   void checkOutputSpecs(OutputFormatContext context) throws IOException; }  And OutputFormatBase would be renamed:  public abstract class FileOutputFormat implements OutputFormat {   protected Path getOutputPath(int reduce; OutputFormatContext context) throws IOException  { ... }   ... current OutputFormatBase methods ... },Resolved,Fixed,,Owen O'Malley,Owen O'Malley,Thu; 18 Jan 2007 19:06:25 +0000,Thu; 11 Feb 2010 06:20:59 +0000,Thu; 11 Feb 2010 06:20:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-238
MAPREDUCE-239,Improvement,Major,,Attribute to mark Mappers and Reducers as side-effect free,There should be an annotation to mark Mapper and Reducer classes as side-effect free. This annotation could then be used to disable speculative execution for such classes. Furthermore; defining a class without the NoSideEffect attribute as a combiner would be a run-time error.   @NoSideEffects class MyMapper extends MapReduceBase implements Mapper  { ... }  would declare that MyMapper may be run speculatively.  @NoSideEffects class MyReducer extends MapReduceBase implements Reducer  { ...}  declares that MyReducer can be run speculative and as a combiner.,Resolved,Won't Fix,,Unassigned,Owen O'Malley,Mon; 5 Feb 2007 22:59:34 +0000,Mon; 16 Jan 2012 08:58:44 +0000,Mon; 16 Jan 2012 08:58:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-239
MAPREDUCE-240,Improvement,Major,,"Improve the shuffle phase by using the ""connection: keep-alive"" and doing batch transfers of files",We should do transfers of map outputs at the granularity of  total-bytes-transferred rather than the current way of transferring a single file and then closing the connection to the server. A single TaskTracker might have a couple of map output files for a given reduce; and we should transfer multiple of them (upto a certain total size) in a single connection to the TaskTracker. Using HTTP-1.1's keep-alive connection would help since it would keep the connection open for more than one file transfer. We should limit the transfers to a certain size so that we don't hold up a jetty thread indefinitely (and cause timeouts for other clients). Overall; this should give us improved performance.,Resolved,Duplicate,MAPREDUCE-318,Jothi Padmanabhan,Devaraj Das,Tue; 8 May 2007 06:17:09 +0000,Fri; 11 Sep 2009 04:25:08 +0000,Fri; 11 Sep 2009 04:25:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-240
MAPREDUCE-241,Improvement,Major,,JobQueueTaskScheduler could assign multiple reduces per heartbeat,Currently the JobQueueTaskScheduler assigns only 1 reduce per heartbeat; for applications where latency is important we could assign more reduces (upto available slots).,Resolved,Won't Fix,,Arun C Murthy,Arun C Murthy,Tue; 27 Jan 2009 08:16:47 +0000,Mon; 21 Jul 2014 18:32:36 +0000,Mon; 21 Jul 2014 18:32:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-241
MAPREDUCE-242,Improvement,Major,,TaskTracker can skip a dfs check on every task launch.,When tasktracker gets a new task to run; it queries the namenode to find out the job directory size. This size is required if the job files are not yet localized. But if its already localized then the dfs call gets wasted. This will be true for all but 1 tasks that run for a job on a tracker. One can avoid it but checking if the job is already localized.,Resolved,Incomplete,,Amar Kamat,Amar Kamat,Tue; 8 Jul 2008 07:47:22 +0000,Fri; 18 Jul 2014 17:46:30 +0000,Fri; 18 Jul 2014 17:46:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-242
MAPREDUCE-243,Improvement,Major,,Allow hadoop to run in an osgi container,I have been running some tests getting hadoop to run within an osgi environment (specifically the Newton framework) and this has uncovered a number of minor bugs when mapred classes are instantiated from a different start point than their main methods.  I have created a number of patches which I'll attach which solve these issues. It's possible these patches could be dealt with as separate issues but all are required to resolve the osgi issue. Happy to split up if easier to manage though.  classpath.patch: this rearranges the classloader hierarchies for Task objects such that a Task is able to resolve api classes in the case where the api classes are no longer loaded from the system classloader.  tasklog.patch: this ensures the log files are able to be resolved in the case where the child process is launched from a different directory to the parent process  taskrunner.patch: this enables the TaskRunner to find a log dir in the case where the parent jvm is not launched by the hadoop scripts; also allows for a client to specify a substitute main class (which delegates to the TaskTracker$Child) in this case for purposes of resolving osgi classpaths but could be more general? Finally adds some extra logging in case where things go wrong.  tasktracker.patch: allow parent to pass through configuration to child taskrunner (specifically in this case for purposes of passing classpath and laucher to taskrunner),Open,Unresolved,,Jean-Baptiste Onofr  ,David Savage,Thu; 6 Sep 2007 12:56:39 +0000,Thu; 2 May 2013 02:29:48 +0000,,,,,HADOOP-1650,,https://issues.apache.org/jira/browse/MAPREDUCE-243
MAPREDUCE-244,Improvement,Major,,Duplicate code in JobHistory TaskAttempt's can be collapsed into super class. ,There is a lot of common code for MapAttempt; ReduceAttempt. All the duplicate code can be moved to TaskAttempt class. The methods logFailed() and logKilled() methods differ only in one string. They can be collapased into a single method.,Resolved,Invalid,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 9 Sep 2008 05:40:26 +0000,Wed; 7 Oct 2009 06:01:55 +0000,Wed; 7 Oct 2009 06:01:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-244
MAPREDUCE-245,Improvement,Major,,Job and JobControl classes should return interfaces rather than implementations,See HADOOP-2202 and HADOOP-2268 for background on this. I am creating a new issue; since the previous two did not fix the problem; and it can be addressed when we make non backwards compatible changes to Hadoop (perhaps along with HADOOP-1230).,Closed,Fixed,,Tom White,Tom White,Wed; 9 Apr 2008 14:37:37 +0000,Tue; 24 Aug 2010 21:13:22 +0000,Sun; 19 Jul 2009 07:32:06 +0000,,,,,HADOOP-1230;HADOOP-2268,https://issues.apache.org/jira/browse/MAPREDUCE-245
MAPREDUCE-246,Improvement,Major,,Job recovery should fail or kill a job that fails ACL checks upon restart; if the job was running previously,Consider a scenario where a job was submitted to the M  kill this job.,Resolved,Fixed,,Unassigned,Hemanth Yamijala,Wed; 11 Mar 2009 10:18:13 +0000,Mon; 21 Jul 2014 21:49:48 +0000,Mon; 21 Jul 2014 21:49:48 +0000,,,,MAPREDUCE-181,,https://issues.apache.org/jira/browse/MAPREDUCE-246
MAPREDUCE-247,Improvement,Major,,Improve job history web page,"There are some minor improvements :  	Remove running jobs from the job history page. 	If the user wants to search jobs with jobname having sleep then the search query required will be ':sleep' which is not very intuitive. Simply sleep should work.",Resolved,Duplicate,MAPREDUCE-157,Unassigned,Amar Kamat,Tue; 17 Mar 2009 07:34:27 +0000,Wed; 7 Oct 2009 06:12:39 +0000,Wed; 7 Oct 2009 06:12:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-247
MAPREDUCE-248,Improvement,Major,,Add error reporting support to LocalJobRunner,"This feature is very useful for unit testing map reduce exception is caught and not propagated  to the user.     	I would be useful to get the exception message through a TaskCompletionEvent or event or by any other means.",Resolved,Won't Fix,,Unassigned,Yoram Kulbak,Tue; 26 Aug 2008 23:17:45 +0000,Fri; 18 Jul 2014 22:29:41 +0000,Fri; 18 Jul 2014 22:29:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-248
MAPREDUCE-249,Improvement,Major,,[mapred] Enable tasks' memory management on Windows.,HADOOP-4173 disabled this.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 26 Sep 2008 08:47:44 +0000,Fri; 18 Jul 2014 23:47:43 +0000,Fri; 18 Jul 2014 23:47:43 +0000,,,,,HADOOP-4173,https://issues.apache.org/jira/browse/MAPREDUCE-249
MAPREDUCE-250,Improvement,Major,,JobTracker should log the scheduling of setup/cleanup task,Setup Cleanup is launched under (m+1)th tip or (r+1)th tip. It will be nice if jobtracker logs this info.,Resolved,Fixed,,Unassigned,Amar Kamat,Mon; 6 Apr 2009 04:13:18 +0000,Tue; 22 Jul 2014 18:25:45 +0000,Tue; 22 Jul 2014 18:25:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-250
MAPREDUCE-251,Improvement,Major,,Should we move out the creation of setup/cleanup tasks from JobInProgress.initTasks()? ,JobInProgress.initTasks() creates TIPs for map and reduce tasks; and also the newly-introduced setup and cleanup tasks. initTasks() is called by the schedulers; as for reasons of memory optimizations; schedulers may choose to initialize M cleanup tasks must be moved out of initTasks into a separate method which is called by the JT).   I think the latter is the right way to go (unless we implement HADOOP-4421; in which case the former option may be viable as well).,Open,Unresolved,,Amareshwari Sriramadasu,Vivek Ratan,Tue; 21 Oct 2008 10:01:56 +0000,Sat; 20 Jun 2009 07:51:04 +0000,,,,,,MAPREDUCE-138,https://issues.apache.org/jira/browse/MAPREDUCE-251
MAPREDUCE-252,Improvement,Major,,Create an InputFormat for reading lines of text as Java Strings,Such a StringInputFormat would be like TextInputFormat but with input types of Long and String; rather than LongWritable and Text. This would allow users to write MapReduce programs that used only Java native types (i.e. no Writables).  This is currently not possible to write without changes to Hadoop due to a limitation in the RecordReader interface explained here: https: HADOOP-3413?focusedCommentId=12597935#action_12597935,Resolved,Incomplete,,Tom White,Tom White,Mon; 16 Jun 2008 14:16:23 +0000,Fri; 18 Jul 2014 05:37:20 +0000,Fri; 18 Jul 2014 05:37:20 +0000,,,,HADOOP-3565;HADOOP-1230,,https://issues.apache.org/jira/browse/MAPREDUCE-252
MAPREDUCE-253,Improvement,Major,,getDiagnostics in TaskReport should return exceptions,Currently; getDiagnostics() returns Strings. When exceptions are thrown in user code and or Hadoop; it would be cleaner to propagate the exception back to the application for better error handling. Hadoop should return the exceptions instead of returning string representations that correspond to printStackTrace() output.,Resolved,Won't Fix,,Unassigned,Santhosh Srinivasan,Mon; 9 Feb 2009 17:24:52 +0000,Mon; 20 Jan 2014 18:53:03 +0000,Mon; 20 Jan 2014 18:53:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-253
MAPREDUCE-254,Improvement,Major,,JT should not iterate through all jobs in every heartbeat to find a cleanup or setup task,On every heartbeat; the JT first looks to see if it can run a setup or cleanup task; before calling a Scheduler to get a Map or Reduce task. The JT maintains a hashmap of JobInProgress objects (which can be waiting; running; or completed). It iterates through this hashmap on each heartbeat to find a setup or cleanup task. This linear search can be be very expensive; especially with large clusters where the number of jobs is high. There are lots of obvious ways to cut down on this linear search.,Open,Unresolved,,Unassigned,Vivek Ratan,Tue; 21 Oct 2008 11:33:41 +0000,Sat; 20 Jun 2009 07:51:04 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-254
MAPREDUCE-255,Improvement,Major,,avoid bzip2 decompressor throwing exception on corrupted (prematurely truncated) file,running map-reduce streaming job using the bzip2 compressor; job fails with one of either of the two following  2124)   Example: $HADOOP_HOME hadoop-streaming.jar     -jobconf num.key.fields.for.partition=1,Resolved,Incomplete,,Unassigned,Suhas Gogate,Mon; 4 Aug 2008 20:41:23 +0000,Fri; 18 Jul 2014 20:30:27 +0000,Fri; 18 Jul 2014 20:30:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-255
MAPREDUCE-256,Improvement,Major,,Optomize reduce phase when there is no map output,When a map produces no output (does not call the collector); it seems desirable that the reduce phase should not attempt to download the 0 length map output file.,Reopened,Unresolved,,Owen O'Malley,Nigel Daley,Fri; 10 Nov 2006 02:23:00 +0000,Sat; 20 Jun 2009 07:51:04 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-256
MAPREDUCE-257,Improvement,Major,,Preventing node from swapping,When a node swaps; it slows everything: maps running on that node; reducers fetching output from the node; and DFS clients reading from the DN. We should just treat it the same way as if OS exhausts memory and kill some tasks to free up memory.,Resolved,Fixed,,Unassigned,Hong Tang,Wed; 13 May 2009 08:52:18 +0000,Tue; 22 Jul 2014 19:35:47 +0000,Tue; 22 Jul 2014 19:35:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-257
MAPREDUCE-258,Improvement,Major,,Update MapOutputServlet to use NIO channels,The TaskTracker can serve the map output segments using RandomAccessFileBuffer; added in JETTY-748.,Resolved,Won't Fix,,Chris Douglas,Chris Douglas,Thu; 20 Nov 2008 22:39:06 +0000,Sat; 19 Jul 2014 00:17:39 +0000,Sat; 19 Jul 2014 00:17:39 +0000,,,,HADOOP-1650;HADOOP-4699,HDFS-916,https://issues.apache.org/jira/browse/MAPREDUCE-258
MAPREDUCE-259,Improvement,Major,,Rack-aware Shuffle,We could try and experiment with rack-aware scheduling of fetches per-reducer. Given the disparities between in-rack and off-rack bandwidth it could be a improvement to do something along these lines:     This could lead to better utilization of both in-rack  switch b w...  Clearly we want to schedule more cross-switch than in-rack since off-rack copies will take significantly more time; hence the 75-25 split.,Resolved,Duplicate,MAPREDUCE-2038,Arun C Murthy,Arun C Murthy,Thu; 16 Aug 2007 10:58:46 +0000,Thu; 17 Jul 2014 17:37:47 +0000,Thu; 17 Jul 2014 17:37:46 +0000,,,,HADOOP-1266,,https://issues.apache.org/jira/browse/MAPREDUCE-259
MAPREDUCE-260,Improvement,Major,,control-c of the submitting program should kill the job,Currently; if you kill the process that submitted the job; the job continues. The default behavior should be to kill the job if the launching process dies.,Resolved,Won't Fix,,Owen O'Malley,Owen O'Malley,Wed; 24 Jan 2007 19:32:42 +0000,Mon; 16 Jan 2012 10:36:33 +0000,Mon; 16 Jan 2012 10:36:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-260
MAPREDUCE-261,Improvement,Major,,Blacklisting of TaskTrackers should take into account the user-ID,With HADOOP-4305; it is possible to blacklist TaskTrackers across jobs. It might make sense to also take into account the users whose tasks are being run on the TaskTrackers; and use it in the blacklisting strategy.,Resolved,Incomplete,,Unassigned,Devaraj Das,Tue; 9 Dec 2008 10:54:05 +0000,Mon; 21 Jul 2014 17:05:08 +0000,Mon; 21 Jul 2014 17:05:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-261
MAPREDUCE-262,Improvement,Major,,Optimize finding of speculative tasks,Assuming HADOOP-2119 provides better data structures for handling running TIPs; finding new speculative tasks can be further optimized. Two of which could be  1) conf.getMapSpeculativeExecution() and conf.getReduceSpeculativeExecution() should be moved to JobInProgress. A simple check for this boolean can prove useful before checking for speculative tasks. This will be useful for jobs with large maps and reducers where scanning all the TIPs  can be costly.  2) Since the progress of a TIP changes only when TaskInProgress.recomputeProgress() is invoked; it makes more sense to check for speculation in JobInProgress.updateTaskStatus() and move the TIPs that can be speculated to the front of the running queue.,Resolved,Fixed,,Unassigned,Amar Kamat,Fri; 22 Feb 2008 11:16:31 +0000,Thu; 17 Jul 2014 21:05:03 +0000,Thu; 17 Jul 2014 21:05:03 +0000,,,,HADOOP-2119,,https://issues.apache.org/jira/browse/MAPREDUCE-262
MAPREDUCE-263,Improvement,Major,,mapred should provide an optional upper-bound for size of map outputs,AFAIK; currently; there is no explicit limit on the amount of disk space available for map tasks to emit map-outputs. They can use whatever space is available (This corresponds to total disk space minus disk space currently used by data-nodes to store dfs blocks.) Thus; some jobs that run fine when DFS is less full; stop working when dfs becomes more full.  If mapred had an (optional) upper-limit on the amount of local disk space used for map outputs; these jobs will run more predictably.,Open,Unresolved,,Unassigned,Milind Bhandarkar,Sun; 28 Oct 2007 19:44:41 +0000,Sat; 20 Jun 2009 07:51:05 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-263
MAPREDUCE-264,Improvement,Critical,,When combiners exist; postpone mappers' spills of map output to disk until combiners are unsuccessful.,When a map value pairs to less than; say; 90K; we just keep running the mapper and combiner alternately until we get enough distinct keys to make this unlikely to be worthwhile or until we run out of input; of course.  This has two costs: the whole internal buffer has to be re-sorted so we can apply the combiner even though as few as 10K new elements have been added; and in some cases we'll call the combiner on many singletons.    The first of these costs can be avoided by doing a mini-sort in the new pairs section and doing a merge to develop the combiner sets and the new sorted retained elements section.  The second of these costs can be avoided by detecting what would otherwise be singleton combiner calls and not making them; which is a good idea in itself even if we don't decide to do this reform.  The two techniques combine well; recycled elements of the buffer need not be combined if there's no new element with the same key.  -dk,Resolved,Won't Fix,,Owen O'Malley,Dick King,Fri; 14 Jul 2006 17:15:12 +0000,Mon; 16 Jan 2012 09:19:39 +0000,Mon; 16 Jan 2012 09:19:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-264
MAPREDUCE-265,Improvement,Major,,check permissions for job inputs and outputs,On job submission; filesystem permissions should be checked to ensure that the input directory is readable and that the output directory is writable.,Resolved,Fixed,,Unassigned,Doug Cutting,Fri; 4 Jan 2008 20:08:32 +0000,Thu; 17 Jul 2014 19:25:12 +0000,Thu; 17 Jul 2014 19:25:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-265
MAPREDUCE-266,Improvement,Major,client,Remove deprecated MultiFileInputFormat,Remove the deprecated class org.apache.hadoop.mapred.MultiFileInputFormat,Resolved,Won't Fix,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 14 Apr 2009 11:55:19 +0000,Wed; 23 Jul 2014 22:15:56 +0000,Wed; 23 Jul 2014 22:15:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-266
MAPREDUCE-267,Improvement,Major,,Rack level copy of map outputs,In case of maps taking of lot of time to complete; a rack level copy of the map output can be maintained so that incase of master node for that map goes down the other copy can be served. This will be useful since re-executing the map can be time consuming and rack-level copy is much cheaper than network-level copy.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 29 Jan 2008 06:40:05 +0000,Thu; 2 May 2013 02:29:12 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-267
MAPREDUCE-268,Improvement,Major,,Implement memory-to-memory merge in the reduce,HADOOP-3446 fixed the reduce to not flush the in-memory shuffled map-outputs before feeding to the reduce. However for latency-sensitive applications with lots of memory like the terasort this hurts performance since the fan-in for the final in-memory merge is too large (all 8000 map-outputs very in-memory) resulting in less than optimal performance.  When I put in an intermediate memory-to-memory merge for the terasort's reduce (there-by avoiding disk i o) to cut the fan-in from 8000 to 100 the 'reduce' phase (including the local datanode-write) sped-up 250% (from 10s to 4s).,Resolved,Duplicate,MAPREDUCE-318,Arun C Murthy,Arun C Murthy,Thu; 14 May 2009 07:31:03 +0000,Tue; 5 Jun 2012 02:37:30 +0000,Mon; 14 Sep 2009 04:57:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-268
MAPREDUCE-269,Improvement,Major,,"[mapred] ""bin/hadoop job -counter"" CLI should accept display names for group-name and counter-name.",Internal names are hard to remember specify. CLI should also accept display names in addition to the actual group-name and counter-name.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Fri; 19 Sep 2008 13:23:24 +0000,Sat; 20 Jun 2009 07:51:05 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-269
MAPREDUCE-270,Improvement,Major,,TaskTracker could send an out-of-band heartbeat when the last running map/reduce completes,Currently the TaskTracker strictly respects the heartbeat interval; this causes utilization issues when all running tasks complete. We could send an out-of-band heartbeat in that case.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 27 Jan 2009 08:18:40 +0000,Tue; 24 Aug 2010 21:13:24 +0000,Mon; 28 Sep 2009 21:32:25 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-270
MAPREDUCE-271,Improvement,Major,examples,Change examples code to use new mapreduce api.,Currently only Wordcount and SecondarySort examples are written using new mapreduce api. Other examples; in org.apache.hadoop.examples package : BaileyBorweinPlouffe; DBCountPageView; Grep; Join;  MultiFileWordCount; PiEstimator; RandomTextWriter; RandomWriter; SleepJob; Sort should be changed to use new mapreduce api.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 7 Apr 2009 06:02:30 +0000,Thu; 24 Nov 2011 04:04:22 +0000,Thu; 28 Jan 2010 11:13:04 +0000,,,,MAPREDUCE-367;HADOOP-5691,,https://issues.apache.org/jira/browse/MAPREDUCE-271
MAPREDUCE-272,Improvement,Major,,Job tracker should report the number of splits that are local to some task trackers,Right now; jon tracker keeps track the number of launched mappers with local data. However; it is not clear how many mappers that are potentially be launched with data locality. This information is readily available in Job Tracker. It is just a matter to create a separate global  counter  and set it at the Job Tracker initialization time.,Open,Unresolved,,Runping Qi,Runping Qi,Tue; 9 Oct 2007 16:47:24 +0000,Thu; 17 Jul 2014 18:09:18 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-272
MAPREDUCE-273,Improvement,Major,,Jobs should not be initialized while the recovery is in progress,In the default case; the eager-task-initializer tries to init a job as soon as its added. There is actually no need for external inits as recovery manager itself does a forceful inits. The important thing is to enforce this delay on inits across schedulers.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Thu; 19 Mar 2009 07:03:42 +0000,Mon; 21 Jul 2014 22:05:02 +0000,Mon; 21 Jul 2014 22:05:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-273
MAPREDUCE-274,Improvement,Major,,Hadoop JobClient can return specific exit codes for specific classes of exceptions,Today if a job tracker becomes unresponsive or dies; the hadoop JobClient throws an exception subclass of IOException and exits with an exit code of 1. However; it would probably fail with the same exit code if there's any other type of exception as well. Programs like HOD which use this client (indirectly through the hadoop script) can make better decisions if the error code is more distinguishable. For e.g. if it's a network related exception; we can treat the cluster are unusable; or retry after awhile etc. More generically; if categories of exceptions can be treated with specific exit codes; it will help.   Comments ?,Resolved,Won't Fix,,Unassigned,Hemanth Yamijala,Wed; 20 Feb 2008 10:54:32 +0000,Thu; 17 Jul 2014 20:57:37 +0000,Thu; 17 Jul 2014 20:57:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-274
MAPREDUCE-275,Improvement,Major,,Display lost tracker information on the jobtracker webui and persist it across restarts,As of today its difficult to distinguish between active tracker and lost trackers (lost trackers are considered active). It will be nice if the jobtracker can display what all trackers are lost and maintain it across restarts. HADOOP-5643 does something similar for decommissioned trackers.,Resolved,Won't Fix,,Amar Kamat,Amar Kamat,Mon; 27 Apr 2009 08:04:37 +0000,Tue; 22 Jul 2014 19:10:45 +0000,Tue; 22 Jul 2014 19:10:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-275
MAPREDUCE-276,Improvement,Major,,Multiple copies of jobconf is present in history-dir after restart,Across restarts; when a job is inited; jobconf for this job is localized to the history folder. These filenames have jobtracker-identifier which changes across restarts. Hence we see multiple jobconfs in the history folder.,Resolved,Duplicate,MAPREDUCE-416,Amar Kamat,Amar Kamat,Tue; 16 Jun 2009 05:04:27 +0000,Fri; 26 Jun 2009 06:11:32 +0000,Fri; 26 Jun 2009 06:11:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-276
MAPREDUCE-277,Improvement,Blocker,jobtracker,Job history counters should be avaible on the UI.,Job history is logging counters. But they are not visible on the UI.  Job history parser and UI should be modified to view counters.,Closed,Fixed,,Jothi Padmanabhan,Amareshwari Sriramadasu,Mon; 7 Apr 2008 09:32:47 +0000,Tue; 24 Aug 2010 21:13:24 +0000,Fri; 18 Sep 2009 17:39:52 +0000,,0.20.1,,MAPREDUCE-157;HADOOP-3245,,https://issues.apache.org/jira/browse/MAPREDUCE-277
MAPREDUCE-278,Improvement,Major,,Proposal for redesign/refactoring of the JobTracker and TaskTracker,During discussions on HADOOP-815 wrt some hard-to-maintain code on the JobTracker we all agreed th this we redo the nomenclature a bit: JobInProgress - Job TaskInProgress - Task taskid - replace with a new TaskAttempt this should help clarify each class and it's roles.  Of course we will probably need a separate org.apache.hadoop.mapred.job.Task v s org.apache.hadoop.mapred.task.Task which is why I feel HADOOP-554 (refactoring of mapred packages) would be very important to get a complete; coherent solution.  Thoughts?,Resolved,Not A Problem,,Sharad Agarwal,Arun C Murthy,Tue; 9 Jan 2007 18:58:17 +0000,Mon; 23 Apr 2012 09:34:10 +0000,Mon; 16 Jan 2012 10:29:12 +0000,,,,,MAPREDUCE-206,https://issues.apache.org/jira/browse/MAPREDUCE-278
MAPREDUCE-279,Improvement,Major,mrv2,Map-Reduce 2.0,Re-factor MapReduce into a generic resource scheduler and a per-job; user-defined component that manages the application execution.,Closed,Fixed,HADOOP-3421;HADOOP-3444,Unassigned,Arun C Murthy,Wed; 2 Jan 2008 19:37:48 +0000,Thu; 2 May 2013 02:29:11 +0000,Thu; 18 Aug 2011 11:47:52 +0000,,,,,MAPREDUCE-2644;MAPREDUCE-2630;YARN-3172;MAPREDUCE-2719;PIG-2125;MAPREDUCE-2639;MAPREDUCE-2633,https://issues.apache.org/jira/browse/MAPREDUCE-279
MAPREDUCE-280,Improvement,Major,,TextInputFormat should allow different treatment on carriage return char '\r',The current implementation treat ' r' as a part of data in a line.   One way to do this is to make readline function as a member function so that the user can create a subclass to overwrite the function with the desired behavior.,Resolved,Not A Problem,,Owen O'Malley,Runping Qi,Wed; 29 Nov 2006 05:53:51 +0000,Tue; 24 Jan 2012 20:19:30 +0000,Mon; 16 Jan 2012 10:20:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-280
MAPREDUCE-281,Improvement,Major,,MultipleFileInputFormat should support a sub InputFormat,Currently; to use MultipleFileInputFormat you need to create a subclass; but it seems pretty easy to modify it to use a sub InputFormat and put the results together into bigger splits.,Open,Unresolved,,Unassigned,Owen O'Malley,Wed; 3 Sep 2008 04:30:27 +0000,Sat; 20 Jun 2009 07:51:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-281
MAPREDUCE-282,Improvement,Major,,The URL in TaskCompletionEvent should be the root URL for the taskTracker,Currently the entire url for the stdout of the task is stored in the URL for TaskCompletionEvent. It would be better to just have the URL for the root page of the relevant task tracker.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Thu; 8 Feb 2007 22:18:35 +0000,Sat; 20 Jun 2009 07:51:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-282
MAPREDUCE-283,Improvement,Major,,We should reuse key and value objects in the MultithreadedMapRunner.,Currently; each key value pairs that were reused. I'm picturing something like:  BlockingQueueKeyValuePair empties; BlockingQueueKeyValuePair newInputs;  the record reader thread would take a KeyValuePair from the empties queue; read into it using the RecordReader; and put it on the newInputs queue.  The work threads would read from newInputs; process the key and value and put the processed objects on the empties queue. The initialization would put the desired number of key-value pairs on the empties queue to start it off.,Resolved,Incomplete,,Unassigned,Owen O'Malley,Fri; 28 Mar 2008 21:32:57 +0000,Thu; 17 Jul 2014 21:52:36 +0000,Thu; 17 Jul 2014 21:52:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-283
MAPREDUCE-284,Improvement,Major,,Improvements to RPC between Child and TaskTracker,"We could improve the RPC between the Child and TaskTracker:  	Set ping interval lower by default to 5s 	Disable nagle's algorithm (tcp no-delay)",Closed,Fixed,,Ravi Gummadi,Arun C Murthy,Fri; 8 May 2009 09:11:50 +0000,Tue; 24 Aug 2010 21:13:25 +0000,Tue; 15 Sep 2009 10:14:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-284
MAPREDUCE-285,Improvement,Major,,Reuse output collectors across maps running on the same jvm,"We have evidence that cutting the shuffle-crossbar between maps and reduces (m * r) leads to perfomant applications since:  	It cuts down the number of connections necessary to shuffle and hence reduces load on the serving-side (TaskTracker) and improves latency (terasort; HADOOP-1338; HADOOP-5223) 	Reduces seeks required for the TaskTracker to serve the map-outputs    So far we've had to manually tune applications to cut down the shuffle- crossbar by having fatter maps with custom input formats etc. For e.g. we saw a significant improvement while running the petasort when we went from ~800;000 maps to 80;00 maps (1.5G to 15G per map) i.e. from 48+ hours to 16 hours;    The downsides are:  	The burden falls on the application-writer to tune this with custom input-formats etc. 	The naive method of using a higher min.split.size leads to considerable non-local i combine) and the failure cases get a bit more complicated.  Thoughts? Lets discuss...",Open,Unresolved,,Unassigned,Arun C Murthy,Thu; 14 May 2009 07:17:02 +0000,Sat; 20 Jun 2009 07:51:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-285
MAPREDUCE-286,Improvement,Major,,Optimize the last merge of the map output files,In ReduceTask; today we do merges of io.sort.factor number of files everytime we merge and write the result back to disk. The last merge can probably be better. For example; if there are io.sort.factor + 10 files at the end; today we will merge 100 files into one and then return an iterator over the remaining 11 files. This can be improved (in terms of disk I O) to merge the smallest 11 files and then return an iterator over the 100 remaining files. Other option is to not do any single level merge when we have io.sort.factor + n files remaining (where n &lt; io.sort.factor) but just return the iterator directly. Thoughts?,Resolved,Fixed,,Unassigned,Devaraj Das,Sat; 1 Mar 2008 09:24:03 +0000,Thu; 17 Jul 2014 21:22:03 +0000,Thu; 17 Jul 2014 21:22:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-286
MAPREDUCE-287,Improvement,Major,,Replace the JobConf.setNumOfMapTasks with FileInputFormat.setMapInputSize(long),It is confusing to users to set the number of mappers and have the system override it. It would be far less confusing to remove JobConf.setNumMapTasks and FileInputFormat.setMinSplitSize and have a single FileInputFormat.setMapInputSize(long) and simplify the logic around it.,Open,Unresolved,,Unassigned,Owen O'Malley,Thu; 31 May 2007 22:20:28 +0000,Sat; 20 Jun 2009 07:51:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-287
MAPREDUCE-288,Improvement,Major,,Documention for using external profilers on Map-Reduce applications,We should document the usage of external profilers such as YourKit mapred_tutorial.html#Profiling. Specifically the ability to use the DistributedCache for distributing the shared object; setting up the LD_LIBRARY_PATH etc.,Resolved,Won't Fix,,Arun C Murthy,Arun C Murthy,Wed; 22 Oct 2008 18:34:49 +0000,Mon; 21 Jul 2014 16:34:45 +0000,Mon; 21 Jul 2014 16:34:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-288
MAPREDUCE-289,Improvement,Major,,JobTracker should not expand jobs if its running low on memory,When the JobTracker detects that its running low on memory it should not expand new jobs if the job has the potential to bring it down. Consider and example where the JobTracker runs on 60% of the max memory and a new job is submitted which can take upto 40% of the max memory.  Ideally the JobTracker should queue the job for expansion and expand when sufficient memory is available.,Resolved,Fixed,,Unassigned,Amar Kamat,Mon; 12 Jan 2009 07:56:23 +0000,Mon; 21 Jul 2014 17:58:28 +0000,Mon; 21 Jul 2014 17:58:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-289
MAPREDUCE-290,Improvement,Major,,Extend HADOOP-3293 to MapReduce package also,HADOOP-3293 made changes to FileInputFormat to identify split locations that contribute most to the split. This functionality has to be added to the MapReduce.FileInputFormat too.,Open,Unresolved,,Jothi Padmanabhan,Jothi Padmanabhan,Tue; 3 Mar 2009 11:05:49 +0000,Mon; 21 Jul 2014 21:25:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-290
MAPREDUCE-291,Improvement,Major,jobtracker,Optionally a separate daemon should serve JobHistory,Currently the JobTracker serves the JobHistory to end-users off files local-disk hdfs. While running very large clusters with a large user-base might result in lots of traffic for job-history which needlessly taxes the JobTracker. The proposal is to have an optional daemon which handles serving of job-history requests.,Resolved,Fixed,,Amar Kamat,Arun C Murthy,Tue; 20 Jan 2009 09:28:41 +0000,Mon; 21 Jul 2014 18:13:44 +0000,Mon; 21 Jul 2014 18:13:44 +0000,,,,,MAPREDUCE-177,https://issues.apache.org/jira/browse/MAPREDUCE-291
MAPREDUCE-292,Improvement,Major,,Pin reduces with consecutive IDs to nodes and have a single shuffle task per job per node,The idea is to reduce disk seeks while fetching the map outputs. If we opportunistically pin reduces with consecutive IDs (like 5; 6; 7 .. max-reduce-tasks on that node) on a node; and have a single shuffle task; we should benefit; if for every fetch; that shuffle task fetches all the outputs for the reduces it is shuffling for. In the case where we have 2 reduces per node; we will decrease the #seeks in the map output files on the map nodes by 50%. Memory usage by that shuffle task would be proportional to the number of reduces it is shuffling for (to account for the number of ramfs instances; one per reduce). But overall it should help.   Thoughts?,Open,Unresolved,,Devaraj Das,Devaraj Das,Wed; 9 Jan 2008 20:15:43 +0000,Sat; 20 Jun 2009 07:51:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-292
MAPREDUCE-293,Improvement,Major,,Need value for Running; Completed and Failed maps and reduces for a job.,Currently there is no JobClient call which gives information for Running; Completed and Failed maps and reduces for a job. Only way to get this is to parse jobdetails.jsp.,Open,Unresolved,,Unassigned,Karam Singh,Fri; 5 Dec 2008 12:02:32 +0000,Sat; 20 Jun 2009 07:51:07 +0000,,,,,HADOOP-4830,,https://issues.apache.org/jira/browse/MAPREDUCE-293
MAPREDUCE-294,Improvement,Major,,"Add Jar ""lib"" directory to TaskRunner's library.path setting to allow JNI libraries to be deployed via JAR file  ","It is extremely convenient to be able to deploy JNI libraries utilized in a custom map-reduce job via the job's JAR file. The TaskRunner already establishes a precedent by automatically adding any jar files contained in the ""lib"" directory of the job jar to the child map reduce process's classpath. Following this convention; it should also be possible to deploy custom JNI libraries in the same lib directory. This involves adding the path to the job jar's lib directory to the VM's library.path setting (after the jar has been expanded in the job cache directory). This does not elimintate the need add dependent shared libraries that may be referenced by the JNI libraries to the system's LD_LIBRARY_PATH variable. In our deployment configuration; we usually pre-install third party shared libraries across the cluster and only deploy our custom JNI libraries via the job jar.",Open,Unresolved,,Ahad Rana,Ahad Rana,Mon; 3 Nov 2008 18:42:08 +0000,Mon; 21 Jul 2014 16:48:32 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-294
MAPREDUCE-295,Improvement,Major,,Jobtracker leaves tasktrackers underutilized,For some workloads; the jobtracker doesn't keep all the slots utilized even under heavy load.,Open,Unresolved,,Unassigned,Khaled Elmeleegy,Mon; 6 Apr 2009 22:51:01 +0000,Thu; 13 Dec 2012 10:39:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-295
MAPREDUCE-296,Improvement,Major,,job statistics should be displayed in the web/ui,It would be really nice; if the job page in the web ui showed the time that:   1. first map started   2. last map finished   3. last reduce finished shuffle   4. last reduce finished sort   5. last reduce finished,Resolved,Duplicate,NULL,Unassigned,Owen O'Malley,Wed; 3 Jan 2007 23:47:50 +0000,Thu; 17 Jul 2014 16:38:57 +0000,Thu; 17 Jul 2014 16:38:57 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-296
MAPREDUCE-297,Improvement,Major,,generalize the TT / JT servers to handle more generic tasks,We've been discussing a proposal to generalize the TT  pbs like systems (or presumably borg) with map-reduce as a user job.  Such a system would allow the current map-reduce code to coexist with other work-queuing libraries or maybe even persistent services on the same Hadoop cluster; although that would be a stretch goal.  We'll kick off a thread with some documents soon.  Our primary goal in going this way would be to get better utilization out of map-reduce clusters and support a richer scheduling model.  The ability to support alternative job frameworks would just be gravy!    Putting this in as a place holder.  Hope to get folks talking about this to post some more detail.,Resolved,Duplicate,MAPREDUCE-279,Unassigned,eric baldeschwieler,Wed; 26 Dec 2007 21:22:30 +0000,Thu; 2 May 2013 02:29:11 +0000,Sun; 17 Jun 2012 10:55:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-297
MAPREDUCE-298,Improvement,Major,,multi-threaded merge phase,Doing merges in multiple threads (when enough cores are available  a monitoring issue); the time spent in merging could be cut by a factor equal to the number of threads.,Open,Unresolved,,Unassigned,Christian Kunz,Wed; 26 Nov 2008 02:50:11 +0000,Sat; 19 Jul 2014 00:20:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-298
MAPREDUCE-299,Improvement,Major,,Check MapReduce types for consistency,It is possible to configure MapReduce programs to use an inconsistent set of types. Although some runtime checks are carried out; there are more that can be done as described in HADOOP-1231.,Open,Unresolved,,Unassigned,Tom White,Sun; 5 Aug 2007 20:19:45 +0000,Thu; 2 May 2013 02:29:10 +0000,,,,,,MAPREDUCE-1411,https://issues.apache.org/jira/browse/MAPREDUCE-299
MAPREDUCE-300,Improvement,Major,,Ability to thread task execution,Currently Hadoop spawns a single threaded JVM for each task.  While good for many tasks; this does not maximize resource usage for slaves that have many cores (machines with more cores are getting more cost effective everyday) and are running jobs that require many gigabytes of read-only in-memory resources to maximize throughput.  Running in separate JVMs requires redundantly loading large amounts of data; reducing the possible number of parallel tasks that can run per a machine even though more cpus are available.  Adding this ability will give hadoop users the flexibility to balance their need for maximizing memory usage  throughput and task segmentation.  Note: This is a blocking bug in porting processes over to hadoop for my own organization.  I am testing a patch for this now that leaves the existing behavior for single threaded operation in-tact.  All synchronization is done through wrapper classes and helper methods and should not add any overhead to non-threaded processes.,Resolved,Not A Problem,,Unassigned,Holden Robbins,Mon; 10 Mar 2008 22:48:24 +0000,Thu; 17 Jul 2014 21:39:21 +0000,Thu; 17 Jul 2014 21:39:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-300
MAPREDUCE-301,Improvement,Major,,mapred.child.classpath.extension property,It would be useful to be able to extend the classpath for the task processes on a job per job basis via a mapred.child.classpath.extension property.,Resolved,Fixed,,Unassigned,Klaas Bosteels,Wed; 3 Jun 2009 14:20:09 +0000,Tue; 22 Jul 2014 20:23:25 +0000,Tue; 22 Jul 2014 20:23:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-301
MAPREDUCE-302,Improvement,Major,,Maintaining cluster information across multiple job submissions,Could we have a way to maintain cluster state across multiple job submissions. Consider a scenario where we run multiple jobs in iteration on a cluster back to back. The nature of the job is same; but input output might differ.   Now; if a node is blacklisted in one iteration of job run; it would be useful to maintain this information and blacklist this node for next iteration of job as well.  Another situation which we saw is; if there are failures less than mapred.map.max.attempts in each iterations few nodes are never marked for blacklisting. But in we consider two or three iterations; these nodes fail all jobs and should be taken out of cluster. This hampers overall performance of the job.  Could have have config variables something which matches a job type (provided by user) and maintains the cluster status for that job type alone?,Open,Unresolved,,dhruba borthakur,Lohit Vijayarenu,Tue; 22 Jan 2008 17:16:52 +0000,Thu; 17 Jul 2014 19:47:00 +0000,,,,,,MAPREDUCE-451;HADOOP-4305,https://issues.apache.org/jira/browse/MAPREDUCE-302
MAPREDUCE-303,Improvement,Major,,refactor the mapred package into small pieces,The mapred package has gotten too big; so I propose changing it to split it into parts.  I propose the following splits:  org.apache.hadoop.mapred = client API org.apache.hadoop.mapred.task = code for task tracker org.apache.hadoop.mapred.job = code for job tracker org.apache.hadoop.mapred.utils = non public code that is shared between the servers  Does anyone have any other divisions that would help?  I would make the classes sent through RPC public classes in the server's package.  Thoughts?,Resolved,Not A Problem,,Owen O'Malley,Owen O'Malley,Fri; 28 Jul 2006 20:21:28 +0000,Mon; 16 Jan 2012 09:22:39 +0000,Mon; 16 Jan 2012 09:22:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-303
MAPREDUCE-304,Improvement,Major,,The locality information for splits should be included in the job history,We should log the hosts and sizes for each split.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Fri; 4 Apr 2008 16:16:13 +0000,Sat; 20 Jun 2009 07:51:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-304
MAPREDUCE-305,Improvement,Major,,Add job-level counters for the launched speculative tasks,Add job-level counters for the launched speculative tasks; this should help track them.   Ideally we would also have counters to check how many of the speculative tasks completed before the original task (thereby helps validate the strategy for launching speculative tasks); however we do not have this infrastructure yet (HADOOP-544) - so I'll file a follow-on bug for that feature.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Wed; 5 Dec 2007 08:02:42 +0000,Sat; 20 Jun 2009 07:51:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-305
MAPREDUCE-306,Improvement,Major,,"job submission protocol should have a method for getting the ""task capacity"" of the cluster",It would help the InputFormats make informed decisions if the JobSubmissionProtocol had a method the returned the number of tasks that the cluster can run at once.,Resolved,Fixed,,Unassigned,Owen O'Malley,Fri; 9 Mar 2007 06:54:03 +0000,Thu; 17 Jul 2014 16:53:22 +0000,Thu; 17 Jul 2014 16:53:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-306
MAPREDUCE-307,Improvement,Major,,Iterator for MapFileOutputFormat,MapFileOutputFormat produces output data that is sorted locally in each part-NNNNN file - however; there is no easy way to iterate over keys from all parts in a globally ascending order.,Open,Unresolved,,Andrzej Bialecki,Andrzej Bialecki,Thu; 14 Feb 2008 20:29:52 +0000,Sat; 20 Jun 2009 07:51:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-307
MAPREDUCE-308,Improvement,Major,,A JobInProgressLIstener can change a job without informing other listeners,As of now the JobInProgressListener adds itself to the JobTracker and gets updated events (e.g.  EagerTaskInitializer). The issue with this model is that a listener can change the job without informing other listeners.,Resolved,Invalid,,Unassigned,Amar Kamat,Sat; 25 Oct 2008 12:19:22 +0000,Wed; 7 Oct 2009 06:13:45 +0000,Wed; 7 Oct 2009 06:13:45 +0000,,,,,MAPREDUCE-463,https://issues.apache.org/jira/browse/MAPREDUCE-308
MAPREDUCE-309,Improvement,Major,,The cluster admin should be able to configure a name for the job tracker,It would be good if the cluster admin could define a job tracker name that was used to form the unique part of the job ids. I think something like:  mapred.jobtracker.name = xxx  job_xxx_200808081200_00001  if it is undefined; it would default to the current behavior of just using the timestamp.,Resolved,Won't Fix,,Unassigned,Owen O'Malley,Thu; 7 Aug 2008 21:19:56 +0000,Fri; 18 Jul 2014 20:51:20 +0000,Fri; 18 Jul 2014 20:51:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-309
MAPREDUCE-310,Improvement,Major,,JobClient should keep on retrying if the jobtracker is still initializing,When the user submits the job while the jobtracker is still initializing; the jobclient comes out with an exception. ideally the jobclient should keep on retrying until the jobtracker is up and ready. This will also take care of HADOOP-3289.,Resolved,Won't Fix,,Amar Kamat,Amar Kamat,Mon; 23 Jun 2008 09:24:49 +0000,Fri; 18 Jul 2014 16:33:48 +0000,Fri; 18 Jul 2014 16:33:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-310
MAPREDUCE-311,Improvement,Major,,JobClient should use multiple volumes as hadoop.tmp.dir,Currently; hadoop.tmp.dir configuration variable allows specification of only a single directory to be used as scratch space. In particular; on the job launcher nodes with multiple volumes; this fails the entire job if the tmp.dir is somehow unusable. When the job launcher nodes have multiple volumes; the tmp space availability can be improved by using multiple volumes (either randomly or in round-robin.) The code for choosing a volume from a comma-separated list of multiple volumes is already there for mapred.local.dir etc. That needs to be used by job client as well.,Open,Unresolved,,Unassigned,Milind Bhandarkar,Tue; 26 May 2009 17:44:04 +0000,Tue; 22 Jul 2014 20:11:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-311
MAPREDUCE-312,Improvement,Major,,Port HADOOP-4667 to the default Map-Reduce scheduler,HADOOP-4667 has implemented 'global scheduling' for the fair-share scheduler with very promising results - we should port the same to the default o.a.h.mapred.JobQueueTaskScheduler.,Resolved,Won't Fix,,Arun C Murthy,Arun C Murthy,Wed; 21 Jan 2009 06:48:51 +0000,Mon; 21 Jul 2014 18:18:08 +0000,Mon; 21 Jul 2014 18:18:08 +0000,,,,,MAPREDUCE-548,https://issues.apache.org/jira/browse/MAPREDUCE-312
MAPREDUCE-313,Improvement,Major,,Add additional jobs of new types to gridmix,Currently; gridmix does not contain any jobs using combiners nor a job sorting compressed input data Word count like jobs should be a good candidate of using combiners. Sorting compressed input data should exercise the mapper spill logic and or the effect of map output compression.,Resolved,Fixed,,Unassigned,Runping Qi,Mon; 25 Feb 2008 19:32:57 +0000,Thu; 17 Jul 2014 21:08:54 +0000,Thu; 17 Jul 2014 21:08:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-313
MAPREDUCE-314,Improvement,Major,,Avoid priority inversion that could result due to scheduling running jobs in an order sorted by priority,"Consider a job; J1; with priority NORMAL that is running reduce tasks occupying all reduce slots and has running and pending map tasks. 	At this point; suppose a job; J2; is submitted with priority HIGH or say its priority is changed to HIGH from NORMAL. 	The schedulers typically will start scheduling tasks from job J2; as J1's running maps complete. The default scheduler in Hadoop does this; and with HADOOP-4471; so will the capacity scheduler. 	However; as there are still pending maps in J1; the reduce tasks of J1 are all stuck and no reduce tasks of J2 can run. 	So; all map tasks of J2 will complete; followed by completion of all map tasks of J1; and then reduce tasks from J1 will start getting freed for J2 to complete.    This could result in jobs completing slowly. Also; if there are enough jobs of higher priority; they could result in low priority jobs being starved. At the same time more and more resources (such as intermediate disk space) will get consumed without jobs completing.  This jira is to discuss and implement a solution for the above problem.",Resolved,Fixed,,Unassigned,Hemanth Yamijala,Fri; 31 Oct 2008 07:20:09 +0000,Mon; 21 Jul 2014 16:44:47 +0000,Mon; 21 Jul 2014 16:44:47 +0000,,,,,YARN-1963;HADOOP-5271,https://issues.apache.org/jira/browse/MAPREDUCE-314
MAPREDUCE-315,Improvement,Major,,Bias the decision of task scheduling (both for not-running and running) on node metrics (load; processing rate etc).,HADOOP-2014 deals with a similar issue but at the rack level. This issue deals with the nodes on the same rack. Consider the following case    Now if H5 asks for a new task to run;  it will be given T1. Ideally it should be given T4 because the processing rate of H1 is better than H4. Giving T1 will kill the locality of a better node. It makes more sense to kill the locality of a bad node instead. If H4 is overloaded then its better to select T4 since that might increase the chances of hitting the locality. With HADOOP-2014 the chances of TIPs from rack1 getting selected decreases since there might be other racks which are overloaded and the hosts having T4;T5;T6 (locally) are in better shape than H5. The point is select splits from nodes (rack local) that either have many local splits or might not be able to process them faster.   Even for speculation; its better to speculate a TIP that might take longer than expected amongst those which can be speculated. Consider the following    Here it makes sense to speculate T2 since there is a reason to believe that T2 on H2 might become a long tail.,Open,Unresolved,,Unassigned,Amar Kamat,Wed; 13 Feb 2008 06:42:08 +0000,Sat; 20 Jun 2009 07:51:08 +0000,,,,,HADOOP-2119;HADOOP-1985,,https://issues.apache.org/jira/browse/MAPREDUCE-315
MAPREDUCE-316,Improvement,Major,,Splittability of input should be controllable by application,Currently; isSplittable method of FileInputFormat always returns true. For some applications; it becomes necessary that the map task process entire file; rather than a block. Therefore; splittability of input (i.e. block-level split vs file-level-split) should be controllable by user via a configuration variable. The default could be block-level split; as is.,Resolved,Won't Fix,,Senthil Subramanian,Milind Bhandarkar,Tue; 29 May 2007 23:07:49 +0000,Thu; 17 Jul 2014 17:14:42 +0000,Thu; 17 Jul 2014 17:14:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-316
MAPREDUCE-317,Improvement,Major,,Submitting job information via DFS in Map/Reduce causing consistency and performance issues,"Job submission involves two steps: submitting jobs to the System directory on DFS (done by the client); then submit the job via the JobSubmissionProtocol to JobTracker. This two step process is seen to have some issues:   	Since the files need to be read from DFS; slowness in the DFS can cause job initialization to become costly. We faced this as described in HADOOP-5286 and HADOOP-4664. 	The two step process could lead to inconsistent information being left around - like in HADOOP-5327 and HADOOP-5335.    This JIRA is to explore options to remove the two step process in submitting a job.",Resolved,Incomplete,,Unassigned,Hemanth Yamijala,Fri; 27 Feb 2009 13:59:40 +0000,Mon; 21 Jul 2014 21:14:23 +0000,Mon; 21 Jul 2014 21:14:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-317
MAPREDUCE-318,Improvement,Major,performance;task,Refactor reduce shuffle code,The reduce shuffle code has become very complex and entangled. I think we should move it out of ReduceTask and into a separate package (org.apache.hadoop.mapred.task.reduce). Details to follow.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Wed; 11 Feb 2009 18:34:32 +0000,Sun; 6 Jan 2013 06:24:18 +0000,Thu; 3 Sep 2009 13:56:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-318
MAPREDUCE-319,Improvement,Major,,Use Grizzly for Fetching Map Output in Shuffle,As mentioned in HADOOP-1273 and references therefrom; Jetty 6 still doesn't seem to be stable enough for use in Hadoop. Instead; we've decided to consider the usage of Grizzly Framework https:  for NIO based communication.,Resolved,Fixed,,Devaraj Das,Tahir Hashmi,Fri; 25 May 2007 07:07:04 +0000,Thu; 17 Jul 2014 17:13:01 +0000,Thu; 17 Jul 2014 17:13:01 +0000,,,,,HDFS-916,https://issues.apache.org/jira/browse/MAPREDUCE-319
MAPREDUCE-320,Improvement,Major,,Map/Reduce should use IP addresses to identify nodes rather than hostnames,We should move the Map Reduce framework to identify hosts as IP addresses rather than hostnames to prevent problems with DNS.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Tue; 12 Jun 2007 20:52:25 +0000,Thu; 17 Jul 2014 17:19:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-320
MAPREDUCE-321,Improvement,Major,,provide progress feedback while the reducer is sorting,during the sort phase of reduce; the progress is stuck at 33%; like: tip_0132_r_000000 0.33333334 reduce  sort   For some jobs this takes a long time; during which it's not clear if the job is making any progress. Some progress indication would be good.,Open,Unresolved,,Unassigned,Yoram Arnon,Fri; 21 Jul 2006 22:47:04 +0000,Mon; 16 Jan 2012 09:38:16 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-321
MAPREDUCE-322,Improvement,Major,,TaskTracker shuold run user tasks nicely in the local machine,If one task tried to use all CPUs in a local machine; all other tasks or processes (includes tasktracker and datanode daemons) may hardly get a chance to run.,Resolved,Fixed,,Unassigned,Tsz Wo Nicholas Sze,Wed; 22 Apr 2009 23:49:52 +0000,Thu; 19 Mar 2015 15:58:32 +0000,Tue; 22 Jul 2014 18:59:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-322
MAPREDUCE-323,Bug,Critical,jobtracker,Improve the way job history files are managed,Today all the jobhistory files are dumped in one job-history folder. This can cause problems when there is a need to search the history folder (job-recovery etc). It would be nice if we group all the jobs under a user folder. So all the jobs for user amar will go in history-folder . Jobs can be categorized using various features like jobid; date; jobname etc but using username will make the search much more efficient and also will not result into namespace explosion.,Resolved,Fixed,,Dick King,Amar Kamat,Mon; 17 Nov 2008 07:48:11 +0000,Thu; 11 Feb 2016 23:09:14 +0000,Wed; 7 Sep 2011 08:35:47 +0000,,0.21.0;0.22.0,,MAPREDUCE-1988;MAPREDUCE-70,MAPREDUCE-1978,https://issues.apache.org/jira/browse/MAPREDUCE-323
MAPREDUCE-324,Improvement,Major,,Exception thrown for URL.openConnection used in the shuffle phase should be caught thus making it possible to reuse the connection for future use,nan,Open,Unresolved,,Amar Kamat,Amar Kamat,Tue; 30 Oct 2007 18:19:21 +0000,Sat; 20 Jun 2009 07:51:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-324
MAPREDUCE-325,Improvement,Major,,JobTracker's processHeartbeat() should not call System.currentTimeMillis() everytime,Consider the following    Here; the call to System.currentTimeMillis() on every call to JobTracker.processHeartbeat() might prove costly. While testing sec. So that means we might make ~130 calls to System.currentTimeMillis() per second. I think in these cases (last-seen-status etc) such a high level of accuracy in terms of timestamp is unnecessary and hence can be avoided.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Tue; 10 Jun 2008 09:09:00 +0000,Tue; 28 Jul 2009 10:05:43 +0000,Tue; 28 Jul 2009 10:05:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-325
MAPREDUCE-326,Improvement,Major,,The lowest level map-reduce APIs should be byte oriented,As discussed here: https: HADOOP-1986#action_12551237  The templates; serializers and other complexities that allow map-reduce to use arbitrary types complicate the design and lead to lots of object creates and other overhead that a byte oriented design would not suffer.  I believe the lowest level implementation of hadoop map-reduce should have byte string oriented APIs (for keys and values).  This API would be more performant; simpler and more easily cross language.  The existing API could be maintained as a thin layer on top of the leaner API.,Open,Unresolved,,Unassigned,eric baldeschwieler,Fri; 14 Dec 2007 17:03:22 +0000,Tue; 16 Feb 2010 21:36:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-326
MAPREDUCE-327,Improvement,Major,,Add explicit remote map count JobTracker metrics,"I am proposing to add a counter REMOTE_MAPS in addition to the following counters: TOTAL_MAPS; DATA_LOCAL_MAPS; RACK_LOCAL_MAPS. A Map Task is considered a ""remote-map"" iff the input split returns a set of locations; but none is chosen to execute the map task.",Open,Unresolved,,Unassigned,Hong Tang,Tue; 28 Apr 2009 18:30:05 +0000,Tue; 22 Jul 2014 19:16:22 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-327
MAPREDUCE-328,Improvement,Major,,Cluster summary should have total tasks in the JT and pending tasks to run.,Cluster summary already shows the running maps and running reduces. It is useful to have total tasks from all initialized jobs and pending tasks from initialized jobs that still need to be run. Pending tasks can be derived from total tasks and running tasks.,Resolved,Incomplete,,Devaraj Das,Vinod Kumar Vavilapalli,Thu; 30 Oct 2008 12:36:32 +0000,Mon; 21 Jul 2014 16:40:51 +0000,Mon; 21 Jul 2014 16:40:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-328
MAPREDUCE-329,Improvement,Major,,eliminate parameters that must change with cluster size,"As far as possible; configurations should be independent of cluster size.  The cluster size is a parameter that the system knows and should thus be used to size things accordingly.  Currently we know that the following parameters must be adjusted to non-default values for large clusters:  	mapred.job.tracker.handler.count 	mapred.reduce.parallel.copies 	tasktracker.http.threads    We should attempt to make each of these either set to something proportional to cluster size or (harder) dynamically sized based on load.",Open,Unresolved,,Unassigned,Doug Cutting,Thu; 6 Sep 2007 20:29:12 +0000,Sat; 20 Jun 2009 07:51:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-329
MAPREDUCE-330,Improvement,Major,,Log information regarding changes to job in jobtracker,Some actions like changing the priority of a job; killing a job; killing a task may need to be tracked for admin purposes. It would be good to; at a minimum; log these at an INFO level in the JT logs.,Resolved,Fixed,,rahul k singh,Hemanth Yamijala,Mon; 16 Mar 2009 05:52:27 +0000,Mon; 21 Jul 2014 21:54:49 +0000,Mon; 21 Jul 2014 21:54:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-330
MAPREDUCE-331,Improvement,Major,,Make jobtracker resilient to memory issues,"JobTracker is vulnerable to memory errors attacks. Few of them are as follows  	JOB INIT : lot of users submitting large jobs. As every jobs is expanded; the jobtracker's memory can be completely used up 	JSP : jsp (jobhistory.jsp etc) can also interfere with jobtracker's memory and hence the jobtracker should be protected against such attacks 	OLD JOBS : lot of completed jobs can garble up jobtracker's memory and hence should be periodically cleaned up. HADOOP-4766 addresses this.    The main intention of this issue is to track various jira's that help jobtracker battle memory attacks. Jobtracker should always be up and available.",Resolved,Fixed,,Unassigned,Amar Kamat,Fri; 2 Jan 2009 08:28:56 +0000,Mon; 21 Jul 2014 17:53:57 +0000,Mon; 21 Jul 2014 17:53:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-331
MAPREDUCE-332,Improvement,Major,,When assigning tasks to trackers; the job tracker should try to balance the number of tasks among the available trackers,I encounter a number of situations like this: A job tracker has 200 task trackers; each with 2 mapper slots and reducer slots. When a job with 200 or fewer reducers was submitted to the job tracker; one normally each task tracker will run one reducer. Unfortunately; it seems that only  about 1 3 have 2 reducers!,Resolved,Incomplete,,Unassigned,Runping Qi,Thu; 26 Jun 2008 22:16:13 +0000,Fri; 18 Jul 2014 17:29:07 +0000,Fri; 18 Jul 2014 17:29:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-332
MAPREDUCE-333,Improvement,Major,,Implement a memory-to-memory sort in the map task,The motivation is similar to HADOOP-5831...  Currently we collect map-outputs in the sort buffer (io.sort.mb) which we eventually sort and spill to disk. For latency-sensitive applications with sufficient memory; e.g. terasort; we could do better by doing a memory-to-memory sort followed by a final memory-to-disk merge.,Open,Unresolved,,Unassigned,Arun C Murthy,Tue; 19 May 2009 07:18:41 +0000,Sat; 20 Jun 2009 07:51:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-333
MAPREDUCE-334,Improvement,Major,,Change mapred.lib code to use new api,Deprecate the code in org.apache.hadoop.mapred.lib. Copy the code to org.apache.hadoop.mapreduce.lib and Change it to use new api.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 14 Apr 2009 09:53:34 +0000,Thu; 2 May 2013 02:29:48 +0000,Thu; 7 Jan 2010 04:29:39 +0000,,,,,HADOOP-1230,https://issues.apache.org/jira/browse/MAPREDUCE-334
MAPREDUCE-335,Improvement,Major,,Reducer inputs should be spilled to HDFS rather than local disk.,Currently; both map outputs and reduce inputs are stored on local disks of tasktrackers. (Un) Availability of local disk space for intermediate data is seen as a major factor in job failures.   The suggested solution is to store these intermediate data on HDFS (maybe with replication factor of 1). However; the main blocker issue with that solution is that lots of temporary names (proportional to total number of maps); can overwhelm the namenode; especially since the map outputs are typically small (most produce one block output).  Also; as we see in many applications; the map outputs can be estimated more accurately; and thus users can plan accordingly; based on available local disk space.  However; the reduce input sizes can vary a lot; especially for skewed data (or because of bad partitioning.)  So; I suggest that it makes more sense to keep map outputs on local disks; but the reduce inputs (when spilled from reducer memory) should go to HDFS.  Adding a configuration variable to indicate the filesystem to be used for reduce-side spills would let us experiment and compare the efficiency of this new scheme.,Open,Unresolved,,Unassigned,Milind Bhandarkar,Fri; 20 Feb 2009 18:14:33 +0000,Sat; 20 Jun 2009 07:51:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-335
MAPREDUCE-336,Improvement,Major,,The logging level of the tasks should be configurable by the job,It would be nice to be able to configure the logging level of the Task JVM's separately from the server JVM's. Reducing logging substantially increases performance and reduces the consumption of local disk on the task trackers.,Closed,Fixed,,Arun C Murthy,Owen O'Malley,Fri; 8 May 2009 07:23:00 +0000,Tue; 23 Jul 2013 06:46:55 +0000,Sat; 22 Aug 2009 00:04:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-336
MAPREDUCE-337,Improvement,Major,,the counter for map input locality should be associated with a map attempt,Instead of being a job counter for map locality that is on the job; each map attempt should be 0 or 1 for whether it was data-local or not.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Mon; 8 Oct 2007 21:42:50 +0000,Sat; 20 Jun 2009 07:51:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-337
MAPREDUCE-338,Improvement,Major,,Need more complete API of JobClient class,We need a programmatic way to find out the information about a map ReduceTaskReports(String jobid) 3. getStartTime() 4. getJobStatus(String jobid); 5. getJobProfile(String jobid);,Resolved,Fixed,,Unassigned,Runping Qi,Fri; 24 Aug 2007 21:20:02 +0000,Thu; 17 Jul 2014 17:41:26 +0000,Thu; 17 Jul 2014 17:41:26 +0000,,,,,HADOOP-1210,https://issues.apache.org/jira/browse/MAPREDUCE-338
MAPREDUCE-339,Improvement,Major,,JobTracker should give preference to failed tasks over virgin tasks so as to terminate the job ASAP if it is eventually going to fail. ,Case in point... I have 1585 maps and 160 slots (40 nodes). The job is such that all maps fail within 2-3 minutes. The job takes forever to realise that the job is bad. It took 2526 failures for it to reach 4 failed attempts for a task.   As I understand; currently the JT prefers a failed task if and only if a task tracker with a split replica for that map came asking for a task. In fact there may not be a single TT at all in the mapred cluster which has a replica for the splits used in this job (pre-0.20). This delays the job failure by a lot and hence degrades cluster utilization as a whole. If i'm on a shared cluster with many jobs waiting on it to fail; it's bad.   The JT should prefer a failed task a lot earlier than waiting for a data local TT to come around asking.,Open,Unresolved,,Devaraj Das,Gautam Kowshik,Mon; 1 Jun 2009 12:52:55 +0000,Wed; 21 Jul 2010 06:49:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-339
MAPREDUCE-340,Improvement,Major,,TextInputFormat should not create input splits for 0 byte files,As part of HADOOP-2027; I discovered that we create input splits for 0 byte files. (In theory this is for both sequence file and text files; but in practice sequence files can't be 0 bytes.) I think 0 byte files can and should be dropped; since they have no input to process.,Open,Unresolved,,Unassigned,Owen O'Malley,Thu; 6 Mar 2008 17:30:32 +0000,Thu; 17 Jul 2014 21:28:35 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-340
MAPREDUCE-341,Improvement,Major,,Modify org.apache.hadoop.mapred.jobcontrol.Job class to allow actions before status changes,"I would like some of my jobs to do other activities after the map reduce is done; but before any dependent jobs would start.  I think this could be accomplished in a many ways; here are three that I could think of:  A) mark the checkRunningState method as protected; so that a subclass could override it and only set the status to SUCCESS after the extra activity is done.  B) Add a handler event mechanism that triggers events before state changes. Handlers of those events could ""cancel"" the state change if they needed to (ie: if something failed)  C) Provide a protected template method that is executed before each state change that subclasses can override.",Open,Unresolved,,Unassigned,Jason Grey,Thu; 29 Nov 2007 15:05:56 +0000,Sat; 20 Jun 2009 07:51:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-341
MAPREDUCE-342,Improvement,Major,,Create a public scheduler API,The work in HADOOP-3412 provided an API to support pluggable schedulers. However implementations have to be in the org.apache.hadoop.mapred package; which is undesirable. The goal of this issue is to create a public API for scheduler writers to code against.,Resolved,Fixed,,Unassigned,Tom White,Thu; 24 Jul 2008 15:08:56 +0000,Fri; 18 Jul 2014 18:18:17 +0000,Fri; 18 Jul 2014 18:18:17 +0000,,,,,MAPREDUCE-2826;HADOOP-1230,https://issues.apache.org/jira/browse/MAPREDUCE-342
MAPREDUCE-343,Improvement,Major,,Failed jobs should report the reason of failure on the web ui,From user's perspective it is difficult to detect why the job failed . Users might need to go through the jobtracker logs or task attempts list to see why the job failed. It would be good to show the reason on the job web ui. Something like,Resolved,Fixed,,Unassigned,Amar Kamat,Wed; 6 Aug 2008 11:53:03 +0000,Fri; 18 Jul 2014 20:32:05 +0000,Fri; 18 Jul 2014 20:32:05 +0000,,,,,MAPREDUCE-1049,https://issues.apache.org/jira/browse/MAPREDUCE-343
MAPREDUCE-344,Improvement,Major,,Remove dead code block in  JobInProgress.completedTask,Since the taskCommitThread ensures that one and only one task of a given TIP is marked as SUCCEEDED; we don't need the code block in JobInProgress.completedTask which checks if the TIP is complete and then just marks the task as complete:,Resolved,Fixed,,Unassigned,Arun C Murthy,Tue; 29 Jan 2008 04:41:56 +0000,Thu; 17 Jul 2014 20:02:42 +0000,Thu; 17 Jul 2014 20:02:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-344
MAPREDUCE-345,Improvement,Major,,Investigate whether the array in the JobInProgress that holds TIP references can be removed,The array; in JobInProgress; that holds the references to TIPs is required now only to serve the clients (web UI via JSPs and JobClient APIs; that traverse the array and create the output). The array can now be removed since HADOOP-2119 introduces some datastructures for running non-running TIPs and we could probably add some more if required (e.g.; for completed TIPs). That way; we will gain when we have large jobs (many tasks) in the sense that we don't have to go through the big array every time a client request is made. We could instead iterate over the datastructures. Also; we should do these traversals without locking the JobTracker to avoid cases where long traversal leads to loss of heartbeats; etc. Some staleness at the client side (in favor of improving the JobTracker's performance) is probably okay.,Resolved,Incomplete,,Unassigned,Devaraj Das,Fri; 28 Mar 2008 11:11:30 +0000,Thu; 17 Jul 2014 21:49:36 +0000,Thu; 17 Jul 2014 21:49:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-345
MAPREDUCE-346,Improvement,Major,,Report Map-Reduce Framework Counters in pipeline order,Currently there is no order in which counters are printed. It would be more user friendly if Map-Reduce Framework counters are reported in the pipeline order.,Resolved,Fixed,,Sharad Agarwal,Sharad Agarwal,Wed; 11 Feb 2009 06:21:42 +0000,Mon; 21 Jul 2014 19:50:40 +0000,Mon; 21 Jul 2014 19:50:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-346
MAPREDUCE-347,Improvement,Major,,Improve the way error messages are displayed from jobclient,Today if a job is submitted with an already existing output directory then an exception trace is displayed on the client. A simple message like 'Error running job as output path already exists' might suffice.,Open,Unresolved,,Ruth Wisniewski,Peeyush Bishnoi,Mon; 30 Mar 2009 08:24:18 +0000,Sat; 23 May 2015 18:26:56 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-347
MAPREDUCE-348,Improvement,Major,,A proposal to merge common functionality of various Schedulers,There are at least 3 Schedulers in Hadoop today: Default; Capacity; and Fairshare. Over time; we're seeing a lot of functionality common to all three. Many bug fixes; improvements to existing functionality; and new functionality are applicable to all three schedulers. This trend seems to be getting stronger; as we notice similar problems; solutions; and ideas. This is a proposal to detect and consolidate such common functionality.,Resolved,Won't Fix,,Unassigned,Vivek Ratan,Mon; 9 Feb 2009 12:23:31 +0000,Mon; 21 Jul 2014 19:48:40 +0000,Mon; 21 Jul 2014 19:48:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-348
MAPREDUCE-349,Improvement,Major,,Combine TaskTracker information into single class in JobTracker,Currently tracker related information is spanned thru multiple datastructures. eg. trackerToTaskMap; trackerToMarkedTasksMap; trackerToHeartbeatResponseMap etc. These are hard to maintain. It would be efficient (as there won't be multiple searches in TreeSet) and much more manageable code if we create a single class say TrackerInfo; and just have one map of trackerId to TrackerInfo,Open,Unresolved,,Unassigned,Sharad Agarwal,Thu; 4 Dec 2008 08:41:55 +0000,Sat; 20 Jun 2009 07:51:10 +0000,,,,,,MAPREDUCE-351,https://issues.apache.org/jira/browse/MAPREDUCE-349
MAPREDUCE-350,Improvement,Major,,Generalize the SequenceFileInputFilter to apply to any InputFormat,I'd like to generalize the SequenceFileInputForm will be addressed in a different issue.,Resolved,Invalid,,Enis Soztutar,Owen O'Malley,Fri; 11 Aug 2006 17:59:50 +0000,Mon; 16 Jan 2012 09:45:28 +0000,Mon; 16 Jan 2012 09:45:27 +0000,,,,HADOOP-3048,,https://issues.apache.org/jira/browse/MAPREDUCE-350
MAPREDUCE-351,Improvement,Major,,Replace Strings with Objects for representing the slaves in the JobTracker.,Currently the JobTracker stores the trackername as a String. JobTracker relies on a hack (string parsing) to deduce the hostname trackers are represented by an ID and the ID provides certain APIs for getting this information. Something like,Open,Unresolved,,Unassigned,Amar Kamat,Sat; 3 May 2008 13:40:23 +0000,Sat; 20 Jun 2009 07:51:11 +0000,,,,,,MAPREDUCE-349,https://issues.apache.org/jira/browse/MAPREDUCE-351
MAPREDUCE-352,Improvement,Major,,Avoid creating JobInProgress objects before Access checks and Queues checks are done in JobTracker submitJob ,In JobTracker submitJob ; JobInProgress instance gets created . after this checks are done for access and queue state. In event of checks failed . There isn't any use for these JIP objects ; hence in event of failure only reason these objects were created was to get conf data and be deleted.  We need to fetch the information required to only do the checks instead of creating a JobInProgress object,Resolved,Incomplete,,Unassigned,rahul k singh,Fri; 5 Jun 2009 04:54:25 +0000,Tue; 22 Jul 2014 20:29:45 +0000,Tue; 22 Jul 2014 20:29:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-352
MAPREDUCE-353,Improvement,Major,,Allow shuffle read and connection timeouts to be configurable,It would be good for latency-sensitive applications to tune the shuffle read connection timeouts... in fact this made a huge difference to terasort since we were seeing individual shuffles stuck for upwards of 60s and had to have a very small read timeout.,Closed,Fixed,,Ravi Gummadi,Arun C Murthy,Fri; 8 May 2009 09:19:48 +0000,Tue; 24 Aug 2010 21:13:27 +0000,Thu; 16 Jul 2009 09:45:54 +0000,,0.21.0,,,MAPREDUCE-1249,https://issues.apache.org/jira/browse/MAPREDUCE-353
MAPREDUCE-354,Improvement,Major,,the map output servlet should only locate the index if it isn't in the cache,Currently; the map output servlet locates the cache file using the local dir allocator; before it determines whether the information is in the cache. It would avoid a lot of filesystem lookups if it waited.,Resolved,Incomplete,,Owen O'Malley,Owen O'Malley,Wed; 4 Feb 2009 21:19:32 +0000,Mon; 21 Jul 2014 19:41:42 +0000,Mon; 21 Jul 2014 19:41:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-354
MAPREDUCE-355,Sub-task,Major,,Change org.apache.hadoop.mapred.join to use new api,To change org.apache.hadoop.examples.Join to use new api; we need to change org.apache.hadoop.mapred.join to use new api. So; Deprecate the code in org.apache.hadoop.mapred.join.  Copy the code to org.apache.hadoop.mapreduce.lib.join and Change it to use new api.  Thoughts ?,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 14 Apr 2009 10:22:43 +0000,Tue; 24 Aug 2010 21:13:30 +0000,Mon; 24 Aug 2009 06:20:19 +0000,,,,HADOOP-6103,,https://issues.apache.org/jira/browse/MAPREDUCE-355
MAPREDUCE-356,Sub-task,Major,,Change org.apache.hadoop.examples.SleepJob to use new api.,Change org.apache.hadoop.examples.SleepJob to use new api.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 15 Apr 2009 10:14:26 +0000,Sat; 20 Jun 2009 07:51:11 +0000,Tue; 28 Apr 2009 10:56:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-356
MAPREDUCE-357,Sub-task,Major,,Change org.apache.hadoop.examples.RandomWriter and  org.apache.hadoop.examples.RandomTextWriter to use new mapreduce api.,nan,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 15 Apr 2009 11:24:15 +0000,Sat; 20 Jun 2009 07:51:11 +0000,Mon; 20 Apr 2009 12:28:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-357
MAPREDUCE-358,Sub-task,Major,,Change org.apache.hadoop.examples. AggregateWordCount and  org.apache.hadoop.examples.AggregateWordHistogram to use new mapreduce api.,Change org.apache.hadoop.examples.AggregateWordCount and  org.apache.hadoop.examples.AggregateWordHistogram to use new mapreduce api.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 16 Apr 2009 05:19:06 +0000,Tue; 24 Aug 2010 21:13:30 +0000,Fri; 26 Jun 2009 06:44:18 +0000,,,,MAPREDUCE-368,,https://issues.apache.org/jira/browse/MAPREDUCE-358
MAPREDUCE-359,Sub-task,Major,,Change org.apache.hadoop.examples.DBCountPageView to use new mapreduce api.,Change org.apache.hadoop.examples.DBCountPageView to use new mapreduce api.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 16 Apr 2009 05:32:49 +0000,Sat; 20 Jun 2009 07:51:11 +0000,Fri; 12 Jun 2009 05:16:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-359
MAPREDUCE-360,Sub-task,Major,,Change org.apache.hadoop.examples.dancing to use new mapreduce api,nan,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Apr 2009 11:23:07 +0000,Sat; 20 Jun 2009 07:51:11 +0000,Tue; 9 Jun 2009 05:18:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-360
MAPREDUCE-361,Sub-task,Major,,Change org.apache.hadoop.examples.terasort to use new mapreduce api,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Apr 2009 11:23:51 +0000,Tue; 24 Aug 2010 21:13:31 +0000,Mon; 25 Jan 2010 08:47:59 +0000,,,,MAPREDUCE-639,,https://issues.apache.org/jira/browse/MAPREDUCE-361
MAPREDUCE-362,Sub-task,Major,,Change org.apache.hadoop.examples.Sort to use new api.,nan,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Apr 2009 11:25:04 +0000,Sat; 20 Jun 2009 07:51:11 +0000,Mon; 1 Jun 2009 12:02:37 +0000,,,,MAPREDUCE-366;HADOOP-5710,,https://issues.apache.org/jira/browse/MAPREDUCE-362
MAPREDUCE-363,Sub-task,Major,,Change org.apache.hadoop.examples.Grep to use new mapreduce api.,nan,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Apr 2009 11:26:07 +0000,Sat; 20 Jun 2009 07:51:11 +0000,Tue; 21 Apr 2009 07:35:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-363
MAPREDUCE-364,Sub-task,Major,,Change org.apache.hadoop.examples.MultiFileWordCount to use new mapreduce api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Apr 2009 11:27:04 +0000,Tue; 24 Aug 2010 21:13:32 +0000,Fri; 29 May 2009 12:01:12 +0000,,,,MAPREDUCE-367;HADOOP-5759,MAPREDUCE-1112,https://issues.apache.org/jira/browse/MAPREDUCE-364
MAPREDUCE-365,Sub-task,Major,,Change org.apache.hadoop.examples.PiEstimator to use new mapreduce api.,nan,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Apr 2009 11:27:49 +0000,Sat; 20 Jun 2009 07:51:12 +0000,Tue; 28 Apr 2009 11:29:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-365
MAPREDUCE-366,Sub-task,Major,,Change org.apache.hadoop.mapred.lib.TotalOrderPartitioner to use new api,Change org.apache.hadoop.mapred.lib.TotalOrderPartitioner to use new api,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 14 Apr 2009 10:27:18 +0000,Sun; 6 Jun 2010 01:51:34 +0000,Mon; 4 May 2009 04:18:47 +0000,,,,MAPREDUCE-362,MAPREDUCE-1820,https://issues.apache.org/jira/browse/MAPREDUCE-366
MAPREDUCE-367,Sub-task,Major,,Change org.apache.hadoop.mapred.lib. CombineFileInputFormat to use new api,Change org.apache.hadoop.mapred.lib. CombineFileInputFormat to use new api,Resolved,Duplicate,HADOOP-5698,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 15 Apr 2009 04:14:47 +0000,Sat; 20 Jun 2009 07:51:12 +0000,Wed; 29 Apr 2009 10:25:25 +0000,,,,MAPREDUCE-364;MAPREDUCE-271,,https://issues.apache.org/jira/browse/MAPREDUCE-367
MAPREDUCE-368,Sub-task,Major,,Change org.apache.hadoop.mapred.jobcontrol to use new api,nan,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 29 May 2009 03:35:44 +0000,Fri; 12 Feb 2010 08:22:56 +0000,Mon; 15 Jun 2009 06:16:43 +0000,,0.21.0,,MAPREDUCE-358,,https://issues.apache.org/jira/browse/MAPREDUCE-368
MAPREDUCE-369,Sub-task,Major,,Change org.apache.hadoop.mapred.lib.MultipleInputs to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:43:45 +0000,Tue; 24 Aug 2010 21:13:32 +0000,Wed; 29 Jul 2009 04:04:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-369
MAPREDUCE-370,Sub-task,Major,,Change org.apache.hadoop.mapred.lib.MultipleOutputs to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:45:06 +0000,Tue; 24 Aug 2010 21:13:33 +0000,Sat; 5 Sep 2009 01:06:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-370
MAPREDUCE-371,Sub-task,Major,,Change org.apache.hadoop.mapred.lib.KeyFieldBasedComparator and org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner to use new api,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:46:46 +0000,Tue; 24 Aug 2010 21:13:33 +0000,Thu; 9 Jul 2009 07:54:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-371
MAPREDUCE-372,Sub-task,Major,,Change org.apache.hadoop.mapred.lib.ChainMapper/Reducer to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:48:09 +0000,Tue; 24 Aug 2010 21:13:35 +0000,Thu; 7 Jan 2010 04:11:04 +0000,,,,MAPREDUCE-954,,https://issues.apache.org/jira/browse/MAPREDUCE-372
MAPREDUCE-373,Sub-task,Major,,Change org.apache.hadoop.mapred.lib. FieldSelectionMapReduce to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:49:48 +0000,Tue; 24 Aug 2010 21:13:37 +0000,Wed; 29 Jul 2009 04:39:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-373
MAPREDUCE-374,Sub-task,Major,,Change org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat/MultipleTextOutputFormat to use new api.,nan,Resolved,Duplicate,MAPREDUCE-370,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:55:25 +0000,Mon; 3 Aug 2009 07:38:39 +0000,Mon; 3 Aug 2009 07:38:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-374
MAPREDUCE-375,Sub-task,Major,, Change org.apache.hadoop.mapred.lib.NLineInputFormat and org.apache.hadoop.mapred.MapFileOutputFormat to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 05:30:17 +0000,Tue; 24 Aug 2010 21:13:38 +0000,Fri; 7 Aug 2009 11:55:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-375
MAPREDUCE-376,Wish,Major,,Add serialization for Thrift,Thrift (http: hadoop-serializer-v2.tar.gz),Resolved,Won't Fix,,Unassigned,Tom White,Fri; 18 Jul 2008 10:52:42 +0000,Fri; 18 Jul 2014 18:07:55 +0000,Fri; 18 Jul 2014 18:07:54 +0000,,,,HIVE-24,HADOOP-4192;MAPREDUCE-447;HADOOP-4203;HADOOP-10860,https://issues.apache.org/jira/browse/MAPREDUCE-376
HADOOP-10860,Wish,Major,,Add serialization for Protocol Buffers,Protocol Buffers (http: ) are a way of encoding data in a compact binary format. This issue is to write a ProtocolBuffersSerialization to support using Protocol Buffers types in MapReduce programs; including an example program. This should probably go into contrib.,Open,Unresolved,,Unassigned,Tom White,Fri; 18 Jul 2008 11:01:17 +0000,Fri; 18 Jul 2014 18:12:59 +0000,,,,,,MAPREDUCE-376,https://issues.apache.org/jira/browse/HADOOP-10860
MAPREDUCE-378,Test,Major,,Large-scale reliability tests,The fact that we do not have any large-scale reliability tests bothers me. I'll be first to admit that it isn't the easiest of tasks; but I'd like to start a discussion around this... especially given that the code-base is growing to an extent that interactions due to small changes are very hard to predict.  One of the simple scripts I run for every patch I work on does something very simple: run sort500 (or greater); then it randomly picks n tasktrackers from ${HADOOP_CONF_DIR} slaves and then kills them; a similar script one kills and restarts the tasktrackers.   This helps in checking a fair number of reliability stories: lost tasktrackers; task-failures etc. Clearly this isn't good enough to cover everything; but a start.  Lets discuss - What do we do for HDFS? We need more for Map-Reduce!,Open,Unresolved,,Devaraj Das,Arun C Murthy,Fri; 21 Dec 2007 21:01:21 +0000,Sat; 20 Jun 2009 07:51:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-378
MAPREDUCE-379,Test,Major,,Implement a Map-Reduce application which can be used to reliably launch speculative tasks,It would be very useful to have a reliable test case to help launch speculative tasks (maps and reduces to ensure that the speculative tasks are launched in a reliable and repeatable manner.  Thoughts?,Open,Unresolved,,Unassigned,Arun C Murthy,Fri; 16 Nov 2007 07:37:23 +0000,Sun; 3 Nov 2013 03:11:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-379
MAPREDUCE-380,Test,Major,,The test TestMiniMRWithDFS.checkTaskDirectories is checking for task directories incorrectly,The check for task directories in TestMiniMRWithDFS.checkTaskDirectories seems incorrect. The following code:   in the test case seems to assume that every configured task tracker has the task tracker directory TaskTracker.SUBDIR created. However; this directory is only created if any task is assigned to the task tracker. As there is no real control over which task trackers will actually be assigned tasks; it seems an incorrect check.,Open,Unresolved,,Unassigned,Hemanth Yamijala,Tue; 14 Oct 2008 07:07:04 +0000,Sat; 20 Jun 2009 07:51:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-380
MAPREDUCE-381,Sub-task,Major,,Add framework hooks to get the running/completed/pending tasks for a given job. Add a way to query the list of currently active tasktrackers from the JobTracker.,Add framework hooks to get the IDs of running pending tasks for a given job. Add a way to query the list of currently active tasktrackers from the JobTracker. These are required to inject failures.,Closed,Fixed,,Devaraj Das,Devaraj Das,Tue; 9 Dec 2008 07:21:43 +0000,Sat; 20 Jun 2009 07:51:13 +0000,Fri; 12 Dec 2008 05:56:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-381
MAPREDUCE-382,Sub-task,Major,,Create a test that would inject random failures for tasks in large jobs and would also inject TaskTracker failures,Create a test that would inject random failures for tasks in large jobs and would also inject TaskTracker failures,Closed,Fixed,,Devaraj Das,Devaraj Das,Wed; 24 Dec 2008 06:47:02 +0000,Sat; 20 Jun 2009 07:51:13 +0000,Thu; 22 Jan 2009 21:33:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-382
MAPREDUCE-383,Bug,Major,,pipes combiner does not reset properly after a spill,When using a pipes combiner; the variable numBytes is not reset to 0 in spillAll; effectively reducing the effect of running a combiner to the first spill.,Resolved,Fixed,,Christian Kunz,Christian Kunz,Wed; 17 Jun 2009 17:53:34 +0000,Fri; 28 Aug 2009 07:28:24 +0000,Mon; 27 Jul 2009 08:43:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-383
MAPREDUCE-384,Bug,Major,pipes,Exception thrown from pipes Map task is not handled properly,In Pipes environment; when map task throws an exception it is not killed immediately. But the tracker is waiting for 603 seconds (10 mins) for the report and then killing the task.   When I threw exception from word count sample program the maptask exits after 603 seconds showing the following on console:   INFO mapred.JobClient: Task Id : task_200709141017_0002_m_000001_1; Status : FAILED task_200709141017_0002_m_000001_1: terminate called after throwing an instance of 'std::exception' task_200709141017_0002_m_000001_1:   what():  St9exception  And the Job UI shows: Task task_200709141017_0002_m_000001_1 failed to report status for 603 seconds. Killing!  Thus; each map task is taking  10 mins for exiting and  is tried 4 times.,Resolved,Unresolved,,Unassigned,Amareshwari Sriramadasu,Fri; 14 Sep 2007 05:57:41 +0000,Fri; 6 Nov 2015 01:22:02 +0000,Fri; 6 Nov 2015 01:22:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-384
MAPREDUCE-385,Bug,Major,,pipes does not allow jobconf values containing commas,Currently hadoop pipes does not allow a -jobconf key=value;key=value... commandline parameter with one or more commas in one of the values of the key-value pairs.  One use case is key=mapred.join.expr; where the value is required to have commas. And it is not always convenient to add this to a configuration file. Submitter. could easily be changed to check for backslash in front of a comma before using it as a delimiter.,Resolved,Won't Fix,,Christian Kunz,Christian Kunz,Wed; 10 Jun 2009 01:23:43 +0000,Tue; 22 Jul 2014 21:04:31 +0000,Tue; 22 Jul 2014 21:04:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-385
MAPREDUCE-386,Bug,Major,,The combiner in pipes is closed before the last values are passed in.,Currently the last spill is sent to the combiner after the close method is called.,Resolved,Fixed,,Owen O'Malley,Owen O'Malley,Fri; 7 Dec 2007 23:47:31 +0000,Thu; 17 Jul 2014 19:03:38 +0000,Thu; 17 Jul 2014 19:03:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-386
MAPREDUCE-387,Bug,Major,,Hadoop Pipes Submitter assumes that presence of a Java InputFormat implies a Java RecordReader,The Submitter's command line parsing makes this assumption; which might not be true always...,Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 14 Aug 2008 20:18:34 +0000,Fri; 18 Jul 2014 20:55:21 +0000,Fri; 18 Jul 2014 20:55:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-387
MAPREDUCE-388,Bug,Major,,pipes combiner has a large memory footprint,Pipes combiner implementation can have a huge memory overhead compared to the spill size. How much; depends on the record size. E.g.; an application asks for 2GB memory when io.sort.mb=500; key is 16 bytes; and value is 4 bytes.,Resolved,Incomplete,,Unassigned,Christian Kunz,Thu; 18 Jun 2009 20:00:34 +0000,Tue; 22 Jul 2014 21:48:05 +0000,Tue; 22 Jul 2014 21:48:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-388
MAPREDUCE-389,Bug,Major,,pipes should wait for the process to exit and fail if the return code is bad,nan,Resolved,Fixed,,Unassigned,Owen O'Malley,Fri; 4 Apr 2008 22:14:59 +0000,Sat; 19 Jul 2014 19:03:30 +0000,Sat; 19 Jul 2014 19:03:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-389
MAPREDUCE-390,Bug,Minor,,Corner case exists in detecting Java process deaths that might lead to orphan pipes processes lying around in memory,In HADOOP-2092; the child pipes process periodically pings the parent Java process to find out whether it is alive. The ping cycle is 5 seconds. Consider the following scenario: 1) The Java task dies at the beginning of the ping cycle 2) A new Java task starts and binds to the same port as the earlier Java task's port 3) The pipes process wakes up and does a ping - it will still be successful since the port number hasn't changed This will lead to orphan processes lying around in memory. The detection of parent process deaths can be made more reliable at least on Unix'ish platforms by checking whether the parent process ID is 1; and if so exit. This will take care of the most common platform that hadoop is run on. For non-unix platforms; the existing ping mechanism can be retained. Thoughts?,Resolved,Fixed,HADOOP-2721,Unassigned,Devaraj Das,Mon; 28 Jan 2008 06:47:59 +0000,Thu; 17 Jul 2014 20:02:04 +0000,Thu; 17 Jul 2014 20:02:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-390
MAPREDUCE-391,New Feature,Major,,add a batch option to pipes launcher,Users who are launching pipes jobs in a script would like to have a non-blocking batch option on the API.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Fri; 7 Sep 2007 21:46:49 +0000,Sat; 20 Jun 2009 07:54:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-391
MAPREDUCE-392,Improvement,Major,contrib/streaming;pipes,streaming and pipes should reuse jvm's by default,With HADOOP-249; tasks can now reuse JVMs.  Pipes and streaming run little user code in their JVMs and should generally benefit from JVM reuse.  Thus I propose we change the default for these to be JVM reuse.,Resolved,Won't Fix,,Unassigned,Doug Cutting,Thu; 6 Nov 2008 16:22:19 +0000,Mon; 21 Jul 2014 16:55:13 +0000,Mon; 21 Jul 2014 16:55:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-392
MAPREDUCE-393,Improvement,Major,,Two small improvements to pipes,"Working with the ..mapred.pipes class a bit today; I found one bug and one possible interface improvement:   	Application. provides a ""submitJob ()"" method; yet it acts like it's a runJob method (and also invokes mapred.JobClient.runClient ())  it should provide two interface methods; one runJob () and one submitJob (); who act just like the JobClient counterparts.    Here is the small patch that implements both changes; based on the 0.17.1 release source  just in case anyone cares for this minor improvement.",Resolved,Incomplete,,Leon Mergen,Leon Mergen,Sat; 9 Aug 2008 20:14:27 +0000,Fri; 18 Jul 2014 20:52:38 +0000,Fri; 18 Jul 2014 20:52:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-393
MAPREDUCE-394,Improvement,Major,,Hadoop Pipes do not load custom InputFormats at appropriate time; rendering them useless in certain scenarios,There's a patch provided below. It was created on the 0.17.0 version; but with a little tweaking can be applied to the 0.18.0 as well. It fixes a timing bug; whereas a custom inputformat was loaded from the jar file; but the inputformat was being processed much earlier in time; resulting in a class not found exception.,Resolved,Fixed,,Unassigned,Mateusz Berezecki,Mon; 25 Aug 2008 19:46:36 +0000,Fri; 18 Jul 2014 22:28:53 +0000,Fri; 18 Jul 2014 22:28:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-394
MAPREDUCE-395,Improvement,Minor,,Dependency cycle: Submitter and TaskTracker,there's a cycle between org.apache.hadoop.mapred.pipes org.apache.hadoop.mapred; breaking the dependency between Submitter and TaskTracker fixes it.,Resolved,Incomplete,,Bill de hOra,Bill de hOra,Sun; 6 Jul 2008 08:40:08 +0000,Fri; 18 Jul 2014 17:40:49 +0000,Fri; 18 Jul 2014 17:40:48 +0000,,,,,HADOOP-3750,https://issues.apache.org/jira/browse/MAPREDUCE-395
MAPREDUCE-396,Improvement,Major,,We should have a C++ implementation of FileInputSplit,It would be good to have library code the deserializes the FileInputSplit so that C++ code using a standard FileInputFormat can understand the InputSplits.,Open,Unresolved,,Unassigned,Owen O'Malley,Fri; 17 Oct 2008 18:04:36 +0000,Sat; 20 Jun 2009 07:54:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-396
MAPREDUCE-397,Bug,Trivial,,In JobInProgress; failed TIP should be added back to the non-running queue only if the tip has not failed.,In case of a task failure; the corresponding TIP is added back to the non-running list via failMap() failReduce() api. This reentry should be done only for TIPs that have not failed. Reentry is useless for failed TIPs.,Resolved,Not A Problem,,Harsh J,Amar Kamat,Fri; 11 Apr 2008 12:38:58 +0000,Sun; 18 Dec 2011 11:31:08 +0000,Sun; 18 Dec 2011 11:31:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-397
MAPREDUCE-398,Bug,Minor,,Task process exit with nonzero status of 134.        ,During fetcher2 stage; i got these errors on all datanodes.   424)  When fetching more than 1000000 urls; these errors occur.,Resolved,Cannot Reproduce,,Unassigned,sha feng,Wed; 31 Dec 2008 06:40:39 +0000,Mon; 21 Jul 2014 17:50:36 +0000,Mon; 21 Jul 2014 17:50:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-398
MAPREDUCE-399,Bug,Minor,,Duplicate destroy of process trees in TaskMemoryManager.,TaskMemoryManager currently works only on Linux and terminates tasks that transgress memory-limits by first calling TaskTracker.purgeTask() and then explicitly destroying the process tree to be sure that the whole process tree is cleaned up. After HADOOP-2721; we don't need this explicit process-tree destroying as the usual code-path of killing tasks itself takes care of cleaning up the whole process-trees.,Resolved,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 6 Mar 2009 11:55:34 +0000,Mon; 21 Jul 2014 21:34:13 +0000,Mon; 21 Jul 2014 21:34:13 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-399
MAPREDUCE-400,Bug,Minor,,WebUI shows 100% Map Complete even though some maps are still running,I have a job that has 50K maps. The web UI shows maps as 100% complete even though the last few maps (20 or so) are still running.,Resolved,Incomplete,,Jothi Padmanabhan,Jothi Padmanabhan,Wed; 31 Dec 2008 12:38:14 +0000,Mon; 21 Jul 2014 17:50:57 +0000,Mon; 21 Jul 2014 17:50:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-400
MAPREDUCE-401,Bug,Minor,,du fails on Ubuntu in TestJobHistory,TestJobHistory.testJobHistoryUserLogLocation is failing; and there is an error in the log related to du failing in the mini MR cluster,Resolved,Fixed,,Unassigned,Steve Loughran,Wed; 20 May 2009 15:00:17 +0000,Tue; 22 Jul 2014 19:45:30 +0000,Tue; 22 Jul 2014 19:45:30 +0000,,,,,HDFS-197,https://issues.apache.org/jira/browse/MAPREDUCE-401
MAPREDUCE-402,Bug,Minor,,TaskTracker doesnt recheck job tracker version on reconnect,This isnt anything I have a test for encountered; just something I noticed when reviewing TaskTracker. 1. TaskTracker sets a justStarted flag to true when starting up 2. One way it uses this flag is to check job tracker versions -the version is only checked when justStarted==true; which is reset after the check. 3. If a JobTracker is unreachable; then the TaskTracker sleeps for 5 seconds and then continues  There is a risk; therefore; that if the job tracker goes down; a different version might come back up; and the Task Tracker will not notice until it makes an incompatible IPC call.  This is a pretty unlikely scenario; you've got to kill the job tracker and bring up a different versioned one in 5 seconds. And the consequence of IPC incompatiblity will be a lost task; regardless of whether this happens early or later in the process. I'm not sure it's worth fixing.,Resolved,Incomplete,,Unassigned,Steve Loughran,Thu; 31 Jul 2008 14:33:40 +0000,Fri; 18 Jul 2014 20:04:09 +0000,Fri; 18 Jul 2014 20:04:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-402
MAPREDUCE-403,Bug,Minor,,"ProcessTree can try and kill a ""null"" PID","Saw this in a test run; while trying to shut down a TaskTracker sf-startdaemon-debug   TerminatorThread WARN util.ProcessTree : Error executing shell command org.apache.hadoop.util.Shell$ExitCodeException: ERROR: garbage process ID ""-null"".",Resolved,Incomplete,,Unassigned,Steve Loughran,Thu; 7 May 2009 15:45:48 +0000,Tue; 22 Jul 2014 19:24:29 +0000,Tue; 22 Jul 2014 19:24:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-403
MAPREDUCE-404,Bug,Minor,,NPE in text.encode when writing an invalid(?) JobProfile,I see an NPE in one of my tests in Text.encode(String); further up the stack is  JobProfile.write(); which appears to write a null user,Resolved,Not A Problem,,Unassigned,Steve Loughran,Wed; 24 Sep 2008 14:35:00 +0000,Fri; 18 Jul 2014 23:45:48 +0000,Fri; 18 Jul 2014 23:45:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-404
MAPREDUCE-405,Bug,Minor,,ReduceTask logs show negative values,While running some tests I can see negative values in reducers log. Something like     Looking at the code it looks like this happens when a node which was temporarily down comes back (i.e becomes available). In such a case the node is still in the penalty box and also in the unique hosts structure.,Resolved,Fixed,,Unassigned,Amar Kamat,Mon; 15 Dec 2008 06:30:52 +0000,Mon; 21 Jul 2014 17:24:25 +0000,Mon; 21 Jul 2014 17:24:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-405
MAPREDUCE-406,Bug,Minor,,setting fs.default.name to an invalid URI format kills init thread in JobTracker,If you set fs.default.name in a JobConf object to something that causes  net.URI to throw an IllegalArgumentException; the job not only fails initalization; but kills the JobInitThread,Resolved,Fixed,,Unassigned,sam rash,Thu; 29 Jan 2009 02:25:39 +0000,Mon; 21 Jul 2014 19:22:54 +0000,Mon; 21 Jul 2014 19:22:54 +0000,,,,,HDFS-301;HADOOP-5687,https://issues.apache.org/jira/browse/MAPREDUCE-406
MAPREDUCE-407,Bug,Minor,,JobClient looking for classes for submitted job in the wrong place,JobClient does some checking of the job being submitted when it submits a jar file along with the job. The problem is that the JobClient pulls classes from the classpath rather than the submitted jar file. Because the jar file may contain newer (or older) versions of classes on the classpath this behavior leads to confusing errors when the job is run. It is also a pain to ensure that the jar file being submitted is on the classpath. Further; if the JobClient uses the submitted jar file rather than the classpath; missing classes from the jar file can be detected earlier.  This patch will cause the JobClient to load the classes for a job from the jar file rather than the classpath. Because of the class loading precedence rules in Java; if the class is on the system class path; it will be loaded from there rather than the submitted jar file; but now users need not (and should not) put job classfiles on the system classpath.  This patch also allows config files to be put in a configuration directory rather than on the classpath; which also eliminates some confusing behavior when there are duplicate instances of config files in different parts of the classpath.,Resolved,Invalid,,Owen O'Malley,Benjamin Reed,Thu; 15 Jun 2006 02:07:18 +0000,Mon; 16 Jan 2012 09:08:22 +0000,Mon; 16 Jan 2012 09:08:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-407
MAPREDUCE-408,Bug,Major,test,TestKillSubProcesses fails with assertion failure sometimes,org.apache.hadoop.mapred.TestKillSubProcesses.testJobKillFailAndSucceed fails sometimes with following error Message:    Stacktrace    one such failure at http: ,Closed,Fixed,,Ravi Gummadi,Amareshwari Sriramadasu,Mon; 15 Jun 2009 05:16:31 +0000,Tue; 24 Aug 2010 21:13:38 +0000,Tue; 4 Aug 2009 07:53:44 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-408
MAPREDUCE-409,Bug,Minor,,Reported percentage complete is different between web ui and command line,"Looking at my job status from the web ui and the command line yields different results.  Here is an example:  From the shell: bash$ bin jobdetails.jsp?jobid=job_0001 map() completion: 0.99955106 reduce() completion: 1.0  From the web UI: Kind	% Complete	Num Tasks	Pending	Running	Complete	Killed	Failures map	100.00%	79731	0	0	79731	0	169 reduce	99.86%	3510	0	1	3509	0	151",Open,Unresolved,,Unassigned,Nigel Daley,Mon; 5 Feb 2007 22:48:54 +0000,Sat; 20 Jun 2009 07:57:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-409
MAPREDUCE-410,Bug,Trivial,,JobTracker TaskInitialization failure on cygwin,"I wanted to test new release and have been trying to queue new job. But it didn't work.  This error is found in JobTracker's log.  ======================================== 2008-11-29 21:39:00;276 ERROR org.apache.hadoop.mapred.EagerTaskInitializationListener: Job initialization failed:  (working copy) @@ -95;6 +95;10 @@    private static final String SECONDARY_FILE_SUFFIX = "".recover"";    private static long jobHistoryBlockSize = 0;    private static String jobtrackerHostname; +    Make the pattern matching the job's history file        final Pattern historyFilePattern =           Pattern.compile(jobtrackerHostname + """" + ""0-9+"" + """"  ========================================  Hadoop Core patched this seems to work well.  Maybe my environment is wrong. But if this is bug; please fix.",Resolved,Cannot Reproduce,,Unassigned,Masahiko,Sat; 29 Nov 2008 18:29:01 +0000,Mon; 16 Mar 2015 19:54:41 +0000,Mon; 16 Mar 2015 19:54:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-410
MAPREDUCE-411,Bug,Trivial,,Inconsistent strings for job and queue related scheduling information in UI when the information is not available.,HADOOP-3930 added support for displaying queue related and job related scheduling information. When this information is not available; it is displayed as 'N A' in some cases and 'NA' in some cases. They should read the same for UI consistency.,Resolved,Fixed,,Ananth Vikram Bommireddipalli,Hemanth Yamijala,Mon; 16 Mar 2009 06:05:56 +0000,Mon; 21 Jul 2014 21:55:22 +0000,Mon; 21 Jul 2014 21:55:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-411
MAPREDUCE-412,Bug,Minor,,JobConf needs better javadoc,"The org.apache.hadoop.mapred.JobConf class needs better  oc #styleguide 	document the unchecked exceptions th does ""the files"" mean? if they are kept; where can they be found? 	deleteLocalFiles: undoubtedly a risky operation.  Need a good spec.  Is it a recursive delete? 	which configuration entries are mandatory (i.e. must be set before submitting the job)?",Resolved,Duplicate,HADOOP-2046,Unassigned,Nigel Daley,Tue; 21 Nov 2006 22:42:35 +0000,Mon; 16 Jan 2012 10:18:26 +0000,Mon; 16 Jan 2012 10:18:26 +0000,,,,,HADOOP-2046,https://issues.apache.org/jira/browse/MAPREDUCE-412
MAPREDUCE-413,Bug,Minor,,job.jar; job.xml not deleted when JobClient submitJob method  fail with exception ,If mapred.system.dir is set to  job.jar     r 10  19397  $ ls -l hadoop-examples.jar rw-rr-  1 _____ _____ 19397  hadoop-examples.jar,Resolved,Cannot Reproduce,,Unassigned,Koji Noguchi,Sat; 13 Jan 2007 01:46:43 +0000,Tue; 12 May 2015 09:47:15 +0000,Tue; 12 May 2015 09:47:15 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-413
MAPREDUCE-414,Bug,Minor,,Remove the methods controlling comparator options from the JobConf and make them static in the comparator class,It struck me after committing HADOOP-2302 that we should ideally have the getters setters for the comparator in the comparator class and not in the JobConf.,Open,Unresolved,,Devaraj Das,Devaraj Das,Thu; 7 Aug 2008 12:47:31 +0000,Sat; 20 Jun 2009 07:57:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-414
MAPREDUCE-415,Bug,Minor,job submission,JobControl Job does always has an unassigned name,"When creating and adding org.apache.hadoop.mapred.jobcontrol.Job(s) they don't use the names specified in their respective JobConf files.  Instead it's just hardcoded to ""unassigned"".",Resolved,Duplicate,MAPREDUCE-368,Unassigned,Xavier Stevens,Thu; 4 Dec 2008 23:04:31 +0000,Fri; 19 Mar 2010 22:33:58 +0000,Fri; 19 Mar 2010 22:33:58 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-415
MAPREDUCE-416,Bug,Major,,Move the completed jobs' history files to a DONE subdirectory inside the configured history directory,Whenever a job completes; the history file can be moved to a directory called DONE. That would make the management of job history files easier (for example; administrators can move the history files from that directory to some other place; delete them; archive them; etc.).,Closed,Fixed,,Amar Kamat,Devaraj Das,Tue; 9 Jun 2009 05:43:55 +0000,Tue; 24 Aug 2010 21:13:39 +0000,Mon; 29 Jun 2009 13:23:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-416
MAPREDUCE-417,Bug,Minor,,Logging could hang/fail when drive is filled by mapred outputs.,HADOOP-1252 addresses the mapred disk problems. In addition to those problems; if mapred fills up the drive used for logging; it might affect TaskTracker DataNodes.  Simple solution for now is not to use the logging drive in MapReduce.,Resolved,Fixed,,Unassigned,Koji Noguchi,Sat; 5 May 2007 01:20:13 +0000,Thu; 17 Jul 2014 17:07:33 +0000,Thu; 17 Jul 2014 17:07:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-417
MAPREDUCE-418,Bug,Minor,,JT not able to find task id while updating status,JT not able to find task ids while updating status in gridmix2. Even though the jobs are completed successfully; JT is displaying following message for most of the tasks: 2009-02-20 14:46:29;488 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status; cannot find taskid attempt_200902201433_0020_r_000003_1,Resolved,Fixed,,Unassigned,Suman Sehgal,Fri; 20 Feb 2009 15:34:11 +0000,Mon; 21 Jul 2014 20:54:32 +0000,Mon; 21 Jul 2014 20:54:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-418
MAPREDUCE-419,Bug,Minor,,mapred.userlog.limit.kb has inconsistent defaults,"The default for ""mapred.userlog.limit.kb"" in mapred-default.xml is 0 whereas it's 100KB in the code.  These defaults should be consistent.",Closed,Fixed,,Philip Zeyliger,Philip Zeyliger,Sat; 13 Jun 2009 16:18:31 +0000,Tue; 24 Aug 2010 21:13:39 +0000,Wed; 24 Jun 2009 08:37:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-419
MAPREDUCE-420,Bug,Trivial,,FileNotFoundException when finishing a profiled task that doesn't generate an output file,"When running a hadoop job with mapred.task.profile=true; hadoop assumes that mapred.task.profile.params contains a ""%s"" that can be changed for a file name that will be created by the profiler containing its text output. If the profiler doesn't generate such an output file; profiled tasks will raise a FileNotFound exception  all or don't allow you to change the name of the output file. In my case; I'm a profiler that doesn't generate text output and only allows you to set the output directory for the snapshot files it generates.",Resolved,Duplicate,MAPREDUCE-105,Rodrigo Schmidt,Rodrigo Schmidt,Fri; 6 Feb 2009 00:59:20 +0000,Tue; 13 Sep 2011 15:55:24 +0000,Wed; 6 Jan 2010 19:27:39 +0000,,,,,HADOOP-2367,https://issues.apache.org/jira/browse/MAPREDUCE-420
MAPREDUCE-421,Bug,Major,pipes,mapred pipes might return exit code 0 even when failing,up to  hadoop 0.18.3 org.apache.hadoop.mapred.JobShell ensured that 'hadoop jar' returns non-zero exit code when the job fails. This is no longer true after moving this to org.apache.hadoop.util.RunJar.  Pipes jobs submitted through cli never returned proper exit code.  The main methods in org.apache.hadoop.util.RunJar. and org.apache.hadoop.mapred.pipes.Submitter should be modified to return an exit code similar to how org.apache.hadoop.mapred.JobShell did it.,Resolved,Fixed,,Christian Kunz,Christian Kunz,Fri; 12 Jun 2009 20:54:55 +0000,Wed; 2 Sep 2009 17:54:36 +0000,Thu; 27 Aug 2009 22:06:31 +0000,,,,,HADOOP-4340,https://issues.apache.org/jira/browse/MAPREDUCE-421
MAPREDUCE-422,Bug,Minor,,TaskTracker directoryCleanupThread never gets terminated,When a task tracker starts its work it calls startCleanupThreads() to create a directoryCleanupThread.  only; that thread is never terminated; it runs for the life of the process.   It should be terminated when the TaskTracker itself is terminated; presumably after it has done the last cleanup.,Resolved,Fixed,,Unassigned,Steve Loughran,Wed; 9 Jul 2008 14:38:32 +0000,Mon; 21 Jul 2014 16:26:49 +0000,Mon; 21 Jul 2014 16:26:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-422
MAPREDUCE-423,Bug,Trivial,,Remove getNumResolvedTaskTrackers() api from JobTracker,nan,Resolved,Not A Problem,,Harsh J,Amar Kamat,Fri; 13 Feb 2009 09:30:21 +0000,Sun; 18 Dec 2011 11:32:09 +0000,Sun; 18 Dec 2011 11:32:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-423
MAPREDUCE-424,Bug,Minor,jobtracker,Unreachable code in TaskInProgress.inCompleteSubTask,TaskInProgress.incompleteSubTask has the following unreachable-code :   It would never reach this code; because it is never called from other places; where taskState is not FAILED; KILLED; FAILED_UNCLEAN and KILLED_UNCLEAN. Also status != null is not required; since status is never null.,Resolved,Incomplete,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 12 Feb 2009 11:29:39 +0000,Mon; 21 Jul 2014 19:51:33 +0000,Mon; 21 Jul 2014 19:51:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-424
MAPREDUCE-425,Bug,Minor,,NPE in TaskInProgress.cleanup,This may be something that only my code triggers; an NPE in TaskTracker$TaskInProgress.cleanup    Looking at the code; the only source of NPE's on that line is localJobConf    It looks like if TaskInProgress.cleanup() ever gets called with no valid localJobConf; then an NPE is the result. The exception gets logged and discarded; but it does appear in the logs.,Resolved,Duplicate,HADOOP-5233,Unassigned,Steve Loughran,Wed; 28 Jan 2009 11:48:23 +0000,Thu; 29 Apr 2010 08:09:24 +0000,Wed; 29 Jul 2009 11:24:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-425
MAPREDUCE-426,Bug,Minor,,Race condition in LaunchTaskAction and KillJobAction,One task wasn't killed when its job was killed.  On the TaskTracker log; it showed;   2007-08-21 17:02:29;219 INFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction: task_0133_r_000080_2    ************** 2007-08-21 17:02:29;232 INFO org.apache.hadoop.mapred.TaskTracker: Received 'KillJobAction' for job: job_0131         ************** 2007-08-21 17:02:29;233 INFO org.apache.hadoop.mapred.TaskRunner: task_0131_m_000077_0 done; removing files. 2007-08-21 17:02:29;376 INFO org.apache.hadoop.mapred.TaskTracker: Received 'KillJobAction' for job: job_0133 2007-08-21 17:02:29;376 INFO org.apache.hadoop.mapred.TaskRunner: task_0133_r_000060_0 done; removing files. 2007-08-21 17:02:29;378 INFO org.apache.hadoop.mapred.TaskRunner: task_0133_r_000071_2 done; removing files. 2007-08-21 17:02:29;381 INFO org.apache.hadoop.mapred.TaskRunner: task_0133_r_000066_1 done; removing files. 2007-08-21 17:02:31;272 INFO org.apache.hadoop.mapred.TaskTracker: task_0133_r_000080_2 0.0% reduce  copy  2007-08-21 17:02:32;275 INFO org.apache.hadoop.mapred.TaskTracker: task_0133_r_000080_2 0.0% reduce  copy  2007-08-21 17:02:33;277 INFO org.apache.hadoop.mapred.TaskTracker: task_0133_r_000080_2 0.0% reduce  copy  ... task_0133_r_000080_2 continue to run    Of course the JobTracker kept on complaining 2007-08-22 19:06:37;880 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status; cannot find taskid task_0133_r_000080_2 2007-08-22 19:06:38;124 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status; cannot find taskid task_0133_r_000080_2 2007-08-22 19:06:47;885 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status; cannot find taskid task_0133_r_000080_2,Resolved,Fixed,,Unassigned,Koji Noguchi,Wed; 22 Aug 2007 20:54:30 +0000,Thu; 17 Jul 2014 17:40:21 +0000,Thu; 17 Jul 2014 17:40:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-426
MAPREDUCE-427,Bug,Minor,,Earlier key-value buffer from MapTask.java is still referenced even though its not required anymore.,Consider the following events for a map task Before HADOOP-1965:    So for the time duration between Stage-4 and Stage-5 the memory used becomes 2 * io.sort.mb which can be totally avoided by removing the comparator's reference to the earlier key-val buffer. So the maximum memory usage can be clamped to io.sort.mb  After HADOOP-1965:    So for the time duration between Stage-4 and Stage-5 there is an unwanted reference to the keyval buffer which prevents the GC from claiming it. However the maximum memory usage will be io.sort.mb.,Resolved,Fixed,HADOOP-2919,Unassigned,Amar Kamat,Tue; 5 Feb 2008 06:04:40 +0000,Thu; 17 Jul 2014 20:25:41 +0000,Thu; 17 Jul 2014 20:25:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-427
MAPREDUCE-428,Bug,Minor,,Reducers reported completion % is generally incorrect when consuming compressed map outputs,When processing compressed map outputs; reducers often report over 100% completion (up to 220%). This is regardless of the compression codec and of whether native compression is used or not.,Resolved,Duplicate,MAPREDUCE-2264,Unassigned,Riccardo Boscolo,Thu; 6 Sep 2007 21:40:15 +0000,Thu; 17 Jul 2014 17:56:12 +0000,Thu; 17 Jul 2014 17:56:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-428
MAPREDUCE-429,Bug,Minor,,HADOOP-801 doesn't add property to hadoop-default.xml,HADOOP-801 (in fixing HADOOP-805) adds a new configuration option  jobclient.output.filter.  This property should have also been added to hadoop-default.xml with a default value of NONE (the current default of FAILURE is too verbose with INFO exceptions).,Resolved,Invalid,,Unassigned,Nigel Daley,Tue; 23 Jan 2007 05:08:51 +0000,Mon; 16 Jan 2012 10:32:51 +0000,Mon; 16 Jan 2012 10:32:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-429
MAPREDUCE-430,Bug,Major,,Task stuck in cleanup with OutOfMemoryErrors,Obesrved a task with OutOfMemory error; stuck in cleanup.,Resolved,Fixed,,Amar Kamat,Amareshwari Sriramadasu,Fri; 19 Jun 2009 05:55:51 +0000,Thu; 27 Aug 2009 16:10:42 +0000,Wed; 26 Aug 2009 16:12:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-430
MAPREDUCE-431,Bug,Minor,jobtracker,Task left in RUNNING state even after the job completion,Task could be left in RUNNING state in the following scenario: 1. Job was killed from command-line. 2. TaskTracker running the task didnt come back. 3. JobTracker marks the tracker as lost; but since Job is not RUNNING; it does not change the Task's state.  The code doing the same in JobTracker.lostTaskTracker method is :,Resolved,Fixed,,Unassigned,Amareshwari Sriramadasu,Thu; 5 Mar 2009 10:25:03 +0000,Mon; 21 Jul 2014 21:30:36 +0000,Mon; 21 Jul 2014 21:30:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-431
MAPREDUCE-432,Bug,Trivial,,JobClient should check input/output specifications  before copying the job files on the DFS,JobClient copies create the job files to the DFS.,Resolved,Duplicate,MAPREDUCE-2384,Unassigned,Amar Kamat,Thu; 10 Jul 2008 10:32:52 +0000,Sun; 26 Jun 2011 20:48:19 +0000,Sun; 26 Jun 2011 20:48:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-432
MAPREDUCE-433,Bug,Major,,TestReduceFetch failed.,Ran TestReduceFetch a few times on a clean trunk.  It failed consistently.,Resolved,Fixed,MAPREDUCE-1172,Chris Douglas,Tsz Wo Nicholas Sze,Fri; 12 Jun 2009 19:31:40 +0000,Tue; 23 Feb 2010 06:31:38 +0000,Tue; 26 Jan 2010 07:54:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-433
MAPREDUCE-434,Improvement,Minor,,LocalJobRunner limited to single reducer,when mapred.job.tracker is set to 'local'; my setNumReduceTasks call is ignored; and the number of reduce tasks is set at 1. This prevents me from locally debugging my partition function; which tries to partition based on the number of reduce tasks.,Closed,Fixed,,Aaron Kimball,Yoram Arnon,Wed; 10 May 2006 06:11:57 +0000,Mon; 24 Feb 2014 20:57:42 +0000,Tue; 6 Aug 2013 06:41:58 +0000,,,,,MAPREDUCE-4337,https://issues.apache.org/jira/browse/MAPREDUCE-434
MAPREDUCE-435,Bug,Minor,,JobTracker might not accept first few jobs if restarted immediately,If the jobtracker is restarted in a very short span of time (e.g. test case). First few submissions might fail as the jobtracker identifier remains same new jobid given by JobTracker.getNewJobId() might return an existing job id.,Resolved,Fixed,,Unassigned,Amar Kamat,Tue; 17 Mar 2009 04:10:30 +0000,Mon; 21 Jul 2014 22:01:26 +0000,Mon; 21 Jul 2014 22:01:26 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-435
MAPREDUCE-436,Bug,Minor,,NPE in TaskRunner.run if hadoop.log.dir not set,I'm getting an NPE in TaskRunner.run; looks like it happens when the system property hadoop.log.dir is unset,Resolved,Duplicate,HADOOP-2681,Unassigned,Steve Loughran,Fri; 20 Mar 2009 16:50:46 +0000,Fri; 18 Jul 2014 05:16:25 +0000,Fri; 18 Jul 2014 05:16:25 +0000,,,,,HADOOP-3438;HADOOP-2681,https://issues.apache.org/jira/browse/MAPREDUCE-436
MAPREDUCE-437,Bug,Minor,jobtracker,JobTracker must ask for a new FS instance and close it when terminated.,This is something I've been experimenting with HADOOP-3268; I'm not sure what the right action is here.  -currently; the JobTracker does not close() its filesystem when it is shut down. This will cause it to leak filesystem references if JobTrackers are started and stopped in the same process.  -The TestMRServerPorts test explicitly closes the filesystem         jt.fs.close();         jt.stopTracker();  -If you move the close() operation into the stopTracker() terminate logic; the filesystem gets cleaned up; but  TestRackAwareTaskPlacement and TestMultipleLevelCaching fail with a FilesystemClosed error (stack traces to follow)  Should the JobTracker close its filesystem whenever it is terminated? If so; there are some tests that need to be reworked slightly to not expect the fileystem to be live after the jobtracker is taken down.,Resolved,Cannot Reproduce,,Steve Loughran,Steve Loughran,Fri; 19 Sep 2008 11:40:45 +0000,Mon; 3 Mar 2014 10:05:24 +0000,Mon; 3 Mar 2014 10:05:24 +0000,,0.20.1;0.21.0;0.22.0,,,HDFS-925,https://issues.apache.org/jira/browse/MAPREDUCE-437
MAPREDUCE-438,Bug,Minor,,When connecting to HDFS using an IP  Task MapRed gets confused when checking the output path. ,The exception appearing below happens if you are using an IP address to reference a HDFS file system path.  Although the URI authority for either path (whether referenced by hostname:port or IP-address:port) refer to the same filesystem; Task throws an exception because the stringified comparisons of the authority in the URIs are not equal.  The FileSystem holds the network location of the namenode as a host name regardless as to whether an IP address or hostname is used when the file system is connected (refer to HADOOP-5191 for an earlier fix specifically for HDFS only).   2009-03-27 04:15:45;045 WARN Thread-145 org.apache.hadoop.mapred.LocalJobRunner: job_local_0002  202),Open,Unresolved,,Unassigned,Bill Habermaas,Wed; 1 Apr 2009 19:05:01 +0000,Mon; 20 Jul 2009 21:07:02 +0000,,,,,,HADOOP-5191,https://issues.apache.org/jira/browse/MAPREDUCE-438
HADOOP-6452,Bug,Minor,,Hadoop JSP pages don't work under a security manager,"When you run Hadoop under a security manager that says ""yes"" to all security checks; you get stack traces when Jetty tries to initialise the JSP engine. Which implies you can't use Jasper under a security manager",Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 24 Apr 2009 15:11:13 +0000,Tue; 24 Aug 2010 20:41:21 +0000,Wed; 23 Dec 2009 12:12:36 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/HADOOP-6452
MAPREDUCE-440,Bug,Minor,,-archives option in JobConf doesn't support symlink for an uncompressed archive directory,According to http: hosts) below   68)  This breaks a number of jobs that worked with the cacheArchives option in hadoop streaming.,Resolved,Duplicate,MAPREDUCE-787,Unassigned,Derek Wollenstein,Mon; 9 Mar 2009 20:32:03 +0000,Fri; 7 May 2010 05:24:31 +0000,Fri; 7 May 2010 05:24:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-440
MAPREDUCE-441,Bug,Major,test,TestMapReduceJobControl.testJobControlWithKillJob timedout in of the hudson runs,TestMapReduceJobControl.testJobControlWithKillJob timedout in of the hudson runs @ http: ,Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Fri; 19 Jun 2009 03:24:27 +0000,Tue; 22 Jul 2014 21:57:49 +0000,Tue; 22 Jul 2014 21:57:49 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-441
MAPREDUCE-442,New Feature,Major,,Ability to re-configure hadoop daemons online,Example :  Like we have bin hadoop mradmin -refreshNodes we should also have bin hadoop mradmin -reconfigure which re-configures mr while the cluster is online. Few parameters like job-expiry-interval etc can be changed in this way without having to restart the whole cluster.   Master; once reconfigured; can ask the slaves to reconfigure (reload its config) from a well defined location on hdfs or via heartbeat.   We can have some whitelisted configs that have reloadable property.,Resolved,Duplicate,HADOOP-7001,Unassigned,Amar Kamat,Thu; 18 Jun 2009 08:19:42 +0000,Tue; 22 Jul 2014 21:47:09 +0000,Tue; 22 Jul 2014 21:47:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-442
MAPREDUCE-443,New Feature,Minor,,snapshot a map-reduce to DFS ... and restore,The idea is to be able to issue a command to the job tracker that will halt a map-reduce and archive it to a directory in such a way that it can later be restarted.  We could also set a mode that would cause this to happen to a job when it fails.  This would allow one to debug and restart a failing job reasonably; which might be important; for long running jobs.  It has certainly been important in similar systems I've seen before.  One  could restart with a new jar or work bench a single failing map or reduce.,Resolved,Duplicate,MAPREDUCE-457,Owen O'Malley,eric baldeschwieler,Fri; 17 Mar 2006 12:26:20 +0000,Fri; 18 Jul 2014 17:37:10 +0000,Fri; 18 Jul 2014 17:36:26 +0000,,,,,HADOOP-313;MAPREDUCE-460;MAPREDUCE-452,https://issues.apache.org/jira/browse/MAPREDUCE-443
MAPREDUCE-444,New Feature,Minor,,Job should be able to specify whether task vm is 32 or 64 bit,Perhaps a job should be able to specify whether it wants it's task VM's to be 32 or 64 bit.  This could be accomplished by the -d32 and -d64  options when the task VM is exec'd.  This becomes important for native libs.,Resolved,Fixed,,Unassigned,Nigel Daley,Sat; 13 Jan 2007 01:50:53 +0000,Tue; 17 Jan 2012 03:49:52 +0000,Tue; 17 Jan 2012 03:49:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-444
MAPREDUCE-445,New Feature,Major,,Web service interface to the JobTracker,I think we need to provide a web services interface to submit and track jobs. This will simplify cross-version and non-Java access to JobTracker functionality.,Resolved,Duplicate,YARN-2332,Unassigned,Owen O'Malley,Wed; 13 May 2009 19:22:17 +0000,Thu; 2 May 2013 02:29:25 +0000,Tue; 10 Jul 2012 16:53:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-445
MAPREDUCE-446,New Feature,Minor,,The WebUI pages that display the list of map and reduce tasks should also include the hostname where the task is running,"Currently; the page that displays the list of map tasks shows ""Task; Complete; Status; Start time; End Time; Counters"". If this could show the hostname as well; it could be helpful in analyzing cases where tasks in a given set of nodes execute much slower than the rest.",Resolved,Fixed,,Unassigned,Jothi Padmanabhan,Fri; 17 Oct 2008 09:41:59 +0000,Sat; 19 Jul 2014 18:59:56 +0000,Sat; 19 Jul 2014 18:59:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-446
MAPREDUCE-447,New Feature,Minor,,Add Serialization for RecordIO,Implement org.apache.hadoop.io.serialization.Serialization Deserializer interfaces,Resolved,Invalid,,Unassigned,Pete Wyckoff,Thu; 18 Sep 2008 03:17:38 +0000,Fri; 18 Jul 2014 23:39:37 +0000,Fri; 18 Jul 2014 23:39:37 +0000,,,,,MAPREDUCE-376,https://issues.apache.org/jira/browse/MAPREDUCE-447
MAPREDUCE-448,New Feature,Minor,,Facility to connect back to a job from the command line. ,There should a facility to connect back to a job from the command line. Once the job is fired from the client and say for some reason the connection is lost; there is no way to connect back for tracking the job's progress from the command line. Something like 'bin hadoop job -connect job-id'.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Thu; 27 Mar 2008 04:52:01 +0000,Thu; 17 Jul 2014 21:49:02 +0000,Thu; 17 Jul 2014 21:49:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-448
MAPREDUCE-449,New Feature,Minor,,There is little information provided when the TaskTracker kills a Task that has not reported within the timeout (600 sec) interval - this patch provides a stack trace of the task ,When we have a task that is killed for not reporting; sometimes there is an obvious programming error; and sometimes the reason the job didn't report is unclear. This patch will cause the TaskTracker to try to generate a stack trace of the offending task before the task is killed. Given how opaque process control is in  Process object. The script that generates the stack trace is very linux specific. The code changes will run on jvm's where the UNIXProcess class is not available; without failure; but no stack trace will be generated.,Resolved,Duplicate,MAPREDUCE-1119,Unassigned,Jason,Thu; 21 Aug 2008 21:18:21 +0000,Fri; 7 May 2010 05:32:28 +0000,Fri; 7 May 2010 05:32:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-449
MAPREDUCE-450,New Feature,Minor,,"OutputFormat should have a ""close"" method called after all the reducers have completed","It would be very useful for OutputFormat's to have a ""close"" method so that any global logic for outputting can take place there. For example; to output a meta data file along with all the reduce outputs. The close method should have the following signature and be run after all the reducers have finished; but before the ""work output path"" is renamed to the final output path:  void close(FileSystem fs; JobConf job; Progressable progress) throws IOException",Resolved,Duplicate,HADOOP-3150,Unassigned,Nathan Marz,Tue; 16 Dec 2008 21:23:15 +0000,Thu; 11 Feb 2010 06:18:19 +0000,Thu; 11 Feb 2010 06:18:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-450
MAPREDUCE-451,New Feature,Minor,,TaskTracker's Memory resource should be considered when tasktracker asks for new task,Currently; taskTracker only considers enough free disk space left when it asks for new task; memory resource should be considered too; or it may works badly in SMP environment.,Resolved,Fixed,,Unassigned,ZhuGuanyin,Fri; 22 Aug 2008 10:42:07 +0000,Fri; 18 Jul 2014 22:23:43 +0000,Fri; 18 Jul 2014 22:23:43 +0000,,,,,MAPREDUCE-302,https://issues.apache.org/jira/browse/MAPREDUCE-451
MAPREDUCE-452,New Feature,Minor,,tasktracker checkpointing capability,"This relates to allowing a resource manager (e.g.; hadoop on demand) to grow and (rarely) shrink jobs on the fly.  Growing is already supported. Shrinking could be done in 2 ways - (1) consider the machine dead and allow speculative execution to take care of it or (2) moving the existing map outputs from that machine somewhere else (another machine; dfs) - ""task tracker checkpointing""   In the case of IO only intensive jobs;  checkpointing the tasktracker doesn't do much for you.  But; in the case of CPU or other scarce resource (e.g.; a DB or Webpage cache...); the checkpointing could be very useful.  The question is how often is this the case and how useful?",Resolved,Fixed,,Unassigned,Pete Wyckoff,Wed; 23 May 2007 00:24:41 +0000,Thu; 17 Jul 2014 17:12:19 +0000,Thu; 17 Jul 2014 17:12:19 +0000,,,,,MAPREDUCE-443,https://issues.apache.org/jira/browse/MAPREDUCE-452
MAPREDUCE-453,New Feature,Minor,,Provide more flexibility in the way tasks are run,The aim With HADOOP-3421 speaking about sharing a cluster among more than one organization (so potentially with non-cooperative users); and posts on the ML speaking about virtualization and the ability to re-use the TaskTracker's VM to run new tasks; it could be useful for admins to choose the way TaskRunners run their children.   More specifically; it could be useful to provide a way to imprison a Task in its working directory; or in a virtual machine. In some cases; reusing the VM might be useful; since it seems that this feature is really wanted (HADOOP-249).  Concretely What I propose is a new class; called called SeperateVMTaskWrapper which contains the current logic for running tasks in another JVM. This class extends another; called TaskWrapper; which could be inherited to provide new ways of running tasks. As part of this issue I would also like to provide two other TaskWrappers : the first would run the tasks as Thread of the TaskRunner's VM (if it is possible without too much changes); the second would use a fixed pool of local unix accounts to insulate tasks from each others (so potentially non-cooperating users will be hable to share a cluster; as described in HADOOP-3421).,Resolved,Duplicate,HADOOP-249;MAPREDUCE-249,Brice Arnould,Brice Arnould,Tue; 1 Jul 2008 10:45:23 +0000,Sun; 17 Jun 2012 05:01:13 +0000,Sun; 17 Jun 2012 04:59:59 +0000,,,,HADOOP-3421,,https://issues.apache.org/jira/browse/MAPREDUCE-453
YARN-2332,New Feature,Major,resourcemanager;webapp,Create REST interface for app submission,Porting a discussion from the LinkedIn Hadoop group to the Hadoop JIRA: http: groupAnswers?viewQuestionAndAnswers=gid=988957discussionID=2156671sik=1239077959330,Open,Unresolved,MAPREDUCE-445,Unassigned,Jeff Hammerbacher,Tue; 7 Apr 2009 04:20:58 +0000,Tue; 22 Jul 2014 21:14:42 +0000,,,,,,MAPREDUCE-2818,https://issues.apache.org/jira/browse/YARN-2332
MAPREDUCE-455,New Feature,Minor,,Hadoop needs a better XML Input,Hadoop does not have a good XML parser for XML input. The XML parser in the streaming class is fairly difficult to work with and doesn't have proper test cases around it.,Open,Unresolved,,Unassigned,Alan Ho,Mon; 17 Dec 2007 06:35:26 +0000,Thu; 17 Jul 2014 19:14:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-455
MAPREDUCE-456,New Feature,Minor,,add a link to the dfs from job tracker WI,add a link to the dfs from job tracker WI,Resolved,Won't Fix,,Owen O'Malley,Yoram Arnon,Fri; 3 Nov 2006 17:46:10 +0000,Mon; 16 Jan 2012 10:14:30 +0000,Mon; 16 Jan 2012 10:14:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-456
MAPREDUCE-457,New Feature,Minor,,Ability to pause/resume tasks,It would be nice to be able to pause (and subsequently resume) tasks that are currently running; in order to allow tasks from higher priority jobs to execute. At present it is quite easy for long-running tasks from low priority jobs to block a task from a newer high priority job; and there is no way to force the execution of the high priority task without killing the low priority jobs.,Open,Unresolved,MAPREDUCE-443,Chris Smith,Chris Smith,Thu; 3 Jul 2008 15:13:59 +0000,Fri; 18 Jul 2014 17:37:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-457
MAPREDUCE-458,New Feature,Minor,,Adding caching to Hadoop which is independent of the task trackers.,It would be nice to have a feature in Hadoop that could cache files locally that is independent of TaskTrackers and JobTrackers. Hadoop-288 caching is dependent on the tasktrackers. In an environment where you would dynamically bring up and down the TaskTrackers for resource sharing; that is problematic. It would be good to have this feature wherein you can install tasktrackers rsync to copy the main hadoop.jar.,Resolved,Not A Problem,,Owen O'Malley,Mahadev konar,Sat; 12 Aug 2006 00:01:01 +0000,Mon; 16 Jan 2012 09:51:44 +0000,Mon; 16 Jan 2012 09:51:44 +0000,,,,,HADOOP-288,https://issues.apache.org/jira/browse/MAPREDUCE-458
MAPREDUCE-459,New Feature,Major,,Elegant decommission of lighty loaded tasktrackers from a map-reduce cluster,There is a need to elegantly move some machines from one map-reduce cluster to another. This JIRA is to discuss how to find lightly loaded tasktrackers that are candidates for decommissioning and then to elegantly decommission them by waiting for existing tasks to finish.,Resolved,Incomplete,,Namit Jain,dhruba borthakur,Fri; 19 Jun 2009 00:37:12 +0000,Tue; 22 Jul 2014 21:48:37 +0000,Tue; 22 Jul 2014 21:48:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-459
MAPREDUCE-460,New Feature,Major,mrv2,Should be able to re-run jobs; collecting only missing output,"For jobs with no side effects (roughly == jobs with speculative execution enabled); if partial output has been generated; it should be possible to re-run the job; and fill in the missing pieces. I have now run the same job twice; once finishing 42 of 44 reduce tasks; another time finishing only 17. Each time; many nodes have failed; causing many many tasks to fail ( in one case; 5k failures from 15k map tasks; 23 failures from 44 reduces); but some valid output was generated. Since the output is only dependent on the input; and both jobs used the same input; I will now be able to combine these two failed task outputs to get a completed job's output. This should be something that can be more automatic.  In particular; it should be possible to resubmit a job; with a list of partitions that should be ignored. A special Combiner; or pre-Combiner; would throw out any map output for partitions that have already been successfully completed; thus reducing the amount of data that needs to be reduced to complete the job. It would; of course; be nice to support ""filling in"" existing outputs; rather than having to do a move operation on completed outputs.",Reopened,Unresolved,,Unassigned,Bryan Pendleton,Wed; 17 May 2006 01:10:21 +0000,Fri; 18 Jul 2014 04:56:12 +0000,,,,,,MAPREDUCE-443,https://issues.apache.org/jira/browse/MAPREDUCE-460
MAPREDUCE-461,New Feature,Minor,,Enable ServicePlugins for the JobTracker,Allow ServicePlugins (see HADOOP-5257) for the JobTracker.,Closed,Fixed,,Fredrik Hedberg,Fredrik Hedberg,Thu; 9 Apr 2009 12:02:07 +0000,Fri; 7 Dec 2012 22:42:28 +0000,Tue; 17 May 2011 03:51:34 +0000,,,,,HADOOP-5257,https://issues.apache.org/jira/browse/MAPREDUCE-461
MAPREDUCE-462,Improvement,Minor,,Multiple; generic InputFormats for MapReduce,The feature th depends on setting up an empty JobConf prior to its instantiation. An alternative is to use a string version of an InputFormat's setup JobConf. The analog to DelegatingMapper simply exposes the child split's index to drive per input logic (in our case; its a script rather than a Map class). As with HADOOP-372; these are lib-level changes; not core.,Open,Unresolved,,Unassigned,Vuk Ercegovac,Fri; 8 Aug 2008 07:00:38 +0000,Sat; 20 Jun 2009 07:57:24 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-462
MAPREDUCE-463,Improvement,Major,,The job setup and cleanup tasks should be optional,For jobs that require low latency and do not require setup or cleanup tasks for the job; it should be possible to turn them off for that job.,Closed,Fixed,,Amareshwari Sriramadasu,Owen O'Malley,Fri; 8 May 2009 07:20:02 +0000,Sat; 28 Jul 2012 00:36:53 +0000,Fri; 26 Jun 2009 07:53:47 +0000,,,,,MAPREDUCE-1099;MAPREDUCE-4488;MAPREDUCE-308,https://issues.apache.org/jira/browse/MAPREDUCE-463
MAPREDUCE-464,Improvement,Minor,,Command options should be provided in examples,Examples like Randomwriter have options for controlling the total data; data per map; key size etc. Help for such examples should also display the available options. The only way to find it out is to go through the code. This help info can have 2 sections namely general and advanced.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 31 Mar 2008 08:26:58 +0000,Thu; 17 Jul 2014 21:53:40 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-464
MAPREDUCE-465,Improvement,Minor,,Deprecate org.apache.hadoop.mapred.lib.MultithreadedMapRunner,Deprecate org.apache.hadoop.mapred.lib.MultithreadedMapRunner to use org.apache.hadoop.mapreduce.lib.MultithreadedMapRunner,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 12 Jun 2009 04:53:10 +0000,Wed; 15 Jul 2009 10:26:32 +0000,Fri; 3 Jul 2009 09:54:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-465
MAPREDUCE-466,Improvement,Minor,,The code in ReduceTask::fetchOutputs that deals with fetch failures can be refactored to a separate method,There is big chunk of code to handle fetch failures in ReduceTask::fetchOutputs. To improve the readability of code; this should be moved out to a separate method.,Resolved,Invalid,,Devaraj Das,Devaraj Das,Wed; 21 May 2008 13:02:51 +0000,Wed; 23 Sep 2009 09:16:44 +0000,Wed; 23 Sep 2009 09:16:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-466
MAPREDUCE-467,New Feature,Major,,Collect information about number of tasks succeeded / total per time unit for a tasktracker. ,Collecting information of number of tasks succeeded   total per tasktracker and being able to see these counts per hour; day and since start time will help reason about things like the blacklisting strategy.,Closed,Fixed,,Sharad Agarwal,Hemanth Yamijala,Thu; 28 May 2009 06:09:12 +0000,Tue; 24 Aug 2010 21:13:43 +0000,Mon; 13 Jul 2009 05:22:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-467
MAPREDUCE-468,Improvement,Minor,,Let users specify -classpath for the tasks,"One user requested   what I am not able to solve is to add the jar file that is inside the (distributedCache) archive to the task's class path.  I believe letting users add the classpath by ""mapred.child. opts"" would be useful. Currently; this '-classpath' is ignored due to the same problem as HADOOP-1493.",Resolved,Fixed,,Unassigned,Koji Noguchi,Thu; 23 Oct 2008 21:37:08 +0000,Mon; 21 Jul 2014 16:35:48 +0000,Mon; 21 Jul 2014 16:35:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-468
HADOOP-6835,Improvement,Major,io,Support concatenated gzip files,When running MapReduce with concatenated gzip files as input only the first part is read; which is confusing; to say the least. Concatenated gzip is described in http: Problem-with-Hadoop-and-concatenated-gzip-files-to21383097.html),Closed,Fixed,,Greg Roelofs,Tom White,Mon; 12 Jan 2009 13:16:32 +0000,Mon; 12 Dec 2011 06:19:09 +0000,Wed; 7 Jul 2010 23:23:16 +0000,,0.20.2,,HADOOP-7386,MAPREDUCE-1795;HADOOP-6335;PIG-42,https://issues.apache.org/jira/browse/HADOOP-6835
MAPREDUCE-470,Improvement,Trivial,,jobdetails.jsp could show analysejobhistory.jsp details after job is complete,It would be good to have analysejobhistory details shown on jobdetails.jsp for successfully completed jobs.,Resolved,Fixed,,Lohit Vijayarenu,Lohit Vijayarenu,Thu; 11 Sep 2008 08:12:28 +0000,Fri; 18 Jul 2014 23:36:34 +0000,Fri; 18 Jul 2014 23:36:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-470
MAPREDUCE-471,Improvement,Minor,,Refactor JobTracker.Expire* arround an utility class,I would like to propose a new class; called ExpiringHashSet; which could factorize the code from JobTracker.ExpireLaunchingTasks and JobTracker.ExpireTrackers.  It behaves like an ordinary HashSet; but adds two methods and one argument to the constructor. That argument; lifeTime; tells after how much milliseconds an element added to the container expire and is removed. The first method; update(element); takes an element as it argument and delay it's expiration by lifeTime milliseconds. The last method; makeExpire is called by the ExpiringHashSet just before it remove an old item. If that method return false; the item won't be removed. Nothing expire while we're synchronized on the ExpiringHashSet.,Resolved,Not A Problem,,Unassigned,Brice Arnould,Fri; 20 Jun 2008 11:49:28 +0000,Thu; 29 Dec 2011 06:43:43 +0000,Thu; 29 Dec 2011 06:43:43 +0000,,,,,HADOOP-3608,https://issues.apache.org/jira/browse/MAPREDUCE-471
MAPREDUCE-472,Improvement,Minor,,Unassigned tasks cannot be killed/failed from the web UI,Even though private actions are enabled; tasks in UNASSIGNED state cannot be killed failed from the web UI like other tasks as there are no such hyper-links on taskdetails.jsp.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Fri; 20 Feb 2009 14:20:11 +0000,Sat; 9 May 2015 01:02:39 +0000,Sat; 9 May 2015 01:00:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-472
MAPREDUCE-473,Improvement,Minor,,Hook InetAddress.getLocalHost().getHostName() to support cluster simulatation.,"I have been running a simulation for weeks now (and also a 30 machine crawl). To make it work I need to sometimes  let DataNodes; and TaskTrackers think they have a different machine-name than the one in InetAddress.getLocalHost()  The patch is:  1) replace InetAddress.getLocalHost().getHostName() with xxxx 	1.a)xxxx could be ""conf.get(""inetaddress.localhost.name"";InetAddress.getLocalHost().getHostName())"" 	1.b)or; xxxx could be a static call; I chose the latter: ""InetAddressWrapper.getLocalHostName(conf)"" 2) InetAddressWrapper.getLocalHostName(conf) checks the config for a hostname; and then calls InetAddress.getLocalHost().getHostName()  There's 3 places where it happens: DataNode DFSClient TaskTracker  I did not patch the two tests that call InetAddress because they are not really using hostname.",Open,Unresolved,,Owen O'Malley,alan wootton,Fri; 5 May 2006 05:39:09 +0000,Sat; 20 Jun 2009 07:57:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-473
MAPREDUCE-474,Improvement,Trivial,,ability to report numeric progress within a particular key,I'd like some mechanism to report numeric progress in maps that have side effects. In the common case; there is exactly one key value for each map and they do a lot of work (minutes to hours) while working on that key. It would be nice if mapred.Reporter had a progress(float) method that set the progress within the current key.,Resolved,Not A Problem,,Owen O'Malley,Owen O'Malley,Wed; 14 Jun 2006 04:33:59 +0000,Mon; 16 Jan 2012 09:09:40 +0000,Mon; 16 Jan 2012 09:09:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-474
MAPREDUCE-475,Improvement,Minor,,JobConf should validate key names in well-defined namespaces and warn on misspelling,"A discussion on the mailing list reveals that some configuration strings in the JobConf are deprecated over time and new configuration names replace them:  e.g.; ""mapred.output.compression.type"" is now replaced with ""mapred.map.output.compression.type""  Programmers who have been manually specifying the former string; however; receive no diagnostic output during testing to suggest that their compression type is being silently ignored.  It would be desirable to notify developers of this change by printing a warning message when deprecated configuration names are used in a newer version of Hadoop. More generally; when any configuration string in the mapred.; fs.; dfs.; etc namespaces are provided by a user and are not recognized by Hadoop; it is desirable to print a warning; to indicate malformed configurations. No warnings should be printed when configuration keys are in user-defined namespaces (e.g.; ""myprogram.mytask.myvalue"").",Resolved,Fixed,,Unassigned,Aaron Kimball,Thu; 21 Feb 2008 04:12:03 +0000,Thu; 17 Jul 2014 21:04:04 +0000,Thu; 17 Jul 2014 21:04:04 +0000,,,,,HADOOP-3582,https://issues.apache.org/jira/browse/MAPREDUCE-475
MAPREDUCE-476,Improvement,Minor,,extend DistributedCache to work locally (LocalJobRunner),The DistributedCache does not work locally when using the outlined recipe at http: DistributedCache.html   Ideally; LocalJobRunner would take care of populating the JobConf and copying remote files to the local file sytem (http; assume hdfs = default fs = local fs when doing local development.,Closed,Fixed,HADOOP-5174,Philip Zeyliger,sam rash,Thu; 28 Feb 2008 22:27:18 +0000,Tue; 24 Aug 2010 21:13:43 +0000,Tue; 25 Aug 2009 10:29:03 +0000,,,,MAPREDUCE-856;MAPREDUCE-711,MAPREDUCE-711,https://issues.apache.org/jira/browse/MAPREDUCE-476
MAPREDUCE-477,Improvement,Minor,,Support for reading bzip2 compressed file created using concatenation of multiple .bz2 files ,Bzip2Codec supported in Hadoop 0.19 0.20  should support for reading bzip2 compressed file created using concatenation of multiple .bz2 files,Resolved,Fixed,,Unassigned,Suhas Gogate,Tue; 31 Mar 2009 19:24:54 +0000,Mon; 21 Jul 2014 22:18:52 +0000,Mon; 21 Jul 2014 22:18:52 +0000,,,,,HADOOP-4012,https://issues.apache.org/jira/browse/MAPREDUCE-477
MAPREDUCE-478,Improvement,Minor,,separate jvm param for mapper and reducer,Memory footprint of mapper and reducer can differ.  It would be nice if we can pass different jvm param (mapred.child. opts) for mappers and reducers.,Closed,Fixed,,Arun C Murthy,Koji Noguchi,Wed; 15 Apr 2009 20:15:19 +0000,Thu; 12 Jan 2012 06:48:39 +0000,Mon; 17 Aug 2009 03:57:36 +0000,,,,HADOOP-6192,,https://issues.apache.org/jira/browse/MAPREDUCE-478
MAPREDUCE-479,Improvement,Minor,,Add reduce ID to shuffle clienttrace,Current clienttrace messages from shuffles note only the destination map ID but not the source reduce ID. Having both source and destination ID of each shuffle enables full tracing of execution.,Closed,Fixed,,Jiaqi Tan,Jiaqi Tan,Thu; 11 Jun 2009 20:49:40 +0000,Tue; 24 Aug 2010 21:13:44 +0000,Mon; 24 Aug 2009 03:53:38 +0000,,0.21.0,,,HADOOP-5876,https://issues.apache.org/jira/browse/MAPREDUCE-479
MAPREDUCE-480,Improvement,Minor,,Dependency cycle: log and mapred,There's a dependency cycle between org.apache.hadoop.log and org.apache.hadoop.mapred. Moving the inner servlet class in LogLevel to StatusHttpServer fixes it,Resolved,Not A Problem,,Unassigned,Bill de hOra,Sun; 6 Jul 2008 09:18:06 +0000,Fri; 18 Jul 2014 17:41:12 +0000,Fri; 18 Jul 2014 17:41:12 +0000,,,,,HADOOP-3750,https://issues.apache.org/jira/browse/MAPREDUCE-480
MAPREDUCE-481,Improvement,Major,,Improvements to Global Black-listing of TaskTrackers,HADOOP-4305 added a global black-list of tasktrackers.  We saw a scenario on one of our clusters where a few jobs caused a lot of tasktrackers to immediately be blacklisted. This was caused by a specific set of jobs which (same user) whose tasks were shot down the by the TaskTracker for being over the vmem limit of 2G. Each of these jobs had over 600 failures of the same kind. This resulted in each of the users black-listing some tasktrackers; which in itself is wrong since the failures had nothing to do with the node on which the failure occurred (i.e. high memory usage) and shouldn't have had to penalized the tasktracker. We clearly need to start treating system and user failures separately for black-listing etc. A DiskError is fatal and should probably we blacklisted immediately while a task which was 'failed' for using more memory shouldn't count against the tasktracker at all!  The other problem is that we never configured mapred.max.tracker.blacklists and continue to use the default value of 4. Further more this config should really be a percent of the cluster-size and not a whole number.,Resolved,Fixed,,Unassigned,Arun C Murthy,Thu; 11 Jun 2009 22:35:40 +0000,Tue; 22 Jul 2014 21:10:47 +0000,Tue; 22 Jul 2014 21:10:47 +0000,,,,,HADOOP-3462,https://issues.apache.org/jira/browse/MAPREDUCE-481
MAPREDUCE-482,Improvement,Minor,,Each shuffle should proceed as a DFA,The shuffle code (for fetching map outputs) should proceed as a DFA. The states (as Owen had mentioned on HADOOP-1183) are (INITIAL; LOCATED; FETCHING; DONE; FAILED). This is to ensure correctness of map output fetching.,Open,Unresolved,,Unassigned,Devaraj Das,Tue; 8 May 2007 06:08:21 +0000,Tue; 10 Jul 2012 03:48:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-482
MAPREDUCE-483,Improvement,Minor,,Enhance 'bin/hadoop job -submit <>',Today 'bin hadoop job -submit' takes a config file and just does a JobClient.submitJob(jobConf); this isn't flexible enough for cases where the user wants to submit a job which calls his main(); does some work and then calls 'JobClient.runJob'; I propose we enhance this subcommand to handle that scenario. This could be really useful for the time we decide to setup a simple webpage with 'form' where the user uploads a job.xml  job.jar and we can fire the job.,Reopened,Unresolved,,Unassigned,Arun C Murthy,Fri; 8 Dec 2006 11:20:10 +0000,Tue; 17 Jan 2012 03:48:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-483
MAPREDUCE-484,Improvement,Trivial,,Logos for Hive and JobTracker,Greetings fine Hadoop peoples;  While working on a few projects here at Cloudera we found ourselves wanting for some sort of icon for both the JobTracker and for Hive. After checking on the project page for Hive (the JobTracker doesn't really have one) and finding that these items have no icons; we rolled up our sleeves and made some. We'd like to contribute these to the project; so if you want 'em; they're all yours.,Resolved,Fixed,,Unassigned,Aaron Newton,Wed; 15 Apr 2009 19:18:35 +0000,Tue; 22 Jul 2014 18:49:06 +0000,Tue; 22 Jul 2014 18:49:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-484
MAPREDUCE-485,Improvement,Minor,,jobID() lookup failure should notify client,https: HADOOP-4419?focusedCommentId=12639889#action_12639889) so they can handle the problem.  This JIRA is for the separate issue of the API change that would require.,Resolved,Incomplete,MAPREDUCE-984,Unassigned,Aaron Kimball,Tue; 25 Nov 2008 20:17:21 +0000,Sat; 19 Jul 2014 00:19:35 +0000,Sat; 19 Jul 2014 00:19:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-485
MAPREDUCE-486,Improvement,Minor,,JobTracker web UI counts COMMIT_PENDING tasks as Running,"In jobdetails.jsp; tasks in COMMIT_PENDING state are listed as ""Running"". I propose creating another column in this table for COMMIT_PENDING tasks; since users find it confusing that a given job can have more tasks ""Running"" than their total cluster capacity.",Closed,Won't Fix,,Harsh J,Todd Lipcon,Sun; 14 Jun 2009 01:21:13 +0000,Wed; 17 Oct 2012 22:30:00 +0000,Sat; 30 Jun 2012 16:07:11 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-486
MAPREDUCE-487,Improvement,Trivial,,DBInputFormat support for Oracle,DBInputFormat doesnt support interfacing with Oracle.,Closed,Duplicate,MAPREDUCE-716,Unassigned,Amandeep Khurana,Thu; 2 Apr 2009 19:43:44 +0000,Tue; 24 Aug 2010 21:13:45 +0000,Tue; 7 Jul 2009 07:19:34 +0000,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-487
MAPREDUCE-488,Improvement,Minor,,JobTracker webui should report heap memory used,As of today JobTracker's webui reports total-available-heap-memory and max-heap-memory. I think it will be useful to show the actual heap memory used i.e total - free.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Mon; 22 Dec 2008 07:59:03 +0000,Sat; 9 May 2015 01:20:11 +0000,Sat; 9 May 2015 01:20:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-488
MAPREDUCE-489,Improvement,Minor,,Force the task tracker to exit when the task is complete; prevents nodes from dying due to resource starvation from impropertly written map/reduce tasks,We have map  there is no more logging done.          LogManager.shutdown(); + +        System.exit(0);        }      }    },Open,Unresolved,,Unassigned,Jason,Thu; 24 Jan 2008 23:17:26 +0000,Thu; 17 Jul 2014 19:57:16 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-489
MAPREDUCE-490,Improvement,Minor,,Allow printing of TaskEvents for a Job from command line,It might make sense to have these commands:  bin hadoop job fromEvent maxEvents full job_id : This will print the contents of the logs (like what the JobClient does today),Resolved,Not A Problem,,Unassigned,Devaraj Das,Wed; 24 Jan 2007 12:56:49 +0000,Mon; 16 Jan 2012 10:35:15 +0000,Mon; 16 Jan 2012 10:35:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-490
MAPREDUCE-491,Improvement,Minor,,RAgzip: multiple map tasks for a large gzipped file,"Currently; the hadoop processes gzipped files with only one map. We have made a patch th creates an access point (.ap) file; which is like the index of the gzipped file chunks.  The access point(.ap) file is located in same path of the gzipped file. If there is a "" test.gz.ap"".",Open,Unresolved,HADOOP-6153,Daehyun Kim,Daehyun Kim,Thu; 13 Nov 2008 10:00:27 +0000,Wed; 23 Jul 2014 19:53:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-491
MAPREDUCE-492,Improvement,Minor,,Pending; running; completed tasks should also be shown as percentage,nan,Resolved,Fixed,,Amar Kamat,Amar Kamat,Thu; 25 Oct 2007 10:50:50 +0000,Thu; 17 Jul 2014 18:16:25 +0000,Thu; 17 Jul 2014 18:16:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-492
MAPREDUCE-493,Improvement,Minor,,Provide -outputcommitter option for streaming and pipes,Similar to -inputformat and -outputformat options in streaming and pipes; we should have -outputcommitter option to specify the job outputcommitter to specify the configuration property mapred.output.committer.class .,Resolved,Invalid,,Unassigned,Amareshwari Sriramadasu,Wed; 15 Oct 2008 09:16:46 +0000,Wed; 7 Oct 2009 06:00:31 +0000,Wed; 7 Oct 2009 06:00:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-493
MAPREDUCE-494,Improvement,Minor,,Enhance the JobClient to allow users to easily query/display TaskCompletionEvents,Currently the code for querying the JobTracker for TaskCompletionEvents and displaying useful information such as error logs and profiling information are deeply buried in JobClient.runJob. This means applications which use alternative interfaces to submit jobs i.e. JobClient.submitJob have to reimplement this functionality. It would be useful to factor it out for the sake of those applications...,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Tue; 29 Apr 2008 00:49:05 +0000,Sat; 20 Jun 2009 07:57:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-494
MAPREDUCE-495,Improvement,Minor,,Makes hidden file filter at public scope,nan,Resolved,Incomplete,,Unassigned,Michael Gottesman,Mon; 30 Jun 2008 18:05:05 +0000,Fri; 18 Jul 2014 17:31:45 +0000,Fri; 18 Jul 2014 17:31:45 +0000,,,,,HADOOP-3890,https://issues.apache.org/jira/browse/MAPREDUCE-495
MAPREDUCE-496,Improvement,Minor,,If mapred.local.dir is configured on top of dfs.data.dir; hadoop should refuse to start rather than deleting the contents of local.dir,I just managed to blow away a DFS by accidentally misconfiguring dfs.data.dir and mapred.local.dir to contain several directories in common. On startup; the task tracker clears out mapred.local.dir; which obviously screws over the datanode.  This should be a reasonably easy check to put in place to make hadoop more idiot proof (or in my case lack-of-sleep proof),Open,Unresolved,,Unassigned,Todd Lipcon,Sat; 6 Dec 2008 22:39:07 +0000,Mon; 21 Jul 2014 17:04:23 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-496
MAPREDUCE-497,Improvement,Minor,,TaskTracker.addDiagnostics(String file; int num; String tag) could exit early if num==0,When a TaskTracker job finishes;  taskFinished() is invoked.   as part of its work it  1. loads in a conf option (that is not in hadoop-default; incidentally) ; mapred.debug.out.lines ; default value -1;  2. calls addDiagnostics passing in that line count  addDiagnostics either builds a string buffer of all the output; or creates a linear array of lines and runs adds them; shuffling them up if there are more lines than expected.   This is all unneeded if the number of lines to print == 0; the entire reading in of the output file can be skipped. This may speed up termination slightly on a run with a large output file and mapred.debug.out.lines ==0.   Note also that a circular buffer would handle the lines0 problem without having to copy all the strings around.,Resolved,Incomplete,,Unassigned,Steve Loughran,Fri; 23 May 2008 13:46:12 +0000,Fri; 18 Jul 2014 05:23:26 +0000,Fri; 18 Jul 2014 05:23:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-497
YARN-2329,Improvement,Minor,,Machine List generated by machines.jsp should be sorted,The listing of machines shown by machine.jsp is arbitrarily ordered.  It would be a more useful to sort them.,Open,Unresolved,,Unassigned,Tim Williamson,Thu; 26 Mar 2009 23:44:11 +0000,Mon; 21 Jul 2014 22:12:58 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-2329
MAPREDUCE-499,Improvement,Trivial,,Revert extra debugging,It appears that HADOOP-3647 is actually caused by a bad disk; unobserved given HADOOP-4277. The extra debugging can be removed.,Resolved,Invalid,,Unassigned,Chris Douglas,Tue; 2 Dec 2008 23:53:10 +0000,Sun; 18 Sep 2011 22:57:57 +0000,Fri; 11 Jun 2010 07:55:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-499
MAPREDUCE-500,Improvement,Minor,,Clean up the JobTracker code,My IDE flags a lot of trouble in the JobTracker code; but I dont want to mix those changes with any lifecycle changes. After doing that; then I'd like to clean up the code in JobTracker  -move to generic types and foreach loops over Vector and iterators. -give all threads the correct type -stop using package scoped static variables to pass instance-data around specifically   TASKTRACKER_EXPIRY_INTERVAL  RETIRE_JOB_CHECK_INTERVAL  RETIRE_JOB_INTERVAL -fix up all the  oc warnings  -remove the needless this. references on lots of local variables -replace the log + stringifyException with log(text;exception).   Its only an hour or so of work; and would improve the code maintainability; but it would  make merging existing code harder.,Resolved,Incomplete,,Unassigned,Steve Loughran,Fri; 1 Aug 2008 11:19:09 +0000,Fri; 18 Jul 2014 20:05:11 +0000,Fri; 18 Jul 2014 20:05:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-500
MAPREDUCE-501,Improvement,Minor,,Spawning tasks faster,"In the current implementation; tasks are assigned to tasktrackers by adding an appropriate action to the heartbeat response list. Each heartbeat response can start one task. As the minimum interval between heartbeats is 5 sec (by default); if the nodes are strong machines (say; each node has 10 task ""slots"") and the cluster is idle; this means that some tasks are spawned after some time (in our example; the last task will be spawned after 45 seconds).  This can be significantly improve the end-to-end execution time if most jobs are finished in the order of minutes.  The patch I attach requests from each TaskTracker to reply in 1 5th of the regular heartbeat interval time if it was assigned a task in this round; making spawning of multiple tasks much more efficient.  A better approach would be to have each TaskTracker report the number of free slots it has (instead of only if it can accept more work or not) and have the JobTracker push the appropriate number of tasks in one response; but this will require changes in the current communication protocol.",Resolved,Incomplete,,Unassigned,Spyros Blanas,Thu; 10 Jul 2008 01:51:38 +0000,Fri; 18 Jul 2014 17:59:38 +0000,Fri; 18 Jul 2014 17:59:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-501
MAPREDUCE-502,Improvement,Major,,Allow jobtracker to be configured with zero completed jobs in memory,There is no way to specify that the jobtracker should not keep any completed job in memory.,Closed,Fixed,,Amar Kamat,Amar Kamat,Fri; 2 Jan 2009 08:17:55 +0000,Tue; 24 Aug 2010 21:13:45 +0000,Fri; 26 Jun 2009 11:09:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-502
MAPREDUCE-503,Improvement,Minor,,Add visual cue to denote if a job is running or not in scheduler UI page,add visual cue to denote if a job is running or not in scheduler UI page.,Resolved,Won't Fix,,Sreekanth Ramakrishnan,Sreekanth Ramakrishnan,Fri; 28 Nov 2008 11:07:44 +0000,Sat; 19 Jul 2014 00:21:59 +0000,Sat; 19 Jul 2014 00:21:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-503
MAPREDUCE-504,Improvement,Trivial,,JobTracker's configuration should be shown on jobtracker.jsp,A job's configuration is displayed for each job on jobdetails.jsp.. It would be really useful if JobTracker's config is also displayed on jobtracker.jsp.,Resolved,Not A Problem,,Unassigned,Amar Kamat,Sat; 6 Dec 2008 15:07:32 +0000,Sun; 26 Jun 2011 20:46:11 +0000,Sun; 26 Jun 2011 20:46:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-504
MAPREDUCE-505,Improvement,Minor,,StatusHttpServer should include hostname/port when bind fails,Just as server includes diagnostics on the host:port binding for a failed socket startup; we should catch and wrap any failure of jetty to start up with the same diagnostics.,Open,Unresolved,,Unassigned,Steve Loughran,Wed; 28 May 2008 16:33:44 +0000,Fri; 18 Jul 2014 05:24:30 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-505
MAPREDUCE-506,Improvement,Minor,,make HistoryViewer a public class.,org.apache.hadoop.mapred.HistoryViewer is useful to access Job history files from application code. The class can be made public.,Resolved,Duplicate,MAPREDUCE-157,Unassigned,Amareshwari Sriramadasu,Tue; 29 Jul 2008 05:40:10 +0000,Wed; 7 Oct 2009 05:59:02 +0000,Wed; 7 Oct 2009 05:59:02 +0000,,,,,MAPREDUCE-2818,https://issues.apache.org/jira/browse/MAPREDUCE-506
MAPREDUCE-507,Improvement,Minor,,Have backlinks from history pages to main jobtracker page,When we go from jobtracker.jsp to the job history page; and from then on to any other page in history; there is no way to go back to the jobtracker page. It would be nice to add this.,Resolved,Won't Fix,,Unassigned,Hemanth Yamijala,Wed; 8 Oct 2008 07:49:36 +0000,Fri; 18 Jul 2014 23:59:16 +0000,Fri; 18 Jul 2014 23:59:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-507
MAPREDUCE-508,Wish,Minor,,dynamic heartbeat interval for the locality-aware task scheduling,In current hadoop release (0.17.0); there is no special scheduling policy for those tasktrackers who have no data for some jobs. So; there would be inefficient in some senarios. For example; tasktracker A has the data for a job; but tasktracker B; which has no data for this job; sends the heartbe message for a new task after a period of current_heartbeat_interval 2 . (4) Jobtracker then find a new task for tasktracker B.  This is just an primary idea for the improvement of the locality-aware scheduling. Any comments are welcome.,Resolved,Fixed,,Unassigned,Leitao Guo,Tue; 1 Jul 2008 08:05:47 +0000,Fri; 18 Jul 2014 17:32:56 +0000,Fri; 18 Jul 2014 17:32:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-508
MAPREDUCE-509,Wish,Minor,,Setting the network interface for TaskTracker connection to task tracker http server,I ma running TestDFSIO using different network interfaces. For that; I am modifying the IP address in hadoop-default.xml; hadoop-site.xml and slaves files in the conf directory. Unfortunately; I can still observed connection from TaskTracker to task tracker http server over the default network interface (eth0) when it is configured to use different network interface. Can you tell me what should be done to be sure that all connection used a unique network interfaces?,Resolved,Not A Problem,,Unassigned,Amnon Katz,Thu; 19 Feb 2009 11:22:11 +0000,Mon; 21 Jul 2014 20:28:24 +0000,Mon; 21 Jul 2014 20:28:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-509
MAPREDUCE-510,Wish,Minor,,A way to get tasks current working directory via JobConf,It would be good to have tasks know its current working directory via JobConf; instead of deriving the same or trying to get local current working directory. I see that we already derive that while updating classpath. Would it be good idea to have it as a config variable to make it available in task execution environment?,Resolved,Not A Problem,,Unassigned,Lohit Vijayarenu,Fri; 26 Sep 2008 07:55:03 +0000,Fri; 18 Jul 2014 23:47:10 +0000,Fri; 18 Jul 2014 23:47:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-510
MAPREDUCE-511,Wish,Minor,,Let combiner use different comparator instead of OutputKeyComparator,"I have a dataset with map key=""city+userid+time"". The output of mapper are sorted by this map key.  Than; I group the reduce output according to ""city+userid"" by define my OutputValueGroupingComparator which just compare ""city+userid"" in the mapkey. I still want the output are sorted by time in each group. It works fine.  But to improve the performance; I want to use combiner which should also group as  ""city+userid""; but sorted by ""city+userid+time"".  So; wish to develop a new feature to let combiner use different comparator instead of OutputKeyComparator.  For example CombinerGroupingComparator?",Open,Unresolved,,Unassigned,Schubert Zhang,Tue; 12 May 2009 08:46:19 +0000,Sat; 20 Jun 2009 07:57:28 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-511
MAPREDUCE-512,Test,Minor,,Add tests for the DFS HTML and JSP pages,"Add some basic tests to look for the standard JSP pages on a locally deployed MiniMR cluster  1. namenode: check that dfshealth is present 2. datanode: check that all the datanode JSPs load 3. GET the standard servlets.  The initial checks can just use httpclient to GET the pages; no need (yet) for HtmlUnit.   If the tests were designed to take optional URLs  (e.g test.namenode.url and test.datanode.url) they could be run against processes brought up externally remotely  They would  	help test that the JSP pages are being compiled down and bundled into the JARS 	verify the classpath is getting set up right 	check that the Jasper engine is working 	check the servlets are all registering    I've effectively had to do this in my own code; having a set of these tests inside hadoop would make it easier to point the blame at the classpath setup or something else.",Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Wed; 4 Feb 2009 23:28:13 +0000,Mon; 26 Jan 2015 22:49:14 +0000,Mon; 26 Jan 2015 22:49:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-512
MAPREDUCE-513,Bug,Major,,Prior code fix in Capacity Scheduler prevents speculative execution in jobs,As part of the code fix for HADOOP-4035; the Capacity Scheduler obtains a task from JobInProgress (calling obtainNewMapTask() or obtainNewReduceTask()) only if the number of pending tasks for a job is greater than zero (see the if-block in TaskSchedulingMgr.getTaskFromJob()). So; if a job has no pending tasks and only has running tasks; it will never be given a slot; and will never have a chance to run a speculative task.,Resolved,Fixed,,Sreekanth Ramakrishnan,Vivek Ratan,Mon; 5 Jan 2009 08:38:40 +0000,Wed; 29 Jul 2009 08:55:08 +0000,Wed; 29 Jul 2009 08:55:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-513
MAPREDUCE-514,Bug,Major,,Check for invalid queues in capacity scheduler,The ResourceManagerConf class that is being moved to the capacity scheduler of HADOOP-3445 needs to check for a queue name that is not configured in the resource-manager-conf.xml file in its APIs and fail if it is not available. This feature was originally available; but due to subsequent changes in HADOOP-3698; queues are no longer being configured as part of the mentioned configuration file. Hence we need a different mechanism to check for valid queues.,Resolved,Won't Fix,,Sreekanth Ramakrishnan,Hemanth Yamijala,Fri; 5 Sep 2008 08:36:57 +0000,Tue; 17 Nov 2009 06:26:40 +0000,Tue; 17 Nov 2009 06:26:40 +0000,,,,HADOOP-3445,HADOOP-4178,https://issues.apache.org/jira/browse/MAPREDUCE-514
MAPREDUCE-515,Bug,Major,,CapacityTaskScheduler.MapSchedulingMgr.killTasksFromJob() will not work as expected,"Once capacity-scheduler decides on killing tasks; it selects running-jobs from the queue and issues killTasksFromJob(). The order in which it kills is as follows  	non-local maps 	local maps    Killing non-local maps : The code here uses JobInProgress.getNonLocalRunningMaps(). HADOOP-2119 introduced this for handling cases like random-writer. Hence this api will return an empty structure if there are reducers in the job. Hence the code fails to serve its purpose.",Resolved,Invalid,,Unassigned,Amar Kamat,Mon; 10 Nov 2008 11:20:18 +0000,Mon; 9 Nov 2009 09:32:38 +0000,Mon; 9 Nov 2009 09:32:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-515
MAPREDUCE-516,Bug,Major,,Fix the 'cluster drain' problem in the Capacity Scheduler wrt High RAM Jobs,When a HighRAMJob turns up at the head of the queue; the current implementation of support for HighRAMJobs in the Capacity Scheduler has problem in that the scheduler stops assigning tasks to all TaskTrackers in the cluster until a HighRAMJob finds a suitable TaskTrackers for all its tasks.  This causes a severe utilization problem since effectively no new tasks are allowed to run until the HighRAMJob (at the head of the queue) gets slots.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 3 Jun 2009 00:38:46 +0000,Sun; 17 Jun 2012 07:27:33 +0000,Wed; 24 Jun 2009 14:43:48 +0000,,0.20.1,,HADOOP-5884,HADOOP-5881;MAPREDUCE-3789;MAPREDUCE-4001,https://issues.apache.org/jira/browse/MAPREDUCE-516
MAPREDUCE-517,Bug,Critical,,The capacity-scheduler should assign multiple tasks per heartbeat,HADOOP-3136 changed the default o.a.h.mapred.JobQueueTaskScheduler to assign multiple tasks per TaskTracker heartbeat; the capacity-scheduler should do the same.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 21 Jan 2009 06:53:25 +0000,Thu; 24 Nov 2011 22:04:04 +0000,Thu; 25 Aug 2011 20:08:50 +0000,,,,HADOOP-5884,,https://issues.apache.org/jira/browse/MAPREDUCE-517
MAPREDUCE-518,Bug,Major,,Have end to end tests based on MiniMRCluster to verify correct behaviour of slot reclamation by queues.,We should have a test that submits long running jobs to different queues one after the other; and ensures that queues get required capacity or get back taken-away capacity after killing tasks within the specified amount of time.,Resolved,Incomplete,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 11 Dec 2008 05:56:28 +0000,Mon; 21 Jul 2014 17:11:46 +0000,Mon; 21 Jul 2014 17:11:46 +0000,,,,,HADOOP-4830,https://issues.apache.org/jira/browse/MAPREDUCE-518
MAPREDUCE-519,Bug,Major,,Fix capacity scheduler's documentation,Parent jira for all documentation related issues in capacity scheduler.,Resolved,Won't Fix,,Chen He,Vinod Kumar Vavilapalli,Thu; 22 Jan 2009 06:24:33 +0000,Mon; 21 Jul 2014 18:30:09 +0000,Mon; 21 Jul 2014 18:30:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-519
MAPREDUCE-520,Bug,Major,,The capacity schedule must start a timer when a queue is underserved,It is important to the user that the timer that controls preemption be started when a queue is underserved; regardless of whether any other queues are over allocation.,Resolved,Won't Fix,,Unassigned,Owen O'Malley,Fri; 23 Jan 2009 00:03:10 +0000,Mon; 21 Jul 2014 18:30:46 +0000,Mon; 21 Jul 2014 18:30:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-520
MAPREDUCE-521,Bug,Major,,After JobTracker restart  Capacity Schduler does not schedules pending tasks from already running tasks.,After JobTracker restart  Capacity Schduler does not schedules pending task from already running tasks.,Resolved,Duplicate,MAPREDUCE-873,rahul k singh,Karam Singh,Fri; 24 Apr 2009 11:04:25 +0000,Fri; 26 Mar 2010 05:58:57 +0000,Fri; 26 Mar 2010 05:58:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-521
MAPREDUCE-522,Bug,Major,capacity-sched,Rewrite TestQueueCapacities to make it simpler and avoid timeout errors,We have seen TestQueueCapacities fail periodically and there have been a couple of times fixes partially fixed the problem; the most recent instance being HADOOP-5869. I found another instance of failure; while running tests locally while testing a different patch. This was a different symptom from the ones we've seen before. The core problem is that the test is too complex and relies on too many things working correctly to be useful. It would make sense to revisit the purpose of the test and see if a simpler model can serve it.,Closed,Fixed,,Sreekanth Ramakrishnan,Hemanth Yamijala,Wed; 17 Jun 2009 07:44:38 +0000,Tue; 24 Aug 2010 21:13:49 +0000,Fri; 3 Jul 2009 13:59:34 +0000,,,,MAPREDUCE-694,,https://issues.apache.org/jira/browse/MAPREDUCE-522
MAPREDUCE-523,Bug,Major,,User limit is not expanding back properly.,User limit is not expanding back properly.,Resolved,Incomplete,,Amar Kamat,Karam Singh,Fri; 14 Nov 2008 08:26:31 +0000,Sat; 19 Jul 2014 00:10:57 +0000,Sat; 19 Jul 2014 00:10:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-523
MAPREDUCE-524,Bug,Major,,Have end to end tests based on MiniMRCluster to verify the correct behaviour of job initialization.,Write tests to verify that the right number of jobs in the right order are initialized and that the limits on the number of jobs that can stay initialized at any time are honoured.,Resolved,Incomplete,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 11 Dec 2008 05:39:32 +0000,Mon; 21 Jul 2014 17:08:41 +0000,Mon; 21 Jul 2014 17:08:41 +0000,,,,MAPREDUCE-525;MAPREDUCE-531;HADOOP-4830,HADOOP-4830,https://issues.apache.org/jira/browse/MAPREDUCE-524
MAPREDUCE-525,Bug,Major,,Have end to end tests based on MiniMRCluster to verify the correct behaviour of job priorities.,"We should have the following tests:  	Basic priority test: submit jobs with different priorities and verify their proper ordering and running. 	New jobs with higher priority are submitted: verify th running of the jobs is affected.",Resolved,Incomplete,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 11 Dec 2008 05:44:45 +0000,Mon; 21 Jul 2014 17:09:12 +0000,Mon; 21 Jul 2014 17:09:12 +0000,,,,MAPREDUCE-524,HADOOP-4830,https://issues.apache.org/jira/browse/MAPREDUCE-525
MAPREDUCE-526,Bug,Major,,Sometimes job does not get removed from scheduler queue after it is killed,"Sometimes when we kill a job; it does get removed from waiting queue; while job status: ""Killed"" with Job Setup and Cleanup: ""Successful""  Also JobTracker webui shows job under failed jobs lists and hadoop job -list all; hadoop queue queuename -showJobs also shows jobs state=5. Prior to killing job state was ""Running""",Resolved,Won't Fix,,Unassigned,Karam Singh,Fri; 8 May 2009 13:17:37 +0000,Tue; 22 Jul 2014 19:28:59 +0000,Tue; 22 Jul 2014 19:28:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-526
MAPREDUCE-527,Bug,Minor,,Capacity Scheduler does not kill reduce tasks if all reducers are in the progress of their last record.,"If the Capacity Scheduler decides to kill a reduce job then it selects the task that made the least progress. In my test setup I created a dummy reduce task that does nothing but waiting indefinitely. All reduce progresses are ""1"" because all reducers are in the progress of their last record. Now the ""getRunningTaskWithLeastProgress(tip)"" will return null; so no task is killed.  Although not very likely this will occur in a production setup (timeout killing would kick in anyway) but it may be a bit unexpecting.  I will attach a patch.",Resolved,Invalid,,Unassigned,Ferdy Galema,Fri; 19 Jun 2009 13:54:35 +0000,Thu; 25 Jun 2009 07:54:33 +0000,Thu; 25 Jun 2009 01:38:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-527
MAPREDUCE-528,Bug,Minor,,NPE in jobqueue_details.jsp page if scheduler has not started,NullPointerException is observed in jobqueue_details.jsp page if the scheduler has not yet started,Resolved,Won't Fix,,Unassigned,Ramya Sunil,Wed; 27 May 2009 11:04:49 +0000,Tue; 22 Jul 2014 20:19:45 +0000,Tue; 22 Jul 2014 20:19:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-528
MAPREDUCE-529,Bug,Major,,Code to create the UI display string for queues in the Capacity Scheduler needs to be synchronized; and needs to better update its information,"There are a couple of problems with SchedulingInfo.toString(); the code which creates the UI display string for a queue:   	it needs synchronized access to the QueueSchedulingInfo object; as this same object can be updated by the reclaim-capacity thread; and during a heartbeat. 	the code directly updates its count of running map reduce tasks. this should be done in a better way; perhaps by calling updateQSIObjects(); rather than walking through the data structures directly. It's also not clear that we want to pay the performance penalty of updating the structures. it maybe OK to provide slightly stale info (the 'staleness' is tiny; in a steady-state and large system; where heartbeats are coming in frequently).",Resolved,Fixed,,Unassigned,Vivek Ratan,Tue; 6 Jan 2009 05:42:30 +0000,Fri; 1 Oct 2010 03:20:26 +0000,Fri; 1 Oct 2010 03:18:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-529
MAPREDUCE-530,Bug,Major,,High-memory jobs in CapacityTaskScheduler: Some scenarios make job execution unpredictable,Karam found some problems with scheduling for high-memory jobs by CapacityTaskScheduler. This issue tracks these.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Tue; 12 May 2009 09:27:42 +0000,Sat; 20 Jun 2009 07:59:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-530
MAPREDUCE-531,Bug,Major,,Have end to end tests based on MiniMRCluster to verify the correct behaviour of user limits,"We should have the following:  	Basic user limit tests 	 		Submit jobs one after another and see that the jobs' usage honours user limits in the steady state. 		Submit jobs simultaneously and see that the jobs' usage honours user limits in the steady state. 	 	 	User limit test with unequal share 	 		Submit jobs so that users get unequal share of the cluster. For e.g. configuring the cluster with min-user-limit of 40% and with 3 users should result in a distribution of 40%; 40% and 20%.",Resolved,Incomplete,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 11 Dec 2008 05:51:42 +0000,Mon; 21 Jul 2014 17:11:23 +0000,Mon; 21 Jul 2014 17:11:23 +0000,,,,MAPREDUCE-524,HADOOP-4830,https://issues.apache.org/jira/browse/MAPREDUCE-531
MAPREDUCE-532,New Feature,Major,capacity-sched,Allow admins of the Capacity Scheduler to set a hard-limit on the capacity of a queue,For jobs which call external services; (eg: distcp; crawlers) user job.,Closed,Fixed,,rahul k singh,Rajiv Chittajallu,Thu; 4 Jun 2009 00:59:18 +0000,Tue; 24 Aug 2010 21:13:50 +0000,Mon; 6 Jul 2009 07:55:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-532
MAPREDUCE-533,New Feature,Major,capacity-sched,Support task preemption in Capacity Scheduler,Without preemption; it is not possible to guarantee capacity since long running jobs may occupy task slots for an arbitrarily long time.,Resolved,Duplicate,YARN-569,Unassigned,Tsz Wo Nicholas Sze,Sat; 20 Jun 2009 00:23:08 +0000,Tue; 22 Jul 2014 22:01:42 +0000,Tue; 22 Jul 2014 22:01:42 +0000,,,,,MAPREDUCE-4468,https://issues.apache.org/jira/browse/MAPREDUCE-533
MAPREDUCE-534,New Feature,Major,,Provide accounting functionality for Hadoop resource manager,HADOOP-3421 describes requirements for a new resource manager in Hadoop to schedule Map Reduce jobs. In production systems; it would be useful to produce accounting information related to the scheduling - such as job start and run times; resources used; etc. This information can be consumed by other systems to build accounting for shared resources. This JIRA is for tracking the requirements; approach and implementation for producing accounting information.,Resolved,Fixed,,Hemanth Yamijala,Hemanth Yamijala,Mon; 7 Jul 2008 17:52:48 +0000,Fri; 18 Jul 2014 17:46:04 +0000,Fri; 18 Jul 2014 17:46:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-534
MAPREDUCE-535,New Feature,Minor,,jobqueue_details.jsp should support a 'refresh' attribute,jobqueue_details.jsp should support a 'refresh' attribute for automatic page-refresh; just like jobdetails.jsp.,Open,Unresolved,,Sreekanth Ramakrishnan,Vinod Kumar Vavilapalli,Fri; 17 Oct 2008 08:42:55 +0000,Sat; 20 Jun 2009 07:59:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-535
MAPREDUCE-536,Improvement,Major,,The information displayed by the capacity scheduler can be improved,"As of now the information displayed by the capacity scheduler is sequential. Following are some ways I think we can improve the display  	It would make more sense if we display it as a table where comparing the information across queues would be easy. Something like    	Along with  Reclaim Time Limit there should be a hint enhance the way boolean information is displayed using ticks and crosses. Something like",Resolved,Incomplete,,Unassigned,Amar Kamat,Fri; 5 Dec 2008 07:00:58 +0000,Mon; 21 Jul 2014 17:01:53 +0000,Mon; 21 Jul 2014 17:01:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-536
MAPREDUCE-537,Improvement,Major,,Instrument events in the capacity scheduler for collecting metrics information,We need to instrument various events in the capacity scheduler so that we can collect metrics about them. This data will help us determine improvements to scheduling strategies itself.,Resolved,Incomplete,,Unassigned,Hemanth Yamijala,Thu; 28 May 2009 06:02:38 +0000,Tue; 22 Jul 2014 20:20:15 +0000,Tue; 22 Jul 2014 20:20:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-537
MAPREDUCE-538,Improvement,Major,,Port HADOOP-4667 to teh capacity scheduler,HADOOP-4667 has implemented 'global scheduling' for the fair-share scheduler with very promising results - we should port the same to the capacity scheduler.,Resolved,Incomplete,,Unassigned,Arun C Murthy,Wed; 21 Jan 2009 06:53:33 +0000,Mon; 21 Jul 2014 18:18:35 +0000,Mon; 21 Jul 2014 18:18:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-538
MAPREDUCE-539,Improvement,Major,,Implement a config validator tool for the capacity scheduler,The capacity scheduler sanity checks configuration when it starts and halts if there are any problems found. For ease of deployment; it would help to have a simple utility that will validate the configuration before the capacity scheduler can be started; and report errors   warnings to the user about (possible) misconfigurations.,Resolved,Duplicate,MAPREDUCE-768,Sreekanth Ramakrishnan,Hemanth Yamijala,Tue; 9 Dec 2008 12:18:28 +0000,Wed; 29 Jul 2009 08:47:49 +0000,Wed; 29 Jul 2009 08:47:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-539
MAPREDUCE-540,Bug,Major,,Upate thread in FairScheduler runs too frequently,The UpdateThread in FairScheduler runs every 500ms (hardcoded). This proves to be very costly when running large clusters. UpdateThread tries to acquire lock on JT object every that often and so seriously affects HeartBeat processing besides everything else. The update interval should be a function of the cluster size. Or in the minimum it should be configurable and by default should be set to a reasonably high default value.,Resolved,Fixed,,Matei Zaharia,Vinod Kumar Vavilapalli,Fri; 6 Feb 2009 09:38:27 +0000,Tue; 30 Jun 2009 22:00:21 +0000,Tue; 30 Jun 2009 20:49:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-540
MAPREDUCE-541,Bug,Major,,NullPointerException in fairshare PoolManager,Found this NPE in a Hadoop 0.20.0 JobTracker log:,Open,Unresolved,,Vinod Kumar Vavilapalli,Nigel Daley,Wed; 4 Mar 2009 04:27:08 +0000,Sat; 20 Jun 2009 08:01:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-541
MAPREDUCE-542,Bug,Major,,FairScheduler.getJobs(queue) should return the jobs in the order of scheduling.,Without this; it is difficult to know what the order of preference of running tasks from jobs at any time is.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 19 Feb 2009 14:13:21 +0000,Sat; 20 Jun 2009 08:01:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-542
MAPREDUCE-543,Bug,Major,,large pending jobs hog resources,"observing the cluster over the last day - one thing i noticed is that small jobs (single digit tasks) are not doing a good job competing against large jobs. what seems to happen is that:   	large job comes along and needs to wait for a while for other large jobs. 	slots are slowly transfered from one large job to another 	small tasks keep waiting forever.    is this an artifact of deficit based scheduling? it seems that long pending large jobs are out-scheduling small jobs",Closed,Duplicate,MAPREDUCE-706,Matei Zaharia,Joydeep Sen Sarma,Mon; 8 Dec 2008 17:14:49 +0000,Tue; 24 Aug 2010 21:13:50 +0000,Tue; 10 Nov 2009 08:02:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-543
MAPREDUCE-544,Bug,Major,,deficit computation is biased by historical load,going through the code over the weekend - one of the things th a slot pace - should get more slots than the second large job.  again - recomputing deficit as mentioned in the context of the current load would fix this situation.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Mon; 15 Dec 2008 19:07:45 +0000,Sat; 20 Jun 2009 08:01:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-544
MAPREDUCE-545,Bug,Major,,Fairshare scheduler always waits for 5% of maps to finish before scheduling reduces.,The FairScheduler.enoughMapsFinishedToRunReduces() method has a hard-coded 5% limit of number of maps to finish before reduces can be scheduled; and this behaviour cannot be changed by users admins. This should in the minimum be configurable; perhaps using the same config property that the framework uses - mapred.reduce.slowstart.completed.maps. Or better it should use the JobInProgress.scheduleReduce() method itself directly.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Tue; 24 Mar 2009 14:44:31 +0000,Sat; 20 Jun 2009 08:01:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-545
MAPREDUCE-546,New Feature,Minor,,Provide sample fair scheduler config file in conf/ and use it by default if no other config file is specified,The capacity scheduler includes a config file template in hadoop conf; so it would make sense to create a similar one for the fair scheduler and mention it in the README.,Closed,Fixed,,Matei Zaharia,Matei Zaharia,Thu; 4 Dec 2008 01:37:59 +0000,Tue; 24 Aug 2010 21:13:51 +0000,Sun; 19 Jul 2009 00:27:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-546
MAPREDUCE-547,New Feature,Minor,,Allow a pool to hold onto its reservation for a while even if it contains no jobs,To better handle the case where a pool is submitting a sequence of jobs one at a time; it could be useful to let a pool hold onto its min share of slots for some timeout after its last job finishes. If no new job is submitted during this timeout; the slots can go back to being shared by other pools.,Open,Unresolved,,Unassigned,Matei Zaharia,Thu; 11 Jun 2009 23:24:14 +0000,Sat; 20 Jun 2009 08:01:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-547
MAPREDUCE-548,New Feature,Major,,Global scheduling in the Fair Scheduler,The current schedulers in Hadoop all examine a single job on every heartbeat when choosing which tasks to assign; choosing the job based on FIFO or fair sharing. There are inherent limitations to this approach. For example; if the job  least T2  T1 seconds; also allow it to launch off-rack tasks. This algorithm improves locality while bounding the delay that any job experiences in launching a task.    It turns out that whether waiting is useful depends on how many tasks are left in the job - the probability of getting a heartbeat from a node with a local task - and on whether the job is CPU or IO bound. Thus there may be logic for removing the wait on the last few tasks in the job.  As a related issue; once we allow global scheduling; we can launch multiple tasks per heartbeat; as in HADOOP-3136. The initial implementation of HADOOP-3136 adversely affected performance because it only launched multiple tasks from the same job; but with the wait rule above; we will only do this for jobs that are allowed to launch non-local tasks.,Closed,Duplicate,MAPREDUCE-706,Matei Zaharia,Matei Zaharia,Sun; 16 Nov 2008 00:09:40 +0000,Tue; 24 Aug 2010 21:13:52 +0000,Fri; 14 Aug 2009 16:33:40 +0000,,,,,MAPREDUCE-312,https://issues.apache.org/jira/browse/MAPREDUCE-548
MAPREDUCE-549,New Feature,Minor,,Allow specifying min shares as percentage of cluster,Currently the guaranteed shares for pools in the fair scheduler are specified as a number of slots. For organizations where a group pays X% of the cluster and the actual number of nodes in the cluster varies due to failures; expansion; etc over time; it would be useful to support a guaranteed share given as a percentage too. This would just let you write in the config file something like minMaps5% minMaps. The scheduler would need to recompute what this means in terms of number of slots on every update (probably through some kind of update(ClusterStatus) method in PoolManager).,Open,Unresolved,,Unassigned,Matei Zaharia,Sat; 14 Feb 2009 08:10:26 +0000,Sat; 20 Jun 2009 08:01:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-549
MAPREDUCE-550,New Feature,Major,,Add support for scheduling jobs based on memory requirements to the Fairscheduler,In HADOOP-3759; we added the ability for users to specify jobs requesting for a certain amount of virtual memory. For e.g. users can say that their jobs require 2GB of memory to run. In HADOOP-4035; functionality was added to the capacity scheduler to schedule jobs based on this specified amount. This JIRA is to add similar support to the Fairshare scheduler.  The basic use case is that there are jobs that require a certain known amount of virtual memory; usually more than the JVM's heap size. This happens specifically for streaming jobs that can launch several processes from the child. Without being aware of these requirements; if tasks are scheduled on nodes just based on available slots; they have a potential of affecting the other processes running on the node; or if memory protection features are enabled (HADOOP-3581); they could result in the task being killed by the tasktracker.  The scheduler must take into account the requested amount of memory by the job; the amount of memory that can be committed to by a tracker; and schedule based on these inputs.,Open,Unresolved,,Unassigned,Hemanth Yamijala,Wed; 25 Mar 2009 04:23:13 +0000,Sat; 20 Jun 2009 08:01:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-550
MAPREDUCE-551,New Feature,Major,contrib/fair-share,Add preemption to the fair scheduler,"Task preemption is necessary in a multi-user Hadoop cluster for two reasons: users might submit long-running tasks by mistake (e.g. an infinite loop in a map program); or tasks may be long due to having to process large amounts of data. The Fair Scheduler (HADOOP-3746) has a concept of guaranteed capacity for certain queues; as well as a goal of providing good performance for interactive jobs on average through fair sharing. Therefore; it will support preempting under two conditions: 1) A job isn't getting its guaranteed share of the cluster for at least T1 seconds. 2) A job is getting significantly less than its fair share for T2 seconds (e.g. less than half its share).  T1 will be chosen smaller than T2 (and will be configurable per queue) to meet guarantees quickly. T2 is meant as a last resort in case non-critical jobs in queues with no guaranteed capacity are being starved.  When deciding which tasks to kill to make room for the job; we will use the following heuristics:  	Look for tasks to kill only in jobs that have more than their fair share; ordering these by deficit (most overscheduled jobs first). 	For maps: kill tasks that have run for the least amount of time (limiting wasted time). 	For reduces: similar to maps; but give extra preference for reduces in the copy phase where there is not much map output per task (at Facebook; we have observed this to be the main time we need preemption - when a job has a long map phase and its reducers are mostly sitting idle and filling up slots).",Closed,Fixed,HADOOP-5701,Matei Zaharia,Matei Zaharia,Sat; 15 Nov 2008 23:51:21 +0000,Tue; 24 Aug 2010 21:13:52 +0000,Sat; 27 Jun 2009 03:46:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-551
MAPREDUCE-552,Improvement,Minor,,Make fair scheduler's per-job scheduling info visible in the default web UI,HADOOP-3930 added an API for displaying per-job and per-queue scheduling info in the JobTracker web UI and the command-line tools. The fair scheduler should set this info for jobs so it can integrate better with these tools.,Resolved,Incomplete,,Unassigned,Matei Zaharia,Sat; 22 Nov 2008 01:33:02 +0000,Sat; 19 Jul 2014 00:18:35 +0000,Sat; 19 Jul 2014 00:18:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-552
MAPREDUCE-553,Improvement,Major,,Fair share schduler may support preemption only with a specific pool,There are a set of jobs th this is the behaviour I want. The wellcare jobs would run in idle slots as long as all user-submitted jobs have been satisfied; but would be preempted as soon as user jobs require any of those slots.,Open,Unresolved,,Unassigned,dhruba borthakur,Sun; 12 Apr 2009 23:43:00 +0000,Sat; 20 Jun 2009 08:01:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-553
MAPREDUCE-554,Improvement,Minor,,Improve limit handling in fairshare scheduler,The fairshare scheduler has a way by which it can limit the number of jobs in a pool by setting the maxRunningJobs parameter in its allocations definition. This limit is treated as a hard limit; and comes into effect even if the cluster is free to run more jobs; resulting in underutilization. Possibly the same thing happens with the parameter maxRunningJobs for user and userMaxJobsDefault. It may help to treat these as a soft limit and run additional jobs to keep the cluster fully utilized.,Open,Unresolved,,Unassigned,Hemanth Yamijala,Fri; 6 Feb 2009 11:18:44 +0000,Sat; 20 Jun 2009 08:01:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-554
MAPREDUCE-555,Improvement,Minor,,Provide an option to turn off priorities in jobs,The fairshare scheduler can define pools mapping to queues (as defined in the capacity scheduler - HADOOP-3445). When used in this manner; one can imagine queues set up to be used by users who come from disparate teams or organizations (say a default queue). For such a queue; it makes sense to ignore job priorities and consider the queue as strict FIFO; as it is difficult to compare priorities of jobs from different users.,Resolved,Fixed,,Unassigned,Hemanth Yamijala,Fri; 6 Feb 2009 11:27:50 +0000,Mon; 21 Jul 2014 19:46:05 +0000,Mon; 21 Jul 2014 19:46:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-555
MAPREDUCE-556,Improvement,Major,,Refactor Hadoop package structure and source tree.,"This Jira proposes refactoring the Hadoop package structure and source tree  Goals 1. A little finer package structure.  	Current structure is a little flat 	Smaller files (name node and data node are way too big)    2. The client interfaces and data types sent across the wire should be clearly identifiable by the package they sit in.  This will help preserving app compatibility since it will be very obvious when one breaks the interface. 3. Split dfs's client and server side jars. 4. Move map-reduce into separate src tree (but same SVN repository) along with its separate jar. 5. The Javadoc for users of Hadoop should not contain the internal server-side interfaces minimize findbug warnings   The top level package structure remains unchanged:    hadoop.fs    hadoop.dfs     hadoop.mapred    Etc.  Considered changing hadoop.dfs to hadoop.hdfs but the ""h"" does not really add much since hadoop is already part of the package name;  didn't seem worth going to through the trouble of breaking compatibility.  Changes will occur internally within the above packages.    sub-Jira HADOOP-2885 proposes restructuring hadoop.dfs.  Other Jiras will be filed for restructuring other parts.",Resolved,Fixed,,Sanjay Radia,Sanjay Radia,Fri; 22 Feb 2008 22:22:06 +0000,Thu; 17 Jul 2014 21:07:16 +0000,Thu; 17 Jul 2014 21:07:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-556
MAPREDUCE-557,Sub-task,Minor,,Restructure the hadoop.dfs package,"This Jira proposes restructurign the package hadoop.dfs.  1. Move all server side and internal protocols (NN-DD etc) to hadoop.dfs.server.*  2. Further breakdown of dfs.server.  	dfs.server.namenode.* 	dfs.server.datanode.* 	dfs.server.balancer.* 	dfs.server.common.* - stuff shared between the various servers 	dfs.protocol.*  - internal protocol between DN; NN and Balancer etc.    3. Client interface:  	hadoop.dfs.DistributedFileSystem. 	hadoop.dfs.protocol.* - the client side protocol",Closed,Fixed,,Sanjay Radia,Sanjay Radia,Fri; 22 Feb 2008 22:27:29 +0000,Thu; 2 May 2013 02:29:13 +0000,Thu; 3 Jul 2008 22:56:00 +0000,,,,HADOOP-3563,,https://issues.apache.org/jira/browse/MAPREDUCE-557
MAPREDUCE-558,Sub-task,Major,,Refactor src structure; but leave package structure alone,This Jira proposes that the src structure be split  as below.  The package structure remains the same for this Jira. (Package renaming is part of other JIras  such as HADOOP-2885).  The idea is that the src will be split   BEFORE the package restructuring  The new proposed src structure is  src org.apache.hadoop.mapred.*  This Jira will not split the jar files.,Closed,Fixed,,Sanjay Radia,Sanjay Radia,Fri; 29 Feb 2008 02:02:36 +0000,Wed; 8 Jul 2009 16:42:55 +0000,Fri; 20 Jun 2008 15:35:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-558
MAPREDUCE-559,Sub-task,Blocker,,Clean up javadoc to reflect the public and private interfaces,Currently hdfs appears in public  doc for developers.,Closed,Fixed,,Sanjay Radia,Sanjay Radia,Thu; 10 Jul 2008 18:36:57 +0000,Wed; 8 Jul 2009 16:43:16 +0000,Mon; 25 Aug 2008 23:38:08 +0000,,,,,HADOOP-4023,https://issues.apache.org/jira/browse/MAPREDUCE-559
MAPREDUCE-560,Sub-task,Major,,Rename dfs package to hdfs for the generated servlet classes,The package name for the generated servlet classes is still org.apache.hadoop.dfs.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 6 Aug 2008 00:32:47 +0000,Wed; 8 Jul 2009 16:43:16 +0000,Fri; 8 Aug 2008 23:30:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-560
MAPREDUCE-561,Sub-task,Major,,Restructure the hadoop.mapred package,The MapReduce code should be split into org.apache.hadoop.mapreduce for the user API (covered by HADOOP-1230); and org.apache.hadoop.mapreduce.server for the server components.,Resolved,Fixed,,Unassigned,Tom White,Thu; 7 Aug 2008 10:31:38 +0000,Fri; 18 Jul 2014 20:50:21 +0000,Fri; 18 Jul 2014 20:50:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-561
MAPREDUCE-562,Bug,Major,,A single slow (but not dead) map TaskTracker impedes MapReduce progress,We see cases where there may be a large number of mapper nodes running many tasks (e.g.; a thousand). The reducers will pull 980 of the map task intermediate files down; but will be unable to retrieve the final intermediate shards from the last node. The TaskTracker on that node returns data to reducers either slowly or not at all; but its heartbeat messages make it back to the JobTracker  so the JobTracker doesn't mark the tasks as failed. Manually stopping the offending TaskTracker works to migrate the tasks to other nodes; where the shuffling process finishes very quickly. Left on its own; it can take hours to unjam itself otherwise.  We need a mechanism for reducers to provide feedback to the JobTracker that one of the mapper nodes should be regarded as lost.,Resolved,Incomplete,,Unassigned,Aaron Kimball,Sat; 6 Jun 2009 00:25:56 +0000,Tue; 22 Jul 2014 20:50:59 +0000,Tue; 22 Jul 2014 20:50:59 +0000,,,,,MAPREDUCE-1800,https://issues.apache.org/jira/browse/MAPREDUCE-562
MAPREDUCE-563,New Feature,Major,,Security features for Map/Reduce,This is a top-level tracking JIRA for security work we are doing in Map reduce. Please add reference to this when opening new security related JIRAs.  Logically a subpiece of HADOOP-4487.,Resolved,Fixed,,Unassigned,Owen O'Malley,Mon; 22 Jun 2009 05:27:11 +0000,Tue; 22 Jul 2014 22:02:46 +0000,Tue; 22 Jul 2014 22:02:46 +0000,,,,,HADOOP-4487,https://issues.apache.org/jira/browse/MAPREDUCE-563
MAPREDUCE-564,Improvement,Major,jobtracker,Provide a way for the client to get the number of currently running maps/reduces,Add counters for Number of Succeeded Maps and Number of Succeeded Reduces so that client can get this number without iterating through all the task reports while the job is in progress.,Resolved,Incomplete,,Ravi Gummadi,Ravi Gummadi,Mon; 22 Jun 2009 09:22:45 +0000,Tue; 22 Jul 2014 22:06:29 +0000,Tue; 22 Jul 2014 22:06:29 +0000,,0.21.0,,MAPREDUCE-653,,https://issues.apache.org/jira/browse/MAPREDUCE-564
MAPREDUCE-565,Bug,Blocker,task,Partitioner does not work with new API,"Partitioner does not work with the new API. MapTask. looks for ""mapred.partitioner.class"" whereas the new API sets it to mapreduce.partitioner.class",Resolved,Fixed,,Owen O'Malley,Jothi Padmanabhan,Mon; 27 Apr 2009 16:53:15 +0000,Wed; 15 Jul 2009 18:50:05 +0000,Tue; 14 Jul 2009 22:42:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-565
MAPREDUCE-566,Improvement,Minor,,Add default port for jobtracker (mapred.job.tracker),HADOOP-3317 standardizes port 8020 as the default port for NameNode   HDFS URIs. The mapred.job.tracker property has no such analogue.  I propose specifying a default port of 8021 if no port-component is specified in the user's mapred.job.tracker property.,Resolved,Incomplete,,Aaron Kimball,Aaron Kimball,Thu; 26 Mar 2009 15:02:53 +0000,Mon; 21 Jul 2014 22:12:28 +0000,Mon; 21 Jul 2014 22:12:28 +0000,,,,,HADOOP-3317,https://issues.apache.org/jira/browse/MAPREDUCE-566
MAPREDUCE-567,New Feature,Major,examples,Add a new example MR that always fails,For testing how Hadoop behaves when jobs fail; it's nice to have an example job that simply fails in either the mappers or the reducers.,Closed,Fixed,,Philip Zeyliger,Philip Zeyliger,Mon; 25 May 2009 22:00:21 +0000,Tue; 24 Aug 2010 21:13:55 +0000,Wed; 24 Jun 2009 13:24:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-567
MAPREDUCE-568,Bug,Major,contrib/streaming,Streaming causes a lot of broken pipes which leads to job failure, 1247)  A lot of these errors occur in streaming. THis leads to job failure. I still am not sure what the reason might be of these errors; but these erros occur too often. I will try and invetigate more to see what the reason might be.,Resolved,Invalid,,Unassigned,Mahadev konar,Tue; 28 Nov 2006 18:52:00 +0000,Mon; 16 Jan 2012 10:19:49 +0000,Mon; 16 Jan 2012 10:19:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-568
MAPREDUCE-569,Improvement,Major,contrib/streaming,Streaming should produce a short per-job log in a persistent location.,Streaming should produce a short per-job log in a persistent location.  The log should include (at least; but not limited to):  the command line that hadoop-streaming is executing   the list of matching input fragments  the actual command lines used by the framework for -mapper and for -reducer  log about all copied files  the name of the output HDFS directory  start and end time of the job  location of stderr logs and other output.,Open,Unresolved,,Unassigned,arkady borkovsky,Thu; 24 Aug 2006 21:50:08 +0000,Mon; 16 Jan 2012 09:55:22 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-569
MAPREDUCE-570,Bug,Minor,contrib/streaming,Streaming job fails with with identity mapper class,Streaming job command:  $HADOOP_HOME hadoop-streaming.jar       -reducer org.apache.hadoop.mapred.lib.IndentityReducer  Error in job tracker hadoop.log:  2008-11-24 22:18:12;637 INFO org.apache.hadoop.mapred.TaskInProgress: Error from  org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker. 2207)^D,Resolved,Duplicate,MAPREDUCE-1888,Unassigned,Suhas Gogate,Fri; 5 Dec 2008 20:48:46 +0000,Mon; 5 Jul 2010 05:32:28 +0000,Mon; 5 Jul 2010 05:32:28 +0000,,,,,MAPREDUCE-1766,https://issues.apache.org/jira/browse/MAPREDUCE-570
MAPREDUCE-571,Bug,Major,contrib/streaming,Streaming should not crash,Streaming framework should not end with a Java stack dump. All the abnormal conditions should be checked and reported.  Specific conditions that need to be exmplicitly checked by the framework are:  does the input exist?  do the top level executables or scripts for -mapper and exist  Any other Exceptions should also be cought and explained in an error message.,Open,Unresolved,,Unassigned,arkady borkovsky,Tue; 22 Aug 2006 16:09:31 +0000,Mon; 16 Jan 2012 09:53:31 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-571
MAPREDUCE-572,Bug,Minor,contrib/streaming,If #link is missing from uri format of -cacheArchive then streaming does not throw error.,Ran hadoop streaming command as -: bin #linkname;Please specify a different link name for all of your caching URIs ]   Streaming should check about present #link after uri of cacheArchive and should throw proper error .,Resolved,Fixed,,Amareshwari Sriramadasu,Karam Singh,Fri; 22 Feb 2008 14:43:11 +0000,Fri; 4 Jun 2010 09:25:07 +0000,Wed; 2 Jun 2010 08:26:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-572
MAPREDUCE-573,Bug,Major,contrib/streaming,reduce scans/copies while reading data in hadoop streaming,follow up from: http: HADOOP-2826  we copy over an entire line (from readLine) and then we break it into two strings by splitting on tab. So there is an extra scan of the input data and an extra copy based on splitting by tab.  instead if we generalized LineReader to instead read until it hits a delimiter - then we can do it with one less scan and copy. Something like:  byte [] tabDelimiter = new byte 1; tabDelimiter0 = ' r';  while()  { lineReader.setDelimiter(tabDelimiter); lineReader.readLine(key); lineReader.setDelimiter(newlineDelimiter); lineReader.readLine(value); }  (take my proposed interfaces with a pinch of salt. just to convey the idea).,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Tue; 15 Apr 2008 00:00:40 +0000,Thu; 17 Jul 2014 21:57:35 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-573
MAPREDUCE-574,Bug,Major,distributed-cache,Fix -file option in Streaming to use Distributed Cache,The -file option works by putting the script into the job's jar file by unjar-ing; copying and then jar-ing it again. We should rework the -file option to use the DistributedCache and the symlink option it provides.,Resolved,Fixed,,Unassigned,Amareshwari Sriramadasu,Wed; 16 Jan 2008 05:13:00 +0000,Thu; 17 Jul 2014 19:42:53 +0000,Thu; 17 Jul 2014 19:42:53 +0000,,,,,HADOOP-1622,https://issues.apache.org/jira/browse/MAPREDUCE-574
MAPREDUCE-575,Bug,Major,contrib/streaming,Job completes but command doesn't return,I've had a job submission command hang on many different occasions.  I can't tell exactly what makes it complete some times and hang others.  Here's some information about one time when it hanged.  I started a job at 12:40.  Here is the info from 'ps aux' including the full command line:   tmpT9M4cq   At the time of submission; the jobtracker reported receiving the job and began processing it.  The first line in this part of the logs is:  2007-01-29 12:40:44;072 INFO org.apache.hadoop.mapred.JobInProgress: Choosing cached task tip_0002_m_000002   At 13:16; the job completed; with the following normal log messages:  2007-01-29 13:16:36;115 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000001_0' has completed tip_0002_r_000001 successfully. 2007-01-29 13:16:36;117 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000001_0' has completed. 2007-01-29 13:16:36;566 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000002_0' has completed tip_0002_r_000002 successfully. 2007-01-29 13:16:36;566 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000002_0' has completed. 2007-01-29 13:16:36;879 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000003_0' has completed tip_0002_r_000003 successfully. 2007-01-29 13:16:36;879 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000003_0' has completed. 2007-01-29 13:16:41;808 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000000_0' has completed tip_0002_r_000000 successfully. 2007-01-29 13:16:41;930 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000000_0' has completed. 2007-01-29 13:16:41;940 INFO org.apache.hadoop.mapred.JobInProgress: Job job_0002 has completed successfully. 2007-01-29 13:16:41;942 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000002_0' from 'tracker_m4b-3-2.local:50050' ... 2007-01-29 13:16:50;660 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000016_0' from 'tracker_m4b-3-8.local:50050' 2007-01-29 13:16:50;661 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000044_0' from 'tracker_m4b-3-8.local:50050' 2007-01-29 13:16:50;662 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000046_0' from 'tracker_m4b-3-8.local:50050'   At 14:03; the hadoop-streaming command (process 21261) that started at 12:40 was still running and using 0.0% of the CPU.  The output of the command ended with:    INFO streaming.StreamJob: Job complete: job_0002  It seems odd that hadoop-streaming would hang instead of returning.  I hope this information is helpful.  Thanks.,Resolved,Duplicate,HADOOP-4620,Unassigned,Andrew McNabb,Mon; 29 Jan 2007 21:10:13 +0000,Mon; 16 Jan 2012 10:38:36 +0000,Mon; 16 Jan 2012 10:38:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-575
MAPREDUCE-576,Bug,Major,contrib/streaming,writing to status reporter before consuming standard input causes task failure.,"A Hadoop Streaming task which writes a status reporter line before consuming input causes the task to fail.  Writing after consuming input does not fail.  I caused this failure using a Python reducer and writing a ""reporter:status:foo n')           sys.stderr.flush()           print line  The hadoop invocation which I used:  hadoop jar  reducer_foo.py  This is on a 64 node hadoop-ec2 cluster.  One of the errors listed on the failures page (they all appear to be the same):   462)",Resolved,Duplicate,HADOOP-5623,Todd Lipcon,Karl Anderson,Mon; 20 Oct 2008 23:33:34 +0000,Sat; 5 Dec 2009 00:08:35 +0000,Sat; 5 Dec 2009 00:08:35 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-576
MAPREDUCE-577,Bug,Major,contrib/streaming,Duplicate Mapper input when using StreamXmlRecordReader,"I have an XML file with 93626 rows.  A row is marked by row... Node 0	0	1	6	12	12	4.00  I've also noticed something really strange in the job's output.  It looks like it's starting over or redoing things. This was run using all six nodes and no limitations on map or reduce tasks.  I haven't seen this behavior in any other case.    INFO mapred.JobClient:     Reduce output records=2",Closed,Fixed,,Ravi Gummadi,David Campbell,Tue; 3 Jun 2008 14:54:00 +0000,Thu; 15 Aug 2013 21:48:48 +0000,Mon; 5 Jul 2010 10:43:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-577
MAPREDUCE-578,Bug,Critical,contrib/streaming,Unit test fails on linux: org.apache.hadoop.streaming.TestStreamingExitStatus.testReduceFailNotOk,Unit test fails on linux: org.apache.hadoop.streaming.TestStreamingExitStatus.testReduceFailNotOk  This fails on Linux (Red H org.apache.hadoop.streaming.TestStreamingExitStatus.tearDown(TestStreamingExitStatus. 70)  Standard Output  test.build.data-or-user.dir= data,Resolved,Cannot Reproduce,,Unassigned,Mukund Madhugiri,Tue; 11 Mar 2008 20:26:57 +0000,Wed; 9 Jun 2010 07:18:29 +0000,Wed; 9 Jun 2010 07:18:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-578
MAPREDUCE-579,Improvement,Trivial,contrib/streaming,"Streaming ""slowmatch"" documentation","The documentation for the Streaming module do not include any mention of the ""slowmatch"" parameter; which checks for CDATA sections while looking for XML records.  An important point is that ""slowmatch=true"" violates the principle of least surprise: the ""begin"" and ""end"" parameters become regular expressions instead of exact strings.  This is probably a useful feature; but should definitely be noted since users will be tempted to use the XML record reader on not-strictly-xml files; which may require escaping the ""begin"" and ""end"" patterns.",Resolved,Fixed,,Harsh J,Bo Adler,Tue; 1 Jul 2008 22:19:19 +0000,Tue; 30 Aug 2016 01:20:58 +0000,Wed; 25 Mar 2015 09:11:18 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-579
MAPREDUCE-580,Bug,Major,contrib/streaming,Streaming doesn't accept -cluster local,"Here is the bug fix:  ...src  384;385d383      Option cluster = createOption(""cluster"";               ""The cluster to process the data""; ""h|local""; 1; false); 422d419        withOption(cluster). 461d457        System.out.println(""  -cluster h|local optional  overrides cluster config""); 805c801",Resolved,Invalid,,Unassigned,Dick King,Thu; 27 Sep 2007 18:32:48 +0000,Tue; 15 Jun 2010 09:44:11 +0000,Tue; 15 Jun 2010 09:44:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-580
MAPREDUCE-581,Bug,Major,contrib/streaming,slurpHadoop(Path; FileSystem) ignores result of java.io.InputStream.read(byte[]; int; int),org.apache.hadoop.streaming.StreamUtil. io.InputStream.read() which may read fewer bytes than requested.,Resolved,Invalid,,Unassigned,Nigel Daley,Mon; 14 May 2007 22:19:40 +0000,Tue; 6 Jul 2010 10:38:54 +0000,Tue; 6 Jul 2010 10:38:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-581
MAPREDUCE-582,Bug,Major,contrib/streaming,Streaming: if streaming command finds errors in the --config ; it reports that the input file is not found and fails,The error message is   ERROR streaming.StreamJob: Error Launching job : Input Pattern ...... * matches 0 files which is quite confusing and scary. Neds better error handling.,Resolved,Cannot Reproduce,,Unassigned,arkady borkovsky,Tue; 27 Nov 2007 22:52:36 +0000,Tue; 15 Jun 2010 11:41:46 +0000,Tue; 15 Jun 2010 11:41:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-582
MAPREDUCE-583,Bug,Major,contrib/streaming,get rid of excessive flushes from PipeMapper/Reducer,there's a flush on the buffered output streams in mapper 4 Hadoop to Tool                                                                                                                          if (numExceptions_ == 0) {         if (!this.ignoreKey)  {           write(key);           clientOut_.write(' n');         }         clientOut_.flush();       } else  {         numRecSkipped_++;       }  tried to measure impact of removing this. number of context switches reported by vmstat shows marked decline.   with flush (10 second intervals):  r  b   swpd   free   buff  cache   si   so    bi    bo   in    cs us sy id wa  4  2    784  23140  83352 3114648    0    0  4819 32397 1175 13220 59 11 13 17  1  2    784 129724  80704 3075696    0    0  4614 27196 1156 14797 49 11 19 21  4  0    784  24160  83440 3174880    0    0    96 36070 1337 10976 67 11  9 12  5  0    784 155872  84400 3158840    0    0   125 44084 1280 11044 68 14 10  8  2  1    784 365128  87048 2892032    0    0   119 38472 1317 11610 69 14 10  7  without flush:  5  0    784  24652  56056 3217864    0    0   310 29499 1379  7603 76  9  7  8  5  3    784 118456  54568 3209992    0    0  3249 33426 1173  6828 63 11 12 14  0  2    784 227628  54820 3198560    0    0  7840 30063 1146  8899 60 10 15 15  3  1    784  25608  55048 3313512    0    0  3251 36276 1194  7915 60 10 15 15  1  2    784 197324  49968 3194572    0    0  4714 35479 1281  8204 62 13 12 13  cs goes down by about 20-30%. but having trouble measuring overall speed improvement (too many variables due to spec. execution etc. - need better benchmark).  can't hurt.,Resolved,Duplicate,HADOOP-3429,Unassigned,Joydeep Sen Sarma,Sat; 5 Apr 2008 08:44:31 +0000,Tue; 6 Jul 2010 11:17:28 +0000,Tue; 6 Jul 2010 11:17:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-583
MAPREDUCE-584,Bug,Minor,contrib/streaming,In Streaming; crashes after all the input is consumed; are not detected,In a Hadoop Streaming; if the user code crashes after all the input has been consumed; the framework considers the process to be successful.,Resolved,Fixed,,Unassigned,arkady borkovsky,Fri; 2 Mar 2007 08:08:49 +0000,Thu; 17 Jul 2014 16:51:09 +0000,Thu; 17 Jul 2014 16:51:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-584
MAPREDUCE-585,Bug,Minor,contrib/streaming,A corrupt text file causes the maps to hang,A corrupt file hangs a map. The map keeps reading the same record again and again and never finishes.,Resolved,Incomplete,,Unassigned,Mahadev konar,Wed; 7 Feb 2007 01:37:53 +0000,Thu; 17 Jul 2014 16:48:52 +0000,Thu; 17 Jul 2014 16:48:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-585
MAPREDUCE-586,Bug,Major,contrib/streaming,Streaming reducers throw OutOfMemory for not so large inputs,I am seeing OutOfMemoryError for moderate size inputs (~70 text files; 20k each ) causing job to fail in streaming. For very small inputs it still succeeds. Looking into details.,Resolved,Invalid,,Unassigned,Sanjay Dahiya,Tue; 12 Dec 2006 14:25:42 +0000,Mon; 16 Jan 2012 10:23:12 +0000,Mon; 16 Jan 2012 10:23:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-586
MAPREDUCE-587,Bug,Minor,contrib/streaming,Stream test TestStreamingExitStatus fails with Out of Memory,contrib X Mac -same problem does not surface on Linux.,Closed,Fixed,,Amar Kamat,Steve Loughran,Sun; 24 May 2009 16:08:56 +0000,Tue; 15 Nov 2011 00:49:17 +0000,Fri; 10 Jun 2011 23:16:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-587
MAPREDUCE-588,Bug,Minor,contrib/streaming,streaming failed without printing out the cause (IllegalArgumentException),When looking at HADOOP-5259; streaming failed as   $ $HADOOP_HOME streamjob27613.jar tmpDir=null Streaming Command Failed! $ echo $? 1,Resolved,Duplicate,MAPREDUCE-1155,Unassigned,Koji Noguchi,Fri; 13 Feb 2009 23:32:53 +0000,Wed; 9 Jun 2010 05:16:41 +0000,Wed; 9 Jun 2010 05:16:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-588
MAPREDUCE-589,Bug,Major,contrib/streaming,StreamXMLRecordReader does not support gzipped files,I am using Hadoop Streaming to analyze Wikipedia data files; which are in XML format and are compressed because they are so large.  While doing some preliminary tests; I discovered that you cannot use StreamXMLRecordReader with gzipped data files  the data is fed into the mapper script as raw data.,Resolved,Incomplete,,Unassigned,Bo Adler,Sun; 15 Jun 2008 06:23:36 +0000,Fri; 18 Jul 2014 05:36:38 +0000,Fri; 18 Jul 2014 05:36:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-589
MAPREDUCE-590,Bug,Minor,contrib/streaming,permissions of local files change when using the -file option,When running hadoop streaming; all files mentioned in the -file option have their permissions changed from default to 777.  If the files are not readable by the owner before hadoop is run the job fails but permissions are still changed (and thus; for example; the job will succeed if run again immediately).,Resolved,Fixed,,Unassigned,S. Alex Smith,Tue; 29 Jul 2008 23:58:41 +0000,Fri; 18 Jul 2014 19:53:07 +0000,Fri; 18 Jul 2014 19:53:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-590
MAPREDUCE-591,Bug,Major,contrib/streaming,TestStreamingStderr fails occassionally,TestStreamingStderr fails occassionally with a timeout on trunk.,Resolved,Cannot Reproduce,,Unassigned,Hemanth Yamijala,Wed; 17 Jun 2009 06:11:11 +0000,Tue; 6 Jul 2010 10:44:57 +0000,Tue; 6 Jul 2010 10:44:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-591
MAPREDUCE-592,Bug,Minor,contrib/streaming,Streaming does not checks whether  -mapper option is provided or not,Ran hadoop command as -: bin hadoop-*-streaming.jar -input in -output out (Here no mapper is provided using -mapper option). Stream job will start and map of that job fails.  Streaming should check about the presence of -mapper option and throw proper error is it not there.,Resolved,Duplicate,MAPREDUCE-1888,Unassigned,Karam Singh,Fri; 22 Feb 2008 13:18:05 +0000,Mon; 5 Jul 2010 05:30:53 +0000,Mon; 5 Jul 2010 05:30:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-592
MAPREDUCE-593,Bug,Major,contrib/streaming,org.apache.hadoop.streaming.TestUlimit fails on JRockit 64-bit; not enough memory,the testUlimit test sets a memory limit that is too small for Java to start. So it fails with a -1 response instead; which breaks the test.,Resolved,Won't Fix,,Unassigned,Steve Loughran,Mon; 1 Sep 2008 13:44:10 +0000,Fri; 18 Jul 2014 22:39:42 +0000,Fri; 18 Jul 2014 22:39:42 +0000,,,,,MAPREDUCE-3594,https://issues.apache.org/jira/browse/MAPREDUCE-593
MAPREDUCE-594,Bug,Major,contrib/streaming,Streaming: org.apache.hadoop.mapred.lib.IdentityMapper should not inserted unnecessary keys,When streaming command specifies  -mapper org.apache.hadoop.mapred.lib.IdentityMapper the reducer should receive exactly the same text lines as where present in the input. The only modification is the reordering the input. Currently; org.apache.hadoop.mapred.lib.IdentityMapper inserts ofsets in the input as keys.  Which renders it useless.  Moreover; in the latest release org.apache.hadoop.mapred.lib.IdentityMapper just crashes:  1760)  (I open only one bug; as it is broken anyway; the new behavior does not actually make it any worse than before),Resolved,Fixed,,Unassigned,arkady borkovsky,Sat; 15 Dec 2007 01:51:30 +0000,Thu; 17 Jul 2014 19:12:19 +0000,Thu; 17 Jul 2014 19:12:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-594
MAPREDUCE-595,Bug,Minor,contrib/streaming,streaming command line does not honor -jt option,"ran hadoop streaming command as -: bin hadoop-*-streaming.jar -input input path -mapper mapper -reducer reducer -output output path  -dfs h -jt h  (Make sure hadoop-site.xml is not in config dir. dfs abnd jt are running ) Streaming will run as local runner  On looking at StreamJob. following was found -: String jt = (String)cmdLine.getValue(""mapred.job.tracker"");       if (null != jt) {         userJobConfProps_.put(""fs.default.name""; jt);               } Where usage is having create option like -: Option jt = createOption(""jt"";                               ""Optional. Override JobTracker configuration""; ""h|local""; 1; false);",Resolved,Invalid,,Unassigned,Karam Singh,Fri; 22 Feb 2008 13:08:42 +0000,Tue; 15 Jun 2010 11:47:45 +0000,Tue; 15 Jun 2010 11:47:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-595
MAPREDUCE-596,Bug,Major,contrib/streaming,can't package zip file with hadoop streaming -file argument,"I'm unable to ship a file with a .zip suffix to the mapper using the -file argument for hadoop streaming.  I am able to ship it if I change the suffix to .zipp.  Is this a bug; or perhaps has something to do with the jar file format which is used to send files to the instance?  For example; with this hadoop invocation; and local files "" streamjob6900.jar tmpDir=null  But in the current directory of the mapper process; ""boto.zip"" does not exist; while ""boto.zipp"" does.",Resolved,Invalid,,Unassigned,Karl Anderson,Tue; 22 Jul 2008 22:15:51 +0000,Tue; 8 Jun 2010 11:51:33 +0000,Tue; 8 Jun 2010 11:51:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-596
MAPREDUCE-597,New Feature,Major,contrib/streaming,recovery after sybchronous Mapper failures on some records,"Ii is sometimes hard or impossible to make sure that the Mapper reacts correctly to all the errors in the input data  especially when reusing legacy or 3rd party code. It would be nice if Streaming infrastructure had the following feature:  	check the exit code of the mapper command; 	if the command has crashed 	log the record that was processed during the failure to the error log 	restart the command 	feed it the remainder of the input This way most of the data gets processed.    This feature should be disabled by default  the user should explicitly specify how many faults are allowed per task. Once the number is exceeded; the whole job should fail without retries.  BTW: this functionality was described in the original MapReduce paper.",Open,Unresolved,,Unassigned,arkady borkovsky,Fri; 10 Aug 2007 19:03:19 +0000,Tue; 13 Jul 2010 03:46:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-597
MAPREDUCE-598,Improvement,Major,contrib/streaming,Streaming: better conrol over input splits,"In steaming; the map command usually expect to receive it's input uninterpreted  just as it is stored in DFS. However; the split (the beginning and the end of the portion of data that goes to a single map task) is often important and is not ""any line break"". Often the input consists of multi-line docments  e.g. in XML.  There should be a way to specify a pattern that separates logical records. Existing ""Streaming XML record reader"" kind of provides this functionality.  However; it is accepted that ""Streaming XML"" is a hack and needs to be replaced",Resolved,Fixed,MAPREDUCE-606;MAPREDUCE-5018;HADOOP-3341,Unassigned,arkady borkovsky,Mon; 26 Nov 2007 18:46:41 +0000,Thu; 17 Jul 2014 18:47:46 +0000,Thu; 17 Jul 2014 18:47:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-598
MAPREDUCE-599,Improvement,Major,contrib/streaming,Unifying Hadoop Steaming/Hadoop Pipe,Hadoop Streaming and Pipe have many similarities. It is worthwhile to examine how to factor out the commonality in the implementation and to unify the user interface as much as possible.,Open,Unresolved,,Unassigned,Runping Qi,Fri; 4 May 2007 21:47:39 +0000,Wed; 22 Sep 2010 17:46:26 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-599
MAPREDUCE-600,Improvement,Major,contrib/streaming,"Streaming command should be able to take its input from a ""file""; rather then from stdin",In some cases; especially when a streaming command is a 3rd party or legacy application;  it is impossible of inconvenient to make it take its input from stdin. The command may require that the input file name is specified as a command line option; or the input file name is hard coded.  The streaming infrastructure should allow to specify a name that can be used in open() to create an input stream equivalent to what would be fed to a streaming command as stdin by default.,Resolved,Won't Fix,,Unassigned,arkady borkovsky,Tue; 20 Nov 2007 22:05:51 +0000,Thu; 17 Jul 2014 18:32:49 +0000,Thu; 17 Jul 2014 18:31:50 +0000,,,,,MAPREDUCE-1769,https://issues.apache.org/jira/browse/MAPREDUCE-600
MAPREDUCE-601,Bug,Major,contrib/streaming,Streaming command should be logged on the cluster,Currently; when a streaming job fails; it is difficult for the cluster administrator to figure out what was going on. Logging all streaming commands in a centralized place will make trouble shooting more efficient.,Resolved,Invalid,,Unassigned,arkady borkovsky,Thu; 30 Nov 2006 00:57:44 +0000,Fri; 2 Jul 2010 07:14:07 +0000,Fri; 2 Jul 2010 07:14:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-601
MAPREDUCE-602,Bug,Major,contrib/streaming,The streaming code should be moved from contrib to Hadoop main framework,Before the actual move; the code needs a bit of further clean up in the following areas:  1. coding style convention; and code quality  2. XMLRecordReader: the current implementation is too hacky.  3. Better  oc,Resolved,Fixed,,Unassigned,Runping Qi,Fri; 4 May 2007 21:43:49 +0000,Thu; 17 Jul 2014 17:06:16 +0000,Thu; 17 Jul 2014 17:06:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-602
MAPREDUCE-603,Bug,Major,contrib/streaming,Fix unchecked warnings in contrib code,There are unchecked warnings in abacus; data_join and streaming.,Resolved,Unresolved,,Unassigned,Tom White,Sat; 21 Apr 2007 07:28:30 +0000,Thu; 17 Jul 2014 16:43:04 +0000,Thu; 17 Jul 2014 16:43:04 +0000,,,,,HADOOP-1190,https://issues.apache.org/jira/browse/MAPREDUCE-603
MAPREDUCE-604,Improvement,Minor,contrib/streaming,Streaming use static methods to get/set jobconf parameters.,Streaming uses a lot of jobconf.get set() methods are not spread around in the codebase.,Open,Unresolved,,Unassigned,Mahadev konar,Thu; 7 Dec 2006 23:31:50 +0000,Thu; 24 Sep 2015 16:04:36 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-604
MAPREDUCE-605,New Feature,Major,contrib/streaming,In Streaming; allow different mappers for different subsets of the input,The command line may look like this:  -mapper mapper-command-1 -input dir11   -mapper mapper-command-2 -input dir22  input -dir21  meaning that map phase will apply mapper-command-1 to part files from dir11; and the part files from dir22 and dir21 will be processed by mapper-command-2 then all will be shuffled and processed by a single reducer.,Open,Unresolved,,Unassigned,arkady borkovsky,Mon; 26 Nov 2007 17:29:00 +0000,Thu; 2 May 2013 02:29:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-605
MAPREDUCE-606,Bug,Major,contrib/streaming,Implement a binary input/output format for Streaming,Lots of streaming applications process textual data with 1 record per line and fields separated by a delimiter. It turns out that there is no point in using any of Hadoop's input output formats in these cases were pure-overhead.,Resolved,Fixed,MAPREDUCE-598,Unassigned,Arun C Murthy,Thu; 10 Apr 2008 07:22:50 +0000,Fri; 18 Jul 2014 05:09:24 +0000,Fri; 18 Jul 2014 05:09:24 +0000,,,,,HADOOP-1722,https://issues.apache.org/jira/browse/MAPREDUCE-606
MAPREDUCE-607,Bug,Minor,contrib/streaming,Streaming has its own methods to monitor jobs. It should use the jobclient methods to monitor the jobs,The job monitor methods in streaming has duplicated code. It should use the jobclient methods with retries.,Resolved,Duplicate,MAPREDUCE-1773,Unassigned,Mahadev konar,Fri; 15 Dec 2006 19:32:40 +0000,Wed; 9 Jun 2010 07:26:53 +0000,Wed; 9 Jun 2010 07:26:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-607
MAPREDUCE-608,Bug,Major,contrib/streaming,"Streaming should support addition output (""side-effect"")",#NAME?,Open,Unresolved,,Unassigned,arkady borkovsky,Thu; 24 Aug 2006 21:55:14 +0000,Mon; 22 Jun 2009 15:06:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-608
MAPREDUCE-609,Improvement,Major,contrib/streaming,Streaming: better support for command lines or streaming command,Quite often; the command line for streaming mapper or reducer needs to use one or two levels of quotes. This make it inconvenient or impossible to pass the commands in the streaming command line. It would be good to have streaming take its specification from a file  especially as longer streaming commands are not typed in; but are either run from files (shell scripts) or generated by other processors.  The current work around is to separate files for the mapper command; for the reducer command; and for the streaming command itself.  This works; but is inconvenient and quite error-prone. Having just one file with all three would be good.,Open,Unresolved,,Unassigned,arkady borkovsky,Fri; 30 Nov 2007 22:19:02 +0000,Mon; 12 Jul 2010 11:29:24 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-609
MAPREDUCE-610,Improvement,Major,contrib/streaming,Streaming: user produced stderr should be available while the job is still running; with no extra text inserted,"This functionality should look like this:  	when a streaming job is run; two additional DFS directories are created  one for mapper stderr; another for reducer stderr.   (The names of the directories may be specified by the user; or may be defaulted to something derived from the output name  e.g. is the output directory is XYZ; the stderr directories may me XYZ.log.map and XYZ.log.reduce) 	for each task; a file is created in the corresponding stderr directory 	the stderr produced by a (map or reduce) task shows up in the DFS as the task is running.  From user perspective; it should like the lines written by the streaming command are appended to the corresponding DFS file.     This may be useful outside streaming as well.  However;  (a) in Java applications; there are other features a task may use to communicate with the Main (b) the implementation of capturing stderr is different in Java MapReduce and in Streaming.",Open,Unresolved,,Unassigned,arkady borkovsky,Mon; 26 Nov 2007 19:15:48 +0000,Tue; 13 Jul 2010 03:32:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-610
MAPREDUCE-611,Bug,Major,contrib/streaming,Streaming infrastructure should report information about runtime errors ,For example; if the streaming command is Perl script an syntax error or a runtime error occurs during script execution; the error message (the stack trace) should be reported to the user; separate from and in addition to the rest of the logs and the stderr output.,Resolved,Won't Fix,,Unassigned,arkady borkovsky,Wed; 21 Nov 2007 01:02:23 +0000,Thu; 17 Jul 2014 18:35:55 +0000,Thu; 17 Jul 2014 18:35:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-611
MAPREDUCE-612,Bug,Minor,contrib/streaming,streaming should default to KeyValueTextInputFormat with IdentityMapper,in 15.3 - streaming defaults to TextInputForm would resolve both of these problems. This would change default behavior though - so a little leery ..  using '-mapper cat' is the common workaround - but it just seems like a needless waste of resources ..,Resolved,Duplicate,MAPREDUCE-1766,Unassigned,Joydeep Sen Sarma,Thu; 24 Apr 2008 17:51:00 +0000,Mon; 5 Jul 2010 06:00:57 +0000,Mon; 5 Jul 2010 05:27:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-612
MAPREDUCE-613,Bug,Major,contrib/streaming,Streaming should allow to re-start the command if it failed in the middle of input,"Sometimes; we need to use imperfect programs to process data.  Recently; I used a public domain program that did what I needed; but crashed after processing few million records (in my case; more than half of the mappers would succeed; with the rest failing at different %%).  It would be nice to be able to tell the Streaming Framework :       if the streaming command fails at some input record (and you get ""pipe broken"" from it);       restart the command and continue feeding it the data.      Please log the failing record.  In textmining; quite often; loosing few record of the input makes no  difference at all. Of course this feature should be disabled by default; and should some ""are really sure"" provision.  (an expert feature).",Resolved,Duplicate,NULL,Unassigned,arkady borkovsky,Fri; 8 Jun 2007 01:05:32 +0000,Mon; 12 Jul 2010 11:14:40 +0000,Mon; 12 Jul 2010 11:14:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-613
MAPREDUCE-614,Bug,Major,contrib/streaming,Streaming partitioner should allow command; not just Java class,Since HADOOP-4842 got committed; Streaming allows both commands and Java classes to be specified as mapper; reducer; and combiner; but the -partitioner option is still limited to Java classes only. Allowing commands to be specified as partitioner as well would greatly improve the flexibility of Streaming programs.,Open,Unresolved,,Unassigned,Klaas Bosteels,Fri; 5 Jun 2009 08:23:49 +0000,Fri; 17 Nov 2017 04:41:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-614
MAPREDUCE-615,Bug,Major,contrib/streaming,need more unit tests for Hadoop streaming,nan,Resolved,Invalid,,Unassigned,Runping Qi,Tue; 10 Apr 2007 16:08:40 +0000,Tue; 6 Jul 2010 11:37:26 +0000,Tue; 6 Jul 2010 11:37:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-615
MAPREDUCE-616,Bug,Major,contrib/streaming,"Streaming: when a job is killed; the message should say it was ""killed"" rather than ""failed""",nan,Resolved,Duplicate,MAPREDUCE-1811,Unassigned,arkady borkovsky,Mon; 3 Dec 2007 18:12:51 +0000,Wed; 9 Jun 2010 07:11:39 +0000,Wed; 9 Jun 2010 07:11:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-616
MAPREDUCE-617,Bug,Minor,contrib/streaming,Streaming should not throw java.lang.RuntimeException and ERROR while displaying help,"Run streaming command as -: bin hadoop-streaming.jar -info  Exception in thread ""main""  155)  It should not display execption and -input and error about missin -input option",Resolved,Fixed,,Unassigned,Karam Singh,Fri; 22 Feb 2008 13:24:08 +0000,Fri; 18 Jun 2010 10:56:11 +0000,Fri; 18 Jun 2010 10:56:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-617
MAPREDUCE-618,Improvement,Major,,Need to be able to re-run specific map tasks (when -reducer NONE),"Sometimes; a few map tasks fail and -reducer NONE.   It should be possible to rerun the failed map tasks . There are several failure modes:  	a task is hanging; so the job is killed 	from the infrastructure perspective; the task has completed successfully ; but it failed to produces correct result 	failed in the proper Hadoop sense It is often too expensive to rerun the whole job.  And for larger jobs; chances are each run will have a few failed tasks.",Open,Unresolved,,Unassigned,arkady borkovsky,Sat; 1 Dec 2007 18:33:55 +0000,Thu; 17 Jul 2014 18:58:46 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-618
MAPREDUCE-619,Bug,Major,contrib/streaming,Include more detail in the exception message when a streaming task fails,When debugging streaming programs; it would be useful to have the last few lines from stderr in the exception message (which is shown in the task's status display).,Open,Unresolved,,Unassigned,Tom White,Fri; 18 Jul 2008 13:46:44 +0000,Mon; 22 Jun 2009 15:06:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-619
MAPREDUCE-620,Improvement,Major,contrib/streaming,Streaming: support local execution,For streaming; local execution does not involve hadoop. It is just   hdfs -cat input | mapper-command | sort | reducer command  While a user can do this herself; having an option to do this by using the infrastructure would greatly simplify user script and and make it easier to ensure that the process will run on the cluster as expected.,Resolved,Won't Fix,,Unassigned,arkady borkovsky,Mon; 26 Nov 2007 19:23:00 +0000,Thu; 17 Jul 2014 18:49:05 +0000,Thu; 17 Jul 2014 18:49:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-620
MAPREDUCE-621,Bug,Major,contrib/streaming,"hadoop streaming to support shell pipes: ""tr ' ' '\t' | cut -f 3;4""",Hadoop streaming does not support shell pipes; but a lot of times shell pipes are very useful for processing streams of data.  I don't see any reason that hadoop streaming cannot support it.,Resolved,Not A Problem,,Unassigned,Zheng Shao,Wed; 14 May 2008 02:41:19 +0000,Fri; 18 Jul 2014 05:22:16 +0000,Fri; 18 Jul 2014 05:22:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-621
MAPREDUCE-622,Bug,Minor,contrib/streaming,Streaming should include more unit tests to test more features that it provides.,Currently streaming has only one test that runs with ant test. It should include more tests to check for the features that streaming provides.,Resolved,Invalid,,Unassigned,Mahadev konar,Thu; 19 Oct 2006 18:06:15 +0000,Tue; 6 Jul 2010 10:50:24 +0000,Tue; 6 Jul 2010 10:50:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-622
MAPREDUCE-623,Improvement,Major,build,Resolve javac warnings in mapred,Towards a solution for HADOOP-5628; we need to resolve all   warnings where ever possible and suppress them where resolution is not possible.,Resolved,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Mon; 13 Apr 2009 11:10:28 +0000,Thu; 18 Mar 2010 22:07:42 +0000,Thu; 18 Feb 2010 09:15:24 +0000,,,,HADOOP-5628;MAPREDUCE-670,PIG-1033,https://issues.apache.org/jira/browse/MAPREDUCE-623
MAPREDUCE-624,Bug,Major,,Improve memory cache utilization in BackupStore (while supporting Mark/Reset),HADOOP-5266 introduced support for Mark Reset of Values Iterator by backing up keys and values to a BackupStore. The current design does not create a memory segment once a file segment has been created; even if space is available. The design could be optimized to consider memory for a new segment irrespective of where the previous segments have been created.,Open,Unresolved,,Jothi Padmanabhan,Jothi Padmanabhan,Mon; 4 May 2009 05:40:57 +0000,Mon; 22 Jun 2009 15:08:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-624
MAPREDUCE-625,Improvement,Minor,,Modify TestTaskLimits to improve execution time,With some small modifications like using a sleep job instead of PI Estimator and using localFS instead of DFS; the run time of this test can be reduced almost by half.,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Tue; 9 Jun 2009 04:45:33 +0000,Tue; 24 Aug 2010 21:13:55 +0000,Fri; 3 Jul 2009 06:15:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-625
MAPREDUCE-626,Bug,Minor,,Modify TestLostTracker to improve execution time,This test can be made faster with a few modifications,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Wed; 10 Jun 2009 06:15:22 +0000,Tue; 24 Aug 2010 21:13:56 +0000,Thu; 16 Jul 2009 08:31:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-626
MAPREDUCE-627,Bug,Minor,,Modify TestTrackerBlacklistAcrossJobs to improve execution time,Some minor modifications can be made to the test case to improve test execution time,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Tue; 9 Jun 2009 06:47:37 +0000,Tue; 24 Aug 2010 21:13:56 +0000,Thu; 16 Jul 2009 05:44:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-627
MAPREDUCE-628,Bug,Minor,,TestJobInProgress brings up MinMR/DFS clusters for every test,TestJobInProgress brings up MiniMR clusters in setUp and brings it down in tearDown methods. Since these methods are called before each test; the test brings up down the cluster several times. Instead; the cluster should just be brought up once; all tests run and then brought down,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Thu; 4 Jun 2009 06:01:19 +0000,Tue; 24 Aug 2010 21:13:57 +0000,Wed; 29 Jul 2009 10:07:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-628
MAPREDUCE-629,Bug,Minor,,Modify TestQueueManager to improve execution time,With a few small changes; the run time of this test can be brought down by half.,Resolved,Duplicate,MAPREDUCE-28,Unassigned,Jothi Padmanabhan,Thu; 11 Jun 2009 10:46:50 +0000,Fri; 21 May 2010 08:04:31 +0000,Fri; 21 May 2010 08:04:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-629
MAPREDUCE-630,Bug,Minor,,TestKillCompletedJob can be modified to improve execution times,This test can be easily made into a unit test,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Wed; 17 Jun 2009 14:56:37 +0000,Tue; 24 Aug 2010 21:13:57 +0000,Thu; 16 Jul 2009 05:48:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-630
MAPREDUCE-631,Bug,Minor,,TestJobInProgressListener brings up MinMR/DFS clusters for every test,TestJobInProgressListener brings up down the cluster several times. Instead; the cluster should just be brought up once; all tests run and then brought down,Resolved,Duplicate,MAPREDUCE-153,Jothi Padmanabhan,Jothi Padmanabhan,Thu; 4 Jun 2009 07:48:06 +0000,Mon; 6 Jul 2009 07:43:27 +0000,Mon; 6 Jul 2009 07:42:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-631
MAPREDUCE-632,Improvement,Major,,Merge TestCustomOutputCommitter with TestCommandLineJobSubmission,TestCommandLineJobSubmission tests job submisison with different command line options. This can be easily enhanced to test custom output committer too and we can do away with TestCustomOutputCommitter,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Fri; 5 Jun 2009 07:03:55 +0000,Tue; 24 Aug 2010 21:13:58 +0000,Fri; 10 Jul 2009 12:04:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-632
HADOOP-6654,Bug,Trivial,io,Example in WritableComparable javadoc doesn't compile,See http: API-Documentation-question---WritableComparable-tt20967409.html.,Closed,Fixed,,Tom White,Tom White,Tue; 16 Dec 2008 14:01:45 +0000,Tue; 24 Aug 2010 20:42:28 +0000,Fri; 26 Mar 2010 17:39:10 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-6654
MAPREDUCE-634,Bug,Minor,examples,Jython WordCount.py example fails with Java >= 1.4,"I had a hard time getting the Jython WordCount.py example to work due to changes to Java:     cd ~ getopt. 268: as of release 1.4;    'assert' is a keyword; and may not be used as an identifier    (try -source 1.3 or lower to use 'assert' as an identifier)            if (frame.getglobal(""_debug"").nonzero_())    Py.assert(frame.getglobal(""len"")._call_(frame.getlocal(2))._eq(i$9));  To work around the problem; I updated the compile file.  I added '--compileropts ""-source 1.3""' to the jythonc call.  Perhaps the underlying problem is Jython-specific; but at least there's a workaround for us.",Resolved,Not A Problem,,Unassigned,Shannon -jj Behrens,Fri; 5 Jan 2007 02:30:30 +0000,Mon; 16 Jan 2012 19:39:44 +0000,Mon; 16 Jan 2012 10:26:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-634
MAPREDUCE-635,Bug,Minor,examples,IllegalArgumentException is thrown if mapred local dir is not writable.,"If specified mapred local directory doesn't have write permission or is non-existent  then ""IllegalArgumentException"" is thrown. Following error message was displayed while running a sleep job with non-writable mapred local directory specified in mapred-site.xml.   sleep job command : $hadoop_home hadoop jar hadoop-examples.jar sleep -m 100 -r 10   2009-05-12 05:36:46;491 INFO org.apache.hadoop.mapred.TaskInProgress: Error from  org.apache.hadoop.mapred.Child.main(Child. 170)  This error message(i.e. IllegalArgumentException) ;somehow; doesn't clearly indicate that problem is with mapred local directory. Error message should be more specific in this case.",Resolved,Duplicate,HADOOP-6766,Unassigned,Suman Sehgal,Tue; 12 May 2009 12:40:22 +0000,Fri; 25 Sep 2015 17:11:16 +0000,Mon; 21 Sep 2015 00:54:28 +0000,,,newbie,,HADOOP-8437,https://issues.apache.org/jira/browse/MAPREDUCE-635
MAPREDUCE-636,Bug,Minor,examples,Inconsistency in config parameter for RandomWriter,All configuration parameters for RandomWriter start with the suffix test.randomwrite; except for test.randomwriter.maps_per_host. Minor inconsistency to fix.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Fri; 16 Nov 2007 11:48:50 +0000,Tue; 10 Feb 2015 22:13:06 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-636
MAPREDUCE-637,Bug,Major,examples,Check in the codes that compute the 10^15+1st bit of   ,We have an improved version of the current BaileyBorwinPlouffe example; which able to compute at least the10^15+1st bit of  .  See also http: hadoop_computes_the_10151st_bi.html,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 13 May 2009 18:21:28 +0000,Tue; 24 Aug 2010 21:13:58 +0000,Wed; 1 Jul 2009 01:37:38 +0000,,,,,HADOOP-5052;MAPREDUCE-691;MAPREDUCE-1923,https://issues.apache.org/jira/browse/MAPREDUCE-637
MAPREDUCE-638,Bug,Minor,examples,Eliminate floating point arithmetic in PiEstimator,The floating point computation in point generation and classification should be replaced by integer arithmetic.,Open,Unresolved,,Unassigned,Tsz Wo Nicholas Sze,Fri; 14 Nov 2008 01:09:35 +0000,Sat; 19 Jul 2014 00:10:07 +0000,,,,newbie,,HADOOP-4437,https://issues.apache.org/jira/browse/MAPREDUCE-638
MAPREDUCE-639,Bug,Major,examples,Update the TeraSort to reflect the new benchmark rules for '09,The terabyte sort rules have been changed and the example should be updated to match them.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Wed; 22 Apr 2009 02:24:54 +0000,Tue; 24 Aug 2010 21:13:59 +0000,Sat; 19 Sep 2009 00:26:37 +0000,,,,MAPREDUCE-361,,https://issues.apache.org/jira/browse/MAPREDUCE-639
MAPREDUCE-640,Bug,Major,examples,Make the Reader for sampling TeraSort input multithreaded,The TeraSort sampler that reads from multiple splits to come up with the partition information can be made multi-threaded; where multiple threads would read from multiple splits concurrently. That should lead to better performance and also we could attempt at sampling more records to arrive at a better partition info.,Open,Unresolved,,Devaraj Das,Devaraj Das,Thu; 25 Dec 2008 09:51:29 +0000,Mon; 22 Jun 2009 15:10:03 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-640
MAPREDUCE-641,Bug,Trivial,examples,WordCount unit test plus a helper class to facilitate testing Mappers and Reducers,There are to pieces to this The first is a test for WordCount; not because word count actually needed one but because it would be useful to beginners to have an example of how to unit test Mappers and Reducers.  The second piece is AOutputCollector and it's associated unit test TestAOutputCollector. This is an abstract class that can be quickly extended by a stub OutputCollector in your unit tests to collect the output from your Mapper and Reducer tests and make it available for easy retreival when testing to see if the fourth key that was emitted was the one you expected.  I think that this would be a useful tool to have in the main test folder but wasn't sure where would be best to put it. Also; since nothing else in Hadoop uses Hungarian notation you'll probably want to rename it. I didn't because I'm not confident about the naming conventions here and figured that since it  and its test probably wouldn't end up living in the same folder as WordCount that you could just rename it when you moved it.,Resolved,Not A Problem,,Unassigned,Kate Rhodes,Sat; 22 Sep 2007 21:30:54 +0000,Sun; 26 Jun 2011 20:43:51 +0000,Sun; 26 Jun 2011 20:43:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-641
MAPREDUCE-642,Bug,Major,distcp,distcp could have an option to preserve the full source path,It would be helpful to have an option that preserves the full source path when copying files from one location to another. This is specially important when archiving moving files from one cluster to another one.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Thu; 14 May 2009 01:14:52 +0000,Thu; 2 May 2013 02:29:25 +0000,Wed; 1 Jul 2009 13:45:53 +0000,,0.21.0,,HDFS-220,MAPREDUCE-689,https://issues.apache.org/jira/browse/MAPREDUCE-642
MAPREDUCE-643,Bug,Major,distcp,distcp -pugp error message is not clear when chgrp fail.,To achieve rsync-like behavior between a local directory and an HDFS instance; a pseudo-distributed MapReduce cluster was started; connected to a fully distributed HDFS instance. An initial distcp from HDFS down to the local fileystem succeeded. The following day; another distcp was run with:  $ bin raw  It failed; its output is below:    INFO mapred.JobClient: Task Id :  org.apache.hadoop.tools.DistCp.main(DistCp. 788)   This distcp update operation does succeed without -pugp.,Resolved,Incomplete,,Unassigned,Aaron Kimball,Thu; 11 Jun 2009 23:47:22 +0000,Tue; 22 Jul 2014 21:11:42 +0000,Tue; 22 Jul 2014 21:11:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-643
MAPREDUCE-644,Bug,Major,distcp,distcp does not skip copying file if we are updating single file,distcp doesn't skip copying file when we do -update on single file if the destfile already exists.  When we do   hadoop distcp -update srcfilename destfilename  it seems to be comparing checksums of srcfilename and destfilename srcfilename and so skip is not done. It should compare checksums of srcfilename and destfilename.,Resolved,Duplicate,MAPREDUCE-648,Ravi Gummadi,Ravi Gummadi,Tue; 16 Jun 2009 08:32:57 +0000,Tue; 15 Sep 2009 06:01:04 +0000,Tue; 15 Sep 2009 06:01:04 +0000,,,,MAPREDUCE-648,,https://issues.apache.org/jira/browse/MAPREDUCE-644
MAPREDUCE-645,Bug,Minor,distcp,When disctp is used to overwrite a file; it should return immediately with an error message,"When disctp is triggered to copy a directory to an already existing file; it just shows a ""copy failed"" error message after 4 attempts without showing any useful error message. This is extremely time consuming on a large cluster and especially when the directory being copied contains several sub-directories. Instead; it would be an improvement if distcp could return immediately displaying a useful error message when an user attempts such an operation. (This is an unlikely situation but still a valid test case)",Closed,Fixed,,Ravi Gummadi,Ramya Sunil,Thu; 5 Feb 2009 12:08:28 +0000,Tue; 24 Aug 2010 21:14:01 +0000,Fri; 18 Sep 2009 06:54:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-645
MAPREDUCE-646,Bug,Major,distcp,distcp should place the file distcp_src_files in distributed cache,When large number of files are being copied by distcp; accessing distcp_src_files seems to be an issue; as all map tasks would be accessing this file. The error message seen is:    INFO mapred.JobClient: Task Id :  org.apache.hadoop.mapred.Child.main(Child. 170)   This could be because of HADOOP-6038 and or HADOOP-4681.  If distcp places this special file distcp_src_files in distributed cache; that could solve the problem.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 17 Jun 2009 19:52:35 +0000,Tue; 24 Aug 2010 21:14:01 +0000,Mon; 29 Jun 2009 18:21:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-646
MAPREDUCE-647,Bug,Major,documentation,Update the DistCp forrest doc to make it consistent with the latest changes (5472; 5620; 5762; 5826),New features have been added to DistCp and the documentation must be updated.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Wed; 27 May 2009 22:59:29 +0000,Thu; 2 May 2013 02:29:25 +0000,Fri; 18 Jun 2010 17:56:24 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-647
MAPREDUCE-648,Bug,Minor,distcp,Two distcp bugs,1. distcp -update launches job when there is at least one dir in source paths to be copied; even though there is nothing to copy.  HADOOP-5675 added fileCount  0 to be checked to decide whether to launch job. And HADOOP-5762 changed this to fileCount + dirCount  0 to solve the issue of empty directories not getting copied to destination. With -update; dirCount is incremented without checking if that dir already exists at the destination. So distcp job is launched because of dirCount  0 even though there is nothing to copy. Incrementing dirCount can be skipped if that dir already exists at the destination in case of -update.  2. distcp doesn't skip copying file when we do -update on single file if the destfile already exists.  When we do  hadoop distcp -update srcfilename destfilename  it seems to be comparing checksums of srcfilename and destfilename srcfilename and so skip is not done. It should compare checksums of srcfilename and destfilename.  See also MAPREDUCE-644.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Tue; 16 Jun 2009 08:41:41 +0000,Tue; 24 Aug 2010 21:14:02 +0000,Tue; 15 Sep 2009 21:03:25 +0000,,,,MAPREDUCE-644,HADOOP-5762,https://issues.apache.org/jira/browse/MAPREDUCE-648
MAPREDUCE-649,Improvement,Major,distcp,distcp should validate the data copied,distcp should validate the files copied by checking the checksums; if the filesystem supports checksums.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Tue; 16 Jun 2009 10:10:01 +0000,Tue; 24 Aug 2010 21:14:02 +0000,Fri; 18 Sep 2009 06:08:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-649
MAPREDUCE-650,New Feature,Major,distcp,Add atomic move option,Provide support for update to move directories need for this is that applications may attempt to start processing data (because files are present); prior to completion of a whole directory copy  resulting in work against an incomplete data set.,Resolved,Fixed,,Ravi Gummadi,Richard Theige,Mon; 9 Mar 2009 22:23:17 +0000,Mon; 21 Jul 2014 21:48:10 +0000,Mon; 21 Jul 2014 21:48:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-650
MAPREDUCE-651,New Feature,Major,distcp,distcp can retry copying specified number of times in case of transient failures,distcp can retry specified number of times copying if the mapreduce job fails with transient error.  Providing option -retries num_tries to discp would be useful for users who copy large amount of data and see transient errors.,Resolved,Duplicate,MAPREDUCE-650,Ravi Gummadi,Ravi Gummadi,Wed; 17 Jun 2009 05:19:28 +0000,Tue; 8 Sep 2009 11:05:16 +0000,Tue; 8 Sep 2009 11:05:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-651
MAPREDUCE-652,New Feature,Major,distcp,Logging turned on by default while using distcp,Distcp should have an option to disable logging during a distcp  eg: hadoop distcp --nolog source dir destination dir  By default logging is enabled or turned on while using distcp.This generates logs in DFS; which need to be cleaned up periodically. During this time; critical applications sometimes fail; when they see distcp logs in the DFS.,Resolved,Won't Fix,,Ravi Gummadi,Sanjeev Jaiswal,Tue; 10 Mar 2009 04:07:08 +0000,Mon; 21 Jul 2014 21:47:43 +0000,Mon; 21 Jul 2014 21:47:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-652
MAPREDUCE-653,New Feature,Major,distcp,distcp can support bandwidth limiting,distcp should support an option for user to specify the bandwidth limit for the distcp job.,Resolved,Won't Fix,,Ravi Gummadi,Ravi Gummadi,Fri; 19 Jun 2009 05:00:24 +0000,Tue; 22 Jul 2014 21:58:22 +0000,Tue; 22 Jul 2014 21:58:22 +0000,,,,MAPREDUCE-564,,https://issues.apache.org/jira/browse/MAPREDUCE-653
MAPREDUCE-654,Improvement,Major,distcp,Add an option -count to distcp for displaying some info about the src files,Add an option -count to distcp for displaying metadata about src files like number of files to be copied and total size of src files to be copied. WIth -count; distcp doesn't do any copy. Just displays info and exits. This is useful specifically when used with -update.  distcp -update -count src* dst        would display the number of files to be updated and the total size of copy needs to be done(by comparing the file sizes and checksums at src and dst). Based on this info; users could allocate the number of nodes needed for the actual update job.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 22 Jun 2009 18:04:44 +0000,Tue; 24 Aug 2010 21:14:03 +0000,Fri; 18 Sep 2009 06:45:03 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-654
MAPREDUCE-655,Sub-task,Major,,Change KeyValueLineRecordReader and KeyValueTextInputFormat to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 24 Jun 2009 09:38:34 +0000,Tue; 24 Aug 2010 21:14:03 +0000,Fri; 10 Jul 2009 08:54:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-655
MAPREDUCE-656,Sub-task,Major,,Change org.apache.hadoop.mapred.SequenceFile* classes to use new api,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 24 Jun 2009 09:41:24 +0000,Tue; 24 Aug 2010 21:14:04 +0000,Mon; 3 Aug 2009 07:34:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-656
MAPREDUCE-657,Bug,Major,jobtracker,CompletedJobStatusStore hardcodes filesystem to hdfs,Today; completedjobstatusstore stores only to hdfs. It should be configurable to write to local-fs too.,Resolved,Fixed,,Amar Kamat,Amar Kamat,Wed; 24 Jun 2009 09:44:55 +0000,Tue; 7 Jul 2009 17:34:20 +0000,Fri; 26 Jun 2009 12:06:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-657
MAPREDUCE-658,Bug,Major,distcp,NPE in distcp if source path does not exist,distcp throws NullPointerException if the source path does not exist. It should emit a proper exception with meaningful error message.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 24 Jun 2009 10:26:33 +0000,Tue; 24 Aug 2010 21:14:08 +0000,Mon; 29 Jun 2009 07:04:03 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-658
MAPREDUCE-659,Bug,Critical,build,gridmix2 not compiling under mapred module trunk/src/benchmarks/gridmix2 ,When build is tried in gridmix2; it fails  trunk build.xml:27: Compile failed; see the compiler error output for details.  Total time: 1 second,Closed,Fixed,,Giridharan Kesavan,Iyappan Srinivasan,Wed; 24 Jun 2009 10:59:46 +0000,Tue; 24 Aug 2010 21:14:08 +0000,Thu; 6 Aug 2009 06:43:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-659
MAPREDUCE-660,Bug,Minor,test,MRBench throws NPE,"On running ""hadoop  org.apache.hadoop.mapred.MRBench"" the following exception is obtained:",Resolved,Fixed,,Unassigned,Ramya Sunil,Wed; 24 Jun 2009 11:07:27 +0000,Wed; 23 Jul 2014 17:47:35 +0000,Wed; 23 Jul 2014 17:47:35 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-660
MAPREDUCE-661,Bug,Major,distcp,distcp doesn't ignore read failures with -i in setup() before MapReduce job is started,After HADOOP-3873; file checksums are checked in setup() before actual MapReduce job is started. And when getFileChecksum() fails with socketTimeoutException when called from setup(); distcp fails even though -i option is specified by user. Similar to how map tasks ignore read failures; setup() should also ignore them and continue processing remaining files.,Resolved,Fixed,,Ravi Gummadi,Ravi Gummadi,Thu; 25 Jun 2009 10:22:39 +0000,Wed; 23 Jul 2014 17:59:19 +0000,Wed; 23 Jul 2014 17:59:19 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-661
MAPREDUCE-662,Bug,Major,distcp,distcp -update fails if source directory is empty (i.e. no files to copy) and target directory does not exists.,It should either create empty target directory or not make any changes on the target (as there is nothing to copy from source); but it should return success.   Tested version of hadoop has  HADOOP-5675.  -bash-3.1$ bin mirror_test1    INFO tools.DistCp: bytesToCopyCount=0.0 With failures; global counters are inaccurate; consider running with -i Copy failed:  885),Closed,Duplicate,HADOOP-5762,Unassigned,Suhas Gogate,Thu; 25 Jun 2009 17:58:36 +0000,Tue; 24 Aug 2010 21:14:09 +0000,Fri; 26 Jun 2009 09:49:35 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-662
MAPREDUCE-663,Bug,Major,,distcp command should return hadoop job id ,When distcp is used through some wrapper script to periodically copy data from source to target; it would be good to have hadoop job ids returned by distcp.  It would help if wrapper script is terminated abnormally; corresponding distcp jobs can be cleaned up; if needed.,Resolved,Fixed,,Unassigned,Suhas Gogate,Thu; 25 Jun 2009 18:05:32 +0000,Wed; 23 Jul 2014 18:12:46 +0000,Wed; 23 Jul 2014 18:12:46 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-663
MAPREDUCE-664,Improvement,Major,distcp,distcp with -delete option does not display number of files deleted from the target that were not present on source ,distcp with -delete option should provide information on total number of files deleted from the target that were not present on the source.,Closed,Fixed,,Ravi Gummadi,Suhas Gogate,Thu; 25 Jun 2009 21:43:30 +0000,Tue; 24 Aug 2010 21:14:09 +0000,Fri; 18 Sep 2009 07:49:51 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-664
MAPREDUCE-665,Task,Blocker,build,Move libhdfs to HDFS project,The subtree src libhdfs currently resides in mapreduce.  It should be moved to HDFS.,Closed,Fixed,,Eli Collins,Tsz Wo Nicholas Sze,Thu; 25 Jun 2009 23:17:04 +0000,Thu; 2 May 2013 02:29:25 +0000,Mon; 9 Nov 2009 07:51:18 +0000,,,,HDFS-423,HDFS-712,https://issues.apache.org/jira/browse/MAPREDUCE-665
MAPREDUCE-666,Bug,Major,jobtracker,Job scheduling information on jobtracker.jsp makes it clunky,Job scheduling information is displayed for each job on the jobtracker.jsp along with many other details. Though it is empty by default; when it is in use; for e.g. with high memory jobs in capacity scheduler; the UI looks clunky with long strings of job scheduling information.,Resolved,Incomplete,,Unassigned,Vinod Kumar Vavilapalli,Fri; 26 Jun 2009 06:58:53 +0000,Wed; 23 Jul 2014 18:13:42 +0000,Wed; 23 Jul 2014 18:13:41 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-666
MAPREDUCE-667,Bug,Major,jobtracker,Re HADOOP-2141; JobTracker's clock is not used everywhere,"HADOOP-2141 introduced the concept of clock. I can see someplaces where its not used namely  	JobInProgress 	JobHistory etc",Resolved,Fixed,,Unassigned,Amar Kamat,Fri; 26 Jun 2009 09:38:54 +0000,Wed; 23 Jul 2014 18:14:32 +0000,Wed; 23 Jul 2014 18:14:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-667
MAPREDUCE-668,Improvement,Major,jobtracker,Improve CompletedJobStatusStore setup/testcases,mapred.job.tracker.persist.jobstatus.hours expects value in hour. It should be made as an interval. Also sleep time is set to 1hour which is too much. Allowing to configure these values will help in testcases. Also the testcase can be made faster by using mock jobs instead of starting a whole new jobtracker. There is no testcase for checking if status objects are cleanedup or not.,Resolved,Fixed,,Unassigned,Amar Kamat,Fri; 26 Jun 2009 09:45:56 +0000,Wed; 23 Jul 2014 18:16:15 +0000,Wed; 23 Jul 2014 18:16:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-668
MAPREDUCE-669,Bug,Major,build,eclipse-files target does not create MR_Ant_Builder,"This is the result of project splitting; same as HDFS-450. The ""eclipse-files"" build target used to create Hadoop_Ant_Builder - an ant based builder for eclipse. The target still works fine for hadoop common; but not for for MapReduce or HDFS.",Resolved,Fixed,,Unassigned,Konstantin Shvachko,Sat; 27 Jun 2009 00:32:40 +0000,Wed; 23 Jul 2014 18:17:11 +0000,Wed; 23 Jul 2014 18:17:11 +0000,,0.21.0,,,HDFS-450,https://issues.apache.org/jira/browse/MAPREDUCE-669
MAPREDUCE-670,Test,Major,build, Create target for 10 minute patch test build for mapreduce,Creating a new Jira to track HADOOP-5628 for MapReduce,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Sun; 28 Jun 2009 14:16:49 +0000,Thu; 2 May 2013 02:29:34 +0000,Mon; 3 Aug 2009 12:13:40 +0000,,,,HADOOP-5628;MAPREDUCE-623,HDFS-458;MAPREDUCE-785,https://issues.apache.org/jira/browse/MAPREDUCE-670
MAPREDUCE-671,Bug,Trivial,build,Update ignore list,MAPREDUCE-551 added conf ivy-.jar from its ignore list.,Closed,Fixed,,Chris Douglas,Chris Douglas,Mon; 29 Jun 2009 06:28:39 +0000,Tue; 24 Aug 2010 21:14:10 +0000,Mon; 29 Jun 2009 23:38:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-671
MAPREDUCE-672,Wish,Major,,"Consider adding a new ""component"" for Sqoop in JIRA",The development of Sqoop now spans several patches. It would be good to have a contrib sqoop component to tag them with to keep related work together in the JIRA.,Resolved,Fixed,,Unassigned,Aaron Kimball,Thu; 4 Jun 2009 01:08:37 +0000,Fri; 2 Jul 2010 06:31:37 +0000,Mon; 29 Jun 2009 08:27:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-672
MAPREDUCE-673,Bug,Minor,,Sqoop depends on commons-cli; which is not in its ivy.xml.,Sqoop's ivy.xml needs commons-cli in order to build from scratch.,Resolved,Fixed,,Kevin Weil,Kevin Weil,Sun; 28 Jun 2009 00:10:38 +0000,Fri; 2 Jul 2010 06:31:37 +0000,Fri; 3 Jul 2009 10:58:40 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-673
MAPREDUCE-674,Improvement,Minor,,"Sqoop should allow a ""where"" clause to avoid having to export entire tables",Sqoop currently only exports at the granularity of a table.  This doesn't work well on systems with large tables; where the overhead of performing a full dump each time is significant.  Allowing the user to specify a where clause is a relatively simple task which will give Sqoop a lot more flexibility.,Resolved,Fixed,,Kevin Weil,Kevin Weil,Sat; 27 Jun 2009 23:20:55 +0000,Fri; 2 Jul 2010 06:31:38 +0000,Tue; 7 Jul 2009 12:13:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-674
MAPREDUCE-675,Improvement,Minor,,Sqoop should allow user-defined class and package names,Currently Sqoop generates a class for each table to be imported; the class names are equal to the table names and they are not part of any package.  This adds --class-name and --package-name parameters to Sqoop; allowing these aspects of code generation to be controlled.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Wed; 27 May 2009 20:29:18 +0000,Fri; 2 Jul 2010 06:31:39 +0000,Tue; 7 Jul 2009 12:41:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-675
MAPREDUCE-676,Bug,Major,,Existing diagnostic rules fail for MAP ONLY jobs,some of the existing rules fail with divide by zero or arithmetic exception as map only jobs do not log reduce side counters. Vaidya driver code and Rules need to be modified to take care of such jobs.,Closed,Fixed,,Suhas Gogate,Suhas Gogate,Mon; 1 Jun 2009 16:16:31 +0000,Tue; 24 Aug 2010 21:14:12 +0000,Tue; 7 Jul 2009 11:31:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-676
MAPREDUCE-677,Bug,Major,test,TestNodeRefresh timesout,nan,Closed,Fixed,,Amar Kamat,Amar Kamat,Mon; 29 Jun 2009 10:46:19 +0000,Tue; 24 Aug 2010 21:14:12 +0000,Tue; 14 Jul 2009 10:53:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-677
MAPREDUCE-678,Bug,Major,distcp,distcp -m option does not work ,In spite of -m 10 ; number of launched map tasks are 15.    bin QA_incremental'    INFO mapred.JobClient:     Map output records=0,Resolved,Cannot Reproduce,,Unassigned,Suhas Gogate,Mon; 29 Jun 2009 21:08:40 +0000,Wed; 23 Jul 2014 18:18:39 +0000,Wed; 23 Jul 2014 18:18:39 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-678
MAPREDUCE-679,New Feature,Major,jobtracker,XML-based metrics as JSP servlet for JobTracker,In HADOOP-4559; a general REST API for reporting metrics was proposed but work seems to have stalled. In the interim; we have a simple XML translation of the existing JobTracker status page which provides the same metrics (including the tables of running failed jobs) as the human-readable page. This is a relatively lightweight addition to provide some machine-understandable metrics reporting.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 30 Jun 2009 00:00:24 +0000,Tue; 24 Aug 2010 21:14:13 +0000,Fri; 18 Sep 2009 22:09:37 +0000,,,,,HDFS-453;MAPREDUCE-2818,https://issues.apache.org/jira/browse/MAPREDUCE-679
MAPREDUCE-680,Bug,Major,contrib/mrunit,Reuse of Writable objects is improperly handled by MRUnit,As written; MRUnit's MockOutputCollector simply stores references to the objects passed in to its collect() method. Thus if the same Text (or other Writable) object is reused as an output containiner multiple times with different values; these separate values will not all be collected. MockOutputCollector needs to properly use io.serializations to deep copy the objects sent in.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 30 Jun 2009 02:11:01 +0000,Tue; 24 Aug 2010 21:14:13 +0000,Wed; 15 Jul 2009 16:43:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-680
MAPREDUCE-681,Improvement,Major,test,Some testcases wait forever on a condition which might result into timeouts,MAPREDUCE-502 and MAPREDUCE-130 testcases should change to fail instead of timeout upon failure.,Resolved,Duplicate,MAPREDUCE-757,Amar Kamat,Amar Kamat,Tue; 30 Jun 2009 05:29:11 +0000,Tue; 14 Jul 2009 04:43:00 +0000,Tue; 14 Jul 2009 04:43:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-681
MAPREDUCE-682,Bug,Major,jobtracker,Reserved tasktrackers should be removed when a node is globally blacklisted,When support was added to reserve tasktrackers for high RAM jobs per MAPREDUCE-516; we missed removing reservations on tasktrackers that are globally blacklisted. This is not a major concern; just that the reservation might cause the job to finish a little later than if the reservation is removed when the blacklisting happens.,Closed,Fixed,,Sreekanth Ramakrishnan,Hemanth Yamijala,Tue; 30 Jun 2009 06:14:07 +0000,Tue; 24 Aug 2010 21:14:14 +0000,Wed; 22 Jul 2009 14:49:31 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-682
MAPREDUCE-683,Bug,Major,jobtracker,TestJobTrackerRestart fails with Map task completion events ordering mismatch,TestJobTrackerRestart fails consistently with Map task completion events ordering mismatch error.,Closed,Fixed,,Amar Kamat,Sreekanth Ramakrishnan,Tue; 30 Jun 2009 10:29:11 +0000,Thu; 2 May 2013 02:29:25 +0000,Tue; 7 Jul 2009 06:28:23 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-683
MAPREDUCE-684,Bug,Major,distcp,distcp returns success but does not copy files due to connection problem. Error is logged on target HDFS log directory,Distcp returns success even though files are not copied due to connection problem.  It creates empty directory structure on the target and log the error message on the target HDFS log directory.  distcp command is run on hadoop 20 fetching data from hadoop 18 cluster.  -bash-3.1$ hadoop  distcp -Dmapred.job.queue.name=xxxx -i -p -update -delete hftp: part-00000 FAIL pig_1245890239320.log :  170)  -bash-3.1$,Resolved,Invalid,,Unassigned,Suhas Gogate,Tue; 30 Jun 2009 18:58:21 +0000,Tue; 30 Jun 2009 19:10:09 +0000,Tue; 30 Jun 2009 19:10:09 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-684
MAPREDUCE-685,Bug,Major,,Sqoop will fail with OutOfMemory on large tables using mysql,The default MySQL JDBC client behavior is to buffer the entire ResultSet in the client before allowing the user to use the ResultSet object. On large SELECTs; this can cause OutOfMemory exceptions; even when the client intends to close the ResultSet after reading only a few rows. The MySQL ConnManager should configure its connection to use row-at-a-time delivery of results to the client.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 30 Jun 2009 21:15:38 +0000,Fri; 2 Jul 2010 06:31:40 +0000,Thu; 9 Jul 2009 12:18:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-685
MAPREDUCE-686,Test,Major,test,Move TestSpeculativeExecution.Fake* into a separate class so that it can be used by other tests also,TestSpeculativeExecution has some utility classes in FakeJobTracker and FakeJobInProgress that could be put to use by other tests as well. It makes sense to move these to a separate class,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Wed; 1 Jul 2009 05:07:57 +0000,Tue; 24 Aug 2010 21:14:15 +0000,Fri; 3 Jul 2009 05:54:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-686
MAPREDUCE-687,Bug,Major,test,TestMiniMRMapRedDebugScript fails sometimes,Testcase: testMapDebugScript took 149.994 sec         FAILED null expected:...t Script Bailing out[] but was:...t Script Bailing out[ log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapred.Task). log4j:WARN Please initialize the log4j system properly.] junit.framework.ComparisonFailure: null expected:...t Script Bailing out[] but was:...t Script Bailing out[ log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapred.Task). log4j:WARN Please initialize the log4j system properly.]         at org.apache.hadoop.mapred.TestMiniMRMapRedDebugScript.testMapDebugScript(TestMiniMRMapRedDebugScript. 212),Resolved,Fixed,,Amareshwari Sriramadasu,Amar Kamat,Wed; 1 Jul 2009 09:52:09 +0000,Wed; 18 Nov 2009 06:09:27 +0000,Tue; 1 Sep 2009 06:33:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-687
MAPREDUCE-688,Bug,Major,tasktracker,TestLostTracker sometimes fails ,"Observed that TestLostTracker failed once with follwing assertion failure: Invalid start time 0 junit.framework.AssertionFailedError: Invalid start time 0 	at org.apache.hadoop.mapred.TestLostTracker.testTaskStatuses(TestLostTracker. 161)",Resolved,Fixed,,Unassigned,Amareshwari Sriramadasu,Wed; 1 Jul 2009 10:06:18 +0000,Wed; 29 Jul 2009 11:11:46 +0000,Wed; 29 Jul 2009 11:11:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-688
MAPREDUCE-689,Improvement,Major,documentation,Update distcp guide for new distcp features,Please udpate the distcp guide with new features from MAPREDUCE-642; HADOOP-5762; HADOOP-5620,Closed,Duplicate,MAPREDUCE-647,Rodrigo Schmidt,dhruba borthakur,Wed; 1 Jul 2009 13:42:51 +0000,Tue; 24 Aug 2010 21:14:16 +0000,Wed; 1 Jul 2009 17:42:15 +0000,,,,,HADOOP-5762;MAPREDUCE-642;HADOOP-5620,https://issues.apache.org/jira/browse/MAPREDUCE-689
MAPREDUCE-690,Bug,Major,,"Sqoop's test ""hive"" script needs to be executable",The testdata hive script needs to be chmod +x so that unit tests can run it. This needs to be set with an svn property.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Wed; 1 Jul 2009 18:46:51 +0000,Fri; 2 Jul 2010 06:31:41 +0000,Fri; 3 Jul 2009 11:12:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-690
MAPREDUCE-691,Improvement,Major,documentation,Document the features available in org.apache.hadoop.examples.pi,"There are quite a few features provided by MAPREDUCE-637:  	DistBbp and DistSum; 	a parser for reading the output; and 	benchmark programs for some arithmetic operations. They should be documented.",Open,Unresolved,,Unassigned,Tsz Wo Nicholas Sze,Wed; 1 Jul 2009 21:00:59 +0000,Wed; 23 Jul 2014 18:41:20 +0000,,,,newbie,,MAPREDUCE-637,https://issues.apache.org/jira/browse/MAPREDUCE-691
MAPREDUCE-692,Improvement,Major,,Make Hudson run Sqoop unit tests,Running 'ant test-contrib' didn't test Sqoop because it wasn't explicitly listed in the build.xml file in src ,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Wed; 1 Jul 2009 21:48:19 +0000,Fri; 2 Jul 2010 06:31:42 +0000,Fri; 3 Jul 2009 11:02:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-692
MAPREDUCE-693,Bug,Minor,jobtracker,"Conf files not moved to ""done"" subdirectory after JT restart","After MAPREDUCE-516; when a job is submitted and the JT is restarted (before job files have been written) and the job is killed after recovery; the conf files fail to be moved to the ""done"" subdirectory. The exact scenario to reproduce this issue is:  	Submit a job 	Restart JT before anything is written to the job files 	Kill the job 	The old conf files remain in the history folder and fail to be moved to ""done"" subdirectory",Resolved,Cannot Reproduce,,Unassigned,Ramya Sunil,Thu; 2 Jul 2009 05:59:50 +0000,Wed; 26 Aug 2009 23:47:56 +0000,Wed; 26 Aug 2009 23:47:56 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-693
MAPREDUCE-694,Bug,Major,build;capacity-sched,JSP jars should be added to dependcy list for Capacity scheduler,Currently JSP*.jar is not added in dependency list for junit target causing; TestQueueCapacities to throw ClassNotFoundException while MiniMRCluster starts up,Closed,Fixed,,Giridharan Kesavan,Sreekanth Ramakrishnan,Thu; 2 Jul 2009 07:36:08 +0000,Tue; 24 Aug 2010 21:14:17 +0000,Fri; 3 Jul 2009 11:12:02 +0000,,,,MAPREDUCE-522,,https://issues.apache.org/jira/browse/MAPREDUCE-694
MAPREDUCE-695,Bug,Minor,test,MiniMRCluster while shutting down should not wait for currently running jobs to finish,Currently in org.apache.hadoop.mapred.MiniMRCluster.shutdown() we do a waitTaskTrackers() which can cause MiniMRCluster to hang indefinitely when used in conjunction with Controlled jobs.,Resolved,Won't Fix,,Unassigned,Sreekanth Ramakrishnan,Thu; 2 Jul 2009 10:16:30 +0000,Fri; 8 May 2015 16:57:28 +0000,Fri; 8 May 2015 16:57:28 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-695
MAPREDUCE-696,Bug,Major,test,Make ControlledMapReduce job to check for failures while waiting for tasks to be scheduled/finished.,Currently when using org.apache.hadoop.mapred.ControlledMapReduceJob.waitTillNTasksStartRunning(JobInProgress; boolean; int) or org.apache.hadoop.mapred.ControlledMapReduceJob.waitTillNTotalTasksFinish(JobInProgress; boolean; int) we dont check for task failures. We should check for the failures.,Open,Unresolved,,Unassigned,Sreekanth Ramakrishnan,Thu; 2 Jul 2009 10:18:30 +0000,Thu; 2 Jul 2009 10:20:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-696
MAPREDUCE-697,Bug,Major,tasktracker,Jobwise list of blacklisted tasktrackers doesn't get refreshed even after restarting blacklisted tasktrackers.,"Jobwise list of blacklisted tasktrackers doesn't get refreshed even after restarting blacklisted tasktrackers. ""jobdetails.jsp"" page keeps on showing the same no. of blacklisted tasktrackers (it doesn't get back to zero).  One associated issue: ================= -- More than 25% of TTs are blacklisted in a job. -- Restart the blacklisted TTs. All the tasktrackers are healthy now. -- try to blacklist other TT for the same job.  Not able to blacklist the ""other"" tasktracker even if  ""mapred.max.tracker.failures"" exceeds the specified limit.",Resolved,Not A Problem,,Unassigned,Suman Sehgal,Thu; 2 Jul 2009 11:50:50 +0000,Wed; 23 Jul 2014 18:44:43 +0000,Wed; 23 Jul 2014 18:44:43 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-697
MAPREDUCE-698,New Feature,Major,contrib/fair-share,Per-pool task limits for the fair scheduler,The fair scheduler could use a way to cap the share of a given pool similar to MAPREDUCE-532.,Closed,Fixed,,Kevin Peterson,Matei Zaharia,Thu; 2 Jul 2009 23:00:48 +0000,Wed; 8 Sep 2010 20:27:09 +0000,Fri; 18 Dec 2009 03:30:26 +0000,,,,,HADOOP-5170,https://issues.apache.org/jira/browse/MAPREDUCE-698
MAPREDUCE-699,Bug,Major,test,Several streaming test cases seem to be failing,ant test is failing several streaming tests with the following error  Error Message   133)  The following are links to two such failures http: ,Resolved,Cannot Reproduce,MAPREDUCE-891,Unassigned,Jothi Padmanabhan,Fri; 3 Jul 2009 03:33:44 +0000,Fri; 7 May 2010 05:22:57 +0000,Fri; 7 May 2010 05:22:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-699
MAPREDUCE-700,Bug,Major,jobtracker,Too many copies of job-conf with the jobtracker,"As of today the jobtracker has job-conf copies in  	mapred.system.dir : created while job-submission 	jobtracker-subdir (created by JobInProgress upon creation) 	log-dir : created upon job-init 	history-dir : created upon job-init    Its difficult to manage these conf files. The problem aggravates under restart.",Resolved,Fixed,,Amar Kamat,Amar Kamat,Fri; 3 Jul 2009 04:20:48 +0000,Tue; 22 Jul 2014 18:50:03 +0000,Tue; 22 Jul 2014 18:50:03 +0000,,,,MAPREDUCE-173,,https://issues.apache.org/jira/browse/MAPREDUCE-700
MAPREDUCE-701,Improvement,Minor,test,Make TestRackAwareTaskPlacement a unit test,This test can be made into a unit test and the functionality verified without needing to start MiniMR DFS and launching jobs,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Fri; 3 Jul 2009 10:23:02 +0000,Tue; 24 Aug 2010 21:14:17 +0000,Mon; 6 Jul 2009 09:15:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-701
MAPREDUCE-702,Bug,Major,build,eclipse-plugin jar target fails during packaging,nan,Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Fri; 3 Jul 2009 10:57:57 +0000,Tue; 24 Aug 2010 21:14:18 +0000,Fri; 3 Jul 2009 11:44:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-702
MAPREDUCE-703,Bug,Major,,Sqoop requires dependency on hsqldb in ivy,Sqoop builds crash without explicit dependency on hsqldb.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 3 Jul 2009 17:10:13 +0000,Fri; 2 Jul 2010 06:31:44 +0000,Fri; 3 Jul 2009 17:33:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-703
MAPREDUCE-704,New Feature,Major,contrib/fair-share,Per-node task limits in the fair scheduler,Some users would like to be able to limit the number of tasks from a job that they run on each node to better control cluster load. This JIRA will add this feature to the fair scheduler. MAPREDUCE-698 adds per-pool limits on number of running tasks as well.,Open,Unresolved,,Unassigned,Matei Zaharia,Fri; 3 Jul 2009 18:04:18 +0000,Wed; 8 Sep 2010 20:27:51 +0000,,,,,,HADOOP-5170,https://issues.apache.org/jira/browse/MAPREDUCE-704
MAPREDUCE-705,New Feature,Major,,User-configurable quote and delimiter characters for Sqoop records and record reparsing,Sqoop needs a mechanism for users to govern how fields are quoted and what delimiter characters separate fields and records. With delimiters providing an unambiguous format; a parse method can reconstitute the generated record data object from a text-based representation of the same record.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 3 Jul 2009 19:09:18 +0000,Fri; 2 Jul 2010 06:31:43 +0000,Wed; 22 Jul 2009 14:14:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-705
MAPREDUCE-706,New Feature,Major,contrib/fair-share,Support for FIFO pools in the fair scheduler,The fair scheduler should support making the internal scheduling algorithm for some pools be FIFO instead of fair sharing in order to work better for batch workloads. FIFO pools will behave exactly like the current default scheduler; sorting jobs by priority and then submission time. Pools will have their scheduling algorithm set through the pools config file; and it will be changeable at runtime.  To support this feature; I'm also changing the internal logic of the fair scheduler to no longer use deficits. Instead; for fair sharing; we will assign tasks to the job farthest below its share as a ratio of its share. This is easier to combine with other scheduling algorithms and leads to a more stable sharing situation; avoiding unfairness issues brought up in MAPREDUCE-543 and MAPREDUCE-544 that happen when some jobs have long tasks. The new preemption (MAPREDUCE-551) will ensure that critical jobs can gain their fair share within a bounded amount of time.,Closed,Fixed,,Matei Zaharia,Matei Zaharia,Sat; 4 Jul 2009 01:35:27 +0000,Tue; 24 Aug 2010 21:14:18 +0000,Fri; 14 Aug 2009 16:32:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-706
MAPREDUCE-707,New Feature,Trivial,contrib/fair-share,Provide a jobconf property for explicitly assigning a job to a pool,A common use case of the fair scheduler is to have one pool per user; but then to define some special pools for various production jobs; import jobs; etc. Therefore; it would be nice if jobs went by default to the pool of the user who submitted them; but there was a setting to explicitly place a job in another pool. Today; this can be achieved through a sort of trick in the JobConf:     This JIRA proposes to add a property called mapred.fairscheduler.pool that allows a job to be placed directly into a pool; avoiding the need for this trick.,Closed,Fixed,,Alan Heirich,Matei Zaharia,Sun; 5 Jul 2009 17:29:15 +0000,Tue; 24 Aug 2010 21:14:20 +0000,Thu; 5 Nov 2009 18:42:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-707
MAPREDUCE-708,Bug,Minor,tasktracker,"node health check script does not refresh the ""reason for blacklisting""","After MAPREDUCE-211; the node health check script does not refresh the ""reason for blacklisting"". The steps to reproduce the issue are:  	Blacklist a TT with an error message 'x' 	Change the health check script to return an error message 'y' 	The ""reason for blacklisting"" still shows 'x'    The impact of this issue is that the feature fails to trap transient errors.",Closed,Fixed,,Sreekanth Ramakrishnan,Ramya Sunil,Mon; 6 Jul 2009 08:39:36 +0000,Tue; 24 Aug 2010 21:14:20 +0000,Tue; 7 Jul 2009 07:29:49 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-708
MAPREDUCE-709,Bug,Minor,,node health check script does not display the correct message on timeout,"When the node health check script takes more than ""mapred.healthChecker.script.timeout"" to return; it should display a timeout message. Instead it displays the full stacktrace as below:     Also the ""mapred.healthChecker.script.timeout"" is not being reflected in the job.xml. It always picks up the default value. It is just an UI issue.",Closed,Fixed,,Sreekanth Ramakrishnan,Ramya Sunil,Mon; 6 Jul 2009 09:39:22 +0000,Tue; 24 Aug 2010 21:14:21 +0000,Tue; 7 Jul 2009 07:50:53 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-709
MAPREDUCE-710,Improvement,Major,,Sqoop should read and transmit passwords in a more secure manner,"Sqoop's current support for passwords involves reading passwords from the command line ""--password foo""; which makes the password visible to other users via 'ps'. An invisible-console approach should be taken.  Related; Sqoop transmits passwords to mysqldump in the same fashion; which is also insecure.",Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Mon; 6 Jul 2009 17:35:57 +0000,Fri; 2 Jul 2010 06:31:46 +0000,Wed; 15 Jul 2009 10:45:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-710
MAPREDUCE-711,Improvement,Major,,Move Distributed Cache from Common to Map/Reduce,Distributed Cache logically belongs as part of map reduce and not Common.,Closed,Fixed,,Vinod Kumar Vavilapalli,Owen O'Malley,Mon; 6 Jul 2009 18:10:25 +0000,Tue; 24 Aug 2010 21:14:21 +0000,Tue; 18 Aug 2009 11:54:11 +0000,,,,MAPREDUCE-856;HADOOP-6125;MAPREDUCE-476,MAPREDUCE-476,https://issues.apache.org/jira/browse/MAPREDUCE-711
MAPREDUCE-712,Improvement,Major,examples,RandomTextWriter example is CPU bound,Running the RandomTextWritter example job ( from the examples jar) pegs the machiens' CPUs.,Closed,Fixed,,Chris Douglas,Khaled Elmeleegy,Mon; 6 Jul 2009 20:38:09 +0000,Tue; 24 Aug 2010 21:14:22 +0000,Fri; 21 Aug 2009 01:29:59 +0000,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-712
MAPREDUCE-713,Improvement,Trivial,,Sqoop has some superfluous imports,Some classes have vestigial imports that should be removed,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Mon; 6 Jul 2009 22:40:01 +0000,Fri; 2 Jul 2010 06:31:45 +0000,Thu; 9 Jul 2009 12:24:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-713
MAPREDUCE-714,Bug,Major,,JobConf.findContainingJar unescapes unnecessarily on Linux,"In JobConf.findContainingJar; the path name is decoded using URLDecoder.decode(...). This was done by Doug in r381794 (commit msg ""Un-escape containing jar's path; which is URL-encoded.  This fixes things primarily on Windows; where paths are likely to contain spaces."") Unfortunately; jar paths do not appear to be URL encoded on Linux. If you try to use ""hadoop jar"" on a jar with a ""+"" in it; this function decodes it to a space and then the job cannot be submitted.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 7 Jul 2009 00:57:06 +0000,Mon; 12 Dec 2011 06:18:30 +0000,Wed; 29 Dec 2010 20:58:27 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-714
MAPREDUCE-715,Improvement,Minor,contrib/fair-share,Allow pool and user default settings to be set through poolDefaults and userDefaults elements,Over time a number of elements have been added to the fair scheduler config file for setting default running job limits; preemption timeouts; etc for pools and for users. Right now these are all set in top-level elements in the allocations file; such as userMaxJobsDefault. It would be easier to understand if there was a userDefaults element that contained defaults for all pools (using the same element names as user elements; e.g. maxRunningJobs in this case); and similarly; a poolDefaults element for pool defaults.,Open,Unresolved,,Unassigned,Matei Zaharia,Tue; 7 Jul 2009 01:04:16 +0000,Tue; 7 Jul 2009 01:07:18 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-715
MAPREDUCE-716,Bug,Major,,org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle,"org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle.  The out of the box implementation of the Hadoop is working properly with mysql hsqldb specific query constructs like ""LIMIT""; ""OFFSET"".  FIX: building a database provider specific logic based on the database providername (which we can get using connection).   I HAVE ALREADY IMPLEMENTED IT FOR ORACLE...READY TO CHECK_IN CODE",Closed,Fixed,,Aaron Kimball,evanand,Thu; 12 Mar 2009 21:48:44 +0000,Tue; 24 Aug 2010 21:14:27 +0000,Tue; 21 Jul 2009 16:13:20 +0000,,,,,MAPREDUCE-792,https://issues.apache.org/jira/browse/MAPREDUCE-716
MAPREDUCE-717,Bug,Major,jobtracker,Fix some corner case issues in speculative execution (post hadoop-2141),Some corner case issues can be fixed: 1) Setup task should not add anything to the job statistics (since they are really fast and might affect the statistics of a job with few tasks) 2) The statistics computations should be guarded for cases where things like sumOfSquares could become less than zero (due to rounding errors mostly). 3) The method TaskInProgress.getCurrentProgressRate() should take into account the COMMIT_PENDING state 4) The testcase TestSpeculativeExecution.testTaskLATEScheduling could be made more robust,Closed,Fixed,,Devaraj Das,Devaraj Das,Tue; 7 Jul 2009 04:05:08 +0000,Tue; 24 Aug 2010 21:14:27 +0000,Tue; 21 Jul 2009 06:14:13 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-717
MAPREDUCE-718,Improvement,Major,jobtracker,Support for per-phase speculative execution,It would be good to have support for per-phase speculative execution where the algorithm looks at the current phase of a task; and compares with the other tasks in the same phase before deciding to launch a speculative task. That would have the following benefits: 1) Support for jobs where map tasks progresses jumps from 0% to 100%. This is true for some jobs like randomwriter. Today; we would launch speculative tasks for such jobs (assuming that the tasks are not making progress). But most of them would be unnecessary.  2) In reality; for reduces; the three phases are quite different from each other; and they take different times too. We should see better results when we look at per-phase speculation.,Open,Unresolved,,Unassigned,Devaraj Das,Tue; 7 Jul 2009 04:21:30 +0000,Sun; 12 Dec 2010 17:10:46 +0000,,,0.21.0,,MAPREDUCE-901,MAPREDUCE-2216,https://issues.apache.org/jira/browse/MAPREDUCE-718
MAPREDUCE-719,Bug,Major,test,"Not able to run Mapred Reliability test as ""other"" user.","While executing ReliabilityTest as ""other"" user; following issues were observed:  -- Tasktrackers are not being killed as ""other"" user is not the owner of tasktrackers. -- This test program just gives the usage message if not able to kill TTs.       ""  INFO mapred.ReliabilityTest: hostname: usage: kill [ -s signal | -p ] [ -a ] pid ...""       Instead it should give an error message and should stop further execution by giving non-zero exit code.",Resolved,Cannot Reproduce,,Unassigned,Suman Sehgal,Tue; 7 Jul 2009 04:45:26 +0000,Wed; 23 Jul 2014 18:48:23 +0000,Wed; 23 Jul 2014 18:48:23 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-719
MAPREDUCE-720,Bug,Major,tasktracker,Task logs should have right access-control,nan,Resolved,Duplicate,HADOOP-4491,Sreekanth Ramakrishnan,Vinod Kumar Vavilapalli,Tue; 7 Jul 2009 05:06:35 +0000,Mon; 10 Aug 2009 10:55:31 +0000,Mon; 10 Aug 2009 10:55:31 +0000,,,,,MAPREDUCE-842,https://issues.apache.org/jira/browse/MAPREDUCE-720
MAPREDUCE-721,Bug,Major,documentation,"When ""mapred.job.tracker.persist.jobstatus.hours"" is set to x hours; the files are not getting deleted after that x hours.It gets deleted after some random hours which is greater than x hours.","When ""mapred.job.tracker.persist.jobstatus.hours"" is set to 1 hour; the jobid files; present in configured directory; are not getting deleted after that 1 hour. It gets deleted after some random hours.  This is irrespective of whether ""mapred.job.tracker.persist.jobstatus.dir"" is set to local file system or DFS.  Steps to reproduce the issue:  1) Im mapred-site.xml;  Set ""mapred.job.tracker.persist.jobstatus.active"" to ""true"" Set ""mapred.job.tracker.persist.jobstatus.hours"" to ""1"" Set ""mapred.job.tracker.persist.jobstatus.dir"" to either  a local file syste by preixing it  with file: ""  2) After that run any job. 3) After it is complete the job id file comes in the configured directory. 4) Wait for one hour 5) Observe After 1 hour the files are not deleted. 6) After some random hours; files gets deleted.",Open,Unresolved,,Unassigned,Iyappan Srinivasan,Tue; 7 Jul 2009 07:51:56 +0000,Wed; 23 Jul 2014 18:54:39 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-721
MAPREDUCE-722,Bug,Major,capacity-sched,More slots are getting reserved for HiRAM job tasks then required,Submitted a normal job with map=124=reduces After submitted High RAM with maps=31=reduces map.memory=1800 reduce.memory=2800 Again 3 job maps=124=reduces total of 248 slots were reserved for both maps and reduces for High Job which much higher then required. Is observed in Hadoop 0.20.0,Closed,Fixed,,Vinod Kumar Vavilapalli,Karam Singh,Tue; 7 Jul 2009 08:27:08 +0000,Tue; 24 Aug 2010 21:14:27 +0000,Tue; 7 Jul 2009 17:02:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-722
YARN-2341,Test,Major,capacityscheduler,Refactor TestCapacityScheduler to separate tests per feature,TestCapacityScheduler has grown rapidly over time. It now has tests for various features interspersed amongst each other. It would be helpful to separate out tests per feature; moving out the central mock objects to a primary test class.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Tue; 7 Jul 2009 09:43:32 +0000,Wed; 23 Jul 2014 18:55:58 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-2341
MAPREDUCE-724,Bug,Minor,,Reducer should not be abstract in order to serve as substitute for IdentityReducer,The old IdentityReducer class has been deprecated since the new Reducer class's default behavior is the very same. The @deprecated tag indicates Reducer is a substitute. However it is an abstract class and cannot be instantiated; which causes problems. I imagine it is just a matter of removing the 'abstract' keyword.,Resolved,Duplicate,HADOOP-5691,Unassigned,Sean Owen,Tue; 7 Jul 2009 10:38:48 +0000,Tue; 7 Jul 2009 10:50:08 +0000,Tue; 7 Jul 2009 10:50:08 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-724
MAPREDUCE-725,Bug,Major,capacity-sched,CapacityScheduler.TaskSchedulingMgr.hasSpeculativeTask bypasses HADOOP-2141,CapacityScheduler.TaskSchedulingMgr.hasSpeculativeTask has a duplicate of the old speculation code (pre HADOOP-2141) which needs to be fixed in-order for speculation to work correctly.,Resolved,Incomplete,,Unassigned,Arun C Murthy,Tue; 7 Jul 2009 16:53:13 +0000,Wed; 23 Jul 2014 18:57:09 +0000,Wed; 23 Jul 2014 18:57:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-725
MAPREDUCE-726,Bug,Major,,Move the mapred script to map/reduce,The mapred script should be moved to mapreduce from Common. This is the parallel of HADOOP-6123.,Resolved,Fixed,,Dick King,Owen O'Malley,Tue; 7 Jul 2009 21:04:19 +0000,Wed; 23 Jul 2014 18:44:08 +0000,Wed; 23 Jul 2014 18:44:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-726
MAPREDUCE-727,Bug,Major,,Move the bin/hadoop jar command over to bin/mapred,Currently 'bin mapred.,Resolved,Fixed,,Unassigned,Arun C Murthy,Tue; 7 Jul 2009 21:27:09 +0000,Wed; 23 Jul 2014 19:05:27 +0000,Wed; 23 Jul 2014 19:05:27 +0000,,,,,HADOOP-9902;MAPREDUCE-967,https://issues.apache.org/jira/browse/MAPREDUCE-727
MAPREDUCE-728,New Feature,Major,,Mumak: Map-Reduce Simulator,Vision:  We want to build a Simulator to simulate large-scale Hadoop clusters; applications and workloads. This would be invaluable in furthering Hadoop by providing a tool for researchers and developers to prototype features (e.g. pluggable block-placement for HDFS; Map-Reduce schedulers etc.) and predict their behaviour and performance with reasonable amount of confidence; there-by aiding rapid innovation.    First Cut: Simulator for the Map-Reduce Scheduler  The Map-Reduce Scheduler is a fertile area of interest with at least four schedulers; each with their own set of features; currently in existence: Default Scheduler; Capacity Scheduler; Fairshare Scheduler  Priority Scheduler.  Each scheduler's scheduling decisions are driven by many factors; such as fairness; capacity guarantee; resource availability; data-locality etc.  Given that; it is non-trivial to accurately choose a single scheduler or even a set of desired features to predict the right scheduler (or features) for a given workload. Hence a simulator which can predict how well a particular scheduler works for some specific workload by quickly iterating over schedulers and o; network topology) etc.,Closed,Fixed,,Hong Tang,Arun C Murthy,Tue; 7 Jul 2009 21:45:27 +0000,Fri; 30 Oct 2015 10:28:33 +0000,Fri; 25 Sep 2009 00:26:53 +0000,,0.21.0,,MAPREDUCE-995;MAPREDUCE-751,MAPREDUCE-1001;MAPREDUCE-1006;MAPREDUCE-729,https://issues.apache.org/jira/browse/MAPREDUCE-728
MAPREDUCE-729,Improvement,Major,jobtracker,Create a MapReduceMaster interface for the JobTracker,It would be useful to have a 'master' interface which specifies all the interfaces exposed by the JobTracker to allow for mock-objects; simulation (MAPREDUCE-728) etc.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Tue; 7 Jul 2009 21:53:36 +0000,Fri; 2 Jul 2010 00:04:32 +0000,,,,,,MAPREDUCE-728,https://issues.apache.org/jira/browse/MAPREDUCE-729
MAPREDUCE-730,Bug,Major,harchive,allow relative paths to be created inside archives.,This jira is a shadow jira for mapreduce changes related to HADOOP-3663. Archives currently stores the full path from the input sources - since it allows multiple sources and regular expressions as inputs. So the created archives have the full path of the input sources. This is un intuitive and a user hassle. We should get rid of it and allow users to say that the created archive should be relative to some absolute path and throw an excpetion if the input does not confirm to the relative absolute path.,Closed,Duplicate,MAPREDUCE-739,Mahadev konar,Mahadev konar,Wed; 8 Jul 2009 00:06:43 +0000,Tue; 24 Aug 2010 21:14:28 +0000,Thu; 16 Jul 2009 23:14:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-730
MAPREDUCE-731,Improvement,Major,jobtracker,Factor out the timer code in jobtracker and add a callback interface,I can see LostTracker; ExpiryJobs and ExpiryLaunchingTasks code in the jobtracker which essentially do the same thing.,Open,Unresolved,,Unassigned,Amar Kamat,Wed; 8 Jul 2009 05:28:46 +0000,Wed; 8 Jul 2009 17:29:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-731
MAPREDUCE-732,Bug,Minor,,"node health check script should not log ""UNHEALTHY"" status for every heartbeat in INFO mode",Currently; when a TT is blacklisted by the node health check script; for every heartbeat a message such as the following is being logged.   Due to this; the the JT logs fill up rapidly clogging the logdirs. Hence this message should be logged in DEBUG mode instead of INFO mode.,Closed,Fixed,,Sreekanth Ramakrishnan,Ramya Sunil,Wed; 8 Jul 2009 09:18:40 +0000,Tue; 24 Aug 2010 21:14:29 +0000,Thu; 9 Jul 2009 10:42:47 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-732
MAPREDUCE-733,Bug,Major,tasktracker,When running ant test TestTrackerBlacklistAcrossJobs; losing task tracker heartbeat exception occurs. ,When running ant test TestTrackerBlacklistAcrossJobs; losing task tracker heartbeat.   It seems when a  task tracker is killed ; it throws exception. Instead it should catch it and process it and allow the rest of the flow to go through.  2009-07-08 11:58:26;116 INFO  ipc.Server (Server. transmitHeartBeat(1196)) - Resending 'status' to 'localhost' with reponseId '6,Closed,Fixed,,Arun C Murthy,Iyappan Srinivasan,Wed; 8 Jul 2009 12:08:44 +0000,Tue; 24 Aug 2010 21:14:29 +0000,Thu; 9 Jul 2009 17:19:43 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-733
MAPREDUCE-734,Bug,Major,capacity-sched,java.util.ConcurrentModificationException observed in unreserving slots for HiRam Jobs,Ran jobs out which 3 were HiRAM; the job were not removed from scheduler queue even after they successfully completed hadoop queue -info queue -showJobs displays somwthing like -: job_200907080724_0031   2       1247059146868   username  NORMAL  0 running map tasks using 0 map slots. 0 additional slots reserved. 0 running reduce tasks using 0 reduce slots. 60 additional slots reserved. job_200907080724_0030   2       1247059146972   username  NORMAL  0 running map tasks using 0 map slots. 0 additional slots reserved. 0 running reduce tasks using 0 reduce slots. 60 additional slots reserved.  But it does not block anything; but seems like zombie process of system Jobtracker log show  util.ConcurrentModificationException,Closed,Fixed,,Arun C Murthy,Karam Singh,Wed; 8 Jul 2009 15:00:05 +0000,Tue; 24 Aug 2010 21:14:31 +0000,Thu; 9 Jul 2009 12:32:56 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-734
MAPREDUCE-735,Bug,Major,,ArrayIndexOutOfBoundsException is thrown by KeyFieldBasedPartitioner,"KeyFieldBasedPartitioner throws ""KeyFieldBasedPartitioner"" when some part of the specified key is missing.  Scenario : ======= when  value of num.key.fields.for.partition is greater than the separators provided in the input. Command: ======== hadoop jar streaming.jar -Dmapred.reduce.tasks=3 -Dnum.key.fields.for.partition=5 -input input-dir  -output output-dir -mapper org.apache.hadoop.mapred.lib.IdentityMapper -reducer org.apache.hadoop.mapred.lib.IdentityReducer -inputformat org.apache.hadoop.mapred.KeyValueTextInputFormat -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner",Resolved,Fixed,,Amar Kamat,Suman Sehgal,Wed; 8 Jul 2009 05:43:19 +0000,Wed; 22 Jul 2009 14:48:30 +0000,Wed; 22 Jul 2009 14:48:30 +0000,,0.20.1,,MAPREDUCE-2,,https://issues.apache.org/jira/browse/MAPREDUCE-735
MAPREDUCE-736,Bug,Minor,,Undefined variable is treated as string.,"This issue is related to HADOOP-2838. For X=$X:Y : Append Y to X (which should be taken from the tasktracker) ;  if  we append to an undefined variable then value for undefined variable should be displayed as blank  e.g. NEW_PATH=$NEW_PATH2: tmp"") in the environemnt.   This is happening in case of default task-controller only. This scenario works fine with linux task-controller.",Resolved,Incomplete,,Unassigned,Suman Sehgal,Tue; 23 Jun 2009 11:25:55 +0000,Tue; 22 Jul 2014 22:07:18 +0000,Tue; 22 Jul 2014 22:07:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-736
MAPREDUCE-737,New Feature,Major,,High Availability support for Hadoop,Currently; We look at the HA of Hadoop cluster. We need to consider the NameNode HA as well as Jobtracker HA. For NameNode; we want to build primary slaves on log. Whether will we use Linux HA package or NameNode-built-in HA package without the help of outter Linux HA package.  After NameNode become high availability; is it necessary to provide HA for Jobtracker? Can Jobtracker  persist the states of Jobs and tasks into HA NameNode? Or Jobtracker also needs the same approach from NameNode for HA support.,Resolved,Duplicate,HDFS-1623,Unassigned,Jie Qiu,Tue; 30 Jun 2009 10:05:00 +0000,Wed; 23 Jul 2014 18:31:14 +0000,Wed; 23 Jul 2014 18:31:14 +0000,,,,,HDFS-243;MAPREDUCE-2288,https://issues.apache.org/jira/browse/MAPREDUCE-737
HADOOP-6162,Improvement,Major,,MapFile doesn't work with serializables other than Writables,Since 0.18 (I think); SequenceFiles have supported serializing arbitrary objects through the serialization framework.  MapFiles still don't.  They require WritableComparable keys and Writable values.,Open,Unresolved,,Unassigned,Justin Patterson,Tue; 7 Jul 2009 19:36:10 +0000,Mon; 27 Jul 2009 08:16:10 +0000,,,,,,,https://issues.apache.org/jira/browse/HADOOP-6162
MAPREDUCE-739,Improvement,Major,harchive,Allow relative paths to be created inside archives.,Archives currently stores the full path from the input sources  since it allows multiple sources and regular expressions as inputs. So the created archives have the full path of the input sources. This is un intuitive and a user hassle. We should get rid of it and allow users to say that the created archive should be relative to some absolute path and throw an excpetion if the input does not confirm to the relative absolute path.,Closed,Fixed,MAPREDUCE-730,Mahadev konar,Mahadev konar,Sat; 28 Jun 2008 00:12:59 +0000,Tue; 24 Aug 2010 21:14:31 +0000,Fri; 17 Jul 2009 02:04:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-739
MAPREDUCE-740,New Feature,Major,jobtracker,Provide summary information per job once a job is finished.,It would be nice if JobTracker can output a one line summary information per job once a job is finished. Otherwise; users or system administrators would end up scraping individual job history logs.,Closed,Fixed,,Arun C Murthy,Hong Tang,Wed; 8 Jul 2009 20:36:12 +0000,Tue; 24 Aug 2010 21:14:32 +0000,Sun; 19 Jul 2009 05:06:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-740
MAPREDUCE-741,Task,Major,documentation,New Hadoop MapReduce Site,New Hadoop MapReduce Site  Set up site (initial pass). May need to add more content. May need to update some links.,Resolved,Fixed,,Doug Cutting,Corinne Chandel,Wed; 8 Jul 2009 23:34:21 +0000,Thu; 16 Jul 2009 21:06:15 +0000,Thu; 16 Jul 2009 21:06:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-741
MAPREDUCE-742,Improvement,Minor,documentation;examples,Improve the java comments for the    examples,There are 3 examples; pi; bbp and distbbp for  computation.  We should tell the difference between them.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 8 Jul 2009 23:35:32 +0000,Tue; 24 Aug 2010 21:14:32 +0000,Fri; 10 Jul 2009 23:02:59 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-742
MAPREDUCE-743,Bug,Major,task,Progress of map phase in map task is not updated properly,Progress of map phase in map task is not updated properly. The progress set by TrackedRecordReader and NewTrackingRecordReader should set the progress object of map phase. It was setting it as the progress of whole task and because of phases; this is not considered as part of map task progress.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Thu; 9 Jul 2009 02:37:54 +0000,Tue; 24 Aug 2010 21:14:33 +0000,Wed; 22 Jul 2009 15:25:16 +0000,,0.21.0,,HADOOP-6163,,https://issues.apache.org/jira/browse/MAPREDUCE-743
MAPREDUCE-744,Sub-task,Major,distributed-cache;security;tasktracker,Support in DistributedCache to share cache files with other users after HADOOP-4493,HADOOP-4493 aims to completely privatize the files distributed to TT via DistributedCache. This jira issues focuses on sharing some all of these files with all other users.,Closed,Fixed,,Devaraj Das,Vinod Kumar Vavilapalli,Thu; 9 Jul 2009 09:49:47 +0000,Tue; 24 Aug 2010 21:14:33 +0000,Fri; 25 Dec 2009 00:56:13 +0000,,,,MAPREDUCE-856,,https://issues.apache.org/jira/browse/MAPREDUCE-744
MAPREDUCE-745,Bug,Major,jobtracker,TestRecoveryManager fails sometimes,nan,Resolved,Fixed,,Amar Kamat,Amareshwari Sriramadasu,Fri; 10 Jul 2009 07:42:03 +0000,Mon; 31 Aug 2009 05:32:16 +0000,Fri; 21 Aug 2009 05:00:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-745
MAPREDUCE-746,Bug,Minor,jobtracker,When a  task tracker is killed; there is a Null Pointer exception thrown.,When a task tracker is killed; the job completes. But tehre is a null pointer exception thrown:   lang.NullPointerException  tempts of the lost trackers to other nodes. 9) The job tracker logs has this exception.,Resolved,Duplicate,MAPREDUCE-754,Unassigned,Iyappan Srinivasan,Fri; 10 Jul 2009 08:11:24 +0000,Fri; 6 Nov 2009 06:20:35 +0000,Fri; 6 Nov 2009 06:20:35 +0000,,,,,MAPREDUCE-754,https://issues.apache.org/jira/browse/MAPREDUCE-746
MAPREDUCE-747,Bug,Major,,In Job Tracker logs; some host locations [either in SPLITS or in HOSTNAME subrecords] have numeric host locations,"For example; instead of saying the normal    HOSTNAME="" 1 .197""  where the IP address of node0123.hadoop-cluster.megacorp.com is in fact 1.2.3.197 .  This is not a property of certain hosts.  In our cluster; most hosts are occasionally reported in each of the two formats.",Resolved,Incomplete,,Unassigned,Dick King,Fri; 10 Jul 2009 18:11:21 +0000,Wed; 23 Jul 2014 19:19:43 +0000,Wed; 23 Jul 2014 19:19:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-747
MAPREDUCE-748,Bug,Major,,In Job Tracker log map attempt failure reports; failed maps show a HOSTNAME without a rack ID.,"For example; from a job tracker log:  MapAttempt TASK_TYPE=""MAP"" TASKID=""task_200904211745_0002_m_000002"" TASK_ATTEMPT_ID=""attempt_200904211745_0002_m_000002_0"" START_TIME=""1240336754665"" TRACKER_NAME=""tracker_redacted1670 .com""",Resolved,Incomplete,,Unassigned,Dick King,Fri; 10 Jul 2009 18:27:08 +0000,Wed; 23 Jul 2014 19:20:06 +0000,Wed; 23 Jul 2014 19:20:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-748
MAPREDUCE-749,Improvement,Major,,Make Sqoop unit tests more Hudson-friendly,Hudson servers (other than Apache's) need to be able to run the sqoop unit tests which depend on thirdparty JDBC drivers   database implementations. The build.xml needs some refactoring to make this happen.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 10 Jul 2009 21:29:42 +0000,Fri; 2 Jul 2010 06:31:47 +0000,Fri; 21 Aug 2009 14:00:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-749
MAPREDUCE-750,Improvement,Major,,Extensible ConnManager factory API,Sqoop uses the ConnFactory class to instantiate a ConnManager implementation based on the connect string and other arguments supplied by the user. This allows per-database logic to be encapsulated in different ConnManager instances; and dynamically chosen based on which database the user is actually importing from. But adding new ConnManager implementations requires modifying the source of a common ConnFactory class. An indirection layer should be used to delegate instantiation to a number of factory implementations which can be specified in the static configuration or at runtime.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Sat; 11 Jul 2009 00:12:52 +0000,Fri; 2 Jul 2010 06:31:48 +0000,Wed; 26 Aug 2009 09:11:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-750
MAPREDUCE-751,New Feature,Major,tools/rumen,Rumen: a tool to extract job characterization data from job tracker logs,"We propose a new map reduce component; rumen; which can be used to process job history logs to produce any or all of the following:   	Retrospective info describing the statistical behavior of the amount of time it would have taken to launch a job into a certain percentage of the number of mapper slots in the log's cluster; given the load over the period covered by the log     	Statistical info as to the runtimes and shuffle times; etc. of the tasks and jobs covered by the log     	files describing detailed job trace information; and the network topology as inferred from the host locations and rack IDs that arise in the job tracker log.  In addition to this facility; rumen includes readers for this information to return job and detailed task information to other tools.            These other tools include a more advanced version of gridmix; and also includes mumak: see blocked issues.",Closed,Fixed,,Dick King,Dick King,Sun; 12 Jul 2009 04:04:24 +0000,Thu; 24 Nov 2011 14:34:42 +0000,Fri; 28 Aug 2009 00:13:34 +0000,,,,MAPREDUCE-728;MAPREDUCE-776,CHUKWA-342,https://issues.apache.org/jira/browse/MAPREDUCE-751
MAPREDUCE-752,Bug,Major,distributed-cache,DistributedCache.addArchiveToClassPath doesn't work,addArchiveToClassPath is a method of DistributedCache class. It should be called before running a task. It accepts path to a jar file on a DFS. After it this method should put this jar file on sitribuuted cache and than add this file to classpath to each map reduce process on job tracker.   This method don't work:  in TaskRunner there is an algorithm that looks for correspondence between DFS paths and local paths in distributed cache. It compares  if (archivesi.getPath().equals( archiveClasspathsj.toString())){  instead of  if (archivesi.toString().equals( archiveClasspathsj.toString())),Resolved,Fixed,,Unassigned,Vladimir Klimontovich,Sun; 12 Jul 2009 13:24:07 +0000,Wed; 23 Jul 2014 19:18:42 +0000,Wed; 23 Jul 2014 19:18:42 +0000,,0.20.1;0.21.0,,,MAPREDUCE-2361;MAPREDUCE-1581,https://issues.apache.org/jira/browse/MAPREDUCE-752
MAPREDUCE-753,Bug,Minor,contrib/streaming;documentation,"In Streaming; ""comparator options"" column does not document the global options.","In streaming;  the ""-Dmapred.text.key.partitioner.options"" has some options like ""-r -k7;7 -k3;3""; which works like this : First soft inteh seventh column; then in taht sorting; subsort on 3rd column and reverse both these sorts.  The documentation for this is not found anywhere. Please document it.",Open,Unresolved,,Unassigned,Iyappan Srinivasan,Mon; 13 Jul 2009 08:00:00 +0000,Fri; 7 May 2010 05:27:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-753
MAPREDUCE-754,Bug,Minor,jobtracker,NPE in expiry thread when a TT is lost,"NullPointerException is obtained in Tracker Expiry Thread. Below is the exception obtained in the JT logs    The steps to reproduce this issue are:  	Blacklist a TT. 	Restart it. 	The above exception is obtained when the first instance of TT is marked as lost.    However the above exception does not break any functionality.",Closed,Fixed,,Amar Kamat,Ramya Sunil,Mon; 13 Jul 2009 12:03:28 +0000,Tue; 24 Aug 2010 21:14:37 +0000,Tue; 8 Dec 2009 15:22:13 +0000,,0.20.1,,,MAPREDUCE-1188;MAPREDUCE-746,https://issues.apache.org/jira/browse/MAPREDUCE-754
MAPREDUCE-755,Improvement,Major,test,Improve TestMRKeyFieldBasedComparator to test encoded byte array,TestMRKeyFieldBasedComparator.testWithoutMRJob() tests KeyFieldBasedComparator.compare() which expects bytes[] with specific encoding. Encoded byte array should also be tested.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 13 Jul 2009 17:07:55 +0000,Tue; 21 Jul 2009 05:14:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-755
MAPREDUCE-756,Bug,Major,jobtracker,TestSpeculativeExecution.testAtSpeculativeCap timed out in one of the runs,TestSpeculativeExecution.testAtSpeculativeCap timed out in one of the hudson runs @  http: ,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Tue; 14 Jul 2009 03:45:59 +0000,Fri; 2 Jul 2010 00:04:49 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-756
MAPREDUCE-757,Bug,Major,jobtracker,JobConf will not be deleted from the logs folder if job retires from finalizeJob(),MAPREDUCE-130 fixed the case where the job is retired from the retire jobs thread. But jobs can also retire when the num-job-per-user limit is exceeded. In such cases the conf file will not be deleted.,Resolved,Duplicate,MAPREDUCE-2714,Amar Kamat,Amar Kamat,Tue; 14 Jul 2009 04:42:17 +0000,Fri; 11 Nov 2011 06:26:27 +0000,Tue; 11 Aug 2009 12:08:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-757
MAPREDUCE-758,Bug,Major,jobtracker,JobInProgressListener events might be garbled,"Consider the following scenario   	EagerTaskInitializer calls jobtracker.initJob(obj1) 	initJob will snapshot the job run-state to PREP 	Before initJob() issues job1.initTask(); user issues a kill and the job now moves to KILLED state. The jobtracker updates the listener about the PREP-KILLED event. 	Now initJob() issues a job1.initTask() which comes out nicely. 	initJob() now snapshots the job state it will be KILLED 	jobtracker now updates the listener with PREP-KILLED event which is incorrect",Resolved,Incomplete,,Unassigned,Amar Kamat,Tue; 14 Jul 2009 06:48:23 +0000,Wed; 23 Jul 2014 19:31:19 +0000,Wed; 23 Jul 2014 19:31:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-758
MAPREDUCE-759,Bug,Major,tasktracker,Refactor localization code in TaskTracker,Localization code in TaskTracker is spread across TaskTracker; TaskTracker.TaskInProgress and TaskRunner. It turns out to be a bit complicated piece of code; as was observed during HADOOP-4491. It would be good if it is refactored into a single class place.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Tue; 14 Jul 2009 08:28:53 +0000,Wed; 23 Jul 2014 19:31:46 +0000,Wed; 23 Jul 2014 19:31:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-759
MAPREDUCE-760,Bug,Major,test,TestNodeRefresh might not work as expected,MAPREDUCE-677 fixed one part of the problem. It is possible that the tasktracker might not have joined the jobtracker and hence the asserts might fail.,Closed,Fixed,,Amar Kamat,Amar Kamat,Tue; 14 Jul 2009 10:53:10 +0000,Tue; 24 Aug 2010 21:14:38 +0000,Fri; 31 Jul 2009 08:38:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-760
MAPREDUCE-761,Improvement,Major,jobtracker,Revisit MapRed logging information,We should revisit what information should be logged so that debugging becomes easier.,Resolved,Incomplete,,Unassigned,Amar Kamat,Tue; 14 Jul 2009 11:34:32 +0000,Wed; 23 Jul 2014 19:33:26 +0000,Wed; 23 Jul 2014 19:33:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-761
MAPREDUCE-762,Bug,Major,,Task's process trees may not be killed if a TT is restarted,Some work has been done to make sure the tasktrackers kill process trees of tasks when they finish (either successfully; or with failures or when they are killed). Related JIRAs are HADOOP-2721; HADOOP-5488 and HADOOP-5420. But when TTs are restarted; we do not handle killing of process trees - though tasks will themselves die on re-establishing contact with the TT.,Resolved,Incomplete,,Unassigned,Hemanth Yamijala,Wed; 15 Jul 2009 07:17:51 +0000,Wed; 23 Jul 2014 19:45:10 +0000,Wed; 23 Jul 2014 19:45:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-762
MAPREDUCE-763,Bug,Major,capacity-sched,Capacity scheduler should clean up reservations if it runs tasks on nodes other than where it has made reservations,Currently capacity scheduler makes a reservation on nodes for high memory jobs that cannot currently run at the time. It could happen that in the meantime other tasktrackers become free to run the tasks of this job. Ideally in the next heartbeat from the reserved TTs the reservation should be removed. Otherwise it could unnecessarily block capacity for a while (until the TT has enough slots free to run a task of this job).,Resolved,Incomplete,,rahul k singh,Hemanth Yamijala,Wed; 15 Jul 2009 07:28:32 +0000,Wed; 23 Jul 2014 19:50:42 +0000,Wed; 23 Jul 2014 19:50:42 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-763
MAPREDUCE-764,Bug,Blocker,contrib/streaming,TypedBytesInput's readRaw() does not preserve custom type codes,The typed bytes format supports byte sequences of the form custom type code length bytes. When reading such a sequence via TypedBytesInput's readRaw() method; however; the returned sequence currently is 0 length bytes (0 is the type code for a bytes array); which leads to bugs such as the one described here.,Closed,Fixed,,Klaas Bosteels,Klaas Bosteels,Wed; 15 Jul 2009 07:48:12 +0000,Sat; 10 Mar 2012 01:57:44 +0000,Mon; 7 Sep 2009 12:29:54 +0000,,0.21.0;1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-764
MAPREDUCE-765,Improvement,Minor,distcp;jobtracker,eliminate the usage of FileSystem.create( ) depracated by Hadoop-5438 ,nan,Closed,Fixed,,He Yongqiang,He Yongqiang,Wed; 15 Jul 2009 13:27:48 +0000,Tue; 24 Aug 2010 21:14:39 +0000,Wed; 22 Jul 2009 18:49:46 +0000,,0.21.0,,,HADOOP-6138,https://issues.apache.org/jira/browse/MAPREDUCE-765
MAPREDUCE-766,Improvement,Major,,Enhance -list-blacklisted-trackers to display host name; blacklisted reason and blacklist report.,Currently; the -list-blacklisted-trackers in the mapred job option list only tracker name. We should enhance it to display as hostname; reason for blacklisting and blacklist report.,Closed,Fixed,,Sreekanth Ramakrishnan,Sreekanth Ramakrishnan,Thu; 16 Jul 2009 02:40:34 +0000,Tue; 24 Aug 2010 21:14:40 +0000,Fri; 31 Jul 2009 09:17:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-766
MAPREDUCE-767,Improvement,Major,contrib/streaming,to remove mapreduce dependency on commons-cli2,mapreduce; streaming and eclipse plugin depends on common-cli2,Resolved,Fixed,,Amar Kamat,Giridharan Kesavan,Thu; 16 Jul 2009 05:35:36 +0000,Mon; 31 Aug 2009 05:33:20 +0000,Wed; 26 Aug 2009 09:39:01 +0000,,0.20.1,,HADOOP-3676,HADOOP-6178,https://issues.apache.org/jira/browse/MAPREDUCE-767
MAPREDUCE-768,New Feature,Major,,Configuration information should generate dump in a standard format.,We need to generate the configuration dump in a standard format .,Closed,Fixed,,V.V.Chaitanya Krishna,rahul k singh,Thu; 16 Jul 2009 08:25:08 +0000,Tue; 24 Aug 2010 21:14:41 +0000,Tue; 25 Aug 2009 14:12:38 +0000,,,,HADOOP-6184,,https://issues.apache.org/jira/browse/MAPREDUCE-768
MAPREDUCE-769,Bug,Major,,findbugs and javac warnings on trunk is non-zero,Obsvered that there are Six findbugs warnings in trunk. They would have gone in;  because of manual test-patch with a different findbugs version.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 17 Jul 2009 11:50:26 +0000,Tue; 24 Aug 2010 21:14:41 +0000,Thu; 15 Oct 2009 11:26:50 +0000,,0.21.0,,AVRO-137,,https://issues.apache.org/jira/browse/MAPREDUCE-769
MAPREDUCE-770,Bug,Minor,test,org.apache.hadoop.tools.TestCopyFiles may leave junk files when an assertion fails,"In most of the testXxxYyyZzz methods; the code runs:     preliminaries     ToolRunner( ...; new String[]  { local and DFS filenames and more filenames } );     assertMaybe(""this result stank""; conditions);    assertMaybe(""this other result stank""; conditions);     deldir(deletee's name);    deldir(second deletee's name);  The assertMaybe's throw AssertionFailedError .  That's what they DO.  Shouldn't this stuff be protected with a try ... finally construct?",Resolved,Fixed,,Unassigned,Dick King,Fri; 17 Jul 2009 21:42:30 +0000,Wed; 23 Jul 2014 20:00:00 +0000,Wed; 23 Jul 2014 20:00:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-770
MAPREDUCE-771,Bug,Blocker,jobtracker,Setup and cleanup tasks remain in UNASSIGNED state for a long time on tasktrackers with long running high RAM tasks,When a high RAM job's task is scheduled on a tasktracker; the number of slots it occupies will be more than one. If enough such tasks are scheduled; there can come a situation when there are no more slots free on the node but the number of tasks running is less than the number of slots. The jobtracker currently schedules a setup or cleanup task based on how many tasks are running on the system; rather than slots. As a result of this; it can schedule a setup or cleanup task on a tasktracker without any free slots. If the high RAM job's tasks are long running; this will significantly delay the running of the setup or cleanup task; and thus the entire job.,Closed,Fixed,,Hemanth Yamijala,Hemanth Yamijala,Sun; 19 Jul 2009 11:58:41 +0000,Tue; 24 Aug 2010 21:14:43 +0000,Mon; 20 Jul 2009 08:45:22 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-771
MAPREDUCE-772,Improvement,Major,,Chaging LineRecordReader algo so that it does not need to skip backwards in the stream,The current algorithm of the LineRecordReader needs to move backwards in the stream (in its constructor) to correctly position itself in the stream.  So it moves back one byte from the start of its split and try to read a record (i.e. a line) and throws that away.  This is so because it is sure that; this line would be taken care of by some other mapper.  This algorithm is difficult and in-efficient if used for compressed stream where data is coming to the LineRecordReader via some codecs. (Although in the current implementation; Hadoop does not split a compressed file and only makes one split from the start to the end of the file and so only one mapper handles it.  We are currently working on BZip2 codecs where splitting is possible to work with Hadoop.  So this proposed change will make it possible to uniformly handle plain as well as compressed stream.)  In the new algorithm; each mapper always skips its first line because it is sure that; that line would have been read by some other mapper.  So now each mapper must finish its reading at a record boundary which is always beyond its upper split limit.  Due to this change; LineRecordReader does not need to move backwards in the stream.,Closed,Fixed,,Abdul Qadeer,Abdul Qadeer,Sat; 23 Aug 2008 00:39:13 +0000,Tue; 24 Aug 2010 21:14:43 +0000,Tue; 21 Jul 2009 05:17:32 +0000,,,,,HADOOP-3646;HADOOP-4182,https://issues.apache.org/jira/browse/MAPREDUCE-772
MAPREDUCE-773,Bug,Major,task,LineRecordReader can report non-zero progress while it is processing a compressed stream,"Currently; the LineRecordReader returns 0.0 from getProgress() for most inputs (since the ""end"" of the filesplit is set to Long.MAX_VALUE for compressed inputs). This can be improved to return a non-zero progress even for compressed streams (though it may not be very reflective of the actual progress).",Closed,Fixed,,Devaraj Das,Devaraj Das,Mon; 20 Jul 2009 11:13:55 +0000,Tue; 24 Aug 2010 21:14:45 +0000,Tue; 18 Aug 2009 08:55:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-773
MAPREDUCE-774,Bug,Trivial,examples,Java/C++ word count examples have different outputs,I ran the c++ word count example using pipes and got this result:          Alethea 1488         Arneb   1508         Auriculariales  1518 Aktistetae      92126 Animalivora     91969 Aplacentalia    92690         Aktistetae      1503         Animalivora     1518         Aplacentalia    1452 Alethea 91928 Arneb   91926 Auriculariales  92448  The correct result generated by Java word count example is:  Aktistetae      93629 Alethea 93416 Animalivora     93487 Aplacentalia    94142 Arneb   93434 Auriculariales  93966,Resolved,Not A Problem,,Unassigned,Hyunjung Park,Mon; 20 Jul 2009 22:16:14 +0000,Wed; 23 Jul 2014 20:02:13 +0000,Wed; 23 Jul 2014 20:02:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-774
MAPREDUCE-775,New Feature,Major,contrib/vertica,Add input/output formatters for Vertica clustered ADBMS.,Add native support for Vertica as an input or output format taking advantage of parallel read and write properties of the DBMS.  On the input side allow for parametrized queries (a la prepared statements) and create a split for each combination of parameters.  Also support the parameter list to be generated from a sql statement.  For example - return metrics for all dimensions that meet criteria X with one input split for each dimension.  Divide the read among any number of hosts in the Vertica cluster.  On the output side; support Vertica streaming load to any number of hosts in the Vertica cluster.  Output may be to a different cluster than input.  Also includes Input and Output formatters that support streaming interface.  Code has been tested and run on live systems under 19 and 20.  Patch for 21 with new API will be ready end of this week.,Closed,Fixed,,Omer Trajman,Omer Trajman,Mon; 20 Jul 2009 23:34:25 +0000,Tue; 24 Aug 2010 21:14:45 +0000,Fri; 18 Sep 2009 18:24:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-775
MAPREDUCE-776,New Feature,Major,benchmarks,Gridmix: Trace-based benchmark for Map/Reduce,Previous benchmarks ( HADOOP-2369 ; HADOOP-3770 ); while informed by production jobs; were principally load generating tools used to validate stability and performance under saturation. The important dimensions of that load- submission order O; submission; and memory usage.,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 21 Jul 2009 02:09:20 +0000,Tue; 24 Aug 2010 21:14:48 +0000,Wed; 16 Sep 2009 06:41:53 +0000,,,,MAPREDUCE-751;MAPREDUCE-966,,https://issues.apache.org/jira/browse/MAPREDUCE-776
MAPREDUCE-777,New Feature,Major,client,A method for finding and tracking jobs from the new API,We need to create a replacement interface for the JobClient API in the new interface. In particular; the user needs to be able to query and track jobs that were launched by other processes.,Closed,Fixed,,Amareshwari Sriramadasu,Owen O'Malley,Tue; 21 Jul 2009 05:59:00 +0000,Tue; 18 Oct 2011 07:18:23 +0000,Fri; 18 Sep 2009 07:05:22 +0000,,,,MAPREDUCE-864;MAPREDUCE-975,,https://issues.apache.org/jira/browse/MAPREDUCE-777
MAPREDUCE-778,New Feature,Major,tools/rumen,[Rumen] Need a standalone JobHistory log anonymizer,Job history logs contain a rich set of information that can help understand and characterize cluster workload and individual job execution. Examples of work that parses or utilizes job history include HADOOP-3585; MAPREDUCE-534; HDFS-459; MAPREDUCE-728; and MAPREDUCE-776. Some of the parsing tools developed in previous work already contains a component to anonymize the logs. It would be nice to combine these effort and have a common standalone tool that can anonymizes job history logs and preserve much of the structure of the files so that existing tools on top of job history logs continue work with no modification.,Closed,Fixed,,Amar Kamat,Hong Tang,Tue; 21 Jul 2009 07:42:45 +0000,Tue; 10 Mar 2015 04:31:56 +0000,Fri; 16 Dec 2011 14:26:01 +0000,,0.23.0;2.0.0-alpha,anonymization;rumen,,MAPREDUCE-3580;MAPREDUCE-3581;HADOOP-7470,https://issues.apache.org/jira/browse/MAPREDUCE-778
MAPREDUCE-779,Improvement,Major,jobtracker,Add node health failures into JobTrackerStatistics,Add the node health failure counts into JobTrackerStatistics.,Closed,Fixed,,Sreekanth Ramakrishnan,Sreekanth Ramakrishnan,Tue; 21 Jul 2009 09:48:01 +0000,Tue; 24 Aug 2010 21:14:50 +0000,Sun; 9 Aug 2009 09:46:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-779
YARN-2342,Improvement,Major,,When killing a task; we don't always need to send a subsequent SIGKILL,In both TaskController process group is not alive or invalid signal is specified or the process doesn't have permissions. The last two don't happen in mapred code.,Open,Unresolved,,Junping Du,Vinod Kumar Vavilapalli,Tue; 21 Jul 2009 11:54:05 +0000,Fri; 1 May 2015 19:35:25 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/YARN-2342
MAPREDUCE-781,Improvement,Major,distcp,distcp overrides user-selected job name,"distcp hard-codes the hadoop job name to ""distcp"" even if the user specifies a job name. This is a problem in general; but especially for generalized replication services since the Job Tracker UI and history can't be made to indicate what is being copied in the job name.",Closed,Fixed,,Venkatesh Seetharam,Rob Weltman,Tue; 21 Jul 2009 16:49:58 +0000,Tue; 24 Aug 2010 21:14:50 +0000,Fri; 18 Sep 2009 08:09:19 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-781
MAPREDUCE-782,Improvement,Minor,performance,Use PureJavaCrc32 in mapreduce spills,HADOOP-6148 implemented a Pure Java implementation of CRC32 which performs better than the built-in one. This issue is to make use of it in the mapred package,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 21 Jul 2009 22:02:10 +0000,Tue; 25 Sep 2012 18:00:33 +0000,Mon; 27 Jul 2009 17:59:56 +0000,,,,,HADOOP-6148;HADOOP-8617,https://issues.apache.org/jira/browse/MAPREDUCE-782
MAPREDUCE-783,Improvement,Minor,,"Rename Sqoop ""local"" transfer to ""direct""","Sqoop can use tools such as mysqldump to pull from databases instead of JDBC. This is invoked using the ""--local"" command line argument. This name is based on a misunderstanding; these tools typically do offer remote access capability. Sqoop should pass host and port parameters to underlying tools where appropriate. Similarly; the ""local"" mode should be renamed; e.g.; to ""direct"" mode and use --direct as an argument instead.",Resolved,Duplicate,MAPREDUCE-816,Aaron Kimball,Aaron Kimball,Wed; 22 Jul 2009 01:02:27 +0000,Fri; 2 Jul 2010 06:31:52 +0000,Fri; 31 Jul 2009 06:21:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-783
MAPREDUCE-784,Improvement,Major,test,Modify TestUserDefinedCounters to use LocalJobRunner instead of MiniMR,This test can be modified to use LocalJobRunner.,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Wed; 22 Jul 2009 06:18:43 +0000,Tue; 24 Aug 2010 21:14:51 +0000,Fri; 24 Jul 2009 08:40:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-784
MAPREDUCE-785,Test,Major,,Refactor TestReduceFetchFromPartialMem into a separate test ,The rationale behind doing this is to enable this test alone to be included in the commit-tests target,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Wed; 22 Jul 2009 06:55:41 +0000,Tue; 24 Aug 2010 21:14:52 +0000,Wed; 22 Jul 2009 11:32:48 +0000,,,,,MAPREDUCE-670,https://issues.apache.org/jira/browse/MAPREDUCE-785
MAPREDUCE-786,Improvement,Major,jobtracker,Jobtracker history should be written aysnchronously to the filesystem,Jobtracker lock is held while writing the history events. This makes the jobtracker slow on flushes; especially when history is written to HDFS. History events should be written asynchronously to avoid this problem.,Resolved,Incomplete,,Sharad Agarwal,Sharad Agarwal,Wed; 22 Jul 2009 09:25:41 +0000,Wed; 23 Jul 2014 20:04:59 +0000,Wed; 23 Jul 2014 20:04:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-786
MAPREDUCE-787,Bug,Major,client,-files; -archives should honor user given symlink path,"Currently; if user gives an option such as -files hdfs: testfile.txt#testlink The symlink name ""testlink"" is not honored. It alwasys creates symlink with name testfile.txt in cwd of the task.  If the user has given a symlink name; it should be honored. If no symlink-name is given; then the path.getName() can be used.",Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 22 Jul 2009 11:11:23 +0000,Tue; 24 Aug 2010 21:14:52 +0000,Fri; 27 Nov 2009 10:56:29 +0000,,,,HADOOP-6334,HADOOP-6333,https://issues.apache.org/jira/browse/MAPREDUCE-787
MAPREDUCE-788,Improvement,Major,benchmarks,Modify gridmix2 to use new api.,Modify gridmix2 to use new api.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 22 Jul 2009 11:15:45 +0000,Tue; 24 Aug 2010 21:14:53 +0000,Wed; 26 Aug 2009 10:30:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-788
MAPREDUCE-789,Improvement,Major,,Oracle support for Sqoop,A separate ConnManager is needed for Oracle to support its slightly different syntax and configuration,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Wed; 22 Jul 2009 18:46:29 +0000,Fri; 2 Jul 2010 06:31:52 +0000,Wed; 12 Aug 2009 14:21:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-789
MAPREDUCE-790,Improvement,Major,jobtracker,TaskTracker blacklisted by one job should be blacklisted for all other jobs in the queue,Once a task tracker is blacklisted by one job; it is still being used by all other jobs in the queue. A blacklisted task tracker could be a signal of marginal node; and thus it should be blacklisted for all jobs at least temporarily. Also; even if one task tracker has been blacklisted globally due to too many failures; the blacklists of the jobs in the queue are not affected; and thus will continue to use the bad task tracker. This could result job failure.,Resolved,Duplicate,HADOOP-4305,Unassigned,Qi Liu,Wed; 22 Jul 2009 19:59:49 +0000,Wed; 22 Jul 2009 21:43:04 +0000,Wed; 22 Jul 2009 21:43:04 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-790
MAPREDUCE-791,New Feature,Major,documentation,Document Hadoop Map-Reduce Architecture,It would be nice to document the Map-Reduce architecture similar to the HDFS design document: http: hdfs_design.html.,Resolved,Fixed,,Unassigned,Arun C Murthy,Wed; 22 Jul 2009 22:05:40 +0000,Wed; 23 Jul 2014 20:05:30 +0000,Wed; 23 Jul 2014 20:05:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-791
MAPREDUCE-792,Bug,Minor,,javac warnings in DBInputFormat,MAPREDUCE-716 introduces   warnings,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 23 Jul 2009 00:34:09 +0000,Tue; 24 Aug 2010 21:14:54 +0000,Thu; 30 Jul 2009 18:49:39 +0000,,,,,MAPREDUCE-716,https://issues.apache.org/jira/browse/MAPREDUCE-792
MAPREDUCE-793,Test,Major,test,Create a new test that consolidates a few tests to be included in the commit-test list,There are few tests that just run similar jobs and test different functionality. It would be useful to have a test that runs one job and tests several of these functionality together so that this test can be included in the fast commit-tests target.,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Thu; 23 Jul 2009 11:10:29 +0000,Tue; 24 Aug 2010 21:14:54 +0000,Wed; 29 Jul 2009 10:36:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-793
MAPREDUCE-794,Bug,Major,jobtracker,JobTrackerInstrumentation data might be grabled ,Here is the sequence of events 1) submit a job  2) kill it in prep state  This should result into -ve values of pending maps in JobTrackerInstrumentation.,Open,Unresolved,,Unassigned,Amar Kamat,Thu; 23 Jul 2009 11:13:26 +0000,Thu; 23 Jul 2009 11:13:46 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-794
MAPREDUCE-795,Bug,Major,jobtracker,JobHistory.markCompleted() should be synchronized,Since other FS calls in JobHistory are synchronized; this call should also be synchronized. This method moves jobhistory files from running to done folder. So while other JobHistory methods perform a search in the running folder this method might move the files in the FS causing inconsistencies.,Resolved,Fixed,,Amar Kamat,Amar Kamat,Thu; 23 Jul 2009 11:20:39 +0000,Wed; 7 Oct 2009 06:21:56 +0000,Wed; 7 Oct 2009 06:21:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-795
MAPREDUCE-796,Bug,Major,examples,"Encountered ""ClassCastException"" on tasktracker while running wordcount with MultithreadedMapRunner",ClassCastException for OutOfMemoryError is encountered on tasktracker while running wordcount example with MultithreadedMapRunner.   Stack trace : =========  170),Resolved,Fixed,,Amar Kamat,Suman Sehgal,Thu; 23 Jul 2009 11:29:52 +0000,Mon; 31 Aug 2009 05:25:24 +0000,Fri; 7 Aug 2009 11:20:59 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-796
MAPREDUCE-797,Improvement,Major,contrib/mrunit,MRUnit MapReduceDriver should support combiners,"The MapReduceDriver allows you to specify a mapper and a reducer class with a simple sort ""shuffle"" between the passes. It would be nice to also support another Reducer implementation being used as a combiner in the middle.",Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 23 Jul 2009 20:29:58 +0000,Tue; 24 Aug 2010 21:14:55 +0000,Thu; 30 Jul 2009 16:35:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-797
MAPREDUCE-798,New Feature,Major,contrib/mrunit,MRUnit should be able to test a succession of MapReduce passes,"MRUnit can currently test that the inputs to a given (mapper; reducer) ""job"" produce certain outputs at the end of the reducer. It would be good to support more end-to-end tests of a series of MapReduce jobs that form a longer pipeline surrounding some data.",Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 23 Jul 2009 20:32:02 +0000,Tue; 24 Aug 2010 21:14:55 +0000,Mon; 24 Aug 2009 12:01:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-798
MAPREDUCE-799,Bug,Major,contrib/mrunit,Some of MRUnit's self-tests were not being run,Due to method naming issues; some test cases were not being executed.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 23 Jul 2009 20:33:07 +0000,Tue; 24 Aug 2010 21:14:56 +0000,Tue; 11 Aug 2009 16:31:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-799
MAPREDUCE-800,New Feature,Major,contrib/mrunit,MRUnit should support the new API,MRUnit's TestDriver implementations use the old org.apache.hadoop.mapred-based classes. TestDrivers and associated mock object implementations are required for org.apache.hadoop.mapreduce-based code.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 23 Jul 2009 20:34:44 +0000,Tue; 24 Aug 2010 21:14:56 +0000,Fri; 21 Aug 2009 14:52:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-800
MAPREDUCE-801,New Feature,Major,,MAPREDUCE framework should issue warning with too many locations for a split,Customized input-format may be buggy and report misleading locations through input-split; an example of which is PIG-878. When an input split returns too many locations; it would not only artificially inflate the percentage of data local or rack local maps; but also force scheduler to use more memory and work harder to conduct task assignment.,Resolved,Fixed,,Unassigned,Hong Tang,Fri; 24 Jul 2009 08:20:44 +0000,Wed; 23 Jul 2014 20:23:55 +0000,Wed; 23 Jul 2014 20:23:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-801
MAPREDUCE-802,Improvement,Major,jobtracker,Simplify the job updated event notification between Jobtracker and schedulers,"HADOOP-4053 and HADOOP-4149 added events to take care of updates to the state   priority of a job notified to the scheduler. We've seen some issues with this framework; such as the following:  	Events are not raised correctly at all places. If a new code path is added to kill a job; raising events is missed out. 	Events are raised with incorrect event data. For e.g. typically start time value is missed out.    The resulting contract break between jobtracker and schedulers has lead to problems in the capacity scheduler where jobs remain stuck in the queue without being ever removed and so on.  It has proven complicated to get this right in the framework and fixes have typically still left dangling cases. Or new code paths introduce new bugs.  This JIRA is about trying to simplify the interaction model so that it is more robust and works well.",Resolved,Fixed,,Sreekanth Ramakrishnan,Hemanth Yamijala,Fri; 24 Jul 2009 10:06:33 +0000,Wed; 23 Jul 2014 20:27:54 +0000,Wed; 23 Jul 2014 20:27:54 +0000,,,,,MAPREDUCE-805,https://issues.apache.org/jira/browse/MAPREDUCE-802
MAPREDUCE-803,Improvement,Major,jobtracker,Provide a command line option to clean up jobtracker system directory,When the JT is restarted; the mapreduce system directory's contents are used for job recovery. For sites that use this feature; there might be instances when we don't want to restart to read the mapred system directory. A sample use case is if there is a full cluster restart with a (typically minor) version upgrade of the Map Reduce code base. To easily support such cases; it would be nice to provide a way for clean up the jobtracker system directory so that no files will be available for cleanup.,Resolved,Duplicate,YARN-2131,Unassigned,Hemanth Yamijala,Fri; 24 Jul 2009 10:10:45 +0000,Wed; 23 Jul 2014 20:29:22 +0000,Wed; 23 Jul 2014 20:29:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-803
MAPREDUCE-804,Bug,Major,task,split.dta is no longer used (?),nan,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Fri; 24 Jul 2009 10:37:09 +0000,Tue; 28 Jul 2009 11:04:15 +0000,Tue; 28 Jul 2009 11:04:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-804
MAPREDUCE-805,Bug,Major,,Deadlock in Jobtracker,We are running a hadoop cluster (version 0.20.0) and have detected the following deadlock on our jobtracker:,Resolved,Fixed,MAPREDUCE-27,Amar Kamat,Michael Tamm,Fri; 24 Jul 2009 12:44:32 +0000,Tue; 8 Dec 2009 06:30:09 +0000,Tue; 11 Aug 2009 10:11:42 +0000,,,,,MAPREDUCE-802,https://issues.apache.org/jira/browse/MAPREDUCE-805
MAPREDUCE-806,Bug,Trivial,examples,WordCount example does not compile given the current instructions,http: WordCount.java,Resolved,Incomplete,,Unassigned,Hector Yuen,Sun; 26 Jul 2009 07:47:54 +0000,Wed; 23 Jul 2014 20:30:05 +0000,Wed; 23 Jul 2014 20:30:05 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-806
MAPREDUCE-807,Bug,Blocker,jobtracker,Stray user files in mapred.system.dir with permissions other than 777 can prevent the jobtracker from starting up.,With restart disabled; the jobtracker does a rm -rf of the mapred.system.dir. If the mapred.system.dir contains user files with permissions other than 777 then the jobtracker gets stuck in a loop trying to delete the mapred.system.dir (and each time failing with AccessControlException). The JobTracker admin has to manually cleanup the mapred.system.dir if this happens.,Resolved,Fixed,,Amar Kamat,Amar Kamat,Mon; 27 Jul 2009 06:15:43 +0000,Mon; 24 Aug 2009 12:22:06 +0000,Mon; 24 Aug 2009 11:20:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-807
MAPREDUCE-808,Bug,Major,contrib/streaming,Buffer objects incorrectly serialized to typed bytes,"TypedBytesOutput.write() should do something like     instead of     since the bytes returned by Buffer.get() are ""only valid between 0 and getCount() - 1"".",Closed,Fixed,,Klaas Bosteels,Klaas Bosteels,Mon; 27 Jul 2009 12:39:02 +0000,Tue; 24 Aug 2010 21:14:57 +0000,Mon; 10 Aug 2009 17:41:10 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-808
MAPREDUCE-809,Bug,Major,jobtracker,Job summary logs show status of completed jobs as RUNNING ,MAPREDUCE-740 added job summary logs. During testing our QA folks noticed that completed jobs show up as RUNNING in the logs.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 27 Jul 2009 22:52:59 +0000,Tue; 24 Aug 2010 21:14:58 +0000,Wed; 29 Jul 2009 23:37:02 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-809
MAPREDUCE-810,Improvement,Major,,Make TaskInProgress independent of JobTracker reference,As of today the TaskInProgress holds a reference of jobtracker and makes a back-call. These circular calls along with synchronization can lead to deadlocks.,Resolved,Duplicate,MAPREDUCE-278,Unassigned,Amar Kamat,Tue; 28 Jul 2009 04:07:08 +0000,Tue; 28 Jul 2009 10:04:43 +0000,Tue; 28 Jul 2009 09:50:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-810
MAPREDUCE-811,Bug,Major,,Refactor TaskTracker.TaskInProgress to a new class file,TaskTracker.TaskInProgress is a fairly large piece of code and can be refactored into a new file; perhaps in a new package o.a.h.mapreduce.server.tasktracker.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Tue; 28 Jul 2009 08:01:53 +0000,Tue; 28 Jul 2009 08:01:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-811
MAPREDUCE-812,Improvement,Major,jobtracker,Total number of splits/maps can be encoded as the first field while serializing splits,To find out the total number of maps; the whole split file is deserialized and  then the checks are made (num-maps = length of the split array). The issue is that if total number of splits is more then unnecessarily load all the splits and then discard it. Instead we can encode the total number of splits as the first field.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 28 Jul 2009 12:12:33 +0000,Tue; 28 Jul 2009 12:12:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-812
MAPREDUCE-813,Task,Minor,documentation,Streaming Doc and  M/R-Tutorial Doc - updates,This JIRA addresses issues in the Streaming doc that also require a cross-link to and update in the M r tutorial (new sub-sections added under Task Execution  Environment section)  2. For -files and -archives options; Hadoop now creates symlink with same name as file (user-defined symlinks; #mysymlink; currently not supported)  Docs affected:streaming  3. Streaming supports streaming command options and generic command options. Generic options must be placed before streaming options; otherwise command fails.  Docs affected: streaming (reorganized the streaming doc to make distinctions between 2 sets of command options more clear),Closed,Fixed,,Unassigned,Corinne Chandel,Tue; 28 Jul 2009 16:37:29 +0000,Tue; 24 Aug 2010 21:14:58 +0000,Tue; 11 Aug 2009 08:01:09 +0000,,0.21.0,,,MAPREDUCE-1694,https://issues.apache.org/jira/browse/MAPREDUCE-813
MAPREDUCE-814,Sub-task,Major,jobtracker,Move completed Job history files to HDFS,Currently completed job history files remain on the jobtracker node. Having the files available on HDFS will enable clients to access these files more easily.,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Wed; 29 Jul 2009 10:47:16 +0000,Tue; 24 Aug 2010 21:14:59 +0000,Mon; 10 Aug 2009 04:23:02 +0000,,,,MAPREDUCE-817,,https://issues.apache.org/jira/browse/MAPREDUCE-814
MAPREDUCE-815,New Feature,Major,,Add AvroInputFormat and AvroOutputFormat so that hadoop can use Avro Serialization,MapReduce needs AvroInputFormat similar to other InputFormats like TextInputFormat to be able to use avro serialization in hadoop. Similarly AvroOutputFormat is needed.,Resolved,Duplicate,AVRO-493,Aaron Kimball,Ravi Gummadi,Thu; 30 Jul 2009 04:38:54 +0000,Thu; 2 May 2013 02:29:27 +0000,Fri; 21 May 2010 22:16:20 +0000,,,,HIVE-895;MAPREDUCE-1126;HADOOP-6492,MAPREDUCE-1360;MAPREDUCE-1634,https://issues.apache.org/jira/browse/MAPREDUCE-815
MAPREDUCE-816,Improvement,Minor,,"Rename ""local"" mysql import to ""direct""","A mysqldump-based fast path known as ""local mode"" is used in sqoop when users pass the argument -local. The restriction that this only import from localhost was based on an implementation technique that was later abandoned in favor of a more general one; which can support remote hosts as well. Thus; local is a poor name for the flag. -direct is more general and more descriptive. This should be used instead.",Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 31 Jul 2009 06:12:24 +0000,Fri; 2 Jul 2010 06:31:53 +0000,Fri; 31 Jul 2009 06:39:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-816
MAPREDUCE-817,Sub-task,Major,client;jobtracker,Add a cache for retired jobs with minimal job info and provide a way to access history file url,MAPREDUCE-814 will provide a way to keep the job history files in HDFS. There should be a way to get the url for the completed job history fie. The completed jobs can be purged from memory more aggressively from jobtracker since the clients can retrieve the information from history file. Jobtracker can just maintain the very basic info about the completed jobs.,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Fri; 31 Jul 2009 07:21:20 +0000,Tue; 24 Aug 2010 21:14:59 +0000,Tue; 11 Aug 2009 17:44:17 +0000,,,,MAPREDUCE-814,,https://issues.apache.org/jira/browse/MAPREDUCE-817
MAPREDUCE-818,Bug,Minor,,org.apache.hadoop.mapreduce.Counters.getGroup returns null if the group name doesnt exist.,org.apache.hadoop.mapreduce.Counters.getGroup returns null if the group name doesnt exist. But the documentation says it returns an empty group if there is none with the specified name.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 31 Jul 2009 10:06:53 +0000,Fri; 28 Aug 2009 07:39:10 +0000,Fri; 21 Aug 2009 11:39:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-818
MAPREDUCE-819,Task,Major,documentation,DistCP Guide - updates,DistCp Guide - updates to examples. Changes suggested and approved by engineer.,Closed,Fixed,,Corinne Chandel,Corinne Chandel,Fri; 31 Jul 2009 19:07:41 +0000,Tue; 24 Aug 2010 21:15:00 +0000,Thu; 15 Oct 2009 02:11:48 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-819
MAPREDUCE-820,Bug,Minor,jobtracker,NPE in TT heartbeat when there is a problem resolving the network topology,When there is a problem while resolving the network topology (such as a non existent topology.script.file.name); NPE is being thrown in the TT heartbeats. Below is the exception obtained:,Resolved,Duplicate,HADOOP-10867,Unassigned,Ramya Sunil,Mon; 3 Aug 2009 13:29:42 +0000,Tue; 4 Aug 2009 03:55:10 +0000,Tue; 4 Aug 2009 03:55:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-820
MAPREDUCE-821,Bug,Critical,,JobClient.runJob leaks file descriptors,In a Java-based driver that runs multiple MapReduce jobs (e.g. Mahout's K-means implementation); numerous calls to JobClient.runJob will cause many RPC connections to be opened and then never closed. This results in the driver job leaking file descriptors and will eventually crash once the OS limit is reached for Too Many Open Files.  This has been verified in Hadoop 18.3 by running the driver and as new MapReduce jobs are run; lsof -p dhows an increasing number of open TCP connections to the cluster.  Looking at the current code in the trunk; it looks like this is caused by runJob not calling close() on the JobClient object it creates. Or alternatively; it's cause by the fact that JobClient does not have a destructor that calls close().  I am going to verify this hypothesis and post a patch.,Resolved,Duplicate,HDFS-73,Unassigned,Mark Desnoyer,Mon; 3 Aug 2009 15:42:29 +0000,Mon; 3 Aug 2009 20:00:27 +0000,Mon; 3 Aug 2009 20:00:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-821
MAPREDUCE-822,Bug,Trivial,jobtracker,"Jobtracker logs should display the  ""job info persisted to file.."" message after job's completion.","timestamp INFO org.apache.hadoop.mapred.JobTracker: Job job-id job info persisted to file : mapred.job.tracker.persist.jobstatus.dir job-id  message should be logged in the jobtracker's log after job's completion if ""mapred.job.tracker.persist.jobstatus.active"" is active.",Resolved,Fixed,,Unassigned,Suman Sehgal,Tue; 4 Aug 2009 08:56:16 +0000,Wed; 23 Jul 2014 20:45:50 +0000,Wed; 23 Jul 2014 20:45:50 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-822
MAPREDUCE-823,Bug,Major,test,TestCommandLineJobSubmission doesn't need MiniDFSCluster to run,The test is included in the list of fast tests and so might profit from replacing MiniDFSCluster with the local file system.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Tue; 4 Aug 2009 11:09:45 +0000,Wed; 23 Jul 2014 20:48:20 +0000,Wed; 23 Jul 2014 20:48:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-823
MAPREDUCE-824,New Feature,Major,capacity-sched,Support a hierarchy of queues in the capacity scheduler,Currently in Capacity Scheduler; cluster capacity is divided among the queues based on the queue capacity. These queues typically represent an organization and the capacity of the queue represents the capacity the organization is entitled to. Most organizations are large and need to divide their capacity among sub-organizations they have. Or they may want to divide the capacity based on a category or type of jobs they run. This JIRA covers the requirements and other details to provide the above feature.,Closed,Fixed,,rahul k singh,Hemanth Yamijala,Tue; 4 Aug 2009 13:38:29 +0000,Tue; 18 Oct 2011 07:01:31 +0000,Thu; 27 Aug 2009 07:50:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-824
MAPREDUCE-825,Bug,Minor,,JobClient completion poll interval of 5s causes slow tests in local mode,The JobClient.NetworkedJob.waitForCompletion() method polls for job completion every 5 seconds. When running a set of short tests in pseudo-distributed mode; this is unnecessarily slow and causes lots of wasted time. When bandwidth is not scarce; setting the poll interval to 100 ms results in a 4x speedup in some tests.  This interval should be parametrized to allow users to control the interval for testing purposes.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 4 Aug 2009 20:52:19 +0000,Tue; 24 Aug 2010 21:15:02 +0000,Wed; 26 Aug 2009 09:28:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-825
MAPREDUCE-826,Bug,Trivial,harchive,harchive doesn't use ToolRunner / harchive returns 0 even if the job fails with exception,nan,Resolved,Fixed,,Koji Noguchi,Koji Noguchi,Wed; 5 Aug 2009 00:24:20 +0000,Wed; 28 Oct 2009 17:55:02 +0000,Mon; 14 Sep 2009 17:15:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-826
MAPREDUCE-827,Bug,Minor,jobtracker,hadoop job -status <jobid> command should display job's completion status also.,"hadoop job -status jobid command doesn't display job status whether it is SUCCEEDED or KILLED.    command ""hadoop job -status jobid""  displays following info:  file: hdfs: jobdetails.jsp?jobid=jobid map() completion: 1.0 reduce() completion: 1.0 Counters: 5         Job Counters                 SLOTS_MILLIS_MAPS=321309                 Total time spent by all reduces waiting after reserving slots (ms)=0                 Total time spent by all maps waiting after reserving slots (ms)=0                 Launched map tasks=10                 SLOTS_MILLIS_REDUCES=0  This command should  display the job's completion status also.",Resolved,Duplicate,MAPREDUCE-817,Unassigned,Suman Sehgal,Wed; 5 Aug 2009 07:37:39 +0000,Tue; 18 Aug 2009 04:36:58 +0000,Tue; 18 Aug 2009 04:36:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-827
YARN-2344,New Feature,Major,resourcemanager,ResourceManager should support maintenance model,We've seen scenarios when we have needed to stop the namenode for a maintenance activity. In such scenarios; if the jobtracker (JT) continues to run; jobs would fail due to initialization or task failures (due to DFS). We could restart the JT enabling job recovery; during such scenarios. But restart has proved to be a very intrusive activity; particularly if the JT is not at fault itself and does not require a restart. The ask is for a admin-controlled feature to pause the JT which would take it to a state somewhat analogous to the safe mode of DFS.,Open,Unresolved,,Junping Du,Hemanth Yamijala,Thu; 6 Aug 2009 06:16:16 +0000,Fri; 1 May 2015 19:46:38 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-2344
MAPREDUCE-829,Bug,Major,tasktracker,When localizing job configuration from FS; TTs configuration on local disk is not loaded at all,We should first load the local configuration fConf; over which the job.xml from the JobTracker's file system should be loaded. This is needed so as to enforce settings specific to the TaskTracker if it has some.,Resolved,Incomplete,,Unassigned,Vinod Kumar Vavilapalli,Thu; 6 Aug 2009 09:03:17 +0000,Wed; 23 Jul 2014 20:54:57 +0000,Wed; 23 Jul 2014 20:54:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-829
MAPREDUCE-830,Improvement,Major,,Providing BZip2 splitting support for Text data,HADOOP-4012 (https: HADOOP-4012) is providing support to handle BZip2 compressed data such that the input compressed file is split at arbitrary points.  This JIRA uses that functionality in LineRecordReader.  The benefit of this work is that; if user provides compressed BZip2 Text data; it will be split by Hadoop and hence will be processed by multiple mappers.  So BZip2 compressed data will be able to fully utilize the cluster power.  Currently BZip2 compressed Text file goes to one mapper and is not split.  So the enhancement in this JIRA provides splitting support  and a considerable performance gains.,Closed,Fixed,,Abdul Qadeer,Abdul Qadeer,Thu; 6 Aug 2009 19:38:52 +0000,Tue; 24 Aug 2010 21:15:02 +0000,Fri; 11 Sep 2009 03:31:00 +0000,,0.21.0,,HADOOP-4012,,https://issues.apache.org/jira/browse/MAPREDUCE-830
MAPREDUCE-831,Task,Trivial,contrib/fair-share,Put fair scheduler design doc in SVN,The JIRA discussion for MAPREDUCE-706 includes a ~10-page design document for the fair scheduler. This should be added in the fair scheduler contrib directory; perhaps as both a .tex and a .pdf.,Resolved,Fixed,,Matei Zaharia,Matei Zaharia,Thu; 6 Aug 2009 20:21:43 +0000,Fri; 26 Nov 2010 23:25:50 +0000,Fri; 26 Nov 2010 23:25:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-831
MAPREDUCE-832,Bug,Major,,Too many WARN messages about deprecated memorty config variables in JobTacker log,When user submit a mapred job using old memory config vairiable (mapred.task.maxmem) followinig message too many times in JobTracker logs -: [ WARN org.apache.hadoop.mapred.JobConf: The variable mapred.task.maxvmem is no longer used instead use  mapred.job.map.memory.mb and mapred.job.reduce.memory.mb ],Resolved,Fixed,,rahul k singh,Karam Singh,Fri; 7 Aug 2009 09:52:31 +0000,Fri; 28 Aug 2009 07:43:05 +0000,Thu; 20 Aug 2009 06:46:09 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-832
MAPREDUCE-833,Bug,Major,,Jobclient does not print any warning message when old memory config variable used with -D option from command line,nan,Resolved,Duplicate,MAPREDUCE-832,Unassigned,Karam Singh,Fri; 7 Aug 2009 09:53:42 +0000,Thu; 20 Aug 2009 06:47:25 +0000,Thu; 20 Aug 2009 06:47:25 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-833
MAPREDUCE-834,Bug,Major,,When TaskTracker config use old memory management values its memory monitoring is diabled.,"TaskTracker memory config values -: mapred.tasktracker.vmem.reserved=8589934592 mapred.task.default.maxvmem=2147483648 mapred.task.limit.maxvmem=4294967296 mapred.tasktracker.pmem.reserved=2147483648 TaskTracker start as -:                2009-08-05 12:39:03;308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.tasktracker.vmem.reserved is no longer used 		2009-08-05 12:39:03;308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.tasktracker.pmem.reserved is no longer used 		2009-08-05 12:39:03;308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.task.default.maxvmem is no longer used 		2009-08-05 12:39:03;308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.task.limit.maxvmem is no longer used 		2009-08-05 12:39:03;308 INFO org.apache.hadoop.mapred.TaskTracker: Starting thread: Map-events fetcher for all reduce tasks on tracker_name 		2009-08-05 12:39:03;309 INFO org.apache.hadoop.mapred.TaskTracker:  Using MemoryCalculatorPlugin : org.apache.hadoop.util.LinuxMemoryCalculatorPlugin@19be4777 		2009-08-05 12:39:03;311 WARN org.apache.hadoop.mapred.TaskTracker: TaskTracker's totalMemoryAllottedForTasks is -1. TaskMemoryManager is disabled.",Resolved,Fixed,,Sreekanth Ramakrishnan,Karam Singh,Fri; 7 Aug 2009 09:59:59 +0000,Fri; 28 Aug 2009 05:55:10 +0000,Fri; 21 Aug 2009 05:35:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-834
MAPREDUCE-835,Bug,Major,,hadoop-mapred examples;test and tools jar iles are being packaged when ant binary or bin-package is used ,When checking mapreduce trunk. If run ant binary or ant bin-package commands-: hadoop-mapred-test-0.21.0-dev.jar; hadoop-mapred-examples-0.21.0-dev.jar; hadoop-mapred-tools-0.21.0-dev.jar are being packaged in tar or build hadoop-mapred-0.21.0-dev directory. and in tar file,Resolved,Fixed,,Unassigned,Karam Singh,Fri; 7 Aug 2009 13:11:23 +0000,Wed; 23 Jul 2014 20:56:21 +0000,Wed; 23 Jul 2014 20:56:21 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-835
MAPREDUCE-836,Bug,Major,examples,Examples of hadoop pipes are not getting package a even when -Dcompile.native=yes -Dcompile.c++=yes option are used while running ant package or tar or similar commands.,Examples of hadoop pies and python are not packed even when -Dcompile.native=yes -Dcompile.c++=yes option are used while running ant package or tar or similar commands.  The pipes examples are compiled and copied under build c++-examples but are not being packaged. Similar is case with python examples also.,Resolved,Fixed,,Unassigned,Karam Singh,Fri; 7 Aug 2009 13:29:21 +0000,Wed; 23 Jul 2014 20:56:39 +0000,Wed; 23 Jul 2014 20:56:39 +0000,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-836
MAPREDUCE-838,Bug,Blocker,task,Task succeeds even when committer.commitTask fails with IOException,In MAPREDUCE-837; job succeeded with empty output even though all the tasks were throwing IOException at commiter.commitTask.,Resolved,Fixed,,Amareshwari Sriramadasu,Koji Noguchi,Fri; 7 Aug 2009 20:08:12 +0000,Mon; 31 Aug 2009 05:02:39 +0000,Tue; 11 Aug 2009 05:52:18 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-838
MAPREDUCE-839,Bug,Minor,,unit test TestMiniMRChildTask fails on mac os-x,The unit test TestMiniMRChildTask fails on Mac OS-X (10.5.8),Closed,Fixed,,Hong Tang,Hong Tang,Fri; 7 Aug 2009 20:49:15 +0000,Tue; 24 Aug 2010 21:15:02 +0000,Mon; 14 Sep 2009 17:34:20 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-839
MAPREDUCE-840,Bug,Minor,,DBInputFormat leaves open transaction,DBInputFormat.getSplits() does not connection.commit() after the COUNT query. This can leave an open transaction against the database which interferes with other connections to the same table.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 7 Aug 2009 21:45:00 +0000,Tue; 24 Aug 2010 21:15:03 +0000,Wed; 12 Aug 2009 14:38:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-840
MAPREDUCE-841,Improvement,Major,jobtracker,Protect Job Tracker against memory exhaustion due to very large InputSplit or JobConf objects,JobTracker only needs to examine a subset of information contained by InputSplit or JobConf objects. But currently JobTracker loads the complete user-defined InputSplit and JobConf objects in memory. This design would leave JobTracker susceptible to memory exhaustion particularly in cases when some bugs in user code which could result in very large input splits or job conf objects (e.g. PIG-901).,Resolved,Fixed,,Unassigned,Hong Tang,Sat; 8 Aug 2009 02:45:19 +0000,Wed; 23 Jul 2014 20:24:33 +0000,Wed; 23 Jul 2014 20:24:33 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-841
MAPREDUCE-842,Sub-task,Major,security;task-controller;tasktracker,Per-job local data on the TaskTracker node should have right access-control,nan,Closed,Fixed,MAPREDUCE-131,Vinod Kumar Vavilapalli,Arun C Murthy,Wed; 22 Oct 2008 20:27:56 +0000,Thu; 6 Jan 2011 09:37:54 +0000,Wed; 12 Aug 2009 16:21:05 +0000,,,,,MAPREDUCE-720;MAPREDUCE-2238,https://issues.apache.org/jira/browse/MAPREDUCE-842
MAPREDUCE-843,Improvement,Major,jobtracker,Cleanup JobInProgress ,Rework Redesign JobInProgress contracts and code.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 10 Aug 2009 13:11:31 +0000,Mon; 10 Aug 2009 13:11:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-843
MAPREDUCE-844,Bug,Major,,TestJobTrackerRestartWithLostTracker fails sometimes,After restart the tasks fail with the following error   2009-08-10 16:35:56;673 WARN  mapred.TaskTracker (TaskTracker. 1678)  leading to job failure.,Resolved,Fixed,,Unassigned,Amar Kamat,Mon; 10 Aug 2009 13:14:15 +0000,Wed; 7 Oct 2009 06:22:46 +0000,Wed; 7 Oct 2009 06:22:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-844
MAPREDUCE-845,Bug,Minor,build,build.xml hard codes findbugs heap size; in some configurations 512M is insufficient to successfully build,When attempting the build with the hardcoded value of 512M for findbugs heap size; the build fails with:   findbugs Java Result: -1      xslt Processing  hadoop-findbugs-report.xml  BUILD FAILED,Closed,Fixed,,Lee Tucker,Lee Tucker,Mon; 10 Aug 2009 21:44:33 +0000,Tue; 24 Aug 2010 21:15:08 +0000,Mon; 10 Aug 2009 23:24:53 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-845
MAPREDUCE-846,Bug,Major,,A long running init can block job queue details webpage,A long running init of a job can potentially block job queue details page from being displayed as JSPUtils.generateJobTable() takes a lock on JobInProgress.,Resolved,Fixed,,Unassigned,Amar Kamat,Tue; 11 Aug 2009 09:04:50 +0000,Wed; 23 Jul 2014 20:59:48 +0000,Wed; 23 Jul 2014 20:59:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-846
MAPREDUCE-847,Improvement,Major,build,Adding Apache License Headers and reduce releaseaudit warnings to zero,rat:report Summary rat:report ------- rat:report Notes: 14 rat:report Binaries: 178 rat:report Archives: 49 rat:report Standards: 1364 rat:report rat:report Apache Licensed: 1152 rat:report Generated Documents: 9 rat:report rat:report JavaDocs are generated and so license header is optional rat:report Generated files do not required license headers rat:report rat:report 203 Unknown Licenses,Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Tue; 11 Aug 2009 10:03:44 +0000,Tue; 24 Aug 2010 21:15:08 +0000,Sun; 17 Jan 2010 17:37:09 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-847
MAPREDUCE-848,Bug,Major,capacity-sched,TestCapacityScheduler is failing,Looks like the commit of HADOOP-805 broke the CapacityScheduler testcase.,Closed,Fixed,,Amar Kamat,Devaraj Das,Tue; 11 Aug 2009 16:47:52 +0000,Tue; 24 Aug 2010 21:15:09 +0000,Wed; 12 Aug 2009 14:06:42 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-848
MAPREDUCE-849,Improvement,Major,,Renaming of configuration property names in mapreduce,In-line with HDFS-531; property names in configuration files should be standardized in MAPREDUCE.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 12 Aug 2009 08:55:29 +0000,Wed; 25 May 2011 08:38:10 +0000,Fri; 18 Sep 2009 15:19:13 +0000,,,,HADOOP-6199;HADOOP-6105,HDFS-531,https://issues.apache.org/jira/browse/MAPREDUCE-849
MAPREDUCE-850,Bug,Major,,PriorityScheduler should use TaskTrackerManager.killJob() instead of JobInProgress.kill(),nan,Resolved,Fixed,,Unassigned,Amar Kamat,Wed; 12 Aug 2009 13:52:35 +0000,Wed; 23 Jul 2014 21:00:10 +0000,Wed; 23 Jul 2014 21:00:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-850
MAPREDUCE-851,Bug,Major,client,Static job property accessors don't accept Configuration but various JobContext sub-classes,"The current method of accepting only JobContext or one of its sub-classes adds much complexity to dynamic job configuration ""builders"" that manipulate the Configuration object in order to dynamically configure Hadoop jobs; and influence internal Hadoop sub-systems during runtime to provide higher level functions and features.",Open,Unresolved,,Unassigned,Chris K Wensel,Wed; 12 Aug 2009 16:00:05 +0000,Wed; 23 Jul 2014 21:01:11 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-851
MAPREDUCE-852,Bug,Major,build,ExampleDriver is incorrectly set as a Main-Class in tools in build.xml,"In build.xml;    	ExampleDriver should not be a Main-Class of tools 	Should we rename the target name from ""tools-jar"" to ""tools""; so that the name would be consistent with the ""examples"" target?",Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 12 Aug 2009 18:18:20 +0000,Tue; 24 Aug 2010 21:15:10 +0000,Mon; 17 Aug 2009 18:13:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-852
MAPREDUCE-853,New Feature,Major,jobtracker,Support a hierarchy of queues in the Map/Reduce framework,In MAPREDUCE-824; we proposed introducing a hierarchy of queues in the capacity scheduler. Currently; the M reduce framework as well. We could treat this as an umbrella JIRA and file additional tasks for each of the changes involved; sticking to the high level approach in this JIRA.,Closed,Fixed,,Unassigned,Hemanth Yamijala,Thu; 13 Aug 2009 04:39:16 +0000,Tue; 24 Aug 2010 21:15:12 +0000,Fri; 18 Sep 2009 16:01:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-853
MAPREDUCE-854,Bug,Major,jobtracker, JobInProgress.initTasks() should not throw KillInterruptedException,JobInProgress.initTasks() throws KillInterruptedException if its killed in init. This is a bad programming practice.,Open,Unresolved,,Amar Kamat,Amar Kamat,Thu; 13 Aug 2009 05:02:49 +0000,Thu; 13 Aug 2009 05:02:49 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-854
MAPREDUCE-855,Bug,Major,test,Testcases faking TaskTrackerManager might result into NPE ,JobInProgress uses JobTracker.getClock() assuming that the JobTracker is initialized before creating JobInProgress. This might not be true as the testcase might fake TaskTrackerManager. In such cases the JobInProgress might result into NPE.,Open,Unresolved,,Amar Kamat,Amar Kamat,Thu; 13 Aug 2009 05:03:54 +0000,Thu; 13 Aug 2009 05:03:54 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-855
MAPREDUCE-856,Sub-task,Major,tasktracker,Localized files from DistributedCache should have right access-control,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Arun C Murthy,Wed; 22 Oct 2008 20:30:11 +0000,Tue; 24 Aug 2010 21:15:12 +0000,Mon; 14 Sep 2009 03:08:39 +0000,,,,MAPREDUCE-744;MAPREDUCE-890;MAPREDUCE-871;MAPREDUCE-711;MAPREDUCE-476,HADOOP-4490,https://issues.apache.org/jira/browse/MAPREDUCE-856
MAPREDUCE-857,Bug,Major,task,task fails with NPE  when GzipCodec is used for mapred.map.output.compression.codec and native libary is not present,Ran a job with mapred.map.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec. Whenmaps of job completes they with following NPE  -: tasklog -: 2009-08-12 13:48:13;423 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 256 2009-08-12 13:48:13;611 INFO org.apache.hadoop.mapred.MapTask: data buffer = 204010944 3355443 2009-08-12 13:49:45;473 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output 2009-08-12 13:49:45;544 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin- contains followings line in trunk code on which error was seen -: Line 104: this.compressor = CodecPool.getCompressor(codec); Line: this.compressor.reset();   If native is available job runs successfully without any failures,Closed,Duplicate,HADOOP-7258,Unassigned,Karam Singh,Thu; 13 Aug 2009 07:30:18 +0000,Tue; 15 Nov 2011 00:48:09 +0000,Tue; 7 Jun 2011 13:46:11 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-857
MAPREDUCE-858,Bug,Minor,jobtracker,"NPE in heartbeat if ""mapred.job.tracker.history.completed.location"" is not writable ","If ""mapred.job.tracker.history.completed.location"" has been configured to write to a location which is not writable by JT; NullPointerException is thrown in TT heartbeat. Below is the Exception obtained:    Instead of an NPE; it would be helpful if an useful error message is logged.",Resolved,Fixed,,Unassigned,Ramya Sunil,Thu; 13 Aug 2009 08:19:19 +0000,Tue; 7 May 2013 00:17:26 +0000,Tue; 7 May 2013 00:17:26 +0000,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-858
MAPREDUCE-859,Bug,Major,build,Unable to run examples with current trunk,Running wordcount with trunk gives  lang.NoClassDefFoundError: org DatumReader. ivy settings need to be updated to get avro jars as well,Closed,Fixed,,Ravi Gummadi,Jothi Padmanabhan,Thu; 13 Aug 2009 08:34:07 +0000,Tue; 24 Aug 2010 21:15:14 +0000,Fri; 14 Aug 2009 05:11:26 +0000,,0.21.0,,,MAPREDUCE-877,https://issues.apache.org/jira/browse/MAPREDUCE-859
MAPREDUCE-860,Sub-task,Major,jobtracker,Modify Queue APIs to support a hierarchy of queues,MAPREDUCE-853 proposes to introduce a hierarchy of queues into the Map Reduce framework. This JIRA is for defining changes to the APIs related to queues.,Resolved,Duplicate,MAPREDUCE-861,rahul k singh,Hemanth Yamijala,Thu; 13 Aug 2009 11:39:11 +0000,Mon; 7 Sep 2009 06:54:28 +0000,Mon; 7 Sep 2009 06:54:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-860
MAPREDUCE-861,Sub-task,Major,jobtracker,Modify queue configuration format and parsing to support a hierarchy of queues.,MAPREDUCE-853 proposes to introduce a hierarchy of queues into the Map Reduce framework. This JIRA is for defining changes to the configuration related to queues.   The current format for defining a queue and its properties is as follows: mapred.queue.queue-name.property-name. For e.g. mapred.queue.queue-name.acl-submit-job. The reason for using this verbose format was to be able to reuse the Configuration parser in Hadoop. However; administrators currently using the queue configuration have already indicated a very strong desire for a more manageable format. Since; this becomes more unwieldy with hierarchical queues; the time may be good to introduce a new format for representing queue configuration.,Closed,Fixed,,rahul k singh,Hemanth Yamijala,Thu; 13 Aug 2009 11:41:20 +0000,Tue; 24 Aug 2010 21:15:14 +0000,Wed; 16 Sep 2009 04:50:35 +0000,,,,MAPREDUCE-893,,https://issues.apache.org/jira/browse/MAPREDUCE-861
MAPREDUCE-862,Sub-task,Major,,Modify UI to support a hierarchy of queues,MAPREDUCE-853 proposes to introduce a hierarchy of queues into the Map Reduce framework. This JIRA is for defining changes to the UI related to queues. This includes the hadoop queue CLI and the web UI on the JobTracker.,Closed,Fixed,,V.V.Chaitanya Krishna,Hemanth Yamijala,Thu; 13 Aug 2009 11:43:43 +0000,Tue; 24 Aug 2010 21:15:16 +0000,Thu; 17 Sep 2009 11:44:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-862
MAPREDUCE-863,Improvement,Major,jobtracker,Improve/standardize job history file content format and the management of the history files,This jira will track the various improvements that will be done in the JobHistory component of Hadoop. The main goals: 1) Make the content format friendly for consumption by other apps 2) Improve the management of the history files.  3) Be able to completely rely on the JobHistory files for anything to do with getting the status of completed jobs; both at the JobClient end; and at the web-UI end,Resolved,Fixed,,Unassigned,Devaraj Das,Thu; 13 Aug 2009 14:55:01 +0000,Wed; 23 Jul 2014 21:03:32 +0000,Wed; 23 Jul 2014 21:03:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-863
MAPREDUCE-864,Sub-task,Major,jobtracker,Enhance JobClient API implementations to look at history files to get information about jobs that are not in memory,MAPREDUCE-817 added an API to get the JobHistory URL from the JobTracker. This is useful in two ways: 1) Users can use this API to get the URL; copy the history files to their local disk; and; do processing on them 2) APIs like JobSubmissionProtocol.getJobCounters; can read a part of the history file; and then return the information to the caller (if the job is not there in JT memory). This would  mimic most of the CompletedJobsStatusStore functionality.,Resolved,Fixed,,Sharad Agarwal,Devaraj Das,Thu; 13 Aug 2009 15:37:17 +0000,Wed; 23 Jul 2014 21:02:47 +0000,Wed; 23 Jul 2014 21:02:47 +0000,,,,MAPREDUCE-157;MAPREDUCE-777,,https://issues.apache.org/jira/browse/MAPREDUCE-864
MAPREDUCE-865,Improvement,Minor,harchive,harchive: Reduce the number of open calls  to _index and _masterindex ,When I have har file with 1000 files in it;     % hadoop dfs -lsr har: _masterindex files 1000 times.  This makes the client slow and add some load to the namenode as well. Any ways to reduce this number?,Resolved,Duplicate,MAPREDUCE-2459,Koji Noguchi,Koji Noguchi,Thu; 13 Aug 2009 23:43:11 +0000,Mon; 22 Jul 2013 14:56:32 +0000,Mon; 22 Jul 2013 14:56:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-865
MAPREDUCE-866,Bug,Major,tasktracker,Move all memory related parameters and their initialization out of TaskTracker.java into TaskMemoryManagerThread,Design-wise; they belong to TaskMemoryManager. TaskTracker can use method calls to initialize get the parameters.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 14 Aug 2009 05:09:50 +0000,Wed; 23 Jul 2014 21:12:58 +0000,Wed; 23 Jul 2014 21:12:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-866
MAPREDUCE-867,Bug,Major,build,trunk builds fails as ivy is lookin for avro jar from the local resolver,nan,Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Fri; 14 Aug 2009 06:25:06 +0000,Tue; 24 Aug 2010 21:15:17 +0000,Fri; 14 Aug 2009 09:28:11 +0000,,,,,HADOOP-6120;MAPREDUCE-877,https://issues.apache.org/jira/browse/MAPREDUCE-867
MAPREDUCE-868,Bug,Blocker,build,Trunk  can't be compiled since Avro dependencies cannot be resolved,nan,Closed,Fixed,,Unassigned,Arun C Murthy,Fri; 14 Aug 2009 07:31:11 +0000,Tue; 24 Aug 2010 21:15:17 +0000,Fri; 14 Aug 2009 07:42:45 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-868
MAPREDUCE-869,Bug,Major,documentation;task,Documentation for config to set map/reduce task environment,HADOOP-2838 added mapred.child.env to allow users to set the map reduce tasks' environment.  MAPREDUCE-478 will break that into mapred.map.child.env and mapred.reduce.child.env. We need to add documentation (forrest) for these knobs.,Closed,Fixed,,Alejandro Abdelnur,Arun C Murthy,Fri; 14 Aug 2009 08:04:39 +0000,Mon; 12 Dec 2011 06:18:43 +0000,Thu; 12 May 2011 00:33:43 +0000,,0.21.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-869
MAPREDUCE-870,Sub-task,Major,,Clean up the job Retire code,Currently completed job's full data structures are kept in memory based on mapred.jobtracker.completeuserjobs.maximum; mapred.jobtracker.retirejob.interval.min; mapred.jobtracker.retirejob.interval and mapred.jobtracker.retirejob.check settings. These controls are not much useful now since MAPREDUCE-817 introduced a cache for keeping just the very basic info of the completed job. These settings should be removed and the job should be purged as soon as the history files are available in HDFS.  Going forward; clients can read the history files if they need to drill down into more information (MAPREDUCE-864).,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Fri; 14 Aug 2009 08:16:13 +0000,Tue; 24 Aug 2010 21:15:18 +0000,Fri; 21 Aug 2009 11:48:51 +0000,,,,,MAPREDUCE-1920,https://issues.apache.org/jira/browse/MAPREDUCE-870
MAPREDUCE-871,Sub-task,Major,tasktracker,Job/Task local files have incorrect group ownership set by LinuxTaskController binary,HADOOP-4491 fixed the secure permissions of local files on a TT. While testing HADOOP-4491 on a cluster; Karam Singh found out a bug. All the files dirs have should be owned by the group corresponding to the group owner of the task-controller binary (via using getegid()) which in turn is a special group to which only TT user belongs. HADOOP-4491 incorrectly set it to primary group of the TT via getgid(); and not the special group.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 14 Aug 2009 08:21:51 +0000,Tue; 24 Aug 2010 21:15:18 +0000,Thu; 27 Aug 2009 10:18:02 +0000,,,,MAPREDUCE-856,,https://issues.apache.org/jira/browse/MAPREDUCE-871
MAPREDUCE-872,Bug,Major,build,Streaming tests in a clean workspace fail because of avro dependency.,This is similar to MAPREDUCE-867. Running streaming (or some other contrib tests) in a clean workspace (empty build ivy dir) fail with the exception trace mentioned at MAPREDUCE-859.,Resolved,Duplicate,MAPREDUCE-877,Unassigned,Vinod Kumar Vavilapalli,Fri; 14 Aug 2009 12:15:02 +0000,Mon; 17 Aug 2009 03:51:01 +0000,Mon; 17 Aug 2009 03:50:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-872
MAPREDUCE-873,Improvement,Major,jobtracker,Simplify Job Recovery,On a couple of occasions we have seen the JobTracker not being able to handle job recovery well; and leading to cluster downtime after a restart. The current design for handling job recovery is complex and prone to corner cases not being handled well enough. In retrospect; it seems like the transaction log based approach as was proposed on HADOOP-3245 (http: comments welcome.,Closed,Fixed,,Sharad Agarwal,Devaraj Das,Fri; 14 Aug 2009 12:47:31 +0000,Tue; 24 Aug 2010 21:15:19 +0000,Tue; 1 Sep 2009 08:45:02 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-873
MAPREDUCE-874,Improvement,Minor,examples,"The name ""PiEstimator"" is misleading","The PiEstimator example mainly illustrates evaluating arbitrary integrals numerically by Map Reduce jobs but not focusing on computing Pi.  The name ""PiEstimator"" is misleading.",Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Fri; 14 Aug 2009 22:24:17 +0000,Tue; 24 Aug 2010 21:15:20 +0000,Fri; 21 Aug 2009 22:18:55 +0000,,,,,HDFS-568,https://issues.apache.org/jira/browse/MAPREDUCE-874
MAPREDUCE-875,Improvement,Major,,Make DBRecordReader execute queries lazily,DBInputFormat's DBRecordReader executes the user's SQL query in the constructor. If the query is long-running; this can cause task timeout. The user is unable to spawn a background thread (e.g.; in a MapRunnable) to inform Hadoop of on-going progress.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 14 Aug 2009 23:09:26 +0000,Tue; 24 Aug 2010 21:15:20 +0000,Thu; 27 Aug 2009 08:43:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-875
MAPREDUCE-876,Improvement,Major,,Sqoop import of large tables can time out,Related to MAPREDUCE-875; Sqoop should use a background thread to ensure that progress is being reported while a database does external work for the MapReduce task.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 14 Aug 2009 23:12:32 +0000,Fri; 2 Jul 2010 06:31:19 +0000,Mon; 7 Sep 2009 11:29:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-876
MAPREDUCE-877,Bug,Blocker,build,Required avro class are missing in contrib projects,Ivy setting in mapreduce root is updated but the contrib ivy settings are not.,Closed,Fixed,MAPREDUCE-872,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Sat; 15 Aug 2009 00:56:32 +0000,Tue; 24 Aug 2010 21:15:21 +0000,Mon; 17 Aug 2009 05:08:04 +0000,,0.21.0,,,MAPREDUCE-859;MAPREDUCE-867;HADOOP-6120,https://issues.apache.org/jira/browse/MAPREDUCE-877
MAPREDUCE-878,Task,Trivial,contrib/fair-share;documentation,Rename fair scheduler design doc to fair-scheduler-design-doc.tex and add Apache license header,As suggested by Tsz Wo Sze in MAPREDUCE-706.,Closed,Fixed,,Matei Zaharia,Matei Zaharia,Sat; 15 Aug 2009 16:34:20 +0000,Tue; 24 Aug 2010 21:15:21 +0000,Sat; 15 Aug 2009 20:38:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-878
MAPREDUCE-879,Bug,Blocker,test,TestTaskTrackerLocalization fails on MAC OS,TestTaskTrackerLocalization failed on an 'ant test' run.,Closed,Fixed,,Sreekanth Ramakrishnan,Devaraj Das,Sun; 16 Aug 2009 16:00:49 +0000,Tue; 24 Aug 2010 21:15:22 +0000,Mon; 26 Apr 2010 22:26:30 +0000,,0.21.0,,,MAPREDUCE-1822,https://issues.apache.org/jira/browse/MAPREDUCE-879
MAPREDUCE-880,Bug,Major,test,TestRecoveryManager times out,nan,Resolved,Cannot Reproduce,,Unassigned,Amar Kamat,Mon; 17 Aug 2009 07:43:20 +0000,Wed; 2 Sep 2009 09:40:34 +0000,Wed; 2 Sep 2009 09:40:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-880
MAPREDUCE-881,Bug,Major,jobtracker,Jobtracker continues even if History initialization fails,If there is some problem in the configuration; Job history initialization fails. JobHistory#init catches the exception and disable the history. This leads to job history not working as expected. However administrators won't notice that there is some problem in the config due to which history got disabled; unless they see the logs. Better approach would be to not catch the exception and let Jobtracker fail to come up if there is error in initialization.,Resolved,Duplicate,MAPREDUCE-157,Unassigned,Sharad Agarwal,Mon; 17 Aug 2009 08:01:47 +0000,Fri; 11 Sep 2009 04:26:24 +0000,Fri; 11 Sep 2009 04:24:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-881
MAPREDUCE-882,Bug,Major,,TestJobHistory fails sometimes,Testcase: testDoneFolderOnHDFS took 31.892 sec Testcase: testJobHistoryFile took 27.901 sec         FAILED Duplicate START_TIME seen for task task_200908161937_0001_m_000003 in history file  org.apache.hadoop.mapred.TestJobHistory.testJobHistoryFile(TestJobHistory. 964)  Testcase: testJobHistoryUserLogLocation took 75.161 sec Testcase: testJobHistoryJobStatus took 156.88 sec,Resolved,Duplicate,MAPREDUCE-745,Amar Kamat,Devaraj Das,Mon; 17 Aug 2009 12:26:04 +0000,Thu; 20 Aug 2009 04:18:01 +0000,Thu; 20 Aug 2009 04:18:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-882
MAPREDUCE-883,Improvement,Minor,documentation;harchive,harchive: Document how to unarchive,I was thinking of implementing harchive's 'unarchive' feature; but realized it has been implemented already ever since harchive was introduced. It just needs to be documented.,Closed,Fixed,,Akira Ajisaka,Koji Noguchi,Mon; 17 Aug 2009 17:06:04 +0000,Mon; 1 Dec 2014 03:08:37 +0000,Thu; 14 Aug 2014 15:39:24 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-883
MAPREDUCE-884,Bug,Major,test,TestReduceFetchFromPartialMem fails sometimes,TestReduceFetchFromPartialMem failed with the following exception trace :,Closed,Fixed,,Jothi Padmanabhan,Amar Kamat,Tue; 18 Aug 2009 05:16:45 +0000,Tue; 24 Aug 2010 21:15:22 +0000,Wed; 23 Sep 2009 05:16:08 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-884
MAPREDUCE-885,Improvement,Major,,More efficient SQL queries for DBInputFormat,"DBInputFormat generates InputSplits by counting the available rows in a table; and selecting subsections of the table via the ""LIMIT"" and ""OFFSET"" SQL keywords. These are only meaningful in an ordered context; so the query also includes an ""ORDER BY"" clause on an index column. The resulting queries are often inefficient and require full table scans. Actually using multiple mappers with these queries can lead to O(n^2) behavior in the database; where n is the number of splits. Attempting to use parallelism with these queries is counter-productive.  A better mechanism is to organize splits based on data values themselves; which can be performed in the WHERE clause; allowing for index range scans of tables; and can better exploit parallelism in the database.",Closed,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 18 Aug 2009 23:54:16 +0000,Thu; 2 May 2013 02:29:21 +0000,Mon; 14 Sep 2009 14:21:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-885
MAPREDUCE-886,Bug,Major,tasktracker,After 4491; when task-controller exit with some error message; LinuxTaskController only ExitCodeException but does not prints the exit code of task-controller,nan,Resolved,Fixed,,Unassigned,Karam Singh,Wed; 19 Aug 2009 08:06:49 +0000,Wed; 23 Jul 2014 21:15:52 +0000,Wed; 23 Jul 2014 21:15:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-886
MAPREDUCE-887,Bug,Major,tasktracker,After 4491; task cleaup directory some gets created under the ownershiptasktracker user instread job submitting.,Some time; when task is killed; task cleanup directory is created under the ownership tasktracker launching user instead job submitting user. dr-xrws--- karams   hadoop  ]  job_200908170914_0020      Here karams is user who submitted job and mapred is the use who launched TT. taskattrempt.cleanup created with mapred  user not with karams user. This issue is intermittent; not always reproducible.,Resolved,Invalid,,Unassigned,Karam Singh,Wed; 19 Aug 2009 08:12:05 +0000,Fri; 28 Aug 2009 13:32:24 +0000,Fri; 28 Aug 2009 13:32:24 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-887
MAPREDUCE-888,Bug,Major,test,TestJobHistory sometimes fails while validating history.,Error Message  Duplicate START_TIME seen for task task_200908190021_0001_m_000003 in history file  org.apache.hadoop.mapred.TestJobHistory.testJobHistoryFile(TestJobHistory. 955),Resolved,Duplicate,MAPREDUCE-882,Unassigned,Amar Kamat,Wed; 19 Aug 2009 11:21:27 +0000,Wed; 19 Aug 2009 11:25:35 +0000,Wed; 19 Aug 2009 11:25:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-888
MAPREDUCE-889,Bug,Blocker,documentation,binary communication formats added to Streaming by HADOOP-1722 should be documented,binary communication formats added to Streaming by HADOOP-1722 should be documented in forrest,Closed,Fixed,,Klaas Bosteels,Amareshwari Sriramadasu,Wed; 19 Aug 2009 11:51:56 +0000,Tue; 24 Aug 2010 21:15:24 +0000,Mon; 12 Apr 2010 22:36:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-889
MAPREDUCE-890,Bug,Blocker,tasktracker,After HADOOP-4491; the user who started mapred system is not able to run job.,Even setup and cleanup task of job fails due exception -: It fails to create job and related directories under mapred.local.dir jobcache Directories are created as -: dr-xrws--- mapred   hadoop    job_200908190916_0002 mapred is not wrtie under this. Even manually I failed to touch file. mapred is use of started mr cluster,Closed,Fixed,,Ravi Gummadi,Karam Singh,Wed; 19 Aug 2009 12:13:08 +0000,Tue; 24 Aug 2010 21:15:25 +0000,Sat; 20 Mar 2010 01:40:09 +0000,,,,MAPREDUCE-856;MAPREDUCE-1322;MAPREDUCE-1421,,https://issues.apache.org/jira/browse/MAPREDUCE-890
MAPREDUCE-891,Bug,Major,contrib/streaming;test,Streaming tests fail with NPE in MiniDFSCluster,Streaming testcases' usage of MiniDFSCluster.startDatanodes causes NPE in GenericOptionsParser:,Closed,Duplicate,MAPREDUCE-699,Unassigned,Arun C Murthy,Wed; 19 Aug 2009 17:43:13 +0000,Tue; 24 Aug 2010 21:15:27 +0000,Thu; 20 Aug 2009 03:24:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-891
MAPREDUCE-892,Improvement,Major,,command line tool to list all tasktrackers and their status,"The ""hadoop mradmin -report"" could list all the tasktrackers that the JobTracker knows about. It will also list a brief status summary for each of the TaskTracker. (This is similar to the hadop dfsadmin -report command that lists all Datanodes)",Resolved,Duplicate,YARN-2345,Dmytro Molkov,dhruba borthakur,Wed; 19 Aug 2009 19:45:10 +0000,Wed; 23 Jul 2014 21:18:39 +0000,Wed; 23 Jul 2014 21:18:39 +0000,,0.21.0,,MAPREDUCE-1044,MAPREDUCE-974,https://issues.apache.org/jira/browse/MAPREDUCE-892
MAPREDUCE-893,Improvement,Major,jobtracker,Provide an ability to refresh queue configuration without restart.,While administering a cluster using multiple queues; administrators feel a need to refresh queue properties on the fly without needing to restart the JobTracker. This is partially supported for some properties such as queue ACLs (HADOOP-5396) and state (HADOOP-5913). The idea is to extend the facility to refresh other queue properties as well; including scheduler properties.,Closed,Fixed,,Vinod Kumar Vavilapalli,Hemanth Yamijala,Thu; 20 Aug 2009 09:19:27 +0000,Tue; 24 Aug 2010 21:15:28 +0000,Fri; 18 Sep 2009 21:04:07 +0000,,,,MAPREDUCE-861,,https://issues.apache.org/jira/browse/MAPREDUCE-893
MAPREDUCE-894,New Feature,Major,,DBInputformat not working with SQLServer,org.apache.hadoop.mapreduce.lib.db.DBInputFormat Microsoft SQLServer doesn't support LIMIT and OFFSET.  Fix: Based on MAPREDUCE-716; I already implemented it. By creating a new class org.apache.hadoop.mapreduce.lib.db.MsSqlDBRecordReader  and modifying class org.apache.hadoop.mapreduce.lib.db.DBInputFormat   Note: this fix is working only with SQLServer 2005 or higher.,Open,Unresolved,,Budianto Lie,Budianto Lie,Thu; 20 Aug 2009 09:55:05 +0000,Mon; 21 Sep 2009 14:10:44 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-894
MAPREDUCE-895,Bug,Major,,FileSystem::ListStatus will now throw FileNotFoundException; MapRed needs updated,HADOOP-6201 (and HDFS-538) determined the semantics of FileSystem::ListStatus is not correct and that the actual file system class vary in their implemenations; with some throwing an exception and some returning null.  Fixing this will require adjusting code that calls this method.,Closed,Fixed,,Jakob Homan,Jakob Homan,Fri; 21 Aug 2009 01:01:17 +0000,Thu; 2 May 2013 02:29:21 +0000,Fri; 21 Aug 2009 22:51:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-895
MAPREDUCE-896,Bug,Major,tasktracker,Users can set non-writable permissions on temporary files for TT and can abuse disk usage.,As of now; irrespective of the TaskController in use; TT itself does a full delete on local files created by itself or job tasks. This step; depending upon TT's umask and the permissions set by files by the user; for e.g in job-work users.,Closed,Fixed,,Ravi Gummadi,Vinod Kumar Vavilapalli,Fri; 21 Aug 2009 04:36:30 +0000,Tue; 24 Aug 2010 21:15:29 +0000,Mon; 28 Dec 2009 13:08:50 +0000,,0.21.0,,MAPREDUCE-1284,MAPREDUCE-1422,https://issues.apache.org/jira/browse/MAPREDUCE-896
MAPREDUCE-897,Improvement,Major,tasktracker,Provide information captured as part of JobTrackerStatistics via the Hadoop metrics API,MAPREDUCE-467 introduced a framework to collect statistics per node on a fixed set of intervals. Presently there is support for collecting statistics related to number of task failures and also health check script failures per hour; day and since start of system. It is felt that this information can be made available via the tasktracker's metrics system as well.,Resolved,Fixed,,Unassigned,Hemanth Yamijala,Fri; 21 Aug 2009 04:37:08 +0000,Wed; 23 Jul 2014 21:44:07 +0000,Wed; 23 Jul 2014 21:44:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-897
MAPREDUCE-898,Sub-task,Major,,Change DistributedCache to use new api.,nan,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 21 Aug 2009 06:22:33 +0000,Tue; 24 Aug 2010 21:15:31 +0000,Mon; 7 Sep 2009 11:10:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-898
MAPREDUCE-899,Bug,Major,tasktracker,When using LinuxTaskController; localized files may become accessible to unintended users if permissions are misconfigured.,To enforce the accessibility of job files to only the job-owner and the TaskTracker; as per MAPREDUCE-842; it is trusted that the  setuid setgid linux TaskController binary is group owned by a special group to which only TaskTracker belongs and not just any group to which TT belongs. If the trust is broken; possibly due to misconfiguration by admins; the local files become accessible to unintended users; yet giving false sense of security to the admins.,Closed,Fixed,,Amareshwari Sriramadasu,Vinod Kumar Vavilapalli,Fri; 21 Aug 2009 09:15:55 +0000,Tue; 24 Aug 2010 21:15:31 +0000,Sun; 31 Jan 2010 12:06:16 +0000,,,,,MAPREDUCE-981,https://issues.apache.org/jira/browse/MAPREDUCE-899
MAPREDUCE-900,Improvement,Minor,build,Proposed enhancements/tuning to hadoop-mapred/build.xml,sibling list of HADOOP-6206 and HDFS-560; enhancements to the mapreduce build for easier single-system build test,Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Fri; 21 Aug 2009 15:57:03 +0000,Fri; 31 Aug 2012 15:23:13 +0000,Fri; 31 Aug 2012 15:23:13 +0000,,0.21.0,,,HADOOP-6206;HDFS-560,https://issues.apache.org/jira/browse/MAPREDUCE-900
MAPREDUCE-901,Improvement,Major,task,Move Framework Counters into a TaskMetric structure,I think we should move all of the Counters that the framework updates into a single class called TaskMetrics. TaskMetrics would have specific fields for each of the metrics like input records; input bytes; output records; etc.  It would both reduce the serialized size of the heartbeats (by shrinking the Counters down to just the user's counters) and decrease the latency for updates to the JobTracker (since Counters are sent at most 1 heartbeat).,Closed,Fixed,,Luke Lu,Owen O'Malley,Fri; 21 Aug 2009 17:51:56 +0000,Tue; 7 Feb 2012 13:53:04 +0000,Fri; 12 Aug 2011 23:26:53 +0000,,0.21.0,,MAPREDUCE-2102;MAPREDUCE-220;MAPREDUCE-718;MAPREDUCE-917,MAPREDUCE-1500;MAPREDUCE-1173;MAPREDUCE-2025;MAPREDUCE-1304;MAPREDUCE-2835,https://issues.apache.org/jira/browse/MAPREDUCE-901
MAPREDUCE-902,Bug,Major,task,Map output merge still uses unnecessary seeks,HADOOP-3638 improved the merge of the map output by caching the index files.  But why not also caching the data files?  In our use-case scenario; still using hadoop-0.18.3; but HADOOP-3638 would only help partially; an individual map tasks finishes in less than 30 minutes; but needs 4 hours to merge 70 spills for 20;000 partitions (with lzo compression); reading about 10kB from each spill file (which is re-opened for every partition). As this is just a merge sort; there is no reason to not keep the input files open and eliminate seek altogether with sequential access.,Resolved,Fixed,,Unassigned,Christian Kunz,Fri; 21 Aug 2009 20:17:26 +0000,Wed; 23 Jul 2014 21:51:15 +0000,Wed; 23 Jul 2014 21:51:15 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-902
MAPREDUCE-903,Improvement,Major,,Adding AVRO jar to eclipse classpath,Avro is missing from the eclipse classpath; which caused Eclipse to whine.  Easy fix.,Closed,Fixed,,Philip Zeyliger,Philip Zeyliger,Fri; 21 Aug 2009 22:47:08 +0000,Tue; 24 Aug 2010 21:15:32 +0000,Fri; 4 Sep 2009 23:30:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-903
MAPREDUCE-904,Improvement,Major,examples,Re-organize the bbp and distbbp examples classes,The bbp and distbbp examples are closely related.  We should put the into the same package.,Open,Unresolved,,Unassigned,Tsz Wo Nicholas Sze,Fri; 21 Aug 2009 23:03:21 +0000,Fri; 2 Jul 2010 00:04:29 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-904
MAPREDUCE-905,Improvement,Minor,,Add Eclipse launch tasks for MapReduce,"This is a revival of HADOOP-5911; but only for the MR project.  Eclipse has a notion of ""run configuration""; which encapsulates what's needed to run or debug an application. I use this quite a bit to start various Hadoop daemons in debug mode; with breakpoints set; to inspect state and what not.  This is simply configuration; so no tests are provided.  After running ""ant eclipse-files"" and refreshing your project; you should see entries in the ""Run"" pulldown.  There's a template for testing a specific test; and also templates to run all the tests; the job tracker; and a task tracker.  It's likely that some parameters need to be further tweaked to have the same behavior as ""ant test""; but for most tests; this works.",Closed,Fixed,,Philip Zeyliger,Philip Zeyliger,Fri; 21 Aug 2009 23:04:34 +0000,Tue; 24 Aug 2010 21:15:32 +0000,Fri; 18 Sep 2009 14:16:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-905
MAPREDUCE-906,Improvement,Major,,Updated Sqoop documentation,Here's the latest documentation for Sqoop; in both user-guide and manpage form. Built with asciidoc.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 21 Aug 2009 23:44:10 +0000,Thu; 2 May 2013 02:29:26 +0000,Sun; 18 Oct 2009 09:28:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-906
MAPREDUCE-907,Improvement,Major,,Sqoop should use more intelligent splits,Sqoop should use the new split generation   InputFormat in MAPREDUCE-885,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 21 Aug 2009 23:45:49 +0000,Thu; 2 May 2013 02:29:22 +0000,Thu; 17 Sep 2009 15:38:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-907
MAPREDUCE-908,Bug,Major,build;test,Defining test.include to run a subset of unit tests no longer works,The test.include property used to be a convenient way to glob tests; e.g. ant -Dtest.include='foo bar package. This no longer works.,Resolved,Fixed,,Unassigned,Chris Douglas,Mon; 24 Aug 2009 05:49:09 +0000,Wed; 23 Jul 2014 21:55:08 +0000,Wed; 23 Jul 2014 21:55:08 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-908
MAPREDUCE-909,Bug,Trivial,,Shell$ExitCodeException while killing/failing a task.,"Encountered ""Shell$ExitCodeException"" in TT logs while killing failing a job on 0.20.1  Stack Trace: ========= 2009-08-22 16:37:05;867 INFO org.apache.hadoop.mapred.TaskTracker: About to purge task:  org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmManager. 386)  2009-08-22 16:37:06;030 WARN org.apache.hadoop.mapred.LinuxTaskController: Exit code from task is : 143",Resolved,Fixed,,Unassigned,Suman Sehgal,Mon; 24 Aug 2009 07:38:57 +0000,Wed; 23 Jul 2014 21:55:31 +0000,Wed; 23 Jul 2014 21:55:31 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-909
MAPREDUCE-910,Improvement,Major,contrib/mrunit,MRUnit should support counters,incrCounter() is currently a dummy stub method in MRUnit that does nothing. Would be good for the mock reporter context implementations to support counters.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Mon; 24 Aug 2009 18:44:46 +0000,Tue; 24 Aug 2010 21:15:34 +0000,Wed; 26 Aug 2009 09:42:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-910
MAPREDUCE-911,Bug,Major,test,TestTaskFail fail sometimes,"TestTaskFail  fail sometimes with following error : junit.framework.AssertionFailedError 	at org.apache.hadoop.mapred.TestTaskFail.validateJob(TestTaskFail. 181)",Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 25 Aug 2009 06:36:36 +0000,Wed; 2 Sep 2009 16:41:29 +0000,Tue; 1 Sep 2009 06:11:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-911
MAPREDUCE-912,Bug,Major,,apache license header missing for some java files,The following files do not have apache license header : src WordCount.java,Closed,Fixed,,Chad Metcalf,Amareshwari Sriramadasu,Wed; 26 Aug 2009 03:34:48 +0000,Tue; 24 Aug 2010 21:15:34 +0000,Sat; 19 Sep 2009 00:13:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-912
MAPREDUCE-913,Bug,Blocker,tasktracker,TaskRunner crashes with NPE resulting in held up slots; UNINITIALIZED tasks and hung TaskTracker,nan,Closed,Fixed,,Amareshwari Sriramadasu,Vinod Kumar Vavilapalli,Wed; 26 Aug 2009 11:20:04 +0000,Tue; 24 Aug 2010 21:15:36 +0000,Wed; 2 Jun 2010 11:11:54 +0000,,0.20.1,,MAPREDUCE-915,,https://issues.apache.org/jira/browse/MAPREDUCE-913
MAPREDUCE-914,Bug,Major,,MapReduce source code has significant number of JavaDocs errors and warnings,nan,Resolved,Fixed,,Unassigned,Konstantin Boudnik,Wed; 26 Aug 2009 04:22:05 +0000,Wed; 23 Jul 2014 21:57:59 +0000,Wed; 23 Jul 2014 21:57:59 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-914
MAPREDUCE-915,Bug,Blocker,security;tasktracker,For secure environments; the Map/Reduce debug script must be run as the user.,The Taskcontroller model allows admins to set up a cluster configuration that runs tasks as users. The debug script feature of Map Reduce provided by the configuration options: mapred.map.task.debug.script and mapred.reduce.task.debug.script need to be run as the user as well in such environments; rather than as the tasktracker user.,Closed,Fixed,,Devaraj Das,Hemanth Yamijala,Wed; 26 Aug 2009 17:38:01 +0000,Tue; 24 Aug 2010 21:15:37 +0000,Tue; 17 Nov 2009 21:27:47 +0000,,0.21.0,,MAPREDUCE-913,,https://issues.apache.org/jira/browse/MAPREDUCE-915
MAPREDUCE-916,Task,Blocker,documentation,Hadoop Doc Split: MapReduce Docs,Hadoop Doc Split: MapReduce Docs  Please note that I am unable to directly check all of the new links. Some links may break and will need to be updated.,Closed,Fixed,,Corinne Chandel,Corinne Chandel,Wed; 26 Aug 2009 20:49:19 +0000,Tue; 24 Aug 2010 21:15:37 +0000,Fri; 18 Sep 2009 02:21:54 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-916
MAPREDUCE-917,Bug,Blocker,task,Remove getInputCounter and getOutputCounter from Contexts,The getInputCounter and getOutputCounter methods need to be removed from the new mapreduce APIs.,Closed,Invalid,,Unassigned,Owen O'Malley,Wed; 26 Aug 2009 21:50:04 +0000,Tue; 24 Aug 2010 21:15:38 +0000,Thu; 3 Sep 2009 21:32:52 +0000,,0.21.0,,MAPREDUCE-901,,https://issues.apache.org/jira/browse/MAPREDUCE-917
MAPREDUCE-918,Improvement,Major,,Test hsqldb server should be memory-only.,Sqoop launches a standalone hsqldb server for unit tests; but it currently writes its database to disk and uses a connect string of  localhost. If multiple test instances are running concurrently; one test server may serve to the other instance of the unit tests; causing race conditions.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 27 Aug 2009 07:03:35 +0000,Fri; 2 Jul 2010 06:31:22 +0000,Mon; 7 Sep 2009 11:36:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-918
MAPREDUCE-920,Improvement,Minor,documentation,Add jvm params introduced in MAPREDUCE-478 to mapred-default.xml,mapred-default.xml still provides definition for old params which were deprecated in MAPREDUCE:478. It should be changed to define the new params such as  mapred.map.child. opts; mapred.map.child.env; mapred.reduce.child.env; mapred.map.child.ulimit;  mapred.reduce.child.ulimit.,Resolved,Won't Fix,,Alejandro Abdelnur,Ramya Sunil,Thu; 27 Aug 2009 11:00:33 +0000,Wed; 7 Sep 2011 08:35:15 +0000,Wed; 7 Sep 2011 08:35:15 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-920
MAPREDUCE-921,Improvement,Major,jobtracker;tasktracker,Map-Reduce framework should gracefully handle heterogenous clusters,Currently several parts of the framework: components; configuration etc. implicitly assume uniformity of the cluster.   This jira is meant to be a meta-issue to track various improvements necessary to handle heterogenous clusters.,Resolved,Won't Fix,,Arun C Murthy,Arun C Murthy,Thu; 27 Aug 2009 15:09:12 +0000,Wed; 23 Jul 2014 22:09:48 +0000,Wed; 23 Jul 2014 22:09:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-921
MAPREDUCE-922,Sub-task,Major,tasktracker,Automatic configuration of number of map and reduce slots based on available resources for dealing with heterogenous clusters,Currently the number of map and reduce slots have to be configured manually; which is reasonable for homogeneous clusters. However; as the clusters start to change over time it becomes rather painful to administer and configure. We should start thinking along the direction of auto-magically configuring the slots based on available resources on the node such as RAM; CPU; disk etc.,Resolved,Won't Fix,,Unassigned,Arun C Murthy,Thu; 27 Aug 2009 15:13:31 +0000,Wed; 23 Jul 2014 22:12:06 +0000,Wed; 23 Jul 2014 22:12:06 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-922
MAPREDUCE-923,Bug,Major,,Sqoop's ORM uses URLDecoder on a file; which replaces plus signs in a jar file name with spaces,In findThisJar; sqoop runs URLDecoder.decode on the resulting jar; which has the effect of replacing any + signs in the path with a space.  This obviously breaks the classpath variable that it's trying to set; and the sqoop-generated code fails to compile.  Ironically; Cloudera's hadoop distro is the one that puts + characters in jar files; and so exhibits the bug.  Here is an example from running sqoop with log4j at debug level.  Note the space in the very last term; which should read hadoop-0.20.0+61-sqoop.jar rather than hadoop-0.20.0 61-sqoop.jar.    DEBUG orm.CompilationManager: Invoking  5.0.8-bin.jar: hadoop-0.20.0 61-sqoop.jar,Resolved,Fixed,,Aaron Kimball,Kevin Weil,Thu; 27 Aug 2009 18:12:13 +0000,Fri; 2 Jul 2010 06:31:23 +0000,Fri; 18 Sep 2009 20:35:14 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-923
MAPREDUCE-924,Bug,Major,pipes,TestPipes must not directly invoke 'main' of pipes as an exit from main could cause the testcase to crash.,TestPipes invokes the main method of the program running pipes. In MAPREDUCE-421; a change was made to the Pipes command runner to invoke System.exit after completion. This itself is a valid change because the pipes command runner is in itself a user facing program. But when combined with a testcase; it causes the testcase to crash rather than providing feedback on whether the test ran correctly or not.  The testcase should be modified to use Tool instead of running main directly.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 28 Aug 2009 07:59:01 +0000,Mon; 7 Sep 2009 07:27:49 +0000,Tue; 1 Sep 2009 17:31:04 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-924
MAPREDUCE-925,Bug,Minor,test,Not able to run parallel instances of ant tests,"Not able to execute two or more parallel instances of ant test.  Scenario: ======= Executed  ""TestRecoveryManager"" in a loop for 100 times and ran some other tests in parallel. Encountered following error message in TestRecoveryManager logs: junit 2009-08-27 10:53:48;724 INFO  mapred.TaskTracker (TaskTracker. tryToGetOutputSize(1594)) - org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker file.out in any of the configured local directories  It seems that new ant test removes the existing mapred local directory itself  and recreates it for current test.",Resolved,Fixed,,Unassigned,Suman Sehgal,Fri; 28 Aug 2009 08:22:06 +0000,Wed; 23 Jul 2014 22:17:52 +0000,Wed; 23 Jul 2014 22:17:52 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-925
MAPREDUCE-926,Bug,Major,jobtracker,History viewer on web UI should filter by job-id also,Job-id is the most famous handle to a job and there should be easier ways of hunting down a job from the history web viewer. Currently; filtering is supported to be based on job name and job owner's name. Job-id is a necessary addition to the list of filters.,Resolved,Duplicate,MAPREDUCE-157,Jothi Padmanabhan,Vinod Kumar Vavilapalli,Fri; 28 Aug 2009 10:03:42 +0000,Fri; 11 Sep 2009 04:26:24 +0000,Thu; 10 Sep 2009 16:09:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-926
MAPREDUCE-927,Sub-task,Major,security;tasktracker,Cleanup of task-logs should happen in TaskTracker instead of the Child,Task logs' cleanup is being done in Child now. This is undesirable atleast for two reasons: 1) failures while cleaning up will affect the user's tasks; and 2) the task's wall time will get affected due to operations that TT actually should own.,Closed,Fixed,,Amareshwari Sriramadasu,Vinod Kumar Vavilapalli,Fri; 28 Aug 2009 10:37:25 +0000,Sun; 19 Dec 2010 03:33:41 +0000,Tue; 9 Mar 2010 10:58:30 +0000,,0.21.0,,MAPREDUCE-1553,,https://issues.apache.org/jira/browse/MAPREDUCE-927
MAPREDUCE-928,Bug,Major,jobtracker,JobTracker startup can get confused if the mapred system dir isn't there,I'm seeing this in my branch; the JobTracker is catching and ignoring a FileNotFoundException when it tries to delete a nonexistent system dir,Resolved,Cannot Reproduce,,Unassigned,Steve Loughran,Fri; 28 Aug 2009 11:25:27 +0000,Thu; 29 Apr 2010 08:09:09 +0000,Fri; 28 Aug 2009 11:45:31 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-928
MAPREDUCE-929,Bug,Major,,MultipleOutputs requires Writable values (again),I'm seeing this in 0.19.2 and it looks like it's also in the trunk.  During the discussion about MultipleOutputs (HADOOP-3149) someone alerted Alejandro to the fact th they are still in the trunk to this day.  I'm trying to use MultipleOutputs with non-Writable values and it's failing for this reason.  Here's the change I'm talking about: http: MultipleOutputs. r1=681235r2=681234pathrev=681235,Open,Unresolved,,Unassigned,Justin Patterson,Fri; 28 Aug 2009 16:18:37 +0000,Fri; 28 Aug 2009 16:18:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-929
MAPREDUCE-930,Improvement,Minor,tools/rumen,rumen should interpret job history log input paths with respect to default FS; not local FS,This allows job history log file directory names that don't specify a file system to use the configured default FS instead of the local FS when the configured default is not the local.,Closed,Fixed,,Chris Douglas,Dick King,Fri; 28 Aug 2009 17:47:55 +0000,Tue; 24 Aug 2010 21:15:39 +0000,Wed; 9 Sep 2009 22:23:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-930
MAPREDUCE-931,Improvement,Minor,tools/rumen,rumen should use its own interpolation classes to create runtimes for simulated tasks,Currently; when a simulator or benchmark is running and simulating hadoop jobs using rumen data; and rumen's runtime system is used to get execution times for the tasks in the simulated jobs; rumen would use some ad hoc code; despite the fact that rumen has a perfectly good interpolation framework to generate random variables that fit discrete CDFs.  We should use the interpolation framework.,Closed,Fixed,,Dick King,Dick King,Fri; 28 Aug 2009 18:21:48 +0000,Tue; 24 Aug 2010 21:15:41 +0000,Sun; 18 Oct 2009 19:28:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-931
MAPREDUCE-932,New Feature,Major,tools/rumen,Rumen needs a job trace sorter,Rumen reads job history logs and produces job traces.  The jobs in a job trace do not occur in any promised order.  Certain tools need the jobs to be ordered by job submission time.  We should include; in Rumen; a tool to sort job traces.,Open,Unresolved,,Dick King,Dick King,Fri; 28 Aug 2009 18:31:10 +0000,Fri; 2 Jul 2010 07:15:01 +0000,,,,,MAPREDUCE-934,,https://issues.apache.org/jira/browse/MAPREDUCE-932
MAPREDUCE-933,Improvement,Major,tools/rumen,rumen needs a unit test where its input job history logs are created as part of the test,Currently; rumen's test cases use job history logs that are stored as part of the test case.  We should fix this because rumen will break if job history log formats change incompatibly; but the unit tests will still pass.,Open,Unresolved,,Unassigned,Dick King,Fri; 28 Aug 2009 18:41:50 +0000,Fri; 2 Jul 2010 07:15:15 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-933
MAPREDUCE-934,Improvement,Major,tools/rumen,rumen should be able to filter and fold job traces,"The rumen command line creates job traces from job history logs.  These job traces are read by the rumen runtime system at the behest of other applications.  We should add a command line tool to rumen to manipulate a job trace in various ways to modify a workload:   	overlap job trace segments to increase the workload 	extract a short segment from a long job trace 	stretch out job traces to dilute the workload",Open,Unresolved,,Unassigned,Dick King,Fri; 28 Aug 2009 18:56:27 +0000,Fri; 2 Jul 2010 07:14:57 +0000,,,,,MAPREDUCE-932,,https://issues.apache.org/jira/browse/MAPREDUCE-934
MAPREDUCE-935,Bug,Major,tasktracker,There's little to be gained by putting a host into the penaltybox at reduce time; if its the only host you have,Exponential backoff may be good for dealing with troublesome hosts; but not if you only have one host in the entire system. From the log of TestNodeRefresh; which for some reason is blocking in the reduce phase; I can see it doesn't take much for the backoff to kick in so rapidly that the reducer is waiting for longer than the test   The result of this backoff process is that the reduce process ends up appearing to hang; getting killed from above.   Note that this isn't the root cause of the problem; but it certainly amplifies things.,Open,Unresolved,,Unassigned,Steve Loughran,Fri; 28 Aug 2009 21:15:43 +0000,Thu; 29 Apr 2010 08:08:18 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-935
MAPREDUCE-936,Improvement,Major,contrib/fair-share,Allow a load difference in fairshare scheduler,The problem we are facing: It takes a long time for all tasks of a job to get scheduled on the cluster; even if the cluster is almost empty.  There are two reasons that together lead to this situation: 1. The load factor makes sure each TT runs the same number of tasks. (This is the part that this patch tries to change).  2. The scheduler tries to schedule map tasks locally (first node-local; then rack-local). There is a wait time (mapred.fairscheduler.localitywait.node and mapred.fairscheduler.localitywait.rack; both are around 10 sec in our conf); and accumulated wait time (JobInfo.localityWait). The accumulated wait time is reset to 0 whenever a non-local map task is scheduled. That means it takes N * wait_time to schedule N non-local map tasks.  Because of 1; a lot of TT will not be able to take more tasks; even if they have free slots. As a result; a lot of the map tasks cannot be scheduled locally.  Because of 2; it's really hard to schedule a non-local task.  As a result; sometimes we are seeing that it takes more than 2 minutes to schedule all the mappers of a job.,Closed,Fixed,,Zheng Shao,Zheng Shao,Fri; 28 Aug 2009 22:11:34 +0000,Tue; 24 Aug 2010 21:15:42 +0000,Fri; 4 Sep 2009 23:34:57 +0000,,0.20.1;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-936
MAPREDUCE-937,Improvement,Trivial,jobtracker,Allow comments in mapred.hosts and mapred.hosts.exclude files,It will be useful to have comments in the mapred.hosts and mapred.hosts.exclude files that will give description to hosts in there and to the file itself so different people maintaining these files will be able to share certain information about the process and hosts.,Closed,Duplicate,HADOOP-6216,Dmytro Molkov,Dmytro Molkov,Fri; 28 Aug 2009 22:28:07 +0000,Tue; 24 Aug 2010 21:15:42 +0000,Wed; 16 Sep 2009 04:45:12 +0000,,,,,HADOOP-6216,https://issues.apache.org/jira/browse/MAPREDUCE-937
MAPREDUCE-938,New Feature,Major,,Postgresql support for Sqoop,Sqoop should be able to import from postgresql databases.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 28 Aug 2009 23:30:04 +0000,Fri; 2 Jul 2010 06:31:24 +0000,Tue; 8 Sep 2009 12:54:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-938
MAPREDUCE-939,Bug,Minor,test,NPE in SortValidator if input path does not exist,If the input to SortValidator does not exist; NullPointerException is thrown. Below is the stacktrace:,Open,Unresolved,,Unassigned,Ramya Sunil,Mon; 31 Aug 2009 04:35:50 +0000,Mon; 31 Aug 2009 04:35:50 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-939
MAPREDUCE-940,Bug,Major,distcp,Distcp should not use mapred.system.dir,Distcp uses mapred.system.dir to create files like _distcp_src_files; _distcp_dst_files; etc. Since MAPREDUCE-181 is removing exposing of mapred.stystem.dir; distcp needs to use something like homeDir   instead of mapred.system.dir. Please see the patch of MAPREDUCE-181 for more details.,Resolved,Fixed,,Unassigned,Ravi Gummadi,Mon; 31 Aug 2009 12:56:14 +0000,Wed; 23 Jul 2014 22:38:13 +0000,Wed; 23 Jul 2014 22:38:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-940
MAPREDUCE-941,Bug,Trivial,,vaidya script calls awk instead of nawk,"The vaidya script uses this construction:  awk 'BEGIN  { RS = """" ; FS = "" n"" }  ;  { print $1 } '  Under ""old awk""; this fails.  Under ""new awk""; this works.  Depending upon the OS; awk may point to either old or new awk.  In the Solaris case; awk defaults to oawk.",Closed,Fixed,,Chad Metcalf,Allen Wittenauer,Mon; 31 Aug 2009 19:43:32 +0000,Tue; 24 Aug 2010 21:15:43 +0000,Fri; 18 Sep 2009 14:34:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-941
MAPREDUCE-942,Bug,Major,,job history logs should have a sane extension,It is not obvious by looking at:  hostname_1251411205412_job_200908271513_0010_DrWho_hadoop-0.20.0-test.jar  that this is a job history log file rather than a jar file.,Resolved,Duplicate,NULL,Unassigned,Allen Wittenauer,Mon; 31 Aug 2009 20:08:15 +0000,Tue; 10 Nov 2009 19:35:22 +0000,Tue; 10 Nov 2009 19:35:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-942
MAPREDUCE-943,Sub-task,Major,jobtracker,TestNodeRefresh timesout occasionally,TestNodeRefresh timesout occasionally. One of the hudson patch build with timeout @http: ,Closed,Fixed,,Amar Kamat,Amareshwari Sriramadasu,Tue; 1 Sep 2009 03:41:28 +0000,Tue; 24 Aug 2010 21:15:43 +0000,Mon; 7 Sep 2009 06:07:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-943
MAPREDUCE-944,Improvement,Major,contrib/fair-share,Extend FairShare scheduler to fair-share memory usage in the cluster,The FairShare Scheduler has an extensible LoadManager API to regulate allocating new tasks on a particular TaskTracker. In similar lines; it would be nice if the FairShare Scheduler can have a pluggable policy to regulate new tasks from a particular job. This will allow one to skip scheduling tasks of a job that  is eating a large percentage of memory in the cluster; i.e. fair-share of memory resources among jobs.,Closed,Fixed,,dhruba borthakur,dhruba borthakur,Wed; 2 Sep 2009 01:11:26 +0000,Tue; 24 Aug 2010 21:15:44 +0000,Thu; 10 Sep 2009 08:42:35 +0000,,,,MAPREDUCE-961,,https://issues.apache.org/jira/browse/MAPREDUCE-944
MAPREDUCE-945,Bug,Major,test,Test programs support only default queue.,None of the test program seems to be supporting queue's concept. These programs looks for the default queue only even if some other queue is specified to run these programs.,Closed,Fixed,,Sreekanth Ramakrishnan,Suman Sehgal,Thu; 19 Mar 2009 11:00:08 +0000,Tue; 24 Aug 2010 21:16:26 +0000,Tue; 8 Sep 2009 15:14:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-945
MAPREDUCE-946,Bug,Blocker,,Fix regression in LineRecordReader to comply with line length parameters,MAPREDUCE-773 accidentally changed code introduced in HADOOP-3144 controlling max line lengths. The behavior should be restored.,Closed,Fixed,,Chris Douglas,Chris Douglas,Wed; 2 Sep 2009 20:47:38 +0000,Tue; 24 Aug 2010 21:16:27 +0000,Thu; 17 Sep 2009 08:06:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-946
MAPREDUCE-947,Improvement,Major,,OutputCommitter should have an abortJob method,The OutputCommitter needs an abortJob method to clean up from failed jobs. Currently there is no way to distinguish between failed or succeeded jobs; making it impossible to write output promotion code.,Closed,Fixed,,Amar Kamat,Owen O'Malley,Tue; 9 Jun 2009 21:18:18 +0000,Tue; 24 Aug 2010 21:16:28 +0000,Wed; 21 Oct 2009 10:00:51 +0000,,0.21.0,,MAPREDUCE-948,MAPREDUCE-1102,https://issues.apache.org/jira/browse/MAPREDUCE-947
MAPREDUCE-948,New Feature,Major,client,FileOutputCommitter should create a _DONE file for successful jobs,Oozie and other workflow systems could use a _DONE file (zero-length) to poll for job-completion to be used as input-availability triggers.,Closed,Duplicate,MAPREDUCE-947,Amar Kamat,Arun C Murthy,Thu; 3 Sep 2009 20:42:13 +0000,Tue; 24 Aug 2010 21:17:10 +0000,Mon; 5 Oct 2009 05:49:07 +0000,,,,MAPREDUCE-947,,https://issues.apache.org/jira/browse/MAPREDUCE-948
MAPREDUCE-949,Bug,Major,,FileSplit still used by TextInputFormat,Even though FileSplit is deprecated; TextInputFormat still uses it,Resolved,Invalid,,Unassigned,Namit Jain,Fri; 4 Sep 2009 00:54:52 +0000,Tue; 24 Jan 2012 12:07:22 +0000,Tue; 24 Jan 2012 12:07:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-949
MAPREDUCE-950,Bug,Major,distributed-cache,Clean up unsymmetrical Job-API w.r.t DistributedCache,MAPREDUCE-898 cleans up user facing APIs in DistributedCache by adding them to Job setFilesToClassPathj() similar to setCacheArchives().,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Fri; 4 Sep 2009 04:24:10 +0000,Wed; 30 Jul 2014 02:47:37 +0000,,,,,OOZIE-638,MAPREDUCE-1744,https://issues.apache.org/jira/browse/MAPREDUCE-950
MAPREDUCE-951,Bug,Blocker,task,MAP_INPUT_BYTES counter is missing,Looks we lost it during one of the merges during project split:  http:  r1=776174r2=785392diff_format=h,Closed,Duplicate,HADOOP-5710,Arun C Murthy,Arun C Murthy,Fri; 4 Sep 2009 08:38:06 +0000,Tue; 24 Aug 2010 21:17:12 +0000,Fri; 4 Sep 2009 09:31:19 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-951
MAPREDUCE-952,Bug,Blocker,task,Previously removed Task.Counter reintroduced by MAPREDUCE-318,HADOOP-5717 introduced org.apache.hadoop.mapreduce.TaskCounters in-lieu of the older org.apache.hadoop.mapred.Task.Counter (see http: m4uwgj for the patch). However; MAPREDUCE-318 seems to have accidentally re-introduced it.,Closed,Fixed,,Jothi Padmanabhan,Arun C Murthy,Fri; 4 Sep 2009 08:41:38 +0000,Tue; 24 Aug 2010 21:17:13 +0000,Wed; 9 Dec 2009 10:10:28 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-952
MAPREDUCE-953,Improvement,Blocker,jobtracker,Generate configuration dump for hierarchial queue configuration,Generate configuration dump for hierarchial queue configuration,Closed,Fixed,,V.V.Chaitanya Krishna,rahul k singh,Fri; 4 Sep 2009 09:46:25 +0000,Tue; 24 Aug 2010 21:17:15 +0000,Fri; 18 Sep 2009 05:56:45 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-953
MAPREDUCE-954,Improvement,Major,client,The new interface's Context objects should be interfaces,When I was doing HADOOP-1230; I was persuaded to make the Context objects as classes. I think that was a serious mistake. It caused a lot of information leakage into the public classes.,Closed,Fixed,,Arun C Murthy,Owen O'Malley,Fri; 4 Sep 2009 18:05:04 +0000,Mon; 10 Oct 2011 13:07:57 +0000,Fri; 18 Sep 2009 23:53:38 +0000,,,,MAPREDUCE-372,,https://issues.apache.org/jira/browse/MAPREDUCE-954
MAPREDUCE-955,Bug,Major,,CombineFileRecordReader should pass a InputSplit in the constructor instead of CombineFileSplit,The specific reader can always cast the class as needed.,Open,Unresolved,,Unassigned,Namit Jain,Fri; 4 Sep 2009 21:22:37 +0000,Sat; 26 Feb 2011 06:33:22 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-955
MAPREDUCE-956,Bug,Major,task,Shuffle should be broken down to only two phases (copy/reduce) instead of three (copy/sort/reduce),For the progress calculations and displaying on the UI; shuffle; in its current form;  is decomposed into three phases (copy reduce). Actually; the sort phase is no longer applicable. I think we should just reduce the number of phases to two and assign 50% weight-age to each of copy and reduce phases. Thoughts?,Open,Unresolved,,Unassigned,Jothi Padmanabhan,Sat; 5 Sep 2009 04:42:00 +0000,Sat; 5 Dec 2009 01:50:55 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-956
MAPREDUCE-957,Wish,Minor,pipes,Set mapred.job.name for a pipes job,Currently mapred.job.name is not set for a pipes job. It will be useful if this value is set when a pipes job is submitted.,Resolved,Incomplete,,Unassigned,Ramya Sunil,Mon; 7 Sep 2009 06:30:36 +0000,Wed; 23 Jul 2014 22:55:33 +0000,Wed; 23 Jul 2014 22:55:33 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-957
MAPREDUCE-958,Bug,Major,tasktracker,TT should bail out early when mapred.job.tracker is bound to 0:0:0:0,It's OK for your job tracker's config to tells the JobTracker to come up on port 0:0:0:0; but its not OK for the TaskTrackers to get the same mapred.job.tracker configuration value; as it stops the TT from being able to report its heartbeat.  This misconfiguration surfaces in the TT's offerService() routine catching and logging a ConnectionRefused exception every time it tries to heartbeat. Now we have improved the error message in such a situation; it is still a bit late in the process to encounter a problem which should be obvious the moment the TT looks at its configuration.   Better to have the TT refuse to start up if jobTrackAddr.getAddress().isAnyLocalAddress().,Resolved,Incomplete,,Unassigned,Steve Loughran,Mon; 7 Sep 2009 15:05:59 +0000,Wed; 23 Jul 2014 23:06:21 +0000,Wed; 23 Jul 2014 23:06:21 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-958
MAPREDUCE-959,Bug,Minor,client;test,JobConf::setWorkingDirectory requires that the default FileSystem is reachable,If mapred.working.dir is not set; JobConf::setWorkingDirectory will attempt to obtain the default working directory for the default FileSystem. In trunk at least; if the default fs is HDFS and not reachable; set will fail:,Open,Unresolved,,Unassigned,Chris Douglas,Mon; 7 Sep 2009 23:04:26 +0000,Mon; 7 Sep 2009 23:07:05 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-959
MAPREDUCE-960,Improvement,Major,,Unnecessary copy in mapreduce.lib.input.KeyValueLineRecordReader,KeyValueLineRecordReader effects the copy from the line to the key value by creating separate arrays:   Since set triggers another copy and Text has a set taking byte[]; off; len; the intermediate copy can be avoided,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 8 Sep 2009 00:47:05 +0000,Tue; 24 Aug 2010 21:17:18 +0000,Wed; 9 Sep 2009 21:07:03 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-960
MAPREDUCE-961,New Feature,Major,contrib/fair-share,ResourceAwareLoadManager to dynamically decide new tasks based on current CPU/memory load on TaskTracker(s),Design and develop a ResouceAwareLoadManager for the FairShare scheduler that dynamically decides how many maps network usage in that machine.  The amount of resources currently used on each task tracker is being fed into the ResourceAwareLoadManager in real-time via an entity that is external to Hadoop.,Open,Unresolved,,Scott Chen,dhruba borthakur,Tue; 8 Sep 2009 05:22:56 +0000,Thu; 13 Jan 2011 02:29:03 +0000,,,0.22.0,,MAPREDUCE-944,MAPREDUCE-1167,https://issues.apache.org/jira/browse/MAPREDUCE-961
MAPREDUCE-962,Bug,Major,tasktracker,NPE in ProcfsBasedProcessTree.destroy(),This causes the following exception in TaskMemoryManagerThread. I observed this while running TestTaskTrackerMemoryManager.,Closed,Fixed,,Ravi Gummadi,Vinod Kumar Vavilapalli,Wed; 2 Sep 2009 11:22:32 +0000,Tue; 24 Aug 2010 21:17:20 +0000,Thu; 5 Nov 2009 06:14:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-962
MAPREDUCE-963,Improvement,Major,,mapred's FileAlreadyExistsException should be deprecated in favor of hadoop-common's one.,We should use org.apache.hadoop.fs.FileAlreadyExistsException instead of org.apache.hadoop.mapred.FileAlreadyExistsException. Mapred's one should be deprecated.,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Tue; 8 Sep 2009 19:23:18 +0000,Fri; 24 Feb 2017 16:05:09 +0000,Wed; 9 Sep 2009 18:49:55 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-963
MAPREDUCE-964,Bug,Critical,,Inaccurate values in jobSummary logs,For some jobs the mapSlotSeconds is incorrect.  negative value    INFO mapred.JobInProgress$JobSummary: jobId=job_200908270718_5861;submitTime=1251935672924;launchTime=1251935687698;finishTime=1251935997949;            numMaps=1026;numSlotsPerMap=1;numReduces=10;numSlotsPerReduce=1;user=dfsload;queue=gridops;status=SUCCEEDED;          mapSlotSeconds=1251949742;reduceSlotsSeconds=537;clusterMapCapacity=11262;clusterReduceCapacity=3754,Closed,Fixed,,Sreekanth Ramakrishnan,Rajiv Chittajallu,Tue; 8 Sep 2009 20:30:08 +0000,Tue; 24 Aug 2010 21:17:22 +0000,Fri; 25 Sep 2009 18:52:35 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-964
MAPREDUCE-965,Bug,Minor,tasktracker,LinuxTaskController logs some of the errors during initializeJob/initializeTask at INFO level instead of WARN/ERROR.,WARN ERROR level will make the problem more conspicuous.,Resolved,Incomplete,,Unassigned,Vinod Kumar Vavilapalli,Wed; 9 Sep 2009 05:56:06 +0000,Wed; 23 Jul 2014 23:30:12 +0000,Wed; 23 Jul 2014 23:30:12 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-965
MAPREDUCE-966,Improvement,Major,tools/rumen,Rumen interface improvement,Rumen could expose a cleaner interface to simplify the integration with other tools.,Closed,Fixed,,Hong Tang,Hong Tang,Wed; 9 Sep 2009 21:53:50 +0000,Tue; 24 Aug 2010 21:17:23 +0000,Sat; 12 Sep 2009 09:31:40 +0000,,0.21.0,,MAPREDUCE-776,,https://issues.apache.org/jira/browse/MAPREDUCE-966
MAPREDUCE-967,Improvement,Major,tasktracker,TaskTracker does not need to fully unjar job jars,In practice we have seen some users submitting job jars that consist of 10;000+ classes. Unpacking these jars into mapred.local.dir and then cleaning up after them has a significant cost (both in wall clock and in unnecessary heavy disk utilization). This cost can be easily avoided,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 10 Sep 2009 06:26:20 +0000,Tue; 24 Aug 2010 21:17:24 +0000,Tue; 15 Dec 2009 20:56:52 +0000,,0.21.0,,HADOOP-6346,MAPREDUCE-727,https://issues.apache.org/jira/browse/MAPREDUCE-967
MAPREDUCE-968,Bug,Major,distcp,NPE in distcp encountered when placing _logs directory on S3FileSystem,If distcp is pointed to an empty S3 bucket as the destination for an s3:  filesystem transfer; it will fail with the following exception  Copy failed:  884),Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 10 Sep 2009 21:31:29 +0000,Sat; 26 Oct 2013 14:10:13 +0000,Mon; 14 Sep 2009 16:00:00 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-968
MAPREDUCE-969,Bug,Major,jobtracker;task;tasktracker,NullPointerException during reduce freezes job,"We experienced several jobs stuck in Reduce on a cluster. All of the stuck reduce tasks had a similar were stuck at ""Need another 2 map output(s) where 0 is already in progress"" despite all of the mappers having completed; and 0 scheduled. The stuck reducers had experienced the following exception early in the shuffle:   2670)  Will attach more information and logs momentarily.",Resolved,Duplicate,HADOOP-4744,Todd Lipcon,Todd Lipcon,Thu; 10 Sep 2009 23:45:37 +0000,Mon; 2 Nov 2009 23:49:00 +0000,Mon; 2 Nov 2009 23:49:00 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-969
MAPREDUCE-970,Bug,Major,tasktracker,task-controller/configuration.c:get_values is broken,task-controller configuration.c:get_values is supposed to return a char** with the last element set to NULL.  It doesn't correctly handle empty config-values; #values as an exactly multiple of MAX_SIZE.,Resolved,Incomplete,,Arun C Murthy,Arun C Murthy,Thu; 10 Sep 2009 23:54:01 +0000,Wed; 23 Jul 2014 23:31:08 +0000,Wed; 23 Jul 2014 23:31:08 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-970
MAPREDUCE-971,Bug,Major,distcp,distcp does not always remove distcp.tmp.dir,Sometimes distcp leaves behind its tmpdir when the target filesystem is s3n.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 11 Sep 2009 00:06:45 +0000,Tue; 24 Aug 2010 21:17:26 +0000,Thu; 17 Sep 2009 15:25:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-971
MAPREDUCE-972,Improvement,Major,distcp;documentation,distcp can timeout during rename operation to s3,rename() in S3 is implemented as copy + delete. The S3 copy operation can perform very slowly; which may cause task timeout.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 11 Sep 2009 01:34:14 +0000,Tue; 24 Aug 2010 21:17:27 +0000,Tue; 3 Nov 2009 08:03:26 +0000,,0.20.1,,HADOOP-6324,MAPREDUCE-1127,https://issues.apache.org/jira/browse/MAPREDUCE-972
MAPREDUCE-973,Bug,Trivial,examples;test,Move test utilities from examples to test,The FailJob class (MAPREDUCE-567) is more a test utility than an example. It should either move to src test; ideally with a unit test built around it; or be removed. Similarly; SleepJob class is mostly used in unit tests.,Closed,Fixed,,Chris Douglas,Chris Douglas,Fri; 11 Sep 2009 03:36:06 +0000,Tue; 24 Aug 2010 21:17:28 +0000,Fri; 11 Sep 2009 17:40:21 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-973
MAPREDUCE-974,Bug,Major,client,"CLI command for viewing tasktrackers should not be under ""job""","For viewing the tasktrackers in a mr cluster the command available is "". hadoop job -list-tracker"". But the tracker info is cluster level info and not job level.",Resolved,Fixed,,Dmytro Molkov,Amar Kamat,Fri; 11 Sep 2009 05:56:28 +0000,Wed; 23 Jul 2014 21:20:21 +0000,Wed; 23 Jul 2014 21:20:21 +0000,,,,,MAPREDUCE-892,https://issues.apache.org/jira/browse/MAPREDUCE-974
MAPREDUCE-975,Sub-task,Major,client;jobtracker,Add an API in job client to get the history file url for a given job id,MAPREDUCE-817 added an API to get history url in RunningJob. Similar API should be added in job client to get the history file given a job id. Something like: String getHistoryFile(JobId jobid);,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Mon; 14 Sep 2009 09:47:37 +0000,Tue; 24 Aug 2010 21:17:30 +0000,Fri; 18 Sep 2009 11:37:06 +0000,,,,MAPREDUCE-157;MAPREDUCE-777,,https://issues.apache.org/jira/browse/MAPREDUCE-975
MAPREDUCE-976,Bug,Major,tasktracker,LinuxTaskController binary should be versioned and mapreduce should run only with a particular version,There is a strict coupling between the mapreduce code and the LinuxTaskController binary that it runs. Accidentally intentionally running different versions of the binary with different versions of the framework may lead to hard-to-debug problems. We should have checks similar to JT-TT version lock-in.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Mon; 14 Sep 2009 11:07:24 +0000,Wed; 23 Jul 2014 23:35:51 +0000,Wed; 23 Jul 2014 23:35:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-976
MAPREDUCE-977,Bug,Major,build,Missing jackson jars from Eclipse template,nan,Closed,Fixed,,Tom White,Tom White,Mon; 14 Sep 2009 15:45:26 +0000,Tue; 24 Aug 2010 21:17:32 +0000,Thu; 17 Sep 2009 09:55:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-977
MAPREDUCE-978,Bug,Major,contrib/streaming,#NAME?,For a streaming application I used the -file option to move some executable files to the slave nodes.  On the submit node; they had +x permissions but on the destination node they were created with -x permissions.  This probably has to do with the umask settings on the various nodes; but streaming should preserve the original permissions.,Resolved,Invalid,,Unassigned,Chris Dyer,Mon; 14 Sep 2009 20:28:41 +0000,Thu; 1 Jul 2010 03:26:30 +0000,Wed; 23 Jun 2010 05:39:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-978
MAPREDUCE-979,Bug,Blocker,jobtracker;tasktracker,JobConf.getMemoryFor{Map|Reduce}Task doesn't fallback to newer config knobs when mapred.taskmaxvmem is set to DISABLED_MEMORY_LIMIT of -1,JobConf.getMemoryFor {Map|Reduce} Task doesn't fallback to newer config knobs when mapred.taskmaxvmem is set to DISABLED_MEMORY_LIMIT of -1; this results in failed job-submissions when mapred-default.xml has the default value of -1.,Resolved,Fixed,,Sreekanth Ramakrishnan,Arun C Murthy,Tue; 15 Sep 2009 03:59:40 +0000,Wed; 14 Oct 2009 17:05:40 +0000,Mon; 12 Oct 2009 09:48:09 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-979
MAPREDUCE-980,New Feature,Major,,Modify JobHistory to use Avro for serialization instead of raw JSON,MAPREDUCE-157 modifies JobHistory to log events using Json Format.  This can be modified to use Avro instead.,Closed,Fixed,,Doug Cutting,Jothi Padmanabhan,Tue; 15 Sep 2009 05:09:21 +0000,Tue; 24 Aug 2010 21:17:33 +0000,Fri; 18 Sep 2009 22:24:12 +0000,,,,MAPREDUCE-157,,https://issues.apache.org/jira/browse/MAPREDUCE-980
MAPREDUCE-981,Bug,Major,tasktracker,TaskTracker.purgeJob fails with NPE if the job is partially localized.,TaskTracker does not cleans up job directory when LinuxTraskController is used with wrong permissions and setup task of job fails,Open,Unresolved,,Amareshwari Sriramadasu,Karam Singh,Tue; 15 Sep 2009 07:04:03 +0000,Wed; 7 Sep 2011 08:34:16 +0000,,,,,,MAPREDUCE-899,https://issues.apache.org/jira/browse/MAPREDUCE-981
MAPREDUCE-982,Bug,Major,distributed-cache,Deprecated DistributedCache still used in the new apis in org.apache.hadoop.mapreduce package,Deprecated DistributedCache still used in the new apis in org.apache.hadoop.mapreduce package e.g. JobContext; we should fix it.,Resolved,Won't Fix,,Unassigned,Arun C Murthy,Tue; 15 Sep 2009 07:09:38 +0000,Wed; 23 Jul 2014 23:37:27 +0000,Wed; 23 Jul 2014 23:37:27 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-982
MAPREDUCE-983,Bug,Major,client,bin/hadoop job -fs file:///sdsdad -list still works,"After bringing up the cluster with latest trunk; if ""bin sdsdad -list"" command is issued; it still displays the previous filesystem that is present in conf and does not take the new fs.  It should pickup the command line fs; overriding any other parameter.",Resolved,Incomplete,,Unassigned,Iyappan Srinivasan,Tue; 15 Sep 2009 12:16:17 +0000,Wed; 23 Jul 2014 23:39:52 +0000,Wed; 23 Jul 2014 23:39:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-983
MAPREDUCE-984,Bug,Major,client,"bin/hadoop job -kill command says"" job successfully killed"" even though job has retired.","After bringing up the cluster; run a command; allow it to finish and move to retired folder. Now try killing the job with ""bin hadoop job -kill job_id"" . It says successfully killed. The message should be . Unable to kill jobid",Resolved,Duplicate,MAPREDUCE-485,Unassigned,Iyappan Srinivasan,Tue; 15 Sep 2009 12:19:02 +0000,Wed; 16 Sep 2009 04:35:16 +0000,Wed; 16 Sep 2009 04:33:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-984
MAPREDUCE-985,Bug,Major,,job -kill-task <task-id>] and -fail-task <task-id> are not task-ids they are attempt ids,Right now; bin hadoop job show soptions as   -kill-task task-id and  -fail-task taskid  These two are confusing as task attempt id and not task ids should be provioded to kill them.  These help messages have to be changed.,Resolved,Fixed,,Unassigned,Iyappan Srinivasan,Tue; 15 Sep 2009 12:28:11 +0000,Wed; 23 Jul 2014 23:43:55 +0000,Wed; 23 Jul 2014 23:43:55 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-985
MAPREDUCE-986,Bug,Major,tools/rumen,rumen makes a task with a null type when one of the task lines is truncated,Rumen was used to produce a job trace; but the job trace contained a LoggedTask that had a null taskType.  This appears to happen when a Task line is truncated.  We should not put the LoggedTask in the trace at all when this happens.,Closed,Fixed,,Dick King,Dick King,Tue; 15 Sep 2009 20:32:52 +0000,Tue; 24 Aug 2010 21:17:34 +0000,Wed; 14 Oct 2009 07:36:04 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-986
MAPREDUCE-987,New Feature,Minor,build;test,Exposing MiniDFS and MiniMR clusters as a single process command-line,"It's hard to test non-Java programs that rely on significant mapreduce functionality.  The patch I'm proposing shortly will let you just type ""bin hadoop jar hadoop-hdfs-hdfswithmr-test.jar minicluster"" to start a cluster (internally; it's using Mini {MR;HDFS} Cluster) with a specified number of daemons; etc.  A test that checks how some external process interacts with Hadoop might start minicluster as a subprocess; run through its thing; and then simply kill the  subprocess.  I've been using just such a system for a couple of weeks; and I like it.  It's significantly easier than developing a lot of scripts to start a pseudo-distributed cluster; and then clean up after it.  I figure others might find it useful as well.  I'm at a bit of a loss as to where to put it in 0.21.  hdfs-with-mr tests have all the required libraries; so I've put it there.  I could conceivably split this into ""minimr"" and ""minihdfs""; but it's specifically the fact that they're configured to talk to each other that I like about having them together.  And one JVM is better than two for my test programs.",Closed,Fixed,,Ahmed Radwan,Philip Zeyliger,Tue; 15 Sep 2009 21:31:10 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Mon; 23 Jul 2012 23:58:12 +0000,,1.2.0;2.0.2-alpha,,MAPREDUCE-4406;MAPREDUCE-4407,HDFS-3167,https://issues.apache.org/jira/browse/MAPREDUCE-987
MAPREDUCE-988,Bug,Major,build,ant package does not copy the capacity-scheduler.jar under HADOOP_HOME/build/hadoop-mapred-0.21.0-dev/contrib/capacity-scheduler,ant package does not copy the hadoop-0.21.0-dev-capacity-scheduler.jar under HADOOP_HOME .  Till yesterday it was copying it properly. Issue seems to be pointing to the latest checkin of  MAPREDUCE-776; which changes build.xml.,Closed,Fixed,,Hong Tang,Iyappan Srinivasan,Wed; 16 Sep 2009 11:39:38 +0000,Tue; 24 Aug 2010 21:17:35 +0000,Thu; 17 Sep 2009 10:55:12 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-988
MAPREDUCE-989,Improvement,Major,distributed-cache,Allow segregation of DistributedCache for maps and reduces,Applications might have differing needs for files in the DistributedCache wrt maps and reduces. We should allow them to specify them separately.,Open,Unresolved,MAPREDUCE-1843,Unassigned,Arun C Murthy,Wed; 16 Sep 2009 17:20:27 +0000,Wed; 23 Jul 2014 23:49:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-989
MAPREDUCE-990,Improvement,Minor,,Making distributed cache getters in JobContext never return null,MAPREDUCE-898 moved distributed cache setters and getters into Job and JobContext.  Since the API is new; I'd like to propose that those getters never return null; but instead always return an array; even if it's empty.  If people don't like this change; I can instead merely update the  oc to reflect the fact that null may be returned.,Open,Unresolved,,Philip Zeyliger,Philip Zeyliger,Wed; 16 Sep 2009 17:35:08 +0000,Sun; 18 Oct 2009 19:23:49 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-990
MAPREDUCE-991,Bug,Major,,HadoopPipes.cc doesn't compile cleanly with SunStudio,Attempting to compile HadoopPipes.cc throws the following warnings and errors:,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 16 Sep 2009 23:15:49 +0000,Wed; 2 Nov 2011 17:49:37 +0000,Wed; 2 Nov 2011 17:49:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-991
MAPREDUCE-992,Bug,Major,jobtracker,bin/hadoop job -events < jobid> gives event links which does not work.,"bin tasklog""  These links should work properly.",Resolved,Incomplete,,Unassigned,Iyappan Srinivasan,Thu; 17 Sep 2009 05:42:47 +0000,Wed; 23 Jul 2014 23:50:49 +0000,Wed; 23 Jul 2014 23:50:49 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-992
MAPREDUCE-993,Bug,Minor,jobtracker,bin/hadoop job -events <jobid> <from-event-#> <#-of-events> help message is confusing,More explanation needs to be there like a) events always start from 1 b) the message could be like from-event-number to-event-number where from-event-number starts from 1. This will give teh end user idea as to what to enter.,Closed,Fixed,HADOOP-7396,Harsh J,Iyappan Srinivasan,Thu; 17 Sep 2009 06:25:40 +0000,Tue; 15 Nov 2011 00:49:01 +0000,Wed; 2 Mar 2011 05:43:40 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-993
MAPREDUCE-994,Bug,Minor,,bin/hadoop job -counter help options do not give information on permissible values.,Right now;  bin hadoop job -counter  DEPRECATED: Use of this script to execute mapred command is deprecated. Instead use the mapred command for it.  Usage: CLI -counter job-id group-name counter-name&#93;  What are these group names and what are the counter-names is not explained. All permissible values of group-name and counter-name should be specified.  Group_name Ex:  org.apache.hadoop.mapreduce.TaskCounter   Counter name example: REDUCE_INPUT_RECORDS,Resolved,Incomplete,,Unassigned,Iyappan Srinivasan,Thu; 17 Sep 2009 06:35:54 +0000,Wed; 23 Jul 2014 23:51:23 +0000,Wed; 23 Jul 2014 23:51:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-994
MAPREDUCE-995,Bug,Critical,,JobHistory should handle cases where task completion events are generated after job completion event,It is apparently possible; in certain circumstances (failed job; for example); for the job history to get task completion events after the job completion event. This currently causes NPE in job history. Thanks Hong for identifying this issue,Resolved,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Thu; 17 Sep 2009 10:18:05 +0000,Fri; 18 Sep 2009 05:53:18 +0000,Fri; 18 Sep 2009 03:23:19 +0000,,,,MAPREDUCE-728,,https://issues.apache.org/jira/browse/MAPREDUCE-995
MAPREDUCE-996,Bug,Major,capacity-sched,Queue Scheduling Information is lost from Ui when we run mapred mradmin -refreshQueues after mapreduce 861,nan,Closed,Duplicate,MAPREDUCE-893,Unassigned,Karam Singh,Thu; 17 Sep 2009 11:36:37 +0000,Tue; 24 Aug 2010 21:17:35 +0000,Tue; 6 Oct 2009 13:14:59 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-996
MAPREDUCE-997,Bug,Major,,Acls are not working properly when they are set to user groups,When submit-job-acl set usergroup (ug1). if user submits a using hadoop.job.ugi=u1;ug2 it is also gets accepted. (user u1 is also part ug1). In hadoop 0.20.0; job gets rejected. Its a regression issue.,Resolved,Incomplete,,Unassigned,Karam Singh,Thu; 17 Sep 2009 11:39:41 +0000,Wed; 23 Jul 2014 23:52:27 +0000,Wed; 23 Jul 2014 23:52:27 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-997
MAPREDUCE-998,Bug,Major,capacity-sched,Wrong error message thrown when we try submit to container queue.,"Setup have multilevel queue. parent queues a;b and has two child queues a11; a12. If we try sub queue ""a"" the following error is thrown -"": [ org.apache.hadoop.ipc.RemoteException:  2740)  ] where it should have proper like user cannot submit job to container queue.",Resolved,Fixed,,Unassigned,Karam Singh,Thu; 17 Sep 2009 11:51:40 +0000,Wed; 23 Jul 2014 23:52:55 +0000,Wed; 23 Jul 2014 23:52:55 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-998
MAPREDUCE-999,Improvement,Major,,Improve Sqoop test speed and refactor tests,Sqoop's tests take a long time to run; but this can be improved (by a factor of 2 or more) by taking advantage of jobclient.completion.poll.interval.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 17 Sep 2009 21:10:07 +0000,Fri; 2 Jul 2010 06:31:25 +0000,Wed; 14 Oct 2009 10:58:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-999
MAPREDUCE-1000,Bug,Major,jobtracker,JobHistory.initDone() should retain the try ... catch in the body,nan,Closed,Fixed,,Jothi Padmanabhan,Hong Tang,Thu; 17 Sep 2009 22:28:22 +0000,Tue; 24 Aug 2010 21:17:37 +0000,Fri; 25 Sep 2009 12:24:36 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1000
MAPREDUCE-1001,Bug,Major,,Reducing code duplication in Mumak,The first release of Mumak (MAPREDUCE-728) introduces some coupling between the core mapred code with Mumak code. Specifically; New constructors are added to JobTracker and JobInProgress to allow simulator to subclass and alter JT JIP behavior. This could be a code maintenance overhead when new changes have to be ported to either the added constructors or the simulation subclasses.  It would be nice to refactor the constructors of JobTracker and JobInProgress to avoid as much code duplication as possible.,Resolved,Won't Fix,,Unassigned,Hong Tang,Fri; 18 Sep 2009 02:27:58 +0000,Thu; 24 Jul 2014 00:02:09 +0000,Thu; 24 Jul 2014 00:02:09 +0000,,,,,MAPREDUCE-728,https://issues.apache.org/jira/browse/MAPREDUCE-1001
MAPREDUCE-1002,Bug,Major,client,After MAPREDUCE-862; command line queue-list doesn't print any queues,Web-ui correctly prints the queues; it is the command line that is not showing any queues.,Closed,Fixed,,V.V.Chaitanya Krishna,Vinod Kumar Vavilapalli,Fri; 18 Sep 2009 06:28:47 +0000,Tue; 24 Aug 2010 21:17:37 +0000,Fri; 18 Sep 2009 11:53:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1002
MAPREDUCE-1003,Bug,Major,,trunk build fails when -Declipse.home is set,compile:      echo contrib: eclipse-plugin        4 errors,Closed,Fixed,,Ravi Gummadi,Giridharan Kesavan,Fri; 18 Sep 2009 10:59:17 +0000,Tue; 24 Aug 2010 21:17:38 +0000,Fri; 18 Sep 2009 13:58:48 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1003
MAPREDUCE-1004,Bug,Major,build,ant binary does not  copy the jar files properly,ant binary does not copy the hadoop-mapred-examples-0.21.0-dev.jar; hadoop-mapred-test-0.21.0-dev.jar; hadoop-mapred-tools-0.21.0-dev.jar to the trunk lib directory.   It should get copied to both these directories.,Resolved,Fixed,,Unassigned,Iyappan Srinivasan,Fri; 18 Sep 2009 12:41:08 +0000,Thu; 24 Jul 2014 00:03:14 +0000,Thu; 24 Jul 2014 00:03:14 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1004
MAPREDUCE-1005,Improvement,Major,build,why should not capacity sheduler jar not copied under lib during build,Right now; the capacity-scheduler.jar is not getting copied under trunk hadoop-0.21.0-dev-capacity-scheduler.jar.  Every time somebody tries to build the trunk; they have to copy this jar from contrib to lib manually.   During any kind of build (ant binary; ant bin-package; ant package) ; this jar file should also get copied to lib. If a person uses default or fair sheduler; he will not use it; but still there is no harm of it being in lib. If he uses capacity scheduler; then it gets used automatically. This manual copy should be avoided.,Resolved,Fixed,,Unassigned,Iyappan Srinivasan,Fri; 18 Sep 2009 13:37:19 +0000,Thu; 24 Jul 2014 00:07:47 +0000,Thu; 24 Jul 2014 00:07:47 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1005
MAPREDUCE-1006,Bug,Major,,Making JobStoryProducer and ClusterStory pluggable in Mumak,Mumak should make JobStoryProducer and ClusterStory pluggable to enable it to simulate synthetic traces and cluster configurations.,Resolved,Won't Fix,,Unassigned,Hong Tang,Fri; 18 Sep 2009 16:19:34 +0000,Thu; 24 Jul 2014 00:02:40 +0000,Thu; 24 Jul 2014 00:02:40 +0000,,0.21.0,,,MAPREDUCE-728,https://issues.apache.org/jira/browse/MAPREDUCE-1006
MAPREDUCE-1007,Bug,Blocker,jobtracker,MAPREDUCE-777 breaks the UI for hierarchial Queues. ,MAPREDUCE-777 breaks jobtracker UI for hierarchial queues. When jobtracker.jsp is accessed; it throws the following exception:    (Issue number and the line number in code match - 1007. Some fun for a Hadoop developer  ),Closed,Fixed,,V.V.Chaitanya Krishna,rahul k singh,Fri; 18 Sep 2009 19:59:27 +0000,Tue; 24 Aug 2010 21:17:39 +0000,Fri; 20 Nov 2009 10:00:14 +0000,,0.21.0,,MAPREDUCE-1082,,https://issues.apache.org/jira/browse/MAPREDUCE-1007
MAPREDUCE-1008,Test,Major,distcp;test,distcp needs CLI unit tests,The distcp tool is often used in automated environments and includes many diagnostic messages. It would be helpful to catch changes to the CLI and validate the correctness of output messages.,Open,Unresolved,,Unassigned,Chris Douglas,Fri; 18 Sep 2009 20:36:31 +0000,Thu; 24 Jul 2014 00:08:54 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1008
MAPREDUCE-1009,Bug,Blocker,documentation,Forrest documentation needs to be updated to describes features provided for supporting hierarchical queues,Forrest documentation must be updated for describing how to set up and use hierarchical queues in the framework and the capacity scheduler.,Closed,Fixed,,Vinod Kumar Vavilapalli,Hemanth Yamijala,Fri; 18 Sep 2009 21:06:37 +0000,Tue; 24 Aug 2010 21:17:40 +0000,Wed; 23 Dec 2009 11:08:08 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1009
MAPREDUCE-1010,Bug,Minor,harchive,Adding tests for changes in archives.,Created this jira so that the tests can be added for HADOOP-6047. The test cases for hadoop archives are in mapreduce.,Resolved,Fixed,,Mahadev konar,Mahadev konar,Fri; 18 Sep 2009 22:36:12 +0000,Thu; 28 Jan 2010 00:41:00 +0000,Thu; 28 Jan 2010 00:41:00 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1010
MAPREDUCE-1011,Improvement,Major,build,Git and Subversion ignore of build.properties,Currently ant test-patch can't use build.properties; because it counts as an non-pristine directory. I'll add build.properties to the subversion properties.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Fri; 18 Sep 2009 23:00:26 +0000,Tue; 24 Aug 2010 21:17:41 +0000,Fri; 18 Sep 2009 23:10:58 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1011
MAPREDUCE-1012,Improvement,Blocker,client,Context interfaces should be Public Evolving,As discussed in MAPREDUCE-954 the nascent context interfaces should be marked as Public Evolving to facilitate future evolution.,Closed,Fixed,,Tom White,Tom White,Sat; 19 Sep 2009 08:13:42 +0000,Tue; 24 Aug 2010 21:17:41 +0000,Sun; 18 Oct 2009 23:45:49 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1012
MAPREDUCE-1013,Improvement,Major,documentation, MapReduce Project page does not show 0.20.1 documentation/release information.,"The MapReduce Project page shows the documentation for 0.20.0 even though the latest stable release version is 0.20.1. The releases page also shows all the pre 0.20.1 releases; but does not show 0.20.1 eventhough if you click on the ""Download a release now!"" link the mirror links are for hadoop core.",Resolved,Fixed,,Unassigned,Andy Sautins,Sun; 20 Sep 2009 20:44:27 +0000,Thu; 24 Jul 2014 00:11:17 +0000,Thu; 24 Jul 2014 00:11:17 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1013
MAPREDUCE-1014,Bug,Blocker,,After the 0.21 branch; MapReduce trunk doesn't compile,When ant is run; the build fails with compilation problems. The first of that is: compile-mapred-classes:   taskdef log4j:ERROR Could not instantiate class org.apache.hadoop.metrics.jvm.EventCounter.   taskdef  476),Closed,Fixed,,Ravi Gummadi,Devaraj Das,Mon; 21 Sep 2009 17:06:35 +0000,Tue; 24 Aug 2010 21:17:42 +0000,Tue; 22 Sep 2009 17:41:18 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1014
MAPREDUCE-1015,Improvement,Major,documentation,Map-Reduce interface classification,HADOOP-5073 introduced the ability to classify apis wrt scope and stability. We should do a sweep over the Map-Reduce apis and classify them accordingly.,Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 21 Sep 2009 18:31:35 +0000,Thu; 24 Jul 2014 00:11:36 +0000,Thu; 24 Jul 2014 00:11:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1015
MAPREDUCE-1016,Bug,Major,,Make the format of the Job History be JSON instead of Avro binary,I forgot that one of the features that would be nice is to off load the job history display from the JobTracker. That will be a lot easier; if the job history is stored in JSON. Therefore; I think we should change the storage now to prevent incompatibilities later.,Closed,Fixed,,Doug Cutting,Owen O'Malley,Mon; 21 Sep 2009 21:05:42 +0000,Tue; 24 Aug 2010 21:17:43 +0000,Fri; 23 Oct 2009 23:51:32 +0000,,,,MAPREDUCE-1072;MAPREDUCE-1135,,https://issues.apache.org/jira/browse/MAPREDUCE-1016
MAPREDUCE-1017,New Feature,Major,,Compression and output splitting for Sqoop,"Sqoop ""direct mode"" writing will generate a single large text file in HDFS. It is important to be able to compress this data before it reaches HDFS. Due to the difficulty in splitting compressed files in HDFS for use by MapReduce jobs; data should also be split at compression time.",Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 22 Sep 2009 00:29:33 +0000,Thu; 2 May 2013 02:29:26 +0000,Thu; 22 Oct 2009 14:58:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1017
MAPREDUCE-1018,Bug,Blocker,documentation,Document changes to the memory management and scheduling model,There were changes done for the configuration; monitoring and scheduling of high ram jobs. This must be documented in the mapred-defaults.xml and also on forrest documentation,Closed,Fixed,,Hemanth Yamijala,Hemanth Yamijala,Tue; 2 Jun 2009 11:45:09 +0000,Tue; 24 Aug 2010 21:17:44 +0000,Mon; 14 Jun 2010 05:24:26 +0000,,0.21.0,,,HADOOP-6821;MAPREDUCE-40;HADOOP-5881,https://issues.apache.org/jira/browse/MAPREDUCE-1018
MAPREDUCE-1019,Bug,Major,tasktracker,Stale user directories left on TTs after MAPREDUCE-856,MAPREDUCE-856 changed the directory structure of job files on the TT. As part of this; it introduced user directories under taskTracker subdirectory which contains private files of a user. The user directories are created on the TT when the user's first task is assigned to this TT. But these user-directories are never cleaned up from the TT; even when no task of this user is running on this TT. This essentially leaves empty user directories hanging around on the TT; whose number may increase over time.  This was originally intended to be fixed in MAPREDUCE-856; but could not be done because increasing complexity already stretched that issue.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Tue; 22 Sep 2009 07:10:06 +0000,Thu; 24 Jul 2014 00:14:48 +0000,Thu; 24 Jul 2014 00:14:48 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1019
MAPREDUCE-1020,Bug,Major,test,Add more unit tests to test the queue refresh feature MAPREDUCE-893,MAPREDUCE-893 included unit tests verifying the sanity of the refresh feature - both the queue properities' refresh as well as the scheduler properties' refresh. The test suite can and should be expanded. This will help easily identifying issues that will otherwise be caught during manual testing. For e.g.; during manual testing of MAPREDUCE-893; we identified an NPE in the scheduler iteration occuring during heartbeat; which could have been easily identified by unit tests.,Open,Unresolved,,V.V.Chaitanya Krishna,Vinod Kumar Vavilapalli,Tue; 22 Sep 2009 07:36:40 +0000,Fri; 2 Jul 2010 00:04:57 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1020
MAPREDUCE-1021,Bug,Major,documentation,mapred-default.xml does not document all framework config parameters,MAPREDUCE-849 renamed and categorized configuration keys. All the configuration keys should be documented with defaults in mapred-default.xml,Resolved,Fixed,,Amareshwari Sriramadasu,Sharad Agarwal,Tue; 22 Sep 2009 07:37:50 +0000,Thu; 24 Jul 2014 00:15:25 +0000,Thu; 24 Jul 2014 00:15:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1021
MAPREDUCE-1022,Bug,Blocker,test,Trunk tests fail because of test-failure in Vertica,ant test fails with,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 22 Sep 2009 09:44:59 +0000,Tue; 24 Aug 2010 21:17:45 +0000,Thu; 24 Sep 2009 03:28:49 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1022
MAPREDUCE-1023,Bug,Major,build,Newly introduced findBugs warnings should be suppressed,FindBugs warnings introduced by MAPREDUCE-711 and HADOOP-6230 should be suppressed by modifying src findbugsExcludeFile.xml.,Closed,Duplicate,MAPREDUCE-769;MAPREDUCE-1108,Unassigned,Vinod Kumar Vavilapalli,Tue; 22 Sep 2009 10:06:56 +0000,Tue; 24 Aug 2010 21:18:12 +0000,Wed; 14 Oct 2009 06:39:45 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1023
MAPREDUCE-1024,Bug,Major,,Provide proper test cases to test the CLI of hierarchical queues,After the implementation of HADOOP-6277; the MRCLI can be modified to provide more appropriate test cases to test the CLI for hierarchical queues.,Open,Unresolved,,Unassigned,V.V.Chaitanya Krishna,Tue; 22 Sep 2009 10:12:06 +0000,Tue; 22 Sep 2009 10:12:56 +0000,,,,,HADOOP-6277,,https://issues.apache.org/jira/browse/MAPREDUCE-1024
MAPREDUCE-1025,Bug,Major,tasktracker,Subprocesses of tasks should be killed even if mapred.userlog.limit.kb is set to a positive value when setsid is used for launching tasks,setsid is to be used when launching tasks even when the deprecated mapred.userlog.limit.kb(or the new mapreduce.task.userlog.limit.kb) is set to a positive value  sothat subprocesses of tasks get killed properly.,Open,Unresolved,,Ravi Gummadi,Ravi Gummadi,Tue; 22 Sep 2009 10:20:01 +0000,Thu; 13 Jan 2011 02:27:47 +0000,,,0.21.0;0.22.0,,MAPREDUCE-1057,,https://issues.apache.org/jira/browse/MAPREDUCE-1025
MAPREDUCE-1026,Sub-task,Major,security,Shuffle should be secure,Since the user's data is available via http from the TaskTrackers; we should require a job-specific secret to access it.,Closed,Fixed,HADOOP-4991,Boris Shkolnik,Owen O'Malley,Tue; 22 Sep 2009 21:29:46 +0000,Tue; 24 Aug 2010 21:18:12 +0000,Fri; 20 Nov 2009 23:44:21 +0000,,,,,HADOOP-4487,https://issues.apache.org/jira/browse/MAPREDUCE-1026
MAPREDUCE-1027,Improvement,Major,jobtracker,jobtracker.jsp can have an html text block for announcements by admins.,jobtracker.jsp is the first page for users of Map announcements time to time.,Resolved,Won't Fix,,Amar Kamat,Vinod Kumar Vavilapalli,Wed; 23 Sep 2009 06:28:54 +0000,Thu; 24 Jul 2014 00:32:01 +0000,Thu; 24 Jul 2014 00:32:01 +0000,,,,,MAPREDUCE-208,https://issues.apache.org/jira/browse/MAPREDUCE-1027
MAPREDUCE-1028,Bug,Blocker,jobtracker,Cleanup tasks are scheduled using high memory configuration; leaving tasks in unassigned state.,A cleanup task is launched for a failed task of a job. This task is created based on the TIP of the failed task; and so is marked as requiring as many slots to run as the original task itself. For instance; if a high RAM job requires 2 slots per task; a cleanup task of the high RAM jobs requires 2 slots as well.  Further; a cleanup task is scheduled to a tasktracker by the jobtracker itself and not the scheduler. While doing so; the JT doesn't check if the TT has enough slots free to run a high RAM cleanup task - always assuming 1 slot is enough. Thus; a task is oversubscribed to the TT.  However; on the TT; before launch; we check that the task can actually run; and wait for so many slots to become available. If the slots don't get freed quickly; we will have tasks stuck in an unassigned state.,Closed,Fixed,,Ravi Gummadi,Hemanth Yamijala,Wed; 23 Sep 2009 10:44:57 +0000,Tue; 24 Aug 2010 21:18:14 +0000,Fri; 25 Sep 2009 18:26:28 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1028
MAPREDUCE-1029,Bug,Blocker,build,TestCopyFiles fails on testHftpAccessControl(),Log : Testcase: testHftpAccessControl took 2.692 sec         FAILED expected:-3 but was:-999 junit.framework.AssertionFailedError: expected:-3 but was:-999         at org.apache.hadoop.tools.TestCopyFiles.testHftpAccessControl(TestCopyFiles. 853),Closed,Fixed,,Jothi Padmanabhan,Amar Kamat,Wed; 23 Sep 2009 11:17:41 +0000,Tue; 24 Aug 2010 21:18:14 +0000,Wed; 14 Oct 2009 08:24:56 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1029
MAPREDUCE-1030,Bug,Blocker,capacity-sched,Reduce tasks are getting starved in capacity scheduler,reduce tasks are getting starved in capacity scheduler.,Closed,Fixed,,rahul k singh,rahul k singh,Wed; 23 Sep 2009 11:28:59 +0000,Tue; 24 Aug 2010 21:18:16 +0000,Tue; 13 Oct 2009 13:45:17 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1030
MAPREDUCE-1031,Bug,Blocker,build,ant tar target doens't seem to compile tests in contrib projects,ant tar shouldn't be skipping contrib tests.,Closed,Fixed,,Aaron Kimball,Arun C Murthy,Wed; 23 Sep 2009 23:12:53 +0000,Tue; 24 Aug 2010 21:18:17 +0000,Mon; 12 Apr 2010 23:43:17 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1031
MAPREDUCE-1032,Bug,Major,capacity-sched,taskcontroller.cfg should be checked before task tracker comes up,Right now; task-controller.cfg should have two mandatory parameters mapreduce.cluster.local.dir and hadoop.log.dir; without which cluster comes up including Task tracker ; but when any jobs are submitted; it gives errors.   This will highly confuse the Ops and end-user.  Even though; when every job is submitted; task-controller.cfg is checked; it should be checked in the very beginning when Task tracker comes up.   Expected behaviour is : 1) TT should not come up. 2) TT logs should show why its not come up like which parameter is missing and if found; if the values mismatches with the mapred-site.xml,Open,Unresolved,,Unassigned,Iyappan Srinivasan,Thu; 24 Sep 2009 04:50:11 +0000,Thu; 24 Sep 2009 04:55:02 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1032
MAPREDUCE-1033,Sub-task,Blocker,,Resolve location of scripts and configuration files after project split,At present; all the sub-projects - common; hdfs and mapreduce - have copies of all the configuration files. Common configuration files should be left in common; mapreduce specific files should be moved to mapreduce project; same with hdfs related files.,Closed,Fixed,,Tom White,Vinod Kumar Vavilapalli,Thu; 24 Sep 2009 08:03:15 +0000,Tue; 24 Aug 2010 21:18:18 +0000,Thu; 10 Jun 2010 23:50:32 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1033
MAPREDUCE-1034,Bug,Major,documentation,Update forrest documentation about cluster restartability w.r.t mapreduce JobTracker,Cluster Restartability section needs to be updated after the changes done to job recovery as part of MAPREDUCE-873.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 24 Sep 2009 08:25:26 +0000,Fri; 2 Jul 2010 00:04:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1034
MAPREDUCE-1035,Sub-task,Blocker,documentation,Remove streaming forrest documentation from the common project,A quick look reveals that the streaming documentation in common already reveals that it differs from that in the mapreduce project. We should resolve these differences and retain this documentation only in mapreduce.,Closed,Duplicate,HADOOP-6507,Unassigned,Vinod Kumar Vavilapalli,Thu; 24 Sep 2009 08:48:11 +0000,Tue; 24 Aug 2010 21:18:19 +0000,Mon; 25 Jan 2010 06:16:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1035
MAPREDUCE-1036,Task,Major,,An API Specification for Sqoop,Over the last several months; Sqoop has evolved to a state that is functional and has room for extensions. Developing extensions requires a stable API and documentation. I am attaching to this ticket a description of Sqoop's design and internal APIs; which include some open questions. I would like to solicit input on the design regarding these open questions and standardize the API.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 24 Sep 2009 18:18:03 +0000,Thu; 2 May 2013 02:29:26 +0000,Tue; 3 Nov 2009 09:35:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1036
MAPREDUCE-1037,Bug,Blocker,build;test,Failing contrib unit tests should not halt the build,As in other contrib projects; ( HADOOP-5457 ); failing unit tests should not prevent tests of subsequent modules from running.,Resolved,Fixed,,Aaron Kimball,Chris Douglas,Thu; 24 Sep 2009 20:16:03 +0000,Fri; 2 Jul 2010 06:31:27 +0000,Thu; 5 Nov 2009 05:00:13 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1037
MAPREDUCE-1038,Bug,Major,build,Mumak's compile-aspects target weaves aspects even though there are no changes to the Mumak's sources,This is particularly time consuming and is the bottle neck even for a simple ant build. In the case where no files have been updated in Mumak; there is no reason to recompile sources along with the aspects. compile-aspects should skip this step in these cases.,Closed,Fixed,,Aaron Kimball,Vinod Kumar Vavilapalli,Fri; 25 Sep 2009 05:08:12 +0000,Tue; 24 Aug 2010 21:18:20 +0000,Tue; 3 Nov 2009 07:50:31 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1038
MAPREDUCE-1039,Sub-task,Blocker,documentation,cluster_setup.xml exists in both mapreduce and common projects,cluster_setup.xml exists in both mapreduce and common projects. And they already deviate because of HADOOP-6217 changes.,Closed,Duplicate,MAPREDUCE-1404,Unassigned,Vinod Kumar Vavilapalli,Fri; 25 Sep 2009 10:36:46 +0000,Tue; 24 Aug 2010 21:18:21 +0000,Mon; 25 Jan 2010 06:24:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1039
MAPREDUCE-1040,Bug,Major,,"acls are not set to ""*"" when acls is enabled and acls are not defined",Before the introduction of hierarchical queues; when the acls is enabled and no acls are defined for a queue; the parser sets it by default to *. But in currently; it doesn't do so. This issue is being handled as part of MAPREDUCE-28 since the test cases introduced in it are also testing this issue.,Open,Unresolved,,Unassigned,V.V.Chaitanya Krishna,Fri; 25 Sep 2009 10:38:13 +0000,Fri; 25 Sep 2009 10:41:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1040
MAPREDUCE-1041,Bug,Minor,,TaskStatuses map in TaskInProgress should be made package private instead of protected,MAPREDUCE-1028 made TaskStatuses protected. As Nigel pointed out in that Jira; making it package private would suffice.,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Fri; 25 Sep 2009 18:23:28 +0000,Tue; 24 Aug 2010 21:18:21 +0000,Mon; 19 Oct 2009 00:03:09 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1041
MAPREDUCE-1042,Improvement,Major,tools/rumen,rumen should be able to output compressed trace files,rumen is used primarily to create job trace files which are then processed by other tools.  These trace files can exceed 100 gigabytes.  However; gzip compression normally achieves 15:1 compression on these traces.  I would like to modify rumen so it can output compressed files directly; rather than outputting unwieldy uncompressed files and letting me compress it later.,Resolved,Won't Fix,,Dick King,Dick King,Fri; 25 Sep 2009 21:58:18 +0000,Thu; 24 Nov 2011 01:37:39 +0000,Thu; 24 Nov 2011 01:12:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1042
MAPREDUCE-1043,Bug,Minor,,JobHistory.parseHistoryFromFS does not appear to get us the information in conf files that correspond to jobs.,We get to see the NAMES of the files in the Listener callbacks; but that doesn't seem quite right because the user is left to parse the conf file hirself.  Perhaps there should be an additional interface that takes a Listener callback string that came with a JOBCONF Key; and delivers an abstraction instance that can be called with its own Listener that in turn will be called with each property value pair from the named conf file?  rumen can be changed to use JobHistory; but it will need to deal with this situation in an ad hoc way unless we make this change.,Open,Unresolved,,Unassigned,Dick King,Fri; 25 Sep 2009 23:29:15 +0000,Fri; 2 Jul 2010 07:16:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1043
MAPREDUCE-1044,Improvement,Major,,Ability to automatically move machines from one MR compute cluster to another,We have multiple map-reduce clusters that provide different service and support levels for their users. We have seen that utilization of hardware resources are not optimized if we have a static partition of existing hardware resources into these separate MR clusters. It would be nice to have a automatic way to move nodes from one MR cluster to another based on load characteristics and configured policies. This JIRA will discuss some of the ideas and possible implementations of those ideas.,Resolved,Won't Fix,,Dmytro Molkov,dhruba borthakur,Sun; 27 Sep 2009 21:45:28 +0000,Wed; 23 Jul 2014 21:21:00 +0000,Wed; 23 Jul 2014 21:21:00 +0000,,,,MAPREDUCE-892,,https://issues.apache.org/jira/browse/MAPREDUCE-1044
MAPREDUCE-1045,Improvement,Major,,Changes to deprecated interfaces break Hive,I can haz compatibility? The following things have broken the Hive Shims: -The removal of a copy constructor in org HIVE-845,Resolved,Duplicate,MAPREDUCE-1725,Unassigned,Cyrus Katrak,Mon; 28 Sep 2009 01:57:19 +0000,Thu; 29 Jul 2010 05:57:48 +0000,Thu; 29 Jul 2010 05:57:48 +0000,,0.20.2,,HIVE-845,,https://issues.apache.org/jira/browse/MAPREDUCE-1045
MAPREDUCE-1046,Improvement,Major,client;task,Remove mapred.{map|reduce}.child.ulimit and use mapred.job.{map|reduce}.memory.mb as the task's ulimit value,Currently mapred. {map|reduce}.child.ulimit is the ulimit value set for the child map reduce task. We also have mapred.job.{map|reduce} .memory.mb in the capacity-scheduler which specifies the 'slot-size' in terms of memory for the child task. I propose we deprecate mapred. {map|reduce}.child.ulimit and use the value of mapred.job.{map|reduce} .memory.mb - this will help reduce proliferation of config knobs.,Open,Unresolved,,Unassigned,Arun C Murthy,Mon; 28 Sep 2009 02:47:46 +0000,Mon; 28 Sep 2009 02:47:46 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1046
MAPREDUCE-1047,Bug,Major,pipes,hadoop.pipes.command.port missing from environment when using bash 4,"I recently upgraded to gnu bash 4.0 and found out that Hadoop Pipes applications break because they cannot read the ""hadoop.pipes.command.port"" environment variable.",Resolved,Duplicate,HADOOP-6388,Unassigned,Simone Leo,Mon; 28 Sep 2009 16:56:48 +0000,Tue; 24 Nov 2009 15:32:27 +0000,Tue; 24 Nov 2009 15:32:27 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1047
MAPREDUCE-1048,Improvement,Major,jobtracker,Show total slot usage in cluster summary on jobtracker webui,With High-Ram jobs coming into the picture; its important to also show the slot usage in cluster summary since total-running-maps  total-slots-occupied.,Closed,Fixed,,Amareshwari Sriramadasu,Amar Kamat,Wed; 30 Sep 2009 09:12:30 +0000,Tue; 24 Aug 2010 21:18:22 +0000,Sat; 24 Oct 2009 06:34:03 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1048
MAPREDUCE-1049,Bug,Major,client;jobtracker,Cause for failures due to errors in job-initialization are not communicated back to the client,The cause for failures due to errors in job-initialization are not communicated back to the client e.g. job which is terminated for crossing the mapred.jobtracker.maxtasks.per.job limit.,Open,Unresolved,,Unassigned,Arun C Murthy,Wed; 30 Sep 2009 18:59:56 +0000,Thu; 13 Jan 2011 02:27:58 +0000,,,0.20.1,,PIG-1377,MAPREDUCE-343,https://issues.apache.org/jira/browse/MAPREDUCE-1049
MAPREDUCE-1050,Test,Major,test,Introduce a mock object testing framework,Using mock objects in unit tests can improve code quality (see e.g. http: ). Hadoop would benefit from having a mock object framework for developers to write unit tests with. Doing so will allow a wider range of failure conditions to be tested and the tests will run faster.,Closed,Fixed,,Tom White,Tom White,Thu; 1 Oct 2009 16:30:48 +0000,Tue; 24 Aug 2010 21:18:23 +0000,Thu; 10 Dec 2009 04:39:41 +0000,,,,,HDFS-669,https://issues.apache.org/jira/browse/MAPREDUCE-1050
MAPREDUCE-1051,Bug,Minor,,mapred.local.dir gets a hardcoded Path in MiniMRCluster.,In the MiniMRCluster.JobTrackerRunner.run() method; there's a hardcoded filename and then Path name.  This should be fixed to get its value from a system property.,Open,Unresolved,,Unassigned,Dick King,Thu; 1 Oct 2009 20:54:10 +0000,Thu; 1 Oct 2009 21:03:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1051
MAPREDUCE-1052,Bug,Major,,In 0.20; JobHistory parsed files using callbacks [Listener].  In 0.21; JobHistoryParser creates a monolithic JobInfo object.,In my opinion; this was a change for the worse.  I would prefer to bring back the callback interface; at least in addition to the JobInfo interface; to give API users the option of not creating the whole object if they only want to glean part of the information.,Open,Unresolved,,Unassigned,Dick King,Sat; 3 Oct 2009 00:26:28 +0000,Fri; 2 Jul 2010 00:04:39 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1052
MAPREDUCE-1053,Bug,Minor,jobtracker,MRReliabilityTest does not kill/fail tasks if history is enabled,When history is enabled; MRReliabilityTest fails to fail kill tasks. Also the scenario of lost TTs is not being tested.,Resolved,Duplicate,MAPREDUCE-1062,Unassigned,Ramya Sunil,Sun; 4 Oct 2009 13:01:22 +0000,Tue; 6 Oct 2009 15:53:37 +0000,Tue; 6 Oct 2009 15:53:37 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1053
MAPREDUCE-1054,Bug,Major,,[Mumak] Enhance unit test coverage,Enhance unit test coverage for mumak.,Open,Unresolved,,Unassigned,Hong Tang,Sun; 4 Oct 2009 23:18:42 +0000,Mon; 4 Jun 2012 07:47:16 +0000,,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1054
MAPREDUCE-1055,Sub-task,Minor,,Improve SimulatorTaskTracker test cases to test tasks that require multiple slots,We should test situations where a task requires multiple slots.,Open,Unresolved,,Tamas Sarlos,Hong Tang,Sun; 4 Oct 2009 23:19:36 +0000,Wed; 7 Oct 2009 22:56:24 +0000,,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1055
MAPREDUCE-1056,Bug,Major,,[Mumak] Add forrest documentation for mumak,nan,Open,Unresolved,,Unassigned,Hong Tang,Sun; 4 Oct 2009 23:26:32 +0000,Tue; 10 Jul 2012 21:27:09 +0000,,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1056
MAPREDUCE-1057,Bug,Major,tasktracker,java tasks are not honouring the value of mapred.userlog.limit.kb,Constructor of JvmEnv missed initializing logSize; which will be used as tailLength when  command for the task is built.,Open,Unresolved,MAPREDUCE-1647,Ravi Gummadi,Ravi Gummadi,Mon; 5 Oct 2009 10:06:25 +0000,Wed; 31 Mar 2010 05:27:23 +0000,,,0.20.1;0.21.0;0.22.0,,MAPREDUCE-1025,,https://issues.apache.org/jira/browse/MAPREDUCE-1057
MAPREDUCE-1058,Improvement,Major,,analysehistory.jsp should report node where task ran,It is kind of painful to determine which nodes which tasks ran on.  It would be useful to list this in the web ui; especially for the best under performing.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Mon; 5 Oct 2009 22:44:06 +0000,Wed; 2 Nov 2011 17:49:15 +0000,Wed; 2 Nov 2011 17:49:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1058
MAPREDUCE-1059,Bug,Major,distcp,distcp can generate uneven map task assignments,distcp writes out a SequenceFile containing the source files to transfer; and their sizes. Map tasks are created over spans of this file; representing files which each mapper should transfer. In practice; some transfer loads yield many empty map tasks and a few tasks perform the bulk of the work.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Mon; 5 Oct 2009 23:46:24 +0000,Tue; 5 Jan 2010 15:58:40 +0000,Wed; 23 Dec 2009 10:17:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1059
MAPREDUCE-1060,Improvement,Major,,JT should kill running maps when all the reducers have completed,We have seen some situations where maps are still running when all the reducers have completed. This could happen because of lost TT's; interplay of speculative tasks with bad TT's etc. If the maps take a long time to run; it unnecessarily delays the job completion time; as this map output is not required anyways. The JT should possibly kill running maps when all the reducers have completed.,Resolved,Won't Fix,,Jonathan Eagles,Jothi Padmanabhan,Tue; 6 Oct 2009 04:36:29 +0000,Thu; 28 Jul 2011 22:46:58 +0000,Thu; 28 Jul 2011 22:10:52 +0000,,,,,MAPREDUCE-1924,https://issues.apache.org/jira/browse/MAPREDUCE-1060
MAPREDUCE-1061,Test,Major,,Gridmix unit test should validate input/output bytes,TestGridmixSubmission currently verifies only that the correct number of jobs have been run. The test should validate the I O parameters it claims to satisfy.,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 6 Oct 2009 05:18:35 +0000,Tue; 24 Aug 2010 21:18:24 +0000,Sun; 18 Oct 2009 10:00:51 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1061
MAPREDUCE-1062,Bug,Major,test,MRReliability test does not work with retired jobs,Currently the MRReliability uses job clients get all job api which also includes retired jobs.  In case we have retired jobs in cluster;  The retired jobs are appended at the end of the job list; this results in Test always getting completed job and not spawning off KillTask thread and KillTracker threads.,Closed,Fixed,,Sreekanth Ramakrishnan,Sreekanth Ramakrishnan,Tue; 6 Oct 2009 05:58:15 +0000,Tue; 24 Aug 2010 21:18:25 +0000,Sun; 18 Apr 2010 22:47:16 +0000,,0.21.0,,HADOOP-6269,,https://issues.apache.org/jira/browse/MAPREDUCE-1062
MAPREDUCE-1063,Task,Minor,benchmarks,Document Gridmix benchmark,The Gridmix benchmark should have forrest documentation and a README pointing to it.,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 6 Oct 2009 08:00:46 +0000,Tue; 24 Aug 2010 21:18:26 +0000,Thu; 8 Oct 2009 16:42:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1063
MAPREDUCE-1064,Test,Major,client,Add unit tests to test Job and Cluster ,Add more tests to test client side apis; like TestJob and TestCluster; referring to Arun's comment at https: MAPREDUCE-777?focusedCommentId=12756402page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12756402,Open,Unresolved,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 6 Oct 2009 09:26:38 +0000,Fri; 2 Jul 2010 00:04:56 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1064
MAPREDUCE-1065,Bug,Blocker,documentation,Modify the mapred tutorial documentation to use new mapreduce api.,nan,Closed,Fixed,,Aaron Kimball,Amareshwari Sriramadasu,Tue; 6 Oct 2009 09:35:22 +0000,Tue; 24 Aug 2010 21:18:27 +0000,Sun; 25 Apr 2010 02:33:16 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1065
MAPREDUCE-1066,Test,Major,test,Add a unit test  to test all the apis in mapreduce.lib.join ,Add a unit test  to test all the api features in mapreduce.lib.join,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Tue; 6 Oct 2009 09:48:16 +0000,Fri; 2 Jul 2010 00:05:01 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1066
MAPREDUCE-1067,Bug,Major,jobtracker,Default state of queues is undefined when unspecified,"Currently; if the state of a queue is not specified; it is being set to ""undefined"" state instead of running state.",Open,Unresolved,,V.V.Chaitanya Krishna,V.V.Chaitanya Krishna,Tue; 6 Oct 2009 09:51:29 +0000,Tue; 10 Jul 2012 21:27:09 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1067
MAPREDUCE-1068,Bug,Major,contrib/streaming,In hadoop-0.20.0 streaming job do not throw proper verbose error message if file is not present,"With hadoop-0.20.0 proper error message is not thrown ; when streaming job is submitted and if file is not present to be distributed with ""-file"" option. But with hadoop-0.18.* proper verbose message is thrown if file is not present and it is easy for the users to debug.   For example:  With hadoop-0.20.0: $ hadoop jar $HADOOP_HOME dummy doesn't exist."" found while processing  -file",Resolved,Fixed,,Amareshwari Sriramadasu,Peeyush Bishnoi,Tue; 6 Oct 2009 11:07:35 +0000,Mon; 21 Dec 2009 09:53:50 +0000,Thu; 12 Nov 2009 05:29:40 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1068
MAPREDUCE-1069,Sub-task,Major,,Implement Sqoop API refactoring,Implement refactoring decisions outlined in MAPREDUCE-1036,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 6 Oct 2009 22:27:56 +0000,Thu; 2 May 2013 02:29:24 +0000,Thu; 29 Oct 2009 17:21:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1069
MAPREDUCE-1070,Bug,Major,,Deadlock in FairSchedulerServlet,FairSchedulerServlet can cause a deadlock with the JobTracker,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 7 Oct 2009 07:40:35 +0000,Mon; 19 Oct 2009 17:38:59 +0000,Mon; 19 Oct 2009 00:19:54 +0000,,0.20.1;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1070
MAPREDUCE-1071,Bug,Major,,o.a.h.mapreduce.jobhistory.EventReader constructor should expect DataInputStream,o.a.h.mapreduce.jobhistory.EventReader constructor should expect DataInputStream; so that it can parse job histories that are aggregated or compressed in file containers such as TFile.,Closed,Fixed,,Hong Tang,Hong Tang,Wed; 7 Oct 2009 07:45:21 +0000,Tue; 24 Aug 2010 21:18:29 +0000,Wed; 14 Oct 2009 06:42:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1071
MAPREDUCE-1072,Bug,Major,,o.a.h.mapreduce.jobhistory.EventWriter.VERSION should be public.,"o.a.h.mapreduce.jobhistory.EventWriter.VERSION (""Avro-Binary"") should be public because it is a public contract.",Open,Unresolved,,Unassigned,Hong Tang,Wed; 7 Oct 2009 08:14:40 +0000,Wed; 7 Oct 2009 17:42:27 +0000,,,,,MAPREDUCE-1016,,https://issues.apache.org/jira/browse/MAPREDUCE-1072
MAPREDUCE-1073,Bug,Major,pipes,Progress reported for pipes tasks is incorrect.,Currently in pipes; org.apache.hadoop.mapred.pipes.PipesMapRunner.run(RecordReaderK1; V1; OutputCollectorK2; V2; Reporter) we do the following:    This would result in consumption of all the records for current task and taking task progress to 100% whereas the actual pipes application would be trailing behind.,Open,Unresolved,,Dick King,Sreekanth Ramakrishnan,Wed; 7 Oct 2009 08:27:52 +0000,Sun; 29 Jan 2012 03:14:42 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1073
MAPREDUCE-1074,New Feature,Major,documentation,Provide documentation for Mark/Reset functionality,HADOOP-5266 introduced support of Mark Reset of Values Iterator. Documentation needs to be updated for the same.,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Mon; 4 May 2009 05:43:28 +0000,Tue; 24 Aug 2010 21:18:29 +0000,Wed; 9 Dec 2009 09:14:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1074
MAPREDUCE-1075,Bug,Major,,getQueue(String queue) in JobTracker would return NPE for invalid queue name,nan,Closed,Fixed,,V.V.Chaitanya Krishna,V.V.Chaitanya Krishna,Wed; 7 Oct 2009 10:36:00 +0000,Tue; 24 Aug 2010 21:18:31 +0000,Tue; 8 Dec 2009 05:06:13 +0000,,,,MAPREDUCE-1110;MAPREDUCE-28,,https://issues.apache.org/jira/browse/MAPREDUCE-1075
MAPREDUCE-1076,Bug,Blocker,client,ClusterStatus class should be deprecated ,ClusterStatus class should be deprecated infavour of ClusterMetrics and TaskTrackerInfo. This was missed in MAPREDUCE-777,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 7 Oct 2009 10:51:52 +0000,Tue; 24 Aug 2010 21:18:31 +0000,Mon; 12 Oct 2009 05:58:57 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1076
MAPREDUCE-1077,Bug,Major,tools/rumen,When rumen reads a truncated job tracker log; it produces a job whose outcome is SUCCESS.  Should be null.,nan,Closed,Fixed,,Dick King,Dick King,Wed; 7 Oct 2009 22:29:14 +0000,Tue; 24 Aug 2010 21:18:33 +0000,Sun; 18 Oct 2009 19:39:05 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1077
MAPREDUCE-1078,Sub-task,Major,,Unit test for zero map jobs and killed jobs,Adding unit test for zero map jobs and killed jobs,In Progress,Unresolved,,Anirban Dasgupta,Anirban Dasgupta,Wed; 7 Oct 2009 22:56:28 +0000,Mon; 30 Nov 2009 19:50:59 +0000,,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1078
MAPREDUCE-1079,Sub-task,Major,documentation,Split commands_manual.xml into common; mapreduce and hdfs parts,nan,Resolved,Duplicate,HADOOP-10899,Unassigned,Vinod Kumar Vavilapalli,Thu; 8 Oct 2009 04:41:10 +0000,Tue; 29 Jul 2014 18:28:59 +0000,Tue; 29 Jul 2014 18:28:59 +0000,,,newbie,,HADOOP-6740,https://issues.apache.org/jira/browse/MAPREDUCE-1079
MAPREDUCE-1080,Bug,Major,capacity-sched,Properties max.map.slots and max.reduce.slots should be hyphenated.,The rest of the properties are hyphenated - for e.g.; maximum-capacity; supports-priority etc. Using dots goes against this.,Closed,Duplicate,MAPREDUCE-1105,Unassigned,Vinod Kumar Vavilapalli,Thu; 8 Oct 2009 06:07:40 +0000,Tue; 24 Aug 2010 21:18:34 +0000,Fri; 11 Dec 2009 09:22:58 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1080
MAPREDUCE-1081,Sub-task,Blocker,documentation,Move hadoop_archives.xml out of mapreduce project,nan,Closed,Invalid,,Unassigned,Vinod Kumar Vavilapalli,Thu; 8 Oct 2009 06:26:51 +0000,Tue; 24 Aug 2010 21:18:34 +0000,Thu; 8 Oct 2009 06:48:01 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1081
MAPREDUCE-1082,Bug,Blocker,client;jobtracker,Command line UI for queues' information is broken with hierarchical queues.,"When the command "".  queue -info any-container-queue""",Closed,Duplicate,MAPREDUCE-1110,V.V.Chaitanya Krishna,Vinod Kumar Vavilapalli,Thu; 8 Oct 2009 07:55:58 +0000,Tue; 24 Aug 2010 21:18:35 +0000,Tue; 8 Dec 2009 05:44:40 +0000,,0.21.0,,MAPREDUCE-1110;MAPREDUCE-1007,,https://issues.apache.org/jira/browse/MAPREDUCE-1082
MAPREDUCE-1083,Improvement,Major,jobtracker, Use the user-to-groups mapping service in the JobTracker,HADOOP-4656 introduces a user-to-groups mapping service on the server-side. The JobTracker should use this to map users to their groups rather than relying on the information passed by the client.,Closed,Fixed,,Boris Shkolnik,Arun C Murthy,Thu; 8 Oct 2009 07:59:13 +0000,Tue; 24 Aug 2010 21:18:36 +0000,Sat; 19 Dec 2009 00:53:57 +0000,,,,HADOOP-4656,,https://issues.apache.org/jira/browse/MAPREDUCE-1083
MAPREDUCE-1084,Improvement,Major,build;test,Implementing aspects development and fault injeciton framework for MapReduce,Similar to HDFS-435 and HADOOP-6204 this JIRA will track the introduction of injection framework for MapReduce. After HADOOP-6204 is in place this particular modification should be very trivial and would take importing (via svn:external) of src build and some tweaking of the build.xml file,Closed,Fixed,,Sreekanth Ramakrishnan,Konstantin Boudnik,Thu; 8 Oct 2009 19:51:02 +0000,Tue; 24 Aug 2010 21:18:37 +0000,Mon; 14 Dec 2009 22:29:47 +0000,,,,HADOOP-6204,,https://issues.apache.org/jira/browse/MAPREDUCE-1084
MAPREDUCE-1085,Bug,Minor,tasktracker,"For tasks; ""ulimit -v -1"" is being run when user doesn't specify mapred.child.ulimit","For tasks; ""ulimit -v -1"" is being run when user doesn't specify mapred.child.ulimit.  Taking -1 as default value and using it in building the command is not right.",Resolved,Fixed,,Todd Lipcon,Ravi Gummadi,Fri; 9 Oct 2009 06:21:27 +0000,Thu; 7 Apr 2011 15:40:49 +0000,Thu; 20 Jan 2011 00:04:18 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1085
MAPREDUCE-1086,Bug,Major,tasktracker,hadoop commands in streaming tasks are trying to write to tasktracker's log,As HADOOP_ROOT_LOGGER is not set in the environment by TT for the children; the children of task jvm(in case of streaming) are trying to write to TT's log and getting the following Exception. Jobs are succeeded; but the issue is to be resolved by setting the environment variables by TT for use by children of task jvm in case of streaming job.  When streaming calls hadoop commands; it's trying to write to TaskTracker log file.  log4j:ERROR setFile(null;true) call failed.  1880) log4j:ERROR Either File or DatePattern options are not set for appender DRFA.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 9 Oct 2009 08:19:21 +0000,Tue; 24 Aug 2010 21:18:38 +0000,Tue; 20 Oct 2009 07:24:29 +0000,,0.20.1;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1086
MAPREDUCE-1087,Bug,Major,tasktracker,Limit resource usage of Map/Reduce debug script,As mentioned here by Devaraj here; Map Reduce debug scripts will run user code and hence need to be resource-limited via ulimits and memory-monitored similar to task-memory-monitoring.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 9 Oct 2009 08:33:52 +0000,Tue; 29 Jul 2014 18:16:06 +0000,Tue; 29 Jul 2014 18:16:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1087
MAPREDUCE-1088,Bug,Major,jobtracker,JobHistory files should have narrower 0600 perms ,Currently the perms on JobHistory files are 0740; I propose we make it 0600.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Fri; 9 Oct 2009 17:10:16 +0000,Fri; 19 Feb 2010 07:42:28 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1088
MAPREDUCE-1089,Bug,Major,contrib/fair-share,Fair Scheduler preemption triggers NPE when tasks are scheduled but not running,We see exceptions like this when preemption runs when a task has been scheduled on a TT but has not yet started running.  2009-10-09 14:30:53;989 INFO org.apache.hadoop.mapred.FairScheduler: Should preempt 2 MAP tasks for job_200910091420_0006: tasksDueToMinShare = 2; tasksDueToFairShare = 0 2009-10-09 14:30:54;036 ERROR org.apache.hadoop.mapred.FairScheduler: Exception in fair scheduler UpdateThread  286),Closed,Fixed,,Todd Lipcon,Todd Lipcon,Sat; 10 Oct 2009 00:55:40 +0000,Tue; 24 Aug 2010 21:18:39 +0000,Thu; 29 Oct 2009 01:32:38 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1089
MAPREDUCE-1090,Bug,Major,tasktracker,Modify log statement in Tasktracker log related to memory monitoring to include attempt id.,Currently the TaskMemoryManagerThread logs a line like: org.apache.hadoop.mapred.TaskMemoryManagerThread: Memory usage of ProcessTree 14321 :372686848bytes. Limit : 2147483648bytes.  It would be very useful to include the Task attempt id for the process tree mentioned in the log statement.,Closed,Fixed,,Hemanth Yamijala,Hemanth Yamijala,Mon; 12 Oct 2009 16:23:06 +0000,Tue; 24 Aug 2010 21:18:40 +0000,Sun; 25 Oct 2009 10:52:19 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1090
MAPREDUCE-1091,Bug,Major,tasktracker,TaskTrackers only work with same build as the JobTracker,Currently tasktrackers check to ensure that they are the same build as the JobTracker and bail-out if not. This is too restrictive - in the past we've had similar complaints: HADOOP-5203.,Closed,Won't Fix,,Unassigned,Arun C Murthy,Mon; 12 Oct 2009 18:47:53 +0000,Tue; 24 Aug 2010 21:18:42 +0000,Tue; 13 Oct 2009 15:41:02 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1091
MAPREDUCE-1092,Test,Major,test,Enable asserts for tests by default,See HADOOP-6309. Let's make the tests run with  asserts by default.,Closed,Fixed,,Eli Collins,Eli Collins,Mon; 12 Oct 2009 21:24:36 +0000,Mon; 12 Dec 2011 06:19:40 +0000,Wed; 5 May 2010 21:36:32 +0000,,,,MAPREDUCE-1093,HADOOP-6309;MAPREDUCE-1506,https://issues.apache.org/jira/browse/MAPREDUCE-1092
MAPREDUCE-1093,Test,Major,,Java assertion failures triggered by tests,While running the tests with  asserts enabled the following two asserts fired:,Resolved,Invalid,,Aaron Kimball,Eli Collins,Mon; 12 Oct 2009 23:19:54 +0000,Thu; 18 Feb 2010 23:18:56 +0000,Thu; 18 Feb 2010 23:18:56 +0000,,,,MAPREDUCE-1092,MAPREDUCE-1506,https://issues.apache.org/jira/browse/MAPREDUCE-1093
MAPREDUCE-1094,Bug,Major,capacity-sched,CapacityScheduler's JobInitPoller shouldn't 'sleep',It is really bad for JobInitPoller to be sleeping for 5seconds before initializing jobs!,Open,Unresolved,,Unassigned,Arun C Murthy,Tue; 13 Oct 2009 00:48:42 +0000,Thu; 13 Jan 2011 02:28:56 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1094
MAPREDUCE-1095,Improvement,Minor,,Hadoop 0.20 Compatible IdentityMapper and IdentityReducer,Certainly useful; and missing from Hadoop 2 API.,Resolved,Invalid,,Unassigned,Cyrus Katrak,Tue; 13 Oct 2009 02:23:09 +0000,Tue; 13 Oct 2009 05:34:20 +0000,Tue; 13 Oct 2009 05:34:20 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1095
MAPREDUCE-1096,Improvement,Trivial,,Add getNames method to VerticaRecord to retrieve input column names,Minor API addition to VerticaRecord. Function getNames() returns names for columns associated with input or output.,Resolved,Not A Problem,,Omer Trajman,Omer Trajman,Tue; 13 Oct 2009 02:59:33 +0000,Mon; 16 Mar 2015 20:02:00 +0000,Mon; 16 Mar 2015 20:01:59 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1096
MAPREDUCE-1097,Improvement,Minor,contrib/vertica,Changes/fixes to support Vertica 3.5,Vertica 3.5 includes three changes that the formatters should handle:  1) deploy_design function that handles much of the logic in the optimize method.  This improvement uses deploy_design if the server version supports it instead of orchestrating in the formatter function. 2) truncate table instead of recreating the table 3) numeric; decimal; money; number types (all the same path),Closed,Fixed,,Omer Trajman,Omer Trajman,Tue; 13 Oct 2009 03:07:08 +0000,Tue; 24 Aug 2010 21:18:42 +0000,Mon; 25 Jan 2010 05:02:35 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1097
MAPREDUCE-1098,Bug,Major,tasktracker,Incorrect synchronization in DistributedCache causes TaskTrackers to freeze up during localization of Cache for tasks.,Currently org.apache.hadoop.filecache.DistributedCache.getLocalCache(URI; Configuration; Path; FileStatus; boolean; long; Path; boolean) allows only one TaskRunner thread in TT to localize DistributedCache across jobs. Current way of synchronization is across baseDir this has to be changed to lock on the same baseDir.,Closed,Fixed,,Amareshwari Sriramadasu,Sreekanth Ramakrishnan,Thu; 10 Sep 2009 09:13:15 +0000,Tue; 24 Aug 2010 21:18:43 +0000,Sat; 24 Oct 2009 23:37:51 +0000,,,,,MAPREDUCE-1186,https://issues.apache.org/jira/browse/MAPREDUCE-1098
MAPREDUCE-1099,Bug,Major,jobtracker,Setup and cleanup tasks could affect job latency if they are caught running on bad nodes,We found cases on our clusters where a setup task got scheduled on a bad node and took upwards of several minutes to run; adversely affecting job runtimes. Speculation did not help here as speculation is not used for setup tasks. I suspect the same could happen for cleanup tasks as well.,Open,Unresolved,,Unassigned,Hemanth Yamijala,Tue; 13 Oct 2009 06:13:38 +0000,Mon; 14 Dec 2009 20:01:29 +0000,,,0.20.1,,,MAPREDUCE-463,https://issues.apache.org/jira/browse/MAPREDUCE-1099
MAPREDUCE-1100,Bug,Major,tasktracker,User's task-logs filling up local disks on the TaskTrackers,Some user's jobs are filling up TT disks by outrageous logging. mapreduce.task.userlog.limit.kb is not enabled on the cluster. Disks are getting filled up before task-log cleanup via mapred.task.userlog.retain.hours can kick in.,Resolved,Won't Fix,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 13 Oct 2009 08:13:17 +0000,Tue; 29 Jul 2014 18:40:21 +0000,Tue; 29 Jul 2014 18:40:21 +0000,,0.20.1;0.20.2;0.21.0,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-1100
MAPREDUCE-1101,Sub-task,Major,build,Rename core jar to common jar,The project name is common while the jar's name refers to core; odd.,Resolved,Duplicate,HADOOP-6404,Unassigned,Vinod Kumar Vavilapalli,Tue; 13 Oct 2009 09:39:09 +0000,Thu; 3 Dec 2009 04:44:04 +0000,Thu; 3 Dec 2009 04:43:33 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1101
MAPREDUCE-1102,Bug,Major,jobtracker,Job gets killed even when the cleanup completes,When the cleanup completes at the tasktracker and the job is killed by the user; the cleanup runs to completion but the job fails. Ideally if the cleanup is completed then the job should not be killed.,Open,Unresolved,,Amar Kamat,Amar Kamat,Tue; 13 Oct 2009 16:38:28 +0000,Thu; 13 Jan 2011 02:29:22 +0000,,,0.20.1,,,MAPREDUCE-947,https://issues.apache.org/jira/browse/MAPREDUCE-1102
MAPREDUCE-1103,Improvement,Major,jobtracker,Additional JobTracker metrics,It would be useful for tracking the following additional JobTracker metrics: running {map|reduce}tasks busy{map|reduce} slots reserved {map|reduce} slots,Closed,Fixed,,Sharad Agarwal,Arun C Murthy,Tue; 13 Oct 2009 20:23:19 +0000,Tue; 24 Aug 2010 21:18:46 +0000,Fri; 23 Oct 2009 09:56:06 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1103
MAPREDUCE-1104,Bug,Major,contrib/mumak,RecoveryManager not initialized in SimulatorJobTracker led to NPE in JT Jetty server,RecoveryManager initialization is not copied to the JobTracker constructor Mumak depends on. This leads to NPE in JT Jetty server.,Closed,Fixed,,Hong Tang,Hong Tang,Tue; 13 Oct 2009 21:46:44 +0000,Tue; 24 Aug 2010 21:18:47 +0000,Sun; 18 Oct 2009 09:41:10 +0000,,0.21.0;0.22.0,,MAPREDUCE-1111,,https://issues.apache.org/jira/browse/MAPREDUCE-1104
MAPREDUCE-1105,Bug,Blocker,capacity-sched,CapacityScheduler: It should be possible to set queue hard-limit beyond it's actual capacity,Currently the CS caps a queue's capacity to it's actual capacity if a hard-limit is specified to be greater than it's actual capacity. We should allow the queue to go upto the hard-limit if specified.  Also; I propose we change the hard-limit unit to be percentage rather than #slots.,Closed,Fixed,,rahul k singh,Arun C Murthy,Wed; 14 Oct 2009 00:03:18 +0000,Tue; 24 Aug 2010 21:18:47 +0000,Wed; 21 Oct 2009 16:31:15 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1105
MAPREDUCE-1106,Improvement,Major,,LocalJobRunner should run with any file-system,LocalJobRunner is hard-coded to run with only the local file-system. This will help users write map data files etc. from any file system.,Resolved,Not A Problem,,Rohan A Mehta,Vinod Kumar Vavilapalli,Wed; 14 Oct 2009 03:42:44 +0000,Wed; 18 May 2011 17:42:47 +0000,Tue; 17 May 2011 19:11:57 +0000,,0.21.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-1106
MAPREDUCE-1107,Improvement,Minor,contrib/fair-share,Creating a new fairscheduler,Hi;  I have created a slight modification of existing fairscheduler by adding a job level scheduling to it. The classes are all inherited from the existing classes. I have compiled them all and created a jar file for the same. I wanted this jar to run for fairscheduler instead of the existing fairscheduler.jar. I have placed it in the HADOOP_HOME lib. Still it doesn't run instead of the present one. What might be the problem? Is there some way to keep it run?  Anjali M,Resolved,Invalid,,Unassigned,Anjali M,Wed; 14 Oct 2009 06:18:14 +0000,Tue; 10 Nov 2009 07:32:08 +0000,Tue; 10 Nov 2009 07:32:08 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1107
MAPREDUCE-1108,Bug,Major,build,Modify test-patch.sh to verify that the number of findBugs warning is always zero,HADOOP-5661 and MAPREDUCE-769 involve going through pains to make sure findBugs warnings become zero. All that effort would be a waste if patches keep ignoring these warnings.   We should modify the Hudson test-patch.sh script to always verify that the findBugs warnings are zero in number. It should scream when the warnings go above zero level and make sure trunk is always at zero findBugs warnings.  And to help contributors about what to do when an un-ignorable warning is spelt out by test-patch.sh; we should modify the output of test-patch.sh to point to src findbugsExcludeFile.xml for suppressing any warnings.,Resolved,Implemented,,Unassigned,Vinod Kumar Vavilapalli,Wed; 14 Oct 2009 06:44:29 +0000,Sat; 25 Apr 2015 23:48:21 +0000,Sat; 25 Apr 2015 23:48:21 +0000,,,,,HADOOP-6430,https://issues.apache.org/jira/browse/MAPREDUCE-1108
MAPREDUCE-1109,Bug,Major,jobtracker,ConcurrentModificationException in jobtracker.jsp,The jobtracker.jsp invoked methods tracker.runningJobs(); tracker.completedJobs() and tracker.failedJobs() but these methods are not synchronized and can cause ConcurrentModificationException if the JT is concurrently changing the contents of these datastructures.,Closed,Not A Problem,,Harsh J,dhruba borthakur,Wed; 14 Oct 2009 06:56:05 +0000,Wed; 17 Oct 2012 22:30:18 +0000,Mon; 9 Jul 2012 02:29:04 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1109
MAPREDUCE-1110,Improvement,Major,jobtracker,Currently QueueManager API's return JobQueueInfo ; instead it should return QueueInfo; similarly wher ever  we are using JobQueueInfo as view ; we should use QueueInfo,nan,Open,Unresolved,,Vinod Kumar Vavilapalli,rahul k singh,Wed; 14 Oct 2009 09:21:23 +0000,Tue; 10 Jul 2012 21:27:10 +0000,,,0.21.0,,MAPREDUCE-1082;MAPREDUCE-1075,,https://issues.apache.org/jira/browse/MAPREDUCE-1110
MAPREDUCE-1111,Bug,Major,contrib/mumak,JT Jetty UI not working if we run mumak.sh off packaged distribution directory.,JT Jetty UI not working if we run mumak.sh off packaged distribution directory. However; if we directly run mumak.sh from the source directory it is ok.,Closed,Fixed,,Hong Tang,Hong Tang,Wed; 14 Oct 2009 20:05:35 +0000,Tue; 24 Aug 2010 21:18:49 +0000,Mon; 19 Oct 2009 19:16:06 +0000,,0.21.0;0.22.0,,MAPREDUCE-1104,,https://issues.apache.org/jira/browse/MAPREDUCE-1111
MAPREDUCE-1112,Bug,Major,,Fix CombineFileInputFormat for hadoop 0.20,HADOOP-5759 is already fixed as a part of MAPREDUCE-364  in hadoop 0.21. This will fix the same problem with CombineFileInputFormat for hadoop 0.20.,Resolved,Duplicate,HADOOP-5759,Zheng Shao,Zheng Shao,Thu; 15 Oct 2009 03:33:09 +0000,Mon; 19 Oct 2009 00:49:06 +0000,Mon; 19 Oct 2009 00:49:06 +0000,,0.20.1,,,MAPREDUCE-364;HADOOP-5759,https://issues.apache.org/jira/browse/MAPREDUCE-1112
MAPREDUCE-1113,Bug,Minor,build;contrib/mumak,mumak compiles aspects even if skip.contrib is true,The compile-aspects task in mumak's build.xml runs regardless of the skip.contrib property. Momentarily uploading a patch to fix this.,Resolved,Won't Fix,,Todd Lipcon,Todd Lipcon,Thu; 15 Oct 2009 04:49:49 +0000,Tue; 29 Jul 2014 18:42:13 +0000,Tue; 29 Jul 2014 18:42:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1113
MAPREDUCE-1114,Improvement,Minor,build,Speed up ivy resolution in builds with clever caching,"An awful lot of time is spent in the ivy:resolve parts of the build; even when all of the dependencies have been fetched and cached. Profiling showed this was in XML parsing. I have a sort-of-ugly hack which speeds up incremental compiles (and more importantly ""ant test"") significantly using some ant macros to cache the resolved classpaths.",Resolved,Won't Fix,,Todd Lipcon,Todd Lipcon,Thu; 15 Oct 2009 05:19:41 +0000,Tue; 29 Jul 2014 18:43:07 +0000,Tue; 29 Jul 2014 18:43:07 +0000,,0.22.0,,,HADOOP-6366,https://issues.apache.org/jira/browse/MAPREDUCE-1114
MAPREDUCE-1115,Improvement,Minor,tasktracker,Support hierarchical pools of directories to use for intermediate MapReduce data files (for SSD drives),Some initial benchmarking shows that SSDs can help a lot for local data files (for shuffle and other intermediate files).   Currently mapred.local.dir just round-robins over the provided directories; it would be nice to allocate a set of SSD directories to round-robin across first; then spill over to normal drives if the SSD directories are full.   amr,Resolved,Won't Fix,,Unassigned,Amr Awadallah,Thu; 15 Oct 2009 05:36:43 +0000,Tue; 29 Jul 2014 18:43:57 +0000,Tue; 29 Jul 2014 18:43:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1115
MAPREDUCE-1116,Bug,Major,tasktracker,Task continues to get localized even though it is marked for killing already,Even after the task is marked for killing; because TT doesn't explicitly check for the task state at various stages like downloading job jar; job conf and distributed cache files; it continues to localize the task. This is waste of resources and time and in some cases affects other tasks. Particularly it continues to download distributed cache files and aggravates issues like MAPREDUCE-1098.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 15 Oct 2009 09:42:40 +0000,Thu; 15 Oct 2009 09:59:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1116
MAPREDUCE-1117,Bug,Major,,ClusterMetrics return metrics for tasks instead of slots',In trunk the issue was fixed as part MAPREDUCE-1048. The fix needs to be ported to 0.21,Closed,Fixed,,Amareshwari Sriramadasu,Sharad Agarwal,Thu; 15 Oct 2009 12:06:09 +0000,Tue; 24 Aug 2010 21:18:49 +0000,Fri; 16 Oct 2009 07:48:58 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1117
MAPREDUCE-1118,Bug,Major,capacity-sched,Capacity Scheduler scheduling information is hard to read / should be tabular format,The scheduling information provided by the capacity scheduler is extremely hard to read on the job tracker web page.  Instead of just flat text; it should be presenting the information in a tabular format; similar to what the fair share scheduler provides.  This makes it much easier to compare what different queues are doing.,Closed,Fixed,,Krishna Ramachandran,Allen Wittenauer,Thu; 15 Oct 2009 19:18:36 +0000,Mon; 12 Dec 2011 06:18:23 +0000,Sun; 6 Nov 2011 02:35:40 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1118
MAPREDUCE-1119,Bug,Major,tasktracker,When tasks fail to report status; show tasks's stack dump before killing,When the TT kills tasks that haven't reported status; it should somehow gather a stack dump for the task. This could be done either by sending a SIGQUIT (so the dump ends up in stdout) or perhaps something like JDI to gather the stack directly from Java. This may be somewhat tricky since the child may be running as another user (so the SIGQUIT would have to go through LinuxTaskController). This feature would make debugging these kinds of failures much easier; especially if we could somehow get it into the TaskDiagnostic message,Closed,Fixed,MAPREDUCE-4121,Aaron Kimball,Todd Lipcon,Fri; 16 Oct 2009 22:53:49 +0000,Sat; 2 Mar 2013 18:10:52 +0000,Fri; 4 Dec 2009 05:08:41 +0000,,0.22.0,,,MAPREDUCE-5044,https://issues.apache.org/jira/browse/MAPREDUCE-1119
MAPREDUCE-1120,Bug,Minor,client,JobClient poll intervals should be job configurations; not cluster configurations,Job.waitForCompletion gets the poll interval from the Cluster object's configuration rather than its own Job configuration. This is counter-intuitive - Chris and I both made this same mistake working on MAPREDUCE-64; and Aaron agrees as well.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Mon; 19 Oct 2009 17:58:09 +0000,Fri; 2 Jul 2010 00:04:37 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1120
MAPREDUCE-1121,Task,Blocker,documentation,Hadoop MapReduce - Site Logo,Hadoop MapReduce - Site Logo   Update the logo (see attached jpg). Image has elephant + MapReduce.  With this update; Site logo and Documentation logo will be the same.,Closed,Fixed,,Corinne Chandel,Corinne Chandel,Mon; 19 Oct 2009 19:53:46 +0000,Tue; 24 Aug 2010 21:18:52 +0000,Tue; 3 Nov 2009 00:33:06 +0000,,0.21.0,,,HDFS-715,https://issues.apache.org/jira/browse/MAPREDUCE-1121
MAPREDUCE-1122,Bug,Major,contrib/streaming,streaming with custom input format does not support the new API,When trying to implement a custom input format for use with streaming; I have found that streaming does not support the new API; org.apache.hadoop.mapreduce.InputFormat; but requires the old API; org.apache.hadoop.mapred.InputFormat.,Open,Unresolved,,Amareshwari Sriramadasu,Keith Jackson,Mon; 19 Oct 2009 20:35:31 +0000,Sun; 8 Dec 2013 09:12:50 +0000,,,0.20.1,,MAPREDUCE-1905,MAPREDUCE-3619,https://issues.apache.org/jira/browse/MAPREDUCE-1122
HADOOP-6322,Improvement,Minor,,addResource(Configuration other) would be useful method to add to Configuration,Currently there are many overloaded addResource() methods in Configuration which take URL; String; InputStream etc. It would be useful to have a version which takes another Configuration object so that we get the same behavior of addResource using a Configuration object as the argument.,Open,Unresolved,,Unassigned,Pradeep Kamath,Tue; 20 Oct 2009 01:30:52 +0000,Tue; 20 Oct 2009 03:37:41 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/HADOOP-6322
MAPREDUCE-1124,Bug,Major,contrib/gridmix,TestGridmixSubmission fails sometimes,"TestGridmixSubmission fails sometimes with following error : Mismatched output bytes 4547848 4561267 	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.check(TestGridmixSubmission. 297)",Closed,Fixed,,Chris Douglas,Amareshwari Sriramadasu,Tue; 20 Oct 2009 05:35:58 +0000,Tue; 24 Aug 2010 21:18:53 +0000,Fri; 11 Dec 2009 19:33:33 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1124
MAPREDUCE-1125,Bug,Major,pipes,SerialUtils.cc: deserializeFloat is out of sync with SerialUtils.hh,nan,Resolved,Fixed,,Simone Leo,Simone Leo,Tue; 20 Oct 2009 15:03:22 +0000,Thu; 12 May 2016 18:22:49 +0000,Fri; 6 Nov 2015 00:57:49 +0000,,0.21.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-1125
MAPREDUCE-1126,Improvement,Major,task,shuffle should use serialization to get comparator,Currently the key comparator is defined as a Java class.  Instead we should use the Serialization API to create key comparators.  This would permit; e.g.; Avro-based comparators to be used; permitting efficient sorting of complex data types without having to write a RawComparator in Java.,Resolved,Won't Fix,,Aaron Kimball,Doug Cutting,Tue; 20 Oct 2009 17:14:47 +0000,Tue; 29 Jul 2014 18:56:34 +0000,Tue; 29 Jul 2014 18:56:34 +0000,,,,MAPREDUCE-815;HADOOP-6323,MAPREDUCE-1462;MAPREDUCE-1452;MAPREDUCE-1183;MAPREDUCE-1360,https://issues.apache.org/jira/browse/MAPREDUCE-1126
MAPREDUCE-1127,Improvement,Major,distcp,distcp should timeout later during S3-based transfers,Per MAPREDUCE-972; rename and other operations on distcp can take longer than the typical mapreduce task timeout. As an interim fix; this timeout should be increased when the distcp destination is S3.,Resolved,Won't Fix,,Aaron Kimball,Aaron Kimball,Tue; 20 Oct 2009 17:58:37 +0000,Tue; 29 Jul 2014 18:57:13 +0000,Tue; 29 Jul 2014 18:57:13 +0000,,,,,MAPREDUCE-972,https://issues.apache.org/jira/browse/MAPREDUCE-1127
MAPREDUCE-1128,Bug,Minor,contrib/mrunit,MRUnit Allows Iteration Twice,MRUnit allows one to iterate over a collection of values twice (ie.  reduce(Key key; IterableValue values; Context context){    for(Value : values )  ; }  Hadoop will allow this as well; however the second iterator will be empty. MRUnit should either match hadoop's behavior or warn the user that their code is likely flawed.,Closed,Fixed,,Aaron Kimball,Ed Kohlwey,Wed; 21 Oct 2009 12:54:13 +0000,Tue; 24 Aug 2010 21:18:53 +0000,Thu; 5 Nov 2009 06:01:48 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1128
MAPREDUCE-1129,Improvement,Major,contrib/fair-share,Assign multiple Map and Reduce tasks in Fairscheduler,In Hadoop-0.20; the period of heartbeat becomes much longer.  Fairscheduler assigns at most one Map and one Reduce task per heartbeat. This makes the cluster become very inefficient. Often time only half of the slots are used.  One idea is that we make Fairscheduler detect this situation (cluster under used) and scheduler more tasks in a heartbeat. Thoughts?,Resolved,Duplicate,MAPREDUCE-706,Unassigned,Scott Chen,Wed; 21 Oct 2009 22:19:06 +0000,Tue; 10 Nov 2009 08:08:10 +0000,Tue; 10 Nov 2009 07:29:40 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1129
MAPREDUCE-1130,New Feature,Major,,Provide a way to open and read a side file using an existing InputFormat,In the Pig subproject there is a need to open a side file for implementing map side joins. In some cases; the entire file needs to be read as a side file and in some cases; there is a need to read a file beginning from a particular split to the last split. In order to use existing InputFormats to achieve this; the pig code would need to mimic hadoop in terms of calling InputFormat.getSplits and then for each split call  InputFormat.createRecordReader; RecordReader.initialize() and then call RecordReader.nextKey() repeatedly till we reach end of split - and then continue to the next split. It would be good if there are some utility methods in Hadoop to achieve this - to read the file partially to the end or entirely to the end.,Open,Unresolved,,Unassigned,Pradeep Kamath,Wed; 21 Oct 2009 22:22:37 +0000,Wed; 21 Oct 2009 22:22:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1130
MAPREDUCE-1131,Bug,Major,client,Using profilers other than hprof can cause JobClient to report job failure,If task profiling is enabled; the JobClient will download the profile.out file created by the tasks under profile. If this causes an IOException; the job is reported as a failure to the client; even though all the tasks themselves may complete successfully. The expected result files are assumed to be generated by hprof. Using the profiling system with other profilers will cause job failure.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Wed; 21 Oct 2009 22:46:32 +0000,Tue; 24 Aug 2010 21:18:54 +0000,Fri; 1 Jan 2010 01:15:46 +0000,,,,,MAPREDUCE-105,https://issues.apache.org/jira/browse/MAPREDUCE-1131
MAPREDUCE-1132,Test,Major,,TestGridmixSubmission failing intermittently,Out of 3 runs on my desktop on trunk; test failed once with failure: Mismatched input bytes 1159031 ,Resolved,Duplicate,MAPREDUCE-1124,Unassigned,Sharad Agarwal,Thu; 22 Oct 2009 11:17:01 +0000,Thu; 22 Oct 2009 12:57:31 +0000,Thu; 22 Oct 2009 12:57:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1132
MAPREDUCE-1133,Bug,Major,,Eclipse .classpath template has outdated jar files and is missing some new ones.,Eclipse environment is broken in trunk: it still uses .21.jar files and includes some libraries which aren't in use any more (similar to HDFS-726).,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Thu; 22 Oct 2009 20:10:39 +0000,Tue; 24 Aug 2010 21:18:55 +0000,Thu; 22 Oct 2009 23:01:38 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1133
MAPREDUCE-1134,Improvement,Major,,The API around HistoryEvent has inelegances,For example; ReduceAttemptFinishedEvent has a getAttemptId() method; but TaskAttemptStartedEvent has a getTaskAttemptId() method.  TaskFailedEvent has a getFailedAttemptID note that ID in this context is spelled with an uppercase D; while all the other Id&#39;s are spelled with a lowercase d  .  Should we make a pass over these things and clean these up before too many people code to this API?  -dk,Resolved,Won't Fix,,Unassigned,Dick King,Thu; 22 Oct 2009 20:39:37 +0000,Tue; 29 Jul 2014 19:02:14 +0000,Tue; 29 Jul 2014 19:02:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1134
MAPREDUCE-1135,Improvement,Major,jobtracker,Making JobHistory log format easily extensible in the future,This jira is branched from MAPREDUCE-1016.  It would be nice to make the JobHistory log format easily extensible in the future.,Resolved,Won't Fix,,Unassigned,Hong Tang,Thu; 22 Oct 2009 20:57:38 +0000,Tue; 29 Jul 2014 19:02:34 +0000,Tue; 29 Jul 2014 19:02:34 +0000,,0.22.0,,MAPREDUCE-1016,,https://issues.apache.org/jira/browse/MAPREDUCE-1135
MAPREDUCE-1136,Bug,Major,tasktracker,ConcurrentModificationException when tasktracker updates task status to jobtracker,In Hadoop 0.18.3; the following exception happened during a job execution. It does not happen often.  Here is the stack trace of the exception. org.apache.hadoop.ipc.RemoteException:  716),Resolved,Fixed,,Unassigned,Qi Liu,Thu; 22 Oct 2009 23:29:33 +0000,Tue; 29 Jul 2014 19:02:59 +0000,Tue; 29 Jul 2014 19:02:59 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1136
MAPREDUCE-1137,Bug,Major,contrib/mumak,Mumak should have a unit test to ensure jetty UI is running properly,Mumak should have a unit test that ensures jetty UI is running properly. This will help detecting issues like MAPREDUCE-1104 sooner.,Resolved,Won't Fix,,Unassigned,Hong Tang,Fri; 23 Oct 2009 01:13:28 +0000,Tue; 29 Jul 2014 19:03:16 +0000,Tue; 29 Jul 2014 19:03:16 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1137
MAPREDUCE-1138,Bug,Major,contrib/streaming,Erroneous output folder handling in streaming testcases,Output folder is shared across testcases. Ideally we should use different output folder for each testcases; Also the deletion failure is silently ignored. MAPREDUCE-947 fixed some part of o p dir cleaning.,Resolved,Duplicate,MAPREDUCE-1888,Unassigned,Amar Kamat,Fri; 23 Oct 2009 05:00:11 +0000,Tue; 6 Jul 2010 10:48:22 +0000,Tue; 6 Jul 2010 10:47:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1138
MAPREDUCE-1139,Bug,Major,test,Contrib tests should respect scr/test/mapred-site.xml,There is no easy way to enforce some parameter value (as default) on contrib tests. This functionality is available for core test i.e by adding the param to mapred-site.xml in src test.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Fri; 23 Oct 2009 05:03:26 +0000,Tue; 29 Jul 2014 19:03:46 +0000,Tue; 29 Jul 2014 19:03:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1139
MAPREDUCE-1140,Bug,Major,tasktracker,Per cache-file refcount can become negative when tasks release distributed-cache files,nan,Closed,Fixed,,Amareshwari Sriramadasu,Vinod Kumar Vavilapalli,Fri; 23 Oct 2009 09:31:52 +0000,Tue; 24 Aug 2010 21:18:55 +0000,Mon; 30 Nov 2009 11:03:42 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1140
MAPREDUCE-1141,Bug,Major,tasktracker,Localization of a task's distributed-cache files gets blocked by deletion of old unrelated files when mapreduce.tasktracker.cache.local.size is hit.,nan,Resolved,Duplicate,MAPREDUCE-1302,Unassigned,Vinod Kumar Vavilapalli,Fri; 23 Oct 2009 09:40:55 +0000,Wed; 16 Dec 2009 08:15:55 +0000,Wed; 16 Dec 2009 08:15:55 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1141
MAPREDUCE-1142,Bug,Major,tasktracker,When cache.local.size is hit on one disk; DistributedCacheManager aggressively deletes old files on other disks too.,When the size of distributed cache files goes beyond mapreduce.tasktracker.cache.local.size on one disk; TrackerDistributedCacheManager deletes old files on other disks too. May be this is a bit aggressive.  An important problem with this excess effort is that issue observed at MAPREDUCE-1141 will be more often.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 23 Oct 2009 09:49:48 +0000,Tue; 29 Jul 2014 19:04:17 +0000,Tue; 29 Jul 2014 19:04:17 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1142
MAPREDUCE-1143,Bug,Blocker,,runningMapTasks counter is not properly decremented in case of failed Tasks.,nan,Closed,Fixed,,rahul k singh,rahul k singh,Fri; 23 Oct 2009 10:37:12 +0000,Tue; 24 Aug 2010 21:18:57 +0000,Fri; 18 Dec 2009 08:34:38 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1143
MAPREDUCE-1144,Bug,Major,jobtracker,JT should not hold lock while writing user history logs to DFS,I've seen behavior a few times now where the DFS is being slow for one reason or another; and the JT essentially locks up waiting on it while one thread tries for a long time to write history files out. The stack trace blocking everything is:  Thread 210 (IPC Server handler 10 on 7277):   State: WAITING   Blocked count: 171424   Waited count: 1209604   Waiting on  2581)     sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)  We should try not to do external IO while holding the JT lock; and instead write the data to an in-memory buffer; drop the lock; and then write.,Resolved,Won't Fix,,Unassigned,Todd Lipcon,Fri; 23 Oct 2009 14:11:43 +0000,Thu; 19 Mar 2015 23:14:28 +0000,Tue; 29 Jul 2014 19:07:01 +0000,,0.20.1,,,MAPREDUCE-5711,https://issues.apache.org/jira/browse/MAPREDUCE-1144
MAPREDUCE-1145,New Feature,Major,,Multiple Outputs doesn't work with new API in 0.20 branch,I know this is working in the 0.21 branch but it's dependent on a ton of other refactorings and near-impossible to backport.  I hacked together a quick forwards-port in o.a.h.mapreduce.lib.output.MultipleOutputs.  Unit test attached; requires a one-liner change to FileOutputFormat.  Maybe 0.20.2?,Resolved,Won't Fix,,Unassigned,Jay Booth,Fri; 23 Oct 2009 16:46:25 +0000,Fri; 19 Feb 2010 18:06:32 +0000,Tue; 3 Nov 2009 07:15:03 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1145
MAPREDUCE-1146,Bug,Major,,Sqoop dependencies break Ecpilse build on Linux,"Under  Linux there's the error in the Eclipse ""Problems"" view:   The problem doesn't appear on MacOS though",Resolved,Fixed,,Aaron Kimball,Konstantin Boudnik,Fri; 23 Oct 2009 17:10:32 +0000,Fri; 2 Jul 2010 06:31:48 +0000,Thu; 17 Dec 2009 18:25:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1146
MAPREDUCE-1147,Bug,Blocker,,Map output records counter missing for map-only jobs in new API,In the new API; the counter for map output records is not incremented for map-only jobs,Resolved,Fixed,,Amar Kamat,Chris Douglas,Fri; 23 Oct 2009 20:42:41 +0000,Mon; 21 Dec 2009 08:22:51 +0000,Tue; 17 Nov 2009 02:16:26 +0000,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1147
MAPREDUCE-1148,Bug,Major,,SQL identifiers are a superset of Java identifiers,SQL identifiers can contain arbitrary characters; can start with numbers; can be words like class which are reserved in Java; etc. If Sqoop uses these names literally for class and field names then compilation errors can occur in auto-generated classes. SQL identifiers need to be cleansed to map onto Java identifiers.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Sat; 24 Oct 2009 00:00:31 +0000,Fri; 2 Jul 2010 06:31:50 +0000,Tue; 15 Dec 2009 18:18:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1148
MAPREDUCE-1149,Bug,Major,,SQL identifiers are a superset of Java identifiers,SQL identifiers can contain arbitrary characters; can start with numbers; can be words like class which are reserved in Java; etc. If Sqoop uses these names literally for class and field names then compilation errors can occur in auto-generated classes. SQL identifiers need to be cleansed to map onto Java identifiers.,Resolved,Duplicate,MAPREDUCE-1148,Aaron Kimball,Aaron Kimball,Sat; 24 Oct 2009 00:00:52 +0000,Fri; 2 Jul 2010 06:31:51 +0000,Sat; 24 Oct 2009 00:01:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1149
MAPREDUCE-1150,Bug,Major,,In the enumeral Events.EventType ; a TaskAttemptFinishedEvent returns a MAP_ATTEMPT_FINISHED .,This is all in the package O.A.H.mapreduce.jobhistory .  There is no TASK_EVENT_FINISHED in the enumeral.  Shouldn't there be?  Shouldn't new TaskAttemptFinishedEvent(...).getEventType() return it; instead of the same value that some other subclass of HistoryEvent returns?,Open,Unresolved,,Unassigned,Dick King,Sat; 24 Oct 2009 00:11:02 +0000,Fri; 2 Jul 2010 00:04:56 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1150
MAPREDUCE-1151,Bug,Major,,Cleanup and Setup jobs should only call cleanupJob() and setupJob() methods of the OutputCommitter,The cleanup and setup jobs run as map jobs and call setUpTask() ; needsTaskCommit() and possibly commitTask() and abortTask() methods of the OutputCommitter. They should only be calling the cleanupJob() and setupJob() methods.,Resolved,Duplicate,MAPREDUCE-1476,Unassigned,Pradeep Kamath,Sat; 24 Oct 2009 01:49:07 +0000,Thu; 20 May 2010 04:19:41 +0000,Thu; 20 May 2010 04:19:41 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1151
MAPREDUCE-1152,Bug,Major,,JobTrackerInstrumentation.killed{Map/Reduce} is never called,JobTrackerInstrumentation.killed {Map Reduce}  metrics added as part of MAPREDUCE-1103 is not captured,Closed,Fixed,,Unassigned,Sharad Agarwal,Sat; 24 Oct 2009 06:51:11 +0000,Tue; 24 Aug 2010 21:19:00 +0000,Fri; 4 Dec 2009 08:13:06 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1152
MAPREDUCE-1153,Bug,Major,jobtracker,Metrics counting tasktrackers and blacklisted tasktrackers are not updated when trackers are decommissioned.,MAPREDUCE-1103 added instrumentation on the jobtracker to count the number of actual; blacklisted and decommissioned tasktrackers. When a tracker is decommissioned; the tasktracker count or the blacklisted tracker count is not decremented.,Closed,Fixed,,Sharad Agarwal,Hemanth Yamijala,Sat; 24 Oct 2009 11:50:09 +0000,Tue; 24 Aug 2010 21:19:01 +0000,Mon; 2 Nov 2009 07:57:37 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1153
MAPREDUCE-1154,New Feature,Major,test,Large-scale; automated test framwork for Map-Reduce,HADOOP-6332 proposes a large-scale; automated; junit-based test-framework for Hadoop.  This jira is meant to track relevant work to Map-Reduce.,Resolved,Duplicate,HADOOP-6332,Unassigned,Arun C Murthy,Sun; 25 Oct 2009 06:47:11 +0000,Tue; 27 Jul 2010 22:45:16 +0000,Tue; 27 Jul 2010 22:45:16 +0000,,,,,HADOOP-6248,https://issues.apache.org/jira/browse/MAPREDUCE-1154
MAPREDUCE-1155,Bug,Minor,contrib/streaming,Streaming tests swallow exceptions,Many of the streaming tests (including TestMultipleArchiveFiles) catch exceptions and print their stack trace rather than failing the job. This means that tests do not fail even when the job fails.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 26 Oct 2009 18:51:49 +0000,Tue; 24 Aug 2010 21:19:02 +0000,Tue; 5 Jan 2010 06:10:31 +0000,,0.20.1;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1155
MAPREDUCE-1156,Improvement,Major,,Caching localized counter names in mapred.Counters,Using YourKit profiling mumak; we found that MissingResourceException was thrown and caught 1.6 million times in Counters.Group.localize for several hundred of jobs. The resource bundle look up and costly exception processing can be easily avoided if we have a global cache of localized counter names.,Open,Unresolved,,Unassigned,Hong Tang,Mon; 26 Oct 2009 22:24:07 +0000,Mon; 26 Oct 2009 22:24:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1156
MAPREDUCE-1157,Bug,Major,jobtracker,JT UI shows incorrect scheduling info for failed/killed retired jobs,After a failed slots.,Resolved,Won't Fix,,Unassigned,Ramya Sunil,Tue; 27 Oct 2009 06:06:33 +0000,Tue; 29 Jul 2014 19:08:42 +0000,Tue; 29 Jul 2014 19:08:42 +0000,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1157
MAPREDUCE-1158,Bug,Major,jobtracker,running_maps is not decremented when the tasks of a job is killed/failed ,"running_maps counter in the metrics is not decremented when the tasks of a job is killed failed. Below are the exact steps to reproduce the problem:  	Initially running_maps=0 	Submit a job with 5 maps. running_maps is set to 5 	Kill 2 attempts of a map task 	Fail 4 attempts of the same map task so that the job is finally marked killed. 	Once the job is marked killed; running_maps is set to 3 and not 0.",Closed,Fixed,,Sharad Agarwal,Ramya Sunil,Tue; 27 Oct 2009 11:06:25 +0000,Tue; 24 Aug 2010 21:19:03 +0000,Wed; 28 Oct 2009 13:33:37 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1158
MAPREDUCE-1159,Improvement,Trivial,,Limit Job name on jobtracker.jsp to be 80 char long,Sometimes a user submits a job with a very long job name. That made jobtracker.jsp very hard to read. We should limit the size of the job name. User can see the full name when they click on the job.,Closed,Fixed,,Harsh J,Zheng Shao,Wed; 28 Oct 2009 07:06:09 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Mon; 28 Feb 2011 17:10:33 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1159
MAPREDUCE-1160,Bug,Major,jobtracker,Two log statements at INFO level fill up jobtracker logs,There are two log statements being logged at an INFO level that are unnecessarily filling up JT logs. This is making it difficult to debug issues on large cluster systems.  The two statements identified are the following:  INFO org.apache.hadoop.mapred.JobInProgress: No reduces to schedule for jobid and INFO org.apache.hadoop.mapred.ResourceEstimator: completedMapsUpdates:22  completedMapsInputSize:656  completedMapsOutputSize:6299,Closed,Fixed,,Ravi Gummadi,Hemanth Yamijala,Wed; 28 Oct 2009 08:51:58 +0000,Tue; 24 Aug 2010 21:19:03 +0000,Thu; 29 Oct 2009 03:52:34 +0000,,0.20.1;0.20.2;0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1160
MAPREDUCE-1161,Bug,Major,,NotificationTestCase should not lock current thread,There are 3 instances where NotificationTestCase is locking Thread.currentThread() is being locked and calling sleep on it. There is also a method stdPrintln that doesn't do anything.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Wed; 28 Oct 2009 22:35:30 +0000,Tue; 24 Aug 2010 21:19:04 +0000,Fri; 4 Dec 2009 09:57:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1161
MAPREDUCE-1162,Improvement,Trivial,,Job history should keep track of which task trackers were blacklisted,It would be useful to have job history keep track of which nodes were blacklisted by the job.  This would be used to build a history of job failure on certain nodes.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Thu; 29 Oct 2009 17:12:32 +0000,Wed; 2 Nov 2011 17:48:48 +0000,Wed; 2 Nov 2011 17:48:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1162
MAPREDUCE-1163,Bug,Trivial,,hdfsJniHelper.h: Yahoo! specific paths are encoded,"This header file defines USER_CLASSPATH as "" hadoop-0.1.0.jar"" .    This define doesn't appear to actually be used anywhere.  But it certainly would be a great way to exploit systems if it used internally at Yahoo!...",Resolved,Fixed,,Allen Wittenauer,Allen Wittenauer,Fri; 18 Sep 2009 21:45:38 +0000,Thu; 5 Nov 2009 08:54:27 +0000,Thu; 5 Nov 2009 05:34:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1163
HDFS-829,Bug,Major,,hdfsJniHelper.c: #include <error.h> is not portable,hdfsJniHelper.c includes error.h but this appears to be unnecessary; since even under Linux none of the routines that are prototyped are used.  Worse yet; error.h doesn't appear to be a standard header file so this breaks on Mac OS X and Solaris and prevents libhdfs from being built.,Closed,Fixed,,Allen Wittenauer,Allen Wittenauer,Fri; 18 Sep 2009 21:37:19 +0000,Mon; 12 Dec 2011 06:19:10 +0000,Tue; 7 Sep 2010 19:00:20 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/HDFS-829
MAPREDUCE-1165,Bug,Major,,SerialUtils.hh: __PRETTY_FUNCTION__ is a GNU extension and not portable,SerialUtils.hh uses _PRETTY_FUNCTION_ to print the name of the function during an assertion.  That is a GNU extension and is not portable across compilers.  C99 defines __func__; which should probably be used instead.,Closed,Fixed,,Allen Wittenauer,Allen Wittenauer,Wed; 16 Sep 2009 22:20:24 +0000,Tue; 24 Aug 2010 21:19:05 +0000,Wed; 23 Dec 2009 05:34:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1165
MAPREDUCE-1166,Bug,Major,,SerialUtils.cc: dynamic allocation of arrays based on runtime variable is not portable,In SerialUtils.cc; the following code appears:      int len;     if (b  -120)  {       negative = true;       len = -120 - b;     }  else  {       negative = false;       len = -112 - b;     }     uint8_t barrlen;   as far as I'm aware; this is not legal in ANSI C and will be rejected by ANSI compliant compilers.  Instead; this should be malloc()'d based upon the size of len and free()'d later.,Resolved,Won't Fix,,Allen Wittenauer,Allen Wittenauer,Wed; 16 Sep 2009 22:36:19 +0000,Wed; 2 Nov 2011 17:48:23 +0000,Wed; 2 Nov 2011 17:48:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1166
MAPREDUCE-1167,New Feature,Major,tasktracker,Make ProcfsBasedProcessTree collect rss memory information,Right now ProcfsBasedProcess collects only virtual memory. We can make it collect rss memory as well. Later we can use rss in TaskMemoryManagerThread to obtain better memory management.,Closed,Fixed,,Scott Chen,Scott Chen,Thu; 29 Oct 2009 19:43:35 +0000,Thu; 2 May 2013 02:29:25 +0000,Tue; 17 Nov 2009 20:25:15 +0000,,0.22.0,,MAPREDUCE-1201,MAPREDUCE-961,https://issues.apache.org/jira/browse/MAPREDUCE-1167
MAPREDUCE-1168,New Feature,Major,,Export data to databases via Sqoop,Sqoop can import from a database into HDFS. It's high time it works in reverse too.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 29 Oct 2009 20:53:54 +0000,Fri; 2 Jul 2010 06:31:28 +0000,Mon; 7 Dec 2009 21:43:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1168
MAPREDUCE-1169,Improvement,Major,,Improvements to mysqldump use in Sqoop,Improve Sqoop's integration with mysqldump,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 29 Oct 2009 20:59:37 +0000,Fri; 2 Jul 2010 06:31:29 +0000,Mon; 23 Nov 2009 18:38:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1169
MAPREDUCE-1170,New Feature,Major,,MultipleInputs doesn't work with new API in 0.20 branch,This patch adds support for MultipleInputs (and KeyValueTextInputFormat) in o.a.h.mapreduce.lib.input; working with the new API.  Included passing unit test.  Include for 0.20.2?,Resolved,Won't Fix,,Unassigned,Jay Booth,Thu; 29 Oct 2009 23:42:59 +0000,Wed; 25 Nov 2009 20:03:27 +0000,Tue; 3 Nov 2009 07:18:43 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1170
MAPREDUCE-1171,Bug,Blocker,task,Lots of fetch failures,Since we upgraded to hadoop-0.20.1  from hadoop0.18.3; we see lot of more map task failures because of 'Too many fetch-failures'.  One of our jobs makes hardly any progress; because of 3000 reduces not able to get map output of 2 trailing maps (with about 80GB output each); which repeatedly are marked as failures because of reduces not being able to get their map output. One difference to hadoop-0.18.3 seems to be that reduce tasks report a failed mapoutput fetch even after a single try when it was a read error (cr.getError().equals(CopyOutputErrorType.READ_ERROR). I do not think this is a good idea; as trailing map tasks will be attacked by all reduces simultaneously.  Here is a log output of a reduce task:    Also I saw a few log messages which look suspicious as if successfully fetched map output is discarded because of the map being marked as failed (because of too many fetch failures). This would make the situation even worse.,Closed,Fixed,,Amareshwari Sriramadasu,Christian Kunz,Fri; 30 Oct 2009 01:53:05 +0000,Tue; 24 Aug 2010 21:19:06 +0000,Fri; 11 Dec 2009 04:12:13 +0000,,0.21.0,,,HADOOP-3327,https://issues.apache.org/jira/browse/MAPREDUCE-1171
MAPREDUCE-1172,Bug,Major,,TestReduceFetch failed in 0.20,When I was testing HDFS-732 on 0.20; TestReduceFetch kept failing.,Resolved,Duplicate,MAPREDUCE-433;MAPREDUCE-1392,Unassigned,Tsz Wo Nicholas Sze,Fri; 30 Oct 2009 23:50:42 +0000,Sat; 23 Jan 2010 01:54:52 +0000,Sat; 23 Jan 2010 00:50:17 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1172
MAPREDUCE-1173,Improvement,Major,,Documenting MapReduce metrics,As part of HADOOP-6350; we should document the metrics for JobTracker and TaskTracker as part of their interfaces.,Open,Unresolved,,Unassigned,Hong Tang,Sat; 31 Oct 2009 01:07:10 +0000,Thu; 2 May 2013 02:29:23 +0000,,,,,,MAPREDUCE-901,https://issues.apache.org/jira/browse/MAPREDUCE-1173
MAPREDUCE-1174,Bug,Major,,Sqoop improperly handles table/column names which are reserved sql words,In some databases it is legal to name tables and columns with terms that overlap SQL reserved keywords (e.g.; CREATE; table; etc.). In such cases; the database allows you to escape the table and column names. We should always escape table and column names when possible.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Sat; 31 Oct 2009 01:58:28 +0000,Fri; 2 Jul 2010 06:31:33 +0000,Thu; 17 Dec 2009 21:31:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1174
MAPREDUCE-1175,Improvement,Major,,We should have a spec on JobHistory file format,Currently; JobHistory schema is specified in o.a.h.m.jobhistory.Event.avpr; it requires some guess work for me to understand the meaning of various records. Also; it would be nice to spec out the dependency among the events. This would make tools like rumen more dependable to parse job history logs.,Open,Unresolved,,Unassigned,Hong Tang,Sat; 31 Oct 2009 02:12:59 +0000,Mon; 10 Jan 2011 21:02:39 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1175
MAPREDUCE-1176,New Feature,Major,,FixedLengthInputFormat and FixedLengthRecordReader,Hello; I would like to contribute the following two classes for incorporation into the mapreduce.lib.input package. These two classes can be used when you need to read data from files containing fixed length (fixed width) records. Such files have no CR LF (or any combination thereof); no delimiters etc; but each record is a fixed length; and extra data is padded with spaces. The data is one gigantic line within a file.  Provided are two classes first is the FixedLengthInputForm classes; does not support compressed files.,Closed,Fixed,,Mariappan Asokan,BitsOfInfo,Sun; 1 Nov 2009 18:38:29 +0000,Mon; 24 Feb 2014 20:57:14 +0000,Tue; 12 Nov 2013 03:11:57 +0000,,2.2.0,,,MAPREDUCE-5455,https://issues.apache.org/jira/browse/MAPREDUCE-1176
MAPREDUCE-1177,Bug,Blocker,tasktracker;test,TestTaskTrackerMemoryManager retries a task for more than 100 times.,TestTaskTrackerMemoryManager retries a task for more than 100 times. The logs showing the same:    Sometimes the test timesout also.,Closed,Fixed,,Vinod Kumar Vavilapalli,Amareshwari Sriramadasu,Mon; 2 Nov 2009 06:53:22 +0000,Tue; 24 Aug 2010 21:19:07 +0000,Fri; 6 Nov 2009 02:16:03 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1177
MAPREDUCE-1178,Bug,Blocker,,MultipleInputs fails with ClassCastException ,When running MultipleInputs against the new API; we get failures with this ClassCastException:   257)  The unit test for MultipleInputs doesn't actually run a job so this snuck through while still passing the unit test.  Attached patch fixes the unit test to expose the failure and does a little casting kung-fu in LineRecordReader to avoid the error.,Closed,Fixed,,Amareshwari Sriramadasu,Jay Booth,Mon; 2 Nov 2009 23:07:25 +0000,Tue; 24 Aug 2010 21:19:08 +0000,Mon; 9 Nov 2009 08:02:26 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1178
MAPREDUCE-1179,Bug,Major,build,org.apache.hadoop.streaming.TestSymLink.testSymLink is failing ,This junit testcase is failing. Please address it.   org.apache.hadoop.streaming.TestSymLink.testSymLink (from TestSymLink)   Failing for the past 1 build (Since #131 )  Took 55 sec. add description  Error Message  132),Resolved,Duplicate,HADOOP-6528,Unassigned,Iyappan Srinivasan,Tue; 3 Nov 2009 10:05:04 +0000,Tue; 2 Feb 2010 05:42:35 +0000,Tue; 2 Feb 2010 05:42:16 +0000,,0.22.0,,,HADOOP-6528;MAPREDUCE-1370;HADOOP-6386,https://issues.apache.org/jira/browse/MAPREDUCE-1179
MAPREDUCE-1180,Wish,Minor,,Detailed area chart of map/reduce slots usage,People are always looking for ideas of things to implement... so here's one.   I'd like an app that I can throw at a JobHistory directory that would show me detailed slot usage by job; user; pool; etc; in an area stacked chart format.  This would be very helpful to determine if a particular job; user; or pool is under over utilizing the capacity; if we need more capacity; what time slots have holes; etc.  I'll see if I can create an example in Excel of what I'm thinking of.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 3 Nov 2009 18:36:54 +0000,Wed; 2 Nov 2011 17:47:32 +0000,Wed; 2 Nov 2011 17:47:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1180
MAPREDUCE-1181,New Feature,Major,tasktracker,Enforce RSS memory limit in TaskMemoryManagerThread,TaskMemoryManagerThread will periodically check the rss memory usage of every task. If the memory usage exceeds the specified threshold; the task will be killed. Also if the total rss memory of all tasks exceeds (total amount of memory - specified reserved memory). The task with least progress will be killed to recover the reserved rss memory.  This is similar to the virtual memory limit provided by TaskMemoryManagerThread. But now the limit is for rss memory. This new feature allow us to avoid page swapping which is prone to error.  The following are the related configurations mapreduce.reduce.memory.rss.mb     RSS memory reserved (not for tasks) on a tasktracker,Resolved,Invalid,,Unassigned,Scott Chen,Tue; 3 Nov 2009 18:56:20 +0000,Thu; 2 May 2013 02:29:24 +0000,Sun; 8 Nov 2009 09:03:44 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1181
MAPREDUCE-1182,Bug,Blocker,,Reducers fail with OutOfMemoryError while copying Map outputs,Reducers fail while copying Map outputs with following exception   1216) ;Error:  Reducer's memory usage keeps on increasing and ultimately exceeds -Xmx value   I even tried with -Xmx6.5g to each reducer but it's still failing   While looking into the reducer logs; I found that reducers were doing shuffleInMemory every time; rather than doing shuffleOnDisk,Resolved,Fixed,,Chandra Prakash Bhagtani,Chandra Prakash Bhagtani,Tue; 3 Nov 2009 10:06:04 +0000,Mon; 21 Dec 2009 08:50:27 +0000,Wed; 25 Nov 2009 21:57:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1182
MAPREDUCE-1183,Improvement,Major,client,Serializable job components: Mapper; Reducer; InputFormat; OutputFormat et al,Currently the Map-Reduce framework uses Configuration to pass information about the various aspects of a job such as Mapper; Reducer; InputFormat; OutputFormat; OutputCommitter etc. and application developers use org.apache.hadoop.mapreduce.Job.set*Class apis to set them at job-submission time:     The proposal is that we move to a model where end-users interact with org.apache.hadoop.mapreduce.Job via actual objects which are then serialized by the framework:,Open,Unresolved,,Owen O'Malley,Arun C Murthy,Thu; 5 Nov 2009 02:08:16 +0000,Thu; 26 Jul 2012 15:43:46 +0000,,,0.21.0,,,MAPREDUCE-1462;MAPREDUCE-1126,https://issues.apache.org/jira/browse/MAPREDUCE-1183
MAPREDUCE-1184,Improvement,Major,,mapred.reduce.slowstart.completed.maps is too low by default,By default; this value is set to 5%.  I believe for most real world situations the code isn't efficient enough to be set this low.  This should be higher; probably around the 50% mark; especially given the predominance of non-FIFO schedulers.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Thu; 5 Nov 2009 04:00:39 +0000,Wed; 2 Nov 2011 17:46:41 +0000,Wed; 2 Nov 2011 17:46:41 +0000,,0.20.1;0.20.2,,,MAPREDUCE-1463,https://issues.apache.org/jira/browse/MAPREDUCE-1184
MAPREDUCE-1185,Improvement,Major,jobtracker,URL to JT webconsole for running job and job history should be the same,The tracking url for running jobs and the jobs which are retired is different. This creates problem for clients which caches the job running url because soon it becomes invalid when job is retired.,Closed,Fixed,,Amareshwari Sriramadasu,Sharad Agarwal,Thu; 5 Nov 2009 07:55:10 +0000,Tue; 24 Aug 2010 21:19:08 +0000,Mon; 7 Dec 2009 06:19:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1185
MAPREDUCE-1186,Bug,Major,tasktracker,While localizing a DistributedCache file; TT sets permissions recursively on the whole base-dir,This is a performance problem.,Closed,Fixed,,Amareshwari Sriramadasu,Vinod Kumar Vavilapalli,Thu; 5 Nov 2009 08:19:41 +0000,Tue; 24 Aug 2010 21:19:09 +0000,Thu; 7 Jan 2010 08:01:26 +0000,,0.21.0,,MAPREDUCE-1284,MAPREDUCE-1098,https://issues.apache.org/jira/browse/MAPREDUCE-1186
MAPREDUCE-1187,Bug,Major,,mradmin -refreshNodes should be implemented,dfsadmin -refreshNodes re-reads the include exclude files for the HDFS; triggers decommisions; etc.  The MapReduce framework should have similar functionality using the same parameter to mradmin.,Resolved,Duplicate,HADOOP-5643,Unassigned,Allen Wittenauer,Thu; 5 Nov 2009 18:54:24 +0000,Thu; 3 Nov 2011 16:54:10 +0000,Thu; 3 Nov 2011 16:54:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1187
MAPREDUCE-1188,Bug,Major,jobtracker,NPE in decommissioning blacklisted nodes,Decommissioning a blacklisted node results into a NPE.,Resolved,Duplicate,MAPREDUCE-754,Amar Kamat,Amar Kamat,Thu; 5 Nov 2009 19:39:26 +0000,Tue; 10 Nov 2009 06:12:41 +0000,Fri; 6 Nov 2009 06:20:07 +0000,,0.20.1,,,MAPREDUCE-754,https://issues.apache.org/jira/browse/MAPREDUCE-1188
MAPREDUCE-1189,Improvement,Major,build,Reduce ivy console output to ovservable level,It is very hard to see what's going in the build because ivy is literally flood the console with nonsensical messages...,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Thu; 5 Nov 2009 21:48:53 +0000,Tue; 24 Aug 2010 21:19:10 +0000,Fri; 13 Nov 2009 19:42:34 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1189
MAPREDUCE-1190,Sub-task,Minor,documentation,Add package.html to pi and pi.math packages.,package.html is missing in the pi and pi.math packages.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Fri; 6 Nov 2009 00:26:40 +0000,Tue; 24 Aug 2010 21:19:10 +0000,Wed; 2 Dec 2009 06:29:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1190
MAPREDUCE-1191,Bug,Major,,JobInProgress.createCache() should not add unknown hosts to the host-to-rack location mapping.,"JobInProgress.createCache() currently would add host names specified in rawsplits to rack "" default-rack"" if it does not already know the mapping. This seems to be a bad idea in the sense that a malicious client can submit jobs with many maps whose locations are non-existent hosts and thus consume up JobTracker's memory.",Open,Unresolved,,Unassigned,Hong Tang,Fri; 6 Nov 2009 01:53:36 +0000,Fri; 6 Nov 2009 09:49:46 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1191
MAPREDUCE-1192,Improvement,Major,distributed-cache,Use the DistributedCache for job.xml and job.jar,It would be more efficient if we used the DistributedCache for a job's configuration and jars.,Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 6 Nov 2009 01:57:09 +0000,Tue; 29 Jul 2014 19:59:47 +0000,Tue; 29 Jul 2014 19:59:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1192
MAPREDUCE-1193,Bug,Major,,Progress reporting in map-only jobs should not have phases,The map task reporting is broken into phases so that the sort (merge) phase accounts for 33% of the progress. Map-only jobs do not have this phase; so it should be excluded.,Open,Unresolved,,Unassigned,Chris Douglas,Fri; 6 Nov 2009 03:49:25 +0000,Fri; 6 Nov 2009 03:49:25 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1193
MAPREDUCE-1194,Bug,Minor,,mapred.reduce.slowstart.completed.maps allows values more than 1.0 and less than 0.0,When run with value less than 0.0 (e.g. -1.0) works similar to 0.0; but when value is more than 1.0 (e.g. 50.0) reducers don't start at all. Is there a reason why such values are allowed? I understand that this is clear from the description that parameter is fraction but some people may forget and confuse it with percents and as result have problems. Why not throw an error in this case?,Open,Unresolved,,Unassigned,Maxim Zizin,Fri; 6 Nov 2009 17:12:07 +0000,Tue; 29 Jul 2014 20:13:08 +0000,,,0.20.1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-1194
MAPREDUCE-1195,New Feature,Major,,Task resource utilization reporting for profiling and scheduling,We can make TaskTracker reports its usage on CPU; memory; bandwidth to JobTracker. JobTracker can use the information for scheduling tasks and profiling jobs.   One way to do this is to first make ProcfsProcessTree to collect the utilization information (CPU; mem...) and write the information in TaskTrackerStatus.taskReports and send them with the heartbeats. Then we can aggregate these information in JobInProgress to do job profiling and scheduling.,Resolved,Duplicate,MAPREDUCE-220,Unassigned,Scott Chen,Fri; 6 Nov 2009 19:44:54 +0000,Thu; 2 May 2013 02:29:25 +0000,Fri; 6 Nov 2009 22:17:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1195
MAPREDUCE-1196,Bug,Blocker,client,MAPREDUCE-947 incompatibly changed FileOutputCommitter,MAPREDUCE-947 unfortunately removed FileOutputCommitter.cleanupJob and doesn't call the deprecated method from the base-class i.e. OutputCommitter.cleanupJob; this means that applications which derive FileOutputCommitter.cleanupJob are now broken.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sun; 8 Nov 2009 18:24:33 +0000,Tue; 24 Aug 2010 21:19:11 +0000,Tue; 10 Nov 2009 00:20:04 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1196
MAPREDUCE-1197,Bug,Major,jobtracker,username:jobid  in job history search should be separated into two.,"Job History web ui takes username:jobid  for search. For searching only through jobid; user has to give "":job_id"". They should be separated into two sothat user can give username or jobid.",Open,Unresolved,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Mon; 9 Nov 2009 05:17:58 +0000,Fri; 2 Jul 2010 00:04:13 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1197
MAPREDUCE-1198,Improvement,Major,contrib/fair-share,Alternatively schedule different types of tasks in fair share scheduler,Matei has mentioned in MAPREDUCE-961 that the current scheduler will first try to launch map tasks until canLaunthTask() returns false then look for reduce tasks. This might starve reduce task. He also mention that alternatively schedule different types of tasks can solve this problem.,Closed,Fixed,,Scott Chen,Scott Chen,Mon; 9 Nov 2009 21:50:55 +0000,Tue; 24 Aug 2010 21:19:12 +0000,Fri; 20 Nov 2009 20:05:58 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1198
MAPREDUCE-1199,Bug,Major,jobtracker,TaskInProgress should also consider blacklisted node while (re)scheduling failed tasks,While rescheduling failed tasks; only the failure count is used. It should also consider the blacklisted trackers information too.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 10 Nov 2009 09:55:17 +0000,Tue; 10 Nov 2009 09:59:28 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1199
MAPREDUCE-1200,Bug,Major,,TestGridmixSubmission unit Test is failing in trunk,"http: 5139995 	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.check(TestGridmixSubmission. 297)",Resolved,Duplicate,MAPREDUCE-1124,Unassigned,Iyappan Srinivasan,Tue; 10 Nov 2009 13:37:44 +0000,Tue; 10 Nov 2009 18:01:09 +0000,Tue; 10 Nov 2009 18:01:09 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1200
MAPREDUCE-1201,Sub-task,Major,,Make ProcfsBasedProcessTree collect CPU usage information,This information can be reported back to jobtracker to help profiling jobs and scheduling tasks.,Closed,Fixed,,Scott Chen,Scott Chen,Tue; 10 Nov 2009 18:37:19 +0000,Fri; 3 Feb 2012 22:16:18 +0000,Mon; 21 Dec 2009 22:46:01 +0000,,0.22.0,,MAPREDUCE-1167,MAPREDUCE-3583,https://issues.apache.org/jira/browse/MAPREDUCE-1201
MAPREDUCE-1202,Bug,Major,jobtracker,Checksum error on a single reducer does not trigger too many fetch failures for mapper during shuffle,During one run of a large map-reduce job; a single reducer keep throwing Checksum exception when try to shuffle from one mapper. The data on the mapper node for that particular reducer is believed to be corrupted; since there are disk issues on the mapper node. However; even with hundreds of retries to fetch the shuffling data for that particular reducer; and numerous reports to job tracker due to this issue; the mapper is still not declared as too many fetch failures in job tracker.  Here is the log: 2009-11-10 19:55:05;655 INFO org.apache.hadoop.mapred.ReduceTask: tempt_200911010621_0023_m_039676_0 even after MAX_FETCH_RETRIES_PER_MAP retries...  or it is a read error;  reporting to the JobTracker,Open,Unresolved,,Unassigned,Qi Liu,Tue; 10 Nov 2009 20:16:10 +0000,Tue; 10 Jul 2012 21:27:09 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1202
MAPREDUCE-1203,Improvement,Minor,,DBOutputFormat: add batch size support for JDBC and recieve  DBWritable object in value not in key,package mapred.lib.db  added batch size support for JDBC in DBOutputFormat  recieve  DBWritable object in value not in key in DBOutputFormat,Closed,Won't Fix,,Aaron Kimball,Alexander Schwid,Thu; 2 Oct 2008 09:10:30 +0000,Fri; 13 Nov 2009 14:40:57 +0000,Tue; 28 Oct 2008 10:36:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1203
MAPREDUCE-1204,Bug,Major,contrib/fair-share,Fair Scheduler preemption may preempt tasks running in slots unusable by the preempting job,"The current preemption code works by first calculating how many tasks need to be preempted to satisfy the min share constraints; and then killing an equal number of tasks from other jobs; sorted to favor killing of young tasks. This works fine for the general case; but there are some edge cases where this can cause problems.  For example; if the preempting job has blacklisted (""marked flaky"") a particular task tracker; and th the preempting jobs can actually make use of the candidate slots before killing them.",Open,Unresolved,,Unassigned,Todd Lipcon,Tue; 10 Nov 2009 22:40:47 +0000,Mon; 13 Dec 2010 23:31:51 +0000,,,0.21.0,,,MAPREDUCE-2205,https://issues.apache.org/jira/browse/MAPREDUCE-1204
MAPREDUCE-1205,Improvement,Major,,Need method to parse comma separated path strings that contain hadoop file glob pattern ,A static method like FileInputFormat.getPathStrings(String commaSeparatedPaths) is needed by PIG. But this method is private.,Open,Unresolved,,Unassigned,Richard Ding,Tue; 10 Nov 2009 23:47:16 +0000,Tue; 10 Nov 2009 23:47:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1205
MAPREDUCE-1206,Bug,Major,,"Need a better answer for ""how many reduces?""",http: reduce jobs.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 11 Nov 2009 00:22:32 +0000,Wed; 2 Nov 2011 17:46:05 +0000,Wed; 2 Nov 2011 17:46:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1206
MAPREDUCE-1207,Improvement,Blocker,client;mrv2,Allow admins to set java options for map/reduce tasks,It will be useful for allow cluster-admins to set some  opts but forget to add this.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 11 Nov 2009 06:26:27 +0000,Tue; 15 Nov 2011 00:48:21 +0000,Sat; 24 Sep 2011 20:50:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1207
MAPREDUCE-1208,Bug,Major,test,TestKillSubProcesses fails with NPE,Here is the stack trace,Open,Unresolved,,Ravi Gummadi,Amar Kamat,Wed; 11 Nov 2009 06:26:35 +0000,Fri; 2 Jul 2010 00:04:22 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1208
MAPREDUCE-1209,Sub-task,Blocker,test,Move common specific part of the test TestReflectionUtils out of mapred into common,As commented by Tom here (https: HADOOP-6230?focusedCommentId=12751058page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12751058); TestReflectionUtils has a single test testSetConf() to test backward compatibility of ReflectionUtils for JobConfigurable objects. TestReflectionUtils can be spilt into two tests - one on common and one in mapred - this single test may reside in mapred till the mapred package is removed.,Closed,Fixed,,Todd Lipcon,Vinod Kumar Vavilapalli,Fri; 4 Sep 2009 03:54:30 +0000,Tue; 24 Aug 2010 21:19:15 +0000,Tue; 15 Dec 2009 01:26:45 +0000,,0.21.0;0.22.0,,,HADOOP-6413,https://issues.apache.org/jira/browse/MAPREDUCE-1209
MAPREDUCE-1210,Bug,Major,,standalone \r is treated as new line by RecordLineReader,In PIg 0.6.0 we are switching to RecordLineReader from our own implementation. We are seeing differences in record counts that were traced down to the fact that standalone  r is treated as line end. I don't think there is any precedence for this and we would like to get this resolved so that we can use RLR and not break backward compatibility. (This problem was detected with real user data.),Resolved,Won't Fix,,Unassigned,Olga Natkovich,Wed; 11 Nov 2009 18:48:58 +0000,Tue; 29 Jul 2014 20:07:44 +0000,Tue; 29 Jul 2014 20:07:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1210
MAPREDUCE-1211,New Feature,Minor,task,Online aggregation and continuous query support,"The purpose of this post is to propose a modified MapReduce architecture that allows data to be pipelined between operators. This extends the MapReduce programming model beyond batch processing; and can reduce completion times and improve system utilization for batch jobs as well. We have built a modified version of the Hadoop MapReduce framework that supports online aggregation; which allows users to see ""early returns"" from a job as it is being computed. Our Hadoop Online Prototype (HOP) also supports continuous queries; which enable MapReduce programs to be written for applications such as event monitoring and stream processing. HOP retains the fault tolerance properties of Hadoop; and can run unmodified user-defined MapReduce programs.  For more information on the HOP design; please see our technical report. http: ",Resolved,Won't Fix,,Unassigned,Tyson Condie,Thu; 12 Nov 2009 17:54:04 +0000,Fri; 21 Oct 2016 07:44:59 +0000,Tue; 29 Jul 2014 20:08:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1211
MAPREDUCE-1212,Bug,Critical,build,Mapreduce contrib project ivy dependencies are not included in binary target,As in HADOOP-6370; only Hadoop's own library dependencies are promoted to ${build.dir} lib; any libraries required by contribs are not redistributed.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 12 Nov 2009 20:32:39 +0000,Tue; 24 Aug 2010 21:19:16 +0000,Fri; 15 Jan 2010 00:43:00 +0000,,,,,HADOOP-6370,https://issues.apache.org/jira/browse/MAPREDUCE-1212
MAPREDUCE-1213,Bug,Major,,TaskTrackers restart is very slow because it deletes distributed cache directory synchronously,We are seeing that when we restart a tasktracker; it tries to recursively delete all the file in the distributed cache. It invoked FileUtil.fullyDelete() which is very very slow. This means that the TaskTracker cannot join the cluster for an extended period of time (upto 2 hours for us). The problem is acute if the number of files in a distributed cache is a few-thousands.,Closed,Fixed,,Zheng Shao,dhruba borthakur,Fri; 13 Nov 2009 11:47:39 +0000,Wed; 1 Aug 2012 13:23:37 +0000,Thu; 17 Dec 2009 02:50:50 +0000,,0.20.1,,MAPREDUCE-1303;MAPREDUCE-1302;HADOOP-6433,MAPREDUCE-2049;MAPREDUCE-1382;HDFS-611,https://issues.apache.org/jira/browse/MAPREDUCE-1213
MAPREDUCE-1214,Improvement,Major,,Add support for counters in Hadoop Local Mode,Currently there is no support for counters ( Records and Bytes written ) in Hadoop Local Mode.  Pig requires to provide counters to user when running in Hadoop Local Mode.,Open,Unresolved,,Unassigned,Ankit Modi,Fri; 13 Nov 2009 22:58:20 +0000,Wed; 30 Apr 2014 00:23:57 +0000,,,,,,PIG-3913,https://issues.apache.org/jira/browse/MAPREDUCE-1214
MAPREDUCE-1215,Bug,Major,,Counter deprecation warnings in jobtracker log are excessive,In a recent test; the log message   was nearly a third of a 1.3GB jobtracker log.,Resolved,Fixed,,Unassigned,Chris Douglas,Sun; 15 Nov 2009 18:40:58 +0000,Tue; 29 Jul 2014 20:16:15 +0000,Tue; 29 Jul 2014 20:16:15 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1215
MAPREDUCE-1216,Bug,Major,,MRUnit Should Sort Reduce Input,MRUnit should sort the input for a reduce task; the same way hadoop does. This is useful if you have a reduce task that; for instance; removes duplicate key value pairs.  example:      produces different results than,Resolved,Invalid,,Unassigned,Ed Kohlwey,Mon; 16 Nov 2009 18:46:28 +0000,Sat; 28 Nov 2009 00:42:56 +0000,Sat; 28 Nov 2009 00:42:56 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1216
MAPREDUCE-1217,Bug,Major,test,TestMapReduceLocal fails intermittently. Assert message is unclear  ,TestMapReduceLocal fails occasionally with the following assert message MultiFileWordCount failed  Besides of the failure; the message is unclear and requires an extra analysis effort.,Resolved,Fixed,,Unassigned,Konstantin Boudnik,Mon; 16 Nov 2009 19:31:42 +0000,Tue; 29 Jul 2014 20:16:46 +0000,Tue; 29 Jul 2014 20:16:46 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1217
MAPREDUCE-1218,Sub-task,Major,,Collecting cpu and memory usage for TaskTrackers,The information can be used for resource aware scheduling. Note that this is related to MAPREDUCE-220. There the per task resource information is collected. This one collects the per machine information.,Closed,Fixed,,Scott Chen,Scott Chen,Wed; 18 Nov 2009 00:41:17 +0000,Thu; 20 Sep 2012 14:07:07 +0000,Wed; 13 Jan 2010 21:06:00 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1218
MAPREDUCE-1219,Bug,Major,,JobTracker Metrics causes undue load on JobTracker,JobTrackerMetricsInst.doUpdates updates job-level counters of all running jobs into JobTracker's metrics causing very bad performance and hampers heartbeats. Since Job level metrics are better served by JobHistory; it may be a good idea to remove these from the metrics framework.,Closed,Fixed,,Sreekanth Ramakrishnan,Jothi Padmanabhan,Wed; 18 Nov 2009 04:33:56 +0000,Tue; 24 Aug 2010 21:19:17 +0000,Mon; 26 Apr 2010 04:16:39 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1219
MAPREDUCE-1220,New Feature,Major,client;jobtracker,Implement an in-cluster LocalJobRunner,Currently very small map-reduce jobs suffer from latency issues due to overheads in Hadoop Map-Reduce such as scheduling; jvm startup etc. We've periodically tried to optimize all parts of framework to achieve lower latencies.  I'd like to turn the problem around a little bit. I propose we allow very small jobs to run as a single task job with multiple maps and reduces i.e. similar to our current implementation of the LocalJobRunner. Thus; under certain conditions (maybe user-set configuration; or if input data is small i.e. less a DFS blocksize) we could launch a special task which will run all maps in a serial manner; followed by the reduces. This would really help small jobs achieve significantly smaller latencies; thanks to lesser scheduling overhead; jvm startup; lack of shuffle over the network etc.   This would be a huge benefit; especially on large clusters; to small Hive Pig queries.  Thoughts?,Closed,Duplicate,MAPREDUCE-2405,Greg Roelofs,Arun C Murthy,Wed; 18 Nov 2009 22:44:52 +0000,Tue; 15 Nov 2011 00:48:49 +0000,Tue; 18 Oct 2011 06:53:38 +0000,,,,,MAPREDUCE-2405,https://issues.apache.org/jira/browse/MAPREDUCE-1220
MAPREDUCE-1221,Improvement,Major,tasktracker,Kill tasks on a node if the free physical memory on that machine falls below a configured threshold,The TaskTracker currently supports killing tasks if the virtual memory of a task exceeds a set of configured thresholds. I would like to extend this feature to enable killing tasks if the physical memory used by that task exceeds a certain threshold.  On a certain operating system (guess?); if user space processes start using lots of memory; the machine hangs and dies quickly. This means that we would like to prevent map-reduce jobs from triggering this condition. From my understanding; the killing-based-on-virtual-memory-limits (HADOOP-5883) were designed to address this problem. This works well when most map-reduce jobs are Java jobs and have well-defined -Xmx parameters that specify the max virtual memory for each task. On the other hand; if each task forks off mappers php; etc); the total virtual memory usage of the process-subtree varies greatly. In these cases; it is better to use kill-tasks-using-physical-memory-limits.,Closed,Fixed,,Scott Chen,dhruba borthakur,Thu; 19 Nov 2009 00:48:17 +0000,Tue; 24 Aug 2010 21:19:19 +0000,Wed; 21 Apr 2010 06:18:41 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1221
MAPREDUCE-1222,Bug,Major,contrib/mumak,[Mumak] We should not include nodes with numeric ips in cluster topology.,Rumen infers cluster topology by parsing input split locations from job history logs. Due to HDFS-778; a cluster node may appear both as a numeric ip or as a host name in job history logs. We should exclude nodes appeared as numeric ips in cluster toplogy when we run mumak until a solution is found so that numeric ips would never appear in input split locations.,Closed,Fixed,,Hong Tang,Hong Tang,Thu; 19 Nov 2009 14:30:59 +0000,Tue; 24 Aug 2010 21:19:20 +0000,Fri; 11 Dec 2009 19:51:16 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1222
MAPREDUCE-1223,Bug,Major,,CompositeInputFormat doesn't consider all tuples when run in a local task tracker,The CrossJoin class does not emit all tuples representing the cross product of values for a given key. The issue only occurs when using the local task tracker; and not when running the job on a cluster.   Example    The expected output is    Instead one gets,Resolved,Invalid,,Unassigned,Ed Kohlwey,Thu; 19 Nov 2009 18:55:14 +0000,Fri; 20 Nov 2009 15:03:07 +0000,Fri; 20 Nov 2009 15:03:07 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1223
MAPREDUCE-1224,Improvement,Major,,"Calling ""SELECT t.* from <table> AS t"" to get meta information is too expensive for big tables","The SqlManager uses the query; ""SELECT t.* from table AS t"" to get table spec is too expensive for big tables; and it was called twice to generate column names and types.  For tables that are big enough to be map-reduced; this is too expensive to make sqoop useful.",Resolved,Fixed,,Spencer Ho,Spencer Ho,Fri; 20 Nov 2009 00:32:00 +0000,Fri; 2 Jul 2010 06:31:49 +0000,Tue; 15 Dec 2009 15:05:33 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1224
MAPREDUCE-1225,Bug,Major,tasktracker,TT successfully localizes a task even though the corresponding cache-file has already changed on DFS.,This happens with the first task of a job being localized on this TT. TT doesn't check if the file on DFS is fresh according to the timestamps set in job-conf during submission. After the first task incorrectly gets localized; all further tasks fail on this TT as expected.  Found this issue while trying to improve test-case for MAPREUCE-913.,Closed,Fixed,,Zhong Wang,Vinod Kumar Vavilapalli,Fri; 20 Nov 2009 05:52:45 +0000,Mon; 12 Dec 2011 06:18:45 +0000,Thu; 17 Jun 2010 10:42:52 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1225
MAPREDUCE-1226,Improvement,Minor,jobtracker;task;tasktracker,Granularity Variable Task Pre-Scheduler in Heterogeneous Environment ,As we deploy the LATE scheduler of the OSDI08 paper; upon some of our cluster enviroments; some slow nodes may be assigned tasks that every time run slowly and be re-executed then killed; so we found these nodes are always with no use and waste the assigned task slots. In the LATE mechanism; we re-execute some of the tasks; so these tasks run on different node twice or more; then this cause some waste of the calculating resources.  Easily; we can remove these node out of the cluster or split the cluster into two or more. But I think it's useful and significant to design a mechanism to help low utility nodes to be effect.  We want to pre-schedule the tasks with the utility based on node historical logs; then assign larger size tasks to the fast nodes. In Hadoop task scheduler; we assign the map task in default splits of 64M. Some may split it into 128M. But; most of them are of the same granularity. So I want to alter this mechanism to a granularity variable one.  As we know; the Map task granularity depends on the DFS file size; while the Reduce task's depends on the Partitioner to split the intermediate results. So I think this is feasible to get the granularity variable mechanism.  If we use the pre-schedule model; then we can expect all the tasks can start at a nearly same time and finish at a nearly same time; and the job can fill a specific time slot.   History-Log-Based nodes Utility description This is the fundamental description of nodes for the pre-scheduler. And in the heterogeneous environment; the cluster can be split into different sub-cluster; and within the sub-cluster the nodes are homogeneous and between the sub-cluster the nodes are heterogeneous.  Nodes Utility Stability We think this is important for the pre-scheduler depends on the stability of the nodes. And we could pick the bad stability nodes up and treat them differently; but we haven't have good method to handle this.   Error tolerant I think the original scheduler in the homogeneous cluster is designed to handle the error nodes; if some nodes get exceptions; the JobTracker re-execute them; and handle these exceptions dynamically.  So if we use the pre-scheduler; we must face the problem of the exceptions. I propose that if some tasks got exceptions; we split the task into more than one part and execute them on more than one different nodes; then the expected finish time will be shorten; and the total job response time will not be too long.  Job Priorities If we use this pre-scheduler; single job will fill the time slot; and if then will be some other high-priority jobs; they will wait. And I don't get effect methods to solve this.,Open,Unresolved,,Unassigned,Zhaoning Zhang,Fri; 20 Nov 2009 07:59:45 +0000,Wed; 2 Dec 2009 19:59:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1226
MAPREDUCE-1227,New Feature,Major,,Allow JobTracker to pause task scheduling,We want to have an ability to pause task scheduling in JobTracker.  The idea is: make job tracker still accept new jobs; but delay their running and do not schedule any new tasks from the currently running jobs.  It will help for example restarting the DFS cluster without affecting jobs: pause execution; restart the DFS; running tasks will fail; but will not be scheduled until the execution is resumed; so the job does not fail.  In general it should help fix non MR problems (DFS; network; etc.) while not failing running jobs and keep accepting new ones.  What do people think of the general idea?,Resolved,Won't Fix,,Unassigned,Dmytro Molkov,Fri; 20 Nov 2009 21:12:39 +0000,Wed; 24 Mar 2010 20:02:37 +0000,Wed; 24 Mar 2010 20:02:37 +0000,,0.22.0,,MAPREDUCE-207,,https://issues.apache.org/jira/browse/MAPREDUCE-1227
MAPREDUCE-1228,Bug,Major,task,OutOfMemoryErrors in ReducerTask due to int overflow on >2G RAM tasks,The ReduceTask RAMManager uses ints for tracking amounts of memory. For tasks with 2G RAM allocated; these can overflow and cause memory usage to become incorrectly tracked and run away.,Resolved,Duplicate,MAPREDUCE-1182,Todd Lipcon,Todd Lipcon,Sat; 21 Nov 2009 00:21:07 +0000,Sat; 21 Nov 2009 00:33:28 +0000,Sat; 21 Nov 2009 00:33:28 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1228
MAPREDUCE-1229,Improvement,Major,contrib/mumak,[Mumak] Allow customization of job submission policy,Currently; mumak replay job submission faithfully. To make mumak useful for evaluation purposes; it would be great if we can support other job submission policies such as sequential job submission; or stress job submission.,Closed,Fixed,,Hong Tang,Hong Tang,Sat; 21 Nov 2009 13:00:37 +0000,Tue; 24 Aug 2010 21:19:21 +0000,Wed; 2 Dec 2009 03:45:14 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1229
MAPREDUCE-1230,Bug,Major,contrib/vertica,Vertica streaming adapter doesn't handle nulls in all cases,Test user reported that Vertica adapter throws an npe when retrieving null values for certain types (binary; numeric both reported).  There is no special case handling when serializing nulls.,Closed,Fixed,,Omer Trajman,Omer Trajman,Sat; 21 Nov 2009 16:23:56 +0000,Tue; 24 Aug 2010 21:19:22 +0000,Wed; 9 Dec 2009 10:39:03 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1230
MAPREDUCE-1231,Improvement,Major,distcp,Distcp is very slow,Currently distcp does a checksums check in addition to file length check to decide if a remote file has to be copied. If the number of files is high (thousands); this checksum check is proving to be fairly costly leading to a long time before the copy is started.,Closed,Fixed,,Jothi Padmanabhan,Jothi Padmanabhan,Mon; 23 Nov 2009 04:15:15 +0000,Tue; 24 Aug 2010 21:19:23 +0000,Mon; 30 Nov 2009 18:41:57 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1231
MAPREDUCE-1232,Bug,Major,capacity-sched,Job info for root level queue does not print correct values,"Job info for root level queue does not print correct values. Test case -: [    Queue Name= q1    Its sub-queues are Sq1; Sq2.    Submit around 8 jobs to each queue Sq1 and Sq2; (Out of these 2 jobs from each queue starts running)    Job Info for each queue Sq1 and Sq2 prints -:       Job info       Number of Waiting Jobs: 6       Number of users who have submitted jobs: 1    While Job Info for q1 (parent of Sq1 and Sq2) prints -:     Job info     Number of Waiting Jobs: 0     Number of users who have submitted jobs: 0 ] For root level either we should remove ""Job Info"" or we should print cumulative values of ""waiting jobs"" and ""users who submitted jobs"" from child queues",Open,Unresolved,,Unassigned,Karam Singh,Mon; 23 Nov 2009 11:56:54 +0000,Mon; 23 Nov 2009 11:56:54 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1232
MAPREDUCE-1233,Bug,Major,jobtracker,Incorrect Waiting maps/reduces in Jobtracker metrics ,Waiting Maps reduce got incremented and doesn't get decremented even after job cleanup.,Resolved,Fixed,,Luke Lu,V.Karthikeyan,Mon; 23 Nov 2009 11:59:57 +0000,Mon; 9 Apr 2012 20:10:01 +0000,Mon; 9 Apr 2012 20:10:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1233
MAPREDUCE-1234,Bug,Minor,client,getJobID() returns null on org.apache.hadoop.mapreduce.Job after job was submitted,After an instance of org.apache.hadoop.mapreduce.Job is submitted via submit() the method getJobID() returns null.  The code of the submit() method should include something like: setJobID(info.getJobID());  after info = jobClient.submitJobInternal(conf);,Resolved,Duplicate,MAPREDUCE-118,Unassigned,Thomas Kathmann,Mon; 23 Nov 2009 15:34:30 +0000,Fri; 4 Dec 2009 08:46:27 +0000,Fri; 4 Dec 2009 08:46:27 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1234
MAPREDUCE-1235,Bug,Minor,,java.io.IOException: Cannot convert value '0000-00-00 00:00:00' from column 6 to TIMESTAMP. ,Description:  io.IOException: Cannot convert value '0000-00-00 00:00:00' from column 6 to TIMESTAMP.  Original question: http: cant_import_table?utm_content=reply_linkutm_medium=emailutm_source=reply_notification,Resolved,Fixed,,Aaron Kimball,valentina kroshilina,Mon; 23 Nov 2009 15:41:35 +0000,Fri; 2 Jul 2010 06:31:54 +0000,Wed; 23 Dec 2009 05:14:29 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1235
MAPREDUCE-1236,Improvement,Minor,,added LOG.isdebugenabled for LOG.debug() as noted in MAPREDUCE-1026,in  MAPREDUCE-1026 we introduces few LOG.debug() not constrained by LOG.isdebugenabed() . Fixing that.,Resolved,Won't Fix,,Boris Shkolnik,Boris Shkolnik,Mon; 23 Nov 2009 18:18:43 +0000,Tue; 29 Jul 2014 20:48:08 +0000,Tue; 29 Jul 2014 20:48:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1236
MAPREDUCE-1237,Bug,Major,,Job with no maps or reduces creates graph with XML parsing error,For some reason; a job that had zero maps and zero reduces got submitted.  When looking at the details of this job in the jobtracker ui; the map completion graph was an XML error rather than something more meaningful.,Resolved,Won't Fix,MAPREDUCE-2903,Unassigned,Allen Wittenauer,Mon; 23 Nov 2009 18:38:45 +0000,Wed; 2 Nov 2011 17:45:46 +0000,Wed; 2 Nov 2011 17:45:46 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1237
MAPREDUCE-1238,Bug,Major,jobtracker,mapred metrics shows negative count of waiting maps and reduces ,Negative waiting_maps and waiting_reduces count is observed in the mapred metrics,Closed,Fixed,,Thomas Graves,Ramya Sunil,Mon; 18 May 2009 09:32:57 +0000,Wed; 16 May 2012 20:45:14 +0000,Tue; 10 Apr 2012 20:15:02 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1238
MAPREDUCE-1239,Bug,Blocker,build,Mapreduce test build is broken after HADOOP-5107,nan,Closed,Fixed,,Giridharan Kesavan,Vinod Kumar Vavilapalli,Tue; 24 Nov 2009 11:32:38 +0000,Tue; 24 Aug 2010 21:19:23 +0000,Thu; 26 Nov 2009 16:26:24 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1239
MAPREDUCE-1240,Bug,Major,,refreshQueues does not work correctly when dealing with maximum-capacity,If we comment out or remove maximum-capacity property or set maximum-capacity=-1 for a queue which has maximum-capacity some value (say 60). After using command -: mapred mradmin -refreshQueues   When we check the Queue Scheduling from Web UI or from CLI it still retains old value and schedules tasks according up to old maximum-capacity if there no other job in cluster where the expected behavior maximum-capacity not retained,Resolved,Fixed,,Unassigned,Karam Singh,Wed; 25 Nov 2009 11:20:13 +0000,Tue; 29 Jul 2014 20:49:53 +0000,Tue; 29 Jul 2014 20:49:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1240
MAPREDUCE-1241,Bug,Blocker,,JobTracker should not crash when mapred-queues.xml does not exist,Currently; if you bring up the JobTracker on an old configuration directory; it gets a NullPointerException looking for the mapred-queues.xml file. It should just assume a default queue and continue.,Closed,Fixed,,Todd Lipcon,Owen O'Malley,Wed; 25 Nov 2009 13:25:44 +0000,Tue; 24 Aug 2010 21:19:24 +0000,Wed; 23 Dec 2009 03:50:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1241
MAPREDUCE-1242,Bug,Trivial,,Chain APIs error misleading,"Hi; I was using the ChainMapper Reducer APIs ; and in Class Chain line 207 the error thrown :   ""The Mapper output key class does not match the previous Mapper input key class""  Shouldn't this be ""The Mapper input key class does not match the previous Mapper Output key class"" ? Sort of misleads",Closed,Fixed,,Harsh J,Amogh Vasekar,Wed; 25 Nov 2009 15:31:34 +0000,Tue; 15 Nov 2011 00:48:23 +0000,Fri; 4 Mar 2011 04:53:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1242
MAPREDUCE-1243,Bug,Major,contrib/streaming,ant compile-test in contrib/streaming fails,Compile fails. It seems that hdfs-test jar file cannot be found. compile-test:      echo contrib: streaming       import org.apache.hadoop.hdfs.MiniDFSCluster;,Resolved,Duplicate,MAPREDUCE-1239,Dmytro Molkov,Scott Chen,Wed; 25 Nov 2009 23:08:02 +0000,Thu; 26 Nov 2009 06:23:02 +0000,Thu; 26 Nov 2009 03:35:29 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1243
MAPREDUCE-1244,Bug,Major,build,eclipse-plugin fails with missing dependencies,nan,Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Thu; 26 Nov 2009 08:59:34 +0000,Tue; 24 Aug 2010 21:19:25 +0000,Fri; 4 Dec 2009 21:47:50 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1244
MAPREDUCE-1245,Bug,Major,test,"TestFairScheduler fails with ""too many open files"" error",This was caused by MAPREDUCE-1103 and was observed after MAPREDUCE-1239.,Closed,Fixed,MAPREDUCE-1256,Sharad Agarwal,Vinod Kumar Vavilapalli,Thu; 26 Nov 2009 09:27:52 +0000,Tue; 24 Aug 2010 21:19:26 +0000,Wed; 2 Dec 2009 06:38:08 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1245
MAPREDUCE-1246,Bug,Major,jobtracker,JobTrackerStatistics/JobTrackerInstrumentation's tracker count will be incorrect if a live tracker is restarted on the same port,Consider a case where an active tracker is restarted and the tracker restarts on the same port. In such a case the jobtracker we will invoke JobTracker.loseTaskTracker() from processHeartbeat(). Later on the tracker is added back (addNewTracker()) which will update the tracker count in metrics andinstrumentation. But the problem is that when the old tracker is lost the metrics and instrumentation's tracker counts are not decremented resulting into incorrect trackers count.,Open,Unresolved,,Unassigned,Amar Kamat,Fri; 27 Nov 2009 10:44:21 +0000,Fri; 27 Nov 2009 10:51:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1246
MAPREDUCE-1247,New Feature,Major,,Send out-of-band heartbeat to avoid fake lost tasktracker,"Currently the TaskTracker report task status to jobtracker through heartbeat; sometimes if the tasktracker  lock the tasktracker to do some cleanup  job; like remove task temp data on disk; the heartbeat thread would hang for a long time while waiting for the lock; so the jobtracker just thought it had lost and would reschedule all its finished maps or un finished reduce on other tasktrackers; we call it ""fake lost tasktracker""; some times it doesn't acceptable especially when we run some large jobs.  So We introduce a out-of-band heartbeat mechanism to send an out-of-band heartbeat in that case.",Resolved,Fixed,,ZhuGuanyin,ZhuGuanyin,Mon; 30 Nov 2009 07:14:16 +0000,Tue; 29 Jul 2014 20:54:21 +0000,Tue; 29 Jul 2014 20:54:21 +0000,,,,,MAPREDUCE-1662,https://issues.apache.org/jira/browse/MAPREDUCE-1247
MAPREDUCE-1248,Improvement,Minor,contrib/streaming,Redundant memory copying in StreamKeyValUtil,I found that when MROutputThread collecting the output of  Reducer; it calls StreamKeyValUtil.splitKeyVal() and two local byte-arrays are allocated there for each line of output. Later these two byte-arrays are passed to variable key and val. There are twice memory copying here; one is the System.arraycopy() method; the other is inside key.set()   val.set().  This causes double times of memory copying for the whole output (may lead to higher CPU consumption); and frequent temporay object allocation.,Resolved,Fixed,,Ruibang He,Ruibang He,Mon; 30 Nov 2009 09:47:11 +0000,Wed; 23 Nov 2011 06:12:07 +0000,Thu; 8 Jul 2010 06:04:57 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1248
MAPREDUCE-1249,Bug,Blocker,task,mapreduce.reduce.shuffle.read.timeout's default value should be 3 minutes; in mapred-default.xml,mapreduce.reduce.shuffle.read.timeout has a value of 30;000 (30 seconds) in mapred-default.xml; whereas the default value in Fetcher code is 3 minutes. It should be 3 minutes by default; as it was in pre MAPREDUCE-353.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Mon; 30 Nov 2009 09:51:03 +0000,Tue; 24 Aug 2010 21:19:28 +0000,Fri; 4 Dec 2009 03:12:42 +0000,,0.21.0,,,MAPREDUCE-353,https://issues.apache.org/jira/browse/MAPREDUCE-1249
MAPREDUCE-1250,Improvement,Major,security,Refactor job token to use a common token interface,The idea is to use a common token interface for both job token and delegation token (HADOOP-6373) so that the RPC layer that uses them don't have to differentiate them.,Closed,Fixed,,Kan Zhang,Kan Zhang,Mon; 30 Nov 2009 19:00:55 +0000,Tue; 24 Aug 2010 21:19:29 +0000,Tue; 22 Dec 2009 01:37:02 +0000,,,,,HADOOP-4487,https://issues.apache.org/jira/browse/MAPREDUCE-1250
MAPREDUCE-1251,Bug,Major,,c++ utils doesn't compile,c++ utils doesn't compile on ubuntu karmic 64-bit. The latest patch for HADOOP-5611 needs to be applied first.,Resolved,Fixed,,Eli Collins,Eli Collins,Mon; 30 Nov 2009 06:18:11 +0000,Tue; 14 Jun 2011 18:47:32 +0000,Sat; 13 Feb 2010 03:09:17 +0000,,0.20.1;0.20.2;0.20.205.0;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1251
HADOOP-6439,Bug,Blocker,conf,Shuffle deadlocks on wrong number of maps,The new shuffle assumes that the number of maps is correct. The new JobSubmitter sets the old value. Something misfires in the middle causing:    WARN conf.Configuration: mapred.map.tasks is deprecated. Instead; use mapreduce.job.maps  But my reduces got stuck at 2 maps   12 when there were only 2 maps in the job.,Closed,Fixed,,V.V.Chaitanya Krishna,Owen O'Malley,Tue; 1 Dec 2009 01:05:58 +0000,Tue; 24 Aug 2010 20:41:18 +0000,Wed; 21 Apr 2010 19:38:29 +0000,,0.21.0;0.22.0,,,HADOOP-6105,https://issues.apache.org/jira/browse/HADOOP-6439
MAPREDUCE-1253,Improvement,Major,contrib/mumak,Making Mumak work with Capacity-Scheduler,In order to make the capacity-scheduler work in the mumak simulation environment; we have to replace the job-initialization threads of the capacity scheduler with classes that perform event-based initialization. We propose to use aspectj to disable the threads  of the JobInitializationPoller class used by the Capacity Scheduler; and then perform the corresponding initialization tasks through a simulation job-initialization class that receives periodic wake-up calls from the simulator engine.,Closed,Fixed,,Anirban Dasgupta,Anirban Dasgupta,Tue; 1 Dec 2009 01:20:52 +0000,Mon; 12 Dec 2011 06:18:57 +0000,Wed; 11 Aug 2010 18:56:51 +0000,,0.21.0;0.22.0,,MAPREDUCE-1695,,https://issues.apache.org/jira/browse/MAPREDUCE-1253
MAPREDUCE-1254,New Feature,Major,task;tasktracker,job.xml should add crc check in tasktracker and sub jvm.,Currently job.xml in tasktracker and subjvm are write to local disk through ChecksumFilesystem; and already had crc checksum information; but load the job.xml file without crc check. It would cause the mapred job finished successful but with wrong data because of disk error.  Example: The tasktracker and sub task jvm would load the default configuration if it doesn't successfully load the job.xml which maybe replace the mapper with IdentityMapper.,Open,Unresolved,,Unassigned,ZhuGuanyin,Tue; 1 Dec 2009 03:07:17 +0000,Thu; 10 Dec 2009 20:45:26 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1254
MAPREDUCE-1255,Task,Minor,,How to write a custom input format and record reader to read multiple lines of text from files,"Can someone explain how to override the ""FileInputFormat"" and ""RecordReader"" in order to be able to read multiple lines of text from input files in a single map task?  Here the key will be the offset of the first line of text and value will be the N lines of text.   I have overridden the class FileInputFormat:  public class MultiLineFileInputFormat 	extends FileInputFormatLongWritable; Text{ ... }  and implemented the abstract method:  public RecordReader createRecordReader(InputSplit split;                 TaskAttemptContext context)          throws IOException; InterruptedException  {...}  I have also overridden the recordreader class:  public class MultiLineFileRecordReader extends RecordReaderLongWritable; Text{...}  and in the job configuration; specified this new InputFormat class:  job.setInputFormatClass(MultiLineFileInputFormat.class);  When I  run this new map reduce program; i get the following  109) 	... 5 more",Resolved,Invalid,,Unassigned,Kunal Gupta,Tue; 1 Dec 2009 06:05:38 +0000,Tue; 1 Dec 2009 06:09:45 +0000,Tue; 1 Dec 2009 06:09:45 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1255
MAPREDUCE-1256,Bug,Major,,org.apache.hadoop.mapred.TestFairScheduler.testPoolAssignment (from TestFairScheduler) is failing in trunk,Trunk build is failing. The unit testcase that fail is:  org.apache.hadoop.mapred.TestFairScheduler.testPoolAssignment (from TestFairScheduler)   http:   Error Message Timeout occurred. Please note the time in the report does not reflect the time until the timeout. Stacktrace junit.framework.AssertionFailedError: Timeout occurred. Please note the time in the report does not reflect the time until the timeout,Resolved,Duplicate,MAPREDUCE-1245,Unassigned,Iyappan Srinivasan,Tue; 1 Dec 2009 06:25:24 +0000,Wed; 2 Dec 2009 05:14:34 +0000,Wed; 2 Dec 2009 05:14:09 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1256
MAPREDUCE-1257,New Feature,Major,,Ability to grab the number of spills,The counters should have information about the number of spills in addition to the number of spill records.,Resolved,Won't Fix,,Unassigned,Sriranjan Manjunath,Tue; 1 Dec 2009 09:34:38 +0000,Tue; 29 Jul 2014 20:56:38 +0000,Tue; 29 Jul 2014 20:56:38 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1257
MAPREDUCE-1258,Bug,Minor,contrib/fair-share,Fair scheduler event log not logging job info,The MAPREDUCE-706 patch seems to have left an unfinished TODO in the Fair Scheduler - namely; in the dump() function for periodically dumping scheduler state to the event log; the part that dumps information about jobs is commented out. This makes the event log less useful than it was before.  It should be fairly easy to update this part to use the new scheduler data structures (Schedulable etc) and print the data.,Closed,Fixed,,Matei Zaharia,Matei Zaharia,Wed; 2 Dec 2009 06:01:56 +0000,Tue; 24 Aug 2010 21:19:30 +0000,Sat; 19 Dec 2009 16:00:37 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1258
MAPREDUCE-1259,Bug,Major,build,Add SureLogic annotations' jar into Ivy and Eclipse configs,In order to use SureLogic analysis tools and allow their concurrency analysis annotations in HDFS code the annotations library has to be automatically pulled from a Maven repo. Also; it has to be added to Eclipse .classpath template.,Resolved,Won't Fix,,Edwin Chan,Konstantin Boudnik,Wed; 2 Dec 2009 18:49:19 +0000,Tue; 29 Jul 2014 20:57:33 +0000,Tue; 29 Jul 2014 20:57:33 +0000,,0.22.0,,MAPREDUCE-1592,HADOOP-6353;HDFS-801,https://issues.apache.org/jira/browse/MAPREDUCE-1259
MAPREDUCE-1260,Bug,Major,build,Update Eclipse configuration to match changes to Ivy configuration,The .eclipse_templates .classpath file doesn't match the Ivy configuration; so I've updated it to match.,Closed,Fixed,,Unassigned,Edwin Chan,Wed; 2 Dec 2009 20:00:41 +0000,Tue; 24 Aug 2010 21:19:30 +0000,Thu; 3 Dec 2009 02:40:36 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1260
MAPREDUCE-1261,Improvement,Major,contrib/mumak,Enhance mumak to implement a 'stress-test' for the JobTracker,I propose we enhance mumak to implement a proper 'stress-test' tool for the JobTracker. The idea is that we enhance mumak to have a mode where it can use the real JobTracker (and Scheduler of course) and mumak's SimulatedTaskTracker to run real workloads from production job-history traces. Clearly we will need to make necessary changes to allow the SimulatedTaskTrackers to run independently (a thread per SimulatedTT) in a distributed manner.  We can then simulate very large clusters and workloads using a handful of machines (say ~50 machines to simulate workload which originally ran on a 4000 node cluster); also we can use this to stress the JobTracker with synthetic workloads.  Thoughts?,Resolved,Won't Fix,,Unassigned,Arun C Murthy,Thu; 3 Dec 2009 06:39:50 +0000,Tue; 29 Jul 2014 20:58:50 +0000,Tue; 29 Jul 2014 20:58:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1261
MAPREDUCE-1262,Bug,Major,,Eclipse Plugin does not build for Hadoop 0.20.1,When trying to run the build script for the Eclipse Plugin in src common.,Resolved,Duplicate,MAPREDUCE-1280,Unassigned,Stephen Watt,Tue; 3 Nov 2009 22:12:34 +0000,Fri; 11 Nov 2011 09:07:12 +0000,Tue; 21 Sep 2010 00:42:41 +0000,,0.20.1;0.20.2;0.21.0;0.22.0,,MAPREDUCE-1299,,https://issues.apache.org/jira/browse/MAPREDUCE-1262
MAPREDUCE-1263,Test,Major,,Hudson doesn't run MapredTestDriver,It doesn't look like src hadoop that don't have file names beginning with Test (ie not picked up by junit). Intentional?,Resolved,Won't Fix,,Unassigned,Eli Collins,Thu; 3 Dec 2009 19:27:59 +0000,Tue; 29 Jul 2014 21:05:05 +0000,Tue; 29 Jul 2014 21:05:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1263
MAPREDUCE-1264,Bug,Major,,Error Recovery failed; task will continue but run forever as new data only comes in very very slowly,Hi;  Sometimes; some of my jobs (It normally always happens in the reducers and on random basis) will not finish and will run forever. I have to manually fail the task so the task will be started and be finished.  The error log on the node is full of entries like:  2239) The error entries all refer to the same data block.  Unfortunately; the reduce function still seems to be called in the reducer with valid data (although very very slowly); so the task will never been killed and restarted and will take forever to run!  If I kill the task; the job will finish without any problems.   I experienced the same problem under version 0.20.0 as well.   Thanks; Thibaut,Resolved,Incomplete,,Unassigned,Thibaut,Thu; 3 Dec 2009 22:27:21 +0000,Tue; 29 Jul 2014 21:07:55 +0000,Tue; 29 Jul 2014 21:07:55 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1264
MAPREDUCE-1265,Improvement,Trivial,,Include tasktracker name in the task attempt error log,When task tempt id to find the TT. This is not very convenient.   It will be nice if  we can also log the tasktracker which causes this error. This way we can just grep the hostname to quickly find all the relevant error message.,Closed,Fixed,,Scott Chen,Scott Chen,Fri; 4 Dec 2009 00:11:22 +0000,Tue; 24 Aug 2010 21:19:31 +0000,Mon; 21 Dec 2009 22:39:57 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1265
MAPREDUCE-1266,Improvement,Minor,jobtracker;task;tasktracker,Allow heartbeat interval smaller than 3 seconds for tiny clusters,"For small clusters; the heartbeat interval has a large effect on job latency. This is especially true on pseudo-distributed or other ""tiny"" (5 nodes) clusters. It's not a big deal for production; but new users would have a happier first experience if Hadoop seemed snappier.  I'd like to change the minimum heartbeat interval from 3.0 seconds to perhaps 0.5 seconds (but have it governed by an undocumented config parameter in case people don't like this change). The cluster size-based ramp up of interval will maintain the current scalable behavior for large clusters with no negative effect.",Resolved,Duplicate,MAPREDUCE-1906,Unassigned,Todd Lipcon,Fri; 4 Dec 2009 22:32:16 +0000,Tue; 10 May 2011 23:02:13 +0000,Tue; 10 May 2011 23:02:13 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1266
MAPREDUCE-1267,Bug,Minor,,Fix typo in mapred-default.xml,There's a typo of mapreduce.client.progerssmonitor.pollinterval instead of mapreduce.client.progressmonitor.pollinterval in mapred-default. Trivial patch to fix.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 4 Dec 2009 23:11:59 +0000,Tue; 24 Aug 2010 21:19:32 +0000,Wed; 9 Dec 2009 09:22:18 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1267
MAPREDUCE-1268,Improvement,Major,contrib/streaming;test,Update streaming tests to JUnit 4 style,Suggested by Chris in MAPREDUCE-1155,Resolved,Duplicate,MAPREDUCE-1155,Todd Lipcon,Todd Lipcon,Fri; 4 Dec 2009 23:15:22 +0000,Mon; 4 Jan 2010 23:18:34 +0000,Mon; 4 Jan 2010 23:18:34 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1268
MAPREDUCE-1269,Bug,Major,,Failed on write sequence files in mapper.,"Because the sort phase is not necessary for my job; I want to write only values into sequence files by keys. So I set a hashmap into mapper:   	private HashMapString; Writer hm;  and I find a suitable org.apache.hadoop.io.SequenceFile.Writer by HashMap:   		Writer seqWriter = hm.get(skey); 		if (seqWriter==null){ 			try  { 				seqWriter = new SequenceFile.Writer(new JobClient(job).getFs() 						; job; new Path(pPathOut; skey); VLongWritable.class; ByteWritable.class); 			}  catch (IOException e)  { 				e.printStackTrace(); 			} 			if (seqWriter!=null) { 				hm.put(skey; seqWriter); 			} else { 				return; 			} 		}  The file names are obtained from job.get(""mapred.task.id""); that insure no replicas exist. The system always outputs :    170)  In fact; each mapper only write 16 sequence files; that will not be overloads to the hadoop system.",Open,Unresolved,,Unassigned,YangLai,Sat; 5 Dec 2009 13:05:42 +0000,Tue; 10 Jul 2012 21:27:10 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1269
MAPREDUCE-1270,Improvement,Major,task,Hadoop C++ Extention,"Hadoop C++ extension is an internal project in baidu; We start it for these reasons:    1  To provide C++ API. We mostly use Streaming before; and we also try to use PIPES; but we do not find PIPES is more efficient than Streaming. So we   think a new C++ extention is needed for us.    2  Even using PIPES or Streaming; it is hard to control memory of hadoop map leaf?id=0B5xhnqH1558YZjcxZmI0NzEtODczMy00NmZiLWFkNjAtZGM1MjZkMmNkNWFkhl=zh_CNpli=1 This is a full package with all hadoop source code. Following document ""HCE InstallMenu.pdf"" in attachment; you will build and deploy it in your cluster.  Attachment ""HCE Tutorial.pdf"" will lead you to write the first HCE program and give other specifications of the interface.  Attachment ""HCE Performance Report.pdf"" gives a performance report of HCE compared to Java MapRed and Pipes.  Any comments are welcomed.",Resolved,Duplicate,MAPREDUCE-2841,Unassigned,Wang Shouyan,Mon; 7 Dec 2009 08:09:23 +0000,Wed; 13 Apr 2016 16:00:49 +0000,Fri; 6 Nov 2015 01:46:55 +0000,,0.20.1,,,MAPREDUCE-2446;MAPREDUCE-2841,https://issues.apache.org/jira/browse/MAPREDUCE-1270
MAPREDUCE-1271,Bug,Major,,mapred.TestJobHistory.testDoneFolderOnHDFS is failing,"The latest trunk build is failing with the following error :  org.apache.hadoop.mapred.TestJobHistory.testDoneFolderOnHDFS (from TestJobHistory)   Error Message Config for completed jobs doesnt exist Stacktrace junit.framework.AssertionFailedError: Config for completed jobs doesnt exist 	at org.apache.hadoop.mapred.TestJobHistory.testDoneFolderOnHDFS(TestJobHistory. 671)   Seems like MAPREDUCE-1185 might be the reason; since it was changing the URL of Job history.  http: ",Open,Unresolved,,Unassigned,Iyappan Srinivasan,Tue; 8 Dec 2009 05:36:57 +0000,Tue; 8 Dec 2009 11:47:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1271
MAPREDUCE-1272,Bug,Major,task,_temporary directories could be left in output directory sometimes,After a job-cleanup task cleans up _temporary directory; there are chances that a speculative attempt could create it again since create file api creates all parent directories. More discussion at this and this,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Tue; 8 Dec 2009 07:34:03 +0000,Tue; 10 Jul 2012 21:27:08 +0000,,,0.20.1,,HADOOP-6418,,https://issues.apache.org/jira/browse/MAPREDUCE-1272
MAPREDUCE-1273,Test,Major,test,TaskTracker.shutdown() spends lot of time in shutting down jetty,While testing; I found that the jetty shutdown took ~8mins. This impacts the junit tests.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Tue; 8 Dec 2009 08:45:05 +0000,Sat; 26 Nov 2016 01:57:30 +0000,Sat; 26 Nov 2016 01:57:30 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1273
MAPREDUCE-1274,Bug,Major,security,The completed job web ui urls include full path names to the local file system on the JobTracker.,Currently; the web ui for MapReduce in 0.21.0-dev include a path to a local file in the url:  http: passwd or some other annoying trick.   I suspect the answer is applying MAPREDUCE-1185 back to 0.21.,Open,Unresolved,,Unassigned,Owen O'Malley,Tue; 8 Dec 2009 17:56:35 +0000,Tue; 10 Jul 2012 21:27:07 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1274
MAPREDUCE-1275,Bug,Major,build,Several Hudson build tests are failing with NoClassDefFoundError; unrelated to the patches being tested,Over the past few days; several Hudson validation tests for patches have been failing with NoClassDefFoundError. See MAPREDUCE:952; MAPREDUCE:1201.  These failures are definitely unrelated to the patches being tested.,Resolved,Cannot Reproduce,,Unassigned,Jothi Padmanabhan,Wed; 9 Dec 2009 08:15:37 +0000,Thu; 17 Mar 2016 16:19:49 +0000,Thu; 17 Mar 2016 16:19:48 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1275
MAPREDUCE-1276,Bug,Blocker,task,Shuffle connection logic needs correction ,While looking at the code with Amareshwari; we realized that  Fetcher#copyFromHost marks connection as successful when url.openConnection returns. This is wrong. Connection is done inside implicitly inside getInputStream; we need to split getInputStream into connect and getInputStream to handle the connection and read time out strategies correctly.,Closed,Fixed,,Amareshwari Sriramadasu,Jothi Padmanabhan,Wed; 9 Dec 2009 09:44:35 +0000,Tue; 24 Aug 2010 21:19:32 +0000,Thu; 20 May 2010 09:29:59 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1276
MAPREDUCE-1277,Bug,Major,contrib/streaming,Streaming job should support other characterset in user's stderr log; not only utf8,Current implementation in streaming  only support utf8 encoded user stderr log; it should encode free to support other characterset.,Open,Unresolved,,ZhuGuanyin,ZhuGuanyin,Wed; 9 Dec 2009 10:28:13 +0000,Fri; 2 Jul 2010 00:04:12 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1277
MAPREDUCE-1278,Bug,Major,test,Test-suite for JobQueueClient isn't comprehensive,"TestJobQueueClient isn't comprehensive. We need more tests to verify   	displayQueueInfo with jobs' list 	displayQueueAclsInfoForCurrentUser In addition; we should verify the actual output of each command; instead of testing internal methods.",Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Wed; 9 Dec 2009 10:37:50 +0000,Fri; 2 Jul 2010 00:04:15 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1278
MAPREDUCE-1279,Bug,Major,client;jobtracker,mapred queue -list will unnecessarily download JobStatus information also,mapred queue -list does a Cluster.getRootQueues() and thus will download the entire queue-hierarchy including all the (potentially large number of) jobs' information. This is not needed and avoiding it can significantly lower the data transferred from JT.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Wed; 9 Dec 2009 10:43:31 +0000,Wed; 9 Dec 2009 10:44:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1279
MAPREDUCE-1280,Bug,Major,,Eclipse Plugin does not work with Eclipse Ganymede (3.4),"The newest version of Eclipse seems incompatible with the plugin. The plugin as released in 0.16.4 will allow you to add  directory does not fix the issue; it is in fact worse: Eclipse does not seem to regard the 0.17 plugin as real. No ""MapReduce Perspective"" is made available in the perspectives selection window.",Closed,Fixed,,Alex Kozlov,Aaron Kimball,Thu; 10 Jul 2008 19:29:59 +0000,Wed; 7 Dec 2011 10:46:37 +0000,Wed; 22 Sep 2010 20:57:49 +0000,,0.20.1;0.21.1;0.22.0,,MAPREDUCE-1299,MAPREDUCE-1282;HADOOP-3884,https://issues.apache.org/jira/browse/MAPREDUCE-1280
MAPREDUCE-1281,Bug,Major,contrib/eclipse-plugin,Project Split Issue : Eclipse-Plugin under the Common Project in JIRA but the code is under the MapReduce project,contrib eclipse-plugin is still listed under the Common Project in JIRA even though the code has been moved to the MapReduce project. As it stands; if one opens a JIRA issue for the eclipse plugin under the common project; one cannot provide a patch and resolve it as the code does not exist in that project.,Resolved,Fixed,,Unassigned,Stephen Watt,Mon; 7 Dec 2009 20:54:06 +0000,Wed; 9 Dec 2009 11:15:41 +0000,Wed; 9 Dec 2009 11:15:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1281
MAPREDUCE-1282,Bug,Major,contrib/eclipse-plugin,eclipse plugin cannot be compiled in in windows,It seems that build-contrib.xml messed up the path.,Resolved,Duplicate,MAPREDUCE-1280,Unassigned,Tsz Wo Nicholas Sze,Tue; 30 Sep 2008 02:04:24 +0000,Thu; 2 Sep 2010 22:46:36 +0000,Thu; 2 Sep 2010 22:46:36 +0000,,,,,MAPREDUCE-1280,https://issues.apache.org/jira/browse/MAPREDUCE-1282
MAPREDUCE-1283,Improvement,Minor,contrib/eclipse-plugin,Support including 3rd party jars supplied in lib/ folder of eclipse project in hadoop jar,Currently; the eclipse plugin only exports the generated class files to the hadoop jar but if there are any 3rd party jars specified in the lib  folder; they should also get packaged in the jar for submission to the cluster. Currently this has to be done manually which can slow down development. I am working on a patch to the current plugin to support this.,Resolved,Incomplete,,Unassigned,Amit Nithian,Sun; 17 May 2009 00:06:16 +0000,Tue; 22 Jul 2014 19:38:28 +0000,Tue; 22 Jul 2014 19:38:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1283
MAPREDUCE-1284,Bug,Major,tasktracker;test,TestLocalizationWithLinuxTaskController fails,With current trunk; the testcase TestLocalizationWithLinuxTaskController fails with an exit code of 139 from task-controller when doing INITIALIZE_USER,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 9 Dec 2009 11:50:28 +0000,Tue; 24 Aug 2010 21:19:33 +0000,Fri; 18 Dec 2009 06:42:26 +0000,,0.22.0,,MAPREDUCE-896;MAPREDUCE-1186,,https://issues.apache.org/jira/browse/MAPREDUCE-1284
MAPREDUCE-1285,Bug,Major,distcp,DistCp cannot handle -delete if destination is local filesystem,The following exception is thrown:,Closed,Fixed,,Peter Romianowski,Peter Romianowski,Wed; 9 Dec 2009 18:50:28 +0000,Tue; 24 Aug 2010 21:19:34 +0000,Fri; 11 Dec 2009 01:31:30 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1285
MAPREDUCE-1286,Bug,Major,task,Quotes in environment HADOOP_CLIENT_OPTS confuse parsing if this env is concatenated with something else,"I use streaming and in the perl-reducer I write to hdfs using  a pipe to hdfs -put - ....    It turns out that because TaskRunner sets the environment HADOOP_CLIENT_OPTS in double quotes; when hdfs shell script concatenates these with something else; the command fails: .e.g  -Dblah=x -Dfoo=y ""-Dhadoop.tasklog.taskid=z -Dhadoop.tasklog.totalLogFileSize=s""...  Since I don't see any reason to have these double quotes in the original code; I propose they're removed.",Reopened,Unresolved,,Yuri Pradkin,Yuri Pradkin,Wed; 9 Dec 2009 18:51:45 +0000,Mon; 21 Jun 2010 01:36:17 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1286
MAPREDUCE-1287,Improvement,Minor,,Avoid calling Partitioner with only 1 reducer,Partitioners are currently called for each record; even though all are destined for the same reduce.,Closed,Fixed,,Chris Douglas,Ed Mazur,Wed; 9 Dec 2009 20:55:57 +0000,Thu; 30 Jun 2011 05:42:13 +0000,Mon; 25 Jan 2010 04:49:52 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1287
MAPREDUCE-1288,Bug,Critical,distributed-cache;security;tasktracker,DistributedCache localizes only once per cache URI,As part of the file localization the distributed cache localizer creates a copy of the file in the corresponding user's private directory. The localization in DistributedCache assumes the key as the URI of the cachefile and if it already exists in the map; the localization is not done again. This means that another user cannot access the same distributed cache file. We should change the key to include the username so that localization is done for every user.,Closed,Fixed,,Devaraj Das,Devaraj Das,Thu; 10 Dec 2009 22:30:37 +0000,Mon; 12 Dec 2011 06:19:25 +0000,Mon; 2 Aug 2010 18:19:27 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1288
MAPREDUCE-1289,Bug,Blocker,test,TestTrackerDistributedCacheManagerWithLinuxTaskController fails,TestTrackerDistributedCacheManagerWithLinuxTaskController fails with INITIALIZE_DISTRIBUTED_CACHE failing in trunk.,Resolved,Duplicate,MAPREDUCE-1186,Amareshwari Sriramadasu,Ravi Gummadi,Fri; 11 Dec 2009 07:27:42 +0000,Wed; 16 Dec 2009 10:32:06 +0000,Wed; 16 Dec 2009 10:32:06 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1289
MAPREDUCE-1290,Bug,Major,,DBOutputFormat does not support rewriteBatchedStatements when using MySQL jdbc drivers,The DBOutputFormat adds a semi-colon to the end of the INSERT statement that it uses to save fields to the database.  Semicolons are typically used in command line programs but are not needed when using the JDBC API.  In this case; the stray semi-colon breaks rewriteBatchedStatement support. See: http: read.php?39;271526;271526#msg-271526 for an example.  In my use case; rewriteBatchedStatement is very useful because it increases the speed of inserts and reduces memory consumption.,Resolved,Fixed,,Unassigned,Joe Crobak,Sat; 12 Dec 2009 19:49:21 +0000,Fri; 8 May 2015 18:48:44 +0000,Fri; 8 May 2015 18:48:44 +0000,,0.20.1,DBOutoutFormat;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-1290
MAPREDUCE-1291,Bug,Blocker,jobtracker,JobTracker holds stale references to retired jobs via setup tasks,JobTracker fails to remove setup tip mapping from taskidToTIPMap if the job gets killed before the setup returns.  Here is the scenario : 1) job inits 2) setup task is launched on tt1 and an entry is made in taskidToTIPMap 3) job is killed 4) cleanup gets launched on tt2 5) cleanup returns KILLING the job and removing all the completed setup reduce mappings from taskidToTIPMap are removed  In the end the setup tip still lingers in the taskidToTIPMap map. Because of the backreference from the tip to jip; the whole job stays in memory forever.,Resolved,Fixed,,Amar Kamat,Amar Kamat,Mon; 14 Dec 2009 09:00:10 +0000,Thu; 11 Feb 2010 11:29:52 +0000,Thu; 11 Feb 2010 11:29:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1291
MAPREDUCE-1292,Bug,Major,,many testcases are failing in trunk with org.apache.hadoop.ipc.RPC.waitForProxy error.,nan,Resolved,Fixed,,Unassigned,rahul k singh,Mon; 14 Dec 2009 11:44:17 +0000,Tue; 29 Jul 2014 21:08:51 +0000,Tue; 29 Jul 2014 21:08:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1292
MAPREDUCE-1293,Bug,Major,contrib/streaming,AutoInputFormat doesn't work with non-default FileSystems,AutoInputFormat uses the wrong FileSystem.get() method when getting a reference to a FileSystem object. AutoInputFormat gets the default FileSystem; so this method breaks if the InputSplit's path is pointing to a different FileSystem.,Closed,Fixed,,Andrew Hitchcock,Andrew Hitchcock,Mon; 14 Dec 2009 22:34:12 +0000,Tue; 24 Aug 2010 21:19:36 +0000,Fri; 1 Jan 2010 00:40:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1293
MAPREDUCE-1294,Bug,Critical,build,Build fails to pull latest hadoop-core-* artifacts,This is the same as HDFS-825 for mapreduce.,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Mon; 14 Dec 2009 23:44:30 +0000,Tue; 24 Aug 2010 21:19:37 +0000,Wed; 16 Dec 2009 03:39:27 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1294
MAPREDUCE-1295,New Feature,Major,tools/rumen,We need a job trace manipulator to build gridmix runs.,"Rumen produces ""job traces""; which are JSON format files describing important aspects of all jobs that are run successfully or not on a hadoop map reduce cluster.  There are two packages under development that will consume these trace files and produce actions in that cluster or another cluster: gridmix3 see jira MAPREDUCE-1124  and Mumak a simulator -- see MAPREDUCE-728 .  It would be useful to be able to do two things with job traces; so we can run experiments using these two tools: change the duration; and change the density.  I would like to provide a ""folder""; a tool that can wrap a long-duration execution trace to redistribute its jobs over a shorter interval; and also change the density by duplicating or culling away jobs from the folded combined job trace.",Closed,Fixed,,Dick King,Dick King,Tue; 15 Dec 2009 00:46:58 +0000,Tue; 24 Aug 2010 21:19:38 +0000,Fri; 8 Jan 2010 01:08:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1295
MAPREDUCE-1296,Bug,Major,capacity-sched,Tasks fail after the first disk (/grid/0/) of all TTs reaches 100%; even though other disks still have space.,Tasks fail after the first disk (  reaches 100% first; because of extra filling up of info like logs etc. After it reaches 100% tasks starts to fail with the error;    503)   This happens even though the other disks are still at 80%; so still can be filled up more.  Steps to reproduce:  1) Bring up  a cluster with Linux task controller. 2) Start filling the dfs up with data using randomwriter or teragen. 3) Once the first disk reaches 100%; the tasks are starting to fail.,Resolved,Fixed,,Unassigned,Iyappan Srinivasan,Tue; 15 Dec 2009 10:11:19 +0000,Tue; 29 Jul 2014 20:53:05 +0000,Tue; 29 Jul 2014 20:53:05 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1296
MAPREDUCE-1297,Bug,Major,build,MiniMRCluster.java compilation failure,compile-mapred-test:     mkdir Created dir:  testshell       1 error,Open,Unresolved,,Unassigned,Giridharan Kesavan,Tue; 15 Dec 2009 16:18:28 +0000,Tue; 15 Dec 2009 22:07:56 +0000,,,0.21.0,,,HADOOP-5901,https://issues.apache.org/jira/browse/MAPREDUCE-1297
MAPREDUCE-1298,Improvement,Minor,tasktracker,better access/organization of userlogs,Right now; it is quite a chore to browse to all userlogs generated during a given map or reduce phase.  It is quite easy to browse to a job and look  via URL? But I haven't found out how to in documentation.,Resolved,Won't Fix,,Unassigned,Meng Mao,Wed; 16 Dec 2009 01:22:40 +0000,Tue; 29 Jul 2014 21:14:51 +0000,Tue; 29 Jul 2014 21:14:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1298
MAPREDUCE-1299,Task,Major,build;contrib/eclipse-plugin,Hudson uses an old version of eclipse to test patches,As diagnosed here; Hudson may be using an old version of eclipse.,Resolved,Fixed,,Giridharan Kesavan,Chris Douglas,Wed; 16 Dec 2009 05:03:34 +0000,Tue; 21 Sep 2010 00:42:02 +0000,Tue; 21 Sep 2010 00:42:02 +0000,,,,MAPREDUCE-1262;MAPREDUCE-1280,,https://issues.apache.org/jira/browse/MAPREDUCE-1299
MAPREDUCE-1300,Improvement,Major,test,Hudson should be able to run Test*LinuxTaskController tests also.,It is difficult to find if a patch breaks any of the LinuxTaskController tests. Hudson should run Test*LinuxTaskController tests also as part of patch testing.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Wed; 16 Dec 2009 05:39:18 +0000,Fri; 2 Jul 2010 00:04:24 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1300
MAPREDUCE-1301,Bug,Major,test,TestDebugScriptWithLinuxTaskController fails ,After MAPREDUCE:879;  TestDebugScriptWithLinuxTaskController fails with following exception :   50),Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 16 Dec 2009 06:59:20 +0000,Tue; 24 Aug 2010 21:19:38 +0000,Wed; 23 Dec 2009 07:24:54 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1301
MAPREDUCE-1302,Improvement,Major,tasktracker,TrackerDistributedCacheManager can delete file asynchronously,With the help of AsyncDiskService from MAPREDUCE-1213; we should be able to delete files from distributed cache asynchronously.  That will help make task initialization faster; because task initialization calls the code that localizes files into the cache and may delete some other files. The deletion can slow down the task initialization speed.,Closed,Fixed,MAPREDUCE-1141,Zheng Shao,Zheng Shao,Wed; 16 Dec 2009 07:37:39 +0000,Tue; 24 Aug 2010 21:19:39 +0000,Tue; 12 Jan 2010 19:52:34 +0000,,0.20.2;0.21.0;0.22.0,,MAPREDUCE-1213,,https://issues.apache.org/jira/browse/MAPREDUCE-1302
MAPREDUCE-1303,Improvement,Major,,Merge org.apache.hadoop.mapred.CleanupQueue with MRAsyncDiskService,org.apache.hadoop.mapred.CleanupQueue is very similar to MRAsyncDiskService. We should be able to simplify the codebase by merging it into MRAsyncDiskService.,Open,Unresolved,,Zheng Shao,Zheng Shao,Wed; 16 Dec 2009 18:39:25 +0000,Wed; 16 Dec 2009 18:39:48 +0000,,,,,MAPREDUCE-1213,,https://issues.apache.org/jira/browse/MAPREDUCE-1303
MAPREDUCE-1304,New Feature,Major,task,Add counters for task time spent in GC,"It's easy to grab the number of millis spent in GC (see JvmMetrics for example). Exposing these as task counters would be handy - occasionally I've seen user jobs where long GC pauses cause big ""unexplainable"" performance problems; and a large counter would make it obvious to the user what's going on.",Closed,Fixed,,Aaron Kimball,Todd Lipcon,Wed; 16 Dec 2009 21:43:56 +0000,Tue; 24 Aug 2010 21:19:40 +0000,Sun; 25 Apr 2010 02:40:11 +0000,,,,,MAPREDUCE-901,https://issues.apache.org/jira/browse/MAPREDUCE-1304
MAPREDUCE-1305,Improvement,Major,distcp,Running distcp with -delete incurs avoidable penalties,"First problem  In org.apache.hadoop.tools.DistCp#deleteNonexisting we serialize FileStatus objects when the path is all we need.  The performance problem comes from org.apache.hadoop.fs.RawLocalFileSystem.RawLocalFileStatus#write which tries to retrieve file permissions by issuing a ""ls -ld path"" which is painfully slow.  Changed that to just serialize Path and not FileStatus.  Second problem  To delete the files we invoke the ""hadoop"" command line tool with option ""-rmr path"". Again; for each file.  Changed that to dstfs.delete(path; true)",Closed,Fixed,,Peter Romianowski,Peter Romianowski,Wed; 16 Dec 2009 22:32:58 +0000,Tue; 24 Aug 2010 21:19:41 +0000,Sat; 13 Feb 2010 10:11:35 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1305
MAPREDUCE-1306,Improvement,Major,contrib/mumak,[MUMAK] Randomize the arrival of heartbeat responses,"We propose to make the following changes to mumak; MAPREDUCE-728  	make the timing of heartbeat responses more realistic by adding an option to randomly perturb them 	randomize the startup time of task trackers in a fixed interval 	remove 2 magic constants from SimulatorEngine and make sure that the first job is submitted only after the entire cluster is up and running",Closed,Fixed,,Tamas Sarlos,Tamas Sarlos,Wed; 16 Dec 2009 23:38:57 +0000,Tue; 24 Aug 2010 21:19:42 +0000,Thu; 11 Mar 2010 02:38:45 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1306
MAPREDUCE-1307,Sub-task,Major,security,Introduce the concept of Job Permissions,"It would be good to define the notion of job permissions analogous to file permissions. Then the JobTracker can restrict who can ""read"" (e.g. look at the job page) or ""modify"" (e.g. kill) jobs.",Closed,Fixed,MAPREDUCE-1483,Vinod Kumar Vavilapalli,Devaraj Das,Thu; 17 Dec 2009 05:54:00 +0000,Tue; 24 Aug 2010 21:19:43 +0000,Sat; 20 Feb 2010 19:16:11 +0000,,,,MAPREDUCE-1455,MAPREDUCE-1455;MAPREDUCE-1483,https://issues.apache.org/jira/browse/MAPREDUCE-1307
MAPREDUCE-1308,Bug,Major,tasktracker,reduce tasks stall and are eventually killed,We recently migrated our 0.19.2 cluster from Gentoo Linux to Fedora Linux.  Everything was running smoothly before; but now about 5%-10% of our jobs have at least one reduce task that stalls out and is eventually killed with the message:        Task attempt_200912102211_1648_r_000009_0 failed to report status for 6003 seconds. Killing!  The task is then re-launched and completes successfully; usually in a couple of minutes.  This is problematic because our scheduled Hadoop jobs now take an extra hour-and-a-half to run (6000 seconds).  There are no indications in the logs that anything is amiss.  The task starts; a small amount of the copy shuffle runs; and then nothing is else is heard from the task until it is killed.  I will attach the relevant parts of the TaskTracker logs in the comments.,Resolved,Cannot Reproduce,,Unassigned,Brian Karlak,Thu; 17 Dec 2009 06:11:03 +0000,Tue; 29 Jul 2014 21:17:03 +0000,Tue; 29 Jul 2014 21:17:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1308
MAPREDUCE-1309,Improvement,Major,tools/rumen,I want to change the rumen job trace generator to use a more modular internal structure; to allow for more input log formats ,There are two orthogonal questions to answer when processing a job tracker log: how will the logs and the xml configuration files be packaged; and in which release of hadoop map reduce were the logs generated?  The existing rumen only has a couple of answers to this question.  The new engine will handle three answers to the version question: 0.18; 0.20 and current; and two answers to the packaging question: separate files with names derived from the job ID; and concatenated files with a header between sections used for easier file interchange.,Closed,Fixed,,Dick King,Dick King,Thu; 17 Dec 2009 23:25:22 +0000,Thu; 2 May 2013 02:29:28 +0000,Thu; 18 Feb 2010 18:43:49 +0000,,,,,MAPREDUCE-1459,https://issues.apache.org/jira/browse/MAPREDUCE-1309
MAPREDUCE-1310,Bug,Major,,CREATE TABLE statements for Hive do not correctly specify delimiters,Imports to HDFS via Sqoop that also inject metadata into Hive do not correctly specify delimiters; using Hive to access the data results in rows being parsed as NULL characters. See http: sqoop_hive_import_giving_null_query_values for an example bug report,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 18 Dec 2009 01:33:12 +0000,Fri; 2 Jul 2010 06:31:31 +0000,Tue; 5 Jan 2010 23:22:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1310
MAPREDUCE-1311,Bug,Major,test,TestStreamingExitStatus fails on hudson patch builds,TestStreamingExitStatus fails on hudson patch builds. The logs have the following error :    The same passes on my local machine.,Resolved,Duplicate,MAPREDUCE-1155,Unassigned,Amareshwari Sriramadasu,Fri; 18 Dec 2009 04:24:44 +0000,Mon; 4 Jan 2010 23:17:17 +0000,Mon; 4 Jan 2010 23:17:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1311
MAPREDUCE-1312,Bug,Major,build;test,TestStreamingKeyValue fails on hudson patch builds,TestStreamingKeyValue fails on hudson patch builds with FileNotFoundException. The failure log from one of the builds is @  http: ,Resolved,Duplicate,MAPREDUCE-1155,Unassigned,Amareshwari Sriramadasu,Fri; 18 Dec 2009 04:31:06 +0000,Mon; 4 Jan 2010 23:17:53 +0000,Mon; 4 Jan 2010 23:17:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1312
MAPREDUCE-1313,Bug,Major,,NPE in FieldFormatter if escape character is set and field is null,Performing an import with the &#45;escaped-by character set on a table with a null field will cause a NullPointerException in FieldFormatter,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 18 Dec 2009 04:34:37 +0000,Fri; 2 Jul 2010 06:31:33 +0000,Sun; 24 Jan 2010 23:13:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1313
MAPREDUCE-1314,Bug,Blocker,,Some logs have wrong configuration names.,After MAPREDUCE-849; some of the logs have wrong configuration names. For example :   INFO mapred.MapTask: mapreduce.task.mapreduce.task.io.sort.mb = 10,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 18 Dec 2009 08:19:02 +0000,Tue; 24 Aug 2010 21:19:45 +0000,Mon; 25 Jan 2010 04:28:27 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1314
MAPREDUCE-1315,Improvement,Minor,jobtracker,taskdetails.jsp and jobfailures.jsp should have consistent convention for machine names in case of lost task tracker,"Machine names displayed in taskdetails.jsp and jobfailures;jsp show inconsistency in convention in case of lost TT i.e in case of lost TT the machine name is displayed as ""tracker_hostname:localhost 127.0.0.1:port"" (not a hyperlink) whereas for other TTs the name displayed is hostname (hyperlink). Ideally the machine names should follow a single convention.",Resolved,Fixed,,Unassigned,Ramya Sunil,Fri; 18 Dec 2009 08:59:49 +0000,Tue; 29 Jul 2014 21:20:19 +0000,Tue; 29 Jul 2014 21:20:19 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1315
MAPREDUCE-1316,Bug,Blocker,jobtracker,JobTracker holds stale references to retired jobs via unreported tasks ,JobTracker fails to remove unreported tasks' mapping from taskToTIPMap if the job finishes and retires. Unreported tasks refers to tasks that were scheduled but the tasktracker did not report back with the task status. In such cases a stale reference is held to TaskInProgress (and thus JobInProgress) long after the job is gone leading to memory leak.,Closed,Fixed,,Amar Kamat,Amar Kamat,Fri; 18 Dec 2009 09:56:04 +0000,Tue; 24 Aug 2010 21:19:45 +0000,Tue; 19 Jan 2010 15:33:30 +0000,,,,,MAPREDUCE-1387;MAPREDUCE-1386,https://issues.apache.org/jira/browse/MAPREDUCE-1316
MAPREDUCE-1317,Improvement,Major,tools/rumen,Reducing memory consumption of rumen objects,We have encountered OutOfMemoryErrors in mumak and gridmix when dealing with very large jobs. The purpose of this jira is to optimze memory consumption of rumen produced job objects.,Closed,Fixed,,Hong Tang,Hong Tang,Fri; 18 Dec 2009 11:29:07 +0000,Tue; 24 Aug 2010 21:19:47 +0000,Fri; 8 Jan 2010 07:28:43 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1317
YARN-2334,Improvement,Major,documentation,Document exit codes and their meanings used by linux task controller.,Currently; linux task controller binary uses a set of exit code; which is not documented. These should be documented.,Resolved,Not A Problem,,Unassigned,Sreekanth Ramakrishnan,Tue; 26 May 2009 09:38:16 +0000,Fri; 1 May 2015 18:35:31 +0000,Fri; 1 May 2015 18:35:31 +0000,,,,,YARN-3567,https://issues.apache.org/jira/browse/YARN-2334
MAPREDUCE-1319,Improvement,Major,client,Refactor ClientProtocol.getSystemDir usage on the job client side to instead use ClientProtocol.getStagingAreaDir,MAPREDUCE-181 introduced ClientProtocol.getStagingAreaDir. It'd be good to refactor the client side where it infers the JobTracker's filesystem; etc. based on this. Seems like the client needn't invoke ClientProtocol.getSystemDir at all.,Open,Unresolved,,Devaraj Das,Devaraj Das,Mon; 21 Dec 2009 17:51:59 +0000,Thu; 13 Jan 2011 02:27:40 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1319
MAPREDUCE-1320,Improvement,Major,,StringBuffer -> StringBuilder occurence ,A good number of toString() implementations use StringBuffer when the reference clearly does not go out of scope of the method and no concurrency is needed. Patch contains replacing those occurences from StringBuffer to StringBuilder.   Created against map reduce project trunk .,Open,Unresolved,,Karthik K,Karthik K,Tue; 22 Dec 2009 00:23:00 +0000,Thu; 13 Jan 2011 02:27:50 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1320
MAPREDUCE-1321,Bug,Minor,tasktracker,Spurios logs with org.apache.hadoop.util.DiskChecker$DiskErrorException in TaskTracker,TaskTracker logs have spurious org.apache.hadoop.util.DiskChecker$DiskErrorException. These logs are for job setup cleanup tasks and for map tasks of jobs with no reduces.,Resolved,Duplicate,MAPREDUCE-1635,Unassigned,Amareshwari Sriramadasu,Tue; 22 Dec 2009 05:13:39 +0000,Tue; 13 Apr 2010 04:34:45 +0000,Tue; 13 Apr 2010 04:34:45 +0000,,0.20.1,,,HADOOP-4963,https://issues.apache.org/jira/browse/MAPREDUCE-1321
MAPREDUCE-1322,Bug,Major,contrib/streaming;test,TestStreamingAsDifferentUser fails on trunk,TestStreamingAsDifferentUser fails on trunk with following exception :  Can not create a Path from a null string  49)  The corresponding line for the exception :,Closed,Fixed,MAPREDUCE-1390,Devaraj Das,Amareshwari Sriramadasu,Tue; 22 Dec 2009 05:48:05 +0000,Tue; 24 Aug 2010 21:19:47 +0000,Fri; 29 Jan 2010 13:36:35 +0000,,0.22.0,,MAPREDUCE-1415;MAPREDUCE-890,MAPREDUCE-181,https://issues.apache.org/jira/browse/MAPREDUCE-1322
MAPREDUCE-1323,Bug,Major,,TestMiniMRWithDFS.testWithDFS (from TestMiniMRWithDFS) is failing,Trunk is failing with one junit test failing. ( 181) http:   org.apache.hadoop.mapred.TestMiniMRWithDFS.testWithDFS (from TestMiniMRWithDFS)  Failing for the past 1 build (Since #181 ) Took 2 ms. add description  Error Message Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit. Stacktrace junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.  Failing for the past 1 build (Since #181 ),Open,Unresolved,,Unassigned,Iyappan Srinivasan,Tue; 22 Dec 2009 08:49:16 +0000,Tue; 22 Dec 2009 08:49:16 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1323
MAPREDUCE-1324,Improvement,Minor,task,Make MapTask.MapOutputBuffer a standalone class,MapTask.MapOutputBuffer has few dependencies on its outer class; but is more than half its total length. It should be factored out into a separate class.,Open,Unresolved,,Chris Douglas,Chris Douglas,Tue; 22 Dec 2009 09:24:41 +0000,Tue; 22 Dec 2009 21:26:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1324
MAPREDUCE-1325,Bug,Major,task,Fix IsolationRunner to run with reduces too,HADOOP-4041 fixed various problems with IsolationRunner; but to keep the patch simple it completely broke it for reduces and postponed the effort for another issue. We should fix IsolationRunner to work with reduces here.,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Tue; 22 Dec 2009 10:24:09 +0000,Fri; 5 Aug 2011 12:02:56 +0000,Fri; 5 Aug 2011 12:02:56 +0000,,0.21.0,,,HADOOP-4041,https://issues.apache.org/jira/browse/MAPREDUCE-1325
MAPREDUCE-1326,Sub-task,Major,build,fi tests don't use fi-site.xml ,When fault injection framework was ported to the Mapreduce fi-site.xml is missed from the testing process. E.g. when the tests run they won't use FI configuration.,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Tue; 22 Dec 2009 17:16:15 +0000,Tue; 24 Aug 2010 21:19:49 +0000,Wed; 23 Dec 2009 00:27:31 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1326
MAPREDUCE-1327,Bug,Major,,Oracle database import via sqoop fails when a table contains the column types such as TIMESTAMP(6) WITH LOCAL TIME ZONE and TIMESTAMP(6) WITH TIME ZONE,"When Oracle table contains the columns ""TIMESTAMP(6) WITH LOCAL TIME ZONE"" and ""TIMESTAMP(6) WITH TIME ZONE""; Sqoop fails to map values for those columns to valid Java data types; resulting in the following exception:  ERROR sqoop.Sqoop: Got exception running Sqoop:  39)   I have modified the code for Hadoop and Sqoop so this bug is fixed on my machine. Please let me know if you would like me to generate the patch and upload it to this ticket.",Resolved,Fixed,,Leonid Furman,Leonid Furman,Tue; 22 Dec 2009 22:30:30 +0000,Fri; 2 Jul 2010 06:31:36 +0000,Mon; 25 Jan 2010 03:41:09 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1327
MAPREDUCE-1328,Bug,Major,contrib/index,contrib/index  - modify build / ivy files as appropriate ,The build   hadoop-hdfs-test .   Also the junit classpath is set to include the files retrieved by ivy ; specific to the index project.,Resolved,Won't Fix,,Unassigned,Karthik K,Tue; 22 Dec 2009 23:45:10 +0000,Tue; 29 Jul 2014 21:38:42 +0000,Tue; 29 Jul 2014 21:38:42 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1328
MAPREDUCE-1329,Improvement,Major,task,Make MapTask.MapOutputBuffer logic more understandable,As noted here; the collection logic could be clarified by explicitly separating states rather than inferring status by examining low-level markers. Similarly; abstractions for metadata; etc. should replace the offset arithmetic currently in use.,Open,Unresolved,,Chris Douglas,Chris Douglas,Wed; 23 Dec 2009 01:12:05 +0000,Wed; 23 Dec 2009 01:13:19 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1329
MAPREDUCE-1330,Improvement,Major,tools/rumen,[rumen] LoggedXXX objects should either be completely mutable or immutable,The current APIs of LoggedXXX objects in rumen do not allow the objects to be modified through setters (package private); but opens the door to modify the object by allowing callers to mutate the listT objects returned from the getters. This is confusing and based on the nature of such objects; it is probably a good idea to make the immutable.,Open,Unresolved,,Unassigned,Hong Tang,Wed; 23 Dec 2009 09:59:56 +0000,Fri; 2 Jul 2010 07:15:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1330
MAPREDUCE-1331,Bug,Major,test,TestMiniMRWithDFS.testWithDFSWithDefaultPort inadvertently mistyped,One of the patches; possibly MAPREDUCE-181; inadvertently mistyped TestMiniMRWithDFS.testWithDFSWithDefaultPort to tesWithDFSWithDefaultPort. As a result it wouldn't run as a JUnit test.,Resolved,Fixed,,Devaraj Das,Hemanth Yamijala,Thu; 24 Dec 2009 08:16:34 +0000,Tue; 5 Jan 2010 15:58:49 +0000,Thu; 24 Dec 2009 18:29:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1331
MAPREDUCE-1332,New Feature,Minor,,Ant tasks for job submission,"Ant tasks to make it easy to work with hadoop filesystem and submit jobs.   submit : uploads JAR; submits job as user; with various settings  filesystem operations: mkdir; copyin; copyout; delete  -We could maybe use Ant1.7 ""resources"" here; and so use hdfs as a source or dest in Ant's own tasks   	security. Need to specify user; pick up user.name from JVM as default? 	cluster binding: namenode job tracker (hostname;port) or url are all that is needed? #job conf: how to configure the job that is submitted? support a list of property name=""name"" value=""something"" children 	testing. AntUnit to generate junitreport compatible XML files 	Documentation. With an example using Ivy to fetch the JARs for the tasks and hadoop client. 	Polling: ant task to block for a job finished?",Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Mon; 26 Jan 2009 15:30:04 +0000,Thu; 2 May 2013 02:29:25 +0000,Sat; 18 Feb 2012 16:24:23 +0000,,0.22.0,,,HADOOP-2778;HADOOP-1508,https://issues.apache.org/jira/browse/MAPREDUCE-1332
MAPREDUCE-1333,Bug,Major,jobtracker;task;tasktracker,Parallel running tasks on one single node may slow down the performance,When I analysis running tasks performance; I found that parallel running tasks on one single node will not be better performance than the serialized ones. We can set mapred.tasktracker. {map|reduce} .tasks.maximum = 1 individually; but there will be parallel map AND reduce tasks.  And I wonder it's true in the real commercial clusters?,Resolved,Won't Fix,,Unassigned,Zhaoning Zhang,Fri; 25 Dec 2009 03:15:27 +0000,Tue; 29 Jul 2014 21:40:21 +0000,Tue; 29 Jul 2014 21:40:21 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1333
MAPREDUCE-1334,Bug,Major,contrib/index,contrib/index - test - TestIndexUpdater fails due to an additional presence of file _SUCCESS in hdfs ,$ cd src  suggestions on the same welcome.,Closed,Fixed,,Karthik K,Karthik K,Fri; 25 Dec 2009 10:17:28 +0000,Tue; 15 Nov 2011 00:50:01 +0000,Fri; 10 Dec 2010 02:12:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1334
MAPREDUCE-1335,New Feature,Major,,Add SASL DIGEST-MD5 authentication to TaskUmbilicalProtocol,Use job token as the credential for Task to local TaskTracker authentication over RPC.,Closed,Fixed,,Kan Zhang,Kan Zhang,Sat; 26 Dec 2009 02:14:06 +0000,Thu; 2 May 2013 02:29:22 +0000,Wed; 3 Feb 2010 03:07:47 +0000,,,,,HADOOP-4487,https://issues.apache.org/jira/browse/MAPREDUCE-1335
MAPREDUCE-1336,Test,Major,contrib/streaming;test,TestStreamingExitStatus - Fix deprecated use of StreamJob submission API,Fix deprecated API in StreamJob and executing the same.,Open,Unresolved,,Unassigned,Karthik K,Sat; 26 Dec 2009 23:49:48 +0000,Fri; 7 May 2010 05:36:24 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1336
MAPREDUCE-1337,Improvement,Major,,Generify StreamJob for better readability,Generify some of the members of StreamJob for better readability.,Closed,Fixed,,Karthik K,Karthik K,Mon; 28 Dec 2009 03:39:51 +0000,Tue; 24 Aug 2010 21:19:52 +0000,Mon; 25 Jan 2010 06:37:10 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1337
MAPREDUCE-1338,New Feature,Major,,need security keys storage solution,set; get; store; load security keys  key alias - byte[] key value - byte[]  store Output stream,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Tue; 20 Oct 2009 19:55:32 +0000,Tue; 24 Aug 2010 21:19:53 +0000,Thu; 21 Jan 2010 21:32:59 +0000,,,,,HADOOP-4487,https://issues.apache.org/jira/browse/MAPREDUCE-1338
MAPREDUCE-1339,Improvement,Critical,,Sqoop full table import job times out when using the split-by attribute,Problem ------------ When running sqoop command for full table import with split-by attribute specified; as follows:  sqoop --connect CONNECT_STRING --username USER_NAME --password PASSWORD --table TABLE_NAME --fields-terminated-by 0x01 --as-textfile  --warehouse-dir OUTPUT_DIR split-by RECORD_ID  Sqoop is going to transform the split-by attribute to ORDER BY clause and run the following query in SQL (say; Oracle):  SELECT * FROM TABLE_NAME ORDER BY RECORD_ID  If the table has; for example; 20 million records; the ORDER BY part will increase the query running significantly; eventually causing time out; and resulting in no output written to Hadoop file system.  Proposed solution ------------------------- Not to append the ORDER_BY clause to SQL query if no where clause is specified.  Can there be any issues with this solution?,Resolved,Duplicate,NULL,Unassigned,Leonid Furman,Tue; 29 Dec 2009 00:42:12 +0000,Fri; 2 Jul 2010 06:31:35 +0000,Mon; 3 May 2010 18:45:33 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1339
MAPREDUCE-1340,Improvement,Major,,Sqoop should close database connection in case of accidental interruption of command execution,If a sqoop command is running and suddenly interrupted or killed; all database connections should be automatically closed.  Currently the code catches  lang.InterruptedException; but it doesn't release and close the database connections in the catch block.  In case this issue is found to be a problem; I suppose it may require some code refactoring in the following classes:  org.apache.hadoop.sqoop.mapred.ImportJob org.apache.hadoop.sqoop.manager.SqlManager (and all its subclasses) org.apache.hadoop.sqoop.mapreduce.DataDrivenImportJob,Resolved,Won't Fix,,Unassigned,Leonid Furman,Tue; 29 Dec 2009 01:24:55 +0000,Fri; 2 Jul 2010 06:31:55 +0000,Mon; 3 May 2010 18:43:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1340
MAPREDUCE-1341,New Feature,Minor,,Sqoop should have an option to create hive tables and skip the table import step,In case the client only needs to create tables in hive; it would be helpful if Sqoop had an optional parameter:  --hive-create-only  which would omit the time consuming table import step; generate hive create table statements and run them.  If this feature seems useful; I can generate the patch. I have modified the Sqoop code and built it on my development machine; and it seems to be working well.,Resolved,Fixed,,Leonid Furman,Leonid Furman,Tue; 29 Dec 2009 01:50:56 +0000,Fri; 2 Jul 2010 06:31:34 +0000,Fri; 12 Feb 2010 05:16:47 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1341
MAPREDUCE-1342,Bug,Major,jobtracker,Potential JT deadlock in faulty TT tracking,JT$FaultyTrackersInfo.incrementFaults first locks potentiallyFaultyTrackers; and then calls blackListTracker; which calls removeHostCapacity; which locks JT.taskTrackers On the other hand; JT.blacklistedTaskTrackers() locks taskTrackers; then calls faultyTrackers.isBlacklisted() which goes on to lock potentiallyFaultyTrackers.  I haven't produced such a deadlock; but the lock ordering here is inverted and therefore could deadlock.  Not sure if this goes back to 0.21 or just in trunk.,Closed,Fixed,,Amareshwari Sriramadasu,Todd Lipcon,Tue; 29 Dec 2009 02:05:31 +0000,Tue; 24 Aug 2010 21:19:54 +0000,Tue; 19 Jan 2010 10:21:26 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1342
MAPREDUCE-1343,Improvement,Major,,Scope Change - FileOutputCommitter # SUCCESSFUL_JOB_OUTPUT_DIR_MARKER; package default to public ,Being a configuration property - it should be public static for apps to set  reset the property as opposed to hardcoding the string.   Scope changed from package default to public.   Also - enhanced with  ocs around the same.,Open,Unresolved,,Unassigned,Karthik K,Tue; 29 Dec 2009 21:02:47 +0000,Wed; 7 Sep 2011 08:20:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1343
MAPREDUCE-1344,Bug,Major,,Cluster.createClient only looks at deprecated mapred.job.tracker should look at mapreduce.jobtracker.address as well,"new Job(conf) calls new Cluster(conf) and Cluster's createClient method only looks for the ""mapred.job.tracker"" key; it should probably also look for the newer version of this ""mapreduce.jobtracker.address""  Note: this is only for the check if mapred.job.tracker is set to ""local""  however if this value is not found its default is ""local"" which will always happen unless this value is set to something else.",Open,Unresolved,,Unassigned,Chris Wilkes,Tue; 29 Dec 2009 23:10:43 +0000,Mon; 4 Jan 2010 03:49:15 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1344
MAPREDUCE-1345,Bug,Major,,JobTracker is slowed down because it forks subprocesses to do a df command,The JobTracker periodically does a df on the local directories. It forks a shell a shell to run a df command. The creation of the separate process is very slow because the process address space is copied by the OS on every subprocess creation. This becomes worse when the JT is configured to use a large heap space.,Resolved,Duplicate,HADOOP-5958,Scott Chen,dhruba borthakur,Wed; 30 Dec 2009 01:26:33 +0000,Wed; 30 Dec 2009 02:04:40 +0000,Wed; 30 Dec 2009 02:04:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1345
MAPREDUCE-1346,Bug,Major,contrib/streaming;test,TestStreamingExitStatus / TestStreamingKeyValue - correct text fixtures in place ,TestStreamingExitStatus does not have the correct text fixtures ; of deleting the input   output files after the last test run.   Cleanup methods as part of setUp refactored to tearDown to accomplish that.   Because of incorrect text fixtures - subsequent test cases fail.,Open,Unresolved,,Unassigned,Karthik K,Wed; 30 Dec 2009 10:45:45 +0000,Fri; 7 May 2010 05:08:57 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1346
MAPREDUCE-1347,Bug,Major,client,Missing synchronization in MultipleOutputFormat,MultipleOutputFormat's RecordWriter implementation doesn't use synchronization when accessing the recordWriters member. When using multithreaded mappers or reducers; this can result in problems where two threads will both try to create the same file; causing AlreadyBeingCreatedException. Doing this more fine-grained than just synchronizing the whole method is probably a good idea; so that multithreaded mappers can actually achieve parallelism writing into separate output streams.  From what I can tell; the new API's MultipleOutputs seems not to have this issue.,Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 31 Dec 2009 00:29:34 +0000,Wed; 26 Oct 2016 14:50:06 +0000,,,1.0.0,concurrency,HADOOP-7298,,https://issues.apache.org/jira/browse/MAPREDUCE-1347
MAPREDUCE-1348,Bug,Major,build,Package org.apache.hadoop.blockforensics does not match directory name,BlockSearch is in the package org.apache.hadoop.blockforensics; but in the source directory org block_forensics. While   doesn't seem to mind about this mismatch; Eclipse treats it as an error.,Closed,Fixed,,Tom White,Tom White,Thu; 31 Dec 2009 01:05:55 +0000,Tue; 24 Aug 2010 21:19:55 +0000,Tue; 23 Mar 2010 02:57:29 +0000,,,,MAPREDUCE-1592,,https://issues.apache.org/jira/browse/MAPREDUCE-1348
MAPREDUCE-1349,Task,Major,,Create jira component - contrib/index ,Can we have a component - contrib index  (in jira ),Resolved,Fixed,,Tom White,Karthik K,Thu; 31 Dec 2009 20:12:07 +0000,Fri; 1 Jan 2010 00:43:58 +0000,Fri; 1 Jan 2010 00:43:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1349
MAPREDUCE-1350,Improvement,Major,contrib/streaming,Streaming should allow TextInputFormat keys to be passed through,Streaming's PipeMapper automatically ignores the key (LongWritable file offset) coming from TextInputFormat. This is usually what the user wants; but occasionally the file offsets are useful - for example; after grepping a large file for a particular pattern; you may want to look at the offset in the file where the pattern matched. There should be a boolean configuration variable which overrides ignoreKey in PipeMapper. 86,Resolved,Duplicate,MAPREDUCE-1785,Unassigned,Todd Lipcon,Sun; 3 Jan 2010 01:42:56 +0000,Wed; 2 Jun 2010 05:04:06 +0000,Wed; 2 Jun 2010 05:04:06 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1350
MAPREDUCE-1351,Sub-task,Major,contrib/mumak,Create Fake Log from Hadoop,Version 1 of Mumak supports simulation of Map-Reduce jobs from the logs generated by original job run. Our main aim to run the job even without submitting it. So this task concerns to generate fake log file of Map-Reduce task; convert that into JSON by Rumen and run those files in Mumak.,Open,Unresolved,,Unassigned,Nishit Shah,Sun; 3 Jan 2010 14:00:59 +0000,Sun; 3 Jan 2010 14:58:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1351
MAPREDUCE-1352,Task,Critical,build,0.21.0 - snapshot incorrect dependency published in .pom files ,The snapshot available here at - https: libaries.properties but pom.xml published in the repository refers to 0.22 . Please fix the same by republishing a .pom again.,Closed,Fixed,,Giridharan Kesavan,Karthik K,Mon; 4 Jan 2010 01:55:36 +0000,Thu; 2 May 2013 02:29:27 +0000,Wed; 6 Jan 2010 09:51:01 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1352
MAPREDUCE-1353,Improvement,Major,jobtracker,Remove JobInProgress (back?) reference from TaskInProgress,Looks like TaskInProgress can get rid of JobInProgress back-reference if the values it requires from the JobInProgress are passed as parameters.,Open,Unresolved,,Amar Kamat,Amar Kamat,Mon; 4 Jan 2010 14:50:18 +0000,Thu; 13 Jan 2011 02:27:49 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1353
MAPREDUCE-1354,Improvement,Critical,jobtracker,Incremental enhancements to the JobTracker for better scalability,It'd be nice to have the JobTracker object not be locked while accessing the HDFS for reading the jobconf file and while writing the jobinfo file in the submitJob method. We should see if we can avoid taking the lock altogether.,Closed,Fixed,,Dick King,Devaraj Das,Tue; 5 Jan 2010 01:51:36 +0000,Mon; 12 Dec 2011 06:19:56 +0000,Fri; 21 May 2010 18:24:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1354
MAPREDUCE-1355,Bug,Minor,contrib/index,"contrib/index - fails to build with error  - "" Overriding index.ivy.settings' is not allowed when using override='notallowed' "" ",Checked out the trunk of mapreduce - tried to build contrib build-contrib.xml:311: Overriding a previous definition of ivy:settings with the id 'index.ivy.settings' is not allowed when using override='notallowed' ; (when in fact the override has been specified to be 'false' ).   Bumping the ivy.version to 2.1.0 seems to be fix the issue.  Marking this as critical since it is not possible to build in the first place.,Resolved,Won't Fix,,Unassigned,Karthik K,Wed; 6 Jan 2010 01:29:56 +0000,Tue; 29 Jul 2014 21:47:34 +0000,Tue; 29 Jul 2014 21:47:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1355
MAPREDUCE-1356,Improvement,Major,,Allow user-specified hive table name in sqoop,The table name used in a hive-destination import is currently pegged to the input table name. This should be user-configurable.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Wed; 6 Jan 2010 01:41:10 +0000,Fri; 2 Jul 2010 06:31:55 +0000,Wed; 27 Jan 2010 05:36:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1356
MAPREDUCE-1357,Task,Major,,contrib/index - As part of the hudson build ,As of now - it seems like contrib index ( If it is dormant - try to understand a bit of background ).,Resolved,Won't Fix,,Unassigned,Karthik K,Wed; 6 Jan 2010 01:46:23 +0000,Tue; 29 Jul 2014 21:47:45 +0000,Tue; 29 Jul 2014 21:47:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1357
MAPREDUCE-1358,Bug,Major,,Utils.OutputLogFilter incorrectly filters for _logs,OutputLogFilter checks if the path contains _logs. This would incorrectly filter out all contents of a directory called server_logs; for example. Instead it should check for a path component exactly equal to _logs,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 6 Jan 2010 01:48:21 +0000,Tue; 24 Aug 2010 21:19:56 +0000,Sat; 13 Feb 2010 11:57:03 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1358
MAPREDUCE-1359,Test,Major,contrib/streaming,TypedBytes TestIO doesn't mkdir its test dir first,TestIO fails when run alone since it doesn't mkdir its test directory in the setUp function. This JIRA should fix it and update the tests to use junit 4 style.,Closed,Fixed,,Anatoli Fomenko,Todd Lipcon,Wed; 6 Jan 2010 21:22:37 +0000,Tue; 24 Aug 2010 21:19:58 +0000,Wed; 20 Jan 2010 20:03:14 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1359
MAPREDUCE-1360,Improvement,Major,,Record skipping should work with more serializations,Record skipping currently supports WritableSerialization; but cannot handle non-class-based serialization systems (e.g.; AvroSerialization). The record skipping mechanism should be made compatible with the metadata-based serialization configuration.,Open,Unresolved,,Unassigned,Aaron Kimball,Wed; 6 Jan 2010 21:36:53 +0000,Sat; 26 Feb 2011 06:45:22 +0000,,,,,,MAPREDUCE-1126;MAPREDUCE-815,https://issues.apache.org/jira/browse/MAPREDUCE-1360
MAPREDUCE-1361,Improvement,Major,contrib/fair-share,In the pools with minimum slots; new job will always receive slots even if the minimum slots limit has been fulfilled,In 0.20; the fair scheduler compares all the jobs based on their running tasks; minimum slots and deficit. If the number of running tasks is less than the number of minimum slots; it will be scheduled first.  Consider a pool with minimum slot of 1000 but already have 5000 running tasks. If we launch another job on this pool; this new job will receive minimum slots based on its weight. This new job may have higher weight if NewJobWeightBooster is used. So this new job will still get extra slots even if the pool's running tasks are way more than the minimum slots.  The latest version does not have this problem because it first compares pool then compares jobs in the pool.,Resolved,Won't Fix,,Scott Chen,Scott Chen,Thu; 7 Jan 2010 02:36:23 +0000,Wed; 16 Jun 2010 18:01:07 +0000,Wed; 16 Jun 2010 18:01:07 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1361
MAPREDUCE-1362,Improvement,Major,pipes,Pipes should be ported to the new mapreduce API,"Pipes is still currently using the old mapred API. This prevents us from using pipes with HBase's TableInputFormat; HRegionPartitioner; etc.   Here is a rough proposal for how to accomplish this:   	Add a new package org.apache.hadoop.mapreduce.pipes that uses the new mapred API. 	the new pipes package will run side by side with the old one. old one should get deprecated at some point. 	the wire protocol used between PipesMapper and PipesReducer and C++ programs must not change. 	bin hadoop should support both pipes (old api) and pipes2 (new api)    Does this sound reasonable?",Patch Available,Unresolved,,Unassigned,Bassam Tabbara,Thu; 7 Jan 2010 08:04:18 +0000,Fri; 6 Nov 2015 02:43:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1362
MAPREDUCE-1363,Bug,Major,task,Spill size underestimated when using certain combiners; causing map tasks to fail,Spill size could get underestimated when using certain combiners; causing map tasks to fail when disk space is really low in some mapred.local.dir.  When doing sortAndSpill(); MapOutputBuffer gets an output path through LocalDirAllocator which checks if the estimated size of the spill is available on any paths specified for intermediate data storage. In case a combiner is specified which emits key-value pairs having serialized size larger than the input key-value pairs' size; the size of the spill file is underestimated. If LocalDirAllocator selects a path for intermediate data storage which does not have enough space to hold the spilled records; an IOException is thrown and the map task fails.  This could be avoided by either improving the estimation of the size of the spill (increasing it by a constant amount or by constant percentage); or LocalDirAllocator could take into consideration a configuration parameter specifying how much extra unused space should be on the path returned by getLocalPathForWrite (similarly to dfs.datanode.du.reserved). In case there is no space left on a device designated for writing intermediate data on; the spill could be retried on a different device (without the failure of the map task).,Open,Unresolved,,Unassigned,Miklos Erdelyi,Thu; 7 Jan 2010 17:05:32 +0000,Thu; 7 Jan 2010 23:05:46 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1363
MAPREDUCE-1364,Task,Major,,Hudson build of mapreduce - 0.21.0 to be green ,Make hudson build of mapreduce-0.21.0 green.  http:    The last successful one was on Dec 11 ; and the latest one seems to fail with some classpath issue on hadoop-core ( complains about missing o.a.h.Configuration etc. ).   Having the build to be green would be useful to understand the sanity of the latest snapshot of branch-0.21 and understand the release schedule for the same.   Thanks for helping.,Closed,Not A Problem,,Unassigned,Karthik K,Thu; 7 Jan 2010 20:04:16 +0000,Fri; 23 Mar 2012 18:11:23 +0000,Sun; 7 Feb 2010 01:48:55 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1364
MAPREDUCE-1365,Bug,Trivial,test,TestTaskTrackerBlacklisting.AtestTrackerBlacklistingForJobFailures is mistyped.,The name of TestTaskTrackerBlacklisting.testTrackerBlacklistingForJobFailures got changed to TestTaskTrackerBlacklisting.AtestTrackerBlacklistingForJobFailures unintentionally in MAPREDUCE-686.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 8 Jan 2010 04:53:52 +0000,Tue; 24 Aug 2010 21:19:58 +0000,Mon; 25 Jan 2010 04:40:19 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1365
MAPREDUCE-1366,Bug,Major,test,Tests should not timeout if TaskTracker/JobTracker crashes in MiniMRCluster,Currently tests timeout if there is any problem bringing up JobTracker or TaskTracker in MiniMRCluster. Instead tests should fail saying JT TT crashed. See test timeout on MAPREDUCE-1365,Resolved,Fixed,MAPREDUCE-1562,Unassigned,Amareshwari Sriramadasu,Fri; 8 Jan 2010 08:14:16 +0000,Tue; 29 Jul 2014 22:03:34 +0000,Tue; 29 Jul 2014 22:03:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1366
MAPREDUCE-1367,Improvement,Major,,LocalJobRunner should support parallel mapper execution,The LocalJobRunner currently supports only a single execution thread. Given the prevalence of multi-core CPUs; it makes sense to allow users to run multiple tasks in parallel for improved performance on small (local-only) jobs.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 8 Jan 2010 23:34:46 +0000,Thu; 4 Jul 2013 10:50:41 +0000,Sat; 30 Jan 2010 01:24:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1367
MAPREDUCE-1368,Bug,Major,contrib/vertica,Vertica adapter doesn't use explicity transactions or report progress,The vertica adapter doesn't use explicit transactions; so speculative tasks can result in duplicate loads.  The JDBC driver supports it so the fix is pretty minor. Also the JDBC driver commits synchronously and the adapter needs to report progress even if it takes longer than the timeout.,Resolved,Won't Fix,,Omer Trajman,Omer Trajman,Sun; 10 Jan 2010 01:04:48 +0000,Tue; 29 Jul 2014 22:31:55 +0000,Tue; 29 Jul 2014 22:31:55 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1368
MAPREDUCE-1369,Bug,Blocker,test,JUnit tests should never depend on anything in conf,The recent change to mapred-queues.xml that causes many mapreduce tests to break unless you delete conf conf and use that instead.,Closed,Fixed,HADOOP-6348,Anatoli Fomenko,Anatoli Fomenko,Mon; 11 Jan 2010 02:50:53 +0000,Tue; 24 Aug 2010 21:20:00 +0000,Fri; 29 Jan 2010 07:20:57 +0000,,0.21.0;0.22.0,,,HADOOP-6374,https://issues.apache.org/jira/browse/MAPREDUCE-1369
MAPREDUCE-1370,Bug,Major,test,TestCombineFileInputFormat.testSplitPlacement fails in trunk,http:    org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat.testSplitPlacement (from TestCombineFileInputFormat)   Failing for the past 1 build (Since #202 )  Took 18 sec. add description  Error Message port out of range:-1 Stacktrace  start(480)) - Jetty bound to port 57237     junit 77 main INFO org.mortbay.log - jetty-6.1.14     junit 17760 main INFO org.mortbay.log - Started SelectChannelConnector@localhost:57237     junit Tests run: 1; Failures: 0; Errors: 1; Time elapsed: 18.611 sec     junit Test org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat FAILED,Resolved,Duplicate,HADOOP-6528,Unassigned,Iyappan Srinivasan,Tue; 12 Jan 2010 05:55:58 +0000,Tue; 2 Feb 2010 05:41:05 +0000,Tue; 2 Feb 2010 05:41:05 +0000,,0.22.0,,,MAPREDUCE-1179;HADOOP-6528,https://issues.apache.org/jira/browse/MAPREDUCE-1370
MAPREDUCE-1371,Bug,Major,tasktracker,TaskTracker.offerService catches exceptions and ignores.,TaskTracker.offerService() code catches exceptions and just logs it. Instead it should throw it out.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Tue; 12 Jan 2010 06:07:07 +0000,Fri; 2 Jul 2010 00:04:58 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1371
MAPREDUCE-1372,Bug,Blocker,jobtracker,ConcurrentModificationException in JobInProgress,We have seen the following  ConcurrentModificationException in one of our clusters,Closed,Fixed,,Dick King,Amareshwari Sriramadasu,Tue; 12 Jan 2010 08:30:53 +0000,Tue; 24 Aug 2010 21:20:03 +0000,Mon; 31 May 2010 23:48:25 +0000,,0.20.1,,,MAPREDUCE-1717,https://issues.apache.org/jira/browse/MAPREDUCE-1372
MAPREDUCE-1373,Bug,Major,jobtracker,Tasklog information for incomplete task is not available via jobhistory webui ,Tasklog information for incomplete tasks is never logged to jobhistory. This is particularly bad for users are they see the tasklog link for the running job but the link is no longer available via jobhistory webui once the job completes.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 12 Jan 2010 12:08:21 +0000,Tue; 12 Jan 2010 12:08:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1373
MAPREDUCE-1374,Improvement,Major,,Reduce memory footprint of FileSplit,We can have many FileInput objects in the memory; depending on the number of mappers.  It will save tons of memory on JobTracker and JobClient if we intern those Strings for host names.     More on String.intern(): http: www. net.URI which internally contains ~10 String fields. This will also be a huge saving.,Resolved,Fixed,,Zheng Shao,Zheng Shao,Wed; 13 Jan 2010 04:26:22 +0000,Tue; 29 Jul 2014 22:33:58 +0000,Tue; 29 Jul 2014 22:33:58 +0000,,0.20.1;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1374
MAPREDUCE-1375,Bug,Major,contrib/streaming;test,TestFileArgs fails intermittently,TestFileArgs failed once for me with the following error,Closed,Fixed,,Todd Lipcon,Amar Kamat,Thu; 14 Jan 2010 14:28:57 +0000,Mon; 12 Dec 2011 06:18:57 +0000,Thu; 2 Sep 2010 08:11:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1375
MAPREDUCE-1376,Improvement,Major,contrib/gridmix,Support for varied user submission in Gridmix,Gridmix currently submits all synthetic jobs as the client user. It should be possible to map users in the trace to a set of users appropriate for the target cluster.,Closed,Fixed,,Chris Douglas,Chris Douglas,Fri; 15 Jan 2010 02:23:42 +0000,Mon; 12 Dec 2011 06:18:44 +0000,Wed; 14 Jul 2010 09:24:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1376
MAPREDUCE-1377,Improvement,Major,test,Edit test tools to use Tool/ToolRunner,HDFS-587 made changes to the HDFS tests to support generic hadoop parameters to tests. This JIRA is to track the mapreduce part of the same.,Open,Unresolved,,Erik Steffl,Sreekanth Ramakrishnan,Fri; 15 Jan 2010 03:52:02 +0000,Mon; 25 Jan 2010 22:04:21 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1377
MAPREDUCE-1378,Bug,Trivial,jobtracker,Args in job details links on jobhistory.jsp are not URL encoded,The logFile argument in the job links on the JT jobhistory.jsp page is not properly URL encoded leading to links that result in 500 errors. I found the issue while working with the Cloudera distro which contained a plus ('+') in the path which is interpreted as a space character (%20) by Firefox. Here is the (trimmed) URL. Note the hadoop-0.20.1+152 directory which should be hadoop-0.20.1%2B152. I have created a patch against current ASF svn trunk but it is untested (although the jsp compiles to a class file ok).  A job link from http: ...,Closed,Fixed,,E. Sammer,E. Sammer,Fri; 15 Jan 2010 05:04:06 +0000,Thu; 18 Nov 2010 19:50:24 +0000,Wed; 17 Feb 2010 22:14:28 +0000,,0.22.0,,,MAPREDUCE-2052;HDFS-1109,https://issues.apache.org/jira/browse/MAPREDUCE-1378
MAPREDUCE-1379,New Feature,Trivial,tasktracker,Limit both numMapTasks and numReduceTasks,In some environment; the number of concurrent running process is very sensitive.    mapreduce.tasktracker.map.tasks.maximum and   mapreduce.tasktracker.reduce.tasks.maximum limit tasks running on each tasktracker separately.  This patch limits them together; using mapreduce.tasktracker.total.tasks.maximum,Resolved,Won't Fix,HADOOP-6749,Unassigned,Bochun Bai,Fri; 15 Jan 2010 06:30:39 +0000,Thu; 6 May 2010 04:25:47 +0000,Sun; 24 Jan 2010 23:51:28 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1379
MAPREDUCE-1380,New Feature,Minor,,Adaptive Scheduler,The Adaptive Scheduler is a pluggable Hadoop scheduler th if; for instance; a job isn't able to meet its deadline; the scheduler automatically requests more resources.,Open,Unresolved,,Jord   Polo,Jord   Polo,Fri; 15 Jan 2010 09:25:55 +0000,Sat; 7 Jan 2017 01:59:50 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1380
MAPREDUCE-1381,Bug,Minor,jobtracker,Incorrect values being displayed for blacklisted_maps and blacklisted_reduces,blacklisted_maps and blacklisted_reduces metrics collected displays wrong values. For example when trackers_blacklisted=6 and with each TT having 6 map slots and 2 reduce slots; blacklisted_maps should be 36 and blacklisted_reduces should be 12. However I observed values which were not expected. Below is a snapshot of the metrics obtained:  mapred.jobtracker: hostName=hostname; sessionId=; blacklisted_maps=24; blacklisted_reduces=8; jobs_completed=136; jobs_failed=26; jobs_killed=0; jobs_preparing=0; jobs_running=13; jobs_submitted=165; map_slots=2748; maps_completed=76501; maps_failed=8741; maps_killed=0; maps_launched=88199; occupied_map_slots=1902; occupied_reduce_slots=902; reduce_slots=916; reduces_completed=21927; reduces_failed=184; reduces_killed=0; reduces_launched=23027; reserved_map_slots=0; reserved_reduce_slots=0; running_maps=1902; running_reduces=902; trackers=464; trackers_blacklisted=6; trackers_decommissioned=1; waiting_maps=-1741; waiting_reduces=2042,Open,Unresolved,,Unassigned,Ramya Sunil,Fri; 15 Jan 2010 10:56:43 +0000,Fri; 19 Feb 2010 07:42:31 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1381
MAPREDUCE-1382,Improvement,Major,,MRAsyncDiscService should tolerate missing local.dir,Currently when some of the local.dir do not exist; MRAsyncDiscService will fail. It should only fail when all directories don't work.,Closed,Fixed,MAPREDUCE-2049,Zheng Shao,Scott Chen,Fri; 15 Jan 2010 20:52:54 +0000,Mon; 12 Dec 2011 06:18:59 +0000,Mon; 24 Jan 2011 22:44:45 +0000,,,,,MAPREDUCE-1213,https://issues.apache.org/jira/browse/MAPREDUCE-1382
MAPREDUCE-1383,New Feature,Major,,Allow storage and caching of delegation token.,Client needs to obtain delegation tokens from all the NameNodes it is going to work with and pass it to the application.,Closed,Fixed,MAPREDUCE-1405,Boris Shkolnik,Boris Shkolnik,Fri; 15 Jan 2010 23:41:23 +0000,Tue; 24 Aug 2010 21:20:04 +0000,Fri; 29 Jan 2010 19:56:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1383
MAPREDUCE-1384,Improvement,Major,tools/rumen,Rumen should return UGI information for users rather than String,It would be cleaner for downstream tools if Rumen were to return the UserGroupInformation about users in the trace- including groups- instead of the username only,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 16 Jan 2010 03:34:04 +0000,Fri; 2 Jul 2010 07:14:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1384
MAPREDUCE-1385,New Feature,Major,,Make changes to MapReduce for the new UserGroupInformation APIs (HADOOP-6299),This is about moving the MapReduce code to use the new UserGroupInformation API as described in HADOOP-6299.,Closed,Fixed,,Devaraj Das,Devaraj Das,Mon; 18 Jan 2010 18:50:03 +0000,Tue; 24 Aug 2010 21:20:05 +0000,Wed; 27 Jan 2010 08:35:21 +0000,,,,HDFS-905;HADOOP-6299,,https://issues.apache.org/jira/browse/MAPREDUCE-1385
MAPREDUCE-1386,Bug,Major,contrib/mumak,'ant javadoc' fails,ant  oc links.,Closed,Duplicate,MAPREDUCE-1338,Unassigned,Amar Kamat,Tue; 19 Jan 2010 05:00:07 +0000,Tue; 24 Aug 2010 21:20:06 +0000,Fri; 22 Jan 2010 08:00:07 +0000,,0.21.0,,,MAPREDUCE-1316,https://issues.apache.org/jira/browse/MAPREDUCE-1386
MAPREDUCE-1387,Bug,Major,jobtracker,Incorrect synchronization of {map|reduce|cleanup|setup} tasks in JobInProgress,JobInProgress.maps[]; JobInProgress.reduces[]; JobInProgress.setup[] and JobInProgress.cleanup[] are incorrectly synchronized resulting into findbugs warnings. Except the getter apis (i.e getMapTasks(); getReduceTasks(); getSetupTasks() and getCleanupTasks()); these structures are always accessed in synchronized methods.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 19 Jan 2010 05:05:05 +0000,Thu; 13 Jan 2011 21:51:40 +0000,,,,,,MAPREDUCE-1316,https://issues.apache.org/jira/browse/MAPREDUCE-1387
MAPREDUCE-1388,Task,Major,,Move RAID from HDFS to MR,Here's the MR side change of HDFS-902. The HDFS RAID code has a MR dependency so let's move it to the mapred repo.,Closed,Fixed,,Eli Collins,Eli Collins,Tue; 19 Jan 2010 08:58:48 +0000,Tue; 24 Aug 2010 21:20:06 +0000,Fri; 22 Jan 2010 19:36:19 +0000,,,,,HDFS-902,https://issues.apache.org/jira/browse/MAPREDUCE-1388
MAPREDUCE-1389,Bug,Major,test,TestDFSIO creates TestDFSIO_results.log file directly under hadoop.home,TestDFSIO_results.log should be created under the ${test.build.data} instead of ${hadoop.home}.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 19 Jan 2010 09:44:23 +0000,Fri; 19 Feb 2010 07:42:27 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1389
MAPREDUCE-1390,Bug,Major,jobtracker;test,"Default value of ""/tmp/hadoop/mapred/system"" for JTConfig.JT_SYSTEM_DIR prevents multiple users from running tests and starting mapred cluster/JobTracker","This was done by MAPREDUCE-181.  Same is the case with "" .",Resolved,Duplicate,MAPREDUCE-1322,Unassigned,Vinod Kumar Vavilapalli,Wed; 20 Jan 2010 07:27:11 +0000,Thu; 28 Jan 2010 14:02:21 +0000,Thu; 28 Jan 2010 14:02:21 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1390
MAPREDUCE-1391,Bug,Major,,mapred.jobtracker.restart.recover should be true by default,I haven't played with it much (about to); but is there a reason why jt recover is false by default?,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 20 Jan 2010 22:24:44 +0000,Tue; 8 May 2012 03:59:41 +0000,Wed; 2 Nov 2011 17:44:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1391
MAPREDUCE-1392,Bug,Major,test,TestReduceFetch failure,TestReduceFetch is failing on one of our QA machines,Resolved,Duplicate,MAPREDUCE-1172,Unassigned,Aaron Kimball,Thu; 21 Jan 2010 01:06:12 +0000,Thu; 21 Jan 2010 01:45:34 +0000,Thu; 21 Jan 2010 01:45:16 +0000,,0.20.1,,,HADOOP-4302,https://issues.apache.org/jira/browse/MAPREDUCE-1392
MAPREDUCE-1393,Improvement,Major,,Update http://hadoop.apache.org/mapreduce/credits.html with current list of committers,The website appears out of date; http: credits.html.,Resolved,Fixed,,Unassigned,Jeff Hammerbacher,Thu; 21 Jan 2010 03:09:31 +0000,Tue; 29 Jul 2014 22:49:03 +0000,Tue; 29 Jul 2014 22:49:03 +0000,,,,,HDFS-910,https://issues.apache.org/jira/browse/MAPREDUCE-1393
MAPREDUCE-1394,Bug,Major,,Sqoop generates incorrect URIs in paths sent to Hive,Hive used to require a ':8020' in HDFS URIs used with LOAD DATA statements; even though the normalized form of such a URI does not contain an explicit port number (since 8020 is the default port). Sqoop matched this by hacking the URI strings it forwarded to Hive.  Hive fixed this bug a while ago  Sqoop should catch up.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 21 Jan 2010 04:12:03 +0000,Fri; 2 Jul 2010 06:31:56 +0000,Wed; 27 Jan 2010 00:05:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1394
MAPREDUCE-1395,Bug,Major,,Sqoop does not check return value of Job.waitForCompletion(),Old code depended on JobClient.runJob() throwing IOException on failure. Job.waitForCompletion can fail in that manner; or it can fail by returning false. Sqoop needs to check for this condition.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 21 Jan 2010 22:31:46 +0000,Fri; 2 Jul 2010 06:31:57 +0000,Wed; 27 Jan 2010 05:30:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1395
MAPREDUCE-1396,Improvement,Major,jobtracker,Display more details about memory usage on jobtracker web UI,HDFS-850 is introducing changes to the NameNode web UI to display additional details of memory information. I think it will be good to have similar information for the jobtracker as well; particularly for heavily used clusters that run the risk of the masters running out of memory.,Resolved,Won't Fix,,Unassigned,Hemanth Yamijala,Fri; 22 Jan 2010 03:24:45 +0000,Sat; 9 May 2015 01:20:44 +0000,Sat; 9 May 2015 01:20:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1396
MAPREDUCE-1397,Bug,Minor,tasktracker,NullPointerException observed during task failures,In an environment where many jobs are killed simultaneously; NPEs are observed in the TT JT logs when a task fails. The situation is aggravated when the taskcontroller.cfg is not configured properly. Below is the exception obtained:,Closed,Fixed,,Amareshwari Sriramadasu,Ramya Sunil,Fri; 22 Jan 2010 10:36:39 +0000,Mon; 20 May 2013 15:26:41 +0000,Tue; 27 Apr 2010 10:03:29 +0000,,0.20.1,,,MAPREDUCE-5260,https://issues.apache.org/jira/browse/MAPREDUCE-1397
MAPREDUCE-1398,Bug,Major,tasktracker,TaskLauncher remains stuck on tasks waiting for free nodes even if task is killed.,Tasks could be assigned to trackers for slots that are running other tasks in a commit pending state. This is an optimization done to pipeline task assignment and launch. When the task reaches the tracker; it waits until sufficient slots become free for it. This wait is done in the TaskLauncher thread. Now; while waiting; if the task is killed externally (maybe because the job finishes; etc); the TaskLauncher is not notified of this. So; it continues to wait for the killed task to get sufficient slots. If slots do not become free for a long time; this would result in considerable delay in waking up the TaskLauncher thread. If the waiting task happens to be a high RAM task; then it is also wasteful; because by waking up; it can make way for normal tasks that can run on the available number of slots.,Closed,Fixed,,Amareshwari Sriramadasu,Hemanth Yamijala,Fri; 22 Jan 2010 17:09:09 +0000,Tue; 24 Aug 2010 21:20:08 +0000,Tue; 16 Feb 2010 10:53:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1398
MAPREDUCE-1399,Bug,Major,harchive,The archive command shows a null error message,nan,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Fri; 22 Jan 2010 21:52:48 +0000,Tue; 24 Aug 2010 21:20:09 +0000,Wed; 10 Feb 2010 02:20:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1399
MAPREDUCE-1400,Bug,Minor,,sed in build.xml fails,MAPRED version of HADOOP-6505,Closed,Fixed,,Allen Wittenauer,Allen Wittenauer,Fri; 22 Jan 2010 22:13:50 +0000,Tue; 24 Aug 2010 21:20:09 +0000,Sat; 13 Feb 2010 11:10:15 +0000,,,,,HADOOP-6505,https://issues.apache.org/jira/browse/MAPREDUCE-1400
MAPREDUCE-1401,Improvement,Major,contrib/gridmix,[Gridmix] Add a load generating factory,To replace previous Gridmix benchmarks (HADOOP-2369 ; HADOOP-3770); it must be possible to put a sustained; saturating load on a cluster. While tools for manipulating traces (MAPREDUCE-1295) allow one to produce lighter or heavier load than observed; a client monitoring and responding to observed load would let one write easier-to-interpret; end-to-end benchmarks.,Resolved,Duplicate,MAPREDUCE-1840,Unassigned,Chris Douglas,Sat; 23 Jan 2010 00:22:27 +0000,Thu; 12 Aug 2010 10:25:53 +0000,Thu; 12 Aug 2010 10:25:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1401
MAPREDUCE-1402,Task,Major,benchmarks,Remove src/benchmarks,src benchmarks has not attracted many contributions. The versions of gridmix currently there are deprecated in in favor of the version in contrib (MAPREDUCE-776) and will be redundant after MAPREDUCE-1401.,Resolved,Fixed,,Chris Douglas,Chris Douglas,Sat; 23 Jan 2010 00:28:23 +0000,Tue; 29 Jul 2014 22:50:10 +0000,Tue; 29 Jul 2014 22:50:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1402
MAPREDUCE-1403,Improvement,Major,client,Save file-sizes of each of the artifacts in DistributedCache in the JobConf,It would be a useful metric to collect... potentially GridMix could use it to emulate jobs which use the DistributedCache.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sat; 23 Jan 2010 00:48:59 +0000,Tue; 24 Aug 2010 21:20:10 +0000,Thu; 11 Mar 2010 10:28:08 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1403
MAPREDUCE-1404,Task,Blocker,documentation,Cluster-Setup and Single-Node-Setup Docs ,(Updated Summary and Description)  The cluster_setup.xml file is in 2 places: common-trunk and mapreduce-trunk.   The single_node_setup.xml file is in 1 place: common-trunk.  Issues:  (1) Remove duplication - cluster_setup.xml should only be in 1 trunk (no duplication of files)  (2) Both files stay together - cluster_setup.xml and single_node_setup.xml should be together in the same location (trunk)  (3) Which trunk - originally; both files were  assigned to the common-trunk during the doc split that occured the summer of 2009.   Solutions:  (1) have both files live in common-trunk  ... OR ...  (2) have both files live in mapreduce-trunk  This ticket affects trunk and branch-0.21,Closed,Fixed,MAPREDUCE-1039,Tom White,Corinne Chandel,Sat; 23 Jan 2010 02:01:00 +0000,Tue; 24 Aug 2010 21:20:11 +0000,Fri; 4 Jun 2010 16:59:14 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1404
MAPREDUCE-1405,Bug,Trivial,,unchecked cast warnings in trunk,nan,Resolved,Duplicate,MAPREDUCE-1383,Unassigned,Chris Douglas,Sun; 24 Jan 2010 23:21:59 +0000,Fri; 29 Jan 2010 03:42:22 +0000,Fri; 29 Jan 2010 03:42:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1405
MAPREDUCE-1406,Bug,Trivial,,JobContext.MAP_COMBINE_MIN_SPILLS is misspelled,JobContext.MAP_COMBINE_MIN_SPILLS is misspelled as JobContext.MAP_COMBINE_MIN_SPISS,Closed,Fixed,,Chris Douglas,Chris Douglas,Mon; 25 Jan 2010 04:28:56 +0000,Tue; 24 Aug 2010 21:20:12 +0000,Mon; 25 Jan 2010 05:11:58 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1406
MAPREDUCE-1407,Bug,Trivial,documentation,Invalid example in the documentation of org.apache.hadoop.mapreduce.{Mapper;Reducer},Both examples are using context.collect instead of context.write,Resolved,Fixed,,Benoit Sigoure,Benoit Sigoure,Mon; 25 Jan 2010 05:53:49 +0000,Sat; 20 Mar 2010 16:55:32 +0000,Sat; 20 Mar 2010 01:43:54 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1407
MAPREDUCE-1408,Bug,Major,contrib/gridmix,Allow customization of job submission policies,Currently; gridmix3 replay job submission faithfully. For evaluation purposes; it would be great if we can support other job submission policies such as sequential job submission; or stress job submission.,Closed,Fixed,,rahul k singh,rahul k singh,Mon; 25 Jan 2010 06:28:16 +0000,Tue; 24 Aug 2010 21:20:12 +0000,Fri; 5 Mar 2010 03:13:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1408
MAPREDUCE-1409,Bug,Major,tasktracker,FileOutputCommitter.abortTask should not catch IOException,FileOutputCommitter.abortTask currently catches IOException. It should be thrown out; thus making the task failed.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Mon; 25 Jan 2010 11:13:48 +0000,Tue; 24 Aug 2010 21:20:14 +0000,Tue; 20 Apr 2010 19:29:38 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1409
MAPREDUCE-1410,Bug,Major,jobtracker,Task-Cleanup attempt cannot be given KillTaskAction if the main attempt is killed with a KillTaskAction,If the main attempt is killed with a KillTaskAction and is added to tasksReportedClosed; then the cleanup-attempt for the task (with same id) can not be given a KillTaskAction; since tasksReportedClosed already contains the attemptID.   The attemptID should be removed from  tasksReportedClosed in incompleteSubTask() method.,Open,Unresolved,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Mon; 25 Jan 2010 11:18:36 +0000,Fri; 11 Feb 2011 02:19:28 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1410
MAPREDUCE-1411,Improvement,Major,client,Infer MapReduce types where possible,Currently users must specify the output types of the map and reduce if they are different to the default (LongWritable keys; Text values). In many cases this information is available to the system from the user-supplied mapper and reducer; so it would be nice if the user didn't have to specify them in two places.,Open,Unresolved,,Tom White,Tom White,Tue; 26 Jan 2010 01:23:47 +0000,Tue; 26 Jan 2010 01:38:20 +0000,,,,,,MAPREDUCE-299,https://issues.apache.org/jira/browse/MAPREDUCE-1411
MAPREDUCE-1412,Bug,Minor,test,TestTaskTrackerBlacklisting fails sometimes,TestTaskTrackerBlacklisting fails occasionally. The granularity of the timer is responsible; the unit test adds a day to the expiration interval to verify that the tracker is removed from the blacklist; but the tracker is not removed if the interval exactly matches 1 day.,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 26 Jan 2010 01:47:38 +0000,Tue; 24 Aug 2010 21:20:14 +0000,Sat; 30 Jan 2010 02:57:26 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1412
MAPREDUCE-1413,Improvement,Trivial,tasktracker,Improve logging of progress/errors in the job and task trackers,"I have code that improves the logging of the trackers as they start stop and fail; through  	More logging of events 	including exception strings and stacks when things go wrong People's whose JTs and TTs aren't behaving may appreciate this",Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Tue; 26 Jan 2010 18:03:57 +0000,Mon; 26 Jan 2015 22:49:41 +0000,Mon; 26 Jan 2015 22:49:41 +0000,,0.20.203.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1413
MAPREDUCE-1414,Bug,Minor,test, TestRecoveryManager can spin waiting for a job to be half done,This is something I've seen: the TestRecoveryManager spinning forever waiting for a job to get half done. The test runner will eventually kill it; but that loses any log and chance of finding the problem.  Solution: have a timeout on how long you wait for the job,Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Tue; 26 Jan 2010 18:10:41 +0000,Thu; 29 Apr 2010 08:51:29 +0000,Sat; 13 Feb 2010 10:28:26 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1414
MAPREDUCE-1415,Bug,Major,contrib/streaming;security,With streaming jobs and LinuxTaskController; the localized streaming binary has 571 permissions instead of 570,After MAPREDUCE-856; all localized files are expected to have **0 permissions for the sake of security.  This was found by Karam while testing LinuxTaskController functionality after MAPREDUCE-856.,Open,Unresolved,,Amareshwari Sriramadasu,Vinod Kumar Vavilapalli,Wed; 27 Jan 2010 06:33:40 +0000,Thu; 13 Jan 2011 02:29:19 +0000,,,,,MAPREDUCE-1322,,https://issues.apache.org/jira/browse/MAPREDUCE-1415
MAPREDUCE-1416,Bug,Major,,New JIRA components for Map/Reduce project,We need more JIRA components for the Map data_join.,Resolved,Fixed,,Steve Loughran,Vinod Kumar Vavilapalli,Wed; 27 Jan 2010 06:49:43 +0000,Sat; 18 Feb 2012 16:20:48 +0000,Sat; 18 Feb 2012 16:20:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1416
MAPREDUCE-1417,Bug,Major,documentation,Forrest documentation should be updated to reflect the changes in MAPREDUCE-744,MAPREDUCE-744 introduced private public visibility of DistributedCache files on the TaskTracker. Forrest documentation is stale and only refers to private visible files.,Closed,Fixed,,Ravi Gummadi,Vinod Kumar Vavilapalli,Wed; 27 Jan 2010 07:15:29 +0000,Tue; 24 Aug 2010 21:20:17 +0000,Thu; 29 Apr 2010 06:42:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1417
MAPREDUCE-1418,Bug,Major,security;tasktracker,LinuxTaskController binary misses validation of arguments passed for relative components in some cases.,The function int check_path_for_relative_components(char * path) should be used to validate the absence of relative components before any operation is done on those paths. This is missed in all the initialize*() functions; as Hemanth pointed out offline.,Open,Unresolved,,Hemanth Yamijala,Vinod Kumar Vavilapalli,Wed; 27 Jan 2010 08:06:52 +0000,Tue; 6 Apr 2010 10:33:28 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1418
MAPREDUCE-1419,Bug,Major,security;tasktracker;test,Enhance tasktracker's localization tests after MAPREDUCE-181,"The following tests are missing:  	Verifying the secure permissions and ownership of the localized token-file 	Making the tests future proof against missing of permissions directories. 	JobContext.JOB_TOKEN_FILE property setting in the localized job-configuration. 	Failure of localization if the token-file is not present in the JT file-system",Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Wed; 27 Jan 2010 08:56:46 +0000,Sat; 26 Nov 2016 01:58:00 +0000,Sat; 26 Nov 2016 01:58:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1419
MAPREDUCE-1420,Bug,Major,test,TestTTResourceReporting failing in trunk,TestTTResourceReporting failing in trunk.   The most specific issue from the logs seems to be : Error executing shell command org.apache.hadoop.util.Shell$ExitCodeException: kill: No such process   Link : http:   Attaching output in a  file.,Closed,Fixed,,Scott Chen,Iyappan Srinivasan,Wed; 27 Jan 2010 12:07:30 +0000,Tue; 24 Aug 2010 21:20:18 +0000,Sat; 20 Mar 2010 07:25:28 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1420
MAPREDUCE-1421,Bug,Major,task-controller;tasktracker;test,LinuxTaskController tests failing on trunk after the commit of MAPREDUCE-1385,"The following tests fail; in particular:  	TestDebugScriptWithLinuxTaskController 	TestJobExecutionAsDifferentUser 	TestPipesAsDifferentUser 	TestKillSubProcessesWithLinuxTaskController",Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 28 Jan 2010 03:40:16 +0000,Tue; 24 Aug 2010 21:20:19 +0000,Wed; 3 Mar 2010 04:54:11 +0000,,0.22.0,,MAPREDUCE-890,,https://issues.apache.org/jira/browse/MAPREDUCE-1421
MAPREDUCE-1422,Bug,Major,task-controller;tasktracker,Changing permissions of files/dirs under job-work-dir may be needed sothat cleaning up of job-dir in all mapred-local-directories succeeds always,After MAPREDUCE-896; if LinuxTaskController is set in config; task-controller binary is launched for changing permissions of taskAttemptDir and taskWorkDir before cleaning up of these directories sothat cleanup will be succeeded even if user had created files dirs under job-work-dir may be needed sothat cleaning up of job-dir in all mapred-local-directories succeeds always.,Closed,Fixed,,Amar Kamat,Ravi Gummadi,Thu; 28 Jan 2010 08:01:03 +0000,Tue; 24 Aug 2010 21:20:20 +0000,Wed; 10 Mar 2010 05:27:35 +0000,,,,,MAPREDUCE-896,https://issues.apache.org/jira/browse/MAPREDUCE-1422
MAPREDUCE-1423,Improvement,Major,client,Improve performance of CombineFileInputFormat when multiple pools are configured,I have a map-reduce job that is using CombineFileInputFormat. It has configured 10000 pools and 30000 files. The time to create the splits takes more than an hour. The reaosn being that CombineFileInputFormat.getSplits() converts the same path from String to Path object multiple times; one for each instance of a pool. Similarly; it calls Path.toUri(0 multiple times. This code can be optimized.,Closed,Fixed,,dhruba borthakur,dhruba borthakur,Thu; 28 Jan 2010 08:45:13 +0000,Tue; 24 Aug 2010 21:20:21 +0000,Wed; 3 Mar 2010 08:17:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1423
MAPREDUCE-1424,Improvement,Major,task,prevent Merger fd  leak when there are lots empty segments in mem,The Merger will open too many files on disk; when there are too many empty segments in shuffle mem.   We process larger data ; eg.  100T in one Job. And we use our partitioner to partition the map output and one map output will wholely shuffle to one reduce So the other reduce will get lots of empty segments.  OneMapOutput's partition like this:                       whole  mapOutput_n                             ---      reduce1                             empty                               ---      reduce2                             empty                           ---      reduce3                            empty                           ---      reduce4  Because; our input data is bigger; so there are lots of map(10^5). And mostly there are several thousands maps to one reduce; and several thousands empty segments.   For example:      1000 mapOutput(on disk) + 3000 empty segments(in mem)  Then; as the io.sort.factor=100      in first merge cycle; the merger will merge 10+3000 segments [ by getPassFactor (1000 - 1)%100 + 1 + 30000 ] because there is no real data in mem; then we should use the left 990 mapOutput to replace the empty 3000 mem segments; then we open 1000 fd.      Once there are several reduce on one taskTracker; we will open several thousand fds.       I think we can use first collection to remove the empty segments; moreover in shuffle phase; we also can not add the segment into mem.,Open,Unresolved,,Unassigned,ShiXing,Thu; 28 Jan 2010 16:10:18 +0000,Thu; 28 Jan 2010 16:17:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1424
MAPREDUCE-1425,Improvement,Major,harchive,archive throws OutOfMemoryError,nan,Closed,Fixed,,Mahadev konar,Tsz Wo Nicholas Sze,Thu; 28 Jan 2010 22:26:55 +0000,Tue; 24 Aug 2010 21:20:21 +0000,Tue; 9 Feb 2010 23:40:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1425
HADOOP-6564,Bug,Major,fs,HarFileSystem cannot handle har:///,nan,Resolved,Invalid,,Mahadev konar,Tsz Wo Nicholas Sze,Thu; 28 Jan 2010 23:16:27 +0000,Mon; 22 Feb 2010 22:01:20 +0000,Mon; 22 Feb 2010 21:55:04 +0000,,,,,MAPREDUCE-1522;HADOOP-6588,https://issues.apache.org/jira/browse/HADOOP-6564
HADOOP-6560,Bug,Major,fs,HarFileSystem throws NPE for har://hdfs-/foo,nan,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Thu; 28 Jan 2010 23:24:13 +0000,Fri; 10 Feb 2012 02:38:41 +0000,Tue; 16 Feb 2010 22:21:42 +0000,,,,,HADOOP-8053,https://issues.apache.org/jira/browse/HADOOP-6560
MAPREDUCE-1428,Improvement,Major,harchive,Make block size and the size of archive created files configurable.,Currently the block size used by archives is the default block size of the hdfs filesystem. We need to make it configurable so that the block size can be higher for the part files that archives create. Also; we need to make the size of part files in archives configurable again to make it bigger in size and create less number of such files.,Closed,Fixed,MAPREDUCE-1465;MAPREDUCE-1509,Mahadev konar,Mahadev konar,Thu; 28 Jan 2010 23:27:15 +0000,Tue; 24 Aug 2010 21:20:22 +0000,Fri; 2 Apr 2010 16:43:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1428
MAPREDUCE-1429,Bug,Major,build;task-controller;test,New ant target to run all and only the linux task-controller related tests,The LinuxTaskController tests cannot be run automatically by Hudson and so we've missed several bugs in the past because of not running some of these tests explicitly ourselves. It's a real pain to run them manually one by one; we should have an ant target to run them all in one swoop.,Resolved,Incomplete,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 29 Jan 2010 08:28:49 +0000,Tue; 29 Jul 2014 22:59:42 +0000,Tue; 29 Jul 2014 22:59:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1429
MAPREDUCE-1430,Sub-task,Major,jobtracker,JobTracker should be able to renew delegation tokens for the jobs,JobTracker should automatically renew delegation tokens for the jobs it is currently running.,Closed,Fixed,,Boris Shkolnik,Devaraj Das,Fri; 29 Jan 2010 18:47:53 +0000,Tue; 24 Aug 2010 21:20:23 +0000,Mon; 22 Feb 2010 03:15:33 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1430
HADOOP-6558,Bug,Major,fs,archive does not work with distcp -update,The following distcp command  works.   However; it does not work for -update.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Fri; 29 Jan 2010 20:14:37 +0000,Tue; 24 Aug 2010 20:41:58 +0000,Thu; 18 Feb 2010 23:29:54 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-6558
MAPREDUCE-1432,Sub-task,Major,,Add the hooks in JobTracker and TaskTracker to load tokens from the token cache into the user's UGI,Related to HADOOP-6520. Here it is about putting hooks in the JobTracker TaskTracker for loading tokens in the user's UGI. This is required when job files are copied from the HDFS on behalf of the user.,Closed,Fixed,,Devaraj Das,Devaraj Das,Fri; 29 Jan 2010 22:34:28 +0000,Tue; 24 Aug 2010 21:20:24 +0000,Sun; 31 Jan 2010 03:49:25 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1432
MAPREDUCE-1433,Sub-task,Major,security,Create a Delegation token for MapReduce,Occasionally; MapReduce jobs need to launch other MapReduce jobs. With security enabled; the task needs to authenticate to the JobTracker as the user with a token.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Sat; 30 Jan 2010 18:16:39 +0000,Tue; 24 Aug 2010 21:20:25 +0000,Tue; 9 Feb 2010 23:09:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1433
MAPREDUCE-1434,New Feature,Major,,Dynamic add input for one job,Always we should firstly upload the data to hdfs; then we can analize the data using hadoop mapreduce.  Sometimes; the upload process takes long time. So if we can add input during one job; the time can be saved.  WHAT?  Client:  a) hadoop job -add-input jobId inputFormat ... Add the input to jobid  b) hadoop job -add-input done Tell the JobTracker; the input has been prepared over.  c) hadoop job -add-input status jobid Show how many input the jobid has.    HOWTO?  Mainly; I think we should do three things:  1. JobClinet: here JobClient should support add input to a job; indeed; JobClient generate the split; and submit to JobTracker.  2. JobTracker: JobTracker support addInput; and add the new tasks to the original mapTasks. Because the uploaded data will be  processed quickly; so it also should update the scheduler to support pending a map task till Client tells the Job input done.  3. Reducer: the reducer should also update the mapNums; so it will shuffle right.  This is the rough idea; and I will update it .,Open,Unresolved,,Unassigned,ShiXing,Mon; 1 Feb 2010 06:19:54 +0000,Thu; 20 Jan 2011 03:25:43 +0000,,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1434
MAPREDUCE-1435,Bug,Major,tasktracker,symlinks in cwd of the task are not handled properly after MAPREDUCE-896,With JVM reuse; TaskRunner.setupWorkDir() lists the contents of workDir and does a fs.delete on each path listed. If the listed file is a symlink to directory; it will delete the contents of those linked directories. This would delete files from distributed cache and jars directory;if mapred.create.symlink is true. Changing ownership permissions of underlying files.  This is observed by Karam while running streaming jobs with DistributedCache and jvm reuse.,Closed,Fixed,,Ravi Gummadi,Amareshwari Sriramadasu,Mon; 1 Feb 2010 09:34:20 +0000,Tue; 24 Aug 2010 21:20:26 +0000,Fri; 5 Mar 2010 02:11:00 +0000,,0.22.0,,HADOOP-6531,,https://issues.apache.org/jira/browse/MAPREDUCE-1435
MAPREDUCE-1436,Bug,Blocker,contrib/fair-share,Deadlock in preemption code in fair scheduler,In testing the fair scheduler with preemption; I found a deadlock between updatePreemptionVariables and some code in the JobTracker. This was found while testing a backport of the fair scheduler to Hadoop 0.20; but it looks like it could also happen in trunk and 0.21. Details are in a comment below.,Resolved,Invalid,MAPREDUCE-1499,Matei Zaharia,Matei Zaharia,Mon; 1 Feb 2010 19:56:42 +0000,Mon; 22 Feb 2010 01:43:49 +0000,Mon; 22 Feb 2010 01:43:49 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1436
MAPREDUCE-1437,Bug,Major,build,org.apache.hadoop.examples.terasort.TestTeraSort.testTeraSort is failing in trunk,Trunk is failing because of this error  http:   Error Message  port out of range:-1  Stacktrace   lang.IllegalArgumentException: port out of range:-1  tachment.,Resolved,Duplicate,HADOOP-6528,Unassigned,Iyappan Srinivasan,Tue; 2 Feb 2010 05:18:55 +0000,Tue; 2 Feb 2010 05:43:36 +0000,Tue; 2 Feb 2010 05:39:48 +0000,,0.22.0,,,HADOOP-6528,https://issues.apache.org/jira/browse/MAPREDUCE-1437
MAPREDUCE-1438,Wish,Minor,tasktracker,Include one minute load average information in TaskTrackerStatus.ResourceStatus,Load averages are useful indicators of overall system CPU and I O activity. Including load average information in ResourceStatus could be useful to schedulers in balancing load across TaskTrackers. Since JDK 1.6; one minute. load information can be obtained using the OperatingSystemMXBean.getSystemLoadAverage() method.,Resolved,Duplicate,YARN-349,Unassigned,Jaideep,Tue; 2 Feb 2010 09:10:32 +0000,Tue; 29 Jul 2014 23:09:54 +0000,Tue; 29 Jul 2014 23:09:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1438
MAPREDUCE-1439,New Feature,Major,jobtracker,Learning Scheduler,I would like to contribute the scheduler I have written to the MapReduce project. Presently the scheduler source code is available on http: . It has been tested to work with Hadoop 0.20; although the code available at the URL had been modified to build with trunk and needs testing. Currently the scheduler is in experimental stages; and any feedback for improvement will be extremely useful.,Resolved,Won't Fix,,Jaideep,Jaideep,Tue; 2 Feb 2010 09:44:09 +0000,Wed; 13 May 2015 21:21:10 +0000,Wed; 13 May 2015 21:21:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1439
MAPREDUCE-1440,Improvement,Major,security,MapReduce should use the short form of the user names,"To minimize disruption on MapReduce; we should use the local names (ie. ""omalley"") rather than the long names (ie. ""omalley@APACHE.ORG"" as the basis for the username in MapReduce.",Closed,Fixed,,Owen O'Malley,Owen O'Malley,Tue; 2 Feb 2010 17:35:46 +0000,Tue; 24 Aug 2010 21:20:27 +0000,Fri; 5 Feb 2010 22:31:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1440
MAPREDUCE-1441,Improvement,Major,jobtracker;tasktracker,Configuration of directory lists should trim whitespace,"HADOOP-2366 added a getTrimmedStringCollection method to Configuration. MapReduce should use this for all the cases where it configures a list of directories. This solves issues that come up when people set mapred.local.dir to "" 3"" (note the spaces). This is a very common mistake that we should guard against.",Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 2 Feb 2010 18:54:49 +0000,Sat; 13 Feb 2010 18:33:33 +0000,Sat; 13 Feb 2010 11:26:55 +0000,,0.21.0;0.22.0,,,HADOOP-2366;HADOOP-6534,https://issues.apache.org/jira/browse/MAPREDUCE-1441
MAPREDUCE-1442,Bug,Major,jobtracker,StackOverflowError when JobHistory parses a really long line,JobHistory.parseLine() fails with StackOverflowError on a really big COUNTER value; triggered via the web interface. See attached file.,Resolved,Won't Fix,,Luke Lu,bc Wong,Tue; 2 Feb 2010 20:09:56 +0000,Tue; 8 Jun 2010 16:41:30 +0000,Tue; 8 Jun 2010 16:41:30 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1442
MAPREDUCE-1443,Bug,Major,client,DBInputFormat can leak connections,The DBInputFormat creates a Connection to use when enumerating splits; but never closes it. This can leak connections to the database which are not cleaned up for a long time.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 2 Feb 2010 20:14:50 +0000,Thu; 4 Feb 2010 17:20:17 +0000,Wed; 3 Feb 2010 20:31:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1443
MAPREDUCE-1444,Bug,Major,,Sqoop ConnManager instances can leak Statement objects,The ConnManager API returns ResultSets to users but does not provide a mechanism to clean up the underlying Statement that generated the ResultSet. Problematically; closing the Statement will invalidate the ResultSet; so these must be cleaned up in LIFO order; putting the onus on the receiver of the ResultSet.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 2 Feb 2010 20:17:05 +0000,Thu; 2 May 2013 02:29:27 +0000,Tue; 16 Feb 2010 23:27:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1444
MAPREDUCE-1445,Improvement,Major,,Refactor Sqoop tests to support better ConnManager testing,Sqoop's test suite is heavily biased toward testing with the HSQLDB embedded database. This issue proposes to refactor some tests into abstract classes which can be used as a basis for testing a variety of connection manager implementations; ensuring better cross-database compatibility coverage.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 2 Feb 2010 20:19:19 +0000,Thu; 2 May 2013 02:29:27 +0000,Thu; 18 Feb 2010 00:22:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1445
MAPREDUCE-1446,New Feature,Major,,Sqoop should support CLOB and BLOB datatypes,Sqoop should allow import of CLOB and BLOB based data.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 2 Feb 2010 20:20:36 +0000,Thu; 2 May 2013 02:29:28 +0000,Thu; 18 Mar 2010 23:18:20 +0000,,,,,MAPREDUCE-1524,https://issues.apache.org/jira/browse/MAPREDUCE-1446
MAPREDUCE-1447,Bug,Major,,job level hook in OutputCommitter is not working in local mode,OutputCommitter is not totally working in local mode. Only task level hooks are called; which are setupTask; needsTaskCommit; commitTask; abortTask. Job level hooks are not working; which are: setupJob; cleanupJob.,Resolved,Duplicate,MAPREDUCE-3563,Unassigned,Daniel Dai,Wed; 3 Feb 2010 02:46:29 +0000,Thu; 22 Dec 2011 19:26:43 +0000,Thu; 22 Dec 2011 19:26:43 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1447
MAPREDUCE-1448,Bug,Major,,[Mumak] mumak.sh does not honor --config option.,When --config is specified; mumak.sh should put the customized conf directory in the classpath.,Closed,Fixed,,Hong Tang,Hong Tang,Wed; 3 Feb 2010 07:55:55 +0000,Tue; 24 Aug 2010 21:20:27 +0000,Tue; 9 Feb 2010 01:43:46 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1448
MAPREDUCE-1449,Bug,Major,,Sqoop Documentation about --split-by column has to be unique key seems to be wrong,"http: sqoo...   The document above shows that "" To guarantee correctness of your input; you must select an ordering column for which each row has a unique value. If duplicate values appear in the ordering column; the results of the import are undefined; and Sqoop will not be able to detect the error.""   I read the source code for sqoop; it seems that the column to split by doesn't have to be a unique key. Plus; when the primary key is a composite key; the sqoop code only takes the first column of the composite key which in most cases is not unique key anyways.   I also checked the output when non-unique key is used to split; there is nothing wrong with the result.   I am wondering if the document is wrong; or there is some hidden trickiness that I am not aware of.   I am using sqoop 20.1.",Resolved,Won't Fix,,Unassigned,mingran wang,Wed; 3 Feb 2010 23:13:14 +0000,Fri; 2 Jul 2010 06:32:04 +0000,Mon; 3 May 2010 18:43:06 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1449
MAPREDUCE-1450,New Feature,Major,,task logs should specify user vs. system death,When looking at task attempt logs; it should specify whether the task was killed by Hadoop or by the user.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 3 Feb 2010 23:26:40 +0000,Wed; 2 Nov 2011 17:44:02 +0000,Wed; 2 Nov 2011 17:44:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1450
MAPREDUCE-1451,Bug,Major,capacity-sched,Minor lock inversions in capacity scheduler,Running jcarder on the contrib unit tests yielded 3 lock inversions in the capacity scheduler. I don't know enough about the scheduler to know if they're problems - they look harmless enough since they seem to all be concerned with the startup code; which probably doesn't run concurrently with other stuff. Attaching the images of the cycles here.,Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 4 Feb 2010 00:28:37 +0000,Thu; 4 Feb 2010 03:37:09 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1451
MAPREDUCE-1452,New Feature,Major,,Add a low-level MapReduce API,Add an API to MapReduce that operates at the raw bytes level. The existing (object-based) MapReduce APIs would be implemented on top of the raw API; and in future it will be easier to add new APIs (like MAPREDUCE-1183) and higher-level abstractions on MapReduce.,Resolved,Duplicate,MAPREDUCE-326,Unassigned,Tom White,Thu; 4 Feb 2010 01:17:43 +0000,Wed; 12 Jan 2011 20:58:38 +0000,Thu; 4 Feb 2010 01:38:23 +0000,,,,,MAPREDUCE-1453;MAPREDUCE-1126,https://issues.apache.org/jira/browse/MAPREDUCE-1452
MAPREDUCE-1453,Improvement,Major,,Enforce the distinction between MapReduce kernel and library code,Currently MapReduce kernel and library code are in the same source tree which makes it possible to inadvertently introduce dependencies on the library by the kernel. With MAPREDUCE-1452 it makes sense to enforce the compile-time dependencies (library depends on kernel; but not vice versa); by having two source trees.,Open,Unresolved,,Unassigned,Tom White,Thu; 4 Feb 2010 01:20:50 +0000,Thu; 13 Jan 2011 02:27:56 +0000,,,,,,MAPREDUCE-1478;MAPREDUCE-1452,https://issues.apache.org/jira/browse/MAPREDUCE-1453
MAPREDUCE-1454,Sub-task,Major,,The servlets should quote server generated strings sent in the response,This is related to HADOOP-6151 but for output. We need to go through all the servlets jsps and pass all the response strings that could be based on the incoming request or user's data through a filter (implemented in HADOOP-6151).,Closed,Fixed,,Chris Douglas,Devaraj Das,Thu; 4 Feb 2010 04:49:35 +0000,Tue; 24 Aug 2010 21:20:29 +0000,Thu; 4 Mar 2010 03:10:46 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1454
MAPREDUCE-1455,Sub-task,Major,jobtracker;security;tasktracker,Authorization for servlets,This jira is about building the authorization for servlets (on top of MAPREDUCE-1307). That is; the JobTracker TaskTracker runs authorization checks on web requests based on the configured job permissions. For e.g.; if the job permission is 600; then no one except the authenticated user can look at the job details via the browser. The authenticated user in the servlet can be obtained using the HttpServletRequest method.,Closed,Fixed,,Ravi Gummadi,Devaraj Das,Thu; 4 Feb 2010 05:39:09 +0000,Tue; 24 Aug 2010 21:20:29 +0000,Tue; 2 Mar 2010 13:52:48 +0000,,,,MAPREDUCE-1493;MAPREDUCE-1307,HADOOP-6568;MAPREDUCE-1307,https://issues.apache.org/jira/browse/MAPREDUCE-1455
MAPREDUCE-1456,Bug,Major,,Undeprecate the Job constructors that don't include Cluster.,There is no reason to break compatibility in the Job API. We should just construct the Cluster automatically as the compatibility layer already does.,Open,Unresolved,,Unassigned,Owen O'Malley,Thu; 4 Feb 2010 17:37:05 +0000,Fri; 2 Jul 2010 00:04:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1456
MAPREDUCE-1457,Sub-task,Major,,For secure job execution; couple of more UserGroupInformation.doAs needs to be added,During our testing in a kerberos environment; we had to add UserGroupInformation.doAs blocks in certain places.,Closed,Fixed,,Jakob Homan,Devaraj Das,Thu; 4 Feb 2010 20:50:11 +0000,Tue; 24 Aug 2010 21:20:30 +0000,Sun; 7 Feb 2010 08:01:31 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1457
MAPREDUCE-1458,Test,Major,test,Test case for regular expression in Hadoop Archives.,We need a test case for regular expressions with hadoop archives.,Open,Unresolved,,Mahadev konar,Mahadev konar,Thu; 4 Feb 2010 21:15:18 +0000,Thu; 13 Jan 2011 02:28:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1458
MAPREDUCE-1459,Bug,Major,,There are javadoc warnings in Trunk,There are two  oc warnings in Trunk.  They're trivial and I will fix them quickly.,Resolved,Incomplete,,Dick King,Dick King,Thu; 4 Feb 2010 22:14:27 +0000,Tue; 29 Jul 2014 23:16:46 +0000,Tue; 29 Jul 2014 23:16:46 +0000,,,,,MAPREDUCE-1309,https://issues.apache.org/jira/browse/MAPREDUCE-1459
MAPREDUCE-1460,Improvement,Major,,Oracle support in DataDrivenDBInputFormat,DataDrivenDBInputFormat does not work with Oracle due to various SQL syntax issues.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 5 Feb 2010 00:31:46 +0000,Thu; 2 May 2013 02:29:28 +0000,Fri; 19 Mar 2010 21:38:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1460
MAPREDUCE-1461,Improvement,Major,tools/rumen,Feature to instruct rumen-folder utility to skip jobs worth of specific duration,JSON outputs of rumen on production logs can be huge in the order of multiple GB. Rumen's folder utility helps in getting a smaller snapshot of this JSON data. It would be helpful to have an option in rumen-folder; wherein user can specify a duration from which rumen-folder should start processing data.  Related JIRA link: https: MAPREDUCE-1295,Closed,Fixed,,Rajesh Balamohan,Rajesh Balamohan,Fri; 5 Feb 2010 05:53:55 +0000,Tue; 15 Nov 2011 00:49:07 +0000,Thu; 28 Apr 2011 04:26:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1461
MAPREDUCE-1462,New Feature,Major,task,Enable context-specific and stateful serializers in MapReduce,Although the current serializer framework is powerful; within the context of a job it is limited to picking a single serializer for a given class. Additionally; Avro generic serialization can make use of additional configuration metadata in a type safe manor without cluttering up the base API with a lot of new methods that will confuse new users.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Fri; 5 Feb 2010 07:36:58 +0000,Sat; 7 Jul 2012 12:56:34 +0000,,,,,HADOOP-6685,MAPREDUCE-1183;MAPREDUCE-1126,https://issues.apache.org/jira/browse/MAPREDUCE-1462
MAPREDUCE-1463,Improvement,Major,jobtracker,Reducer should start faster for smaller jobs,Our users often complain about the slowness of smaller ad-hoc jobs. The overhead to wait for the reducers to start in this case is significant. It will be good if we can start the reducer sooner in this case.,Open,Unresolved,,Scott Chen,Scott Chen,Fri; 5 Feb 2010 22:08:23 +0000,Fri; 8 Oct 2010 00:41:04 +0000,,,,,,MAPREDUCE-1184,https://issues.apache.org/jira/browse/MAPREDUCE-1463
MAPREDUCE-1464,New Feature,Major,,In JobTokenIdentifier change method getUsername to getUser which returns UGI,The TokenIdentifier interface has changed in HADOOP-6510. This jira tracks corresponding change in MR. The only change is that in JobTokenIdentifier getUsername method will be changed to getUser that will return ugi.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Sat; 6 Feb 2010 01:46:18 +0000,Tue; 24 Aug 2010 21:20:32 +0000,Mon; 8 Feb 2010 05:08:09 +0000,,,,HADOOP-6510,,https://issues.apache.org/jira/browse/MAPREDUCE-1464
MAPREDUCE-1465,Improvement,Major,harchive,archive partSize should be configurable,The archive part size is current set to 2GB.  For archiving 10^5 small files; it took 52 minutes since there is only 1 mapper.,Resolved,Duplicate,MAPREDUCE-1428,Mahadev konar,Tsz Wo Nicholas Sze,Mon; 8 Feb 2010 18:02:07 +0000,Wed; 10 Feb 2010 01:52:45 +0000,Wed; 10 Feb 2010 01:52:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1465
MAPREDUCE-1466,Improvement,Minor,client,FileInputFormat should save #input-files in JobConf,We already track the amount of data consumed by MR applications (MAP_INPUT_BYTES); alongwith; it would be useful to #input-files from the client-side for analysis. Along the lines of MAPREDUCE-1403; it would be easy to stick in the JobConf during job-submission.,Closed,Fixed,,Luke Lu,Arun C Murthy,Mon; 8 Feb 2010 19:32:40 +0000,Tue; 24 Aug 2010 21:20:33 +0000,Tue; 6 Apr 2010 22:43:50 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1466
MAPREDUCE-1467,Improvement,Minor,,Add a --verbose flag to Sqoop,Need a --verbose flag that sets the log4j level to DEBUG.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 9 Feb 2010 01:13:38 +0000,Fri; 2 Jul 2010 06:32:07 +0000,Fri; 12 Feb 2010 05:28:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1467
MAPREDUCE-1468,Improvement,Major,,Too many log messages generated if a node has a different Hadoop version installed,When upgrading or downgrading Hadoop; for a large cluster it is possible that some nodes are not upgraded downgraded. In this case; the jobtracker and namenode generates gigabytes of logs each day; reporting protocol version mismatch. Such log message is generated once every 3ms.  Ideally; the misbehaved node should quit retrying after several attempts if there is a protocol version mismatch. At the very least; the log message should be minimized (maybe once a day or once per start up).,Open,Unresolved,,Unassigned,Qi Liu,Tue; 9 Feb 2010 01:28:24 +0000,Tue; 9 Feb 2010 01:34:23 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1468
MAPREDUCE-1469,Bug,Major,,Sqoop should disable speculative execution in export,Concurrent writers of the same output shard may cause the database to try to insert duplicate primary keys concurrently. Not a good situation. Speculative execution should be forced off for this operation.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 9 Feb 2010 01:33:18 +0000,Fri; 2 Jul 2010 06:32:05 +0000,Fri; 12 Feb 2010 05:23:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1469
MAPREDUCE-1470,Improvement,Major,,Move Delegation token into Common so that we can use it for MapReduce also,We need to update one reference for map reduce when we move the hdfs delegation tokens.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Tue; 9 Feb 2010 06:36:02 +0000,Tue; 24 Aug 2010 21:20:34 +0000,Tue; 9 Feb 2010 08:31:02 +0000,,,,HDFS-949,,https://issues.apache.org/jira/browse/MAPREDUCE-1470
MAPREDUCE-1471,Bug,Major,,FileOutputCommitter does not safely clean up it's temporary files,When the FileOutputCommitter cleans up during it's cleanupJob method; it potentially deletes the temporary files of other concurrent jobs.  Since all the temporary files for all concurrent jobs are written to working_path directories should also be guaranteed to be unique to avoid this problem. Suggest modifying cleanupJob to only remove files that it created itself.,Resolved,Won't Fix,,Unassigned,Jim Finnessy,Tue; 9 Feb 2010 15:24:39 +0000,Mon; 23 Apr 2012 13:47:16 +0000,Sun; 22 Apr 2012 05:37:21 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1471
MAPREDUCE-1472,Bug,Blocker,jobtracker,JobTracker.submitJob holds a lock on the JobTracker while copying job-conf from HDFS,This could have very bad impact on responsiveness of the cluster.  JobTracker.submitJob also forks a DU and writes to it's local-disk.,Resolved,Duplicate,HADOOP-1354,Arun C Murthy,Arun C Murthy,Tue; 9 Feb 2010 23:38:05 +0000,Wed; 10 Feb 2010 17:18:59 +0000,Wed; 10 Feb 2010 17:18:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1472
MAPREDUCE-1473,Improvement,Major,,Sqoop should allow users to control export parallelism,Sqoop uses MapReduce jobs to export files back to a table in the database. The degree of parallelism is controlled by the number of splits; i.e.; the number of input files used. The bottleneck in the system; though; is likely to be the database itself.  Users should have the ability to tune the number of parallel exporters being used to a degree appropriate to their database deployment.,Resolved,Won't Fix,,Aaron Kimball,Aaron Kimball,Wed; 10 Feb 2010 02:20:56 +0000,Thu; 2 May 2013 02:29:28 +0000,Mon; 3 May 2010 18:41:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1473
MAPREDUCE-1474,Bug,Major,documentation,forrest docs for archives is out of date.,The docs for archives are out of date. The new docs that were checked into hadoop common were lost because of the project split.,Closed,Fixed,,Mahadev konar,Mahadev konar,Wed; 10 Feb 2010 02:23:31 +0000,Tue; 24 Aug 2010 21:20:35 +0000,Sat; 13 Feb 2010 10:36:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1474
MAPREDUCE-1475,Bug,Major,tasktracker,Race condition while launching task cleanup attempt.,We found a race condition while launching task cleanup tempt which could not be launched. And the slot was never released.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Wed; 10 Feb 2010 08:52:35 +0000,Wed; 10 Feb 2010 10:41:46 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1475
MAPREDUCE-1476,Bug,Major,,committer.needsTaskCommit should not be called for a task cleanup attempt,Currently; Task.done() calls committer.needsTaskCommit() to know whether it needs a commit or not. This need not be called for task cleanup attempt as no commit is required for a cleanup attempt.  Due to MAPREDUCE-1409; we saw a case where cleanup attempt went into COMMIT_PENDING state.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 10 Feb 2010 10:52:56 +0000,Tue; 24 Aug 2010 21:20:35 +0000,Mon; 15 Feb 2010 14:23:38 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1476
MAPREDUCE-1477,Bug,Major,jobtracker;tasktracker,Number of free slots on TaskTracker are calculated differently by JobTracker and TaskTracker,Currently number of free slots of TaskTracker come from different sources on JobTracker and TaskTracker. JobTracker iterates through TaskReports in TaskTrackerStatus and finds out how many slots are free; where as TaskTracker keeps it as a number.  We saw some situations where these values could be different (when bugs like MAPREDUCE-1475 were hit).  To make it a single source; I think TaskTracker should send number of free slots also in the heartbeat.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Wed; 10 Feb 2010 11:05:11 +0000,Wed; 10 Feb 2010 11:05:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1477
MAPREDUCE-1478,Improvement,Major,task,Separate the mapred.lib and mapreduce.lib classes to a different jar and include the user jar ahead of the lib jar.,Currently the user can't include updated library jars as part of their job. By pulling out the lib classes we can include the classes (eg. TextInputFormat) in the user's jar and get their version and not the system installed one.,Open,Unresolved,,Unassigned,Owen O'Malley,Wed; 10 Feb 2010 22:12:45 +0000,Tue; 18 Jan 2011 19:20:32 +0000,,,,,,MAPREDUCE-1453,https://issues.apache.org/jira/browse/MAPREDUCE-1478
MAPREDUCE-1479,New Feature,Major,tools/rumen,The trace generator should test operation on the current format by building a test case that runs an ad hoc cluster,Rumen's trace generator; built in final form when we install MAPREDUCE-1309 ; has features that can parse a history event log in the current format.  The testing story on that feature is not good.  We can improve it by writing a test case that builds a local single-node cluster; runs a carefully crafted map reduce job on that cluster; runs the trace generator on the resulting job tracker log; and finally tests the trace for correctness.,Open,Unresolved,,Unassigned,Dick King,Wed; 10 Feb 2010 22:57:48 +0000,Thu; 2 May 2013 02:29:28 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1479
MAPREDUCE-1480,Bug,Major,,CombineFileRecordReader does not properly initialize child RecordReader,CombineFileRecordReader instantiates child RecordReader instances but never calls their initialize() method to give them the proper TaskAttemptContext.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Thu; 11 Feb 2010 00:29:46 +0000,Thu; 2 May 2013 02:29:28 +0000,Tue; 23 Mar 2010 00:11:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1480
MAPREDUCE-1481,Bug,Major,contrib/streaming,Streaming should swallow IOExceptions when closing clientOut,in PipeMapRed.mapRedFinished; streaming flushes and closes clientOut_; the handle to the subprocess's stdin. If the subprocess has already exited or closed its stdin; this will generate a Broken Pipe IOException. This causes us to skip waitOutputThreads; which is incorrect; since the subprocess may have data still written from stdout that needs to be read.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Thu; 11 Feb 2010 00:53:45 +0000,Tue; 20 Dec 2011 14:21:49 +0000,,,0.20.1;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1481
MAPREDUCE-1482,Bug,Major,jobtracker,Better handling of task diagnostic information stored in the TaskInProgress,Task diagnostic information can be very large at times eating up Jobtracker's memory. There should be some way to avoid storing large error strings in JobTracker.,Closed,Fixed,,Amar Kamat,Amar Kamat,Thu; 11 Feb 2010 08:21:17 +0000,Tue; 24 Aug 2010 21:20:39 +0000,Tue; 16 Mar 2010 18:03:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1482
MAPREDUCE-1483,Bug,Major,jobtracker;security,CompletedJobStore should be authorized using job-acls,MAPREDUCE-1307 adds job-acls. CompletedJobStore serves job-status off DFS after jobs are long gone and needs to have job-acls also serialized so as to facilitate authorization of job related requests.,Resolved,Duplicate,MAPREDUCE-1307,Unassigned,Vinod Kumar Vavilapalli,Thu; 11 Feb 2010 09:42:35 +0000,Wed; 17 Feb 2010 18:30:56 +0000,Wed; 17 Feb 2010 18:30:56 +0000,,,,,MAPREDUCE-1307,https://issues.apache.org/jira/browse/MAPREDUCE-1483
MAPREDUCE-1484,Improvement,Major,,Framework should not sort the input splits,Currently the framework sorts the input splits by size before the job is submitted. This makes it very difficult to run map only jobs that transform the input because the assignment of input names to output names isn't obvious. We fixed this once in HADOOP-1440; but the fix was broken so it was rolled back.,Open,Unresolved,,Unassigned,Owen O'Malley,Thu; 11 Feb 2010 17:59:25 +0000,Thu; 4 Mar 2010 02:05:46 +0000,,,,,MAPREDUCE-207,,https://issues.apache.org/jira/browse/MAPREDUCE-1484
MAPREDUCE-1485,Improvement,Major,capacity-sched,CapacityScheduler should have prevent a single job taking over large parts of a cluster,The proposal is to have a per-queue limit on the number of concurrent tasks a job can run on a cluster.   We've seen cases where a single; large; job took over a majority of the cluster - worse; it meant that any bug in it caused issues for both the NameNode and the JobTracker.,Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 11 Feb 2010 19:52:13 +0000,Tue; 29 Jul 2014 23:31:41 +0000,Tue; 29 Jul 2014 23:31:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1485
MAPREDUCE-1486,Bug,Major,task,Configuration data should be preserved within the same MapTask,Map tasks involve a number of Contexts  at least a TaskAttemptContext and a MapContext. These context objects contain a Configuration each; when one context is initialized; it initializes its own Configuration by deep-copying a previous Configuration.  If one Context instance is used entirely prior to a second; more specific Context then the second Context should contain the configuration data initialized in the previous Context. This specifically affects the interaction between an InputFormat and its RecordReader instance(s).,Open,Unresolved,,Aaron Kimball,Aaron Kimball,Fri; 12 Feb 2010 02:11:45 +0000,Mon; 1 Nov 2010 22:30:55 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1486
MAPREDUCE-1487,Bug,Major,,io.DataInputBuffer.getLength() semantic wrong/confused,I was trying Google Protocol Buffer as a value type on hadoop; then when I used it in reducer; the parser always failed. while it worked fine on a plain inputstream reader or mapper.   the reason is th in IFile. as a hack ; to        valueIn.reset(nextValueBytes.getData(); nextValueBytes.getPosition(); nextValueBytes.getLength() - nextValueBytes.getPosition());  fixed the issue; but the semantic of DataInputBuffer should be fixed and streamlined,Open,Unresolved,,Unassigned,Yang Yang,Fri; 12 Feb 2010 10:12:01 +0000,Fri; 10 Aug 2012 10:20:47 +0000,,,0.20.1;0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1487
MAPREDUCE-1488,Improvement,Major,task,Add framework counters to track NN accesses,Shoot-off from HDFS-974.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Fri; 12 Feb 2010 19:35:10 +0000,Thu; 13 Jan 2011 02:27:36 +0000,,,,,HDFS-974,,https://issues.apache.org/jira/browse/MAPREDUCE-1488
MAPREDUCE-1489,Improvement,Major,,DataDrivenDBInputFormat should not query the database when generating only one split,DataDrivenDBInputFormat runs a query to establish bounding values for each split it generates; but if it's going to generate only one split (mapreduce.job.maps == 1); then there's no reason to do this. This will remove overhead associated with a single-threaded import of a non-indexed table since it avoids a full table scan.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Sat; 13 Feb 2010 01:35:42 +0000,Thu; 2 May 2013 02:29:28 +0000,Fri; 26 Mar 2010 23:50:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1489
MAPREDUCE-1490,Bug,Major,contrib/raid,Raid client throws NullPointerException during initialization,During instantiation and initialization; the DistributedRaidFileSystem class throws a NullPointerException.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Sun; 14 Feb 2010 01:35:41 +0000,Tue; 24 Aug 2010 21:20:41 +0000,Sun; 14 Feb 2010 09:09:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1490
MAPREDUCE-1491,Improvement,Major,contrib/raid,Use HAR filesystem to merge parity files ,The HDFS raid implementation (HDFS-503) creates a parity file for every file that is RAIDed. This puts additional burden on the memory requirements of the namenode. It will be  nice if the parity files are combined together using the HadoopArchive (har) format.   This was (HDFS-684) before; but raid migrated to MAPREDUCE.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Sun; 14 Feb 2010 04:41:32 +0000,Tue; 24 Aug 2010 21:20:42 +0000,Tue; 16 Feb 2010 23:37:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1491
MAPREDUCE-1492,Improvement,Major,contrib/raid,Delete or recreate obsolete har files used on hdfs raid,The current code for har on raid doesn't delete or recreate har directories when they become obsolete. We should fix that.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Sun; 14 Feb 2010 09:43:30 +0000,Mon; 12 Dec 2011 06:18:46 +0000,Sun; 20 Jun 2010 09:09:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1492
MAPREDUCE-1493,Sub-task,Major,jobtracker;security,Authorization for job-history pages,MAPREDUCE-1455 introduces authorization for most of the Map Reduce jsp pages and servlets; but left history pages. This JIRA will make sure that authorization checks are made while accessing job-history pages also.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Mon; 15 Feb 2010 07:19:33 +0000,Tue; 24 Aug 2010 21:20:43 +0000,Mon; 8 Mar 2010 09:47:06 +0000,,,,MAPREDUCE-1455,,https://issues.apache.org/jira/browse/MAPREDUCE-1493
MAPREDUCE-1494,Bug,Minor,tasktracker;test,TestJobDirCleanup verifies wrong jobcache directory,TestJobDirCleanup verifies tasktracker jobcache after MAPREDUCE-856.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Mon; 15 Feb 2010 11:13:10 +0000,Tue; 24 Aug 2010 21:20:43 +0000,Sun; 25 Apr 2010 01:24:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1494
MAPREDUCE-1495,Improvement,Major,,Reduce locking contention on JobTracker.getTaskCompletionEvents(),While profiling JT for slow performance with small-jobs; it was observed that JobTracker.getTaskCompletionEvents() is attributing to 40% of lock contention on JT.  This JIRA ticket is created to explore the possibilities of reducing the sychronized code block in this method.,Resolved,Duplicate,MAPREDUCE-1354,Unassigned,Rajesh Balamohan,Mon; 15 Feb 2010 13:04:10 +0000,Tue; 16 Feb 2010 19:52:38 +0000,Tue; 16 Feb 2010 19:52:38 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1495
MAPREDUCE-1496,Bug,Major,,org.apache.hadoop.mapred.lib.FieldSelectionMapReduce removes empty fields from key/value end,If input record's key and or value has empty fields in the end then these fields will be cut off by org.apache.hadoop.mapred.lib.FieldSelectionMapReduce,Open,Unresolved,,Unassigned,Maxim Zizin,Mon; 15 Feb 2010 18:01:54 +0000,Tue; 10 Jul 2012 21:27:08 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1496
MAPREDUCE-1497,Bug,Major,tasktracker,Suppress warning on inconsistent TaskTracker.indexCache synchronization,Findbugs warns that TaskTracker.indexCache is incorrectly synchronized.  It is not accessed synchronously from MapOutputServlet.doGet; TaskCleanupThread and  TaskTracker.killOverflowingTasks() method. Other callers access it synchronously.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 16 Feb 2010 10:09:32 +0000,Tue; 24 Aug 2010 21:20:44 +0000,Sat; 20 Mar 2010 07:17:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1497
MAPREDUCE-1498,Improvement,Major,client,Map reduce delegate token should be automatically set by the frontend,"Currently; if we need to create Job JobClient object in the backend; we need to add following code in the frontend:  TokenDelegationTokenIdentifier mrDelegationToken = jobClient.getDelegationToken(new Text()); TokenCache.addDelegationToken(""JobTracker""; mrDelegationToken);  Once we add this code; application is no longer compilable with old hadoop library. This add code maintenance burden to the application developer. If this is a common enough use case; we shall put this code in the core code rather than let application developer consume the pain.",Open,Unresolved,,Unassigned,Daniel Dai,Wed; 17 Feb 2010 02:51:45 +0000,Thu; 13 Jan 2011 02:29:20 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1498
MAPREDUCE-1499,Bug,Critical,jobtracker,JobTracker.finalizeJob inverts lock order and causes potential deadlock,This issue was brought up by Matei in MAPREDUCE-1436 as a fairsched bug; but it turns out it's a JT bug even with the fifo scheduler in unpatched 0.20.2. JobTracker.finalizeJob locks JT.jobs; JT.taskScheduler; etc; having gotten the JIP log before the JT lock.,Resolved,Cannot Reproduce,MAPREDUCE-1436,Aaron Kimball,Todd Lipcon,Wed; 17 Feb 2010 08:32:27 +0000,Thu; 25 Feb 2010 01:20:42 +0000,Wed; 24 Feb 2010 22:39:25 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1499
MAPREDUCE-1500,Bug,Major,jobtracker,Improve the way Counters are managed by JobTracker,Counters typically eat up a considerable amount of JobTracker's heap space. There is also a considerable heap space wastage due to duplicate Strings in Counters. Some amount of Counters' storage optimization can help reduce the load on JobTracker's memory.,Open,Unresolved,,Arun C Murthy,Amar Kamat,Wed; 17 Feb 2010 15:27:27 +0000,Fri; 5 Mar 2010 14:51:25 +0000,,,,,,MAPREDUCE-901,https://issues.apache.org/jira/browse/MAPREDUCE-1500
MAPREDUCE-1501,Improvement,Major,,FileInputFormat to support multi-level/recursive directory listing,As we have seen multiple times in the mailing list; users want to have the capability of getting all files out of a multi-level directory structure.  4 %3C4A258A16.8050300@darose.net%3E   One solution that our users had is to write a new FileInputFormat; but that means all existing FileInputFormat subclasses need to be changed in order to support this feature.  We can easily provide a JobConf option (which defaults to false) to FileInputFormat.listStatus(...) to recursively go into directory structure.,Resolved,Fixed,,Zheng Shao,Zheng Shao,Wed; 17 Feb 2010 22:55:51 +0000,Mon; 13 Sep 2010 06:11:10 +0000,Tue; 9 Mar 2010 01:57:51 +0000,,,inputformat,HIVE-1083,MAPREDUCE-1577,https://issues.apache.org/jira/browse/MAPREDUCE-1501
MAPREDUCE-1502,Improvement,Major,,Sqoop should run mysqldump in a mapper as opposed to a user-side process,"Sqoop currently runs mysqldump (""direct import mode"") in the local user process with a single thread. Better system performance and reliability could be achieved by running this in a parallel set of mapper tasks.",Resolved,Won't Fix,,Aaron Kimball,Aaron Kimball,Thu; 18 Feb 2010 01:07:36 +0000,Thu; 2 May 2013 02:29:28 +0000,Mon; 3 May 2010 18:41:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1502
MAPREDUCE-1503,Improvement,Major,,Push HADOOP-6551 into MapReduce,We need to throw readable exceptions instead of returning false.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Thu; 18 Feb 2010 19:35:42 +0000,Tue; 24 Aug 2010 21:20:44 +0000,Fri; 19 Feb 2010 08:59:29 +0000,,,,HADOOP-6551,,https://issues.apache.org/jira/browse/MAPREDUCE-1503
MAPREDUCE-1504,New Feature,Major,,SequenceFile.Reader constructor leaking resources,When SequenceFile.Reader constructor throws an IOException (because the file does not conform to SequenceFile format); we will have such a problem. The caller won't have a pointer to the reader because of the IOException thrown.  We should call in.close() inside the constructor to make sure that we don't leak resources (file descriptor and connection to the data node; etc).,Resolved,Fixed,HADOOP-5476,Unassigned,Zheng Shao,Thu; 18 Feb 2010 20:25:13 +0000,Sun; 21 Feb 2010 08:23:38 +0000,Sun; 21 Feb 2010 08:19:14 +0000,,,,,HIVE-1185,https://issues.apache.org/jira/browse/MAPREDUCE-1504
MAPREDUCE-1505,Bug,Major,client,Cluster class should create the rpc client only when needed,It will be good to have the org.apache.hadoop.mapreduce.Cluster create the rpc client object only when needed (when a call to the jobtracker is actually required). org.apache.hadoop.mapreduce.Job constructs the Cluster object internally and in many cases the application that created the Job object really wants to look at the configuration only. It'd help to not have these connections to the jobtracker especially when Job is used in the tasks (for e.g.; Pig calls mapreduce.FileInputFormat.setInputPath in the tasks and that requires a Job object to be passed).  In Hadoop 20; the Job object internally creates the JobClient object; and the same argument applies there too.,Closed,Fixed,,Dick King,Devaraj Das,Thu; 18 Feb 2010 21:56:51 +0000,Mon; 12 Dec 2011 06:19:55 +0000,Sun; 6 Jun 2010 01:28:33 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1505
MAPREDUCE-1506,Bug,Major,tasktracker,Assertion failure in TestTaskTrackerMemoryManager,With asserts enabled; TestTaskTrackerMemoryManager sometimes fails. From what I've inspected; it's because some tasks are marked as FAILED TIPFAILED while others are marked SUCCEEDED.  This can be reproduced by applying MAPREDUCE-1092 and then running ant clean test -Dtestcase=TestTaskTrackerMemoryManager,Resolved,Fixed,,Unassigned,Aaron Kimball,Thu; 18 Feb 2010 23:16:20 +0000,Mon; 9 Mar 2015 20:17:56 +0000,Tue; 29 Jul 2014 23:34:04 +0000,,,,,MAPREDUCE-1093;MAPREDUCE-1092,https://issues.apache.org/jira/browse/MAPREDUCE-1506
MAPREDUCE-1507,Bug,Major,,The old MapReduce API is only partially deprecated,Not all of the old API is currently marked as deprecated. E.g. org.apache.hadoop.mapred.OutputFormat is deprecated; but org.apache.hadoop.mapred.FileOutputFormat isn't.,Resolved,Won't Fix,,Tom White,Tom White,Thu; 18 Feb 2010 23:21:08 +0000,Tue; 29 Jul 2014 23:34:26 +0000,Tue; 29 Jul 2014 23:34:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1507
MAPREDUCE-1508,Bug,Major,test,NPE in TestMultipleLevelCaching on error cleanup path,TestMultipleLevelCaching dereferences objects in a finally block which may not have been initialized.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 19 Feb 2010 00:03:11 +0000,Tue; 24 Aug 2010 21:20:46 +0000,Sat; 20 Mar 2010 06:14:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1508
MAPREDUCE-1509,Improvement,Major,harchive,Partition size of Hadoop Archives should be configurable,The size of partitions on Hadoop Archives is fixed to 2G:    static final long partSize = 2 * 1024 * 1024 * 1024l;  We should make it a configurable parameter so that users can define it at the command line  $ hadoop archive -partsize 4 ....,Resolved,Duplicate,MAPREDUCE-1428,Rodrigo Schmidt,Rodrigo Schmidt,Fri; 19 Feb 2010 02:43:27 +0000,Fri; 19 Mar 2010 01:15:09 +0000,Fri; 19 Mar 2010 01:15:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1509
MAPREDUCE-1510,Improvement,Major,contrib/raid,RAID should regenerate parity files if they get deleted,Currently; if a source file has a replication factor lower or equal to that expected by RAID; the file is skipped and no parity file is generated. I don't think this is a good behavior since parity files can get wrongly deleted; leaving the source file with a low replication factor. In that case; raid should be able to recreate the parity file.,Resolved,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Fri; 19 Feb 2010 03:01:28 +0000,Thu; 4 Mar 2010 18:24:17 +0000,Tue; 2 Mar 2010 21:48:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1510
MAPREDUCE-1511,Improvement,Major,job submission,Examples should not use deprecated APIs,MAPREDUCE-777 deprecated some APIs which are still being used by the examples. This issue is to fix the examples so they use the replacements.,Open,Unresolved,,Tom White,Tom White,Fri; 19 Feb 2010 05:18:43 +0000,Mon; 22 Feb 2010 04:45:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1511
MAPREDUCE-1512,Improvement,Minor,contrib/raid,RAID could use HarFileSystem directly instead of FileSystem.get,Makes the code run slightly faster and avoids possible problems in matching the right filesystem like the stale cache reported in HADOOP-6097.  This is a minor improvement for trunk; but it is really helpful for people running RAID on earlier releases susceptible to HADOOP-6097; since RAID would crash on them.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Fri; 19 Feb 2010 08:04:54 +0000,Tue; 24 Aug 2010 21:20:46 +0000,Thu; 4 Mar 2010 20:51:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1512
MAPREDUCE-1513,Bug,Minor,,Fix the deprecation around MapFileOutputFormat,MapFileOutputFormat relies on the old version of OutputFormat; making it useless.  This is a known issue (see also: http: %3c4A4AF7F1.7000105@yahoo-inc.com%3e )  I couldn't find a jira issue for it; so here we are..,Open,Unresolved,,Unassigned,Kyle Maxwell,Fri; 19 Feb 2010 22:03:13 +0000,Fri; 2 Jul 2010 00:04:18 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1513
MAPREDUCE-1514,Improvement,Major,documentation,Add documentation on permissions; limitations; error handling for archives.,add documentaion on permissions aspect of archives and other limitations that it might have. Also add documentation on error handling (with respect to quota's otherwise) to the forrest docs.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 19 Feb 2010 23:14:38 +0000,Tue; 24 Aug 2010 21:20:49 +0000,Thu; 1 Apr 2010 20:47:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1514
MAPREDUCE-1515,Bug,Major,build,need to pass down java5 and forrest home variables,Currently; the build script doesn't pass down the variables for   and forrest; so the build breaks unless they are on the command line.,Closed,Fixed,,Al Thompson,Owen O'Malley,Sat; 20 Feb 2010 22:15:13 +0000,Mon; 27 Dec 2010 20:08:48 +0000,Mon; 26 Apr 2010 03:54:39 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1515
MAPREDUCE-1516,New Feature,Major,,JobTracker should issue a delegation token only for kerberos authenticated client,Delegation tokens should be issued only if the client is kerberos authenticated.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Sun; 21 Feb 2010 03:15:06 +0000,Mon; 12 Dec 2011 06:18:56 +0000,Fri; 11 Jun 2010 21:47:43 +0000,,,,HADOOP-6580;HADOOP-6814,,https://issues.apache.org/jira/browse/MAPREDUCE-1516
MAPREDUCE-1517,New Feature,Major,contrib/streaming,streaming should support running on background,"StreamJob submit the job and use a while loop monitor the progress. I prefer it running on background.  Just add """" at the end of command is a alternative solution; but it keeps a  process on client machine. When submit hundreds jobs at the same time; the client machine is overloaded.  Adding a -background option to StreamJob; tell it only submit and don't monitor the progress.",Closed,Fixed,,Bochun Bai,Bochun Bai,Sun; 21 Feb 2010 06:01:55 +0000,Mon; 12 Dec 2011 06:19:52 +0000,Tue; 28 Sep 2010 08:19:55 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1517
MAPREDUCE-1518,Improvement,Major,contrib/raid,On contrib/raid; the RaidNode currently runs the deletion check for parity files on directories too. It would be better if it didn't.,nan,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Mon; 22 Feb 2010 00:05:24 +0000,Tue; 24 Aug 2010 21:20:51 +0000,Fri; 5 Mar 2010 08:54:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1518
MAPREDUCE-1519,Bug,Major,contrib/raid,RaidNode fails to create new parity file if an older version already exists,When RaidNode tries to recreate a parity file for a source file that has been modified (recreated) recently; it crashes.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Mon; 22 Feb 2010 03:02:36 +0000,Tue; 24 Aug 2010 21:20:52 +0000,Tue; 23 Feb 2010 07:31:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1519
MAPREDUCE-1520,Bug,Major,,TestMiniMRLocalFS fails on trunk,TestMiniMRLocalFS fails on trunk. I checked with both trunk revs - pre and post MAPREDUCE-1430 commit and it failed in both the cases.,Closed,Fixed,,Amareshwari Sriramadasu,Devaraj Das,Mon; 22 Feb 2010 06:11:46 +0000,Tue; 24 Aug 2010 21:20:52 +0000,Thu; 4 Mar 2010 06:17:14 +0000,,0.22.0,,,HADOOP-6545,https://issues.apache.org/jira/browse/MAPREDUCE-1520
MAPREDUCE-1521,Improvement,Major,jobtracker,Protection against incorrectly configured reduces,We've seen a fair number of instances where naive users process huge data-sets (10TB) with badly mis-configured #reduces e.g. 1 reduce.  This is a significant problem on large clusters since it takes each attempt of the reduce a long time to shuffle and then run into problems such as local disk-space etc. Then it takes 4 such attempts.  Proposal: Come up with heuristics configs to fail such jobs early.   Thoughts?,Resolved,Fixed,,Mahadev konar,Arun C Murthy,Mon; 22 Feb 2010 17:43:55 +0000,Tue; 29 Jul 2014 23:35:23 +0000,Tue; 29 Jul 2014 23:35:23 +0000,,,,,PIG-1249,https://issues.apache.org/jira/browse/MAPREDUCE-1521
MAPREDUCE-1522,Bug,Blocker,,FileInputFormat may change the file system of an input path,org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(Job job; Path path) uses the default FileSystem but not the FileSystem specified in the path.   There is a similar problem in FileInputFormat.setInputPaths(..).,Resolved,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Mon; 22 Feb 2010 22:00:26 +0000,Thu; 2 May 2013 02:29:31 +0000,Fri; 5 Mar 2010 22:21:22 +0000,,,,,HADOOP-6564,https://issues.apache.org/jira/browse/MAPREDUCE-1522
MAPREDUCE-1523,Bug,Major,tools/rumen,Sometimes rumen trace generator fails to extract the job finish time.,We saw sometimes (not very often) that rumen may fail to extract the job finish time from Hadoop 0.20 history log.,Closed,Fixed,,Dick King,Hong Tang,Mon; 22 Feb 2010 22:21:54 +0000,Fri; 29 Oct 2010 02:04:42 +0000,Thu; 8 Apr 2010 00:59:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1523
MAPREDUCE-1524,Improvement,Major,,Support for CLOB and BLOB values larger than can fit in memory,"The patch in MAPREDUCE-1446 provides support for ""inline"" CLOB and BLOB values which can be fully materialized. Values which are too big for RAM should be written to separate files in HDFS and referenced in an indirect fashion; access should be provided through a stream.",Resolved,Won't Fix,,Aaron Kimball,Aaron Kimball,Mon; 22 Feb 2010 23:06:01 +0000,Thu; 2 May 2013 02:29:28 +0000,Mon; 3 May 2010 18:41:26 +0000,,,,,MAPREDUCE-1446,https://issues.apache.org/jira/browse/MAPREDUCE-1524
MAPREDUCE-1525,Bug,Major,build,mapreduce- trunk-commit fails because of not able to delete ivy file,mapreduce- trunk-commit fails because of not able to delete ivy file  http: .nfs000000000540c1c300000029,Resolved,Cannot Reproduce,,Unassigned,Iyappan Srinivasan,Tue; 23 Feb 2010 04:54:25 +0000,Tue; 29 Jul 2014 23:38:17 +0000,Tue; 29 Jul 2014 23:38:17 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1525
MAPREDUCE-1526,Improvement,Major,contrib/gridmix,Cache the job related information while submitting the job ; this would avoid many RPC calls to JobTracker.,nan,Closed,Fixed,,rahul k singh,rahul k singh,Tue; 23 Feb 2010 11:28:03 +0000,Mon; 12 Dec 2011 06:19:24 +0000,Wed; 14 Jul 2010 09:25:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1526
MAPREDUCE-1527,Improvement,Major,,QueueManager should issue warning if mapred-queues.xml is skipped.,"MAPREDUCE-861 added support for hierarchical queues and used a new file mapred-queues.xml to configure queues. But the QueueManager will silently skip the file if property ""mapred.queue.names"" is defined in Configuration. This tripped us when we are testing MAPREDUCE-1235 and copied configuration files from a Hadoop 0.20 cluster.  I suggest QueueManager issue a friendly warning if both of the following are true: (1) ""mapred.queue.names"" exists in Configuration; (2) ""mapred-queues.xml"" is found in the classpath.",Closed,Fixed,,Hong Tang,Hong Tang,Tue; 23 Feb 2010 22:22:47 +0000,Tue; 24 Aug 2010 21:20:54 +0000,Fri; 5 Mar 2010 08:34:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1527
MAPREDUCE-1528,Bug,Major,,TokenStorage should not be static,Currently; TokenStorage is a singleton. This doesn't work for some use cases; such as Oozie. I think that each Job should have a TokenStorage that is associated it.,Closed,Fixed,,Jitendra Nath Pandey,Owen O'Malley,Tue; 23 Feb 2010 22:26:05 +0000,Mon; 12 Dec 2011 06:18:56 +0000,Fri; 9 Jul 2010 20:28:30 +0000,,,,HADOOP-6845,,https://issues.apache.org/jira/browse/MAPREDUCE-1528
MAPREDUCE-1529,Bug,Major,,TokenCache - needs api to clear the cache.,It may cause some tests to fail (ones that run multiple jobs from the same process). For example TestQueueManager,Resolved,Won't Fix,,Boris Shkolnik,Boris Shkolnik,Tue; 23 Feb 2010 23:50:16 +0000,Mon; 22 Mar 2010 17:48:05 +0000,Mon; 22 Mar 2010 17:48:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1529
MAPREDUCE-1530,Improvement,Minor,contrib/vaidya,Hadoop vaidya - additional diagnostic rule,Additional ten diagnostic rules for hadoop vaidya.,Open,Unresolved,,Unassigned,Suhas Gogate,Wed; 24 Feb 2010 07:25:35 +0000,Wed; 24 Feb 2010 07:28:14 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1530
MAPREDUCE-1531,Bug,Critical,tasktracker,Log truncation via MAPREDUCE-1100 is broken,MAPREDUCE-1100 has a bug where the index isn't updated correctly.,Resolved,Invalid,,Unassigned,Arun C Murthy,Wed; 24 Feb 2010 18:58:15 +0000,Thu; 25 Feb 2010 04:34:05 +0000,Thu; 25 Feb 2010 04:34:05 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1531
MAPREDUCE-1532,Bug,Major,job submission;security,Delegation token is obtained as the superuser,When the UserGroupInformation.doAs is invoked for proxy users; the delegation token is incorrectly obtained as the real user.,Closed,Fixed,,Devaraj Das,Devaraj Das,Thu; 25 Feb 2010 02:55:05 +0000,Mon; 12 Dec 2011 06:20:07 +0000,Wed; 12 May 2010 03:00:15 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1532
MAPREDUCE-1533,Bug,Major,jobtracker,Reduce or remove usage of String.format() usage in CapacityTaskScheduler.updateQSIObjects and Counters.makeEscapedString(),"When short jobs are executed in hadoop with OutOfBandHeardBeat=true; JT executes heartBeat() method heavily. This internally makes a call to CapacityTaskScheduler.updateQSIObjects().   CapacityTaskScheduler.updateQSIObjects(); internally calls String.format() for setting the job scheduling information. Based on the datastructure size of ""jobQueuesManager"" and ""queueInfoMap""; the number of times String.format() gets executed becomes very high. String.format() internally does pattern matching which turns to be out very heavy (This was revealed while profiling JT. Almost 57% of time was spent in CapacityScheduler.assignTasks(); out of which String.format() took 46%.  Would it be possible to do String.format() only at the time of invoking JobInProgress.getSchedulingInfo?. This might reduce the pressure on JT while processing heartbeats.",Closed,Fixed,,Dick King,Rajesh Balamohan,Thu; 25 Feb 2010 05:06:12 +0000,Mon; 12 Dec 2011 06:19:20 +0000,Sun; 6 Jun 2010 06:13:50 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1533
MAPREDUCE-1534,Bug,Major,task,MAP_INPUT_BYTES couner is not recorded with new M/R API ,I ran a WordCount example from hadoop 0.20.0 distribution and it does not record the MAP_INPUT_BYTES counter. Looks like it may be a problem with new mapreduce (Job) API.,Resolved,Duplicate,HADOOP-5710,Unassigned,Suhas Gogate,Thu; 25 Feb 2010 18:13:55 +0000,Thu; 25 Feb 2010 18:26:38 +0000,Thu; 25 Feb 2010 18:26:38 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1534
MAPREDUCE-1535,Improvement,Blocker,,Replace usage of FileStatus#isDir(),HADOOP-6585 will deprecate FileStatus#isDir(). This jira is for replacing all uses of isDir() in MR with checks of isDirectory() or isFile() as needed.,Closed,Fixed,,Eli Collins,Eli Collins,Fri; 26 Feb 2010 01:35:12 +0000,Tue; 24 Aug 2010 21:20:55 +0000,Mon; 31 May 2010 17:48:10 +0000,,0.21.0;0.22.0,,HADOOP-6585,,https://issues.apache.org/jira/browse/MAPREDUCE-1535
MAPREDUCE-1536,Bug,Major,,DataDrivenDBInputFormat does not split date columns correctly.,The DateSplitter does not properly split a range of (min; max) dates.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Fri; 26 Feb 2010 03:51:21 +0000,Tue; 24 Aug 2010 21:20:55 +0000,Thu; 18 Mar 2010 17:37:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1536
MAPREDUCE-1537,Bug,Major,,TestDelegationTokenRenewal fails,TestDelegationTokenRenewal does not compile in trunk. The reason is that DelegationTokenSecretManager in hdfs requires namesystem in constructor.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Fri; 26 Feb 2010 03:53:58 +0000,Tue; 24 Aug 2010 21:20:56 +0000,Fri; 26 Feb 2010 21:31:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1537
MAPREDUCE-1538,Bug,Major,tasktracker,TrackerDistributedCacheManager can fail because the number of subdirectories reaches system limit,TrackerDistributedCacheManager deletes the cached files when the size goes up to a configured number. But there is no such limit for the number of subdirectories. Therefore the number of subdirectories may grow large and exceed system limit. This will make TT cannot create directory when getLocalCache and fails the tasks.,Closed,Fixed,,Scott Chen,Scott Chen,Fri; 26 Feb 2010 04:29:04 +0000,Tue; 24 Aug 2010 21:20:57 +0000,Fri; 16 Apr 2010 22:12:44 +0000,,0.22.0,,MAPREDUCE-1568,MAPREDUCE-1914,https://issues.apache.org/jira/browse/MAPREDUCE-1538
MAPREDUCE-1539,New Feature,Major,,authorization checks for inter-server protocol (based on HADOOP-6600),authorization checks for inter-server protocol (based on HADOOP-6600),Resolved,Fixed,,Boris Shkolnik,Boris Shkolnik,Fri; 26 Feb 2010 08:08:34 +0000,Fri; 14 May 2010 02:15:22 +0000,Fri; 14 May 2010 02:15:22 +0000,,,,HADOOP-6600,,https://issues.apache.org/jira/browse/MAPREDUCE-1539
MAPREDUCE-1540,Bug,Major,jobtracker,Sometimes JobTracker holds stale refrence of JobInProgress even after Job gets retired,Ran random writer; sort and sort validate job. Checked the jmap -histo:live and verified that there is no reference of JobInProgress after Jobs are retired  Now submitter around 77  sleeps of around 10000 maps. then after 1 hr killed all the job when jobs got retired. again checked jmap -histo:live  for JobInProgress for JT process found 2 references were there. Found this while doing sanity testing of 1316,Resolved,Cannot Reproduce,,Amar Kamat,Karam Singh,Fri; 26 Feb 2010 08:50:15 +0000,Fri; 26 Feb 2010 19:11:20 +0000,Fri; 26 Feb 2010 19:11:20 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1540
MAPREDUCE-1541,Bug,Major,jobtracker,JobHistory page should list job start time rather than job-tracker start time,nan,Resolved,Not A Problem,,Devaraj K,Arun C Murthy,Fri; 26 Feb 2010 19:47:27 +0000,Sun; 29 Jan 2012 02:27:26 +0000,Sun; 29 Jan 2012 02:27:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1541
MAPREDUCE-1542,Bug,Major,security,Deprecate mapred.permissions.supergroup in favor of hadoop.cluster.administrators,HADOOP-6568 added the configuration hadoop.cluster.administrators through which admins can configure who the superusers supergroups for the cluster are. MAPREDUCE itself already has mapred.permissions.supergroup (which is just a single group). As agreed upon at HADOOP-6568; this should be deprecated in favor of hadoop.cluster.administrators.,Resolved,Won't Fix,,Ravi Gummadi,Vinod Kumar Vavilapalli,Mon; 1 Mar 2010 03:58:53 +0000,Wed; 5 May 2010 11:12:01 +0000,Wed; 5 May 2010 06:06:19 +0000,,,configuration,,HDFS-1008;HADOOP-6748;MAPREDUCE-1754,https://issues.apache.org/jira/browse/MAPREDUCE-1542
MAPREDUCE-1543,Bug,Major,security,Log messages of JobACLsManager should use security logging of HADOOP-6586,JobACLsManager added in MAPREDUCE-1307 logs the successes and failures w.r.t job-level authorization in the corresponding Daemons' logs. The log messages should instead use security logging of HADOOP-6586.,Closed,Fixed,,Luke Lu,Vinod Kumar Vavilapalli,Mon; 1 Mar 2010 04:35:17 +0000,Mon; 12 Dec 2011 06:19:36 +0000,Sun; 6 Jun 2010 04:36:41 +0000,,,logging,,,https://issues.apache.org/jira/browse/MAPREDUCE-1543
MAPREDUCE-1544,Bug,Minor,,Miscellaneous improvements to HTML markup for web UIs,The Web UIs have various bits of bad markup (eg missing head sections; some pages missing CSS links; inconsistent td vs th for table headings). We should fix this up.,Resolved,Incomplete,,Ben Lee,Todd Lipcon,Mon; 1 Mar 2010 22:38:29 +0000,Tue; 29 Jul 2014 23:40:41 +0000,Tue; 29 Jul 2014 23:40:41 +0000,,,newbie,,HDFS-1013,https://issues.apache.org/jira/browse/MAPREDUCE-1544
MAPREDUCE-1545,Improvement,Major,jobtracker,Add 'first-task-launched' to job-summary,It would be useful to track 'first-task-launched' time to job-summary for better reporting.,Closed,Fixed,,Luke Lu,Arun C Murthy,Mon; 1 Mar 2010 23:07:59 +0000,Mon; 12 Dec 2011 06:19:26 +0000,Sun; 6 Jun 2010 04:20:02 +0000,,,,HADOOP-6657,,https://issues.apache.org/jira/browse/MAPREDUCE-1545
MAPREDUCE-1546,Improvement,Minor,,Jobtracker JSP pages should automatically redirect to the corresponding history page if not in memory,MAPREDUCE-1185 redirects jobdetails.jsp to it's corresponding history page.  For convenience; we should also redirect the following JSP pages to the corresponding history pages: jobconf.jsp jobtasks.jsp taskdetails.jsp taskstats.jsp,Resolved,Fixed,,Scott Chen,Scott Chen,Tue; 2 Mar 2010 02:00:21 +0000,Wed; 5 May 2010 18:29:58 +0000,Wed; 5 May 2010 07:18:18 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1546
MAPREDUCE-1547,Bug,Major,build,Build Hadoop-Mapreduce-trunk and Mapreduce-trunk-Commit  fails,http: commitBuild.sh: No such file or directory,Closed,Fixed,,Giridharan Kesavan,Iyappan Srinivasan,Tue; 2 Mar 2010 05:14:58 +0000,Tue; 24 Aug 2010 21:20:58 +0000,Tue; 2 Mar 2010 09:10:35 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1547
MAPREDUCE-1548,Improvement,Major,harchive,Hadoop archives should be able to preserve times and other properties from original files,"Files inside hadoop archives don't keep their original:   	modification time 	access time 	permission 	owner 	group    all such properties are currently taken from the file storing the archive index; and not the stored files. This doesn't look very correct.  There should be possible to preserve the original properties of the stored files.",Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Tue; 2 Mar 2010 09:11:09 +0000,Mon; 26 Jan 2015 22:18:10 +0000,Thu; 23 Sep 2010 04:31:43 +0000,,0.22.0,,MAPREDUCE-1578,MAPREDUCE-1628;HADOOP-11436,https://issues.apache.org/jira/browse/MAPREDUCE-1548
MAPREDUCE-1549,Bug,Major,test,TestTrackerDistributedCacheManager failed on some machines,TestTrackerDistributedCacheManager.testPublicPrivateCache fails on some machines.,Resolved,Duplicate,HADOOP-5710,Unassigned,Amar Kamat,Tue; 2 Mar 2010 10:15:04 +0000,Tue; 29 May 2012 18:53:51 +0000,Fri; 18 Nov 2011 23:31:51 +0000,,,,,MAPREDUCE-3356;MAPREDUCE-2073,https://issues.apache.org/jira/browse/MAPREDUCE-1549
MAPREDUCE-1550,Bug,Major,jobtracker,UGI.doAs should not be used for getting the history file of jobs,When the jobtracker tries to open a job history file it does a doAs to get the filesystem for the user (that had submitted the job). This should not be done since the job history files are owned by the jobtracker.,Resolved,Invalid,,Devaraj Das,Devaraj Das,Tue; 2 Mar 2010 20:21:20 +0000,Thu; 9 Sep 2010 11:44:42 +0000,Thu; 9 Sep 2010 11:44:42 +0000,,0.22.0,,MAPREDUCE-1664,,https://issues.apache.org/jira/browse/MAPREDUCE-1550
MAPREDUCE-1551,Bug,Major,test,TestMiniMRLocalFS fails,TestMiniMRLocalFS fails consistently on trunk:,Resolved,Duplicate,MAPREDUCE-1520,Unassigned,Chris Douglas,Tue; 2 Mar 2010 23:29:50 +0000,Wed; 3 Mar 2010 03:37:19 +0000,Wed; 3 Mar 2010 03:37:19 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1551
MAPREDUCE-1552,Improvement,Major,,TaskTracker should report which fs during error,We run with ZFS with fs quotas for the mapred spill space to prevent it over-running the HDFS space.  During merge; we some times end up running out of space.  It would be useful if the stack trace (see below) included which file system the errors actually came from.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 3 Mar 2010 00:30:03 +0000,Wed; 2 Nov 2011 17:43:44 +0000,Wed; 2 Nov 2011 17:43:44 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1552
MAPREDUCE-1553,Bug,Blocker,documentation,mapred.userlog.retain.hours is improperly renamed in MAPREDUCE-849,mapred.userlog.retain.hours is renamed as mapred.task.userlog.retain.hours in JobContext. But; in mapred-default; it is mapreduce.task.userlog.retain.hours.,Resolved,Won't Fix,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 3 Mar 2010 06:39:06 +0000,Tue; 13 Apr 2010 08:36:09 +0000,Tue; 13 Apr 2010 08:36:09 +0000,,0.21.0,,MAPREDUCE-927,,https://issues.apache.org/jira/browse/MAPREDUCE-1553
MAPREDUCE-1554,Bug,Major,,If user name contains '_'; then searching of jobs based on user name on job history web UI doesn't work,"If user name contains underscore as part of it; then searching of jobs based on user name on job history web UI doesn't work. This is because in code; everywhere     is done on history file name to get user name. And other parts of history file name also should not be obtained by using split(""_"").",Resolved,Won't Fix,,Devaraj K,Ravi Gummadi,Wed; 3 Mar 2010 09:38:38 +0000,Thu; 5 Feb 2015 17:14:26 +0000,Thu; 5 Feb 2015 17:14:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1554
MAPREDUCE-1555,Bug,Major,task,tasktracker heartbeat hang,Maybe some code of MapTask is wrong.       In above code; if the splitMetaInfo is set null; Second Serialization (will invoke write) will throw NullPointerException.,Open,Unresolved,,Unassigned,Ruyue Ma,Wed; 3 Mar 2010 17:18:56 +0000,Thu; 15 Apr 2010 07:36:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1555
MAPREDUCE-1556,Improvement,Major,jobtracker,upgrade to Avro 1.3.0,Avro 1.3.0 has now been released.  HADOOP-6486 and HDFS-892 require it; and the version of Avro used by MapReduce should be synchronized with these projects.,Closed,Fixed,,Doug Cutting,Doug Cutting,Wed; 3 Mar 2010 19:33:11 +0000,Tue; 24 Aug 2010 21:20:59 +0000,Thu; 11 Mar 2010 22:38:49 +0000,,,,HADOOP-6486,,https://issues.apache.org/jira/browse/MAPREDUCE-1556
MAPREDUCE-1557,Improvement,Trivial,,MapReduce teragen  example should print correct error message for invalid inputs. Currently throws ArrayIndexOutOfBoundsException .,MapReduce teragen  example should print correct error message for invalid inputs.  Currently for invalid  CLI arguments stack trace is thrown with  ArrayIndexOutOfBoundsException.,Resolved,Duplicate,MAPREDUCE-5807,Ravi Phulari,Ravi Phulari,Wed; 3 Mar 2010 20:06:14 +0000,Tue; 17 Mar 2015 09:53:25 +0000,Tue; 17 Mar 2015 09:53:25 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1557
MAPREDUCE-1558,Bug,Major,security,specify correct server principal for RefreshAuthorizationPolicyProtocol and RefreshUserToGroupMappingsProtocol protocols in MRAdmin (for HADOOP-6612),nan,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Wed; 3 Mar 2010 22:47:33 +0000,Mon; 12 Dec 2011 06:18:35 +0000,Fri; 14 May 2010 19:50:37 +0000,,,,HADOOP-6612,,https://issues.apache.org/jira/browse/MAPREDUCE-1558
MAPREDUCE-1559,Bug,Major,jobtracker,The DelegationTokenRenewal timer task should use the jobtracker's credentials to create the filesystem,The submitJob RPC finally creates a timer task for renewing the delegation tokens of the submitting user. This timer task inherits the context of the RPC handler that runs in the context of the job submitting user; and when it tries to create a filesystem; the RPC client tries to use the user's credentials. This should instead use the JobTracker's credentials.,Closed,Fixed,,Devaraj Das,Devaraj Das,Thu; 4 Mar 2010 01:03:03 +0000,Mon; 12 Dec 2011 06:19:30 +0000,Sat; 19 Jun 2010 01:45:46 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1559
MAPREDUCE-1560,Bug,Major,tasktracker,Better diagnostic message for tasks killed for going over vmem limit,Currently the user has no indication of his tasks getting killed due to vmem limit; the only way to know is by looking at TT logs. We should get the TT to insert a diagnostic string for the task to indicate this.,Resolved,Invalid,,Arun C Murthy,Arun C Murthy,Fri; 5 Mar 2010 03:43:22 +0000,Fri; 5 Mar 2010 08:53:00 +0000,Fri; 5 Mar 2010 08:46:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1560
MAPREDUCE-1561,Bug,Major,,"mapreduce patch tests hung with ""java.lang.OutOfMemoryError: Java heap space""",http: console  Error form the console:   exec     junit   INFO mapreduce.Job:  map 0% reduce 0%,Resolved,Duplicate,MAPREDUCE-1556,Doug Cutting,Giridharan Kesavan,Fri; 5 Mar 2010 06:32:43 +0000,Tue; 23 Mar 2010 10:54:36 +0000,Tue; 23 Mar 2010 10:54:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1561
MAPREDUCE-1562,Bug,Major,test,TestBadRecords fails sometimes,TestBadRecords.testMapRed fails sometimes. One instance of this was seen by Hudson while testing MAPREDUCE-890: http: .,Resolved,Duplicate,MAPREDUCE-1366,Unassigned,Vinod Kumar Vavilapalli,Fri; 5 Mar 2010 07:02:28 +0000,Fri; 28 Jan 2011 03:11:18 +0000,Fri; 28 Jan 2011 03:11:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1562
MAPREDUCE-1563,Bug,Major,tasktracker,Task diagnostic info would get missed sometimes.,TaskStatus's diagnostic info is reset in TaskTracker.cloneAndResetRunningTaskStatuses() method while constructing TaskTrackerStatus to send the heartbeat. It is also reset after receiving the response in TaskTracker.transmitHeartbeat() method. If any task sets diagnostic info between both the clearStatus() calls; the info is lost.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Fri; 5 Mar 2010 08:37:31 +0000,Thu; 13 Jan 2011 02:29:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1563
MAPREDUCE-1564,Improvement,Major,documentation,Document the framework counters,We need to document the framework counters in the mapred-tutorial.,Open,Unresolved,,Unassigned,Arun C Murthy,Fri; 5 Mar 2010 16:52:12 +0000,Wed; 11 May 2011 00:36:37 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-1564
MAPREDUCE-1565,Improvement,Major,jobtracker;task,Need human-readable counter groups for framework job-counters and task-counters,Currently the 'group' is just the class-names of the counters; which is very unfortunate - we'll probably need to have both for a while to maintain compatibility; sigh.,Open,Unresolved,,Unassigned,Arun C Murthy,Fri; 5 Mar 2010 17:53:18 +0000,Thu; 13 Jan 2011 02:29:15 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1565
MAPREDUCE-1566,Bug,Major,security,Need to add a mechanism to import tokens and secrets into a submitted job.,We need to include tokens and secrets into a submitted job. I propose adding a configuration attribute that when pointed at a token storage file will include the tokens and secrets from that token storage file.,Closed,Fixed,,Jitendra Nath Pandey,Owen O'Malley,Fri; 5 Mar 2010 23:06:47 +0000,Mon; 12 Dec 2011 06:19:31 +0000,Fri; 23 Jul 2010 00:51:16 +0000,,,,HADOOP-6861,,https://issues.apache.org/jira/browse/MAPREDUCE-1566
MAPREDUCE-1567,Bug,Major,security,Sharing Credentials between JobConfs leads to unintentional sharing of credentials,Currently; if code does new JobConf(jobConf); it will share the Credentials. That leads to unintentional sharing.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Sat; 6 Mar 2010 00:26:41 +0000,Thu; 13 Jan 2011 02:28:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1567
MAPREDUCE-1568,Improvement,Major,,TrackerDistributedCacheManager should clean up cache in a background thread,Right now the TrackerDistributedCacheManager do the clean up with the following code path:   The deletion of the cache files can take a long time and it should not be done by a task. We suggest that there should be a separate thread checking and clean up the cache files.,Closed,Fixed,,Scott Chen,Scott Chen,Sat; 6 Mar 2010 01:43:17 +0000,Tue; 24 Aug 2010 21:21:00 +0000,Thu; 29 Apr 2010 22:43:34 +0000,,0.22.0,,MAPREDUCE-1538,,https://issues.apache.org/jira/browse/MAPREDUCE-1568
MAPREDUCE-1569,Improvement,Minor,contrib/mrunit,Mock Contexts & Configurations,Currently the library creates a new Configuration object in the MockMapContext and MocKReduceContext constructors; rather than allowing the developer to configure and pass their own,Closed,Fixed,MAPREDUCE-2002,Chris White,Chris White,Sat; 6 Mar 2010 14:12:24 +0000,Thu; 15 Mar 2012 07:47:26 +0000,Sat; 20 Mar 2010 06:30:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1569
MAPREDUCE-1570,Improvement,Minor,contrib/mrunit,Shuffle stage - Key and Group Comparators,Shuffle method in org.apache.hadoop.mrunit.MapReduceDriverBase doesn't currently allow the use of custom GroupingComparator and SortComparator.,Closed,Fixed,,Chris White,Chris White,Sat; 6 Mar 2010 14:19:52 +0000,Tue; 24 Aug 2010 21:21:02 +0000,Sun; 25 Apr 2010 20:48:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1570
MAPREDUCE-1571,Bug,Major,,OutOfMemoryError during shuffle,"A OutOfMemoryError can occur when determining if the shuffle can be accomplished in memory  2010-03-06 07:54:49;621 INFO org.apache.hadoop.mapred.ReduceTask: Shuffling 4191933 bytes (435311 raw bytes) into RAM from  org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.  between:      this.numCopiers = conf.getInt(""mapred.reduce.parallel.copies""; 5); and:        maxSingleShuffleLimit = (long)(maxSize * MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION); where MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION is 0.25f  because      copiers = new ArrayListMapOutputCopier(numCopiers); so the total memory allocated for in-mem shuffle is 1.25 * maxSize  A JIRA should be filed to correlate the constant 5 above and MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION.",Resolved,Duplicate,MAPREDUCE-1182,Unassigned,Jacob Rideout,Sun; 7 Mar 2010 20:17:18 +0000,Sun; 7 Mar 2010 21:17:01 +0000,Sun; 7 Mar 2010 21:17:01 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1571
MAPREDUCE-1572,Improvement,Minor,contrib/mrunit,MapReduceDriver combiner functionality,the MapReduceDriver for the new API should be updated to allow the configuration of a Combiner,Resolved,Duplicate,MRUNIT-67,Unassigned,Chris White,Sun; 7 Mar 2010 23:59:59 +0000,Mon; 19 Mar 2012 16:56:44 +0000,Mon; 19 Mar 2012 16:56:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1572
MAPREDUCE-1573,Bug,Major,task-controller;test,TestStreamingAsDifferentUser fails if run as tt_user,TestStreamingAsDifferentUser fails if run as tt_user. MAPREDUCE-890 didn't make the necessary changes needed for the newly added testcase in TestStreamignAsDifferentUser.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 8 Mar 2010 11:39:09 +0000,Tue; 24 Aug 2010 21:21:02 +0000,Tue; 9 Mar 2010 09:32:28 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1573
MAPREDUCE-1574,Improvement,Minor,,"Combiners should implement a specialized ""Combiner"" interface; not the generic ""Reducer"" interface","I just spent 30 minutes trying to figure out why my job throws "" io.IOException: wrong key class"" when I pass my Reducer class to Job.setCombinerClass. Finally; I understood that a Reducer can act as Combiner only if its output key value.  So yes; this is documented. But you can make life easier for users by defining a Combiner interface (that Job.setCombinerClass will accept) to force this at compile time. The new interface should implement the Reducer interface and specialize it (is it even possible with generics?). Alternatively; you can call this interface ""SimpleReducer"".  If the generics-trick suggested above is impossible to implement; for the (common?) case of having the same class acting as Combiner and Reducer you can do one of either: 1) Thin Combiner implementation that wraps a given Reducer. 2) Add a new method; say Job.setCombinerClassToReducer (that accepts a Reducer); acting similarly to the new Job.setCombinerClass - but here the name should alert the user she's doing something special.",Open,Unresolved,,Unassigned,Danny Leshem,Mon; 8 Mar 2010 12:49:28 +0000,Mon; 15 Mar 2010 04:44:55 +0000,,,0.20.1;0.20.2;0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1574
MAPREDUCE-1575,Test,Minor,test,TestStreamingAsDifferentUser.testStreamingWithDistCache tries to set permissions for a non-existent file.,TestStreamingAsDifferentUser.testStreamingWithDistCache; in an effort to mock public distributed cache files; sets up world executable permissions on the parent directory of a public cache file it creates in the test. This file is expected to be copied to hdfs: tmp directory before the copy happens.,Open,Unresolved,,Unassigned,Hemanth Yamijala,Mon; 8 Mar 2010 18:48:18 +0000,Mon; 8 Mar 2010 18:52:12 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1575
MAPREDUCE-1576,Bug,Major,,Counters like number of records written in map are not available in hadoop local execution engine,Counters like number of records written in map are not available in hadoop local execution engine - currently for the number of records the value reported is 0.,Resolved,Duplicate,MAPREDUCE-1214,Unassigned,Pradeep Kamath,Mon; 8 Mar 2010 18:52:31 +0000,Mon; 8 Mar 2010 18:55:08 +0000,Mon; 8 Mar 2010 18:55:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1576
MAPREDUCE-1577,Improvement,Major,,FileInputFormat in the new mapreduce package to support multi-level/recursive directory listing ,See MAPREDUCE-1501 for details.,Resolved,Duplicate,MAPREDUCE-3193,Zheng Shao,Zheng Shao,Tue; 9 Mar 2010 01:58:37 +0000,Sat; 24 Aug 2013 00:28:56 +0000,Sat; 24 Aug 2013 00:28:55 +0000,,,,,MAPREDUCE-1501,https://issues.apache.org/jira/browse/MAPREDUCE-1577
MAPREDUCE-1578,Bug,Major,harchive,HadoopArchives.java should not use HarFileSystem.VERSION,If we upgrade the protocol on HarFileSystem; HadoopArchives might generate an old archive and assign the new version number to it.  This should be fixed,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Tue; 9 Mar 2010 02:10:13 +0000,Tue; 24 Aug 2010 21:21:03 +0000,Tue; 9 Mar 2010 19:31:40 +0000,,,,MAPREDUCE-1548,MAPREDUCE-1579;HADOOP-6591,https://issues.apache.org/jira/browse/MAPREDUCE-1578
MAPREDUCE-1579,Improvement,Blocker,harchive,archive: check and possibly replace the space charater in paths,"Since the space character is used as a separator in the index files; it won't work if there are spaces in the path (see also HADOOP-6591).  The archive tools should   	detect if there are spaces in the paths and 	provide an option to replace it with some other characters.",Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 9 Mar 2010 06:13:32 +0000,Tue; 24 Aug 2010 21:21:06 +0000,Fri; 12 Mar 2010 19:52:58 +0000,,,,,MAPREDUCE-1585;HADOOP-6591;MAPREDUCE-1578,https://issues.apache.org/jira/browse/MAPREDUCE-1579
MAPREDUCE-1580,Bug,Major,tasktracker,Tasklog's job-acl file should be one for job,Currently; job-acl file is created in every attempt directory of user-logs. MAPREDUCE-927 puts jobid attemptid hierarchy for user-log directories. job-acl file can be moved to jobid directory and can be localized along with the log directory.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Tue; 9 Mar 2010 10:24:53 +0000,Thu; 13 Jan 2011 02:29:12 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1580
MAPREDUCE-1581,Bug,Minor,distributed-cache,DistributedCache#addXxxToClassPath() fails silently if qualified pathes are passed in,"In both methods (addFileToClassPath  addArchiveToClassPath) you can specify a path. If this path is fully qualified (hdfs: ....) the files are not in the job classpath. (since the : in the path is also used as path separator).  So i think with one of the following simple improvements:  	throw an exception if the specified path is fully qualified 	OR disqualify the path (f.e. with new Path(path.toUri().getPath()))    people would have an easier start with the DistributedCache!",Open,Unresolved,,Unassigned,Johannes Zillmann,Tue; 9 Mar 2010 10:43:54 +0000,Fri; 11 Mar 2011 04:51:12 +0000,,,,,,MAPREDUCE-2361;MAPREDUCE-752,https://issues.apache.org/jira/browse/MAPREDUCE-1581
MAPREDUCE-1582,Improvement,Minor,job submission,JobClient#monitorAndPrintJob() should use logger for logging taskDiagnostics,In JobClient#monitorAndPrintJob() (around line 1324 in version 0.20.1) the exception of tasktrackers are printed via system.err. Using LOG.error() instead would make capturing the logs easier !,Open,Unresolved,,Unassigned,Johannes Zillmann,Tue; 9 Mar 2010 10:52:51 +0000,Tue; 7 Sep 2010 04:11:26 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1582
MAPREDUCE-1583,Bug,Minor,examples,"teragen ""t"" parameter may be overflowing",My IDE is warning me that the logic in TeraGen. to apply a T value is overflowing:    Perhaps the IDE thinks knows that the compiler will multiply the four integers to produce a compile time constant; so one of them needs to be marked as 1000L to stop the size of a terabyte being much less than expected; with consequences for sort times.,Open,Unresolved,,Unassigned,Steve Loughran,Tue; 9 Mar 2010 17:10:29 +0000,Thu; 29 Apr 2010 08:09:13 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1583
MAPREDUCE-1584,Bug,Major,jobtracker,analysejobhistory.jsp doesn't analyse reduces of jobs with 0 maps,analysejobhistory.jsp returns without proceeding to 'analysing reduces' if the number of maps in the job is 0.,Open,Unresolved,,Ravi Gummadi,Ravi Gummadi,Tue; 9 Mar 2010 18:12:01 +0000,Thu; 13 Jan 2011 02:29:10 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1584
MAPREDUCE-1585,Bug,Major,harchive,Create Hadoop Archives version 2 with filenames URL-encoded,Hadoop Archives version 1 don't cope with files that have spaces on their names.  One proposal is to URLEncode filenames inside the index file (version 2; refers to HADOOP-6591).  This task is to allow the creation of version 2 files that have file names encoded appropriately. It currently depends on HADOOP-6591,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Wed; 10 Mar 2010 00:34:33 +0000,Tue; 24 Aug 2010 21:21:08 +0000,Tue; 6 Apr 2010 19:07:57 +0000,,,,HADOOP-6591;HADOOP-6645,MAPREDUCE-1579,https://issues.apache.org/jira/browse/MAPREDUCE-1585
MAPREDUCE-1586,Bug,Major,test,TestWebUIAuthorization fails sometimes,Testcase testAuthorizationForJobHistoryPages() failed once on my local machine with    I guess the testcase needs to wait for retiring of job instead of only waiting for completion of job before accessing history related jsps,Open,Unresolved,,Unassigned,Ravi Gummadi,Wed; 10 Mar 2010 06:01:08 +0000,Wed; 10 Mar 2010 06:01:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1586
MAPREDUCE-1587,Bug,Minor,client,NPE in JobClient querying an (empty) queue,Getting a stack trace on a VM-hosted cluster with an empty queue. Thought maybe it was the -verbose option; but no; remove that and I still see it.,Resolved,Cannot Reproduce,,Unassigned,Steve Loughran,Wed; 10 Mar 2010 13:57:40 +0000,Sun; 20 Jul 2014 13:34:23 +0000,Sun; 20 Jul 2014 13:34:23 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1587
MAPREDUCE-1588,Improvement,Major,,Fail early if the configured values for total number of tasks is greater than 'mapreduce.jobtracker.maxtasks.perjob',If a job is configured with high value for num-map and num-reduce tasks; then the JobTracker should fail early i.e during job submission.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Wed; 10 Mar 2010 15:21:19 +0000,Wed; 30 Jul 2014 00:16:08 +0000,Wed; 30 Jul 2014 00:16:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1588
MAPREDUCE-1589,Improvement,Minor,contrib/streaming;examples,Need streaming examples in mapred/src/examples/streaming,The examples directory contains the examples for pipes;  mapred but not for the streaming.  We are planning to add the test cases for the streaming in the examples respository,Open,Unresolved,,Alok Singh,Alok Singh,Thu; 11 Mar 2010 01:38:08 +0000,Thu; 13 Jan 2011 02:29:12 +0000,,,,hadoop_examples_streaming,,,https://issues.apache.org/jira/browse/MAPREDUCE-1589
MAPREDUCE-1590,Improvement,Major,harchive,Move HarFileSystem from Hadoop Common to Mapreduce tools.,Keeping HarFileSystem in Hadoop Common has been a mistake since we sometimes cannot make changes to archives without breaking build across  common and mapreduce. Also; it would be good to package archives as a seperate jar which can be used as a user jar.,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 11 Mar 2010 17:11:58 +0000,Tue; 24 Aug 2010 21:21:08 +0000,Wed; 24 Mar 2010 21:46:42 +0000,,,,,HADOOP-6646,https://issues.apache.org/jira/browse/MAPREDUCE-1590
HADOOP-7078,Improvement,Trivial,,Add better javadocs for RawComparator interface,The RawComparator interface is very important to understand for users implementing their own serialization classes. Right now the  oc is woefully sparse. We should improve that.,Closed,Fixed,,Harsh J,Todd Lipcon,Thu; 11 Mar 2010 19:26:35 +0000,Tue; 15 Nov 2011 00:50:37 +0000,Sun; 26 Dec 2010 20:07:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/HADOOP-7078
MAPREDUCE-1592,Improvement,Major,build,Generate Eclipse's .classpath file from Ivy config,MapReduce companion issue for HADOOP-6407.,Closed,Fixed,MAPREDUCE-1619,Tom White,Tom White,Thu; 11 Mar 2010 19:44:51 +0000,Mon; 12 Dec 2011 06:18:39 +0000,Tue; 9 Nov 2010 05:49:43 +0000,,,ant;eclipse;ivy,MAPREDUCE-1259;MAPREDUCE-1348,HDFS-1035;HADOOP-6407,https://issues.apache.org/jira/browse/MAPREDUCE-1592
MAPREDUCE-1593,Improvement,Trivial,tools/rumen,[Rumen] Improvements to random seed generation ,RandomSeedGenerator introduced in MAPREDUCE-1306 could be more efficient by reusing the MD5 object across calls. Wrapping the MD5 in a ThreadLocal makes the call thread safe as well. Neither of these is an issue with the current client; the mumak simulator; but the changes are small and make the code more useful in the future. Thanks to Chris Douglas for the suggestion.,Closed,Fixed,,Tamas Sarlos,Tamas Sarlos,Thu; 11 Mar 2010 22:35:08 +0000,Tue; 24 Aug 2010 21:21:09 +0000,Thu; 18 Mar 2010 21:01:10 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1593
MAPREDUCE-1594,New Feature,Major,contrib/gridmix,Support for Sleep Jobs in gridmix,Support for Sleep jobs in gridmix,Closed,Fixed,,rahul k singh,rahul k singh,Fri; 12 Mar 2010 06:02:00 +0000,Mon; 12 Dec 2011 06:18:52 +0000,Wed; 14 Jul 2010 09:24:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1594
MAPREDUCE-1595,Bug,Major,security;task-controller,LinuxTaskController is too strict on the initial ownership of files/dir.,Linux task controller is too strict now w.r.t the initial ownership of the files dirs to be owned either by TT or by the jobOwner.,Resolved,Duplicate,MAPREDUCE-1609,Unassigned,Vinod Kumar Vavilapalli,Fri; 12 Mar 2010 10:39:08 +0000,Thu; 29 Apr 2010 04:41:55 +0000,Thu; 29 Apr 2010 04:41:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1595
MAPREDUCE-1596,Bug,Critical,build,MapReduce trunk snapshot is not being published to maven,The hadoop-core and hadoop-hdfs artifacts are pushed to maven on a regular basis (daily?); but hadoop-mapreduce has not been updated since 2 10. Is there something automatic in Hudson that is configured for these core and hdfs; but not mapred?  Downstream projects that try to build against Hadoop's trunk (via Ivy or Maven) cannot compile due to API inconsistency here.,Closed,Fixed,,Giridharan Kesavan,Aaron Kimball,Fri; 12 Mar 2010 19:18:21 +0000,Tue; 24 Aug 2010 21:21:10 +0000,Sat; 13 Mar 2010 07:26:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1596
MAPREDUCE-1597,Bug,Major,,combinefileinputformat does not work with non-splittable files,CombineFileInputFormat.getSplits() does not take into account whether a file is splittable. This can lead to a problem for compressed text files - for example; getSplits() may return more than 1 split depending on the size of the compressed file; all the splits recordreader will read the complete file.  I ran into this problem while using Hive on hadoop 20.,Closed,Fixed,MAPREDUCE-1649,Amareshwari Sriramadasu,Namit Jain,Fri; 12 Mar 2010 21:57:10 +0000,Mon; 27 Jul 2015 11:39:59 +0000,Tue; 7 Sep 2010 09:06:39 +0000,,,,HIVE-11376,SQOOP-721,https://issues.apache.org/jira/browse/MAPREDUCE-1597
MAPREDUCE-1598,Bug,Major,jobtracker,Wrongly configured 'hadoop.job.history.user.location' can cause jobs to be pinned in JobTracker's memory forever,Wrongly configured 'hadoop.job.history.user.location' can disable job-history. Jobs retires when JobHistory notifies the JobTracker after moving the history file to the done folder (i.e mapreduce.jobtracker.jobhistory.completed.location). If the JobHistory gets disabled; JobTracker would not receive any notification and thus jobs will be pinned in JobTracker's memory forever.,Open,Unresolved,,Unassigned,Amar Kamat,Sun; 14 Mar 2010 17:03:34 +0000,Thu; 20 Jan 2011 03:25:41 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1598
MAPREDUCE-1599,Bug,Major,,MRBench reuses jobConf and credentials there in.,MRBench reuses the jobconf and therefore credentials are re-used; but JobTracker cancels the delegation tokens therefore the test fails sometimes.  The fix is to pass the mapreduce.job.complete.cancel.delegation.tokens=false in the jobconf so that JobTracker does not cancel the tokens.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Mon; 15 Mar 2010 17:30:25 +0000,Mon; 12 Dec 2011 06:18:25 +0000,Tue; 1 Jun 2010 22:33:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1599
MAPREDUCE-1600,Bug,Blocker,client,o.a.h.mapreduce.FileOutputCommitter should qualify the output path,Same as HADOOP-4746; but for the new api.,Resolved,Not A Problem,,Arun C Murthy,Arun C Murthy,Mon; 15 Mar 2010 22:29:17 +0000,Sat; 7 Jul 2012 13:17:28 +0000,Sat; 7 Jul 2012 13:17:28 +0000,,0.20.2,,MAPREDUCE-3377,,https://issues.apache.org/jira/browse/MAPREDUCE-1600
MAPREDUCE-1601,Bug,Major,build,CombineFileInputFormat and Job classes,org.apache.hadoop.mapred.lib.CombineFileInputFormat can not be used with org.apache.hadoop.mapreduce.Job because Job.setInputFormat requires subclass of  org.apache.hadoop.mapreduce.InputFormat and CombineFileInputFormat extends org.apache.hadoop.mapred.FileInputFormat.  Also CombineFileInputFormat uses deprecated classes.,Resolved,Won't Fix,,Unassigned,Aleksandar Stupar,Tue; 16 Mar 2010 14:42:34 +0000,Wed; 17 Mar 2010 04:35:04 +0000,Wed; 17 Mar 2010 04:35:04 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1601
MAPREDUCE-1602,Bug,Major,harchive,When the src does not exist; archive shows IndexOutOfBoundsException,nan,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 16 Mar 2010 21:51:05 +0000,Tue; 24 Aug 2010 21:21:10 +0000,Wed; 31 Mar 2010 20:43:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1602
MAPREDUCE-1603,New Feature,Minor,tasktracker,Add a plugin class for the TaskTracker to determine available slots,Currently the #of available map and reduce slots is determined by the configuration. MAPREDUCE-922 has proposed working things out automatically; but that is going to depend a lot on the specific tasks -hard to get right for everyone.  There is a Hadoop cluster near me that would like to use CPU time from other machines in the room; machines which cannot offer storage; but which will have spare CPU time when they aren't running code scheduled with a grid scheduler. The nodes could run a TT which would report a dynamic number of slots; the number depending upon the current grid workload.   I propose we add a plugin point here; so that different people can develop plugin classes that determine the amount of available slots based on workload; RAM; CPU; power budget; thermal parameters; etc. Lots of space for customisation and improvement. And by having it as a plugin: people get to integrate with whatever datacentre schedulers they have without Hadoop itself needing to be altered: the base implementation would be as today: subtract the number of active map and reduce slots from the configured values; push that out.,Resolved,Won't Fix,,Unassigned,Steve Loughran,Tue; 16 Mar 2010 22:00:00 +0000,Wed; 23 Jul 2014 22:11:47 +0000,Wed; 23 Jul 2014 22:11:47 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1603
MAPREDUCE-1604,Bug,Major,documentation;security,Job acls should be documented in forrest.,Job acls introduced in MAPREDUCE-1307 should be documented in forrest.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 17 Mar 2010 06:02:44 +0000,Tue; 24 Aug 2010 21:21:10 +0000,Mon; 26 Apr 2010 12:42:45 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1604
MAPREDUCE-1605,New Feature,Major,contrib/gridmix,Support multiple headless users to be able to submit job via gridmix v3,nan,Open,Unresolved,,Unassigned,rahul k singh,Wed; 17 Mar 2010 08:08:27 +0000,Wed; 17 Mar 2010 22:49:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1605
MAPREDUCE-1606,Bug,Major,test,TestJobACLs may timeout as there are no slots for launching JOB_CLEANUP task,TestJobACLs may timeout as there are no slots for launching JOB_CLEANUP task. Because MiniMRCluster with 0 TaskTrackers is started in the test. In trunk; we can set the config property mapreduce.job.committer.setup.cleanup.needed to false sothat we don't get into this issue.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 17 Mar 2010 08:58:01 +0000,Tue; 24 Aug 2010 21:21:11 +0000,Fri; 11 Jun 2010 11:24:53 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1606
MAPREDUCE-1607,Bug,Major,task-controller,Task controller may not set permissions for a task cleanup attempt's log directory,Task controller uses the INITIALIZE_TASK command to initialize task attempt and task log directories. For cleanup tasks; task attempt directories are named as task-attempt-id.cleanup. But log directories do not have the .cleanup suffix. The task controller is not aware of this distinction and tries to set permissions for log directories named task-attempt-id.cleanup. This is a NO-OP. Typically the task cleanup runs on the same node that ran the original task attempt as well. So; the task log directories are already properly initialized. However; the task cleanup can run on a node that has not run the original task attempt. In that case; the initialization would not happen and this could result in the cleanup task failing.,Closed,Fixed,,Amareshwari Sriramadasu,Hemanth Yamijala,Thu; 18 Mar 2010 12:00:35 +0000,Tue; 24 Aug 2010 21:21:11 +0000,Tue; 11 May 2010 14:42:00 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1607
MAPREDUCE-1608,New Feature,Major,,Allow users to do speculative execution of a task manually,"Speculative execution improves the latency of the job. Sometimes the job has few very slow reducers. Spending a little more resource on speculative tasks can improve the latency a lot. It will be nice that the users can manually select one task and force the speculative execution on that task just like we can manually kill fail"".  Thoughts?",Open,Unresolved,,Scott Chen,Scott Chen,Fri; 19 Mar 2010 00:26:36 +0000,Wed; 17 Nov 2010 17:39:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1608
MAPREDUCE-1609,Bug,Major,tasktracker,TaskTracker.localizeJob should not set permissions on job log directory recursively,Currently TaskTracker.localizeJob sets permissions (570 with LinuxTaskController) on job log directory recursively. When the tracker restarts reinit; we would hit MAPREDUCE-1607.  This problem is missed by the patch for MAPREDUCE-927. The above problem never existed before MAPREDUCE:927.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 19 Mar 2010 03:52:55 +0000,Tue; 24 Aug 2010 21:21:12 +0000,Wed; 28 Apr 2010 04:29:11 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1609
MAPREDUCE-1610,Bug,Major,documentation,Forrest documentation should be updated to reflect the changes in MAPREDUCE-856,The directory structure under mapred-local-dir is changed in MAPREDUCE-856. This needs changes to the forrest documentation.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 19 Mar 2010 05:00:10 +0000,Tue; 24 Aug 2010 21:21:13 +0000,Mon; 10 May 2010 15:33:25 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1610
MAPREDUCE-1611,Bug,Blocker,security,Refresh nodes and refresh queues doesnt work with service authorization enabled,If service-level authorization enabled (i.e hadoop.security.authorization set to true) for MapReduce then refreshing the node and queue fails with the following message,Closed,Fixed,,Amar Kamat,Amar Kamat,Fri; 19 Mar 2010 16:53:55 +0000,Tue; 24 Aug 2010 21:21:15 +0000,Wed; 5 May 2010 04:59:46 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1611
MAPREDUCE-1612,Bug,Major,jobtracker,job conf file is not accessible from job history web page,Clicking on conf file link from job history web page is causing an NPE if history file(and the job conf file) are stored on DFS. This NPE is from jobconf_history.jsp because jobConf built from path on DFS is not having any properties.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 19 Mar 2010 17:47:27 +0000,Tue; 24 Aug 2010 21:21:16 +0000,Tue; 27 Apr 2010 04:55:11 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1612
MAPREDUCE-1613,Improvement,Minor,build,Install/deploy source jars to Maven repo,Publishing source jars to the Maven repo enables most IDEs to easily show Hadoop code to developers.,Closed,Fixed,,Unassigned,Patrick Angeles,Fri; 19 Mar 2010 17:47:37 +0000,Tue; 24 Aug 2010 21:21:16 +0000,Mon; 26 Apr 2010 17:33:34 +0000,,0.22.0,,,HDFS-1047;HADOOP-6635;HDFS-1047,https://issues.apache.org/jira/browse/MAPREDUCE-1613
MAPREDUCE-1614,Bug,Major,benchmarks,TestDFSIO should allow to configure output directory,TestDFSIO has a hardcoded location for its files to be written and read to or from. This location is  ' doesn't allow anyone to write into it. It'd be convenient to have a command line option to specify an alternative location on demand.,Resolved,Duplicate,MAPREDUCE-1832,Konstantin Boudnik,Konstantin Boudnik,Fri; 19 Mar 2010 19:18:55 +0000,Wed; 4 May 2011 20:04:16 +0000,Wed; 4 May 2011 20:04:16 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1614
MAPREDUCE-1615,Bug,Blocker,,ant test on trunk does not compile.,ant test on trunk fails to compile with the following error:,Closed,Fixed,,Chris Douglas,Mahadev konar,Fri; 19 Mar 2010 23:36:58 +0000,Tue; 24 Aug 2010 21:21:17 +0000,Sat; 20 Mar 2010 06:10:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1615
MAPREDUCE-1616,Test,Major,,Automate system test case for checking the file permissions in mapred.local.dir,The file under mapred.local.dir permission must be recursively tested when the task is running; for this use the controllable task; so the temporary file permission can be checked.,Open,Unresolved,,Balaji Rajagopalan,Balaji Rajagopalan,Mon; 22 Mar 2010 17:48:17 +0000,Mon; 27 Sep 2010 04:14:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1616
MAPREDUCE-1617,Bug,Major,test,TestBadRecords failed once in our test runs,org.apache.hadoop.mapred.TestBadRecords.testBadMapRed failed with the following exception:  211),Closed,Fixed,,Luke Lu,Amareshwari Sriramadasu,Tue; 23 Mar 2010 03:57:55 +0000,Mon; 12 Dec 2011 06:18:25 +0000,Fri; 21 May 2010 09:44:57 +0000,,0.20.2,,,HADOOP-5130,https://issues.apache.org/jira/browse/MAPREDUCE-1617
MAPREDUCE-1618,Bug,Trivial,documentation,JobStatus.getJobAcls() and setJobAcls should have javadoc,org.apache.hadoop.mapreduce.JobStatus.getJobAcls() and setJobAcls are added in MAPREDUCE-1307. They should have  oc.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 23 Mar 2010 06:34:00 +0000,Tue; 24 Aug 2010 21:21:17 +0000,Mon; 26 Apr 2010 04:12:48 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1618
MAPREDUCE-1619,Improvement,Trivial,build,Eclipse .classpath file should be generated from Ivy files to avoid duplicating dependencies,Using Ant-Eclipse (http: ) it's possible to generate Eclipse files from Ivy files; this avoids unnecessary duplication of dependencies information.  See: HADOOP-6407,Closed,Duplicate,MAPREDUCE-1592,Paolo Castagna,Paolo Castagna,Tue; 23 Mar 2010 09:32:29 +0000,Tue; 24 Aug 2010 21:21:18 +0000,Thu; 25 Mar 2010 07:01:38 +0000,,0.20.3,,,HDFS-1063,https://issues.apache.org/jira/browse/MAPREDUCE-1619
MAPREDUCE-1620,Bug,Major,,Hadoop should serialize the Configration after the call to getSplits() to the backend such that any changes to the Configuration in getSplits() is serialized to the backend,In 0.20.1 and 0.20.2; when using the new API; while working on the next pig release we discovered that the hadoop code makes a copy of the Configuration and hands a copy to the getSplits() call. Any changes to the Configuration made in getSplits() are on that copy. However the original Configuraiton is the one which gets serialized to the backend - hence any changes made to the Configuration in the getSplits() implementation does not get serialized to the backend. In a framework like Pig; there are usecases for writing information into the Configuration during getSplits - it would be helpful if Hadoop would ensure that these changes get serialized to the backend.,Open,Unresolved,,Unassigned,Pradeep Kamath,Tue; 23 Mar 2010 19:24:42 +0000,Wed; 24 Mar 2010 18:02:56 +0000,,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1620
MAPREDUCE-1621,Bug,Major,contrib/streaming,Streaming's TextOutputReader.getLastOutput throws NPE if it has never read any output,If TextOutputReader.readKeyValue() has never successfully read a line; then its bytes member will be left null. Thus when logging a task failure; PipeMapRed.getContext() can trigger an NPE when it calls outReader_.getLastOutput().,Closed,Fixed,,Amareshwari Sriramadasu,Todd Lipcon,Tue; 23 Mar 2010 19:25:22 +0000,Mon; 12 Dec 2011 06:19:32 +0000,Fri; 16 Jul 2010 11:00:06 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1621
MAPREDUCE-1622,Bug,Minor,build,Include slf4j dependencies in binary tarball,After MAPREDUCE-1556 and HADOOP-6486; starting Trackers from a binary tarball produces the following warning:,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 23 Mar 2010 20:41:26 +0000,Tue; 24 Aug 2010 21:21:18 +0000,Sun; 25 Apr 2010 20:58:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1622
MAPREDUCE-1623,Sub-task,Blocker,documentation,Apply audience and stability annotations to classes in mapred package,There are lots of implementation classes in org.apache.hadoop.mapred which makes it difficult to see the user-level MapReduce API classes in the Javadoc. (See http: package-summary.html for example.) By marking these implementation classes with the InterfaceAudience.Private annotation we can exclude them from user Javadoc (using HADOOP-6658).  Later work will move the implementation classes into o.a.h.mapreduce.server and related packages (see MAPREDUCE-561); but applying the annotations is a good first step.,Closed,Fixed,,Tom White,Tom White,Wed; 24 Mar 2010 04:29:22 +0000,Tue; 24 Aug 2010 21:21:18 +0000,Thu; 20 May 2010 05:44:15 +0000,,,,,HADOOP-6668;MAPREDUCE-1650,https://issues.apache.org/jira/browse/MAPREDUCE-1623
MAPREDUCE-1624,Improvement,Major,documentation,Document the job credentials and associated details to do with delegation tokens (on the client side),Document the job credentials and associated details to do with delegation tokens (on the client side),Closed,Fixed,,Devaraj Das,Devaraj Das,Wed; 24 Mar 2010 05:55:08 +0000,Tue; 15 Nov 2011 00:49:18 +0000,Fri; 10 Jun 2011 23:10:39 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1624
MAPREDUCE-1625,Sub-task,Blocker,documentation,Improve grouping of packages in Javadoc,"There are a couple of problems with the current Javadoc:  	The main MapReduce package documentation on the index page appears under ""Other Packages"" below the fold. 	Some contrib classes and packages are interspersed in the main MapReduce documentation; which is very confusing for users.",Closed,Fixed,,Tom White,Tom White,Wed; 24 Mar 2010 18:49:11 +0000,Tue; 24 Aug 2010 21:21:20 +0000,Mon; 26 Apr 2010 21:41:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1625
MAPREDUCE-1626,Improvement,Major,documentation,Publish Javadoc for all contrib packages with user-facing APIs,Some packages don't appear in the Javadoc. E.g. MRUnit; Vertica.,Closed,Fixed,,Jolly Chen,Tom White,Wed; 24 Mar 2010 19:01:11 +0000,Mon; 12 Dec 2011 06:18:54 +0000,Thu; 12 May 2011 16:09:26 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-1626
MAPREDUCE-1627,Improvement,Minor,harchive,HadoopArchives should not uses DistCp method,If HadoopArchives does not use the DistCp method; it could be packaged as a standalone tool.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 24 Mar 2010 21:04:54 +0000,Tue; 24 Aug 2010 21:21:20 +0000,Thu; 25 Mar 2010 17:14:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1627
MAPREDUCE-1628,Bug,Major,harchive,HarFileSystem shows incorrect replication numbers and permissions,In the har dir; the replication # of part-0 is 3.   but the replication # of the individual har: t20 shown above is incorrect.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Sat; 27 Feb 2010 00:02:04 +0000,Tue; 24 Aug 2010 21:21:21 +0000,Wed; 31 Mar 2010 18:46:43 +0000,,,,,MAPREDUCE-1548,https://issues.apache.org/jira/browse/MAPREDUCE-1628
MAPREDUCE-1629,Bug,Trivial,,Get rid of fakeBlockLocations() on HarFileSystem; since it's not used,On HarFileSystem.  I think function fakeBlockLocations() was left behind when Mahadev fixed HADOOP-6467.,Closed,Fixed,,Mahadev konar,Rodrigo Schmidt,Sat; 20 Mar 2010 01:36:18 +0000,Tue; 24 Aug 2010 21:21:21 +0000,Fri; 26 Mar 2010 18:01:18 +0000,,0.22.0,,,HADOOP-6467,https://issues.apache.org/jira/browse/MAPREDUCE-1629
MAPREDUCE-1630,Bug,Major,,Starting JobTracker with a wrong keytab should throw error right away,If the JobTracker is started with a wrong key tab file; it should die immediately throwing the right error to the user. Right now; the JobTracker keeps trying to login with the available credentials and hence the process does not die immediately. So; to the user it appears like the JobTracker process is running successfully. This is misleading.,Resolved,Won't Fix,,Unassigned,Arun Ramani,Wed; 24 Mar 2010 23:48:11 +0000,Wed; 30 Jul 2014 17:13:12 +0000,Wed; 30 Jul 2014 17:13:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1630
MAPREDUCE-1631,Bug,Major,build,hadoop-mapreduce-trunk build has broken because fo build issue.,http: console  ERROR: Publisher hudson.tasks.JavadocArchiver aborted due to exception  122),Resolved,Incomplete,,Unassigned,Iyappan Srinivasan,Thu; 25 Mar 2010 13:07:13 +0000,Wed; 30 Jul 2014 17:13:27 +0000,Wed; 30 Jul 2014 17:13:27 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1631
MAPREDUCE-1632,Bug,Major,harchive;test,TestHadoopArchives fails on trunk,Here is the test report: org.apache.hadoop.tools.TestHadoopArchives.testPathWithSpaces  (from TestHadoopArchives) Failing for the past 7 builds (Since Failed#48 ) Took 25 sec.  Error Message:  expected: ,Resolved,Duplicate,HADOOP-6645,Unassigned,Amareshwari Sriramadasu,Thu; 25 Mar 2010 14:18:32 +0000,Tue; 30 Mar 2010 22:03:00 +0000,Tue; 30 Mar 2010 22:03:00 +0000,,0.22.0,,,HADOOP-6645,https://issues.apache.org/jira/browse/MAPREDUCE-1632
MAPREDUCE-1633,Bug,Major,documentation,Queue ACLs documentation must talk about wildcards,Currently the Forrest documentation about queue ACLs is not talking about wildcards - the value that states that all users are allowed for an operation in a queue. This should be documented.,Resolved,Fixed,,Unassigned,Hemanth Yamijala,Thu; 25 Mar 2010 18:04:20 +0000,Wed; 30 Jul 2014 17:15:44 +0000,Wed; 30 Jul 2014 17:15:31 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-1633
MAPREDUCE-1634,New Feature,Major,client,add input and output formats for Avro value wrappers,HADOOP-6660 proposes adding an AvroValue wrapper for Avro data.  We should add InputFormat and OutputFormat implementations for Avro data files that use this.,Resolved,Duplicate,AVRO-493,Unassigned,Doug Cutting,Thu; 25 Mar 2010 20:54:42 +0000,Wed; 31 Mar 2010 23:24:07 +0000,Wed; 31 Mar 2010 23:24:07 +0000,,,,HADOOP-6660,MAPREDUCE-815,https://issues.apache.org/jira/browse/MAPREDUCE-1634
MAPREDUCE-1635,Bug,Major,tasktracker,ResourceEstimator does not work after MAPREDUCE-842,MAPREDUCE-842 changed Child's mapred.local.dir to have attemptDir as the base local directory. Also assumption is that org.apache.hadoop.mapred.MapOutputFile always gets Child's mapred.local.dir.  But; MapOuptutFile.getOutputFile() is called from TaskTracker's conf; which does not find the output file. Thus TaskTracker.tryToGetOutputSize() always returns -1.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 26 Mar 2010 10:35:12 +0000,Tue; 24 Aug 2010 21:21:22 +0000,Mon; 12 Apr 2010 14:21:54 +0000,,0.21.0,,,MAPREDUCE-1662,https://issues.apache.org/jira/browse/MAPREDUCE-1635
MAPREDUCE-1636,Bug,Major,jobtracker,Missing counters on taskdetails.jsp,A tip counter is actually the counter of its best performing attempt. This is correctly displayed on jobtasks.jsp but is missing on the taskdetails.jsp.,Resolved,Fixed,,Unassigned,Amar Kamat,Fri; 26 Mar 2010 16:33:10 +0000,Wed; 30 Jul 2014 17:16:11 +0000,Wed; 30 Jul 2014 17:16:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1636
MAPREDUCE-1637,Sub-task,Major,build;test,Create a test for API compatibility between releases,We should have an automated test (or a set of tests) for checking that programs written against an old version of the API still run with a newer version.,Resolved,Won't Fix,,Tom White,Tom White,Fri; 26 Mar 2010 17:35:24 +0000,Wed; 30 Jul 2014 17:16:54 +0000,Wed; 30 Jul 2014 17:16:54 +0000,,,,,HADOOP-6676;HADOOP-6733,https://issues.apache.org/jira/browse/MAPREDUCE-1637
MAPREDUCE-1638,Improvement,Major,build;client,Remove MapReduce server depedencies on client code,I think it makes sense to separate the MapReduce source into client and server parts.,Resolved,Fixed,,Tom White,Tom White,Fri; 26 Mar 2010 18:56:17 +0000,Wed; 30 Jul 2014 17:18:10 +0000,Wed; 30 Jul 2014 17:18:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1638
MAPREDUCE-1639,New Feature,Major,,Grouping using hashing instead of sorting,"most applications of map-reduce care about grouping and not sorting. Sorting is a (relatively expensive) way to achieve grouping. In order to achieve just grouping - one can:   	replace the sort on the Mappers with a HashTable - and maintain lists of key-values against each hash-bucket. 	key-value tuples inside each hash bucket are sorted - before spilling or sending to Reducer. Anytime this is done - Combiner can be invoked. 	HashTable is serialized by hash-bucketid. So merges (of either spills or Map Outputs) works similar to today (at least there's no change in overall compute complexity of merge)    Of course this hashtable has nothing to do with partitioning. it's just a replacement for map-side sort.    this is (pretty much) straight from the MARS project paper: http: mars_pact08.pdf. They report a 45% speedup in inverted index calculation using hashing instead of sorting (reference implementation is NOT against Hadoop though).",Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Sat; 27 Mar 2010 13:57:57 +0000,Thu; 2 May 2013 02:29:58 +0000,,,,,,MAPREDUCE-3235;HADOOP-7761,https://issues.apache.org/jira/browse/MAPREDUCE-1639
MAPREDUCE-1640,Bug,Major,tasktracker,Node health feature fails to blacklist a node if the health check script times out in some cases,"Node health check feature fails to blacklist a TT if health check script times out. Below are the values that were set:  	mapred.healthChecker.interval=60000 	mapred.healthChecker.script.timeout=6000    And the script was:",Resolved,Incomplete,,Unassigned,Vinod Kumar Vavilapalli,Mon; 29 Mar 2010 08:33:37 +0000,Wed; 30 Jul 2014 17:19:13 +0000,Wed; 30 Jul 2014 17:19:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1640
MAPREDUCE-1641,Bug,Major,distributed-cache,Job submission should fail if same uri is added for mapred.cache.files and mapred.cache.archives,The behavior of mapred.cache.files and mapred.cache.archives is different during localization in the following way:  If a jar file is added to mapred.cache.files;  it will be localized under TaskTracker under a unique path.  If a jar file is added to mapred.cache.archives; it will be localized under a unique path in a directory named the jar file name; and will be unarchived under the same directory.  If same jar file is passed for both the configurations; the behavior undefined. Thus the job submission should fail. Currently; since distributed cache processes files before archives; the jar file will be just localized and not unarchived.,Resolved,Fixed,MAPREDUCE-1709,Dick King,Amareshwari Sriramadasu,Mon; 29 Mar 2010 10:13:34 +0000,Wed; 30 Jul 2014 17:48:27 +0000,Wed; 30 Jul 2014 17:48:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1641
MAPREDUCE-1642,Bug,Major,test,Many hudson test failures because of ZipException,Nowadays; many hudson patch builds fail because of ZipException.  One such failure @http: ,Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Mon; 29 Mar 2010 12:48:05 +0000,Wed; 30 Jul 2014 17:19:57 +0000,Wed; 30 Jul 2014 17:19:57 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1642
HBASE-2389,Bug,Major,,HTable - delete / put unnecessary sync. ,HTable is not thread-safe ; but some of the methods seem to have a synchronized block  (put delete) etc.   It might as well be better to remove them altogether.,Closed,Fixed,,Unassigned,Karthik K,Mon; 29 Mar 2010 18:20:04 +0000,Fri; 20 Nov 2015 12:41:50 +0000,Tue; 30 Mar 2010 05:15:10 +0000,,,,,,https://issues.apache.org/jira/browse/HBASE-2389
MAPREDUCE-1644,Task,Major,,Remove Sqoop from Apache Hadoop (moving to github),Sqoop is moving to github! All code for sqoop is already live at http: sqoop - this issue removes the duplicate code from the Apache Hadoop repository before the 0.21 release.,Resolved,Fixed,,Aaron Kimball,Aaron Kimball,Mon; 29 Mar 2010 22:26:11 +0000,Fri; 2 Jul 2010 06:32:10 +0000,Thu; 8 Apr 2010 00:12:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1644
MAPREDUCE-1645,Bug,Major,jobtracker,Task cleanup attempt details should also be logged to JobHistory,Currently; Task cleanup attempt details are not logged to JobHistory. JobHistory should log at least where the task cleanup attempt ran.,Resolved,Fixed,,Unassigned,Amareshwari Sriramadasu,Tue; 30 Mar 2010 04:53:50 +0000,Wed; 30 Jul 2014 17:20:23 +0000,Wed; 30 Jul 2014 17:20:23 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1645
MAPREDUCE-1646,Task,Major,test,Task Killing tests,The following tasks covered in the test.  1. In a running job; kill a task and verify the job succeeds.  2. Setup a job with long running tasks th the output _attempt-id directory is cleaned up. The important difference we are trying to check is btw kill and fail; there would a subtle difference.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Tue; 30 Mar 2010 10:21:25 +0000,Fri; 6 Aug 2010 01:58:52 +0000,,,,,MAPREDUCE-1774,,https://issues.apache.org/jira/browse/MAPREDUCE-1646
MAPREDUCE-1647,Bug,Major,tasktracker,JvmEnv miss logSize argument,class JvmEnv missed logSize argument in its constructor; thus task-jvms seems will never limit their stdout stderr outputs into specified size.,Resolved,Duplicate,MAPREDUCE-1057,Unassigned,Guilin Sun,Tue; 30 Mar 2010 12:22:33 +0000,Wed; 31 Mar 2010 05:27:23 +0000,Wed; 31 Mar 2010 03:27:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1647
MAPREDUCE-1648,Improvement,Major,tasktracker,Use rolling to limit tasklogs,"There are at least two types of task-logs: syslog and stdlog  Task-Jvm outputs syslog by log4j with TaskLogAppender; TaskLogAppender looks just like ""tail -c""; it stores last N byte stderr to log4j via LoggingOutputStream; no client code have to be changed; and RollingFileAppender seems better than 'tail -c' too.",Resolved,Won't Fix,,Unassigned,Guilin Sun,Tue; 30 Mar 2010 12:55:50 +0000,Wed; 30 Jul 2014 17:22:57 +0000,Wed; 30 Jul 2014 17:22:57 +0000,,,logging,,MAPREDUCE-1716,https://issues.apache.org/jira/browse/MAPREDUCE-1648
MAPREDUCE-1649,Bug,Major,,Compressed files with TextInputFormat does not work with CombineFileInputFormat,CombineFileInputFormat creates splits based on blocks; regardless whether the underlying FileInputFormat is splittable or not..  This means that we can have 2 or more splits for a compressed text file with TextInputFormat. For each of these splits; TextInputFormat.getRecordReader will return a RecordReader for the whole compressed file; thus causing duplicate input data.,Resolved,Invalid,MAPREDUCE-1597,Zheng Shao,Zheng Shao,Tue; 30 Mar 2010 18:35:51 +0000,Tue; 7 Sep 2010 11:31:56 +0000,Tue; 7 Sep 2010 11:31:56 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1649
MAPREDUCE-1650,Sub-task,Major,documentation,Exclude Private elements from generated MapReduce Javadoc,Exclude elements annotated with InterfaceAudience.Private or InterfaceAudience.LimitedPrivate from Javadoc and JDiff.,Closed,Fixed,,Tom White,Tom White,Wed; 31 Mar 2010 00:00:42 +0000,Thu; 2 May 2013 02:29:29 +0000,Mon; 26 Apr 2010 17:30:48 +0000,,,,,MAPREDUCE-1623;HADOOP-5073,https://issues.apache.org/jira/browse/MAPREDUCE-1650
MAPREDUCE-1651,Bug,Major,security,Public Cluster#getDelegationToken() method returns private implementation class,Cluster#getDelegationToken() returns a DelegationTokenIdentifier; which is marked as InterfaceAudience.Private. Cluster#renewDelegationToken and Cluster#cancelDelegationToken have the same problem.,Open,Unresolved,,Unassigned,Tom White,Wed; 31 Mar 2010 00:27:56 +0000,Mon; 12 Mar 2012 23:24:35 +0000,,,,,,HADOOP-8152,https://issues.apache.org/jira/browse/MAPREDUCE-1651
MAPREDUCE-1652,Bug,Major,,Tasks need to emit a better error message when job-acls.xml file cannot be created,If task cannot create job-acls.xml in userlogs task-attempt-dir(because of disc being full; OR disc has gone bad; etc); then task should emit a better error message instead of failing with FileNotFoundException in writeJobACLs().  The stack trace shown currently is:   205),Resolved,Duplicate,MAPREDUCE-2041,Unassigned,Ravi Gummadi,Wed; 31 Mar 2010 05:58:31 +0000,Wed; 30 Jul 2014 23:42:37 +0000,Wed; 30 Jul 2014 23:42:37 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1652
MAPREDUCE-1653,Bug,Trivial,test,Add apache header to UserNamePermission.java,Add the missing header to the file.,Resolved,Duplicate,HADOOP-6332,Balaji Rajagopalan,Balaji Rajagopalan,Wed; 31 Mar 2010 06:48:02 +0000,Wed; 7 Apr 2010 11:27:58 +0000,Wed; 7 Apr 2010 11:27:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1653
MAPREDUCE-1654,Test,Major,test,Automate the job killing system test case. ,nan,Open,Unresolved,,Balaji Rajagopalan,Balaji Rajagopalan,Wed; 31 Mar 2010 06:51:20 +0000,Thu; 2 May 2013 02:29:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1654
MAPREDUCE-1655,New Feature,Major,test,Automate the local file permission checking when a job is running. ,This test case will automate the file permission under mapred.local.dir when a job runs.,Resolved,Duplicate,MAPREDUCE-1616,Unassigned,Balaji Rajagopalan,Wed; 31 Mar 2010 06:52:56 +0000,Wed; 31 Mar 2010 08:50:37 +0000,Wed; 31 Mar 2010 08:39:57 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1655
MAPREDUCE-1656,Improvement,Minor,,JobStory should provide queue info.,Add a method in JobStory to get the queue to which a job is submitted.,Closed,Fixed,,Hong Tang,Hong Tang,Wed; 31 Mar 2010 08:13:17 +0000,Tue; 24 Aug 2010 21:21:24 +0000,Fri; 2 Apr 2010 23:01:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1656
MAPREDUCE-1657,Bug,Major,tasktracker,After task logs directory is deleted; tasklog servlet displays wrong error message about job ACLs,When task log gets deleted if from Web UI we click view task log; web page displays wrong error message -: [ HTTP ERROR: 401  User user1 failed to view tasklogs of job job_201003241521_0001!  user1 is not authorized for performing the operation VIEW_JOB on job_201003241521_0001. VIEW_JOB Access control list configured for this job :   RequestURI=  or user is owner of job.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 31 Mar 2010 08:45:33 +0000,Tue; 24 Aug 2010 21:21:24 +0000,Wed; 28 Apr 2010 06:36:33 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1657
MAPREDUCE-1658,Improvement,Major,tools/rumen,[Rumen] Extract some job configurations.,"Enhance Rumen to extract the following configuration parameters from JobConf that may be relevant to job execution:  	mapred.map.tasks.speculative.execution; mapred.reduce.tasks.speculative.execution 	mapred.reduce.slowstart.completed.maps 	io.sort.factor; io.sort.mb; io.sort.record.percent; io.sort.spill.percent 	mapreduce.reduce.shuffle.connect.timeout; mapreduce.reduce.shuffle.read.timeout 	mapred.job.shuffle.merge.percent; mapred.job.shuffle.input.buffer.percent 	mapred.inmem.merge.threshold",Resolved,Duplicate,MAPREDUCE-2153,Unassigned,Hong Tang,Wed; 31 Mar 2010 09:02:03 +0000,Wed; 27 Oct 2010 05:57:38 +0000,Wed; 27 Oct 2010 05:57:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1658
MAPREDUCE-1659,Bug,Major,contrib/raid,RaidNode should write temp files on /tmp and add random numbers to their names to avoid conflicts,The RaidNode methods to raid files and recover them should write recovery and tmp files on  raid.  Besides that; filenames should have a random number appended to them to avoid conflicts. This makes the code safer and avoids errors when multiple recoveries run in parallel.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Wed; 31 Mar 2010 12:12:37 +0000,Tue; 24 Aug 2010 21:21:24 +0000,Wed; 21 Apr 2010 05:26:25 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1659
MAPREDUCE-1660,Improvement,Minor,test,org.apache.hadoop.mapred.TestFileInputFormat should be ported to new api.,org.apache.hadoop.mapred.TestFileInputFormat.testLocality()  and testMultiLevelInput() should be ported to new api test org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Wed; 31 Mar 2010 14:37:43 +0000,Thu; 13 Jan 2011 02:29:17 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1660
MAPREDUCE-1661,Bug,Major,,The input directory in test TestTaskOwner.java is not cleaned up,The test should delete the directories in hdfs that it creates as a good practice; it should leave around any vestige directories; since it can cause undesired side effects.,Resolved,Duplicate,HADOOP-6332,Balaji Rajagopalan,Balaji Rajagopalan,Thu; 1 Apr 2010 05:11:21 +0000,Wed; 7 Apr 2010 11:26:24 +0000,Wed; 7 Apr 2010 11:26:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1661
MAPREDUCE-1662,Bug,Major,tasktracker,TaskRunner.prepare() and close() can be removed,TaskRunner.prepare() and close() methods call only mapOutputFile.removeAll(). The removeAll() call is a always a no-op in prepare(); because the directory is always empty during start up of the task. The removeAll() call in close() is useless; because it is followed by a attempt directory cleanup. Since the map output files are in attempt directory;  the call to close() is useless. After MAPREDUCE-842; these calls are under TaskTracker space; passing the wrong conf. Now; the calls do not make sense at all. I think we can remove the methods.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 1 Apr 2010 05:47:04 +0000,Mon; 12 Dec 2011 06:18:25 +0000,Fri; 21 May 2010 08:46:05 +0000,,0.22.0,,,MAPREDUCE-1635;MAPREDUCE-1247,https://issues.apache.org/jira/browse/MAPREDUCE-1662
MAPREDUCE-1663,Bug,Major,task,mapred.local.dir for IsolationRunner is not set properly,MAPREDUCE-842 enforces that mapred.local.dir for Task to be attemptDirs in all local dirs. The conf is not set to attemptDirs for IsolationRunner.  So; the map output files are created directly under Cluster's local dir. The same can be seen in TestIsolationRunner. Test does not fail because it is not validated.,Resolved,Won't Fix,,Unassigned,Amareshwari Sriramadasu,Thu; 1 Apr 2010 06:13:29 +0000,Fri; 5 Aug 2011 12:02:34 +0000,Fri; 5 Aug 2011 12:02:34 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1663
MAPREDUCE-1664,Bug,Major,security,Job Acls affect Queue Acls,MAPREDUCE-1307 introduced job ACLs for securing job level operations. So in current trunk; queue ACLs and job ACLs are checked(with AND for both acls) for allowing job level operations. So for doing operations like killJob; killTask and setJobPriority user should be part of both mapred.queue. {queuename}.acl-administer-jobs and in mapreduce.job.acl-modify-job. This needs to change so that users who are part of mapred.queue.{queuename} .acl-administer-jobs will be able to do killJob;killTask;setJobPriority and users part of mapreduce.job.acl-modify-job will be able to do killJob;killTask;setJobPriority.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Thu; 1 Apr 2010 08:57:44 +0000,Thu; 11 Feb 2016 23:12:18 +0000,Fri; 17 Sep 2010 07:38:02 +0000,,0.22.0,,MAPREDUCE-1759;MAPREDUCE-1550;HADOOP-6922,,https://issues.apache.org/jira/browse/MAPREDUCE-1664
MAPREDUCE-1665,Bug,Major,security,kill and modify should not be the same acl,The permission to kill a job task should be split out from modification.  There are definitely instances where someone who can kill a job should not be able to modify it.  Third person job monitoring; for example; such as we have here at LinkedIn.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Thu; 1 Apr 2010 14:30:23 +0000,Wed; 2 Nov 2011 17:42:57 +0000,Wed; 2 Nov 2011 17:42:57 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1665
MAPREDUCE-1666,New Feature,Minor,job submission,job output chroot support,It would be useful to be able to submit the same job and have it chroot the output to a different base directory before execution.  This would allow for input to be the same; but output different for the same job over multiple runs (potentially by different users).,Resolved,Invalid,,Unassigned,Allen Wittenauer,Thu; 1 Apr 2010 20:43:02 +0000,Thu; 1 Apr 2010 22:13:17 +0000,Thu; 1 Apr 2010 22:13:17 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1666
MAPREDUCE-1667,Bug,Major,jobtracker,resource estimation still works badly in some cases,A premise upon which our current implemention of ResourceEstimator is that the MapInputSize and MapOutputSize has relation.   In many user cases; the premise is not satisfied.    e.g.   1. The map input is a file list. 2. Every mapper will download the file; process; then output (into map intermediate output)  if one file name is very long; the estimated output size maybe very big.,Open,Unresolved,,Ruyue Ma,Ruyue Ma,Fri; 2 Apr 2010 09:17:43 +0000,Mon; 5 Apr 2010 06:12:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1667
MAPREDUCE-1668,Bug,Major,contrib/raid,RaidNode should only Har a directory if all its parity files have been created,In the current code; it can happen that a directory will be Archived (Har'ed) before all its parity files have been generated since parity file generation is not atomic. We should verify if all the parity files are present before Archiving a directory.,Closed,Fixed,,Ramkumar Vadali,Rodrigo Schmidt,Fri; 2 Apr 2010 14:17:31 +0000,Mon; 12 Dec 2011 06:20:04 +0000,Mon; 30 Aug 2010 04:14:23 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1668
MAPREDUCE-1669,Improvement,Major,,The imported JSON credentials should support binary secrets.,Currently; we support adding a file with secrets to a job. It can either be in binary or JSON; but the JSON format assumes that all of the secrets are UTF-8; which is often false. We should pick a format that allows binary data to be included.,Open,Unresolved,,Unassigned,Owen O'Malley,Fri; 2 Apr 2010 17:46:15 +0000,Fri; 2 Apr 2010 17:46:15 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1669
MAPREDUCE-1670,Bug,Major,contrib/raid,RAID should avoid policies that scan their own destination path,Raid currently allows policies that include the destination directory into the source directory and vice-versa. Both situations can create cycles and should be avoided.,Closed,Fixed,,Ramkumar Vadali,Rodrigo Schmidt,Sat; 3 Apr 2010 23:52:01 +0000,Mon; 12 Dec 2011 06:18:28 +0000,Mon; 30 Aug 2010 01:48:01 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1670
MAPREDUCE-1671,Test,Major,test,"Test scenario for ""Killing Task Attempt id till job fails""",1) In a  job; kill the task attemptid of one task.  Whenever that task  tries to run again with another task atempt id for mapred.map.max.attempts times; kill that task attempt id. After the mapred.map.max.attempts times; the whole job should get killed.,Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Mon; 5 Apr 2010 07:21:07 +0000,Mon; 27 Sep 2010 04:14:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1671
MAPREDUCE-1672,Test,Major,test,"Create test scenario for ""distributed cache file behaviour; when dfs file is not modified""",This test scenario is for a distributed cache file behaviour when it is not modified before and after being accessed by maximum two jobs. Once a job uses a distributed cache file that file is stored in the mapred.local.dir. If the next job uses the same file; then that is not stored again. So; if two jobs choose the same tasktracker for their job execution then; the distributed cache file should not be found twice.  This testcase should run a job with a distributed cache file. All the tasks' corresponding tasktracker's handle is got and checked for the presence of distributed cache with proper permissions in the proper directory. Next when job runs again and if any of its tasks hits the same tasktracker; which ran one of the task of the previous job; then that file should not be uploaded again and task use the old file.,Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Mon; 5 Apr 2010 11:15:02 +0000,Tue; 6 Jul 2010 04:34:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1672
MAPREDUCE-1673,New Feature,Major,contrib/raid,Start and Stop scripts for the RaidNode,We should have scripts that start and stop the RaidNode automatically. Something like start-raidnode.sh and stop-raidnode.sh,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Mon; 5 Apr 2010 12:29:35 +0000,Tue; 24 Aug 2010 21:21:25 +0000,Wed; 21 Apr 2010 00:20:43 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1673
MAPREDUCE-1674,New Feature,Major,capacity-sched,Some new features for CapacityTaskScheduler,Some new features for CapacityTaskScheduler developed at Baidu.,Resolved,Incomplete,,Unassigned,Kang Xiao,Tue; 6 Apr 2010 02:30:55 +0000,Wed; 30 Jul 2014 17:27:05 +0000,Wed; 30 Jul 2014 17:27:05 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1674
MAPREDUCE-1675,Improvement,Major,contrib/gridmix,SleepJob hacks GridmixKey to pass along the sleep duration from map tasks to reduce tasks.,SleepJob hacks GridmixKey to pass along the sleep duration from map tasks to reduce tasks. We need to come up with cleaner solution,Resolved,Incomplete,,Unassigned,rahul k singh,Tue; 6 Apr 2010 05:32:42 +0000,Wed; 30 Jul 2014 17:27:35 +0000,Wed; 30 Jul 2014 17:27:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1675
MAPREDUCE-1676,Test,Major,,"Create test scenario for ""distributed cache file behaviour; when dfs file is modified""",Verify the Distributed Cache functionality. This test scenario is for a distributed cache file behaviour when it is modified before and after being accessed by maximum two jobs. Once a job uses a distributed cache file  that file is stored in the mapred.local.dir. If the next job  uses the same file; but with differnt timestamp; then that  file is stored again. So; if two jobs choose the same tasktracker for their job execution then; the distributed cache file should be found twice.  This testcase runs a job with a distributed cache file. All the tasks' corresponding tasktracker's handle is got and checked for the presence of distributed cache with proper permissions in the proper directory. Next when job runs again and if any of its tasks hits the same tasktracker; which ran one of the task of the previous job; then that file should be uploaded again and task should not use the old file.,Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Tue; 6 Apr 2010 15:04:22 +0000,Thu; 2 May 2013 02:29:31 +0000,,,0.22.0,,MAPREDUCE-1758,,https://issues.apache.org/jira/browse/MAPREDUCE-1676
MAPREDUCE-1677,Test,Major,test,Test scenario for a distributed cache file behaviour  when the file is private,Verify the Distributed Cache functionality.  This test scenario is for a distributed cache file behaviour  when the file is private. Once a job uses a distributed  cache file with private permissions that file is stored in the  mapred.local.dir; under the directory which has the same name   as job submitter's username. The directory has 700 permission  and the file under it; should have 777 permissions.,Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Tue; 6 Apr 2010 15:07:26 +0000,Thu; 13 May 2010 23:06:35 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1677
MAPREDUCE-1678,New Feature,Trivial,job submission,Change org.apache.hadoop.mapreduce.Cluster methods to allow for extending,Change methods in org.apache.hadoop.mapreduce.Cluster from private to protected to allow extension of cluster. If the method createRPCProxy is changed from private to protected; then alternate cluster implementations could be written that return other ClientProtocol's.  For example; changing the protocol some custom implementation called SimpleClient  ie: public class SimpleCluster extends Cluster {   @Override   protected ClientProtocol createRPCProxy(InetSocketAddress addr; Configuration conf) throws IOException  {     return new SimpleClient(conf);   }   },Closed,Duplicate,MAPREDUCE-2400,Harsh J,Kyle Ellrott,Tue; 6 Apr 2010 23:24:11 +0000,Tue; 15 Nov 2011 00:48:33 +0000,Tue; 14 Jun 2011 11:51:04 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1678
MAPREDUCE-1679,Improvement,Trivial,capacity-sched,capacity scheduler's user-limit documentation is not helpful,The example given for the user limit tunable doesn't actually show how that value comes into play.  With 4 users; the Max() is 25 for both the user limit and the capacity limit (from my reading of the source).  Either pushing the example to 5 users or raising the user limit to something higher than 25 would help a great deal.  Also; presenting this info in tabular format showing how the max() value is in play would also be great.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 6 Apr 2010 23:42:46 +0000,Wed; 2 Nov 2011 17:42:27 +0000,Wed; 2 Nov 2011 17:42:27 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1679
MAPREDUCE-1680,New Feature,Major,jobtracker,Add a metrics to track the number of heartbeats processed,It would be nice to add a metrics that tracks the number of heartbeats processed by JT.,Closed,Fixed,,Dick King,Hong Tang,Wed; 7 Apr 2010 00:28:25 +0000,Mon; 12 Dec 2011 06:19:45 +0000,Thu; 6 May 2010 02:22:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1680
MAPREDUCE-1681,Improvement,Major,build;documentation,MapReduce API compatibility,This is an umbrella issue to document and test MapReduce API compatibility across releases.,Resolved,Fixed,,Unassigned,Tom White,Wed; 7 Apr 2010 03:59:30 +0000,Wed; 30 Jul 2014 17:30:57 +0000,Wed; 30 Jul 2014 17:30:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1681
MAPREDUCE-1682,Bug,Major,jobtracker,Tasks should not be scheduled after tip is killed/failed.,We have seen the following scenario in our cluster: A job got marked failed; because four attempts of a TIP failed. This would kill all the map and reduce tips. Then a job-cleanup attempt is launched. The job-cleanup attempt failed because it could not report status for 10 minutes. There are 3 such job-cleanup attempts leading the job to get killed after 1 failed.,Resolved,Fixed,,Arun C Murthy,Amareshwari Sriramadasu,Wed; 7 Apr 2010 04:37:13 +0000,Wed; 30 Jul 2014 17:31:33 +0000,Wed; 30 Jul 2014 17:31:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1682
MAPREDUCE-1683,Bug,Major,jobtracker,Remove JNI calls from ClusterStatus cstr,The ClusterStatus constructor makes two JNI calls to the Runtime to fetch memory information. ClusterStatus instances are often created inside the JobTracker to obtain other; unrelated metrics (sometimes from schedulers' inner loops). Given that this information is related to the JobTracker process and not the cluster; the metrics are also available via JvmMetrics; and the jsps can gather this information for themselves: these fields can be removed from ClusterStatus,Closed,Fixed,,Luke Lu,Chris Douglas,Wed; 7 Apr 2010 06:58:10 +0000,Mon; 12 Dec 2011 06:18:59 +0000,Mon; 24 May 2010 18:45:18 +0000,,0.20.2,,MAPREDUCE-1779,,https://issues.apache.org/jira/browse/MAPREDUCE-1683
MAPREDUCE-1684,Bug,Major,capacity-sched,ClusterStatus can be cached in CapacityTaskScheduler.assignTasks(),Currently;  CapacityTaskScheduler.assignTasks() calls getClusterStatus() thrice: once in assignTasks(); once in MapTaskScheduler and once in ReduceTaskScheduler. It can be cached in assignTasks() and re-used.,Closed,Fixed,,Koji Noguchi,Amareshwari Sriramadasu,Wed; 7 Apr 2010 10:46:56 +0000,Wed; 15 May 2013 05:16:06 +0000,Tue; 28 Aug 2012 21:29:22 +0000,,1.0.2,,,MAPREDUCE-4499,https://issues.apache.org/jira/browse/MAPREDUCE-1684
MAPREDUCE-1685,Bug,Major,,Debug statements affecting performance of JobTracker.heartbeat,Several debug statements that come in the critical section in JobTracker.heartbeat() are not protected by a LOG.isDebugEnabled() and so incur non-trivial costs; in the order of 15% of the total heartbeat processing time.,Resolved,Duplicate,MAPREDUCE-1533,Unassigned,Vinod Kumar Vavilapalli,Thu; 8 Apr 2010 08:42:24 +0000,Tue; 27 Apr 2010 08:24:27 +0000,Tue; 27 Apr 2010 08:24:27 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1685
MAPREDUCE-1686,Bug,Minor,contrib/streaming;test,ClassNotFoundException for custom format classes provided in libjars,The StreamUtil::goodClassOrNull method assumes user-provided classes have package names and if not; they are part of the Hadoop Streaming package. For example; using custom InputFormat or OutputFormat classes without package names will fail with a ClassNotFound exception which is not indicative given the classes are provided in the libjars option. Admittedly; most Java packages should have a package name so this should rarely come up.  Possible resolution options:  1) modify the error message to include the actual classname that was attempted in the goodClassOrNull method 2) call the Configuration::getClassByName method first and if class not found check for default package name and try the call again,Resolved,Fixed,,Paul Burkhardt,Paul Burkhardt,Thu; 8 Apr 2010 16:30:43 +0000,Fri; 29 Oct 2010 02:04:18 +0000,Fri; 30 Jul 2010 09:39:17 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1686
MAPREDUCE-1687,Bug,Major,contrib/gridmix,Stress submission policy does not always stress the cluster.,Currently; the rough idea of stress submission policy is to continue submitting jobs until the pending map tasks reach 2x of the cluster capacity. This proves to be inadequate and we saw a large job could monopolize the whole cluster.,Resolved,Fixed,,Amar Kamat,Hong Tang,Fri; 9 Apr 2010 07:24:17 +0000,Sun; 1 Apr 2012 05:01:24 +0000,Sun; 1 Apr 2012 05:00:24 +0000,,,,,MAPREDUCE-3769;MAPREDUCE-3481,https://issues.apache.org/jira/browse/MAPREDUCE-1687
MAPREDUCE-1688,Bug,Major,jobtracker,A failing retry'able notification in JobEndNotifier can affect notifications of other jobs.,The JobTracker puts all the notification commands into a delay-queue.  It has a single thread that loops through this queue and sends out the notifications.  When it hits failures with any notification which is configured to be retired via job.end.retry.attempts and job.end.retry.interval; the notification is queued back again. A single notification with sufficiently large number of configured retries and which consistently fails will affect other notifications in the queue.,Resolved,Duplicate,MAPREDUCE-3028,Ravi Prakash,Vinod Kumar Vavilapalli,Fri; 9 Apr 2010 17:56:16 +0000,Fri; 1 Feb 2013 03:20:47 +0000,Tue; 21 Feb 2012 22:07:32 +0000,,0.20.1;1.0.0;1.0.2;1.0.3,,,MAPREDUCE-4935;MAPREDUCE-3028,https://issues.apache.org/jira/browse/MAPREDUCE-1688
MAPREDUCE-1689,Improvement,Major,client;jobtracker;task;tasktracker,Write MR wire protocols in Avro IDL,As part of the the move to AVRO and wire compatibility; write all Map-Reduce protocols in AVRO IDL. This is analogous to HDFS-1069.,Resolved,Won't Fix,,Arun C Murthy,Arun C Murthy,Sat; 10 Apr 2010 23:43:13 +0000,Wed; 30 Jul 2014 17:10:32 +0000,Wed; 30 Jul 2014 17:10:32 +0000,,,,,HADOOP-6659,https://issues.apache.org/jira/browse/MAPREDUCE-1689
MAPREDUCE-1690,Improvement,Major,task;tasktracker,Using BuddySystem to reduce the ReduceTask's mem usage in the step of shuffle,"When the reduce task launched; it will start several MapOutputCopier threads to download the output from finished map; every thread is a MapOutputCopier thread running instance. Every time the thread trying to copy map output from remote from local; the MapOutputCopier thread will desides to shuffle the map output data in memory or to disk; this depends on the map output data size and the configuration of the ShuffleRamManager which loaded from the client hadoop-site.xml or JobConf; no matter what; if the reduce task decides to shuffle the map output data in memory ; the MapOutputCopier will connect to the remote map host ; read the map output in the socket; and then  copy map-output into an in-memory buffer; and every time; the in-memory buffer is from ""byte[] shuffleData = new bytemapOutputLength;""; here is where the problem begin. In our cluster; there are some special jobs which will process a huge number of original data; say 110TB;  so the reduce tasks will shuffle a lot of data; some shuffled to disk and some shuffle in memory; even though; their will be a lot of data shuffled in memory; and every time the MapOutputCopier threads will ""new"" some memory from the reduce heap; for a long-running-huge-data job; this will easily feed the Reduce Task's heap size to the full;  make the reduce task to OOM and then exhausted the memory of the TaskTracker machine.        Here is our solution: Change the code logic when MapOutputCopier threads shuffle map-output in memory; using a BuddySystem similar to the Linux Kernel  BuddySystem which used to allocate and deallocate memory page. When the reduce task launched ; initialize some memory to this BuddySystem; say 128MB; everytime the reduce want to shuffle map-output in memory ;just require memory buffer from the buddySystem; if the buddySystem has enough memory ; use it; and if not ; let  the MapOutputCopier threads to wait() just like what they do right now in the current hadoop shuffle code logic. This will reduce the Reduce Task's memory usage and reduce the TaskTracker memory shortage a lot. In our cluster; this buddySystem makes the situation of ""lost a batch of tasktrackers because of memory over used when the huge jobs running  ""  disappeared. And therefore makes the cluster more stable.",Resolved,Won't Fix,,Unassigned,luoli,Sun; 11 Apr 2010 06:14:08 +0000,Wed; 30 Jul 2014 17:40:08 +0000,Wed; 30 Jul 2014 17:40:08 +0000,,0.20.2;0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1690
HADOOP-6700,Improvement,Major,documentation,Hadoop commands guide should include examples,Currently; The Hadoop command guide (http: commands_manual.html) just lists all the available command line options; with a description. It should include examples for each command for more clarity.,Resolved,Fixed,,Unassigned,Amareshwari Sriramadasu,Mon; 12 Apr 2010 06:32:51 +0000,Fri; 15 May 2015 18:03:57 +0000,Fri; 15 May 2015 18:03:57 +0000,,,newbie,,HADOOP-10899,https://issues.apache.org/jira/browse/HADOOP-6700
MAPREDUCE-1692,Bug,Minor,contrib/streaming,Remove TestStreamedMerge from the streaming tests,Currently the TestStreamedMerge is never run as a part of the streaming test suite; the code paths which were exercised by the test was removed in HADOOP-1315; so it is better to remove the testcase from the code base.,Closed,Fixed,,Amareshwari Sriramadasu,Sreekanth Ramakrishnan,Mon; 12 Apr 2010 06:37:05 +0000,Tue; 24 Aug 2010 21:21:25 +0000,Sat; 17 Apr 2010 09:39:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1692
MAPREDUCE-1693,Task,Major,test,Process tree clean up of either a failed task or killed task tests.,The following scenarios covered in the test.  1. Run a job which spawns subshells in the tasks. Kill one of the task. All the child process of the killed task must be killed. 2. Run a job which spawns subshells in tasks. Fail one of the task. All the child process of the killed task must be killed along with the task after its failure. 3. Check process tree cleanup on paritcular task-tracker when we use -kill-task and -fail-task with both map and reduce.  4. Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Let the job complete . Check if all the child processes are killed; the overall job should fail.  l)Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Kill fail the job while in progress. Check if all the child processes are killed.,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 12 Apr 2010 18:15:56 +0000,Wed; 30 Jul 2014 18:00:26 +0000,Wed; 30 Jul 2014 18:00:26 +0000,,,,MAPREDUCE-1713,,https://issues.apache.org/jira/browse/MAPREDUCE-1693
MAPREDUCE-1694,Bug,Major,contrib/streaming;documentation,streaming documentation appears to be wrong on overriding settings w/-D,"Throughout http: streaming.html ; there are many examples that do ""hadoop jar streaming blah -Dsomething=something"".  None of these examples appear to work anymore.  Moving the ""-Dsomething=something"" to be after ""hadoop jar streaming"" works.",Closed,Fixed,,Unassigned,Allen Wittenauer,Mon; 12 Apr 2010 20:12:23 +0000,Tue; 24 Aug 2010 21:21:26 +0000,Fri; 23 Apr 2010 20:57:05 +0000,,0.20.2,,,MAPREDUCE-813,https://issues.apache.org/jira/browse/MAPREDUCE-1694
MAPREDUCE-1695,Bug,Major,capacity-sched,capacity scheduler is not included in findbugs/javadoc targets,Capacity Scheduler is not included in findbugs  oc targets.,Closed,Fixed,,Hong Tang,Hong Tang,Tue; 13 Apr 2010 00:26:34 +0000,Tue; 24 Aug 2010 21:21:27 +0000,Fri; 23 Apr 2010 09:11:54 +0000,,,,MAPREDUCE-1715;MAPREDUCE-1253,,https://issues.apache.org/jira/browse/MAPREDUCE-1695
MAPREDUCE-1696,Improvement,Minor,jobtracker,Add current time to the job tracker web UI pages,Add current time (both GMT and local) to the job tracker web UI pages,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Mon; 12 May 2008 07:46:33 +0000,Tue; 13 Apr 2010 04:11:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1696
MAPREDUCE-1697,Bug,Major,contrib/streaming;documentation,Document the behavior of -file option in streaming and deprecate it in favour of generic -files option.,The behavior of -file option in streaming is not documented anywhere. The behavior of -file is the following : 1) All the files passed through  -file option are packaged into job.jar. 2) If -file option is used for .class or .jar files; they are unjarred on tasktracker and placed in ${mapred.local.dir} . Symlinks to these files are created from the cwd of the task. Names of these symlinks are actually file names.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 13 Apr 2010 05:03:40 +0000,Tue; 24 Aug 2010 21:21:28 +0000,Tue; 8 Jun 2010 06:43:10 +0000,,0.20.1,,,MAPREDUCE-1826,https://issues.apache.org/jira/browse/MAPREDUCE-1697
MAPREDUCE-1698,Improvement,Major,,InputSplit.getLocations() semantics is not clear.,The semantics of InputSplit.getLocations() is not clear and this has led to sub optimal implementations and even bugs (PIG-878) in the past.,Open,Unresolved,,Unassigned,Hong Tang,Wed; 14 Apr 2010 00:31:19 +0000,Wed; 14 Apr 2010 01:03:23 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1698
MAPREDUCE-1699,Bug,Major,jobtracker,JobHistory shouldn't be disabled for any reason,Recently we have had issues with JobTracker silently disabling job-history and starting to keep all completed jobs in memory. This leads to OOM on the JobTracker. We should never do this.,Resolved,Fixed,,Krishna Ramachandran,Arun C Murthy,Wed; 14 Apr 2010 01:04:22 +0000,Mon; 31 Oct 2011 05:00:59 +0000,Mon; 31 Oct 2011 05:00:59 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1699
MAPREDUCE-1700,Bug,Major,task,User supplied dependencies may conflict with MapReduce system JARs,If user code has a dependency on a version of a JAR that is different to the one that happens to be used by Hadoop; then it may not work correctly. This happened with user code using a different version of Avro; as reported here.  The problem is analogous to the one that application servers have with WAR loading. Using a specialized classloader in the Child JVM is probably the way to solve this.,Closed,Fixed,,Tom White,Tom White,Wed; 14 Apr 2010 04:10:00 +0000,Fri; 9 Dec 2016 03:31:04 +0000,Wed; 9 Jan 2013 16:24:04 +0000,,,,,MAPREDUCE-1938;HADOOP-10893;MAPREDUCE-5802;PIG-3043,https://issues.apache.org/jira/browse/MAPREDUCE-1700
MAPREDUCE-1701,Bug,Major,jobtracker,AccessControlException while renewing a delegation token in not correctly handled in the JobTracker,The timer task for renewing delegation token gets scheduled even when an AccessControlException is obtained.,Closed,Fixed,,Boris Shkolnik,Devaraj Das,Wed; 14 Apr 2010 06:17:20 +0000,Mon; 12 Dec 2011 06:19:12 +0000,Thu; 29 Jul 2010 00:57:14 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1701
MAPREDUCE-1702,Improvement,Minor,contrib/gridmix,CPU/Memory emulation for GridMix3,Currently GridMix3 can successfully recreate I memory usage of tasks on the cluster; save them to JobHistory so that they can be read by Rumen; and replay the cpu and memory usage in gridmix3 jobs.,Closed,Fixed,,Unassigned,Jaideep,Thu; 15 Apr 2010 04:05:40 +0000,Tue; 15 Nov 2011 00:49:41 +0000,Wed; 15 Jun 2011 11:44:02 +0000,,,,MAPREDUCE-2104,,https://issues.apache.org/jira/browse/MAPREDUCE-1702
MAPREDUCE-1703,Bug,Major,tasktracker,TaskRunner would crash in finally block if taskDistributedCacheManager is null,"If TaskRunner throws an Exception before initializing taskDistributedCacheManager; it would crash in finally block at taskDistributedCacheManager.release(). TaskRunner would crash without doing tip.reportTaskFinished() thus not failing the task. Task will be marked FAILED after ""mapred.task.timeout"" because there is no report from  the task.  We should add a not null check for taskDistributedCacheManager in finally block.",Resolved,Duplicate,MAPREDUCE-1707,Unassigned,Amareshwari Sriramadasu,Thu; 15 Apr 2010 05:10:25 +0000,Thu; 29 Apr 2010 08:50:13 +0000,Thu; 29 Apr 2010 08:50:13 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1703
MAPREDUCE-1704,Bug,Major,contrib/raid,Parity files that are outdated or nonexistent should be immediately disregarded,In the current implementation; old or nonexistent parity files are not immediately disregarded. Absence will trigger exceptions; but old files could lead to bad recoveries and maybe data corruption. This should be fixed.,Resolved,Invalid,,Scott Chen,Rodrigo Schmidt,Thu; 15 Apr 2010 08:24:28 +0000,Mon; 8 Nov 2010 02:02:22 +0000,Mon; 8 Nov 2010 02:02:22 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1704
MAPREDUCE-1705,Bug,Major,contrib/raid,Archiving and Purging of parity files should handle globbed policies,Archiving (har) and purging of parity files don't work in policies whose source is a globbed path.,Closed,Fixed,,Rodrigo Schmidt,Rodrigo Schmidt,Thu; 15 Apr 2010 08:28:56 +0000,Tue; 24 Aug 2010 21:21:29 +0000,Tue; 27 Apr 2010 01:10:36 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1705
MAPREDUCE-1706,Improvement,Major,contrib/raid,Log RAID recoveries on HDFS,It would be good to have a way to centralize all the recovery logs; since recovery can be executed by any hdfs client. The best place to store this information is HDFS itself.,Closed,Fixed,,Scott Chen,Rodrigo Schmidt,Thu; 15 Apr 2010 08:44:45 +0000,Tue; 15 Nov 2011 00:49:20 +0000,Fri; 4 Feb 2011 00:44:44 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1706
MAPREDUCE-1707,Bug,Major,tasktracker,TaskRunner can get NPE in getting ugi from TaskTracker,The following code in TaskRunner can get NPE in the scenario described below.    The scenario: Tracker got a LaunchTaskAction; Task is localized and TaskRunner is started. Then Tracker got a KillJobAction; This would issue a kill for the task. But; kill will be a no-op because the task did not actually start; The job is removed from runningJobs.  Then if TaskRunner calls tracker.getRunningJob(t.getJobID()); it will be null.  Instead of TaskRunner doing a back call to tasktracker to get the ugi; tracker.getRunningJob(t.getJobID()).getUGI(); ugi should be passed a parameter in the constructor of TaskRunner.,Closed,Fixed,,Vinod Kumar Vavilapalli,Amareshwari Sriramadasu,Thu; 15 Apr 2010 08:58:38 +0000,Mon; 12 Dec 2011 06:19:16 +0000,Tue; 4 May 2010 06:30:55 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1707
MAPREDUCE-1708,Bug,Major,task;test,Add a test for connect and read time outs during shuffle.,Write a test which injects connect and read time outs during shuffle and validates the fetch failures for corresponding maps.,Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Thu; 15 Apr 2010 10:32:16 +0000,Wed; 30 Jul 2014 17:46:02 +0000,Wed; 30 Jul 2014 17:46:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1708
MAPREDUCE-1709,Bug,Major,,mapred.cache.archives is not creating links for long path names,I got the following complaint:    We specified this JobConf parameter:  mapred.cache.archives= tutorial-udf.jar   I will look into this and publish detailed problem duplication instructions soon.,Resolved,Duplicate,MAPREDUCE-1641,Dick King,Dick King,Thu; 15 Apr 2010 18:00:14 +0000,Wed; 30 Jul 2014 17:47:29 +0000,Wed; 30 Jul 2014 17:47:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1709
MAPREDUCE-1710,Task,Major,test,Process tree clean up of exceeding memory limit tasks.,1. Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Let the job complete . Check if all the child processes are killed; the overall job should fail.  2. Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Kill fail the job while in progress. Check if all the child processes are killed.,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 16 Apr 2010 11:25:41 +0000,Wed; 30 Jul 2014 17:53:11 +0000,Wed; 30 Jul 2014 17:53:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1710
MAPREDUCE-1711,Improvement,Major,contrib/gridmix,Gridmix should provide an option to submit jobs to the same queues as specified in the trace.,Gridmix should provide an option to submit jobs to the same queues as specified in the trace.,Closed,Fixed,,rahul k singh,Hong Tang,Fri; 16 Apr 2010 23:00:05 +0000,Mon; 12 Dec 2011 06:19:25 +0000,Wed; 14 Jul 2010 09:24:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1711
MAPREDUCE-1712,Bug,Major,harchive,HAR sequence files throw errors in MR jobs,When a HAR is specified as the input for a map reduce job and the file format is sequence file; an error similar to the following is thrown (this one is from Hive).     This is caused by the dummy block location returned by HarFileSystem.getFileBlockLocations().,Resolved,Duplicate,MAPREDUCE-1752,Mahadev konar,Paul Yang,Sat; 17 Apr 2010 00:50:14 +0000,Wed; 2 Mar 2011 22:56:14 +0000,Wed; 2 Mar 2011 22:56:14 +0000,,0.20.1,,,MAPREDUCE-1752,https://issues.apache.org/jira/browse/MAPREDUCE-1712
MAPREDUCE-1713,Task,Major,test,Utilities for system tests specific.,1.  A method for restarting  the daemon with new configuration.       public static  void restartCluster(HashtableString;Long props; String confFile) throws Exception;  2.  A method for resetting the daemon with default configuration.       public void resetCluster() throws Exception;  3.  A method for waiting until daemon to stop.       public  void waitForClusterToStop() throws Exception;  4.  A method for waiting until daemon to start.       public  void waitForClusterToStart() throws Exception;  5.  A method for checking the job whether it has started or not.       public boolean isJobStarted(JobID id) throws IOException;  6.  A method for checking the task whether it has started or not.       public boolean isTaskStarted(TaskInfo taskInfo) throws IOException;,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 19 Apr 2010 07:00:33 +0000,Wed; 30 Jul 2014 18:00:52 +0000,Wed; 30 Jul 2014 18:00:52 +0000,,0.21.0,,MAPREDUCE-1693;MAPREDUCE-1774,,https://issues.apache.org/jira/browse/MAPREDUCE-1713
MAPREDUCE-1714,Bug,Major,,Delegation Token is scheduled for renewal when previous renewal faild with AccessControlException,In case of failed renewal (with AccessControlException) we should not schedule another renewal (because it till fail too).,Resolved,Duplicate,MAPREDUCE-1701,Boris Shkolnik,Boris Shkolnik,Mon; 19 Apr 2010 21:52:49 +0000,Mon; 19 Apr 2010 22:06:04 +0000,Mon; 19 Apr 2010 22:06:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1714
MAPREDUCE-1715,Bug,Major,,TaskSchedulingContext.updateNoOfSlotsOccupiedByUser does not update slots used by a new user,TaskSchedulingContext.updateNoOfSlotsOccupiedByUser does not update slots used by a new user.,Open,Unresolved,,Unassigned,Hong Tang,Tue; 20 Apr 2010 17:19:36 +0000,Tue; 20 Apr 2010 18:05:45 +0000,,,,,MAPREDUCE-1695,,https://issues.apache.org/jira/browse/MAPREDUCE-1715
MAPREDUCE-1716,Sub-task,Major,task;tasktracker,Truncate logs of finished tasks to prevent node thrash due to excessive logging,nan,Resolved,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 21 Apr 2010 10:42:37 +0000,Wed; 30 Jul 2014 18:08:36 +0000,Wed; 30 Jul 2014 18:08:36 +0000,,0.20.3;0.21.0;0.21.1;0.22.0,critical-0.22.0,,MAPREDUCE-1648,https://issues.apache.org/jira/browse/MAPREDUCE-1716
MAPREDUCE-1717,Improvement,Major,jobtracker,Topology resolution should be asynchronous ,Currently we hold the JT lock while resolving topology of nodes. We need to make this asynchronous w.r.t. the JT lock.,Resolved,Incomplete,,Unassigned,Arun C Murthy,Wed; 21 Apr 2010 18:31:01 +0000,Wed; 30 Jul 2014 18:09:06 +0000,Wed; 30 Jul 2014 18:09:06 +0000,,0.22.0,,,MAPREDUCE-1372,https://issues.apache.org/jira/browse/MAPREDUCE-1717
MAPREDUCE-1718,Bug,Major,,job conf key for the services name of DelegationToken for HFTP url is constructed incorrectly in HFTPFileSystem,the key (build in TokenCache) is hdfs.service.host_HOSTNAME.PORT; but  in HftpFileSystem it is sometimes built as hdfs.service.host_IP.PORT.  Fix. change it to always be IP.,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Thu; 22 Apr 2010 00:26:34 +0000,Mon; 12 Dec 2011 06:19:56 +0000,Fri; 23 Jul 2010 22:57:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1718
MAPREDUCE-1719,Bug,Major,jobtracker,Wrong map-output estimates by ResourceEstimator because of overflow errors in 'long' calculations,On a cluster with disks nearly full; while running a simple sort job on a 10TBdata with ~100 maps; ResourceEstimator is not getting triggered even after 10%maps are completed. Instead; maps keep on getting scheduled till the disks became full and then eventually when the disk size becomes zero; the ResourceEstimator finally comes back alive saying it can find only zero bytes instead of the estimated '9642' bytes. The estimate should have be close to 10GB.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 22 Apr 2010 06:14:38 +0000,Thu; 22 Apr 2010 06:18:03 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1719
MAPREDUCE-1720,Bug,Major,jobtracker, 'Killed' jobs and 'Failed' jobs should be displayed seperately in JobTracker UI,The JobTracker UI shows both Failed Killed Jobs as Failed. The Killed job status has been separated from Failed as part of HADOOP-3924; so the UI needs to be updated to reflect the same..,Resolved,Not A Problem,,Harsh J,Subru Krishnan,Thu; 22 Apr 2010 09:28:07 +0000,Thu; 24 Apr 2014 01:41:05 +0000,Fri; 13 Jul 2012 15:00:33 +0000,,0.20.1,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-1720
MAPREDUCE-1721,Bug,Minor,examples,Default output format for RandomTextWriter should be TextOutputFormat,Default output format for RandomTextWriter should be TextOutputFormat; currently output format is SequenceFileOutputFormat.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Thu; 22 Apr 2010 10:09:25 +0000,Thu; 13 Jan 2011 02:28:38 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1721
MAPREDUCE-1722,Improvement,Minor,contrib/index,contrib/index - Upgrade to new Hadoop and Lucene API,contrib index should be updated and based on these new APIs.,Resolved,Won't Fix,,Unassigned,Renaud Delbru,Thu; 22 Apr 2010 12:00:59 +0000,Wed; 30 Jul 2014 18:12:31 +0000,Wed; 30 Jul 2014 18:12:31 +0000,,0.20.2,index;lucene,,,https://issues.apache.org/jira/browse/MAPREDUCE-1722
MAPREDUCE-1723,Improvement,Major,capacity-sched,Capacity Scheduler should allow configuration of Map & Reduce task slots independently per queue,The Capacity Scheduler allows configuration of percentage of task slots per queue. We have a scenario in which our biggest queue (50% quota) has Jobs with mainly Map tasks  we need to enforce strict capacity limits per queue due to SLA requirements. So other smaller queues which require Reduce tasks gets starved even though the Reduce slots are idle. The Grid can be more efficiently utilized if Capacity Scheduler allows configuration of Map  Reduce task slots capacity independently per queue.,Resolved,Won't Fix,,Unassigned,Subru Krishnan,Thu; 22 Apr 2010 12:05:01 +0000,Wed; 30 Jul 2014 18:15:00 +0000,Wed; 30 Jul 2014 18:14:59 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1723
MAPREDUCE-1724,Bug,Minor,jobtracker,JobTracker balks at empty String for locations,"If a split has locations which are """" (empty String); then the JobTracker will get upset during initialization:  2010-04-22 19:09:20;395 ERROR org.apache.hadoop.mapred.JobTracker: Job initialization failed:  637)  Two key points:  	This is different from Hadoop 0.18 	CombineFileSplit has a constructor where String[] location is not specified; and hence the location array is populated with empty Strings.",Resolved,Fixed,,Unassigned,Craig Macdonald,Fri; 23 Apr 2010 10:08:40 +0000,Wed; 30 Jul 2014 18:15:53 +0000,Wed; 30 Jul 2014 18:15:53 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1724
MAPREDUCE-1725,Bug,Blocker,client,Fix MapReduce API incompatibilities between 0.20 and 0.21,A few API compatibilities have crept in since 0.20 (they are being tracked in MAPREDUCE-1623). These should be fixed before 0.21 is released.,Closed,Fixed,,Tom White,Tom White,Fri; 23 Apr 2010 20:55:17 +0000,Tue; 24 Aug 2010 21:21:32 +0000,Mon; 7 Jun 2010 22:21:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1725
HADOOP-6812,Bug,Major,documentation,fs.inmemory.size.mb not listed in conf. Cluster setup page gives wrong advice.,"http: cluster_setup.html Documentation error: Real-World Cluster Configurations    core  io.sort.factor					 should be mapred core  io.sort.mb					 should be mapred",Closed,Fixed,,Chris Douglas,Edward Capriolo,Mon; 29 Mar 2010 16:11:34 +0000,Mon; 12 Dec 2011 06:19:02 +0000,Fri; 28 Jan 2011 22:43:33 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/HADOOP-6812
MAPREDUCE-1727,Bug,Major,test,TestJobACLs fails after HADOOP-6686,HADOOP-6686; an incompatbile change; removed exception class name in unwrapped exceptions thrown at the RPC client. TestJobACLs depended on this for verifying exceptions; and thus is broken now.,Closed,Fixed,,Ravi Gummadi,Vinod Kumar Vavilapalli,Mon; 26 Apr 2010 07:22:51 +0000,Tue; 24 Aug 2010 21:21:33 +0000,Wed; 28 Apr 2010 07:23:11 +0000,,0.22.0,,,HADOOP-6686,https://issues.apache.org/jira/browse/MAPREDUCE-1727
MAPREDUCE-1728,Bug,Major,,Oracle timezone strings do not match Java,OracleDBRecordReader sets the session timezone based on the toString representation of the current  util.TimeZone. This is incorrect; Oracle manages a separate database of acceptable timezone strings; whose string representations are different than the timezone representations recognized by Java.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Mon; 26 Apr 2010 23:26:02 +0000,Tue; 24 Aug 2010 21:21:33 +0000,Tue; 27 Apr 2010 17:34:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1728
MAPREDUCE-1729,New Feature,Major,distributed-cache,Distributed cache should provide an option to fail the job or not; if cache file gets modified on the fly.,Currently; distributed cache fails the job if the cache file gets modified on the fly. But there should be an option to fail a job or not. See discussions in MAPREDUCE-1288.,Resolved,Won't Fix,,Akira Ajisaka,Amareshwari Sriramadasu,Tue; 27 Apr 2010 04:16:38 +0000,Wed; 30 Jul 2014 18:22:07 +0000,Wed; 30 Jul 2014 18:22:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1729
MAPREDUCE-1730,Test,Major,,Automate test scenario for successful/killed jobs' memory is properly removed from jobtracker after these jobs retire.,Automate using herriot framework;  test scenario for successful killed jobs' memory is properly removed from jobtracker after these jobs retire.  This should test when successful and failed jobs are retired;  their jobInProgress object are removed properly.,Resolved,Fixed,,Iyappan Srinivasan,Iyappan Srinivasan,Tue; 27 Apr 2010 07:43:39 +0000,Wed; 30 Jul 2014 18:23:09 +0000,Wed; 30 Jul 2014 18:23:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1730
MAPREDUCE-1731,Task,Major,test,Process tree clean up suspended task tests.,1 .Verify the process tree cleanup of suspended task and task should be terminated after timeout. 2. Verify the process tree cleanup of suspended task and resume the task before task timeout.,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Tue; 27 Apr 2010 08:52:39 +0000,Wed; 30 Jul 2014 18:01:25 +0000,Wed; 30 Jul 2014 18:01:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1731
MAPREDUCE-1732,Bug,Major,,bin/hadoop jar hadoop-test.jar mrbench ...  won't honor the -files option,When one of our users incanted    bin MRBench&#93; -jar local path to job jar file containing Mapper and Reducer implementations; default is current jar file&#93; -numRuns number of times to run the job; default is 1&#93; -maps number of maps for each run; default is 2&#93; -reduces number of reduces for each run; default is 1&#93; -inputLines number of input lines to generate; default is 1&#93; -inputType type of input to generate; one of ascending (default); descending; random&#93; -verbose  .,Resolved,Incomplete,,Dick King,Dick King,Tue; 27 Apr 2010 18:21:43 +0000,Wed; 30 Jul 2014 18:23:43 +0000,Wed; 30 Jul 2014 18:23:43 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1732
MAPREDUCE-1733,New Feature,Major,,Authentication between pipes processes and java counterparts.,The connection between a pipe process and its parent  process should be authenticated.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Tue; 27 Apr 2010 23:20:09 +0000,Mon; 12 Dec 2011 06:20:01 +0000,Thu; 22 Jul 2010 22:36:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1733
MAPREDUCE-1734,Improvement,Blocker,documentation,Un-deprecate the old MapReduce API in the 0.20 branch,"This issue is to un-deprecate the ""old"" MapReduce API (in o.a.h.mapred) in the next 0.20 release; as discussed at http: msg01833.html",Resolved,Fixed,,Todd Lipcon,Tom White,Wed; 28 Apr 2010 04:59:47 +0000,Mon; 12 Sep 2011 21:37:00 +0000,Mon; 12 Sep 2011 21:37:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1734
MAPREDUCE-1735,Improvement,Blocker,,Un-deprecate the old MapReduce API in the 0.21 branch,"This issue is to un-deprecate the ""old"" MapReduce API (in o.a.h.mapred) in the next 0.21 release; as discussed at http: msg01833.html",Closed,Fixed,,Tom White,Tom White,Wed; 28 Apr 2010 05:01:25 +0000,Thu; 2 Feb 2012 14:19:03 +0000,Fri; 18 Jun 2010 21:22:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1735
HADOOP-8984,Bug,Critical,,S3 File Permissions,"Till lately I've been using 0.20.2 and everything was ok. Now I'm using the latest trunc 0.22.0-SNAPSHOT and getting the following thrown:  Exception in thread ""main""  187)  (The ""it is owned by ... and permissions "" is not a mistake; seems like the empty string is printed there)",Resolved,Incomplete,,Unassigned,Danny Leshem,Wed; 28 Apr 2010 07:10:39 +0000,Wed; 30 Jul 2014 18:31:00 +0000,Wed; 30 Jul 2014 18:31:00 +0000,,2.0.2-alpha,,,MAPREDUCE-181;HADOOP-9042,https://issues.apache.org/jira/browse/HADOOP-8984
MAPREDUCE-1737,Improvement,Major,contrib/gridmix,Refactoring of TestGridmixSubmission .,nan,Resolved,Duplicate,MAPREDUCE-2120,Unassigned,rahul k singh,Wed; 28 Apr 2010 07:18:47 +0000,Wed; 19 Jan 2011 08:55:46 +0000,Wed; 19 Jan 2011 08:55:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1737
MAPREDUCE-1738,Improvement,Major,,MapReduce portion of HADOOP-6728 (ovehaul metrics framework),nan,Closed,Fixed,,Luke Lu,Luke Lu,Wed; 28 Apr 2010 17:59:07 +0000,Tue; 15 Nov 2011 00:50:00 +0000,Wed; 17 Aug 2011 21:54:57 +0000,,0.20.2,,HADOOP-6728,,https://issues.apache.org/jira/browse/MAPREDUCE-1738
MAPREDUCE-1739,New Feature,Major,,Collecting CPU and memory usage for MapReduce jobs,MAPREDUCE-220 collects CPU and memory usage for each task. We can aggregate them to get the information per job. Such information can be used for scheduling; profiling or charging the users based on the resource they consumed.  Here are some information that should be useful: 1. Total CPU cycles (# of giga-cycles) 2. Total Memory occupied time (GB-sec) 3. Maximum peak memory on one task (GB) 4. Maximum peak CPU on one task (GHz)  Thoughts?,Open,Unresolved,,Scott Chen,Scott Chen,Wed; 28 Apr 2010 20:43:06 +0000,Thu; 2 May 2013 02:29:30 +0000,,,,,,MAPREDUCE-1808,https://issues.apache.org/jira/browse/MAPREDUCE-1739
MAPREDUCE-1740,Bug,Major,jobtracker,NPE in getMatchingLevelForNodes when node locations are variable depth,"In getMatchingLevelForNodes; we assume that both nodes have the same ""depth"" (ie number of path components). If the user provides a topology script that assigns one node a path like  blah; this function will throw an NPE.  I'm not sure if there are other places where we assume that all node locations have a constant number of paths. If so we should check the output of the topology script aggressively to be sure this is the case. Otherwise I think we simply need to add &amp; n2 != null to the while loop",Closed,Fixed,,Ahmed Radwan,Todd Lipcon,Thu; 29 Apr 2010 00:24:55 +0000,Tue; 10 Mar 2015 04:32:43 +0000,Tue; 20 Mar 2012 18:37:52 +0000,,0.20.3,,,HADOOP-7103,https://issues.apache.org/jira/browse/MAPREDUCE-1740
MAPREDUCE-1741,Test,Major,test,Automate the test scenario of  job related files are moved from history directory to done directory,Job related files are moved from history directory to done directory; when  1) Job succeeds 2) Job is killed 3) When 100 files are put in the done directory 4) When multiple jobs are completed at the same time; some successful; some failed.  Also; two files; conf.xml and job files should be present in the done directory.,Resolved,Fixed,,Iyappan Srinivasan,Iyappan Srinivasan,Thu; 29 Apr 2010 07:34:27 +0000,Wed; 30 Jul 2014 18:36:15 +0000,Wed; 30 Jul 2014 18:36:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1741
MAPREDUCE-1742,Bug,Blocker,job submission,Job.setNumReduceTasks doesn't work,Calling Job.setNumReduceTasks(0) doesn't seem to work with the latest trunc; and the job still goes through a reduction phase. Also; Job.setNumReduceTasks(1) doesn't seem to work either; and several reducers are spawned.  It seems that something about Job.setNumReduceTasks got broken recently.,Resolved,Invalid,,Unassigned,Danny Leshem,Thu; 29 Apr 2010 16:15:27 +0000,Tue; 25 May 2010 09:23:06 +0000,Tue; 25 May 2010 09:23:06 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1742
MAPREDUCE-1743,Bug,Major,,"conf.get(""map.input.file"") returns null when using MultipleInputs in Hadoop 0.20","There is a problem in getting the input file name in the mapper when uisng MultipleInputs in Hadoop 0.20. I need to use MultipleInputs to support different formats for my inputs to the my MapReduce job. And inside each mapper; I also need to know the exact input file that the mapper is processing. However; conf.get(""map.input.file"") returns null. Can anybody help me solve this problem? Thanks in advance.  public class Test extends Configured implements Tool{  	static class InnerMapper extends MapReduceBase implements MapperWritable; Writable; NullWritable; Text 	{ 		................ 		................  		public void configure(JobConf conf) 		{	 			String inputName=conf.get(""map.input.file"")); 			....................................... 		}  	}  	public int run(String[] arg0) throws Exception  { 		JonConf job; 		job = new JobConf(Test.class); 		........................................... 		 		MultipleInputs.addInputPath(conf; new Path(""A""); TextInputFormat.class); 		MultipleInputs.addInputPath(conf; new Path(""B""); SequenceFileFormat.class); 		........................................... 	} }",Open,Unresolved,,Liyin Liang,Yuanyuan Tian,Thu; 29 Apr 2010 17:34:20 +0000,Thu; 26 Jun 2014 17:03:28 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1743
MAPREDUCE-1744,Bug,Major,,DistributedCache creates its own FileSytem instance when adding a file/archive to the path,According to the contract of UserGroupInformation.doAs() the only required operations within the doAs() block are the creation of a JobClient or getting a FileSystem .  The DistributedCache.add(File Archive)ToClasspath() methods create a FileSystem instance outside of the doAs() block; this FileSystem instance is not in the scope of the proxy user but of the superuser and permissions may make the method fail.  One option is to overload the methods above to receive a filesystem.  Another option is to do obtain the FileSystem within a doAs() block; for this it would be required to have the proxy user set in the passed configuration.  The second option seems nicer; but I don't know if the proxy user is as a property in the jobconf.,Closed,Fixed,MAPREDUCE-1862,Dick King,Dick King,Thu; 29 Apr 2010 22:36:57 +0000,Mon; 5 Mar 2012 02:49:17 +0000,Wed; 4 Jan 2012 18:15:38 +0000,,,,,MAPREDUCE-950,https://issues.apache.org/jira/browse/MAPREDUCE-1744
MAPREDUCE-1745,Bug,Major,,FileInputFormat.setInputPaths() has sideffects on the passed conf besides setting the input.dir path,it sets other props; like mapred.working.dir ; it sets this using the current user (which may be the superuser); then the job submission for a proxy user fails because the mapred.working.dir is not the right one for the proxy user.  This is observed when using relative directories; they are resolved to the homeDir of the superuser instead of the proxy user.  I did not check; but I suspect the FileOutputForamt.setOutputPath() may have similar side effects  There is a workaround; setting up the mapred.input.dir and mapred.output.dir directly by hand in the conf instead using the methods above,Open,Unresolved,,Unassigned,Dick King,Thu; 29 Apr 2010 22:44:04 +0000,Tue; 26 Jul 2011 17:57:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1745
MAPREDUCE-1746,Improvement,Major,distributed-cache,DistributedCache add(File|Archive)ToClassPath should only use FileSystem if path is not fully qualified,Currently setting a file archive in the DistributedCache classpath creates a FileSystem instance to fully qualify the path; even if the path given is already fully qualified.  This forces a connection to the cluster.  The methods should check if the path is already fully qualified and if so it should not create a FileSystem instance and try to qualify the path.  This would allow creating a jobconf in disconnected mode until submission time.,Open,Unresolved,,Unassigned,Alejandro Abdelnur,Fri; 30 Apr 2010 01:27:14 +0000,Fri; 30 Apr 2010 03:45:14 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1746
MAPREDUCE-1747,Bug,Blocker,documentation,Remove documentation for the 'unstable' job-acls feature,As discussed here and here at MAPREDUCE-1604; the job-acls feature is currently unstable. Without MAPREDUCE-1664; job-acls are practically useless because of their problematic interactions with queue-acls. Removing them for 0.21 will both relieve ourselves of these problems as well as the burden to support the backwards compatibility of the configuration options as well as the going-to-be-changed semantics of the feature. This jira is about removing the documentation from 0.21 so that the completed feature can be added in 0.22 with ease.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 30 Apr 2010 06:55:57 +0000,Tue; 24 Aug 2010 21:21:35 +0000,Thu; 6 May 2010 04:41:13 +0000,,0.21.0,,,MAPREDUCE-1748,https://issues.apache.org/jira/browse/MAPREDUCE-1747
MAPREDUCE-1748,Bug,Major,documentation,Put back the documentation for the job-acls feature,This is related to MAPREDUCE-1747 which removed the documentation of job-acls for 0.21 release. Once the branch is cut of 21; we should put back the documentation into the trunk 0.22.,Resolved,Not A Problem,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 30 Apr 2010 06:58:54 +0000,Fri; 30 Apr 2010 09:17:10 +0000,Fri; 30 Apr 2010 09:17:10 +0000,,0.22.0,,,MAPREDUCE-1747,https://issues.apache.org/jira/browse/MAPREDUCE-1748
MAPREDUCE-1749,Improvement,Major,,Pull configuration strings out of JobContext,The configuration strings should not have been included in JobContext; because they distract from the intended use of the interface.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Fri; 30 Apr 2010 18:12:16 +0000,Tue; 24 Aug 2010 21:21:35 +0000,Fri; 30 Apr 2010 22:27:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1749
MAPREDUCE-1750,Wish,Minor,,Make #rows avail. to reducers as environment variable,Given that there is a sort phase between the copy phase and the reduce phase; it seems like there is a chance for counting during sort.  It would be nice if my reducers could have access to an environment variable; say; mapred.reduce.rows; that contained the number of rows present for this reducer (as counted during the sort step).,Open,Unresolved,,Unassigned,Adam Kramer,Mon; 3 May 2010 03:19:34 +0000,Mon; 3 May 2010 06:45:38 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1750
MAPREDUCE-1751,Improvement,Blocker,build,Change MapReduce to depend on Hadoop 'common' artifacts instead of 'core',This is the MapReduce part of HADOOP-6404.,Closed,Fixed,,Tom White,Tom White,Mon; 3 May 2010 22:36:44 +0000,Thu; 2 May 2013 02:29:31 +0000,Fri; 28 May 2010 03:48:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1751
MAPREDUCE-1752,Improvement,Major,harchive,Implement getFileBlockLocations in HarFilesystem,To efficiently run map reduce on the data that has been HAR'ed it will be great to actually implement getFileBlockLocations for a given filename. This way the JobTracker will have information about data locality and will schedule tasks appropriately. I believe the overhead introduced by doing lookups in the index files can be smaller than that of copying data over the wire. Will upload the patch shortly; but would love to get some feedback on this. And any ideas on how to test it are very welcome.,Closed,Fixed,,Dmytro Molkov,Dmytro Molkov,Wed; 5 May 2010 02:00:38 +0000,Thu; 2 May 2013 02:29:33 +0000,Tue; 30 Nov 2010 05:54:29 +0000,,,,,MAPREDUCE-1712,https://issues.apache.org/jira/browse/MAPREDUCE-1752
HADOOP-6777,Improvement,Major,test,Implement a functionality for suspend and resume a process.,Adding  two methods in DaemonProtocolAspect.aj for suspend and resume the process.  public int DaemonProtocol.resumeProcess(String pid) throws IOException; public int DaemonProtocol.suspendProcess(String pid) throws IOException;,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Wed; 5 May 2010 04:18:37 +0000,Thu; 2 May 2013 02:29:32 +0000,Tue; 25 May 2010 23:05:54 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/HADOOP-6777
MAPREDUCE-1754,Bug,Major,jobtracker,Replace mapred.persmissions.supergroup with an acl : mapreduce.cluster.administrators,mapred.permissions.supergroup should be replaced with an acl so that it does not restrict the admins to a single group. See more details on MAPREDUCE-1542.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Wed; 5 May 2010 05:42:33 +0000,Mon; 12 Dec 2011 06:19:28 +0000,Fri; 28 Jan 2011 21:35:42 +0000,,0.22.0,,HADOOP-6748;HADOOP-6862,MAPREDUCE-1542,https://issues.apache.org/jira/browse/MAPREDUCE-1754
MAPREDUCE-1755,Bug,Major,,Zombie tasks kept alive by logging system,I'm currently looking at a task that; as far as the task tracker is concerned; is dead.  Like long long long ago dead.  It was a failed task that ran out of heap.  Rather than just kill it; I thought I would see what it was doing; since it was clearly using system resources.  It would appear the system is trying to log but failing.  I'm guessing we're missing an error condition and not doing the appropriate thing. See the comments for more.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 5 May 2010 17:01:58 +0000,Wed; 2 Nov 2011 17:41:33 +0000,Wed; 2 Nov 2011 17:41:33 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1755
MAPREDUCE-1756,Bug,Major,contrib/fair-share,FairScheduler may assign tasks over the TaskTracker limit,FairScheduler may assign tasks over the TaskTracker limit. The over assigned task will wait on the TaskTracker in the state of UNASSIGNED causing a higher latency.,Resolved,Invalid,,Scott Chen,Scott Chen,Thu; 6 May 2010 02:05:16 +0000,Fri; 7 May 2010 01:46:05 +0000,Fri; 7 May 2010 01:46:05 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1756
MAPREDUCE-1757,Bug,Major,test,TestUserLogCleanup failed in one of the Hudson builds,Found this from the Hudson run for MAPREDUCE-1747.  Error Message,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 6 May 2010 05:22:49 +0000,Thu; 6 May 2010 05:25:13 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1757
MAPREDUCE-1758,New Feature,Minor,,Building blocks for the  herriot test cases ,There is so much commonality in the test cases that we are writing; so it is pertinent to create reusable code. The common methods will be added to herriot framework.,Open,Unresolved,,Balaji Rajagopalan,Balaji Rajagopalan,Thu; 6 May 2010 11:15:21 +0000,Thu; 2 May 2013 02:29:31 +0000,,,,,MAPREDUCE-1676,,https://issues.apache.org/jira/browse/MAPREDUCE-1758
MAPREDUCE-1759,Bug,Major,security,Exception message for unauthorized user doing killJob; killTask; setJobPriority needs to be improved,The Exception message contains ADMINISTER_JOBS or MODIFY_JOB as the operation name when an unauthorized user tries to do killTask; killJob or setJobPriority operations. This needs to be changed so that user gets the correct operation instead of ADMINISTER_JOBS or MODIFY_JOB.,Resolved,Duplicate,MAPREDUCE-1664,Ravi Gummadi,Ravi Gummadi,Thu; 6 May 2010 11:51:20 +0000,Thu; 23 Sep 2010 22:29:54 +0000,Fri; 17 Sep 2010 09:26:23 +0000,,0.22.0,,MAPREDUCE-1664,,https://issues.apache.org/jira/browse/MAPREDUCE-1759
MAPREDUCE-1760,Improvement,Major,test,Herriot tests for MapReduce should support submission into a specific queue,Hadoop might be configured in a way to allow job submission only into a special queues.   Herriot tests have to be able to read a queue name configuration parameter from system-test.xml file and use it for job submission.,Open,Unresolved,,Unassigned,Konstantin Boudnik,Thu; 6 May 2010 17:50:53 +0000,Mon; 27 Sep 2010 04:14:23 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1760
MAPREDUCE-1761,Improvement,Major,,FairScheduler should allow separate configuration of node and rack locality wait time,It would be nice that we can separately assign rack locality wait time. In our use case; we would set node locality wait to zero and wait only rack locality.  I propose that we add two parameters mapred.fairscheduler.locality.delay.nodetorack mapred.fairscheduler.locality.delay.racktoany This allows specifying the wait time on each stage.  And we can use mapred.fairscheduler.locality.delay as the default value of the above fields so that this is backward compatible.  Thoughts?,Closed,Fixed,,Scott Chen,Scott Chen,Thu; 6 May 2010 19:13:00 +0000,Mon; 12 Dec 2011 06:20:06 +0000,Wed; 12 May 2010 05:11:11 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1761
MAPREDUCE-1762,Improvement,Major,,Add a setValue() method in Counter,Counters are very useful because of the logging and transmitting are already there. It is very convenient to transmit and store numbers. But currently Counter only has an increment() method. It will be nice if there can be a setValue() method in this class that will allow us to transmit wider variety of information through it.  What do you think?,Closed,Fixed,,Scott Chen,Scott Chen,Thu; 6 May 2010 21:33:10 +0000,Mon; 12 Dec 2011 06:19:14 +0000,Sun; 6 Jun 2010 05:41:28 +0000,,0.22.0,,MAPREDUCE-220,MAPREDUCE-1947,https://issues.apache.org/jira/browse/MAPREDUCE-1762
MAPREDUCE-1763,Improvement,Critical,jobtracker,JobHistory should enable history collection after a timeout or some other event,"If you search for disableHistory in JobHistory.  one can discover that it is enabled only at the initialization time.  There are two instances where job history can be disabled:   	if it fails to initialize the the output directories 	If it fails to create a single job history file    There are a few problems with that.  One is that there is no way to revert the flag even if the original problem goes away.  Second; these cases should probably be handled separately.  The result of which is that once the job history file creation fails; the job history mechanism becomes disabled and there is no way to switch it back.  One simple solution is to have a timeout after which we can try to enable the job history collection.  Another is to have a more granular job history control per job.  Alex K",Resolved,Duplicate,MAPREDUCE-1699,Unassigned,Alex Kozlov,Thu; 6 May 2010 23:23:02 +0000,Fri; 7 May 2010 03:57:50 +0000,Fri; 7 May 2010 03:57:50 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1763
MAPREDUCE-1764,Bug,Major,,FairScheduler locality delay may put heavy pressure on Jobtracker,FairScheduler locality delay feature holds the scheduling of jobs until it gets good locality. This greatly improves the locality of the tasks. Reduce the cost of traffic.  We have observed the following problem on FairScheduler locality delay: We have some machines have older data and some newly added machines do not have important data. When these machines send heartbeat; JT scans tasks to find jobs has the right locality. Often time; these machines will scan all of the tasks of all the jobs and do not get any tasks. Scanning all the tasks on the JT is very costly. This makes JT very slow. And these machines often time do not get scheduled. This hurts the cluster utilization.  Any ideas?,Open,Unresolved,,Dmytro Molkov,Scott Chen,Fri; 7 May 2010 00:06:08 +0000,Thu; 13 Jan 2011 02:27:56 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1764
MAPREDUCE-1765,Bug,Minor,contrib/streaming;documentation,Streaming doc - change StreamXmlRecord to StreamXmlRecordReader ,"Streaming doc - fix typo.  CHANGE: hadoop jar hadoop-streaming.jar -inputreader ""StreamXmlRecord;begin=BEGIN_STRING;end=END_STRING"" ..... (rest of the command)  TO THIS: hadoop jar hadoop-streaming.jar -inputreader ""StreamXmlRecordReader;begin=BEGIN_STRING;end=END_STRING"" ..... (rest of the command)  Note: No new test code; changes to documentation only.  See: Bugzilla Ticket 2520942 - XML Streaming",Closed,Fixed,,Corinne Chandel,Corinne Chandel,Thu; 12 Mar 2009 18:42:02 +0000,Tue; 24 Aug 2010 21:21:36 +0000,Wed; 16 Jun 2010 05:43:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1765
MAPREDUCE-1766,Bug,Major,contrib/streaming,Hadoop Streaming should not use TextInputFormat class as the default input format class.,The TextInputFormat class does not work with IdentityMapper class.,Resolved,Fixed,MAPREDUCE-612,Unassigned,Runping Qi,Mon; 16 Jul 2007 18:42:59 +0000,Thu; 17 Jul 2014 17:32:53 +0000,Thu; 17 Jul 2014 17:32:53 +0000,,,,,MAPREDUCE-570,https://issues.apache.org/jira/browse/MAPREDUCE-1766
MAPREDUCE-1767,Improvement,Major,contrib/streaming,Steaming infrastructures should provide statisics about job,This should include  the commands (mapper and reducer commands) executed  time information (e.g. min; max; and avg start time; end time; elapsed time for tasks; total elapsed time )  sizes  bytes and records; min; max; avg per task and total; input and output  information about input and output data sets (all output data sets; if there are several)  all user counters (when they are implemented for streaming)  the information should be stored in a file  e.g. in the working directory from where the job was launched; with a name derived from the job name,Resolved,Fixed,,Unassigned,arkady borkovsky,Wed; 21 Nov 2007 00:58:52 +0000,Tue; 22 Jul 2014 22:44:21 +0000,Thu; 17 Jul 2014 18:35:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1767
MAPREDUCE-1768,Improvement,Major,contrib/streaming,Streaming command should be able to produced multiple outputs stored as separate DFS data sets,"Some streaming commands in map or reduce phase; as a ""side effect""; produce several output files. The names of output files may be hard coded; or specified on the command line.  Streaming infrastructure should allow to get these files copied into DFS.  For each distinct ""output file name""; a separate DFS dataset (DFS directory) should be created; and a file of an individual task should be stored there as a part file.   The names of directories may be derived from the main ""output name"" (default)  Related to https: HADOOP-2236:  in case of reduce; a single name output file may be seen as a special case if this.",Open,Unresolved,,Unassigned,arkady borkovsky,Tue; 20 Nov 2007 22:19:07 +0000,Fri; 7 May 2010 05:15:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1768
MAPREDUCE-1769,Improvement,Major,contrib/streaming,"Streaming command should be able to take its output to a ""file""; rather then to stdout",In some cases; especially when a streaming command is a 3rd party or legacy application; it is impossible of inconvenient to make it write its output to stdout The command may require that the ouput file name is specified as a command line option; or the output file name is hard coded.  Related to https: HADOOP-2235,Resolved,Won't Fix,,Unassigned,arkady borkovsky,Tue; 20 Nov 2007 22:11:30 +0000,Thu; 17 Jul 2014 18:32:49 +0000,Thu; 17 Jul 2014 18:32:48 +0000,,,,,MAPREDUCE-600,https://issues.apache.org/jira/browse/MAPREDUCE-1769
MAPREDUCE-1770,Bug,Major,,have option to limit stderr output from user scripts in hadoop streaming,People often echo to stderr to debug their programs.  We have had cases where someone inadvertently dumped large amounts of data to stderr. this created large userlog directories and caused quite a few mapred slaves to become dysfunctional (logs partition was full).  Hence looking for a defensive measure against such errant scripts. We are currently putting in a limit on the number of bytes from the script's stderr that are forwarded to System.err.,Resolved,Fixed,,Unassigned,Joydeep Sen Sarma,Thu; 21 Aug 2008 00:04:56 +0000,Fri; 18 Jul 2014 22:15:44 +0000,Fri; 18 Jul 2014 22:15:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1770
HADOOP-6757,Bug,Major,scripts,NullPointerException for hadoop clients launched from streaming tasks,TaskRunner sets HADOOP_ROOT_LOGGER to info;TLA while launching the child tasks. TLA implicitly assumes that that task-id information will be made available via the 'hadoop.tasklog.taskid' parameter. 'hadoop.tasklog.taskid' is passed to the child task by the TaskRunner via HADOOP_CLIENT_OPTS. When the streaming task launches a hadoop client (say hadoop job -list); the HADOOP_ROOT_LOGGER of the hadoop client is set to 'info;TLA' but hadoop.tasklog.taskid is not set resulting into NPE.,Resolved,Fixed,,Amar Kamat,Amar Kamat,Fri; 7 May 2010 05:19:51 +0000,Thu; 29 Mar 2012 16:37:38 +0000,Thu; 29 Mar 2012 16:37:38 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-6757
MAPREDUCE-1772,Bug,Minor,contrib/streaming;documentation,Hadoop streaming doc should not use IdentityMapper as an example,From the URL http: wc  This will produce the following exception:   io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text; recieved org.apache.hadoop.io.LongWritable,Resolved,Fixed,,Amareshwari Sriramadasu,Marco Nicosia,Fri; 17 Oct 2008 23:08:23 +0000,Fri; 29 Oct 2010 02:03:17 +0000,Mon; 19 Jul 2010 10:31:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1772
MAPREDUCE-1773,Bug,Major,contrib/streaming,streaming doesn't support jobclient.output.filter,the streaming Jobclient implementation i.e contrib r; streaming; pipes so that we don't miss some core functionality.  GenericJobClient implements Tools and then StreamJob extends GenericJobClient; JobClient extends GenericJobClient  Alok,Closed,Fixed,,Amareshwari Sriramadasu,Alok Singh,Sat; 11 Jul 2009 00:17:12 +0000,Mon; 12 Dec 2011 06:20:03 +0000,Tue; 1 Jun 2010 11:40:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1773
MAPREDUCE-1774,New Feature,Major,test,Large-scale Automated Framework,This is MapReduce part of HADOOP-6332,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Fri; 7 May 2010 05:32:50 +0000,Thu; 2 May 2013 02:29:33 +0000,Sat; 26 Jun 2010 20:27:00 +0000,,0.21.0,,HADOOP-6786;MAPREDUCE-1646;MAPREDUCE-1713;HADOOP-6771;HADOOP-6875,HADOOP-6332,https://issues.apache.org/jira/browse/MAPREDUCE-1774
MAPREDUCE-1775,Improvement,Minor,contrib/streaming,Streaming should use hadoop.tmp.dir instead of stream.tmpdir,Hadoop streaming currently uses stream.tmpdir (on the job-client side) to create jars to be submitted etc. This only adds complexity to site-specific configuration files. Instead; it should use hadoop.tmp.dir configuration variable.,Open,Unresolved,,Unassigned,Milind Bhandarkar,Tue; 26 May 2009 17:47:43 +0000,Tue; 22 Jul 2014 20:12:54 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-1775
MAPREDUCE-1776,New Feature,Major,tasktracker,Hadoop should provide a simplified way of fetching user-logs,Hi;     Currently ; in both streaming and normal mode hadoop mapred program; user can't download the  logs programatically.  jobclient.output.filter=ALL; allows user to print output in the stdout stderr   We need to have the ability to fetch the user logs from the framework.  in 0.18; under the hod ; we used to store the logs in the hdfs. For 0.20; as long as the jobhistory resides user can view the logs but then it's gone.  So in short ; I am proposing that hadoop  1) provide the options to the JobClient (i.e jobconf var jobclient.output.logs.location); so that it will download the output in the hdfs location instead of printing to stdout.  Thanks Alok     Alok,Resolved,Incomplete,,Unassigned,Alok Singh,Sat; 20 Mar 2010 04:08:19 +0000,Wed; 30 Jul 2014 16:41:53 +0000,Wed; 30 Jul 2014 16:41:53 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1776
MAPREDUCE-1777,Bug,Major,contrib/streaming,In streaming; jobs that used to work; crash in the map phase -- even if the mapper is /bin/cat,"The exception is either ""out of memory"" of or ""broken pipe""  see both stack dumps bellow.  st Hadoop input: |null| last tool output: |[B@20fa83| Date: Sat Dec 15 21:02:18 UTC 2007    1760)",Resolved,Not A Problem,,Unassigned,arkady borkovsky,Sat; 15 Dec 2007 23:57:10 +0000,Thu; 19 Aug 2010 20:41:54 +0000,Thu; 19 Aug 2010 20:41:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1777
MAPREDUCE-1778,Improvement,Major,jobtracker,CompletedJobStatusStore initialization should fail if {mapred.job.tracker.persist.jobstatus.dir} is unwritable,If  {mapred.job.tracker.persist.jobstatus.dir} points to an unwritable location or mkdir of {mapred.job.tracker.persist.jobstatus.dir}  fails; then CompletedJobStatusStore silently ignores the failure and disables CompletedJobStatusStore. Ideally the JobTracker should bail out early indicating a misconfiguration.,Closed,Fixed,,Krishna Ramachandran,Amar Kamat,Mon; 10 May 2010 02:38:19 +0000,Mon; 12 Dec 2011 06:18:34 +0000,Wed; 23 Jun 2010 17:53:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1778
MAPREDUCE-1779,Bug,Blocker,client;jobtracker,Should we provide a way to know JobTracker's memory info from client?,In HADOOP-4435; in branch 0.20; getClusterStatus() method returns JobTracker's used memory and total memory. But these details are missed in new api (through MAPREDUCE-777). If these details are needed only for web UI; I don't think they are needed for client. So; should we provide a way to know JobTracker's memory info from client? If yes; an api should be added in org.apache.hadoop.mapreduce.Cluster for the same.,Resolved,Won't Fix,,Unassigned,Amareshwari Sriramadasu,Mon; 10 May 2010 05:09:14 +0000,Mon; 17 May 2010 20:40:39 +0000,Mon; 17 May 2010 20:40:39 +0000,,0.21.0,,MAPREDUCE-1683,,https://issues.apache.org/jira/browse/MAPREDUCE-1779
MAPREDUCE-1780,Bug,Major,jobtracker,AccessControlList.toString() is used for serialization of ACL in JobStatus.java,HADOOP-6715 is created to fix AccessControlList.toString() for the case of WILDCARD. JobStatus.write() and readFields() assume that toString() returns the serialized String of AccessControlList object; which is not true. Once HADOOP-6715 gets fixed in COMMON; JobStatus.write() and JobStatus.readFields() should be fixed depending on the fix of HADOOP-6715.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 10 May 2010 09:55:47 +0000,Mon; 12 Dec 2011 06:19:54 +0000,Thu; 12 Aug 2010 08:26:32 +0000,,,,HADOOP-6715,,https://issues.apache.org/jira/browse/MAPREDUCE-1780
MAPREDUCE-1781,Bug,Major,contrib/streaming,"option ""-D mapred.tasktracker.map.tasks.maximum=1"" does not work when no of mappers is bigger than no of nodes - always spawns 2 mapers/node","Hello  I am a new user of Hadoop and I have some trouble using Hadoop Streaming and the ""-D mapred.tasktracker.map.tasks.maximum"" option.   I'm experimenting with an unmanaged application (C++) which I want to run over several nodes in 2 scenarios 1) the number of maps (input splits) is equal to the number of nodes 2) the number of maps is a multiple of the number of nodes (5; 10; 20; ...  Initially; when running the tests in scenario 1 I would sometimes get 2 process time --format=""-duration:   -inputformat ""me.MyInputFormat""  Why is this happening and how can I make it work properly (i.e. be able to limit exactly how many mappers I can have at 1 time per node)?  Thank you in advance",Resolved,Invalid,,Unassigned,Tudor Vlad,Mon; 10 May 2010 19:17:32 +0000,Wed; 9 Jun 2010 05:11:26 +0000,Wed; 9 Jun 2010 05:11:26 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1781
MAPREDUCE-1782,Bug,Major,harchive,GlobPath support for har,When a fully qualified path for a har file is used; the FileSystem.globStatus() returns null. Please see the attached test case.,Open,Unresolved,,Mahadev konar,Santhosh Srinivasan,Tue; 11 May 2010 03:52:06 +0000,Tue; 11 May 2010 04:40:24 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1782
MAPREDUCE-1783,Improvement,Major,contrib/fair-share,Task Initialization should be delayed till when a job can be run,The FairScheduler task scheduler uses PoolManager to impose limits on the number of jobs that can be running at a given time. However; jobs that are submitted are initiaiized immediately by EagerTaskInitializationListener by calling JobInProgress.initTasks. This causes the job split file to be read into memory. The split information is not needed until the number of running jobs is less than the maximum specified. If the amount of split information is large; this leads to unnecessary memory pressure on the Job Tracker. To ease memory pressure; FairScheduler can use another implementation of JobInProgressListener that is aware of PoolManager limits and can delay task initialization until the number of running jobs is below the maximum.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Tue; 11 May 2010 22:50:37 +0000,Tue; 15 Nov 2011 00:48:54 +0000,Wed; 1 Dec 2010 00:41:45 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1783
MAPREDUCE-1784,Bug,Minor,,IFile should check for null compressor,IFile assumes that when it has a codec it can always get a compressor. This fails when mapred.compress.map.output is true but the native libraries are not installed; resulting in an NPE:     Let's make IFile handle this case by logging and using non-compressed streams.l,Resolved,Fixed,,Eli Collins,Eli Collins,Wed; 12 May 2010 02:00:14 +0000,Thu; 7 Apr 2011 15:40:40 +0000,Mon; 15 Nov 2010 17:17:42 +0000,,0.20.3;0.21.1;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1784
MAPREDUCE-1785,Improvement,Minor,contrib/streaming,Add streaming config option for not emitting the key,PipeMapper currently does not emit the key when using TextInputFormat. If you switch to input formats (eg LzoTextInputFormat) the key will be emitted. We should add an option so users can explicitly make streaming not emit the key so they can change input formats without breaking or having to modify their existing programs.,Resolved,Fixed,,Eli Collins,Eli Collins,Wed; 12 May 2010 19:27:41 +0000,Fri; 11 Jun 2010 10:07:51 +0000,Wed; 2 Jun 2010 07:46:16 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1785
MAPREDUCE-1786,Improvement,Major,task,Add method to support pre-partitioned data,There are some applications where the map wants to partition the data itself. This happens in Pipes; if the user has a C++ partitioner. It would make sense to support it in streaming too. There is also use case where the Java partitioner needs the context object to update counters; etc.  This jira is only about adding the method to the mapreduce Java API. The Pipes interface can be updated in a follow up Jira.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Thu; 13 May 2010 03:34:09 +0000,Thu; 13 May 2010 03:34:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1786
HADOOP-6763,Bug,Major,,Remove verbose logging from the Groups class,2010-02-25 08:30:52;269 INFO  security.Groups (Groups. getGroups(76)) - Retu rning cached groups for 'oom'  should both be demoted to debug level.,Closed,Fixed,,Boris Shkolnik,Owen O'Malley,Thu; 25 Feb 2010 16:37:29 +0000,Mon; 12 Dec 2011 06:19:15 +0000,Thu; 13 May 2010 20:46:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/HADOOP-6763
MAPREDUCE-1788,Bug,Major,client,o.a.h.mapreduce.Job shouldn't make a copy of the JobConf,Having o.a.h.mapreduce.Job make a copy of the passed in JobConf has several issues: any modifications done by various pieces such as InputSplit etc. are not reflected back and causes issues for frameworks built on top.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 13 May 2010 20:25:09 +0000,Tue; 15 Nov 2011 00:48:44 +0000,Sun; 18 Sep 2011 02:53:26 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1788
MAPREDUCE-1789,Bug,Blocker,build,MapReduce trunk fails to compile following HADOOP-6600,A few classes need updating following the change to KerberosInfo introduced in HADOOP-6600,Closed,Invalid,,Tom White,Tom White,Thu; 13 May 2010 23:25:07 +0000,Tue; 24 Aug 2010 21:21:37 +0000,Fri; 14 May 2010 02:26:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1789
MAPREDUCE-1790,Improvement,Major,build,Automatic resolution of Lzo codecs is needed.,The test cases are failing due to non-availablity of the jar  hadoop-gpl-compression-0.1.0-1005060043.jar; need changes to aop xml to fix this.,Resolved,Won't Fix,,Giridharan Kesavan,Balaji Rajagopalan,Fri; 14 May 2010 11:55:47 +0000,Wed; 30 Jul 2014 19:32:45 +0000,Wed; 30 Jul 2014 19:32:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1790
MAPREDUCE-1791,Sub-task,Major,test,Remote cluster control functionality needs JavaDocs improvement,This is MR part of HADOOP-6752.,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Sat; 15 May 2010 00:41:39 +0000,Fri; 29 Oct 2010 02:04:27 +0000,Sat; 26 Jun 2010 20:24:13 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1791
MAPREDUCE-1792,Bug,Major,jobtracker,add script that backups job statistics,When cluster is terminated; job statistics from previous execution is lost. A script should be created to backup job statistics so that analysis can be performed across cluster restart.  A utility to visualize job statistics is also desirable.,Resolved,Won't Fix,,Unassigned,Ted Yu,Sun; 16 May 2010 13:16:50 +0000,Wed; 30 Jul 2014 19:33:36 +0000,Wed; 30 Jul 2014 19:33:36 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1792
HADOOP-6788,Bug,Major,test,[Herriot] Exception exclusion functionality is not working correctly.,"Exception exclusion functionality is not working correctly because of that tests are failing by not matching the error count. I debugged the issue and found that the problem with shell command which is generating in the getNumberOfMatchesInLogFile function.  Currently building the shell command in the following way.   if(list != null){   for(int i =0; i  list.length; ++i)   {     filePattern.append("" | grep -v "" + list[i] );   } }     String[] cmd =         new String[] {             ""bash"";             ""-c"";             ""grep -c ""                 + pattern + "" "" + filePattern                 + "" | awk -F: ' {s+=$2} END {print s}'"" };      However; The above commnad won't work correctly because you are counting the exceptions in the file before excluding the known exceptions. In this case it gives the mismatch error counts everytime.The shell command should be in the following way to work correctly.  if (list != null) {   int index = 0;   for (String excludeExp : list) {     filePattern.append((++index  list.length)? ""| grep -v "" :              ""| grep -vc "" + list[i] );     } } String[] cmd =    new String[] {        ""bash"";        ""-c"";        ""grep ""            + pattern + "" "" + filePattern            + "" | awk -F: '{s+=$2}  END  {print s} '"" };",Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 17 May 2010 10:40:42 +0000,Thu; 2 May 2013 02:29:33 +0000,Fri; 4 Jun 2010 04:13:51 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/HADOOP-6788
MAPREDUCE-1794,Task,Major,test,Test the job status of lost task trackers before and after the timeout.,This test covers the following scenarios.  1. Verify the job status whether it is succeeded or not when  the task tracker is lost and alive before the timeout. 2. Verify the job status and killed attempts of a task whether it is succeeded or not and killed attempts are matched or not  when the task trackers are lost and it timeout for all the four attempts of a task.,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 17 May 2010 11:18:58 +0000,Wed; 30 Jul 2014 19:35:52 +0000,Wed; 30 Jul 2014 19:35:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1794
MAPREDUCE-1795,Improvement,Major,,add error option if file-based record-readers fail to consume all input (e.g.; concatenated gzip; bzip2),"When running MapReduce with concatenated gzip files as input; only the first part (""member"" in gzip spec parlance; http: feature; whenever that occurs.",Resolved,Won't Fix,,Greg Roelofs,Greg Roelofs,Tue; 18 May 2010 01:18:43 +0000,Thu; 10 Jun 2010 21:57:29 +0000,Thu; 10 Jun 2010 21:57:29 +0000,,,,,HADOOP-6335;PIG-42;HADOOP-6835,https://issues.apache.org/jira/browse/MAPREDUCE-1795
MAPREDUCE-1796,Bug,Major,jobtracker,job tracker history viewer shows all recent jobs as being run at job tracker (re)start time,This has been the behavior of the History viewer for long that it shows the timestamp when the JobTracker restarted rather than Job start time.,Resolved,Duplicate,MAPREDUCE-1541,Unassigned,Ted Yu,Tue; 18 May 2010 03:10:35 +0000,Tue; 18 May 2010 04:02:59 +0000,Tue; 18 May 2010 04:02:59 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1796
MAPREDUCE-1797,Improvement,Major,jobtracker,The JobTracker lock can be a reader/writer lock,The Jobtracker has a global lock and a per-job JobInProgress lock. The aim for the JobInprogress lock is to support the ability to lock a single job's metadata without  blocking out the entire JobTracker. However; many code paths acquire the JobTracker lock and then acquire the JobInProgress lock while keeping the JobTracker lock. This somewhat defeats the benefit of having a per-job lock.,Resolved,Won't Fix,,dhruba borthakur,dhruba borthakur,Tue; 18 May 2010 22:07:12 +0000,Wed; 30 Jul 2014 19:36:13 +0000,Wed; 30 Jul 2014 19:36:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1797
MAPREDUCE-1798,Improvement,Major,,normalize property names for JT kerberos principal names in configuration (from HADOOP 6633),nan,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Wed; 19 May 2010 00:00:47 +0000,Mon; 12 Dec 2011 06:20:02 +0000,Fri; 21 May 2010 16:21:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1798
MAPREDUCE-1799,Bug,Major,task;tasktracker,TaskTracker webui fails to show logs for tasks whose child JVM itself crashes before process launch,In many cases like invalid JVM arguments; JVM started with too much initialize heap or beyond OS ulimits; the child JVM itself crashes before the process can even be launched. In these situation; the tasktracker's webUI doesn't show the logs. This is because of a bug in the TaskLogServlet which displays logs only when syslog; stdout; stderr are all present. In the JVM crash case; syslog isn't created and so task-logs aren't displayed at all.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Wed; 19 May 2010 10:39:36 +0000,Thu; 2 May 2013 02:29:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1799
MAPREDUCE-1800,Bug,Major,,using map output fetch failures to blacklist nodes is problematic,If a mapper and a reducer cannot communicate; then either party could be at fault. The current hadoop protocol allows reducers to declare nodes running the mapper as being at fault. When sufficient number of reducers do so - then the map node can be blacklisted.   In cases where networking problems cause substantial degradation in communication across sets of nodes - then large number of nodes can become blacklisted as a result of this protocol. The blacklisting is often wrong (reducers on the smaller side of the network partition can collectively cause nodes on the larger network partitioned to be blacklisted) and counterproductive (rerunning maps puts further load on the (already) maxed out network links).  We should revisit how we can better identify nodes with genuine network problems (and what role; if any; map-output fetch failures have in this).,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Wed; 19 May 2010 18:08:50 +0000,Sat; 22 May 2010 14:57:27 +0000,,,,,,MAPREDUCE-562,https://issues.apache.org/jira/browse/MAPREDUCE-1800
MAPREDUCE-1801,Bug,Major,,do not throw exception if cannot get a delegation token; it may be from a unsecured cluster (part of HDFS-1044),nan,Open,Unresolved,,Boris Shkolnik,Boris Shkolnik,Wed; 19 May 2010 22:50:53 +0000,Mon; 28 Feb 2011 06:05:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1801
MAPREDUCE-1802,Bug,Major,,allow outputcommitters to skip setup/cleanup,Job setup and cleanup overheads in our (larger) clusters are very significant and add to latency for small jobs. It turns out that Hive does not require job setup and cleanup at all - since all management of output cleanup for example.,Resolved,Duplicate,MAPREDUCE-463,Joydeep Sen Sarma,Joydeep Sen Sarma,Thu; 20 May 2010 01:01:32 +0000,Thu; 20 May 2010 05:49:34 +0000,Thu; 20 May 2010 05:49:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1802
MAPREDUCE-1803,Bug,Major,build,0.21 nightly snapshot build has dependency on 0.22 snapshot,The POM generated in https:  has a reference to hadoop-core 0.22.0-SNAPSHOT,Resolved,Invalid,,Unassigned,Aaron Kimball,Thu; 20 May 2010 02:44:30 +0000,Mon; 31 May 2010 22:02:25 +0000,Mon; 31 May 2010 22:02:25 +0000,,,,,HDFS-1166,https://issues.apache.org/jira/browse/MAPREDUCE-1803
MAPREDUCE-1804,New Feature,Major,benchmarks;test,Stress-test tool for HDFS introduced in HDFS-708,This issue is to commit the SLive test developed in HDFS-708 to MR trunk.,Closed,Fixed,,Konstantin Shvachko,Konstantin Shvachko,Thu; 20 May 2010 19:05:53 +0000,Mon; 12 Dec 2011 06:18:41 +0000,Fri; 21 May 2010 01:11:08 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1804
MAPREDUCE-1805,Improvement,Major,,Document configurations parameters that are read by MapReduce framework and cannot be changed per job,From the documentation in mapred-default.xml; it is not apparent whether the configurations parameters (such as mapred.tasktracker.map.tasks.maximum) can be specified per-job; or whether these parameters are read by the framework at start-up and can never be changed. It would be helpful to annotate the default configurations file with this information.,Open,Unresolved,,Unassigned,Milind Bhandarkar,Thu; 20 May 2010 19:48:03 +0000,Thu; 20 May 2010 20:05:26 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1805
MAPREDUCE-1806,Bug,Major,harchive,CombineFileInputFormat does not work with paths not on default FS,In generating the splits in CombineFileInputFormat; the scheme and authority are stripped out. This creates problems when trying to access the files while generating the splits; as without the har: ; the file won't be accessed through the HarFileSystem.,Closed,Fixed,MAPREDUCE-2704,Gera Shegalov,Paul Yang,Thu; 20 May 2010 21:48:48 +0000,Wed; 17 Apr 2013 21:43:34 +0000,Tue; 30 Oct 2012 05:52:41 +0000,,0.22.0;0.23.1,,,HIVE-3025;MAPREDUCE-5161,https://issues.apache.org/jira/browse/MAPREDUCE-1806
MAPREDUCE-1807,Bug,Major,,TestQueueManager can take long enough to time out,Sometimes TestQueueManager takes such a long time that the JUnit engine times out and declares it a failure.  We should fix this; possibly by splitting the file's 19 test cases into two or more manageable test sets.,Resolved,Duplicate,MAPREDUCE-28,Unassigned,Dick King,Fri; 21 May 2010 02:44:59 +0000,Fri; 21 May 2010 16:46:23 +0000,Fri; 21 May 2010 08:05:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1807
MAPREDUCE-1808,New Feature,Major,tasktracker,Have a configurable metric reporting CPU/disk usage per user,Many organizations are looking at resource usage per department O per user and aggregate them using Ganglia.  Eventually; we can create an API for pluggable metrics (there is one for Jobtracker and Tasktracker).  Let me know your thoughts.  Alex K,Open,Unresolved,,Alex Kozlov,Alex Kozlov,Thu; 6 May 2010 23:12:19 +0000,Mon; 7 Mar 2011 08:02:51 +0000,,,,,,MAPREDUCE-1739,https://issues.apache.org/jira/browse/MAPREDUCE-1808
MAPREDUCE-1809,Task,Major,build,Ant build changes for Streaming system tests in contrib projects.,Implementing new target( test-system) in build-contrib.xml file for executing the system test that are in contrib projects. Also adding 'subant'  target in aop.xml that calls the build-contrib.xml file for system tests.,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Sun; 23 May 2010 17:51:03 +0000,Thu; 2 May 2013 02:29:32 +0000,Fri; 26 Nov 2010 10:00:21 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1809
MAPREDUCE-1810,Bug,Major,build,0.21 build is broken,   @KerberosInfo(MRJobConfig.JOB_JOBTRACKER_ID),Closed,Fixed,,Tom White,Sharad Agarwal,Mon; 24 May 2010 05:19:00 +0000,Thu; 2 May 2013 02:29:32 +0000,Thu; 27 May 2010 21:19:53 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1810
MAPREDUCE-1811,Bug,Minor,client,Job.monitorAndPrintJob() should print status of the job at completion,"Job.monitorAndPrintJob() just prints ""Job Complete"" at the end of the job. It should print the state whether the job SUCCEEDED KILLED.",Closed,Fixed,MAPREDUCE-616,Harsh J,Amareshwari Sriramadasu,Mon; 24 May 2010 10:18:52 +0000,Tue; 15 Nov 2011 00:48:11 +0000,Wed; 2 Mar 2011 05:39:16 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1811
MAPREDUCE-1812,Task,Major,test,New properties for suspend and resume process.,Adding new properties in system-test-mr.xml file for suspend and resume process.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Tue; 25 May 2010 07:00:37 +0000,Thu; 2 May 2013 02:29:32 +0000,Fri; 16 Jul 2010 20:07:11 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1812
MAPREDUCE-1813,Bug,Major,contrib/streaming,NPE in PipeMapred.MRErrorThread,Some reduce tasks fail with following NPE  449),Closed,Fixed,,Ravi Gummadi,Amareshwari Sriramadasu,Tue; 25 May 2010 08:07:22 +0000,Mon; 12 Dec 2011 06:19:00 +0000,Fri; 11 Jun 2010 11:41:24 +0000,,0.20.1,,,HADOOP-3089;HADOOP-4620,https://issues.apache.org/jira/browse/MAPREDUCE-1813
MAPREDUCE-1814,Improvement,Trivial,contrib/gridmix,[GridMix] Factor out GridMix constants into a separate file,It would be nice to have all the GridMix configuration parameters factored out in one place file.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 25 May 2010 08:38:55 +0000,Tue; 25 May 2010 08:38:55 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1814
MAPREDUCE-1815,Bug,Major,jobtracker,Directory in logs/history causes ArrayIndexOutOfBoundsException,Creating a directory in the jobtracker history directory causes an ArrayIndexOutOfBounds exception.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 25 May 2010 23:12:23 +0000,Wed; 2 Nov 2011 17:40:55 +0000,Wed; 2 Nov 2011 17:40:55 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1815
MAPREDUCE-1816,Improvement,Minor,contrib/raid,HAR files used for RAID parity need to have configurable partfile size,RAID parity files are merged into HAR archives periodically. This is required to reduce the number of files that the NameNode has to track. The number of files present in a HAR archive depends on the size of HAR part files - higher the size; lower the number of files. The size of HAR part files is configurable through the setting har.partfile.size; but that is a global setting. This task introduces a new setting specific to raid.har.partfile.size; that is used in-turn to set har.partfile.size,Resolved,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Wed; 26 May 2010 06:04:21 +0000,Fri; 29 Oct 2010 02:03:29 +0000,Thu; 30 Sep 2010 13:23:00 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1816
MAPREDUCE-1817,Bug,Major,tasktracker,JT and TT should not have to match build versions,TaskTracker#offerService checks for a match with the JT VersionInfo#getBuildVersion; and fails if they are the same version but happen to be built at a different time of day. It seems like the correct test is VersionInfo#getRevision.  fwiw the NN and DN do not have to match build versions.,Resolved,Not A Problem,,Unassigned,Eli Collins,Wed; 26 May 2010 17:22:18 +0000,Thu; 27 May 2010 15:55:04 +0000,Thu; 27 May 2010 15:55:04 +0000,,0.20.1;0.20.2;0.20.3;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1817
MAPREDUCE-1818,Improvement,Minor,contrib/raid,RaidNode should specify a pool name incase the cluster is using FairScheduler,contrib fairscheduler (FairScheduler) supports scheduling based on pools. The RaidNode should specify a pool name based on configuration to make use of pools.,Resolved,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Wed; 26 May 2010 19:22:37 +0000,Thu; 7 Apr 2011 15:40:40 +0000,Fri; 29 Oct 2010 01:36:07 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1818
MAPREDUCE-1819,Improvement,Major,contrib/raid,RaidNode should be smarter in submitting Raid jobs,The RaidNode currently computes parity files as follows: 1. Using RaidNode.selectFiles() to figure out what files to raid for a policy 2. Using #1 repeatedly for each configured policy to accumulate a list of files.  3. Submitting a mapreduce job with the list of files from #2 using DistRaid.doDistRaid()  This task addresses the fact that #2 and #3 happen sequentially. The proposal is to submit a separate mapreduce job for the list of files for each policy and use another thread to track the progress of the submitted jobs. This will help reduce the time taken for files to be raided.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Wed; 26 May 2010 21:11:24 +0000,Mon; 12 Dec 2011 06:19:24 +0000,Tue; 12 Oct 2010 18:24:22 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1819
MAPREDUCE-1820,Bug,Major,,InputSampler does not create a deep copy of the key object when creating a sample; which causes problems with some formats like SequenceFile<Text;Text>,I tried to use the InputSampler on a SequenceFileText;Text and found that it comes up with duplicate keys in the sample.  The problem was tracked down to the fact that the Text object returned from the reader is essentially a wrapper pointing to a byte array; which changes as the sequence file reader progresses.  There was also a bug in that the reader should be initialized before the use.  The am attaching a patch that fixes both of the issues.  --Alex K,Closed,Fixed,,Alex Kozlov,Alex Kozlov,Wed; 26 May 2010 22:30:31 +0000,Wed; 8 May 2013 21:13:26 +0000,Thu; 8 Jul 2010 00:11:22 +0000,,,,,MAPREDUCE-366;MAPREDUCE-5225,https://issues.apache.org/jira/browse/MAPREDUCE-1820
MAPREDUCE-1821,Bug,Major,task,IFile.Reader should check whether data crc has checked before it stop reading.,Currently IFile data has crc checked in IFileInputStream (doRead method);  Normally the IFile would end with 2 bytes of -1; which means EOF_MARKER for keylength and valuelength; and then with 4 bytes crc checksum; IFileInputStream  checksumIn would check crc before IFile.Reader get EOF_MARKER;  IFile.Reader would stop reading when positionToNextRecord() read keylength EOF_MARKER(-1);and valuelength  EOF_MARKER(-1);  But if something error happened(IFile corrupted); if the IFileReader read -1; -1 not at end of the IFile; the data may not checked!  Then Reader thought it had got all data and close reader......the task may fake success without any WARNing.,Open,Unresolved,,ZhuGuanyin,ZhuGuanyin,Thu; 27 May 2010 06:23:55 +0000,Thu; 3 Aug 2017 22:08:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1821
MAPREDUCE-1822,Bug,Major,,TestTaskTrackerLocalization fails in a fresh trunk checkout.,This is not the same as MAPREDUCE:879 .  In 879; testTaskControllerSetup throws an exception for a nonexistent file.  That problem has been fixed.  In a fresh trunk; the same unit test delivers an assertion failure.,Open,Unresolved,,Unassigned,Dick King,Thu; 27 May 2010 17:33:33 +0000,Fri; 28 May 2010 17:48:01 +0000,,,,,,MAPREDUCE-879,https://issues.apache.org/jira/browse/MAPREDUCE-1822
MAPREDUCE-1823,Improvement,Major,,Reduce the number of calls of HarFileSystem.getFileStatus in RaidNode,RaidNode makes lots of calls of HarFileSystem.getFileStatus. This method fetches information from DataNode so it is slow. It becomes the bottleneck of the RaidNode. It will be nice if we can make this more efficient.,Open,Unresolved,,Scott Chen,Scott Chen,Fri; 28 May 2010 18:48:10 +0000,Thu; 13 Jan 2011 02:29:05 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1823
MAPREDUCE-1824,Improvement,Major,,JobTracker should reuse file system handle for delegation token renewal,In trunk; the DelegationTokenRenewal obtains the file system handle by creating the uri out of service in the token; which is ip:port. The intention of this jira is to use host name of the namenode so that fils system handle in the cache on jobtracker could be re-used. This jira is created because such an optimization is there in 20 code and the patch attached is the direct port of the code in 20.,Resolved,Later,,Daryn Sharp,Jitendra Nath Pandey,Fri; 28 May 2010 22:28:26 +0000,Mon; 9 Mar 2015 23:17:09 +0000,Mon; 9 Mar 2015 23:17:09 +0000,,,,,HADOOP-7510,https://issues.apache.org/jira/browse/MAPREDUCE-1824
MAPREDUCE-1825,Bug,Major,jobtracker,jobqueue_details.jsp and FairSchedulerServelet should not call finishedMaps and finishedReduces when job is not initialized,JobInProgress.finishedMaps() and finishedReduces() are synchronized. They are called from jobqueue_details.jsp and FairSchedulerServelet which iterates through all jobs. If any job is in initialization; these pages don't come up until the initialization finishes.  See comment for more details,Closed,Fixed,,Scott Chen,Amareshwari Sriramadasu,Mon; 31 May 2010 05:51:16 +0000,Mon; 12 Dec 2011 06:19:00 +0000,Sat; 5 Feb 2011 00:46:00 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1825
MAPREDUCE-1826,Bug,Major,contrib/streaming,Passing a directory for -file option does not work as expected.,When I tried passing a directory through -file option; the contents of directory are added to the job jar; not the directory itself. After MAPREDUCE-967; because the contents of the passed directory are not added to the jar unpack pattern; the files dirs inside the passed directory are not unjarred. Thus they are not symlinked from cwd of the task.  Currently; there is no way for the user to access the files under the directory passed through -file option.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Mon; 31 May 2010 11:35:12 +0000,Tue; 1 Jun 2010 07:49:03 +0000,,,0.21.0,,,MAPREDUCE-1697,https://issues.apache.org/jira/browse/MAPREDUCE-1826
MAPREDUCE-1827,Task,Major,test,[Herriot] Task Killing/Failing tests for a streaming job.,1. Set the sleep time for the tasks is 3 seconds and kill the task of streaming job using SIGKILL. After that  verify whether task is killed after 3 seconds or not and also verify whether job is succeeded or not. 2. Set the maximum attempts for the maps and reducers are one. make the task to fail and verify whether task  is failed or not.Also verify whether the job is failed or not.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 31 May 2010 14:23:49 +0000,Thu; 2 May 2013 02:29:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1827
MAPREDUCE-1828,Bug,Major,tasktracker,Job doesn't fail graciously when an invalid mapred.child.env value is specified,When invalid input is given to -Dmapred.child.env=; ArrayIndexOutOfBoundsException is seen instead of giving a useful error message.  bin cat   212),Resolved,Won't Fix,,Ravi Gummadi,Ravi Gummadi,Tue; 1 Jun 2010 09:42:39 +0000,Wed; 30 Jul 2014 19:53:04 +0000,Wed; 30 Jul 2014 19:53:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1828
MAPREDUCE-1829,Improvement,Major,jobtracker,JobInProgress.findSpeculativeTask should use min() to find the candidate instead of sort(),findSpeculativeTask needs only one candidate to speculate so it does not need to sort the whole list. It may looks OK but someone can still submit big jobs with small slow task thresholds. In this case; this sorting becomes expensive.,Closed,Fixed,,Scott Chen,Scott Chen,Tue; 1 Jun 2010 18:04:22 +0000,Mon; 12 Dec 2011 06:19:58 +0000,Sat; 12 Jun 2010 09:56:15 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1829
MAPREDUCE-1830,Improvement,Major,build,Ivy2.0 has bugs: let's upgrate to 2.1.0,Similar to HDFS-1177 Ivy needs to be upgraded up to 2.1,Resolved,Duplicate,MAPREDUCE-1870,Konstantin Boudnik,Konstantin Boudnik,Tue; 1 Jun 2010 18:16:49 +0000,Wed; 21 Jul 2010 18:06:29 +0000,Wed; 21 Jul 2010 18:06:29 +0000,,0.21.0,,,HADOOP-6798,https://issues.apache.org/jira/browse/MAPREDUCE-1830
MAPREDUCE-1831,Improvement,Major,contrib/raid,BlockPlacement policy for RAID,Raid introduce the new dependency between blocks within a file. The blocks help decode each other. Therefore we should avoid put them on the same machine.  The proposed BlockPlacementPolicy does the following 1. When writing parity blocks; it avoid the parity blocks and source blocks sit together. 2. When reducing replication number; it deletes the blocks that sits with other dependent blocks. 3. It does not change the way we write normal files. It only has different behavior when processing raid files.,Closed,Fixed,,Scott Chen,Scott Chen,Tue; 1 Jun 2010 19:01:05 +0000,Tue; 15 Nov 2011 00:50:06 +0000,Fri; 10 Dec 2010 22:29:52 +0000,,0.23.0,,,MAPREDUCE-1861,https://issues.apache.org/jira/browse/MAPREDUCE-1831
MAPREDUCE-1832,Improvement,Major,benchmarks,Support for file sizes less than 1MB in DFSIO benchmark.,Currently DFSIO benchmark allows to specify files sizes in 1MB increments. It would be useful to be able to specify smaller sizes.,Closed,Fixed,HDFS-1182,Konstantin Shvachko,Konstantin Shvachko,Wed; 2 Jun 2010 00:53:21 +0000,Thu; 2 May 2013 02:29:56 +0000,Fri; 4 Jun 2010 02:09:33 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1832
MAPREDUCE-1833,Improvement,Major,contrib/gridmix,[gridmix3] limit the maximum task duration in sleep job.,In production job history logs; sometimes a task takes very long time to finish. Replaying such trace in sleep-job mode in Gridmix3 would unnecessarily prolong the benchmark execution time. It would be desirable to allow users to limit the maximum task duration.,Resolved,Duplicate,MAPREDUCE-1936,Hong Tang,Hong Tang,Wed; 2 Jun 2010 07:09:55 +0000,Fri; 16 Jul 2010 00:37:30 +0000,Tue; 13 Jul 2010 00:51:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1833
MAPREDUCE-1834,Bug,Major,contrib/mumak,TestSimulatorDeterministicReplay timesout on trunk,TestSimulatorDeterministicReplay timesout on trunk. See hudson patch build http: ,Closed,Fixed,,Hong Tang,Amareshwari Sriramadasu,Wed; 2 Jun 2010 07:57:33 +0000,Mon; 12 Dec 2011 06:20:01 +0000,Tue; 3 Aug 2010 18:24:48 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1834
MAPREDUCE-1835,Bug,Major,security,TestDelegationTokenRenewal token fails sometimes in branch 0.21,"org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal fails sometimes in branch 0.21.  The test fails with following error: Testcase: testDTRenewal took 15.606 sec 	FAILED renew wasn't called as many times as expected expected:5 but was:4 junit.framework.AssertionFailedError: renew wasn't called as many times as expected expected:5 but was:4 	at org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.testDTRenewal(TestDelegationTokenRenewal. 303)  In run of 5; the test failed twice.",Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Wed; 2 Jun 2010 09:41:23 +0000,Wed; 30 Jul 2014 19:54:31 +0000,Wed; 30 Jul 2014 19:54:31 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1835
MAPREDUCE-1836,Bug,Major,,Refresh for proxy superuser config (mr part for HDFS-1096),nan,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Wed; 2 Jun 2010 17:21:07 +0000,Mon; 12 Dec 2011 06:20:04 +0000,Fri; 4 Jun 2010 00:41:38 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1836
MAPREDUCE-1837,Improvement,Major,contrib/raid,Raid should store the metadata in HDFS,Currently if you change the stripe length in the raid policy. The existing raided files cannot be recovered. Also in the future if we want to upgrade to a better erasure code such as Reed-Solomon or LDPC and change the policy for that. The same problem will happen. We can avoid this problem if we store the information in a metadata file.,Resolved,Won't Fix,,Scott Chen,Scott Chen,Wed; 2 Jun 2010 20:08:05 +0000,Tue; 1 Aug 2017 17:12:58 +0000,Tue; 1 Aug 2017 17:12:57 +0000,,0.22.0,,,HDFS-503,https://issues.apache.org/jira/browse/MAPREDUCE-1837
MAPREDUCE-1838,Improvement,Minor,contrib/raid,DistRaid map tasks have large variance in running times,HDFS RAID uses map-reduce jobs to generate parity files for a set of source files. Each map task gets a subset of files to operate on. The current code assigns files by walking through the list of files given in the constructor of DistRaid  The problem is that the list of files given to the constructor has the order of (pretty much) the directory listing. When a large number of files is added; files in that order tend to have the same size. Thus a map task can end up with large files where as another can end up with small files; increasing the variance in run times.  We could do smarter assignment by using the file sizes.,Resolved,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Wed; 2 Jun 2010 21:36:21 +0000,Fri; 29 Oct 2010 02:04:43 +0000,Tue; 6 Jul 2010 06:27:05 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1838
MAPREDUCE-1839,Improvement,Minor,harchive,HadoopArchives should provide a way to configure replication,When creating HAR archives; the part files use the default replication of the filesystem. This should be made configurable through either the configuration file or command line.,Resolved,Not A Problem,,Unassigned,Ramkumar Vadali,Thu; 3 Jun 2010 01:21:39 +0000,Fri; 4 Jun 2010 18:48:42 +0000,Fri; 4 Jun 2010 18:48:42 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1839
MAPREDUCE-1840,Improvement,Major,contrib/gridmix,[Gridmix] Exploit/Add security features in GridMix,"Use security information while replaying jobs in Gridmix. This includes  	Support for multiple users 	Submitting jobs as different users 	Allowing usage of secure cluster (hdfs + mapreduce) 	Support for multiple queues    Other features include :   	Support for sleep job 	Support for load job    + testcases for verifying all of the above changes",Closed,Fixed,,Amar Kamat,Amar Kamat,Thu; 3 Jun 2010 05:50:29 +0000,Mon; 12 Dec 2011 06:19:29 +0000,Wed; 14 Jul 2010 09:23:26 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1840
MAPREDUCE-1841,Bug,Major,task,o.a.h.mapreduce.FileOutputCommitter doens't check for existence of ${mapred.output.dir}/_temporary,o.a.h.mapred.FileOutputCommitter.getWorkOutputPath checks for existence of ${mapred.output.dir} temporary to ensure tasks launched _after the job-cleanup task fail early (in a vast majority of cases). This check is missing in the mapreduce libraries.  Related note: FileOutputCommitter.setupTask seems a more appropriate place for the above check...,Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 3 Jun 2010 18:44:33 +0000,Wed; 30 Jul 2014 19:57:20 +0000,Wed; 30 Jul 2014 19:57:20 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1841
MAPREDUCE-1842,Bug,Major,job submission,JobID.forName() creates JobID instances that break equality,"We have some code that uses serialization to store org.apache.hadoop.mapreduce.JobID instances (among other things). Since org.apache.hadoop.mapreduce.JobID is not serializable; we store the String representation and use org.apache.hadoop.mapreduce.JobID.forName(String) to read it back.  Unfortunately the instance created by that method is not equal to the same id as created by the constructor. Here's a unit test for the problem:  @Test public void forNameCopyShouldProduceInstanceEqualToOriginal() {     JobID jobId1 = new JobID(""original""; 1);     JobID jobId2 = JobID.forName(jobId1.toString());      assertEquals(jobId1; jobId2); }  forName(String) produces a backwards compatible instance from the old mapred package but the equals method shared by them both uses this.getClass() == that.getClass() and that causes the incompatible instances.  I know this backwards compatible stuff is important but could you please fix this ? The simplest fix would be to change the implementation of equals() or override it in the backwards compatibillity version of JobID in the old mapred package",Open,Unresolved,,Unassigned,Age Mooij,Fri; 4 Jun 2010 12:13:18 +0000,Wed; 27 Dec 2017 07:33:09 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1842
MAPREDUCE-1843,Improvement,Major,distributed-cache,Allow for map and reduce specific DistributedCache artifacts,In several cases; only the maps or the reduces need artifacts in the DistributedCache. We need to allow for the same.,Resolved,Duplicate,MAPREDUCE-989,Unassigned,Arun C Murthy,Mon; 7 Jun 2010 05:57:22 +0000,Mon; 7 Jun 2010 08:16:37 +0000,Mon; 7 Jun 2010 08:15:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1843
MAPREDUCE-1844,Bug,Blocker,test,Tests failing with java.lang.NoClassDefFoundError,Tests are failing with  lang.NoClassDefFoundError (see http: .ivy2 2) checkout trunk 3) ant -Dtestcase=TestMRCLI run-test-mapred,Resolved,Fixed,,Unassigned,Amar Kamat,Mon; 7 Jun 2010 08:08:27 +0000,Fri; 25 Jun 2010 20:42:23 +0000,Fri; 25 Jun 2010 20:42:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1844
MAPREDUCE-1845,Bug,Major,contrib/fair-share,FairScheduler.tasksToPeempt() can return negative number,This method can return negative number. This will cause the preemption to under-preempt. The bug was discovered by Joydeep.,Closed,Fixed,,Scott Chen,Scott Chen,Mon; 7 Jun 2010 18:40:57 +0000,Tue; 24 Aug 2010 21:21:41 +0000,Thu; 1 Jul 2010 23:10:53 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1845
MAPREDUCE-1846,Improvement,Major,,Add option to run Slive tests in test jar driver. ,Currently there is no way to run Slive tests through test jar. It is required to add option to run slive tests from test jar driver.,Resolved,Duplicate,HDFS-708,Ravi Phulari,Ravi Phulari,Tue; 8 Jun 2010 00:30:05 +0000,Thu; 24 Nov 2011 01:11:11 +0000,Thu; 24 Nov 2011 01:11:11 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1846
MAPREDUCE-1847,Bug,Minor,capacity-sched,capacity scheduler job tasks summaries are wrong if nodes fail,The Job Scheduling Information the web UI is needs to be re-computed in case nodes fail.  Otherwise it will report tasks are running that are not.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 8 Jun 2010 22:34:11 +0000,Wed; 2 Nov 2011 17:40:43 +0000,Wed; 2 Nov 2011 17:40:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1847
MAPREDUCE-1848,Improvement,Major,jobtracker,Put number of speculative; data local; rack local tasks in JobTracker metrics,It will be nice that we can collect these information in JobTracker metrics,Closed,Fixed,,Scott Chen,Scott Chen,Wed; 9 Jun 2010 21:33:00 +0000,Mon; 12 Dec 2011 06:19:43 +0000,Thu; 15 Jul 2010 23:31:47 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1848
MAPREDUCE-1849,New Feature,Major,,Implement a FlumeJava-like library for operations over parallel collections using Hadoop MapReduce,The API used internally at Google is described in great detail at http: citation.cfm?id=1806596.1806638.,Resolved,Implemented,,Unassigned,Jeff Hammerbacher,Wed; 9 Jun 2010 21:40:47 +0000,Fri; 22 Mar 2013 19:36:29 +0000,Fri; 22 Mar 2013 19:36:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1849
MAPREDUCE-1850,Improvement,Major,,Include job submit host information (name and ip) in jobconf and jobdetails display,Enhancement to identify the source (submit host and ip) of a job request.,Closed,Fixed,,Krishna Ramachandran,Krishna Ramachandran,Wed; 9 Jun 2010 22:36:51 +0000,Mon; 12 Dec 2011 06:19:29 +0000,Tue; 29 Jun 2010 09:37:46 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1850
MAPREDUCE-1851,Improvement,Major,contrib/streaming;documentation,Document configuration parameters in streaming,There are several streaming options such as stream.map.output.field.separator; stream.num.map.output.key.fields; stream.map.input.field.separator;  stream.reduce.input.field.separator;  stream.map.input.ignoreKey; stream.non.zero.exit.is.failure etc which are spread everywhere. These should be documented at single place with description and default-value.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 10 Jun 2010 04:30:39 +0000,Mon; 12 Dec 2011 06:18:37 +0000,Wed; 23 Jun 2010 07:14:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1851
MAPREDUCE-1852,Bug,Major,test,build/test path is hardcoded in many testcases.,build test path is hardcoded in many testcases; instead it should be read from system property test.build.dir or any other other appropriate property.,Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Thu; 10 Jun 2010 04:58:27 +0000,Wed; 30 Jul 2014 20:11:35 +0000,Wed; 30 Jul 2014 20:11:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1852
MAPREDUCE-1853,Bug,Critical,task,MultipleOutputs does not cache TaskAttemptContext,"In MultipleOutputs there is    so for every reduce call it creates a new Job instance ...which creates a new LocalJobRunner. That does not sound like a good idea.  You end up with a flood of ""jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker; sessionId= - already initialized""  This should probably also be added to 0.22.",Closed,Fixed,,Torsten Curdt,Torsten Curdt,Thu; 10 Jun 2010 14:35:34 +0000,Wed; 23 Nov 2011 06:03:25 +0000,Wed; 16 Jun 2010 11:25:45 +0000,,0.21.0;0.22.0,,,MAPREDUCE-2740,https://issues.apache.org/jira/browse/MAPREDUCE-1853
MAPREDUCE-1854,New Feature,Major,test,[herriot] Automate health script system test,1. There are three scenarios; first is induce a error from health script; verify that task tracker is blacklisted.  2. Make the health script timeout and verify the task tracker is blacklisted.  3. Make an error in the health script path and make sure the task tracker stays healthy.,Open,Unresolved,,Balaji Rajagopalan,Balaji Rajagopalan,Thu; 10 Jun 2010 17:34:06 +0000,Thu; 2 May 2013 02:29:31 +0000,,,,,,MAPREDUCE-1882,https://issues.apache.org/jira/browse/MAPREDUCE-1854
MAPREDUCE-1855,Bug,Major,,refreshSuperUserGroupsConfiguration for MR should use server side configuration for the refresh (for HADOOP-6815),nan,Resolved,Fixed,,Boris Shkolnik,Boris Shkolnik,Thu; 10 Jun 2010 17:52:18 +0000,Fri; 29 Oct 2010 02:04:24 +0000,Wed; 23 Jun 2010 00:25:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1855
MAPREDUCE-1856,Improvement,Major,build,Extract a subset of tests for smoke (DOA) validation,Similar to that of HDFS-1199 for MapReduce. Adds an ability to run up to 30 minutes of the tests to 'smoke' MapReduce build i.e. find possible issues faster than the full test cycle does).,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Fri; 11 Jun 2010 00:32:45 +0000,Fri; 29 Oct 2010 02:04:23 +0000,Tue; 17 Aug 2010 02:42:14 +0000,,0.21.0,,,HADOOP-6810,https://issues.apache.org/jira/browse/MAPREDUCE-1856
MAPREDUCE-1857,Bug,Trivial,contrib/streaming,Remove unused streaming configuration from src,The configuration stream.numinputspecs is just set and not read anywhere. It can be removed.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 11 Jun 2010 08:11:10 +0000,Fri; 29 Oct 2010 02:04:25 +0000,Thu; 24 Jun 2010 06:55:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1857
MAPREDUCE-1858,Bug,Major,distcp,TestCopyFiles fails consistently on trunk,All the tests in TestCopyFiles fail. For e.g.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Fri; 11 Jun 2010 11:00:51 +0000,Sun; 13 Jun 2010 04:40:40 +0000,Sun; 13 Jun 2010 04:40:40 +0000,,0.22.0,,,HADOOP-6796,https://issues.apache.org/jira/browse/MAPREDUCE-1858
MAPREDUCE-1859,New Feature,Major,job submission,maxConcurrentMapTask & maxConcurrentReduceTask per job,It would be valuable if one could specify the max number of map Capacity-Schedulers.,Resolved,Won't Fix,,Unassigned,Johannes Zillmann,Fri; 11 Jun 2010 11:10:59 +0000,Wed; 30 Jul 2014 20:14:49 +0000,Wed; 30 Jul 2014 20:14:49 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1859
MAPREDUCE-1860,Bug,Major,,LocalJobRunner should use local filesystem to qualify systemdir,getSystemDir() in LocalJobRunner returns a path qualified using the default file system from the Configuration. Usually default filesystem is set to hdfs cluster. which means that when trying to use the local mode - the jobclient ends up using hdfs as system directory.  this seems like an error. localjobrunner should use local file system as it's default file system and that should be used to qualify the mapred system directory.,Resolved,Invalid,,Unassigned,Joydeep Sen Sarma,Fri; 11 Jun 2010 20:55:29 +0000,Sat; 12 Jun 2010 05:40:03 +0000,Sat; 12 Jun 2010 00:04:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1860
MAPREDUCE-1861,Improvement,Major,contrib/raid,Raid should rearrange the replicas while raiding,Raided file introduce extra dependencies on the blocks on the same stripe. Therefore we need a new way to place the blocks.  It is desirable th the same time.,Closed,Won't Fix,,Scott Chen,Scott Chen,Sat; 12 Jun 2010 01:42:37 +0000,Tue; 15 Nov 2011 00:49:09 +0000,Thu; 31 Mar 2011 21:20:28 +0000,,0.23.0,,,MAPREDUCE-1831,https://issues.apache.org/jira/browse/MAPREDUCE-1861
MAPREDUCE-1862,Bug,Major,,Distributed Cache doesn't accept paths from non-default filesystems,addFileToClassPath addArchive... try to qualify supplied against default file system. this fails when the supplied path doesn't belong to default file system.  this happens during local mode execution. fs.default.name may be pointing to production hdfs. localjobrunner tries to add files in local filesystem (because; starting 0.21; it correctly uses a local system dir) to distributed cache. this bombs.,Resolved,Duplicate,MAPREDUCE-1744,Joydeep Sen Sarma,Joydeep Sen Sarma,Sat; 12 Jun 2010 04:54:29 +0000,Tue; 15 Jun 2010 19:13:14 +0000,Tue; 15 Jun 2010 19:11:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1862
MAPREDUCE-1863,Bug,Major,tools/rumen,[Rumen] Null failedMapAttemptCDFs in job traces generated by Rumen,All the traces generated by Rumen for jobs having failed task attempts has null value for failedMapAttemptCDFs.,Closed,Fixed,,Amar Kamat,Amar Kamat,Mon; 14 Jun 2010 09:23:24 +0000,Mon; 12 Dec 2011 06:19:37 +0000,Tue; 29 Jun 2010 06:46:37 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1863
MAPREDUCE-1864,Bug,Major,contrib/streaming,PipeMapRed.java has uninitialized members log_ and LOGNAME ,PipeMapRed. has members log_ and LOGNAME; which are never initialized and they are used in code for logging in several places.  They should be removed and PipeMapRed should use commons LogFactory and Log for logging. This would improve code maintainability.  Also; as per comment ; stream.joblog_ configuration property can be removed.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 15 Jun 2010 05:28:33 +0000,Mon; 12 Dec 2011 06:19:57 +0000,Fri; 2 Jul 2010 06:21:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1864
MAPREDUCE-1865,Bug,Major,tools/rumen,[Rumen] Rumen should also support jobhistory files generated using trunk,Rumen code in trunk parses and process only jobhistory files from pre-21 hadoop mapreduce clusters. It should also support jobhistory files generated using trunk.,Closed,Fixed,,Amar Kamat,Amar Kamat,Tue; 15 Jun 2010 06:04:11 +0000,Mon; 12 Dec 2011 06:19:58 +0000,Fri; 16 Jul 2010 06:36:23 +0000,,0.22.0,,MAPREDUCE-1876,,https://issues.apache.org/jira/browse/MAPREDUCE-1865
MAPREDUCE-1866,Bug,Minor,contrib/streaming,Remove deprecated class org.apache.hadoop.streaming.UTF8ByteArrayUtils,The class org.apache.hadoop.streaming.UTF8ByteArrayUtils is deprecated in favor of org.apache.hadoop.util.UTF8ByteArrayUtils in branch 0.19. The same should be removed.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 15 Jun 2010 08:32:30 +0000,Fri; 29 Oct 2010 02:04:14 +0000,Thu; 29 Jul 2010 05:51:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1866
MAPREDUCE-1867,Bug,Minor,contrib/streaming,Remove unused methods in org.apache.hadoop.streaming.StreamUtil,There are many unused methods in org.apache.hadoop.streaming.StreamUtil. They should be removed from the class for maintainability.,Resolved,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Tue; 15 Jun 2010 09:32:15 +0000,Thu; 7 Apr 2011 15:40:49 +0000,Tue; 26 Oct 2010 19:05:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1867
MAPREDUCE-1868,Improvement,Major,client,Add read timeout on userlog pull,Add read and connection timeout to prevent job client hangs  jobclient can block indefinitely during task log pull if read or connect fails           at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection. 1396),Closed,Fixed,,Krishna Ramachandran,Krishna Ramachandran,Tue; 15 Jun 2010 18:04:12 +0000,Mon; 12 Dec 2011 06:19:22 +0000,Wed; 23 Jun 2010 17:38:46 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1868
MAPREDUCE-1869,Bug,Critical,tasktracker,TaskTracker hangs due to Java's usage of fork() being MT-unsafe,A TaskTracker process on our grid appears to be locked up and not sending heartbeats to the namenode.  Attaching jstack and pstack output.  Even tho the hangs appear to be in LocalDirAllocator; the local file system seems to be a-ok.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 15 Jun 2010 22:56:43 +0000,Wed; 2 Nov 2011 17:40:29 +0000,Wed; 2 Nov 2011 17:40:29 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1869
MAPREDUCE-1870,Bug,Blocker,build,Harmonize MapReduce JAR library versions with Common and HDFS,MapReduce part of HADOOP-6800.,Closed,Fixed,,Tom White,Tom White,Wed; 16 Jun 2010 05:34:01 +0000,Fri; 29 Oct 2010 02:03:37 +0000,Thu; 1 Jul 2010 05:05:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1870
MAPREDUCE-1871,Test,Major,test,"Create automated test scenario for ""Collect information about number of tasks succeeded / total per time unit for a tasktracker""","Create automated test scenario for ""Collect information about number of tasks succeeded   total per time unit for a tasktracker""  1) Verification of all the above mentioned fields with the specified TTs. Total no. of tasks and successful tasks should be equal to the corresponding no. of tasks specified in TTs logs  2)  Fail a task on tasktracker.  Node UI should update the status of tasks on that TT accordingly.   3)  Kill a task on tasktracker.  Node UI should update the status of tasks on that TT accordingly  4) Positive Run simultaneous jobs and check if all the fields are populated with proper values of tasks.  Node UI should have correct valiues for all the fields mentioned above.   5)  Check the fields across one hour window  Fields related to hour should be updated after every hour  6) Check the fields across one day window  fields related to hour should be updated after every day  7) Restart a TT and bring it back.  UI should retain the fields values.    8) Positive Run a bunch of jobs with 0 maps and 0 reduces simultanously.",Resolved,Fixed,,Iyappan Srinivasan,Iyappan Srinivasan,Wed; 16 Jun 2010 07:32:35 +0000,Wed; 30 Jul 2014 18:05:48 +0000,Wed; 30 Jul 2014 18:05:48 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1871
MAPREDUCE-1872,Improvement,Major,capacity-sched,Re-think (user|queue) limits on (tasks|jobs) in the CapacityScheduler,"We need to re-think our story to have lead to a better overall picture of having limits on  {users; queues}  w.r.t   	Jobs - limits on submission; initialization 	Tasks - limits per-job; per-queue on total tasks; concurrent tasks etc.",Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 16 Jun 2010 17:25:58 +0000,Wed; 30 Jul 2014 20:18:22 +0000,Wed; 30 Jul 2014 20:18:22 +0000,,,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-1872
MAPREDUCE-1873,Improvement,Major,contrib/fair-share,Add a metrics instrumentation class to collect metrics about fair share scheduler,Export the following metrics:  1. num of starved jobs (jobs that get slots less then their fair share defined in fair scheduler) 2. num of starved pools (pools that get assigned map or reduce less than its min map slots or min reduce slots. 3. num of active pools 4. total min maps 5. total max maps 6. total min reduces 7. total max reduces  3~7 are available in FairSchedulerServlet. To report here is to create another metrics data export path so that these metrics can be displayed in ODS; jmx or ganglia.,Open,Unresolved,,Unassigned,Kai Ren,Wed; 16 Jun 2010 18:25:04 +0000,Wed; 16 Jun 2010 18:25:34 +0000,,,0.22.0,hadoop;metrics,,,https://issues.apache.org/jira/browse/MAPREDUCE-1873
MAPREDUCE-1874,Improvement,Major,,Enable column sorting for all JobTracker Administration UI tables ,"Add ability to sort columns in ascending or descending order for all JobTracker Admin tables   ""Scheduling Info"" ""Running Jobs""  ""Retired Jobs""  ""Completed Jobs""",Resolved,Won't Fix,,Unassigned,Krishna Ramachandran,Wed; 16 Jun 2010 23:42:25 +0000,Wed; 30 Jul 2014 20:21:21 +0000,Wed; 30 Jul 2014 20:21:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1874
MAPREDUCE-1875,New Feature,Major,,Need sample map reduce program for arithmetic calculations from text files  and produce the results in hadoop 0.20.2,Hi I am new to Hadoop Map-reduce programming. Can anyone provide me the sample map-reduce code for some basic arithmatic calculations. Like; read from the text  div opearations and produce the output. Kindly anyone help me on this,Resolved,Invalid,,Unassigned,Senthil,Thu; 17 Jun 2010 10:21:03 +0000,Thu; 17 Jun 2010 14:58:28 +0000,Thu; 17 Jun 2010 14:58:28 +0000,,0.20.2,0,,,https://issues.apache.org/jira/browse/MAPREDUCE-1875
MAPREDUCE-1876,Bug,Major,jobtracker,TaskAttemptStartedEvent.java incorrectly logs MAP_ATTEMPT_STARTED as event type for reduce tasks,TaskAttemptStartedEvent is used to log the start time of both the map and reduce task attempts to JobHistory. Following is the implementation of getEventType() method of TaskAttemptStartedEvent,Closed,Fixed,,Amar Kamat,Amar Kamat,Fri; 18 Jun 2010 04:44:36 +0000,Fri; 29 Oct 2010 02:03:38 +0000,Fri; 25 Jun 2010 11:48:28 +0000,,0.22.0,,MAPREDUCE-1865,MAPREDUCE-1980,https://issues.apache.org/jira/browse/MAPREDUCE-1876
HADOOP-10906,Bug,Major,,getContentSummary() for HarFileSystem throws IllegalArgumentException,As HarFileSystem does not implement getContentSummary(); the implementation from FilterFileSystem is inherited by default. However; FilterFileSystem.getContentSummary() does not work for the HarFileSystem because the method attempts to use HarFileSystem's underlying FS to call getContentSummary(). In the case where the the underlying filesystem is HDFS; an exception similar to the following is thrown:     One solution is to implement HarFileSystem.getContentSummary() using code similar to FileSystem.getContentSummary().,Open,Unresolved,,Unassigned,Paul Yang,Sat; 19 Jun 2010 00:29:50 +0000,Wed; 11 Mar 2015 16:36:46 +0000,,,,,,,https://issues.apache.org/jira/browse/HADOOP-10906
MAPREDUCE-1878,Improvement,Major,contrib/mrunit,Add MRUnit documentation,A short user guide for MRUnit; written in asciidoc.,Closed,Fixed,,Aaron Kimball,Aaron Kimball,Sat; 19 Jun 2010 01:49:56 +0000,Mon; 12 Dec 2011 06:19:36 +0000,Fri; 3 Dec 2010 22:49:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1878
MAPREDUCE-1879,Improvement,Major,jobtracker,JobTracker web page showing &apos;,nan,Resolved,Fixed,,Unassigned,Tsz Wo Nicholas Sze,Sat; 19 Jun 2010 05:24:16 +0000,Wed; 30 Jul 2014 21:00:05 +0000,Wed; 30 Jul 2014 21:00:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1879
MAPREDUCE-1880,Bug,Minor,examples,"java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result. while running ""hadoop jar hadoop-0.20.1+169.89-examples.jar pi 4 30""","If I run ""hadoop jar hadoop-0.20.1+169.89-examples.jar pi 4 30""; I get the following output:  Number of Maps  = 4 Samples per Map = 30 Wrote input for Map #0 Wrote input for Map #1 Wrote input for Map #2 Wrote input for Map #3 Starting Job   INFO mapred.JobClient:     Reduce input records=8 Job Finished in 28.593 seconds  156)   ""hadoop jar hadoop-0.20.1+169.89-examples.jar pi 2 10"" finishes fine",Closed,Fixed,,Tsz Wo Nicholas Sze,Victor Pakhomov,Sat; 19 Jun 2010 20:03:30 +0000,Tue; 24 Aug 2010 21:21:43 +0000,Tue; 22 Jun 2010 03:33:40 +0000,,0.20.1,pi_example;ubuntu_lucid,,,https://issues.apache.org/jira/browse/MAPREDUCE-1880
MAPREDUCE-1881,Improvement,Minor,,Improve TaskTrackerInstrumentation,"The TaskTrackerInstrumentation class provides a useful way to capture key events at the TaskTracker for use in various reporting tools; but it is currently rather limited; because only one TaskTrackerInstrumentation can be added to a given TaskTracker and this objects receives minimal information about tasks (only their IDs). I propose enhancing the functionality through two changes:   	Support a comma-separated list of TaskTrackerInstrumentation classes rather than just a single one in the JobConf; and report events to all of them. 	Make the reportTaskLaunch and reportTaskEnd methods in TaskTrackerInstrumentation receive a reference to a whole Task object rather than just its TaskAttemptID. It might also be useful to make the latter receive the task's final state; i.e. failed; killed; or successful.    I'm just posting this here to get a sense of whether this is a good idea. If people think it's okay; I will make a patch against trunk that implements these changes.",Resolved,Fixed,,Matei Zaharia,Matei Zaharia,Sun; 20 Jun 2010 02:36:02 +0000,Mon; 24 Sep 2012 18:37:10 +0000,Fri; 20 Aug 2010 17:46:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1881
MAPREDUCE-1882,New Feature,Major,test,Use Jsch instead of Shell.java ,In herriot ( hadoop system test case dev) we often find that we are resorted to habit of ssh to remote node execute a shell command; and come out. It is wise to use Jsch instead of doing this through Shell. ( hadoop code); since Jsch provides nice Java abstraction; the JIRA will only close after we import Jsch input hadoop build system and also fix all the existing test cases.,Open,Unresolved,,Iyappan Srinivasan,Balaji Rajagopalan,Mon; 21 Jun 2010 11:34:52 +0000,Mon; 27 Sep 2010 04:14:23 +0000,,,,,HADOOP-6879,MAPREDUCE-1854,https://issues.apache.org/jira/browse/MAPREDUCE-1882
MAPREDUCE-1883,Bug,Major,test,herriot bug with getDaemonConf,"I found this bug with getDaemonConf the interface method implemented by JTProtocol and TTProtocol.   Configuration tConf = client.getProxy().getDaemonConf(); String reportAddress = tConf.get(""mapred.task.tasker.report.address""); System.out.println(reportAddress);  It prints it out as 0:0:0:0:12345 instead of printing it as 0.0.0.0:12345; and this issues needs to be fixed; somewhere is the wire the report address is getting mangled.",Open,Unresolved,,Unassigned,Balaji Rajagopalan,Mon; 21 Jun 2010 11:43:20 +0000,Mon; 27 Sep 2010 04:14:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1883
MAPREDUCE-1884,Bug,Major,,Remove/deprecate mapred.map.tasks tunable,Considering it isn't used for much that I know; is there any reason to keep the mapred.map.tasks tunable hanging around?  If not; let's remove it from the documentation; xml files; etc.  All it does is generate user confusion when it doesn't work.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 22 Jun 2010 01:46:41 +0000,Wed; 2 Nov 2011 17:40:14 +0000,Wed; 2 Nov 2011 17:40:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1884
MAPREDUCE-1885,Bug,Major,,Trunk compilation is broken because of FileSystem api change in HADOOP-6826,Trunk compilation is broken because of FileSystem api change in HADOOP-6826.  Here are the error messages:       iajc   297 error The method create(Path; FsPermission; boolean; int; short; long; Progressable) in the type FileSystem is not applicable for the arguments (Path; FsPermission; EnumSetCreateFlag; int; short; long; null)      iajc jobFileOut = logDirFs.create(logDirConfPath;      iajc      iajc      iajc 2 errors,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Tue; 22 Jun 2010 05:01:33 +0000,Thu; 2 May 2013 02:29:32 +0000,Tue; 22 Jun 2010 06:10:18 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1885
MAPREDUCE-1886,Bug,Major,test,org.apache.hadoop.mapred.TestMiniMRChildTask.testTaskEnv fails with timeout,testcase failure is seen here:  Link :  http: ,Open,Unresolved,,Unassigned,Giridharan Kesavan,Tue; 22 Jun 2010 08:57:41 +0000,Tue; 22 Jun 2010 09:07:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1886
MAPREDUCE-1887,Bug,Major,,MRAsyncDiskService does not properly absolutize volume root paths,"In MRAsyncDiskService; volume names are sometimes specified as relative paths; which are not converted to absolute paths. This can cause errors of the form ""cannot delete  root"" even though the actual path is inside the root.",Closed,Fixed,,Aaron Kimball,Aaron Kimball,Tue; 22 Jun 2010 20:20:48 +0000,Mon; 12 Dec 2011 06:18:25 +0000,Fri; 25 Jun 2010 01:07:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1887
MAPREDUCE-1888,Bug,Major,contrib/streaming,Streaming overrides user given output key and value types.,The following code in StreamJob. overrides user given output key and value types.,Closed,Fixed,MAPREDUCE-1138,Ravi Gummadi,Amareshwari Sriramadasu,Wed; 23 Jun 2010 04:31:06 +0000,Mon; 12 Dec 2011 06:19:57 +0000,Mon; 5 Jul 2010 05:12:28 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1888
MAPREDUCE-1889,New Feature,Major,test,[herriot] Ability to restart a single node for pushconfig,Right now the pushconfig is supported only at a cluster level; this jira will introduce the functionality to be supported at node level.,Open,Unresolved,,Balaji Rajagopalan,Balaji Rajagopalan,Wed; 23 Jun 2010 08:39:54 +0000,Thu; 2 May 2013 02:29:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1889
MAPREDUCE-1890,Test,Major,test,Create automated test scenarios for decommissioning of task trackers,"Test scenarios :  1) Put a healthy slave task tracker in the dfs.exclude file.  2) As a valid user; decommission a  node in the cluster by issuing the command ""hadoop mradmin -refreshNodes""  3) Make sure that the node is decommissioned.  4) Now take the task tracker out of the file.  5) As a valid user; again issue the command ""hadoop mradmin -refreshNodes""  6) Make sure that the node is not in the decommiossion list.  7) Bring back that node.",Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Wed; 23 Jun 2010 09:30:58 +0000,Thu; 2 May 2013 02:29:32 +0000,,,,,HADOOP-6879,,https://issues.apache.org/jira/browse/MAPREDUCE-1890
MAPREDUCE-1891,Improvement,Major,tasktracker,Disk io of shuffle phase may decrease if shuffled data not decompressed,Current shuffled data is decompressed immediately. It may use much less memory for shuffle buffer if the data is not decompressed until merging to disk.,Open,Unresolved,,Unassigned,Kang Xiao,Wed; 23 Jun 2010 15:25:06 +0000,Wed; 23 Jun 2010 15:32:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1891
MAPREDUCE-1892,Improvement,Major,contrib/raid,RaidNode can allow layered policies more efficiently,The RaidNode policy file can have layered policies that can cover a file more than once. To avoid processing a file multiple times (for RAIDing); RaidNode maintains a list of processed files that is used to avoid duplicate processing attempts.  This is problematic in that a large number of processed files could cause the RaidNode to run out of memory.  This task proposes a better method of detecting processed files. The method is based on the observation that a more selective policy will have a better match with a file name than a less selective one. Specifically; the more selective policy will have a longer common prefix with the file name.  So to detect if a file has already been processed; the RaidNode only needs to maintain a list of processed policies and compare the lengths of the common prefixes. If the file has a longer common prefix with one of the processed policies than with the current policy; it can be assumed to be processed already.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Wed; 23 Jun 2010 22:16:33 +0000,Mon; 12 Dec 2011 06:19:35 +0000,Tue; 2 Nov 2010 18:31:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1892
MAPREDUCE-1893,Improvement,Major,benchmarks;test,Multiple reducers for Slive,Slive currently uses single reducer. It could use multiple ones.,Closed,Fixed,,Konstantin Shvachko,Konstantin Shvachko,Thu; 24 Jun 2010 23:16:21 +0000,Mon; 12 Dec 2011 06:19:01 +0000,Fri; 2 Jul 2010 00:36:08 +0000,,0.22.0,,,HDFS-708,https://issues.apache.org/jira/browse/MAPREDUCE-1893
MAPREDUCE-1894,Bug,Major,contrib/raid,DistributedRaidFileSystem.readFully() does not return,DistributedRaidFileSystem.readFully() has a while(true) loop with no return. The read functions do not have this problem.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Thu; 24 Jun 2010 23:37:11 +0000,Mon; 12 Dec 2011 06:20:07 +0000,Tue; 6 Jul 2010 06:22:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1894
MAPREDUCE-1895,Bug,Major,tasktracker,MapEventFetcherThread should not iterate over jobs that are not localized,We have seen a scenario of lost trackers on our clusters because of the following: TaskLauncher has locked a TaskTracker$RunningJob and doing localizeJob; which involves DFS operations. Map-event fetcher has locked TaskTracker.runningJobs map and is waiting to lock the RunningJob object. TaskTracker offerService is waiting to lock TaskTracker.runningJobs map; thus failing to send heartbeats in 10 minutes.   So; I think map-event fetcher should skip jobs that are not localized.,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Fri; 25 Jun 2010 05:50:11 +0000,Fri; 25 Jun 2010 05:59:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1895
MAPREDUCE-1896,Task,Major,test,[Herriot] New property for multi user list.,Adding new property for multi user list.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 25 Jun 2010 09:14:06 +0000,Thu; 2 May 2013 02:29:31 +0000,Fri; 16 Jul 2010 20:10:35 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1896
MAPREDUCE-1897,Bug,Major,test,trunk build broken on compile-mapred-test,...apparently.  Fresh checkout of trunk (all three hadoop-*); build.properties project.version fix; ant veryclean mvn-install of common; hdfs; and then mapreduce:                                           ^,Resolved,Fixed,,Konstantin Boudnik,Greg Roelofs,Fri; 25 Jun 2010 23:37:26 +0000,Fri; 29 Oct 2010 02:03:23 +0000,Thu; 2 Sep 2010 05:47:12 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1897
MAPREDUCE-1898,Task,Major,test,[Herriot] Implement a functionality for getting the job summary information of a job.,Implement a method for getting the job summary details of a job. The job summary should be. jobId; startTime; launchTime; finishTime; numMaps; numSlotsPerMap; numReduces; numSlotsPerReduce; user; queue; status; mapSlotSeconds; reduceSlotSeconds; clusterMapCapacity;clusterReduceCapacity.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 28 Jun 2010 05:43:57 +0000,Thu; 2 May 2013 02:29:31 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1898
MAPREDUCE-1899,Task,Major,test,[Herriot] Test jobsummary information for different jobs.,Test the following scenarios.  1. Verify the job summary information for killed job. 2. Verify the job summary information for failed job. 3. Verify the job queue information in job summary after job has successfully completed. 4. Verify the job summary information for high ram jobs.,Resolved,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 28 Jun 2010 09:05:43 +0000,Wed; 30 Jul 2014 18:06:34 +0000,Wed; 30 Jul 2014 18:06:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1899
MAPREDUCE-1900,Bug,Major,jobtracker;tasktracker,MapReduce daemons should close FileSystems that are not needed anymore,Related to HADOOP-6843; this jira is to make MapReduce behave better with respect to closing FileSystems when they are not needed anymore.,Closed,Fixed,,Kan Zhang,Devaraj Das,Mon; 28 Jun 2010 18:58:26 +0000,Mon; 12 Dec 2011 06:19:44 +0000,Wed; 4 Aug 2010 18:37:01 +0000,,,,HADOOP-6888,HADOOP-4655,https://issues.apache.org/jira/browse/MAPREDUCE-1900
MAPREDUCE-1901,Improvement,Major,,Jobs should not submit the same jar files over and over again,Currently each Hadoop job uploads the required resources (jars sha) would be a good alternative to have available.,Resolved,Duplicate,YARN-1492,Unassigned,Joydeep Sen Sarma,Wed; 30 Jun 2010 19:21:38 +0000,Fri; 13 Nov 2015 18:57:10 +0000,Fri; 13 Nov 2015 18:57:09 +0000,,,,,MAPREDUCE-1902,https://issues.apache.org/jira/browse/MAPREDUCE-1901
MAPREDUCE-1902,Improvement,Major,distributed-cache,job jar file is not distributed via DistributedCache,The main jar file for an job is not distributed via the distributed cache. It would be more efficient if that were the case.  It would also allow us to comprehensively tackle the inefficiencies in distribution of jar files and such (see MAPREDUCE-1901).,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Wed; 30 Jun 2010 22:25:18 +0000,Mon; 17 Jan 2011 23:18:31 +0000,,,,,,MAPREDUCE-1901,https://issues.apache.org/jira/browse/MAPREDUCE-1902
MAPREDUCE-1903,Improvement,Major,jobtracker,Allow different slowTaskThreshold for mappers and reducers,We have been running the new speculative logic in HADOOP-2141 done by Andy in our production cluster. One thing that we observed is that there are significantly low number of speculative reducers. We have seen usually 100 speculative mappers launched per minute but speculative reducers are usually less than 5. But reducers are usually where we get complains about having speculative issues.  These two types of tasks has different properties and different needs. It would be nice if we can configure the slow threshold separately to deal with them separately.  We can add the following config keys to allow setting them independently. MRJobConfig.SPECULATIVE_MAP_SLOWTASK_THRESHOLD MRJobConfig.SPECULATIVE_REDUCE_SLOWTASK_THRESHOLD  Thoughts?,Open,Unresolved,,Scott Chen,Scott Chen,Thu; 1 Jul 2010 01:19:57 +0000,Thu; 13 Jan 2011 02:29:02 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1903
MAPREDUCE-1904,Improvement,Major,tasktracker,Reducing locking contention in TaskTracker.MapOutputServlet's LocalDirAllocator,While profiling tasktracker with Sort benchmark; it was observed that threads block on LocalDirAllocator.getLocalPathToRead() in order to get the index file and temporary map output file.  As LocalDirAllocator is tied up with ServetContext;  only one instance would be available per tasktracker httpserver.  Given the jobid  mapid; LocalDirAllocator retrieves index file path and temporary map output file path. getLocalPathToRead() is internally synchronized.  Introducing a LRUCache for this lookup reduces the contention heavily (LRUCache with key =jobid +mapid and value=PATH to the file). Size of the LRUCache can be varied based on the environment and I observed a throughput improvement in the order of 4-7% with the introduction of LRUCache.,Open,Unresolved,,Unassigned,Rajesh Balamohan,Thu; 1 Jul 2010 04:10:02 +0000,Wed; 15 Jun 2011 05:53:29 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1904
MAPREDUCE-1905,Bug,Blocker,task,Context.setStatus() and progress() api are ignored,TaskAttemptContext.setStatus() and progress() were overriden in TaskInputOutputContext; inbranch 0.20; to call the underlying reporter apis. But the methods are no more over-riden in TaskInputOutputContextImpl after MAPREDUCE-954.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Thu; 1 Jul 2010 05:44:30 +0000,Mon; 12 Dec 2011 06:20:07 +0000,Thu; 11 Nov 2010 04:11:01 +0000,,0.21.0,,MAPREDUCE-1122,,https://issues.apache.org/jira/browse/MAPREDUCE-1905
MAPREDUCE-1906,Improvement,Major,jobtracker;performance;tasktracker,Lower default minimum heartbeat interval for tasktracker > Jobtracker,I get a 0% to 15% performance increase for smaller clusters by making the heartbeat throttle stop penalizing clusters with less than 300 nodes.  Between 0.19 and 0.20; the default minimum heartbeat interval increased from 2s to 3s.   If a JobTracker is throttled at 100 heartbeats   sec for large clusters; why should a cluster with 10 nodes be throttled to 3.3 heartbeats per second?,Closed,Fixed,,Todd Lipcon,Scott Carey,Thu; 1 Jul 2010 17:09:39 +0000,Tue; 25 Sep 2012 17:12:42 +0000,Fri; 31 Dec 2010 18:16:42 +0000,,0.20.1;0.20.2;1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1906
MAPREDUCE-1907,Bug,Major,tasktracker,nutch doesnt run under 0.20.2+228-1~karmic-cdh3b1 version of hadoop,new versions of hadoop appear to put jars in a different format now; instead of file: job.jar!; which breaks nutch when its trying to load its plugins. Specifically; the stack trace looks like:  Caused by:  170)  Running this on an older version of hadoop works.,Resolved,Won't Fix,,Unassigned,Robert Gonzalez,Thu; 1 Jul 2010 19:32:17 +0000,Wed; 30 Jul 2014 21:35:53 +0000,Wed; 30 Jul 2014 21:35:53 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1907
MAPREDUCE-1908,Bug,Major,contrib/raid,DistributedRaidFileSystem does not handle ChecksumException correctly,ChecksumException reports the offset of corruption within a block; whereas DistributedRaidFileSystem.setAlternateLocations was expecting it to report the offset of corruption within the file.  The best way of dealing with a missing block corrupt block is to just use the current seek offset in the file as the position of corruption.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Thu; 1 Jul 2010 20:40:53 +0000,Mon; 12 Dec 2011 06:18:24 +0000,Mon; 11 Oct 2010 21:48:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1908
MAPREDUCE-1909,Improvement,Minor,,TrackerDistributedCacheManager takes a blocking lock fo a loop that executes 10K times,In TrackerDistributedCachaManager. ; the portion where the cache is cleaned up; the lock is taken on the main hash table and then all the entries are scanned to see if they can be deleted.  That's a long lockage.  The table is likely to have 10K entries.  I would like to reduce the longest lock duration by maintaining the set of CacheStatus es to delete incrementally.  1: Let there be a new HashSet; deleteSet; that's protected under synchronized(cachedArchives)  2: When refcount is decreased to 0; move the CacheStatus from cachedArchives to deleteSet  3: When seeking an existing CacheStatus; look in deleteSet if it isn't in cachedArchives  4: When refcount is increased from 0 to 1 in a pre-existing CacheStatus see 3:; above move the CacheStatus from deleteSet to cachedArchives  5: When we clean the cache; under synchronized(cachedArchives) ; move deleteSet to a local variable and create a new empty HashSet.  This is constant time.,Open,Unresolved,,Dick King,Dick King,Thu; 1 Jul 2010 21:50:15 +0000,Sat; 31 Jul 2010 00:19:47 +0000,,,,,,MAPREDUCE-1914,https://issues.apache.org/jira/browse/MAPREDUCE-1909
MAPREDUCE-1910,New Feature,Minor,contrib/raid,Allow raid policy to specify a parent policy,We encountered the problem that there are lots of redundancy in our raid.xml file. Most of the policy shares the same properties. It will be nice if a policy can inherit from a previously defined policy and get the default properties from it. This way it is easier to maintain the raid policies.,Resolved,Won't Fix,,Scott Chen,Scott Chen,Thu; 1 Jul 2010 23:58:38 +0000,Tue; 1 Aug 2017 17:12:57 +0000,Tue; 1 Aug 2017 17:12:57 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1910
MAPREDUCE-1911,Bug,Major,contrib/streaming,Fix errors in -info option in streaming,"Here are some of the findings by Karam while verifying -info option in streaming:  	We need to add ""Optional"" for -mapper; -reducer;-combiner and -file options. 	For -inputformat and -outputformat options; we should put ""Optional"" in the prefix for the sake on uniformity. 	We need to remove -cluster decription. 	-help option is not displayed in usage message. 	when displaying message for -info or -help options; we should not display ""Streaming Job Failed!""; also exit code should be 0 in case of -help -info option.",Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 2 Jul 2010 06:07:07 +0000,Mon; 12 Dec 2011 06:19:50 +0000,Mon; 19 Jul 2010 07:13:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1911
MAPREDUCE-1912,Improvement,Major,tools/rumen,[Rumen] Add a driver for Rumen tool ,"Rumen; as a tool; has 2 entry points :  	Trace builder 	Folder    It would be nice to have a single driver program and have 'trace-builder' and 'folder' as its options.",Open,Unresolved,,Amar Kamat,Amar Kamat,Fri; 2 Jul 2010 06:27:58 +0000,Thu; 13 Jan 2011 02:28:54 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1912
HADOOP-6875,Bug,Major,test,[Herriot] Cleanup of temp. configurations is needed upon restart of a cluster,1. New configuration directory is not cleaning up after resetting to default configuration directory in a pushconfig functionality. Because of this reason; it's giving  permission denied problem for a folder; if  other user tried running the tests in the same cluster with pushconfig functionality. I could see this issue while running the tests on a cluster with security enabled and different user.  I have added the functionality for above issue and attaching the patch  2.  Throwing IOException and it says token is expired while running  the tests. I could see this issue in a secure cluster.  This issue has been resolved by setting the following attribute in the configuration.   mapreduce.job.complete.cancel.delegation.tokens=false  adding updating this attribute in the push configuration functionality while creating the new configuration.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 2 Jul 2010 14:50:19 +0000,Mon; 27 Sep 2010 04:14:37 +0000,Fri; 23 Jul 2010 19:39:25 +0000,,0.21.0,,MAPREDUCE-1774,,https://issues.apache.org/jira/browse/HADOOP-6875
MAPREDUCE-1914,Bug,Major,,TrackerDistributedCacheManager never cleans its input directories,When we localize a file into a node's cache; it's installed in a directory whose subroot is a random long .  These long s all sit in a single flat directory per disk; per cluster node.  When the cached file is no longer needed; its reference count becomes zero in a tracking data structure.  The file then becomes eligible for deletion when the total amount of space occupied by cached files exceeds 10G by default or the total number of such files exceeds 10K.  However; when we delete a cached file; we don't delete the directory that contains it; this importantly includes the elements of the flat directory; which then accumulate until they reach a system limit; 32K in some cases; and then the node stops working.  We need to delete the flat directory when we delete the localized cache file it contains.,Resolved,Fixed,,Dick King,Dick King,Fri; 2 Jul 2010 23:46:53 +0000,Wed; 30 Jul 2014 21:53:49 +0000,Wed; 30 Jul 2014 21:53:49 +0000,,,,,MAPREDUCE-1538;MAPREDUCE-1909,https://issues.apache.org/jira/browse/MAPREDUCE-1914
MAPREDUCE-1915,Bug,Trivial,tasktracker,IndexCache - getIndexInformation - check reduce index Out Of Bounds,"When checking if the ""reduce"" index is out of bounds the check should be   info.mapSpillRecord.size() = reduce  instead of:  info.mapSpillRecord.size()  reduce  Not a big bug since an Out Of Bounds is thrown downstream anyway.",Resolved,Fixed,,Priyo Mustafi,Rares Vernica,Mon; 5 Jul 2010 23:02:42 +0000,Thu; 7 Apr 2011 15:40:42 +0000,Fri; 4 Feb 2011 22:18:30 +0000,,0.20.1;0.20.2;0.20.3;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1915
MAPREDUCE-1916,Bug,Minor,contrib/streaming,Usage should be added to HadoopStreaming.java,The command: bin hadoop jar streaming.jar just prints : No Arguments Given!  It should print the valid arguments also.,Resolved,Duplicate,MAPREDUCE-1911,Unassigned,Amareshwari Sriramadasu,Tue; 6 Jul 2010 10:28:18 +0000,Mon; 12 Jul 2010 09:34:27 +0000,Mon; 12 Jul 2010 09:32:28 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1916
MAPREDUCE-1917,Improvement,Major,task,Semantics of map.input.bytes is not consistent,map.input.bytes counter is updated by RecordReader. For sequence files; it is the size of the raw data; which may be compressed. For text files; it is the size of uncompressed data. For PigStorage; it is always 0. This request is to have a consistent semantics for this counter. Since HDFS_BYTES_READ already shows the raw split size read by the mapper; MAP_INPUT_BYTES should be the size of uncompressed data.,Open,Unresolved,,Arun C Murthy,Milind Bhandarkar,Tue; 6 Jul 2010 16:51:42 +0000,Tue; 6 Jul 2010 16:51:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1917
MAPREDUCE-1918,Improvement,Major,tools/rumen,Add documentation to Rumen,Add forrest documentation to Rumen tool.,Closed,Fixed,,Amar Kamat,Amar Kamat,Tue; 6 Jul 2010 18:10:17 +0000,Mon; 12 Dec 2011 06:19:08 +0000,Mon; 13 Sep 2010 05:30:59 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1918
MAPREDUCE-1919,Task,Major,test,[Herriot] Test for verification of per cache file ref  count.,It covers the following scenarios.  1. Run the job with two distributed cache files and verify whether job is succeeded or not. 2.  Run the job with distributed cache files and remove one cache file from the DFS when it is localized.verify whether the job is failed or not. 3.  Run the job with two distribute cache files and the size of  one file should be larger than local.cache.size.Verify  whether job is succeeded or not.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Tue; 6 Jul 2010 19:01:58 +0000,Mon; 27 Sep 2010 04:14:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1919
MAPREDUCE-1920,Bug,Critical,,Job.getCounters() returns null when using a cluster,Calling Job.getCounters() after the job has completed (successfully) returns null.,Closed,Fixed,,Tom White,Aaron Kimball,Tue; 6 Jul 2010 20:07:10 +0000,Fri; 29 Oct 2010 02:03:35 +0000,Thu; 12 Aug 2010 04:19:42 +0000,,0.21.0,,,MAPREDUCE-870,https://issues.apache.org/jira/browse/MAPREDUCE-1920
MAPREDUCE-1921,Improvement,Major,,IOExceptions should contain the filename of the broken input files,If bzip or other decompression fails; the IOException  does not contain the name of the broken file that caused the exception.  It would be nice if such actions could be avoided in the future by having the name of the files that are broken spelled out in the exception.,Open,Unresolved,,Krishna Ramachandran,Krishna Ramachandran,Wed; 7 Jul 2010 00:11:54 +0000,Wed; 16 Feb 2011 02:53:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1921
MAPREDUCE-1922,Improvement,Major,,Counters for data-local and rack-local tasks should be replaced by bytes-read-local and bytes-read-rack,As more and more applications use combine file input format (to reduce number of mappers); formats with columns groups implemented as different hdfs files (zebra; hbase); composite input formats (map-side joins); data-locality and rack-locality loses its meaning. (A map task reading only one column group; say 20% of its input; locally and 80% remote still gets flagged as data-local map.)  So; my suggestion is to drop these counters; and instead; replace them with HDFS_LOCAL_BYTES_READ; HDFS_RACK_BYTES_READ; and HDFS_TOTAL_BYTES_READ. These counters will make it easier to reason about read-performance for maps.,Open,Unresolved,,Arun C Murthy,Milind Bhandarkar,Wed; 7 Jul 2010 02:49:31 +0000,Wed; 7 Jul 2010 07:54:14 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1922
MAPREDUCE-1923,Improvement,Minor,examples,Support arbitrary precision in the distbbp example,The precision obtained by distbbp is limited by Java double (IEEE 754 64-bit); which has machine epsilon e=2^(-53).  When it is used to compute the 10^15 th bit of  ; only 26-bit precision with 99.9999998% confident is obtained.  (Will provide the error analysis later.)   It would be great if it supports arbitrary precision arithmetics.,Open,Unresolved,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 7 Jul 2010 03:23:43 +0000,Wed; 25 Aug 2010 22:30:53 +0000,,,,,,MAPREDUCE-637,https://issues.apache.org/jira/browse/MAPREDUCE-1923
MAPREDUCE-1924,Bug,Major,,Mappers running when reducers have finished,Occasionally; I will run jobs for which some reducers are able to finish but there are still mappers running. I understand why sometimes mappers restart themselves even after the reduce phase has begun--too many fetch-failures; for example. But in today's case; ALL of the reducers have succeeded and are done; so these mappers really ARE unnecessary...so it is a bug that they are running.  Then; I killed one of them to see what was up--it just restarted itself. So; it is another bug that mappers don't know they're unnecessary when they're killed.  My guess is that if one of these jobs; which clearly finished at least once; were to die randomly a few times; it would take the whole job with it--even though the job has completed.  Whenever all reduce tasks are complete; Hadoop should kill ALL remaining map tasks and immediately move to finish the job.,Resolved,Duplicate,MAPREDUCE-1060,Unassigned,Adam Kramer,Wed; 7 Jul 2010 22:24:46 +0000,Fri; 13 Aug 2010 23:19:20 +0000,Fri; 13 Aug 2010 23:19:20 +0000,,,,,MAPREDUCE-1060,https://issues.apache.org/jira/browse/MAPREDUCE-1924
MAPREDUCE-1925,Bug,Major,tools/rumen,TestRumenJobTraces fails in trunk,"TestRumenJobTraces failed with following error: Error Message  the gold file contains more text at line 1 expected:56 but was:0  Stacktrace  	at org.apache.hadoop.tools.rumen.TestRumenJobTraces.testHadoop20JHParser(TestRumenJobTraces. 294)  Full log of the failure is available at http: ",Closed,Fixed,,Ravi Gummadi,Amareshwari Sriramadasu,Thu; 8 Jul 2010 10:31:21 +0000,Mon; 12 Dec 2011 06:19:31 +0000,Fri; 23 Jul 2010 22:05:29 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1925
MAPREDUCE-1926,Bug,Blocker,build,MapReduce distribution is missing build-utils.xml,The tarball should be able to build itself.,Closed,Fixed,,Tom White,Tom White,Thu; 8 Jul 2010 21:47:19 +0000,Fri; 29 Oct 2010 02:03:37 +0000,Fri; 6 Aug 2010 20:37:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1926
MAPREDUCE-1927,Test,Minor,test,unit test for HADOOP-6835 (concatenated gzip support),More extensive test of concatenated gzip (and bzip2) decoding support for HADOOP-6835 (and HADOOP-4012 and HADOOP-6852).,Closed,Fixed,,Greg Roelofs,Greg Roelofs,Thu; 8 Jul 2010 21:58:10 +0000,Tue; 15 Nov 2011 00:48:06 +0000,Mon; 28 Feb 2011 05:37:17 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1927
MAPREDUCE-1928,New Feature,Major,job submission;jobtracker;tasktracker,Dynamic information fed into Hadoop for controlling execution of a submitted job,Currently the job submission protocol requires the job provider to put every bit of information inside an instance of JobConf. The submitted information includes the input data (hdfs path) ; suspected resource requirement; number of reducers etc.  This information is read by JobTracker as part of job initialization. Once initialized; job is moved into a running state. From this point; there is no mechanism for any additional information to be fed into Hadoop infrastructure for controlling the job execution.                             The execution pattern for the job looks very much static from this point. Using the size of input data and a few settings inside JobConf; number of mappers is computed. Hadoop attempts  I have worked out end-to-end.,Open,Unresolved,,Unassigned,Raman Grover,Thu; 8 Jul 2010 22:10:31 +0000,Tue; 3 Jan 2012 13:43:49 +0000,,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1928
MAPREDUCE-1929,Bug,Blocker,build,Allow artifacts to be published to the staging Apache Nexus Maven Repository,MapReduce companion issue to HADOOP-6847.,Resolved,Fixed,,Tom White,Tom White,Fri; 9 Jul 2010 10:53:29 +0000,Thu; 7 Apr 2011 15:40:46 +0000,Tue; 11 Jan 2011 19:24:43 +0000,,,,,HADOOP-6847,https://issues.apache.org/jira/browse/MAPREDUCE-1929
MAPREDUCE-1930,Bug,Major,tools/rumen,Rumen expects history file names to be in old format,Rumen expects history file names to be in old format. History file name format got changed in trunk; but Rumen is not modified to understand the new file name format. So TraceBulder is skipping processing of the new history file names. See the old patterns jobFileNameRegex and confFileNameRegex in TraceBuilder. ,Resolved,Duplicate,MAPREDUCE-1865,Ravi Gummadi,Ravi Gummadi,Mon; 12 Jul 2010 07:36:16 +0000,Mon; 12 Jul 2010 07:49:29 +0000,Mon; 12 Jul 2010 07:49:29 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1930
MAPREDUCE-1931,Improvement,Major,contrib/gridmix,Gridmix forrest documentation ,Gridmix forrest documentation,Closed,Fixed,,Ranjit Mathew,rahul k singh,Mon; 12 Jul 2010 07:48:23 +0000,Mon; 12 Dec 2011 06:18:37 +0000,Thu; 18 Nov 2010 11:23:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1931
MAPREDUCE-1932,Bug,Major,task,record skipping doesn't work with the new map/reduce api,The new HADOOP-1230 map reduce api doesn't support the record skipping features.,Resolved,Won't Fix,,Harsh J,Owen O'Malley,Wed; 17 Dec 2008 23:52:03 +0000,Mon; 19 Dec 2011 15:01:00 +0000,Sun; 18 Dec 2011 11:45:02 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1932
MAPREDUCE-1933,Test,Major,test,Improve automated testcase for tasktracker dealing with corrupted disk.,"Test ""TestCorruptedDiskJob"" was added in 0.20.203.0; to implement this test:  	After the TaskTracker has already run some tasks successfully; ""corrupt"" a disk by making the corresponding mapred.local.dir unreadable 10 01:51; but the patch was committed without these improvements nor response to them.  This bug remains open until these improvements are implemented or responded to.",Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Mon; 12 Jul 2010 08:26:49 +0000,Tue; 14 May 2013 05:14:43 +0000,,,0.20.203.0,,HADOOP-6879,,https://issues.apache.org/jira/browse/MAPREDUCE-1933
MAPREDUCE-1934,Test,Major,,Timing issue with Distributed Cache testcases for already automated (herriot ) test scenarios.,Sometimes; Distributed cache testcases fail becuse the tasktrackers dont come up fast enough after kill and start. This needs to be fixed.,Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Mon; 12 Jul 2010 09:06:47 +0000,Thu; 2 May 2013 02:29:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1934
MAPREDUCE-1935,Improvement,Major,,HFTP needs to be updated to use delegation tokens (from HDFS-1007),nan,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Mon; 12 Jul 2010 21:37:11 +0000,Mon; 12 Dec 2011 06:18:39 +0000,Mon; 19 Jul 2010 20:54:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1935
MAPREDUCE-1936,Improvement,Major,contrib/gridmix,[gridmix3] Make Gridmix3 more customizable.,"I'd like to make gridmix3 more customizable. Specifically; the proposed customizations include:  	add (random) location information for each sleep map task. 	make the parameters used in stress submission load throttling configurable.",Closed,Fixed,,Hong Tang,Hong Tang,Tue; 13 Jul 2010 00:11:47 +0000,Mon; 12 Dec 2011 06:19:51 +0000,Wed; 21 Jul 2010 19:06:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1936
MAPREDUCE-1937,Bug,Blocker,build,mvn-deployed snapshot is out of sync with trunk,"Trying to use the 0.22.0-SNAPSHOT artifacts from common; hdfs; and mapred retrieved from Apache maven in my project results in ""ClassNotFoundException: TokenStorage"". In common; ""TokenStorage"" was renamed to ""Credentials"". Building all three projects locally works  suggesting that the publicly-published mapred jar is out-of-sync with trunk",Resolved,Not A Problem,,Unassigned,Aaron Kimball,Tue; 13 Jul 2010 19:05:55 +0000,Wed; 18 Aug 2010 20:21:18 +0000,Wed; 18 Aug 2010 20:21:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1937
MAPREDUCE-1938,New Feature,Blocker,job submission;task;tasktracker,Ability for having user's classes take precedence over the system classes for tasks' classpath,It would be nice to have the ability in MapReduce to allow users to specify for their jobs alternate implementations of classes that are already defined in the MapReduce libraries. For example; an alternate implementation for CombineFileInputFormat.,Closed,Fixed,HADOOP-6942,Krishna Ramachandran,Devaraj Das,Wed; 14 Jul 2010 00:37:20 +0000,Tue; 26 Mar 2013 08:06:59 +0000,Sun; 30 Oct 2011 20:17:44 +0000,,,,PIG-2484,HADOOP-6942;MAPREDUCE-1700,https://issues.apache.org/jira/browse/MAPREDUCE-1938
MAPREDUCE-1939,Improvement,Major,task,split reduce compute phase into two threads one for reading and another for computing,it is known that  reduce task is made up of three phases: shuffle ; sort and reduce. During reduce phase; a reduce function will read a record from disk or memory first and process it to write to hdfs finally. To convert this serial progress to parallel progress ; I split the reduce phase into two threads called producer and consumer individually. producer is used to read record from disk and consumer to process the records read by the first one. I use two buffer; if  producer is writing one buffer consumer will read from another buffer.  Theoretically  there will be a overlap between this two phases so we can reduce the whole reduce time.  I wonder why hadoop does not implement it originally? Is there some potential problems for such ideas ?  I have already implemmented a prototypy. The producer just reads bytes from the disk and leaves the work of transformation to real key and value objects to consumer. The results is not good only a improvement of 13%  for time. I think it has someting with the buffer size and the time spending on different threads.Maybe the tiem spend by consumer thread is too long and the producer has to wait until the next buffer is available.,Resolved,Won't Fix,,Unassigned,wangxiaowei,Wed; 14 Jul 2010 02:59:57 +0000,Tue; 10 Mar 2015 02:53:58 +0000,Tue; 10 Mar 2015 02:53:58 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1939
MAPREDUCE-1940,Improvement,Major,tools/rumen,[Rumen] Add appropriate switches to Folder and TraceBuilder w.r.t input and output files,Currently Folder and TraceBuilder expect the input and output to be the last arguments in the command line. It would be better to add special switches to the input and output files to avoid confusion.,Open,Unresolved,,Unassigned,Amar Kamat,Wed; 14 Jul 2010 11:31:38 +0000,Mon; 23 Aug 2010 22:56:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1940
MAPREDUCE-1941,New Feature,Major,jobtracker,Need a servlet in JobTracker to stream contents of the job history file,"There is no convenient mechanism to retrieve the contents of the job history file. Need a way to retrieve the job history file contents from Job Tracker.   This can perhaps be implemented as a servlet on the Job tracker.   	Create a jsp servlet that accepts job id as a request parameter 	Stream the contents of the history file corresponding to the job id; if user has permissions to view the job details.",Resolved,Fixed,,Srikanth Sundarrajan,Srikanth Sundarrajan,Wed; 14 Jul 2010 13:56:59 +0000,Mon; 21 Jul 2014 18:14:24 +0000,Mon; 21 Jul 2014 18:14:24 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1941
MAPREDUCE-1942,Bug,Minor,build, 'compile-fault-inject' should never be called directly.,Similar to HDFS-1299: prevent calls to helper targets.,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Wed; 14 Jul 2010 18:35:49 +0000,Fri; 29 Oct 2010 02:03:20 +0000,Fri; 16 Jul 2010 20:21:52 +0000,,0.21.0,,,HDFS-1299;HADOOP-6860,https://issues.apache.org/jira/browse/MAPREDUCE-1942
MAPREDUCE-1943,Improvement,Major,,Implement limits on per-job JobConf; Counters; StatusReport; Split-Sizes,We have come across issues in production clusters wherein users abuse counters; statusreport messages and split sizes. One such case was when one of the users had 100 million counters. This leads to jobtracker going out of memory and being unresponsive. In this jira I am proposing to put sane limits on the status report length; the number of counters and the size of block locations returned by the input split.,Closed,Fixed,,Mahadev konar,Mahadev konar,Wed; 14 Jul 2010 21:13:29 +0000,Sat; 27 Apr 2013 00:29:01 +0000,Thu; 25 Aug 2011 20:18:13 +0000,,,,,MAPREDUCE-5186,https://issues.apache.org/jira/browse/MAPREDUCE-1943
MAPREDUCE-1944,Test,Major,,Not able to rum worcount test example of Map/REduce,Not able to  run Workcount test.  I get this logs  INFO mapred.FileInputFormat: Total input paths to process : 2   INFO mapred.JobClient: Task Id :  org.apache.hadoop.util.RunJar.main(RunJar. 156),Open,Unresolved,,Unassigned,diptee dalal,Thu; 15 Jul 2010 09:03:41 +0000,Thu; 15 Jul 2010 09:03:41 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1944
MAPREDUCE-1945,Improvement,Major,,Support for using different Kerberos keys for Jobtracker and TaskTrackers,This is the MapRed part of HADOOP-6632.,Closed,Fixed,,Kan Zhang,Kan Zhang,Fri; 16 Jul 2010 01:37:42 +0000,Mon; 12 Dec 2011 06:19:41 +0000,Tue; 20 Jul 2010 00:55:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1945
MAPREDUCE-1946,Improvement,Major,job submission,enhance FileInputFormat.setInputPaths(),FileInputFormat.setInputPaths(Job job; Path... inputPaths) can be enhanced in the following 3 ways: 1) when the input paths are known only  com.carrieriq.m2m.platform.mmp2.input.PackageInput.configureJobConf(PackageInput. 336)  After incorporating all three optimizations; total time taken in customized setInputPaths(JobConf conf; SetPath inputPaths) was 2 seconds. The combined time calling FileInputFormat.addInputPath() was over 80 minutes.,Open,Unresolved,,Unassigned,Ted Yu,Fri; 16 Jul 2010 03:11:51 +0000,Fri; 16 Jul 2010 03:11:51 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1946
MAPREDUCE-1947,Bug,Major,build,test-patch target for javadoc broken?,"Running ""ant  oc"" in mapreduce trunk gives following warning:   But test-patch did not complain for the patch build which introduced the warning; and it did not complain for any further builds.",Resolved,Incomplete,,Giridharan Kesavan,Amareshwari Sriramadasu,Fri; 16 Jul 2010 07:46:20 +0000,Wed; 30 Jul 2014 23:03:06 +0000,Wed; 30 Jul 2014 23:03:06 +0000,,0.22.0,,,MAPREDUCE-2315;MAPREDUCE-1762,https://issues.apache.org/jira/browse/MAPREDUCE-1947
MAPREDUCE-1948,Improvement,Major,tools/rumen,[Rumen] Use org.apache.commons.cli.CommandLineParser for parsing Rumen's cli arguments,Instead of writing a custom cli parser; its better that we use org.apache.commons.cli.CommandLineParser for parsing Rumen's arguments.,Open,Unresolved,,Ravi Gummadi,Amar Kamat,Mon; 19 Jul 2010 09:16:18 +0000,Wed; 21 Jul 2010 09:11:40 +0000,,,,,,MAPREDUCE-1949,https://issues.apache.org/jira/browse/MAPREDUCE-1948
MAPREDUCE-1949,Improvement,Major,contrib/gridmix,[Gridmix] Use org.apache.commons.cli.CommandLineParser for parsing the cli arguments,Instead of writing a custom cli parser; its better that we use CommandLineParser for the same.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 19 Jul 2010 09:18:36 +0000,Mon; 19 Jul 2010 09:19:06 +0000,,,,,,MAPREDUCE-1948,https://issues.apache.org/jira/browse/MAPREDUCE-1949
MAPREDUCE-1950,Bug,Major,tasktracker,Jetty Acceptor can stuck TaskTracker forever,"We have observed some TaskTrackers keep getting blacklisted because of ""Too many fetch-failure"" and the logs are full of the following exception. There can be lots of these exceptions in one millisecond.",Open,Unresolved,,Scott Chen,Scott Chen,Mon; 19 Jul 2010 23:09:00 +0000,Tue; 19 Jul 2011 12:25:17 +0000,,,0.20.1,,,MAPREDUCE-2386,https://issues.apache.org/jira/browse/MAPREDUCE-1950
MAPREDUCE-1951,Bug,Major,test,SecurityAuth.audit file created after every test run,After every test run; a SecurityAuth.audit file gets created in the $HADOOP_HOME folder which is not cleaned up.,Resolved,Duplicate,HADOOP-6970,Unassigned,Amar Kamat,Tue; 20 Jul 2010 07:28:24 +0000,Thu; 24 Feb 2011 19:56:17 +0000,Thu; 24 Feb 2011 19:56:17 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1951
MAPREDUCE-1952,Improvement,Major,test,Add a separate ant 'test' target for MapReduce tools,There should be some easy way to run tools tests in one go.,Resolved,Won't Fix,,Unassigned,Amar Kamat,Tue; 20 Jul 2010 09:19:43 +0000,Wed; 30 Jul 2014 23:05:32 +0000,Wed; 30 Jul 2014 23:05:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1952
MAPREDUCE-1953,Bug,Major,tools/rumen,[Rumen] Fail early if -input-cycle in not specified in Folder,The Folder code does the following    There is no point in doing other initializations if -input-cycle is not provided,Open,Unresolved,,Unassigned,Amar Kamat,Wed; 21 Jul 2010 06:39:04 +0000,Thu; 13 Jan 2011 02:28:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1953
MAPREDUCE-1954,Test,Major,test,Automate the Test scenario of Execution of jobs by original user and other users with Linux Task Controller,"Execution of streaming script ""other user""  Permission denied message  . Same user it should pass. Execution of sleep job by the other user on the cluster. Job should not pass.",Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Wed; 21 Jul 2010 11:21:05 +0000,Thu; 2 May 2013 02:29:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1954
MAPREDUCE-1955,Test,Major,test,Because of changes in JobInProgress.java; JobInProgressAspect.aj also needs to change.,Because of changes in JobInProgress.  So JobInProgressAspect.aj  also needs to change too.,Open,Unresolved,,Iyappan Srinivasan,Iyappan Srinivasan,Wed; 21 Jul 2010 11:37:44 +0000,Fri; 23 Jul 2010 18:54:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1955
MAPREDUCE-1956,Improvement,Major,tasktracker,allow reducer to initialize lazily,"From http: R job Reducers are initialized with Mappers at the job initialization; but the reduce method is called in reduce phase when all the maps had been finished. So in large jobs where Reducer loads data (100 MB for business logic) in-memory on initialization; the performance can be increased by lazily initializing Reducers i.e. loading data in reduce method controlled by an initialize flag variable which assures that it is loaded only once. By lazily initializing Reducers which require memory (for business logic) on initialization; number of maps can be increased.""  Introducing a parameter for this purpose would allow more people to utilize the above pattern.",Resolved,Invalid,,Unassigned,Ted Yu,Wed; 21 Jul 2010 17:38:01 +0000,Wed; 21 Jul 2010 22:24:07 +0000,Wed; 21 Jul 2010 22:24:07 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1956
MAPREDUCE-1957,Task,Major,test,[Herriot] Test Job cache directories cleanup after job completes.,Test the job cache directories cleanup after job completes.Test covers the following scenarios.  1. Submit a job and create folders and files in work folder with  non-writable permissions under task attempt id folder. Wait till the job completes and verify whether the files and folders are cleaned up or not.  2. Submit a job and create folders and files in work folder with  non-writable permissions under task attempt id folder. Kill the job and verify whether the files and folders are cleaned up or not.  3. Submit a job and create folders and files in work folder with  non-writable permissions under task attempt id folder. Fail the job and verify whether the files and folders are cleaned up or not.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Wed; 21 Jul 2010 18:49:20 +0000,Thu; 2 May 2013 02:29:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1957
MAPREDUCE-1958,Bug,Major,,using delegation token over hftp for long running clients (part of hdfs 1296),nan,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Thu; 22 Jul 2010 00:11:04 +0000,Mon; 12 Dec 2011 06:18:27 +0000,Tue; 3 Aug 2010 23:48:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1958
MAPREDUCE-1959,Bug,Major,job submission;security,Should use long name for token renewer on the client side,When getting a delegation token from a NN; a client needs to specify the renewer for the token. For use on a MapRed cluster; JT should be specified as the renewer. However; in the current code; the client maps JT's long name (Kerberos principal name) to cluster-internal short name and then sets the short name as the renewer. This is undesirable for 2 reasons. 1) It's unnecessary since NN (or JT) converts client-supplied renewer from long to short name anyway. 2) In principle; the mapping from long to short name should be done on the server. This is consistent with the authentication case; where the client uses the same long name to authenticate to multiple servers and servers map client's long name to their own internal short names. It facilitates using the same job client to get delegation tokens from multiple NN's; which may have different mapping rules for JT.,Open,Unresolved,,Kan Zhang,Kan Zhang,Thu; 22 Jul 2010 17:40:05 +0000,Wed; 7 Sep 2011 08:17:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1959
MAPREDUCE-1960,Improvement,Major,,Limit the size of jobconf.,In some of our production cluster users have huge job.xml's that bring down the jobtracker. THis jira is to put limit on the size of the jobconf; so that we dont blow up the memory on jobtracker.,Resolved,Fixed,,Mahadev konar,Mahadev konar,Thu; 22 Jul 2010 22:12:04 +0000,Wed; 30 Jul 2014 23:08:56 +0000,Wed; 30 Jul 2014 23:08:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1960
MAPREDUCE-1961,Bug,Major,contrib/gridmix,[gridmix3] ConcurrentModificationException when shutting down Gridmix,We observed the following exception occasionally at the end of the Gridmix run:,Closed,Fixed,,Hong Tang,Hong Tang,Fri; 23 Jul 2010 00:47:12 +0000,Mon; 12 Dec 2011 06:18:35 +0000,Thu; 12 Aug 2010 08:49:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1961
MAPREDUCE-1962,Bug,Major,test,[Herriot] IOException throws and it fails with token expired while running the tests.,Throwing IOException and tests fails due to token is expired. I could see this issue in a secure cluster.   This issue has been resolved by setting the following attribute in the configuration before running the tests. mapreduce.job.complete.cancel.delegation.tokens=false  2. Fix the timing issue in testtaskkilling test.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 23 Jul 2010 07:11:12 +0000,Mon; 27 Sep 2010 04:14:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1962
MAPREDUCE-1963,Task,Major,test,[Herriot] TaskMemoryManager should log process-tree's status while killing tasks,"1. Execute a streaming job which will increase memory usage beyond configured memory limits during mapping phase. TaskMemoryManager should logs a map task's process-tree's status just before killing the task.   2. Execute a streaming job which will increase memory usage beyond configured memory limits during reduce phase. 	TaskMemoryManager should logs a reduce task's process-tree's status just before killing the task.",Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 23 Jul 2010 07:43:48 +0000,Thu; 2 May 2013 02:29:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1963
MAPREDUCE-1964,New Feature,Major,,Running hi Ram jobs when TTs are blacklisted,More slots are getting reserved for HiRAM job tasks then required   Blacklist more than 25% TTs across the job.  Run high ram job.  No  lang.RuntimeException should be displayed.,Resolved,Fixed,,Unassigned,Balaji Rajagopalan,Fri; 23 Jul 2010 07:51:35 +0000,Wed; 30 Jul 2014 23:09:11 +0000,Wed; 30 Jul 2014 23:09:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1964
MAPREDUCE-1965,Improvement,Major,,Add info for job failure on jobtracker UI.,MAPREDUCE-1521 added a filed to jobstatus to mark reason for failures of the job. This information needs to be displayed on the jobtracker UI.,Resolved,Fixed,,Mahadev konar,Mahadev konar,Fri; 23 Jul 2010 21:18:49 +0000,Wed; 30 Jul 2014 23:09:26 +0000,Wed; 30 Jul 2014 23:09:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1965
MAPREDUCE-1966,Bug,Major,jobtracker,Fix tracker blacklisting ,The current heuristic of rolling up fixed number of job failures per tracker isn't working well; we need better design heuristics.,Open,Unresolved,,Greg Roelofs,Arun C Murthy,Fri; 23 Jul 2010 22:38:06 +0000,Mon; 23 Jul 2012 20:08:03 +0000,,,,,,MAPREDUCE-2231;MAPREDUCE-2490,https://issues.apache.org/jira/browse/MAPREDUCE-1966
MAPREDUCE-1967,Improvement,Major,,When a reducer fails on DFS quota; the job should fail immediately,Suppose an M R job has so much output th least we shouldn't have to await four failures by one task before shutting the job down.,Open,Unresolved,,Unassigned,Dick King,Sat; 24 Jul 2010 00:50:24 +0000,Mon; 26 Jul 2010 18:09:05 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1967
MAPREDUCE-1968,Task,Major,contrib/gridmix,Deprecate GridMix v1,"GridMix v2 in ""src gridmix"". The latter should be deprecated and then removed to reduce the clutter in the source-tree.  One way of doing this is shown by the ""hadoop"" script from 0.20.xx that has been deprecated in favour of ""mapred""; for example.",Resolved,Fixed,,Unassigned,Ranjit Mathew,Mon; 26 Jul 2010 03:46:27 +0000,Wed; 30 Jul 2014 23:14:02 +0000,Wed; 30 Jul 2014 23:14:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1968
MAPREDUCE-1969,New Feature,Major,contrib/raid,Allow raid to use Reed-Solomon erasure codes,Currently raid uses one parity block per stripe which corrects one missing block on one stripe. Using Reed-Solomon code; we can add any number of parity blocks to tolerate more missing blocks. This way we can get a good file corrupt probability even if we set the replication to 1.  Here are some simple comparisons: 1. No raid; replication = 3: File corruption probability = O(p^3); Storage space = 3x  2. Single parity raid with stripe size = 10; replication = 2: File corruption probability = O(p^4); Storage space = 2.2x   3. Reed-Solomon raid with parity size = 4 and stripe size = 10; replication = 1: File corruption probability = O(p^5); Storage space = 1.4x  where p is the missing block probability. Reed-Solomon code can save lots of space without compromising the corruption probability.  To achieve this; we need some changes to raid: 1. Add a block placement policy that knows about raid logic and do not put blocks on the same stripe on the same node. 2. Add an automatic block fixing mechanism. The block fixing will replace the replication of under replicated blocks. 3. Allow raid to use general erasure code. It is now hard coded using Xor. 4. Add a Reed-Solomon code implementation  We are planing to use it on the older data only. Because setting replication = 1 hurts the data locality.,Resolved,Won't Fix,,Ramkumar Vadali,Scott Chen,Mon; 26 Jul 2010 22:23:16 +0000,Tue; 1 Aug 2017 17:12:52 +0000,Tue; 1 Aug 2017 17:12:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1969
MAPREDUCE-1970,Sub-task,Major,contrib/raid,Reed-Solomon code implementation to be used in raid,A Reed-Solomon erasure code implementation.,Closed,Fixed,,Scott Chen,Scott Chen,Mon; 26 Jul 2010 22:25:34 +0000,Mon; 12 Dec 2011 06:18:30 +0000,Wed; 27 Oct 2010 06:01:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1970
MAPREDUCE-1971,New Feature,Major,,herriot automation system test case for verification of bug fix to jobhistory,Run a few jobs and check the job history page .  Job history information should be displayed properly  .  Analyze a running job . The values shown in the page should be correct .  Concurrently access jobs in job history page . No exception should be thrown.   In the developed herriot test case accesses the job tracker tracker directly; the jsp page access does the same.,Open,Unresolved,,Unassigned,Balaji Rajagopalan,Tue; 27 Jul 2010 11:03:13 +0000,Mon; 27 Sep 2010 04:14:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1971
MAPREDUCE-1972,Bug,Blocker,,TestUserLogCleanup test cant clean up the toBeDeleted,All the hudson patch test builds are failing as the Mapreduce-Patch-h4.grid.sp2.yahoo.net 2010-07-14_22-2,Resolved,Duplicate,MAPREDUCE-2238,Unassigned,Giridharan Kesavan,Tue; 27 Jul 2010 15:27:29 +0000,Mon; 10 Jan 2011 20:13:48 +0000,Mon; 10 Jan 2011 20:13:48 +0000,,,,,MAPREDUCE-2238,https://issues.apache.org/jira/browse/MAPREDUCE-1972
HDFS-1402,Improvement,Minor,,Optimize input split creation,The input split returns the locations that host the file blocks in the split. The locations are determined by the getBlockLocations method of the filesystem client which requires a remote connection to the filesystem (i.e. HDFS). The remote connection is made for each file in the entire input split. For jobs with many input files the network connections dominate the cost of writing the input split file.  A job requests a listing of the input files from the remote filesystem and creates a FileStatus object as a handle for each file in the listing. The FileStatus object can be imbued with the necessary host information on the remote end and passed to the client-side in the bulk return of the listing request. A getHosts method of the FileStatus would then return the locations for the blocks comprising that file and eliminate the need for another trip to the remote filesystem.  The INodeFile maintains the blocks for a file and is an obvious choice to be the originator for the locations of that file. It is also available to the FSDirectory which first creates the listing of FileStatus objects. We propose that the block locations be generated by the INodeFile to instantiate the FileStatus object during the getListing request.  Our tests demonstrated a factor of 2000 speedup for approximately 60;000 input files.,Open,Unresolved,,Unassigned,Paul Burkhardt,Tue; 27 Jul 2010 23:14:40 +0000,Thu; 2 May 2013 02:29:33 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/HDFS-1402
MAPREDUCE-1974,Bug,Major,contrib/fair-share,FairScheduler can preempt the same task many times,In FairScheduler.preemptTasks(); tasks are collected from JobInProgress.runningMapCache. But tasks repeat multiple times in  JobInProgress.runningMapCache (on rack; node and cluster). This makes FairScheduler preempt the same task many times.,Closed,Fixed,,Scott Chen,Scott Chen,Tue; 27 Jul 2010 23:36:00 +0000,Mon; 12 Dec 2011 06:19:42 +0000,Fri; 4 Feb 2011 22:57:33 +0000,,0.21.0;0.21.1;0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1974
MAPREDUCE-1975,Bug,Major,contrib/gridmix,gridmix shows unnecessary InterruptedException,The following InterruptedException is seen when gridmix is run and it ran successfully:    INFO gridmix.Gridmix: Exiting...,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 28 Jul 2010 06:36:10 +0000,Mon; 12 Dec 2011 06:19:45 +0000,Tue; 7 Sep 2010 03:47:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1975
MAPREDUCE-1976,Bug,Major,jobtracker,Inconsistency in logging hostnames to JobHistory,JobHistory line for successful task-attempts store tracker-name (i.e  xyz.com:1234) for the hostname field while unsuccessful task-attempts store only the hostname (i.e xyz.com).,Resolved,Duplicate,MAPREDUCE-3349,Unassigned,Amar Kamat,Wed; 28 Jul 2010 08:03:00 +0000,Tue; 8 Nov 2011 05:45:56 +0000,Tue; 8 Nov 2011 05:45:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1976
MAPREDUCE-1977,Improvement,Major,tools/rumen,[Rumen] Do Not Store CDFs in Output JSON Files,Per-Job Cumulative Distribution Functions (CDFs) stored in JSON files emitted by Rumen are redundant and waste space (~30%). They can easily be re-computed upon loading or just-in-time upon request.,Open,Unresolved,,Amar Kamat,Ranjit Mathew,Wed; 28 Jul 2010 10:00:12 +0000,Wed; 28 Jul 2010 10:01:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1977
MAPREDUCE-1978,Improvement,Major,tools/rumen,[Rumen] TraceBuilder should provide recursive input folder scanning,Currently; TraceBuilder assumes that the input is either jobhistory files or a folders containing jobhistory files directly underneath the specified folder. There could be a use cases where the input folder could contain sub-folders containing jobhistory files. Rumen should support such input folders.,Closed,Fixed,,Ravi Gummadi,Amar Kamat,Wed; 28 Jul 2010 10:23:31 +0000,Tue; 15 Nov 2011 00:49:58 +0000,Mon; 2 May 2011 09:30:25 +0000,,,,,MAPREDUCE-323,https://issues.apache.org/jira/browse/MAPREDUCE-1978
MAPREDUCE-1979,Bug,Major,contrib/gridmix,Output directory already exists error in gridmix when gridmix.output.directory is not defined,Output directory already exists error is seen in gridmix when gridmix.output.directory is not defined. When gridmix.output.directory is not defined; then gridmix uses inputDir  and thus the same issue.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 28 Jul 2010 11:40:13 +0000,Mon; 12 Dec 2011 06:19:09 +0000,Mon; 13 Sep 2010 05:03:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1979
MAPREDUCE-1980,Bug,Major,,TaskAttemptUnsuccessfulCompletionEvent.java incorrectly logs MAP_ATTEMPT_KILLED as event type for reduce tasks,TaskAttemptUnsuccessfulCompletionEvent is used to log unsuccessful map and reduce task attempts to JobHistory. Following is the implementation of getEventType() method of TaskAttemptUnsuccessfulCompletionEvent      public EventType getEventType()  {     return EventType.MAP_ATTEMPT_KILLED;   },Closed,Fixed,,Amar Kamat,Amar Kamat,Wed; 28 Jul 2010 13:12:26 +0000,Thu; 7 Apr 2011 15:40:52 +0000,Mon; 16 Aug 2010 06:24:13 +0000,,,,,MAPREDUCE-1876,https://issues.apache.org/jira/browse/MAPREDUCE-1980
MAPREDUCE-1981,Improvement,Major,job submission,Improve getSplits performance by using listLocatedStatus,This jira will make FileInputFormat and CombinedFileInputForm to use the new API; thus reducing the number of RPCs to HDFS NameNode.,Closed,Fixed,,Hairong Kuang,Hairong Kuang,Wed; 28 Jul 2010 21:17:06 +0000,Tue; 20 Jan 2015 21:36:09 +0000,Fri; 26 Jul 2013 18:23:53 +0000,,0.23.0,,HDFS-202,MAPREDUCE-6219;MAPREDUCE-5603,https://issues.apache.org/jira/browse/MAPREDUCE-1981
MAPREDUCE-1982,Bug,Major,tools/rumen,[Rumen] TraceBuilder's output shows jobname as NULL for jobhistory files with valid jobnames,TraceBuilder fails to extract configuration properties (like job-name) from the job-conf if the job-conf has the properties stored using the deprecated keys.,Closed,Fixed,,Ravi Gummadi,Amar Kamat,Thu; 29 Jul 2010 08:31:26 +0000,Mon; 12 Dec 2011 06:19:37 +0000,Tue; 3 Aug 2010 05:49:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1982
MAPREDUCE-1983,Task,Major,test,[Herriot] Test linux task controller with invalid information in conf.,This case is about scenarios where the taskcontroller file is absent; or contains incorrect values for mapred.local.dir.Submit a job and verify whether job fails or not.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Thu; 29 Jul 2010 09:59:59 +0000,Mon; 27 Sep 2010 04:14:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1983
MAPREDUCE-1984,Bug,Major,,herriot TestCluster fails because exclusion is not there,restart is part of the test case which causes ioexceptions; and this needs to be ignored. The test case should not be incorrectly failed.,Resolved,Fixed,,Balaji Rajagopalan,Balaji Rajagopalan,Thu; 29 Jul 2010 10:17:48 +0000,Fri; 29 Oct 2010 02:04:28 +0000,Mon; 27 Sep 2010 04:28:47 +0000,,0.21.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1984
MAPREDUCE-1985,Bug,Major,jobtracker,java.lang.ArrayIndexOutOfBoundsException in analysejobhistory.jsp of jobs with 0 maps,This is Yahoo bug #3460762 included in ydist; but couldn't find a public JIRA for it. Uploading patch from YDH in case anyone else has run into this on the 0.20 branch.,Resolved,Won't Fix,,Unassigned,Todd Lipcon,Fri; 30 Jul 2010 01:46:36 +0000,Mon; 2 Aug 2010 10:08:06 +0000,Fri; 30 Jul 2010 01:48:18 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1985
MAPREDUCE-1986,Bug,Major,jobtracker,History files fail to move to DONE folder when hadoop.job.history.location is configured to a HDFS path,When hadoop.job.history.location is configured to a HDFS path and when the job retires; the history files are never moved to mapred.job.tracker.history.completed.location and they remain forever in hadoop.job.history.location . The jobhistory is never viewable thereafter.,Resolved,Duplicate,MAPREDUCE-2463,Unassigned,Ramya Sunil,Fri; 30 Jul 2010 04:40:04 +0000,Mon; 18 Jul 2011 04:35:36 +0000,Fri; 15 Jul 2011 17:06:25 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1986
MAPREDUCE-1987,Bug,Major,,"No verification on sample size can lead to incorrect partition file and ""Split points are out of order"" IOException","If I understand correctly; the partition file should containt distinct values in increasing order. In InputSampler.writePartitionFile (...)  if  the sample size is lower than the number of reduce size; the k index might keep the same value. As a side effet of the while loop; values will be interleaved.  Example : taking 100 samples on a 120 reducers job will produce the following values of k and last after the while loop      while (last = k &amp; comparator.compare(sampleslast; samplesk) == 0)  {         ++k;       }       incorrect; samples69 has already been written           The partition file will be considered as corrupted when reading it  with the TotalOrderPartitioner:    throw new IOException(""Split points are out of order"");  It seems to me that the number of partitions should be min(samples.length;  job.getNumReduceTasks(); number of distinct values in sample)",Open,Unresolved,,Unassigned,Fabrice Huet,Fri; 30 Jul 2010 16:09:02 +0000,Fri; 30 Jul 2010 16:09:02 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1987
MAPREDUCE-1988,Improvement,Major,jobtracker,We would like more information to be available in job history index,"So far; people have requested:   	completion state 	start time 	end time 	job name    be available from an index record  Please make additional requests here.",Resolved,Incomplete,,Unassigned,Dick King,Fri; 30 Jul 2010 22:13:52 +0000,Wed; 30 Jul 2014 23:15:19 +0000,Wed; 30 Jul 2014 23:15:19 +0000,,,,MAPREDUCE-323,,https://issues.apache.org/jira/browse/MAPREDUCE-1988
MAPREDUCE-1989,Bug,Major,contrib/gridmix,Gridmix3 doesn't emit out proper mesage when user resolver is set and no user list is given,"Currently; Gridmix3 emits out the following mesage when user resolver is set and no user list is given. ""Resource null ignored"". This is not clear meaningful to user.",Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 2 Aug 2010 11:43:14 +0000,Mon; 12 Dec 2011 06:18:56 +0000,Mon; 27 Sep 2010 07:16:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1989
MAPREDUCE-1990,Bug,Major,tools/rumen,[Rumen] TraceBuilder should ignore jobs with no jobhistory file,TraceBuilder will generate output for job having its job-conf in the jobhistory folder but no jobhistory file. Job-trace for a job with missing jobhistory file is pretty useless and contains junk information.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 2 Aug 2010 20:55:56 +0000,Thu; 13 Jan 2011 02:27:54 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1990
MAPREDUCE-1991,Bug,Major,task-controller,taskcontroller allows stealing permissions on any local file,The linux task-controller setuid binary allows a malicious user to chmod any file on the system to 644 (and as a side effect appends some junk to the end),Resolved,Invalid,,Todd Lipcon,Todd Lipcon,Tue; 3 Aug 2010 02:23:15 +0000,Thu; 20 Oct 2011 22:30:48 +0000,Thu; 20 Oct 2011 22:30:48 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1991
MAPREDUCE-1992,Bug,Major,jobtracker,NPE in JobTracker's constructor,On my local machine; JobTracker is not coming up with current trunk. Logs show the following NPE:  2010-08-03 14:01:41;449 FATAL org.apache.hadoop.mapred.JobTracker:  4236)  2010-08-03 14:01:41;449 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG:,Closed,Fixed,,Kan Zhang,Ravi Gummadi,Tue; 3 Aug 2010 08:30:40 +0000,Mon; 12 Dec 2011 06:18:53 +0000,Thu; 12 Aug 2010 10:01:24 +0000,,0.22.0,,,HADOOP-6912,https://issues.apache.org/jira/browse/MAPREDUCE-1992
MAPREDUCE-1993,Bug,Major,,TestTrackerDistributedCacheManagerWithLinuxTaskController fails on trunk,TestTrackerDistributedCacheManagerWithLinuxTaskController fails when run with the DefaultTaskController.,Closed,Fixed,,Devaraj Das,Devaraj Das,Wed; 4 Aug 2010 06:09:01 +0000,Mon; 12 Dec 2011 06:19:15 +0000,Wed; 4 Aug 2010 13:18:02 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1993
MAPREDUCE-1994,Bug,Major,security;task-controller,Linux task-controller determines its own path insecurely,"The task-controller uses argv0 to determine its own path; and then calls stat() on that. Instead it should stat("" exe"") directly. This is important since argv0 can be spoofed to point to another program and thus either fool the autodetection of HADOOP_HOME or evade various permissions checks.",Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 4 Aug 2010 22:40:20 +0000,Wed; 30 Jul 2014 23:21:23 +0000,Wed; 30 Jul 2014 23:21:23 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1994
MAPREDUCE-1995,Improvement,Major,contrib/fair-share,FairScheduler can wait for JobInProgress lock while holding JobTracker lock,Here is the related code path.,Resolved,Invalid,,Scott Chen,Scott Chen,Thu; 5 Aug 2010 01:47:43 +0000,Thu; 5 Aug 2010 01:59:33 +0000,Thu; 5 Aug 2010 01:59:33 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1995
MAPREDUCE-1996,Bug,Trivial,documentation,API: Reducer.reduce() method detail misstatement,"method detail for Reducer.reduce() method has paragraph starting:  ""Applications can use the Reporter  provided to report progress or just indicate that they are alive. In scenarios where the application takes an insignificant amount of time to process individual key ",Closed,Fixed,,Harsh J,Glynn Durham,Thu; 5 Aug 2010 17:05:31 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Mon; 28 Feb 2011 05:26:14 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1996
MAPREDUCE-1997,Improvement,Major,examples,Add options to inject task failures in SleepJob for testing,Seems to be a reasonable way to do cluster wide (manual) testing for jobtracker scheduler features such as MAPREDUCE-339,Open,Unresolved,,Luke Lu,Luke Lu,Thu; 5 Aug 2010 21:44:26 +0000,Thu; 13 Jan 2011 02:29:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1997
MAPREDUCE-1998,New Feature,Major,capacity-sched,Size-based queuing for capacity scheduler,On job submission; it would be useful if the capacity scheduler could pick a queue based on the # of maps and reduces.  This way one could have queues based on job-size without users having to pick the queue prior to submission.,Resolved,Won't Fix,,Krishna Ramachandran,Allen Wittenauer,Fri; 6 Aug 2010 19:33:35 +0000,Wed; 2 Nov 2011 17:39:59 +0000,Wed; 2 Nov 2011 17:39:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1998
MAPREDUCE-1999,Bug,Major,,ClientProtocol incorrectly uses hdfs DelegationTokenSelector,ClientProtocol in MR incorrectly uses the DelegationTokenSelector in hdfs due to a wrong import. It should use the DelegationTokenSelector in mapreduce.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Fri; 6 Aug 2010 19:49:56 +0000,Mon; 12 Dec 2011 06:19:21 +0000,Mon; 9 Aug 2010 20:46:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-1999
MAPREDUCE-2000,Bug,Major,tools/rumen,Rumen is not able to extract counters for Job history logs from Hadoop 0.20,"Rumen tries to match the end of a value string through indexOf("" """"). It does not take into account the case when an escaped '""' in the value string. This leads to the incorrect parsing the remaining key=value properties in the same line.",Closed,Fixed,,Hong Tang,Hong Tang,Fri; 6 Aug 2010 23:04:48 +0000,Mon; 12 Dec 2011 06:19:35 +0000,Thu; 12 Aug 2010 09:14:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2000
MAPREDUCE-2001,Improvement,Minor,,Enhancement to SequenceFileOutputFormat to allow user to set MetaData,The org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputForm to make this solution work.),Open,Unresolved,,Unassigned,David Rosenstrauch,Mon; 9 Aug 2010 17:51:05 +0000,Wed; 17 Oct 2012 04:01:12 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2001
MAPREDUCE-2002,Bug,Minor,contrib/mrunit,MRUnit driver classes should provide ability to set a configuration object to be passed into the mapper/reducer,"Short description:  Enhance the org.apache.hadoop.mrunit.mapreduce.MapDriver; ReduceDriver; and MapReduceDriver unit test driver classes to contain ""setConfiguration"" and ""withConfiguration"" methods for passing in user-supplied org.apache.hadoop.conf.Configuration objects; and have those configuration objects eventually get passed on to the Context objects th is not too difficult to fix in the MRUnit framework code; however; and would greatly help the usability of MRUnit.   Although I don't have time to code this enhancement right now; if needed preferred I could squeeze out some time to code up a patch for this.  If that's needed; please let me know.",Open,Unresolved,MRUNIT-86;MAPREDUCE-1569,Unassigned,David Rosenstrauch,Wed; 11 Aug 2010 02:43:39 +0000,Thu; 15 Mar 2012 07:47:26 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2002
MAPREDUCE-2003,Improvement,Major,tasktracker,It should be able to specify different jvm settings for map and reduce child process (via mapred.child.map.java.opts and mapred.child.reduce.java.opts options) ,Sometimes mapper child process requires different JVM settings than reducer. For example when mapper requires much more memory than reducer. Now it's only possible to set options for both using mapred.child. opts. Thus; we're adding more flexibility and compatibility with old configurations.  The same should be done for mapred.child.env.,Closed,Duplicate,MAPREDUCE-1207;MAPREDUCE-478,Unassigned,Vladimir Klimontovich,Wed; 11 Aug 2010 12:11:52 +0000,Tue; 24 Aug 2010 21:21:52 +0000,Wed; 18 Aug 2010 20:47:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2003
MAPREDUCE-2004,Bug,Minor,jobtracker,IP address vs host name in updating Counter.DATA_LOCAL_MAPS,"Hello;   I set ""mapred.task.cache.levels"" to 1 so th the data-local-maps counter does not take this into consideration.  Cheers; Rares",Open,Unresolved,,Unassigned,Rares Vernica,Wed; 11 Aug 2010 17:18:39 +0000,Wed; 11 Aug 2010 17:18:39 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2004
MAPREDUCE-2005,Bug,Major,,TestDelegationTokenRenewal fails,"looks like the problem is in host resolution. test is using ""localhost:0""; but in DelegationTokenRenewal we use getCannonicalName() for localhost; and on some machine it is not ""localhost"" Fix - change test to use getCannonicalName too.",Open,Unresolved,,Boris Shkolnik,Boris Shkolnik,Wed; 11 Aug 2010 18:57:10 +0000,Thu; 12 Aug 2010 21:02:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2005
MAPREDUCE-2006,Bug,Major,contrib/gridmix,Gridmix can emit better error messages instead of throwing Exceptions,Gridmix throws Exceptions (including those that come from mapreduce jobs) when there are some issues like (1) ioPath already exists and -generate option is given (2) when -generate option is given; ioPath (a) doesn't exist (b) exists but with wrong permissions (3) gridmix.output.directory path already exists (4) gridmix.min.file.size is  the size specified as option to -generate etc.  These can be validated early and provide proper error messages to the user of gridmix.,Resolved,Incomplete,,Unassigned,Ravi Gummadi,Thu; 12 Aug 2010 10:51:00 +0000,Wed; 30 Jul 2014 23:26:43 +0000,Wed; 30 Jul 2014 23:26:43 +0000,,,,,MAPREDUCE-3829,https://issues.apache.org/jira/browse/MAPREDUCE-2006
MAPREDUCE-2007,Improvement,Major,,Is it possible that use ArrayList or other type  instead Iterable  when use reduce(Object; Iterable; Context)?,1) Sometimes We only need get the elements count of the input values of Reducer task;  but we have to iterate all the input values to calculate it.  2) Sometimes We only need get a few elements (for example top n;last n ;or random ) from  the input values of Reducer task;  if it can use ArrayList or other type  instead Iterable  when use reduce(Object; Iterable; Context);it 's more conveniency.,Resolved,Won't Fix,,Unassigned,Han Hui Wen,Thu; 12 Aug 2010 15:56:16 +0000,Thu; 12 Aug 2010 18:02:31 +0000,Thu; 12 Aug 2010 18:02:31 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2007
MAPREDUCE-2008,New Feature,Minor,examples;test,write Junit test cases that run the Hadoop examples,I will be adding junit test cases that run the hadoop examples; specifically I'll be adding a test suite that tests everything under the src examples package.  Since this is my first contribution to the project I'll need some help to figure out how to submit this,Open,Unresolved,,Unassigned,Saikat Kanjilal,Thu; 29 Jul 2010 22:40:23 +0000,Thu; 13 Jan 2011 02:28:47 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2008
MAPREDUCE-2009,Bug,Major,contrib/gridmix,GridMix hangs forever if there is no tasktracker running in the cluster.,Suppose if user submit a GridMix job in a cluster. However; there are no task trackers running in the cluster; in this case the GridMix is hanging forever at JobMonitor. Please make sure to exit the job with appropriate message after specified amount of time instead of waiting forever.,Resolved,Incomplete,,Amar Kamat,Vinay Kumar Thota,Fri; 13 Aug 2010 05:40:38 +0000,Wed; 30 Jul 2014 23:28:58 +0000,Wed; 30 Jul 2014 23:28:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2009
MAPREDUCE-2010,Improvement,Major,tools/rumen,[Rumen] Parallelize TraceBuilder,"Currently; Rumen's TraceBuilder processes jobs in sequential manner and emits them in sorted order (based on job-id). Following are the steps :  	Read data from input files 	Parse and analyze the JobHistory data 	Write the data to the output file    Steps #1 and #2 can be done in parallel. Step #3 can be made sequential (if user needs it) else can also be done in parallel.   I could achieve ~50% speedup by simply parallelizing step#1 and step#2 (i.e output was sorted based on job-id).",Open,Unresolved,,Amar Kamat,Amar Kamat,Fri; 13 Aug 2010 11:20:38 +0000,Thu; 13 Jan 2011 02:29:07 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2010
MAPREDUCE-2011,Improvement,Major,distributed-cache,Reduce number of getFileStatus call made from every task(TaskDistributedCache) setup,On our cluster; we had jobs with 20 dist cache and very short-lived tasks resulting in 500 map tasks launched per second resulting in  10;000 getFileStatus calls to the namenode.  Namenode can handle this but asking to see if we can reduce this somehow.,Resolved,Won't Fix,,Unassigned,Koji Noguchi,Sat; 14 Aug 2010 00:09:54 +0000,Mon; 11 Jan 2016 17:18:19 +0000,Mon; 11 Jan 2016 17:18:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2011
MAPREDUCE-2012,Bug,Blocker,test,Some contrib tests fail in branch 0.21 and trunk,After the commit of MAPREDUCE-1920; some contrib tests such as TestStreamingStatus; TestStreamingTaskLog and etc. are timing out.,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Sat; 14 Aug 2010 09:19:19 +0000,Fri; 29 Oct 2010 02:03:16 +0000,Sun; 15 Aug 2010 05:35:42 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2012
MAPREDUCE-2013,Improvement,Major,,Enhance the JobHistory testcases to check event-types,Lately; we have seen 2 JobHistory bugs (MAPREDUCE-1876 and MAPREDUCE-1980). Ideally; the JobHistory testcases should have caught it. Maybe its the right time to rethink on how to (re-)factor and re-write the testcases better.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 16 Aug 2010 06:37:32 +0000,Thu; 13 Jan 2011 02:29:26 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2013
MAPREDUCE-2014,Bug,Major,security,Remove task-controller from 0.21 branch,nan,Closed,Fixed,,Tom White,Tom White,Mon; 16 Aug 2010 18:33:52 +0000,Tue; 29 Nov 2011 09:20:16 +0000,Tue; 17 Aug 2010 04:45:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2014
MAPREDUCE-2015,Bug,Major,contrib/gridmix,GridMix always throws an FileAlreadyExistsException even ouput directory is not available in HDFS.,Gridmix always throws an FileAlreadyExistsException even ouput directory is not available in HDFS. Actually I was launching the Gridmix in a command line for generating the data; before launching I just make sure the output directory is not available in the HDFS by deleting the folder if already exists.However; I could see output directory already exists exception every time. Please see the attached logs for more information.,Resolved,Duplicate,MAPREDUCE-1979,Ranjit Mathew,Vinay Kumar Thota,Tue; 17 Aug 2010 04:37:37 +0000,Tue; 5 Aug 2014 15:24:49 +0000,Tue; 17 Aug 2010 05:39:54 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2015
MAPREDUCE-2016,Bug,Major,contrib/gridmix,GridMix throws an ArithmeticException error when tasktracker count is zero while generating the data.,GridMix throws an ArithmeticException error when tasktracker count is zero. In generating data; while calculating the bytes per task tracker in getSplit method; throws an exception if tasktracker count is zero. Actually bytes are calculating by dividing the number of task trackers in the cluster. So we need to build the better exception handling for these kinds of cases. Should add a condition (count should be 0) for tasktracker count before calculating the bytes per tasktracker.     INFO gridmix.JobSubmitter:  Job org.apache.hadoop.mapreduce.Job@18a8ce2 submission failed   619),Resolved,Incomplete,,Amar Kamat,Vinay Kumar Thota,Tue; 17 Aug 2010 10:24:30 +0000,Wed; 30 Jul 2014 23:31:30 +0000,Wed; 30 Jul 2014 23:31:30 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2016
MAPREDUCE-2017,New Feature,Major,capacity-sched,Move jobs between queues post-job submit,It would be massively useful to be able to move a job between queues after it has already been submitted.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 17 Aug 2010 18:52:27 +0000,Wed; 2 Nov 2011 17:39:32 +0000,Wed; 2 Nov 2011 17:39:32 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2017
MAPREDUCE-2018,Bug,Major,examples,TeraSort example fails in trunk,Exceptions are thrown while computing splits near the end of file - typically when the number of bytes read is smaller than RECORD_LENGTH    INFO input.FileInputFormat: Total input paths to process : 1 Spent 19ms computing base-splits. Spent 2ms computing TeraScheduler splits. Computing input splits took 22ms Sampling 1 splits of 1 Got an exception while reading splits  181)  TeraInoutFormat I believe assumes the file sizes are exact multiples of RECORD_LENGTH,Resolved,Fixed,,Unassigned,Krishna Ramachandran,Tue; 17 Aug 2010 22:52:42 +0000,Wed; 30 Jul 2014 23:31:56 +0000,Wed; 30 Jul 2014 23:31:56 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2018
MAPREDUCE-2019,Task,Major,contrib/gridmix,Add  targets for gridmix unit and system tests in a gridmix build xml file.,Add the targets for both unit and system tests in gridmix build xml (src build.xml). The target name for system tests would be 'test-system' and same way the target name for unit tests would be 'test'.,Resolved,Incomplete,,Vinay Kumar Thota,Vinay Kumar Thota,Wed; 18 Aug 2010 10:09:00 +0000,Wed; 30 Jul 2014 23:33:12 +0000,Wed; 30 Jul 2014 23:33:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2019
MAPREDUCE-2020,Improvement,Major,,Use new FileContext APIs for all mapreduce components ,Migrate mapreduce components to using improved FileContext APIs implemented in  HADOOP-4952 and  HADOOP-6223,Open,Unresolved,,Krishna Ramachandran,Krishna Ramachandran,Fri; 20 Aug 2010 00:09:10 +0000,Mon; 28 Feb 2011 06:03:51 +0000,,,0.22.0,,HADOOP-7000;HADOOP-6999,,https://issues.apache.org/jira/browse/MAPREDUCE-2020
MAPREDUCE-2021,Bug,Major,client,CombineFileInputFormat returns duplicate  hostnames in split locations,CombineFileInputFormat.getSplits creates splits with duplicate locations. It adds locations of the files in the split to an ArrayList; if all the files are on same location; the location is added again and again. Instead; it should add it to a Set instead of List to avoid duplicates.,Closed,Fixed,MAPREDUCE-4593,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 20 Aug 2010 04:21:32 +0000,Thu; 2 May 2013 02:30:53 +0000,Thu; 2 Sep 2010 07:31:07 +0000,,0.20.2,,,HIVE-3387,https://issues.apache.org/jira/browse/MAPREDUCE-2021
MAPREDUCE-2022,Bug,Blocker,test,trunk build broken,Trunk compilation fails with following errors:                     ^  This is due to commit of HDFS-202,Closed,Fixed,,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 20 Aug 2010 08:22:13 +0000,Mon; 12 Dec 2011 06:19:33 +0000,Fri; 20 Aug 2010 11:33:33 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2022
MAPREDUCE-2023,Bug,Major,benchmarks,TestDFSIO read test may not read specified bytes.,TestDFSIO's read test may read less bytes than specified when reading large files.,Closed,Fixed,,Hong Tang,Hong Tang,Fri; 20 Aug 2010 09:24:51 +0000,Mon; 12 Dec 2011 06:19:02 +0000,Fri; 3 Sep 2010 01:13:35 +0000,,,,,HDFS-1338,https://issues.apache.org/jira/browse/MAPREDUCE-2023
MAPREDUCE-2024,Bug,Minor,jobtracker,5th JobTracker constructor (for simulator) uses outdated configs; duplicates code,"The fifth JobTracker constructor (JobTracker(final JobConf conf; Clock clock; boolean ignoredForSimulation)) still uses the old ""mapred.*"" config settings and appears to duplicate much of the code in the fourth (main) ctor.  It should be modernized and; ideally; share as much code as possible with the main one in order to minimize simulation drift and the potential for config errors.",Resolved,Duplicate,MAPREDUCE-1001,Unassigned,Greg Roelofs,Fri; 20 Aug 2010 23:50:00 +0000,Fri; 3 Sep 2010 19:31:52 +0000,Fri; 3 Sep 2010 19:31:52 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2024
MAPREDUCE-2025,Improvement,Major,client;jobtracker;task,Improve job counter wire protocol with incremental schema and delta values,The current job counter protocol is quite verbose (string key and vlong value pairs) especially when keys are long. By using an incremental schema (key to key id mapping) and data (vint key id to vlong value delta) protocol; we can significantly lower the counter overhead and allow us to up (from the current 1 update hdfs etc) counter improvement is tracked by MAPREDUCE-901 (a more common case with more optimization opportunities; as the schema is fixed.),Open,Unresolved,,Luke Lu,Luke Lu,Sat; 21 Aug 2010 01:32:37 +0000,Thu; 13 Jan 2011 02:29:03 +0000,,,0.20.2,,,MAPREDUCE-901,https://issues.apache.org/jira/browse/MAPREDUCE-2025
MAPREDUCE-2026,Improvement,Major,,JobTracker.getJobCounters() should not hold JobTracker lock while calling JobInProgress.getCounters(),JobTracker.getJobCounter() will lock JobTracker and call JobInProgress.getCounters(). JobInProgress.getCounters() can be very expensive because it aggregates all the task counters. We found that from the JobTracker jstacks that this method is one of the bottleneck of the JobTracker performance.  JobInProgress.getCounters() should be able to be called out side the JobTracker lock because it already has JobInProgress lock. For example; it is used by jobdetails.jsp without a JobTracker lock.,Closed,Fixed,MAPREDUCE-2114,Joydeep Sen Sarma,Scott Chen,Sat; 21 Aug 2010 03:40:33 +0000,Tue; 15 Nov 2011 00:48:39 +0000,Thu; 3 Feb 2011 20:01:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2026
MAPREDUCE-2027,Bug,Major,contrib/fair-share,fair share scheduler causes unnecessary preemption under some conditions,When the cluster hits speculative cap - JobInProgress does not speculate any more. however FairShare Scheduler continues to believe that tasks need to be speculated.  Under such conditions; FS Scheduler will start preempting repeatedly (because from it's perspective - certain jobs are not getting the slots they deserve (for speculative tasks)).  There may be other reasons for excessive preemption as well - this one stood out clearly.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Mon; 23 Aug 2010 21:24:16 +0000,Thu; 26 Aug 2010 21:48:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2027
MAPREDUCE-2028,Bug,Major,contrib/streaming,streaming should support MultiFileInputFormat,There should be a way to call MultiFileInputFormat from streaming without having to write Java code...,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 24 Aug 2010 22:48:28 +0000,Wed; 2 Nov 2011 17:39:02 +0000,Wed; 2 Nov 2011 17:39:02 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2028
MAPREDUCE-2029,Bug,Major,contrib/raid,DistributedRaidFileSystem not removed from cache on close(),When DistributedRaidFileSystem.close() is called; it does not remove itself from the FileSystem cache; but it does close the underlying filesystem; e.g. DFS.  Because the DRFS with the closed DFS is still in the cache; calling FileSystem.get() returns a stale DRFS that throws 'filesystem closed' exceptions.,Closed,Fixed,,Ramkumar Vadali,Paul Yang,Wed; 25 Aug 2010 00:32:09 +0000,Mon; 12 Dec 2011 06:19:26 +0000,Thu; 30 Sep 2010 13:09:03 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2029
MAPREDUCE-2030,Bug,Major,contrib/gridmix,Throwing IOException while submitting the gridmix jobs consecutively through ToolRunner.,Gridmix throws an IOException while submitting the Gridmix jobs consecutively through ToolRunner. For first job its works fine and for next job onwards; it throws the below exception.      junit  io.IOException: Stream closed,Resolved,Invalid,,Ranjit Mathew,Vinay Kumar Thota,Wed; 25 Aug 2010 08:17:04 +0000,Tue; 31 Aug 2010 06:33:14 +0000,Tue; 31 Aug 2010 06:33:14 +0000,,,,MAPREDUCE-2033,,https://issues.apache.org/jira/browse/MAPREDUCE-2030
MAPREDUCE-2031,Bug,Major,tasktracker;test,TestTaskLauncher and TestTaskTrackerLocalization fail with NPE in trunk.,TestTaskLauncher and TestTaskTrackerLocalization fail in trunk after the commit of MAPREDUCE-1881 with NPE:       NPE happens because taskTracker.myInstrumentation is not initialized.,Closed,Fixed,,Ravi Gummadi,Amareshwari Sriramadasu,Wed; 25 Aug 2010 08:49:03 +0000,Mon; 12 Dec 2011 06:18:47 +0000,Mon; 6 Sep 2010 03:39:03 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2031
MAPREDUCE-2032,Bug,Major,task,TestJobOutputCommitter fails in ant test run,"TestJobOutputCommitter fails in a ""ant test"" run with following exception :   But it passes when it is run individually.",Closed,Fixed,,Dick King,Amareshwari Sriramadasu,Wed; 25 Aug 2010 09:18:39 +0000,Mon; 12 Dec 2011 06:19:44 +0000,Wed; 8 Sep 2010 09:40:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2032
MAPREDUCE-2033,Task,Major,contrib/gridmix,[Herriot] Gridmix generate data tests with various submission policies and different user resolvers.,Tests for submitting and verifying the gridmix generate input data in different submission policies and various user resolver modes. It covers the following scenarios.  1. Generate the data in a STRESS submission policy with SubmitterUserResolver mode and verify whether the generated data matches with given size of input or not. 2. Generate the data in a REPLAY submission policy with RoundRobinUserResolver mode and verify whether the generated data matches with the given input size or not. 3. Generate the data in a SERIAL submission policy with EchoUserResolver mode and specify the no.of bytes per file. Verify whether each file size is matches with given per file size or not and also verify the overall size of generated data.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Wed; 25 Aug 2010 09:50:19 +0000,Tue; 15 Nov 2011 00:48:20 +0000,Wed; 15 Jun 2011 11:06:39 +0000,,,gridmix;system-tests,MAPREDUCE-2030,,https://issues.apache.org/jira/browse/MAPREDUCE-2033
MAPREDUCE-2034,Test,Trivial,test,TestSubmitJob triggers NPE instead of permissions error,TestSubmitJob.testSecureJobExecution catches any IOException and assumes a permissions error has been caught. In fact; it was passing an invalid path name to the NameNode and triggering an NPE; not a Permission denied error; in one case; but the test was not specific enough to detect this.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 25 Aug 2010 21:20:14 +0000,Thu; 7 Apr 2011 15:40:42 +0000,Wed; 10 Nov 2010 19:43:07 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2034
MAPREDUCE-2035,Improvement,Minor,task-controller,Enable -Wall and fix warnings in task-controller build,Enabling -Wall shows a bunch of warnings. We should enable them and then fix them.,Resolved,Won't Fix,,Todd Lipcon,Todd Lipcon,Fri; 27 Aug 2010 00:27:12 +0000,Wed; 7 Sep 2011 08:16:52 +0000,Wed; 7 Sep 2011 08:16:52 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2035
MAPREDUCE-2036,Improvement,Minor,contrib/raid;harchive,Enable Erasure Code in Tool similar to Hadoop Archive,Features: 1) HAR-like Tool 2) RAID5 RAID6  pluggable interface to implement additional coding 3) Enable to group blocks across files 4) Portable across cluster since all necessary metadata is embedded  While it was developed separately from HAR or RAID due to time constraints; it would make sense to integrate with either of them.,Resolved,Won't Fix,,         ,Wittawat Tantisiriroj,Fri; 27 Aug 2010 20:19:32 +0000,Tue; 1 Aug 2017 17:12:56 +0000,Tue; 1 Aug 2017 17:12:56 +0000,,,,,HDFS-503,https://issues.apache.org/jira/browse/MAPREDUCE-2036
MAPREDUCE-2037,New Feature,Major,,Capturing interim progress times; CPU usage; and memory usage; when tasks reach certain progress thresholds,We would like to capture the following information  are not symmetrically placed.  Data capture boundaries should coincide with activity boundaries.  For the state information capture CPU and memory we should average over the covered interval.  This data would flow in with the heartbeats.  It would be placed in the job history as part of the task attempt completion event; so it could be processed by rumen or some similar tool and could drive a benchmark engine.,Closed,Fixed,,Dick King,Dick King,Fri; 27 Aug 2010 21:05:20 +0000,Thu; 2 May 2013 02:29:34 +0000,Fri; 12 Aug 2011 21:05:32 +0000,,,,,MAPREDUCE-2039,https://issues.apache.org/jira/browse/MAPREDUCE-2037
MAPREDUCE-2038,New Feature,Major,,Making reduce tasks locality-aware,"Currently Hadoop MapReduce framework does not take into consideration of data locality when it decides to launch reduce tasks. There are several cases where it could become sub-optimal.  	The map output data for a particular reduce task are not distributed evenly across different racks. This could happen when the job does not have many maps; or when there is heavy skew in map output data. 	A reduce task may need to access some side file (e.g. Pig fragmented join; or incremental merge of unsorted smaller dataset with an already sorted large dataset). It'd be useful to place reduce tasks based on the location of the side files they need to access.    This jira is created for the purpose of soliciting ideas on how we can make it better.",Open,Unresolved,MAPREDUCE-259,Unassigned,Hong Tang,Fri; 27 Aug 2010 21:36:35 +0000,Thu; 17 Jul 2014 17:37:24 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2038
MAPREDUCE-2039,Improvement,Major,,Improve speculative execution,In speculation; the framework issues a second task tempts in parallel to discover the problem sooner.   As part of this patch we would like to add benchmarks that simulate rare tasks that behave poorly; so we can discover whether this change in the code is a good idea and what the proper configuration is.  Early versions of this will be driven by our assumptions.  Later versions will be driven by the fruits of MAPREDUCE:2037,Resolved,Fixed,,Dick King,Dick King,Fri; 27 Aug 2010 23:41:43 +0000,Wed; 30 Jul 2014 23:38:36 +0000,Wed; 30 Jul 2014 23:38:36 +0000,,,,,MAPREDUCE-2063;MAPREDUCE-2037;HADOOP-2141,https://issues.apache.org/jira/browse/MAPREDUCE-2039
MAPREDUCE-2040,New Feature,Minor,contrib/dynamic-scheduler,Forrest Documentation for Dynamic Priority Scheduler,New Forrest documentation for dynamic priority scheduler,Resolved,Fixed,,Thomas Sandholm,Thomas Sandholm,Sat; 28 Aug 2010 00:29:57 +0000,Fri; 29 Oct 2010 02:04:17 +0000,Wed; 6 Oct 2010 03:48:12 +0000,,0.21.0,,,HADOOP-4768,https://issues.apache.org/jira/browse/MAPREDUCE-2040
MAPREDUCE-2041,Bug,Major,task,TaskRunner logDir race condition leads to crash on job-acl.xml creation,"TaskRunner's prepareLogFiles() warns on mkdirs() failures but ignores them.  It also fails even to check the return value of setPermissions().  Either one can fail (e.g.; on NFS; where there appears to be a TOCTOU-style race; except with C = ""creation""); in which case the subsequent creation of job-acl.xml in writeJobACLs() will also fail; killing the task:     This in turn causes TestTrackerBlacklistAcrossJobs to fail sporadically; the job-acl.xml failure always seems to affect host2 - and to do so more quickly than the intentional exception on host1 - which triggers an assertion failure due to the wrong host being job-blacklisted.",Open,Unresolved,,Unassigned,Greg Roelofs,Sat; 28 Aug 2010 05:17:40 +0000,Wed; 30 Jul 2014 23:42:37 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2041
MAPREDUCE-2042,Bug,Major,job submission,InputFormat#getSplits() is called twice in local mode,"In local mode the InputFormat#getSplits() is called twice in local mode.  	1st time: JobClient#writeOld NewSplits() (then they write the splits to disk ) 	2nd time: LocalJobRunner#run() (instead of reading the split file )    That can become annoying in case the InputFormat access external resources or takes a little longer to create the splits.",Resolved,Unresolved,,Unassigned,Johannes Zillmann,Sat; 28 Aug 2010 21:07:05 +0000,Tue; 10 Mar 2015 02:58:52 +0000,Tue; 10 Mar 2015 02:58:52 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2042
MAPREDUCE-2043,Improvement,Major,tasktracker,TaskTrackerInstrumentation and JobTrackerInstrumentation should be public,"Hadoop administrators can specify classes to be loaded as ""TaskTrackerInstrumentation"" and ""JobTrackerInstrumentation"" implementations; which; roughly; define listeners on TT and JT events.  Unfortunately; since the class has default access; extending it requires setting the extension's package to org.apache.hadoop.mapred; which seems like poor form.  I propose we make the two instrumentation classes public; so they can be extended wherever.",Open,Unresolved,,Philip Zeyliger,Philip Zeyliger,Mon; 30 Aug 2010 18:07:56 +0000,Wed; 1 Sep 2010 17:44:30 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2043
MAPREDUCE-2044,Improvement,Major,contrib/gridmix,[Gridmix] Document the usage of '-' as the input-trace in GridMix,GridMix users can pipeline the input trace to GridMix using the '-' option. This needs a documentation.,Resolved,Incomplete,,Amar Kamat,Amar Kamat,Tue; 31 Aug 2010 06:28:33 +0000,Wed; 30 Jul 2014 23:45:39 +0000,Wed; 30 Jul 2014 23:45:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2044
MAPREDUCE-2045,Improvement,Major,contrib/gridmix,[Gridmix] Separate out the -generate option in Gridmix,Currently; the data generating option (-generate) is embedded in the main GridMix command. This is very confusing and needs to separated out as a full-fledged option.,Resolved,Incomplete,,Amar Kamat,Amar Kamat,Tue; 31 Aug 2010 06:30:51 +0000,Wed; 30 Jul 2014 23:45:54 +0000,Wed; 30 Jul 2014 23:45:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2045
MAPREDUCE-2046,Improvement,Major,,A CombineFileInputSplit cannot be less than a dfs block ,I ran into this while testing some hive features.  Whether we use hiveinputformat or combinehiveinputformat; a split cannot be less than a dfs block size. This is a problem if we want to increase the block size for older data to reduce memory consumption for the name node.  It would be useful if the input split was independent of the dfs block size.,Closed,Fixed,,dhruba borthakur,Namit Jain,Tue; 31 Aug 2010 19:19:12 +0000,Mon; 12 Dec 2011 06:18:57 +0000,Mon; 6 Sep 2010 10:26:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2046
MAPREDUCE-2047,Improvement,Major,jobtracker,reduce overhead of findSpeculativeTask,We are bottlenecked (in the JT) on the jobtracker lock and calls to findSpeculativeTask frequently show up as one of the top routines (by time) called holding this lock.  this routine calls canBeSpeculated() and hasRunOnMachine() for each task in a candidate job. Both these routines are reasonably expensive when invoked repeatedly  for thousands of tasks. The top candidates for speculation from a job only need to be refreshed periodically (and not once every heartbeat) - and we can can avoid most of these invocations this way.,Resolved,Incomplete,,Joydeep Sen Sarma,Joydeep Sen Sarma,Tue; 31 Aug 2010 22:10:39 +0000,Wed; 30 Jul 2014 23:46:17 +0000,Wed; 30 Jul 2014 23:46:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2047
MAPREDUCE-2048,Improvement,Major,contrib/fair-share,reduce overhead of sorting jobs/pools in FairScheduler heartbeat processing,We are bound on the JT by the jobtracker lock. Sorting of jobs (and pools in hadoop-trunk) done by the FairScheduler is done once per heartbeat while this lock is held. This shows up as one of the places where we spend a lot of time holding the jobtracker lock.  We can avoid sorting the jobs insert into the sortedset).  This may be less of an issue in trunk (as we sort pools and then sort jobs within a pool) as opposed to hadoop-20 (where we sort all jobs). however - in our workload - we have lots of pools (one per user) and lots of jobs in some pools (production pools) - so i think it's reasonable to assume that this is worth addressing in trunk as well.,Open,Unresolved,,Joydeep Sen Sarma,Joydeep Sen Sarma,Wed; 1 Sep 2010 00:00:30 +0000,Wed; 1 Sep 2010 00:00:41 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2048
MAPREDUCE-2049,Bug,Minor,jobtracker;tasktracker,JT and TT should prune invalid local dirs on startup,MRAsyncDiskService fails when it's given local dirs it can't create or write. Per MAPREDUCE-1213 this conflicts with the previous behavior. The TTs will no longer start on hosts where the config has localdirs th don't exist are created (if possible); they're only ignored if they can not be created.,Resolved,Won't Fix,MAPREDUCE-1382,Zheng Shao,Eli Collins,Thu; 2 Sep 2010 04:54:57 +0000,Sat; 9 May 2015 01:07:28 +0000,Sat; 9 May 2015 01:07:28 +0000,,0.21.0;0.22.0,,,MAPREDUCE-1213,https://issues.apache.org/jira/browse/MAPREDUCE-2049
MAPREDUCE-2050,Bug,Major,security;test,TestMRCLI fails on trunk,TestMRCLI fails with following error:,Resolved,Duplicate,HADOOP-6938,Boris Shkolnik,Amareshwari Sriramadasu,Thu; 2 Sep 2010 09:11:36 +0000,Thu; 2 May 2013 02:29:33 +0000,Mon; 6 Sep 2010 03:34:32 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2050
MAPREDUCE-2051,Test,Major,contrib/fair-share,Contribute a fair scheduler preemption system test,We've seen a number of bugs in the fair share scheduler not caught by its unit tests; which are heavily mock-based. This JIRA is to add an integration stress test for the fairshare scheduler. This test can help identify races and deadlocks; and when run within the jcarder framework has identified several potential deadlocks for us that aren't turned up running small scale testing.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 2 Sep 2010 23:46:08 +0000,Mon; 12 Dec 2011 06:19:21 +0000,Mon; 1 Nov 2010 22:55:20 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2051
MAPREDUCE-2052,Bug,Major,,Fix URL encoding of job history logfiles,MAPREDUCE-1378 attempts to address this issue but sometimes results in doubly-URL-encoded logFile paths.,Open,Unresolved,,Unassigned,Patrick Angeles,Fri; 3 Sep 2010 18:24:30 +0000,Tue; 11 Jan 2011 19:36:43 +0000,,,0.20.1;0.20.2,,,HDFS-1109;MAPREDUCE-1378,https://issues.apache.org/jira/browse/MAPREDUCE-2052
MAPREDUCE-2053,Task,Major,contrib/gridmix,[Herriot] Test Gridmix file pool for different input file sizes based on pool minimum size.,Scenario: 1. Generate 1.8G data with Gridmix data generator; such that the files can create under different folders inside the given input directory and also create the files directly in the given input directory with the following sizes  {50 MB;100 MB;400 MB; 50 MB;300 MB;10 MB ;60 MB;40 MB;20 MB;10 MB;500 MB} . 2.Set the FilePool minimum size is 100 MB. 3. Verify the files count and sizes after excluding the files that are less than file pool minimum size.Also make sure; whether files are collected recursively from the different locations under input folder or not.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 6 Sep 2010 07:13:27 +0000,Tue; 15 Nov 2011 00:48:45 +0000,Wed; 15 Jun 2011 11:07:08 +0000,,,gridmix;system-tests,,,https://issues.apache.org/jira/browse/MAPREDUCE-2053
MAPREDUCE-2054,Bug,Major,contrib/dynamic-scheduler,Hierarchical queue implementation broke dynamic queue addition in Dynamic Scheduler,Queue names were returned from the queue manager as an immutable set after the hierarchical queuname feature which breaks the dynamic priority scheduler,Closed,Fixed,,Thomas Sandholm,Thomas Sandholm,Wed; 8 Sep 2010 16:23:46 +0000,Mon; 12 Dec 2011 06:18:38 +0000,Mon; 28 Feb 2011 05:22:58 +0000,,0.21.0,,,HADOOP-4768,https://issues.apache.org/jira/browse/MAPREDUCE-2054
MAPREDUCE-2055,Bug,Major,jobtracker,Retired job info cache should contain more details than just JobStatus,RetireJobInfo cache currently holds only job status. Other data like profile; counters are obtained from CompletedJobStatusStore,Open,Unresolved,,Unassigned,Krishna Ramachandran,Thu; 9 Sep 2010 01:19:33 +0000,Thu; 13 Jan 2011 02:27:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2055
MAPREDUCE-2056,Bug,Major,,run job options broken,HADOOP-1622 was apparently broken in refactoring (I think in the refactoring that removed JobShell) a few releases ago. e.g.; running  hadoop -libjars lib.jar main.jar Class   now tries to run -libjars as a library.  It would be nice to fix this regression.,Resolved,Invalid,,Unassigned,Ron Bodkin,Thu; 9 Sep 2010 07:16:43 +0000,Mon; 13 Sep 2010 17:23:24 +0000,Mon; 13 Sep 2010 03:47:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2056
MAPREDUCE-2057,Bug,Major,jobtracker,Job Tracker appears to do host access-control (mapred.hosts; mapred.hosts.exclude) based on presented name from TaskTracker,As far as I can tell; where the NameNode; in validating the dfs.hosts and dfs.hosts.exclude files uses the source IP address for the RPC connection; the JobTracker appears to use the presented hostname (set via slave.host.name or the standard hostname-search semantics) from the TaskTracker. Obviously this is a security bug as in a production environment it could allow rogue machines to present the hostname of a real TaskTracker and take over that role; but it also turns up as a configuration bug because it means that you can set up a (multi-homed; natch) environment where the same set of files work for the NameNode; but don't for the JobTracker or vice versa - with the same binding hostname for fs.default.name and mapred.job.tracker.,Resolved,Fixed,,Unassigned,Matthew Byng-Maddick,Thu; 9 Sep 2010 16:53:59 +0000,Wed; 30 Jul 2014 23:52:49 +0000,Wed; 30 Jul 2014 23:52:49 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2057
MAPREDUCE-2058,Bug,Major,contrib/fair-share,FairScheduler:NullPointerException in web interface when JobTracker not initialized,When I contact the jobtracker web interface prior to the job tracker being fully initialized (say; if hdfs is still in safe mode); I get the following error:    ERROR mortbay.log:  jobtracker.jsp  522),Patch Available,Unresolved,,Unassigned,Dan Adkins,Thu; 9 Sep 2010 18:16:44 +0000,Wed; 6 May 2015 03:31:26 +0000,,,0.22.0;1.0.4,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-2058
MAPREDUCE-2059,Bug,Major,jobtracker,RecoveryManager attempts to add jobtracker.info,The jobtracker is treating the file 'jobtracker.info' in the system data directory as a job to be recovered; resulting in the following:    WARN mapred.JobTracker: Failed to add the job jobtracker.info  4256),Closed,Fixed,,Subroto Sanyal,Dan Adkins,Thu; 9 Sep 2010 19:04:38 +0000,Mon; 12 Dec 2011 06:18:32 +0000,Thu; 24 Nov 2011 01:32:27 +0000,,0.20.203.0;0.22.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2059
MAPREDUCE-2060,Bug,Major,jobtracker,IOException: Filesystem closed on submitJob,I get the following strange error on the jobtracker when  org.apache.hadoop.ipc.Server$Handler.run(Server. 1374),Resolved,Won't Fix,,Unassigned,Dan Adkins,Thu; 9 Sep 2010 20:49:13 +0000,Wed; 11 Mar 2015 20:28:56 +0000,Wed; 11 Mar 2015 20:28:56 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2060
MAPREDUCE-2061,Bug,Major,,child environment substitution is broken,"TaskRunner.getVMEnvironment is still broken in a couple of ways even after HADOOP-5981:  	It does not recognize ${VAR} notation. This is necessary if we have both ""VAR"" and ""VAR_1"" existent; and it becomes ambiguous whether $VAR_1 means appending _1 following $VAR; or simply taking the value of $VAR_1 	It tries to do lazy-binding except for self-referencing like X=$X:Y. This would cause some unexpected behavior. For instance; if I specify ""A=$LD_LIBRARY_PATH:xxx""; A would be shown as "":xxx""; while if I specify ""LD_LIBRARY_PATH=$Z:xxx;Z=$LD_LIBRARY_PATH:yyy""; Z would be come the actual value of LD_LIBRARY_PATH + "":yyy"" (and LD_LIBRARY_PATH is not affected at all). I think we should support eager binding (and we can support lazy binding later through quoting or escaping).",Resolved,Duplicate,NULL,Unassigned,Hong Tang,Sat; 11 Sep 2010 01:16:22 +0000,Wed; 30 Jul 2014 23:56:03 +0000,Wed; 30 Jul 2014 23:56:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2061
MAPREDUCE-2062,Bug,Major,jobtracker,speculative execution is too aggressive under certain conditions,"The function canBeSpeculated has subtle bugs that cause too much speculation in certain cases.   	it compares the current progress of the task with the last observed mean of all the tasks. if only one task is in question - then the progress rate decays as time progresses (in the absence of updates) and std-dev is zero. So a job with a single reducer or mapper is almost always speculated. 	is only a single task has reported progress - then the stddev is zero. so other tasks may be speculated aggressively. 	several tasks take a while to report progress initially. they seem to get speculated as soon as speculative-lag is over. the lag should be configurable at the minimum.",Resolved,Fixed,,Unassigned,Joydeep Sen Sarma,Sat; 11 Sep 2010 01:21:22 +0000,Thu; 31 Jul 2014 03:53:47 +0000,Wed; 30 Jul 2014 23:56:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2062
MAPREDUCE-2063,New Feature,Major,,We need a benchmark to model system behavior in the face of tasks with time-variant performance,This benchmark would accept descriptions of task performance; with the times of reaching the say deciles of progress reported.,Open,Unresolved,,Dick King,Dick King,Sun; 12 Sep 2010 17:51:36 +0000,Thu; 2 May 2013 02:29:33 +0000,,,,,,MAPREDUCE-2039,https://issues.apache.org/jira/browse/MAPREDUCE-2063
MAPREDUCE-2064,Improvement,Minor,documentation,Tutorial should mention SetMapOutputKeyClass,The official tutorial (mapred_tutorial.html) (and all other tutorials I've seen on the web) show a program that has the same datatypes for the key value pairs with setOutputKeyClass(type) andsetOutputValueClass(type); which appy to both the mapper and reducer classes. If the types output by the mapper and reducer are not the same; that should be followed with setMapOutputKeyClass(type) and setMapOutputValueClass(type).  (I'm assuming that at least a call to setOutput{Key;Value} Class is required.),Resolved,Fixed,,Unassigned,Clarence Gardner,Sun; 12 Sep 2010 20:58:47 +0000,Thu; 11 Feb 2016 22:50:52 +0000,Thu; 24 Sep 2015 15:31:39 +0000,,0.21.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2064
MAPREDUCE-2065,Improvement,Trivial,documentation,Tutorial includes overly specified compilation command,"The tutorial (mapred_tutorial.html) shows a command line to compile the wordcount program. It specifically mentions three Hadoop-supplied jar files in the classpath; but in my 0.20.2 installation (and I assume; later ones as well); only one is necessary; that being ""core"". In fact; the mentioned mapred and hdfs jars are not even present in my HADOOP_HOME directory.",Resolved,Invalid,,Unassigned,Clarence Gardner,Sun; 12 Sep 2010 21:08:06 +0000,Tue; 14 Sep 2010 16:15:19 +0000,Tue; 14 Sep 2010 16:15:19 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2065
MAPREDUCE-2066,Task,Major,contrib/gridmix,Gridmix v3 needs java doc improvements.,Most of the Gridmix v3  API functionality is missing the  doc information. This has to be fixed.,Open,Unresolved,,Amar Kamat,Vinay Kumar Thota,Mon; 13 Sep 2010 09:26:59 +0000,Wed; 1 Jun 2011 03:33:24 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2066
MAPREDUCE-2067,Bug,Major,security,Distinct minicluster services (e.g. NN and JT) overwrite each other's service policies,MR portion of HADOOP-6951.,Closed,Fixed,,Aaron T. Myers,Aaron T. Myers,Tue; 14 Sep 2010 18:47:28 +0000,Mon; 12 Dec 2011 06:19:01 +0000,Thu; 30 Sep 2010 00:16:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2067
MAPREDUCE-2068,Bug,Minor,task,TaskInProgress contains duplicate idWithinJob() / getIdWithinJob() accessors,"Both are public; both ""return partition;""; and neither is currently deprecated.  Main user seems to be JobInProgress; and it mostly uses the ""get"" flavor; but it also uses the other one in two places.",Closed,Not A Problem,,Harsh J,Greg Roelofs,Tue; 14 Sep 2010 20:44:29 +0000,Tue; 15 Nov 2011 00:48:38 +0000,Wed; 7 Sep 2011 08:52:53 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2068
MAPREDUCE-2069,Improvement,Minor,distcp,Distcp setup is slow,When starting a distcp the setup phase often takes a very long time. For example during the distcp I just ran the setup phase took 15 minutes and the actual copy 3 minutes. Could this be improved? Or  org.apache.hadoop.util.CopyFiles.main(CopyFiles. 864),Resolved,Not A Problem,,Unassigned,Johan Oskarsson,Fri; 7 Dec 2007 14:03:03 +0000,Wed; 15 Sep 2010 22:54:07 +0000,Wed; 15 Sep 2010 22:54:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2069
MAPREDUCE-2070,New Feature,Minor,,Cartesian product file split,Generates a Cartesian product of file pairs from two directory inputs and enables a RecordReader to optimally read the split in tuple order; eliminating extraneous read operations.  The new InputFormat generates a split comprised of file combinations as tuples. The size of the split is configurable. A RecordReader employs the convenience class; CartesianProductFileSplitReader; to generate file pairs in tuple ordering. The actual read operations are delegated to the RecordReader which must implement the CartesianProductTupleReader interface. An implementor of a RecordReader can perform file manipulations without restriction and also benefit from the optimization of tuple ordering.  In the Cartesian product of two sets with cardinalities; X and Y; each element x in  {X }  need only be referenced once; saving X(Y-1) references of the elements. If the Cartesian product is split into subsets of size N there are then X(Y N bytes.,Open,Unresolved,,Unassigned,Paul Burkhardt,Wed; 15 Sep 2010 23:04:19 +0000,Thu; 2 May 2013 02:29:33 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2070
MAPREDUCE-2071,Bug,Major,pipes,In Hadoop Pipes; reduce tasks with no shuffled data input can time out in the close method even when progress is sent,Likely has to do with the fact that PipesReducer starts the application with a Null reporter in the close method.,Open,Unresolved,,Unassigned,Christian Kunz,Thu; 16 Sep 2010 01:07:58 +0000,Thu; 16 Sep 2010 01:07:58 +0000,,,0.20.1;0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2071
MAPREDUCE-2072,Improvement,Major,job submission,Allow multiple instances of same local job to run simutaneously on the same machine,On the same (build) machine; there may be multiple instances of same local job running - e.g. same unit test from snapshot build and release build.  For each build project on our build machine; there is environment variable with unique value defined.   In JobClient.submitJobInternal(); there is following code:     JobID jobId = jobSubmitClient.getNewJobId();     Path submitJobDir = new Path(getSystemDir(); jobId.toString());  The above code doesn't handle the scenario described previously and often leads to the following failure: Caused by: org.apache.hadoop.util.Shell$ExitCodeException: chmod: cannot access ` job_local_0002': No such file or directory   org.apache.hadoop.mapred.HadoopClient.runJob(HadoopClient. 177)  One solution would be to incorporate the value of the underlying environment variable into either NewJobId or SystemDir so that there is no conflict.,Resolved,Fixed,,Unassigned,Ted Yu,Thu; 16 Sep 2010 04:16:58 +0000,Wed; 30 Jul 2014 23:58:34 +0000,Wed; 30 Jul 2014 23:58:34 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2072
MAPREDUCE-2073,Test,Trivial,distributed-cache;test,TestTrackerDistributedCacheManager should be up-front about requirements on build environment,TestTrackerDistributedCacheManager will fail on a system where the build directory is in any path where an ancestor doesn't have a+x permissions. On one of our hudson boxes; for example; hudson's workspace had 700 permissions and caused this test to fail reliably; but not in an obvious manner. It would be helpful if the test failed with a more obvious error message during setUp() when the build environment is misconfigured.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 16 Sep 2010 05:40:26 +0000,Wed; 17 Oct 2012 18:27:26 +0000,Wed; 10 Nov 2010 21:26:31 +0000,,0.22.0,,,MAPREDUCE-1549,https://issues.apache.org/jira/browse/MAPREDUCE-2073
MAPREDUCE-2074,Bug,Minor,distributed-cache,Task should fail when symlink creation fail,If I pass an invalid symlink as   -Dmapred.cache.files= abc  Task only reports a WARN and goes on.      I believe we should fail the task at this point.,Closed,Fixed,,Priyo Mustafi,Koji Noguchi,Thu; 16 Sep 2010 21:44:31 +0000,Tue; 15 Nov 2011 00:49:10 +0000,Tue; 1 Mar 2011 05:59:56 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2074
MAPREDUCE-2075,New Feature,Minor,,Show why the job failed  (e.g. Job ___ failed because task ____ failed 4 times),"When our users have questions about their jobs' failure; they tend to copypaste all the userlog exceptions they see on the webui console.  However; most of them are not the one that caused the job to fail.   When we tell them 'This task failed 4 times""; sometimes that's enough information for them to solve the problem on their own.  It would be nice if jobclient or job status page shows the reason for the job being flagged as fail.",Resolved,Duplicate,MAPREDUCE-343,Unassigned,Koji Noguchi,Thu; 16 Sep 2010 22:07:49 +0000,Fri; 17 Sep 2010 04:02:02 +0000,Fri; 17 Sep 2010 04:02:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2075
MAPREDUCE-2076,Improvement,Minor,,Showing inputsplit filename/offset inside the webui or tasklog,For debugging purposes; it would be nice to have inputsplit's  filename and offset for FileInputFormat and alike. (in addition to input split's node list that is already shown),Resolved,Duplicate,MAPREDUCE-3678,Unassigned,Koji Noguchi,Thu; 16 Sep 2010 22:15:07 +0000,Tue; 24 Jul 2012 18:20:16 +0000,Tue; 24 Jul 2012 18:20:16 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2076
MAPREDUCE-2077,Bug,Major,,Name clash in the deprecated o.a.h.util.MemoryCalculatorPlugin,Name clash compile error in the deprecated org.apache.hadoop.util.MemoryCalculatorPlugin due to JLS3 8.4.8.3 (cf. http: view_bug.do?bug_id=6182950)  The bug doesn't manifest in jdk 1.6 up to 20; but shows up in NetBeans 6.9+ due to its bundled (conforming) compiler. Fix is trivial: just remove the offending method in the deprecated subclass as its equivalent erasure is inherited from the parent class anyway.,Closed,Fixed,,Luke Lu,Luke Lu,Thu; 16 Sep 2010 23:00:23 +0000,Mon; 12 Dec 2011 06:19:06 +0000,Fri; 4 Feb 2011 03:23:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2077
MAPREDUCE-2078,Bug,Major,tools/rumen,TraceBuilder unable to generate the traces while giving the job history path by globing.,I was trying to generate the traces for MR job histories by using TraceBuilder. However; it's unable to generate the traces while giving the job history path by globing. It throws a file not found exception even though the job history path is exists.  I have provide the job history path in the below way.  hdfs:   Exception:   121)  It's truncating the last  slash in the path.,Closed,Fixed,,Amar Kamat,Vinay Kumar Thota,Fri; 17 Sep 2010 05:59:20 +0000,Mon; 12 Dec 2011 06:19:39 +0000,Wed; 22 Sep 2010 05:58:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2078
MAPREDUCE-2079,Improvement,Major,pipes,PipesMapRunner does not use map output classes,"In org.apache.hadoop.mapred.pipes.PipesMapRunner. at lines 71-72 instead of:   	job.getOutputKeyClass()    and 	job.getOutputValueClass()    there should be called:  	job.getMapOutputKeyClass()    and 	job.getMapOutputValueClass()    This modification will allow pipe jobs to use intermediate map output classes different from the job final output classes.",Open,Unresolved,,Unassigned,Cosmin Catanoaie,Sun; 19 Sep 2010 18:41:48 +0000,Mon; 10 Jan 2011 20:53:57 +0000,,,0.20.1;0.20.2;0.20.3;0.21.0;0.21.1;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2079
MAPREDUCE-2080,Bug,Major,tasktracker,Reducer JVM process hangs,We use cdh3b2  After reducer took more than 600 seconds to report to tasktracker; tasktracker tried to kill it. However reducer JVM process hung.  Attaching stack trace of reducer.,Resolved,Fixed,,Unassigned,Ted Yu,Sun; 19 Sep 2010 21:31:06 +0000,Thu; 31 Jul 2014 00:00:40 +0000,Thu; 31 Jul 2014 00:00:40 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2080
MAPREDUCE-2081,Test,Major,contrib/gridmix,[GridMix3] Implement functionality for get the list of job traces which has different intervals.,Girdmix system tests should require different job traces with different time intervals for generate and submit the gridmix jobs. So; implement a functionaliy for getting the job traces and arrange them in hash table with time interval as key.Also getting the list of traces from resource location irrespective of time. The following methods needs to implement.  Method signature: public static Map String; String getMRTraces(Configuration conf)  throws IOException; - it get the traces with time intervals from resources default location.  public static Map String; String getMRTraces(Configuration conf;Path path)  throws IOException; - it get the traces with time intervals from user specified resource location.   public static ListString listMRTraces(Configuration conf) throws IOException  -it list all the traces from resource default location irrespective of time interval.  public static ListString listMRTraces(Configuration conf; Path tracesPath) throws IOException - it list all the traces from user specified user location irrespective of  time interval.  public static ListString listMRTracesByTime(Configuration conf; String timeInterval) throws IOException - it list all traces of a given time interval from default resource location.  public static ListString listMRTracesByTime(Configuration conf; String timeInterval;Path path) throws IOException - it list all traces of a given time interval from a given resources location.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 20 Sep 2010 10:42:42 +0000,Thu; 2 May 2013 02:29:34 +0000,Wed; 15 Jun 2011 11:07:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2081
MAPREDUCE-2082,Bug,Major,,Race condition in writing the jobtoken password file when launching pipes jobs,In Application.  when jobtoken password file is written; there is a race condition because the file is written in job's work directory. The file should rather be written in the task's working directory.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Tue; 21 Sep 2010 02:45:30 +0000,Mon; 12 Dec 2011 06:18:42 +0000,Fri; 1 Oct 2010 22:30:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2082
MAPREDUCE-2083,Improvement,Major,,Run partial reduce instead of combiner at reduce node to overlap shuffle delay with reduce,Shuffle delays can be large for mapreductions with lots of intermediate data. Some of this shuffle delay can be overlapped with reduce if some of the reduce computation is started on partial intermediate data received by a reduce. Along these lines; the patch HADOOP-3226 runs the combiner on the reduce side to prune the data th running partial reduce on the small remainder data does not delay starting final reduce.,Resolved,Incomplete,,Unassigned,Faraz Ahmad,Tue; 21 Sep 2010 22:31:20 +0000,Tue; 10 Mar 2015 02:54:59 +0000,Tue; 10 Mar 2015 02:54:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2083
MAPREDUCE-2084,Bug,Blocker,documentation,Deprecated org.apache.hadoop.util package in MapReduce produces deprecations in Common classes in Eclipse,As reported in this thread the classes in org.apache.hadoop.util from the Common JAR; like Tool; are marked as deprecated by Eclipse; even though they are not deprecated. The fix is to mark the individual classes in the MapReduce org.apache.hadoop.util class as deprecated; not the whole package.,Closed,Fixed,,Tom White,Tom White,Wed; 22 Sep 2010 16:09:34 +0000,Mon; 12 Dec 2011 06:18:26 +0000,Tue; 11 Jan 2011 06:04:25 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2084
MAPREDUCE-2085,Bug,Minor,,job submissions to a tracker using a different default filesystem than the jobclient fails,the scenario is one where a jobclient with default filesystem 'A' tries to submit jobs to a tracker whose system directory lives in filesystem 'B'.  jobclient copies jars archives to tracker's system directory. however - it does not use the fully qualified uri's of the returned paths. this leads to failures subsequently in the client because it attempts to dereference these paths against it's default file system (which is different from the tracker's file system),Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Wed; 22 Sep 2010 22:26:25 +0000,Mon; 27 Sep 2010 17:32:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2085
MAPREDUCE-2086,Bug,Major,,CHANGES.txt does not reflect the release of version 0.21.0.,CHANGES.txt should show the release date for 0.21.0 and include section for for 0.21.1 - Unreleased. Latest changes; that did not make into 0.21.0; should be moved under 0.21.1 section.,Resolved,Fixed,,Tom White,Konstantin Shvachko,Thu; 23 Sep 2010 19:18:31 +0000,Fri; 29 Oct 2010 02:03:27 +0000,Tue; 5 Oct 2010 22:29:30 +0000,,0.21.0,,,HADOOP-6969,https://issues.apache.org/jira/browse/MAPREDUCE-2086
MAPREDUCE-2087,Improvement,Major,,Reuse 'subcountersArray' in Counters#Group.makeEscapedCompactString(),While optimizing Counters#Group.makeEscapedCompactString(); MAPREDUCE-1533 pre-converted the sub-counters into their escaped form for computing the overall size required for holding the escaped sub-counters in a StringBuffer. As a result of this pre-conversion; escaped sub-counters are stored cached in an array called subcountersArray. Later; while the final escaped string is constructed; all the sub-counters are again converted into their escaped form. Here the subcountersArray; which is created during the pre-conversion stage; can be reused.,Open,Unresolved,,Unassigned,Amar Kamat,Fri; 24 Sep 2010 05:44:43 +0000,Fri; 24 Sep 2010 05:44:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2087
MAPREDUCE-2088,Bug,Major,jobtracker,TaskGraphServlet throws ArrayIndexOutOfBoundsException when progress % > 100%,"I'm currently running a map reduce job in which the reducer inserts data into HBase. It is a long running job dealing with hundreds of GB of map output data and 9 out of 10 reducers are currently showing 110+% progress (i.e. the total job reduce progress is 100% but clickig through to the reducer list shows reducers with percentages over 100%).   The number of reduce input records is 4;299;991;005  While keeping an eye on it through the job detail page of the JobTracker web gui; the Jobtracker started generating exceptions every 30 seconds which turned out to be generated by the TaskGrapServlet that displays reducer progress. The stacktrace also showed up in the web gui in the area that normally holds the reducer progress graph. 30 seconds is of course the refresh rate of the status page.  I guess the root cause here is progress percentages being greater than 100%. I found issue HADOOP-5210 which reports a cause for progress crossing 100% but it is marked as fixed in 0.20.1 and I'm running 0.20.2.  One thing that might impact the progress percentages is the fact that we LZO compress our map outputs. For the above job uncompressed output (""Map output bytes"") was 2;462;412;228;874 which compressed to 694;405;054;632 (FILE_BYTES_WRITTEN taskgraph  522)",Open,Unresolved,,Unassigned,Age Mooij,Fri; 24 Sep 2010 12:41:29 +0000,Fri; 24 Sep 2010 12:50:15 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2088
MAPREDUCE-2089,Improvement,Major,client;job submission;jobtracker;security;task;tasktracker,JobToken should be passed over RPC,JobToken file is currently created by the JobTracker; and stored in the HDFS. Later on; the TaskTrackers pull that file from the HDFS as part of job localization. The HDFS operations can be avoided if the the jobToken file is passed over RPC (Jobclient - JobTracker - TaskTrackers).,Open,Unresolved,,Devaraj Das,Devaraj Das,Fri; 24 Sep 2010 18:29:02 +0000,Wed; 7 Sep 2011 08:15:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2089
MAPREDUCE-2090,Bug,Major,build;test,Clover build doesn't generate per-test coverage,Because of the way the structure of Hadoop's builds is done Clover can't properly detect test classes among the sources. As the result clover reports are incomplete and do not provide viral per-test coverage info.,Resolved,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Fri; 24 Sep 2010 19:13:56 +0000,Fri; 29 Oct 2010 02:03:18 +0000,Mon; 4 Oct 2010 04:53:06 +0000,,0.21.1;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2090
MAPREDUCE-2091,Bug,Major,build,Map/Reduce Build Failing due to missing Smoke Tests,"The Compilation (the ANT clean and tar directives) of the Map smoke-tests not found.  The fastest way to reproduce this error is to run : ""ant run-test-mapred-excluding-commit-and-smoke""",Resolved,Incomplete,,Unassigned,Stephen Watt,Fri; 24 Sep 2010 19:49:48 +0000,Thu; 31 Jul 2014 00:13:22 +0000,Thu; 31 Jul 2014 00:13:22 +0000,,0.21.1;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2091
MAPREDUCE-2092,Bug,Major,tasktracker,Trunk can't be compiled,Compilation of the trunk is broken because of an attempt to call ServiceAuthorizationManager.refresh from a static content.  0.21 branch seems to be Ok.,Resolved,Fixed,,Unassigned,Konstantin Boudnik,Fri; 24 Sep 2010 21:45:20 +0000,Sat; 25 Sep 2010 02:57:25 +0000,Sat; 25 Sep 2010 02:57:25 +0000,,,,,HDFS-1422,https://issues.apache.org/jira/browse/MAPREDUCE-2092
MAPREDUCE-2093,Improvement,Major,test,Herriot JT and TT clients should vend statistics,Mapreduce counterpart of HDFS-1408,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Tue; 28 Sep 2010 00:13:21 +0000,Mon; 12 Dec 2011 06:20:03 +0000,Thu; 11 Nov 2010 20:03:24 +0000,,0.22.0,,HADOOP-6977,,https://issues.apache.org/jira/browse/MAPREDUCE-2093
MAPREDUCE-2094,Bug,Major,task,LineRecordReader should not seek into non-splittable; compressed streams.,"When implementing a custom derivative of FileInputForm the JavaDoc describes. 	""Force"" developers to think about it and make this method abstract. 	Use a ""safe"" default (i.e. return false)",Resolved,Fixed,,Niels Basjes,Niels Basjes,Tue; 28 Sep 2010 09:40:11 +0000,Tue; 30 Aug 2016 01:20:56 +0000,Fri; 8 May 2015 21:36:19 +0000,,,,,HADOOP-6901,https://issues.apache.org/jira/browse/MAPREDUCE-2094
MAPREDUCE-2095,Bug,Major,contrib/gridmix,Gridmix unable to run for compressed traces(.gz format).,I was trying to run gridmix with compressed trace file.However; it throws a JsonParseException and exit.  exception details: ================== org.codehaus.jackson.JsonParseException: Illegal character ((CTRL-CHAR; code 31)): only regular white space ( t) is allowed between tokens   org.apache.hadoop.mapred.gridmix.StressJobFactory$StressReaderThread.run(StressJobFactory. 166)   INFO gridmix.Gridmix: Exiting...,Closed,Fixed,,Ranjit Mathew,Vinay Kumar Thota,Tue; 28 Sep 2010 11:06:18 +0000,Thu; 2 May 2013 02:29:34 +0000,Mon; 11 Oct 2010 10:30:11 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2095
MAPREDUCE-2096,Bug,Blocker,jobtracker;security;tasktracker,Secure local filesystem IO from symlink vulnerabilities,This JIRA is to contribute a patch developed on the private security@ mailing list.  The vulnerability is that MR daemons occasionally open files that are located in a path where the user has write access. A malicious user may place a symlink in place of the expected file in order to cause the daemon to instead read another file on the system  one which the attacker may not naturally be able to access. This includes delegation tokens belong to other users; log files; keytabs; etc.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 28 Sep 2010 19:46:35 +0000,Mon; 12 Dec 2011 06:18:27 +0000,Thu; 6 Jan 2011 18:42:05 +0000,,0.22.0,,HADOOP-6978,,https://issues.apache.org/jira/browse/MAPREDUCE-2096
MAPREDUCE-2097,Bug,Major,task,java.lang.NullPointerException in reduce task,"While executing hive query ""select count from table "" ; i got this error message  Ended Job = job_201009291356_0003 with errors FAILED: Execution Error; return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask  On investigating task tracker logs ; i found out  2010-09-29 14:31:46;839 WARN org.apache.hadoop.conf.Configuration:  job.xml:a  org.apache.hadoop.mapred.ReduceTask$ReduceCopier$GetMapEventsThread.run(ReduceTask. 2683 is :  ListMapOutputLocation loc = mapLocations.get(host)  where host is:-URI u = URI.create(event.getTaskTrackerHttp());  host = u.getHost() ;  What's the fix??",Open,Unresolved,,Unassigned,vaibhav negi,Wed; 29 Sep 2010 14:53:38 +0000,Fri; 12 Aug 2011 20:54:55 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2097
MAPREDUCE-2098,Bug,Major,jobtracker,Extra url encoding makes jobdetailshistory.jsp report FileNotFoundException,In cdh3b2; when viewing :50030 done  The issue was due to double encoding. In jobhistory.jsp; line 237:       String encodedJobFileName =           JobHistory.JobInfo.encodeJobHistoryFileName(jobFile.getName());  Then MAPREDUCE-1378 encodes the filename again.,Resolved,Incomplete,,Unassigned,Ted Yu,Wed; 29 Sep 2010 20:02:12 +0000,Thu; 31 Jul 2014 00:15:45 +0000,Thu; 31 Jul 2014 00:15:45 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2098
MAPREDUCE-2099,Bug,Major,contrib/raid,RaidNode should recreate outdated parity HARs,After parity files are archived into a parity HAR; a change in the source file does not cause the HAR to be recreated. Instead; individual parity files are created for the modified files but the HAR is not touched. This causes increased disk usage for parity data.  The parity HAR could be recreated if a certain percentage of files in the HAR are determined to be outdated.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Thu; 30 Sep 2010 21:19:08 +0000,Mon; 12 Dec 2011 06:19:07 +0000,Fri; 29 Oct 2010 01:30:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2099
MAPREDUCE-2100,Improvement,Minor,task,log split information for map task,for regular filesplits - the split information can be seen in the status of the task. however for others (combinefilesplit) - the split information is not available readily. this makes it difficult to deal with data corruptions bugs in large data sets.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Thu; 30 Sep 2010 23:21:25 +0000,Thu; 30 Sep 2010 23:21:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2100
MAPREDUCE-2101,Bug,Major,,compile-mapred-test broken in trunk,r1002905 seems to have caused it.,Resolved,Not A Problem,,Aaron T. Myers,Ramkumar Vadali,Fri; 1 Oct 2010 03:34:24 +0000,Fri; 1 Oct 2010 16:04:25 +0000,Fri; 1 Oct 2010 16:04:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2101
MAPREDUCE-2102,New Feature,Major,task,Collect iops per task,We should enhance the MR framework to collect iops per task along with CPU Memory (MAPREDUCE-220).,Open,Unresolved,,Unassigned,Arun C Murthy,Sun; 3 Oct 2010 16:27:49 +0000,Fri; 5 Aug 2011 14:01:12 +0000,,,,,MAPREDUCE-901,,https://issues.apache.org/jira/browse/MAPREDUCE-2102
MAPREDUCE-2103,Improvement,Trivial,task-controller,task-controller shouldn't require o-r permissions,"The task-controller currently checks that ""other"" users don't have read permissions. This is unnecessary - we just need to make it's not executable. The debian policy manual explains it well:   Setuid and setgid executables should be mode 4755 or 2755 respectively; and owned by the appropriate user or group. They should not be made unreadable (modes like 4711 or 2711 or even 4111); doing so achieves no extra security; because anyone can find the binary in the freely available Debian package; it is merely inconvenient. For the same reason you should not restrict read or execute permissions on non-set-id executables.  Some setuid programs need to be restricted to particular sets of users; using file permissions. In this case they should be owned by the uid to which they are set-id; and by the group which should be allowed to execute them. They should have mode 4754; again there is no point in making them unreadable to those users who must not be allowed to execute them.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 4 Oct 2010 04:08:00 +0000,Wed; 17 Oct 2012 18:27:27 +0000,Fri; 13 May 2011 22:12:17 +0000,,0.22.0,,HADOOP-7025,,https://issues.apache.org/jira/browse/MAPREDUCE-2103
MAPREDUCE-2104,Bug,Major,tools/rumen,Rumen TraceBuilder Does Not Emit CPU/Memory Usage Details in Traces,Via MAPREDUCE-220; we now have CPU Memory usage correctly.,Closed,Fixed,,Amar Kamat,Ranjit Mathew,Mon; 4 Oct 2010 11:04:28 +0000,Thu; 2 May 2013 02:29:11 +0000,Mon; 6 Jun 2011 05:42:42 +0000,,0.22.0,,MAPREDUCE-1702,,https://issues.apache.org/jira/browse/MAPREDUCE-2104
MAPREDUCE-2105,Improvement,Major,contrib/gridmix,Simulate Load Incrementally and Adaptively in GridMix3,"Tasks launched by GridMix3 should incrementally and adaptively simulate load (I time-slices. By ""adaptive"" I mean taking the existing load into account before inflicting additional load to meet a target load (we are unlikely to achieve 100% fidelity as we overshoot or undershoot with each iteration).",Closed,Fixed,,Amar Kamat,Ranjit Mathew,Mon; 4 Oct 2010 11:27:54 +0000,Tue; 15 Nov 2011 00:49:17 +0000,Wed; 15 Jun 2011 11:04:19 +0000,,0.22.0,,,MAPREDUCE-2115,https://issues.apache.org/jira/browse/MAPREDUCE-2105
MAPREDUCE-2106,Improvement,Major,contrib/gridmix,Emulate CPU Usage of Tasks in GridMix3,MAPREDUCE-220 makes CPU Memory usage of Tasks available in JobHistory files. Use this to emulate the CPU usage of Tasks (of course; once MAPREDUCE-2104 is done).,Closed,Fixed,,Amar Kamat,Ranjit Mathew,Mon; 4 Oct 2010 11:33:38 +0000,Tue; 15 Nov 2011 00:48:42 +0000,Tue; 14 Jun 2011 07:45:34 +0000,,0.22.0,,,MAPREDUCE-2591,https://issues.apache.org/jira/browse/MAPREDUCE-2106
MAPREDUCE-2107,Improvement,Major,contrib/gridmix,Emulate Memory Usage of Tasks in GridMix3,MAPREDUCE-220 makes CPU Memory usage of Tasks available in JobHistory files. Use this to emulate the memory usage of Tasks (of course; once MAPREDUCE-2104 is done).,Closed,Fixed,,Amar Kamat,Ranjit Mathew,Mon; 4 Oct 2010 11:34:58 +0000,Tue; 15 Nov 2011 00:49:02 +0000,Wed; 15 Jun 2011 11:43:00 +0000,,0.22.0,,MAPREDUCE-2401;MAPREDUCE-2469,,https://issues.apache.org/jira/browse/MAPREDUCE-2107
MAPREDUCE-2108,New Feature,Major,capacity-sched;contrib/fair-share,Allow TaskScheduler manage number slots on TaskTrackers,Currently the map slots and reduce slots are managed by TaskTracker configuration. To change the task tracker slots; we need to restart the TaskTrackers. Also; for a non-uniform cluster; we have to deploy different sets of configuration.  Now JobTracker holds the CPU and memory status of TaskTrackers (MAPREDUCE-1218). So it makes sense to just let JobTracker.taskScheduler decided the number of slots on each node. This way we can 1. Change the number of slots dynamically without restarting TaskTracker 2. Use different number of slots based on the resource of a TaskTracker  To achieve this; we need to change the logic that we use totalMapSlots and totalReduceSlots in JobTracker. I think they are used in WebUI and speculativeCap.  We will need to make JobTracker calculate these numbers from TaskScheduler and TaskTrackerStatus. TaskScheduler and TaskTracker can both hold their maximum slots. We pick the smaller one.  Thoughts?,Closed,Won't Fix,,Scott Chen,Scott Chen,Mon; 4 Oct 2010 21:06:52 +0000,Tue; 15 Nov 2011 00:49:20 +0000,Thu; 15 Sep 2011 05:09:16 +0000,,0.23.0,,,MAPREDUCE-2198,https://issues.apache.org/jira/browse/MAPREDUCE-2108
MAPREDUCE-2109,Bug,Major,security,Add support for reading multiple hadoop delegation token files,This is the MR part of HADOOP-6988.,Resolved,Won't Fix,,Aaron T. Myers,Aaron T. Myers,Mon; 4 Oct 2010 23:30:06 +0000,Tue; 24 May 2011 19:12:50 +0000,Tue; 24 May 2011 19:12:50 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2109
MAPREDUCE-2110,Improvement,Minor,,add getArchiveIndex to HarFileSystem,This patch adds a public getter for archiveIndex to HarFileSystem; allowing us to access the index file corresponding to a har file system (useful for raid).  Index: src     public Path getHomeDirectory() {,Resolved,Won't Fix,,Unassigned,Patrick Kling,Mon; 4 Oct 2010 23:32:04 +0000,Thu; 2 May 2013 02:29:33 +0000,Tue; 16 Nov 2010 19:27:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2110
MAPREDUCE-2111,Improvement,Minor,,make getPathInHar public in HarFileSystem,"This patch makes getPathInHar public in HarFileSystem allowing us to retrieve the local path name of a file stored within a HAR archive. This is useful for maintaining HAR archives within the context of RAID.  Index: src    	private Path getPathInHar(Path path) { +  public Path getPathInHar(Path path) {      Path harPath = new Path(path.toUri().getPath());      if (archivePath.compareTo(harPath) == 0)        return new Path(Path.SEPARATOR);",Resolved,Won't Fix,,Unassigned,Patrick Kling,Mon; 4 Oct 2010 23:40:40 +0000,Thu; 2 May 2013 02:29:33 +0000,Tue; 16 Nov 2010 19:29:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2111
MAPREDUCE-2112,New Feature,Minor,,Create a Common Data-Generator for Testing Hadoop,It is useful to have a common data-generator for testing Hadoop and related projects. Such a tool should be able to generate data in a specified format and should be able to use a Hadoop cluster for speeding up the data-generation. This tool can then be used across Hadoop (e.g. GridMix3); Pig; Hive; etc. reducing the need for each project to invent something like this itself.  We can use the data-generator used in PigMix2 (PIG-200) as a starting point. It is described in http: ) released under the GNU GPL; it has to be modified a bit to eliminate this dependency before it can be included in Apache Hadoop.,Open,Unresolved,,Unassigned,Ranjit Mathew,Tue; 5 Oct 2010 11:40:47 +0000,Tue; 5 Oct 2010 16:51:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2112
MAPREDUCE-2113,Bug,Trivial,test,SequenceFile tests assume createWriter w/ overwrite,Many of the SequenceFile tests create writers in a loop. This fails after HADOOP-6856; which will not overwrite the destination by default.,Resolved,Invalid,,Unassigned,Chris Douglas,Tue; 5 Oct 2010 18:48:53 +0000,Mon; 25 Oct 2010 22:29:37 +0000,Mon; 25 Oct 2010 22:29:37 +0000,,0.22.0,,HADOOP-6991,,https://issues.apache.org/jira/browse/MAPREDUCE-2113
MAPREDUCE-2114,Improvement,Major,jobtracker,user finer grained locks in JT getCounters implementation,"We are bound on the JobTracker lock on our largest cluster. One pattern i have seen is the following:   	JT acquires JobTracker lock - but blocked on JIP lock:     lang.Thread.State: BLOCKED (on object monitor)  a time. we don't need to lock the entire job.",Resolved,Duplicate,MAPREDUCE-2026,Unassigned,Joydeep Sen Sarma,Thu; 7 Oct 2010 00:52:56 +0000,Tue; 12 Oct 2010 07:32:47 +0000,Tue; 12 Oct 2010 07:32:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2114
MAPREDUCE-2115,Improvement,Major,contrib/gridmix,[GridMix] Add emulation plugin support in GridMix,Currently; GridMix faithfully emulates I emulation plugins (emulins). GridMix; as a framework; should provide support for various such emulins. A GridMix user can now select a set of emulins based on the load to be simulated.,Closed,Duplicate,MAPREDUCE-2106,Amar Kamat,Amar Kamat,Thu; 7 Oct 2010 05:22:09 +0000,Tue; 15 Nov 2011 00:50:03 +0000,Wed; 15 Jun 2011 11:03:04 +0000,,,,,MAPREDUCE-2105,https://issues.apache.org/jira/browse/MAPREDUCE-2115
MAPREDUCE-2116,Improvement,Major,jobtracker,optimize getTasksToKill to reduce JobTracker contention,getTasksToKill shows up as one of the top routines holding the JT lock. Specifically; the translation from tempt is fixed (and one should not need a map lookup to find the association). on a different note - not clear to me why TreeMaps are in use here (i didn't find any iteration over these maps). any background info on why things are arranged the way they are would be useful.,Open,Unresolved,,Joydeep Sen Sarma,Joydeep Sen Sarma,Thu; 7 Oct 2010 08:01:05 +0000,Wed; 7 Sep 2011 08:15:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2116
MAPREDUCE-2117,Improvement,Major,distcp,Superfast Distcp when copying data within the same hdfs cluster,There are use cases when distcp is used to copy a bunch of files directories from one part of the HDFS namespace to another part within the same HDFS cluster. It is superfast if we can instruct relevant datanodes to make local replicas of relevant blocks and limit network usage to a minimum. It is especially useful to make HBase take a backup of a region with minimum downtime.,Open,Unresolved,,Unassigned,dhruba borthakur,Fri; 8 Oct 2010 05:39:10 +0000,Fri; 8 Oct 2010 20:13:44 +0000,,,,,,HDFS-222,https://issues.apache.org/jira/browse/MAPREDUCE-2117
MAPREDUCE-2118,Improvement,Major,,optimize getJobSetupAndCleanupTasks ,in every heartbeat; while holding the JobTracker global lock; all jobs are scanned for job setup cleanup task.,Open,Unresolved,,Joydeep Sen Sarma,Joydeep Sen Sarma,Fri; 8 Oct 2010 17:02:10 +0000,Wed; 7 Sep 2011 08:15:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2118
MAPREDUCE-2119,Bug,Major,test,many unit tests with SequenceFiles fail on trunk,"The following tests are failing in trunk :  	TestSequenceFile 	TestSequenceFileInputFormat 	TestSequenceFileAsTextInputFormat 	TestSequenceFileInputFilter 	TestMRSequenceFileAsTextInputFormat 	TestMRSequenceFileInputFilter",Resolved,Duplicate,MAPREDUCE-2113,Unassigned,Amareshwari Sriramadasu,Mon; 11 Oct 2010 10:57:11 +0000,Tue; 12 Oct 2010 05:01:32 +0000,Tue; 12 Oct 2010 05:01:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2119
MAPREDUCE-2120,Improvement,Major,contrib/gridmix;test,TestGridmixSubmission consumes a lot of time.,TestGridmixSubmission consumes a lot of time. It took 582 seconds on my machine. The test time should be improved.,Resolved,Incomplete,,Unassigned,Amareshwari Sriramadasu,Mon; 11 Oct 2010 11:03:52 +0000,Thu; 31 Jul 2014 00:20:18 +0000,Thu; 31 Jul 2014 00:20:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2120
MAPREDUCE-2121,Bug,Blocker,,TestControlledMapReduceJob times out on trunk.,TestControlledMapReduceJob times out on trunk. Logs show the following ArrayIndexOutOfBoundsException:,Resolved,Duplicate,HADOOP-7087,Todd Lipcon,Amareshwari Sriramadasu,Mon; 11 Oct 2010 11:06:14 +0000,Thu; 2 May 2013 02:29:35 +0000,Fri; 11 Feb 2011 08:10:38 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2121
MAPREDUCE-2122,Bug,Major,,TestJobQueueInformation fails on trunk,TestJobQueueInformation fails on trunk with following exception:,Open,Unresolved,,Unassigned,Amareshwari Sriramadasu,Mon; 11 Oct 2010 11:10:14 +0000,Mon; 11 Oct 2010 11:10:14 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2122
MAPREDUCE-2123,Improvement,Major,,Multiple threads per JVM,"I have a process th seems to be working:  In the main class:     Configuration config = getConf();     config.set(""num_threads_per_jvm""; Integer.toString(numThreads));     Job job = new Job(config; ""Standardize stuff"");  In the Mapper class:   public void run(final Context context) throws IOException; InterruptedException {     int numThreads = Integer.parseInt(context.getConfiguration().get(""num_threads_per_jvm"");     setup(context);   Wait for all the threads to complete     for (MapRunner mapRunner : mapRunners)  {       mapRunner.join();     }     cleanup(context);   }    private class MapRunner extends Thread {     final Context context;      private MapRunner(Context context)  {       this.context = context;     }      @Override     public void run() {       boolean gotValue = true;       do {         try {           Text key = null;           Text value = null;           synchronized(contextMutex) {             gotValue = context.nextKeyValue();             if (gotValue)  {               key = context.getCurrentKey();               value = context.getCurrentValue();             }           }           if (gotValue)  {             map(key; value; context);           }         } catch (Exception e)  {           throw new RuntimeException(e);         }       } while (gotValue);     }   }",Resolved,Not A Problem,,Unassigned,Randy Wilson,Mon; 11 Oct 2010 17:19:41 +0000,Thu; 31 Jul 2014 00:21:36 +0000,Thu; 31 Jul 2014 00:21:36 +0000,,,,,HADOOP-249,https://issues.apache.org/jira/browse/MAPREDUCE-2123
MAPREDUCE-2124,Improvement,Minor,jobtracker,Add job counters for measuring time spent in three different phases in reducers,We currently have SLOTS_MILLIS_REDUCES which measures the total slot time of reducer. It will be useful if we have   which measures three different phases of a reducer. This will help us identify the bottleneck of the reducers.,Open,Unresolved,,Scott Chen,Scott Chen,Mon; 11 Oct 2010 18:03:18 +0000,Thu; 15 Sep 2011 05:34:07 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2124
MAPREDUCE-2125,Improvement,Major,jobtracker,Put map-reduce framework counters to JobTrackerMetricsInst,We have lots of useful information in the framework counters including #spills; filesystem read and write. It will be nice to put them all in the jobtracker metrics to get a global view of all these numbers.,Open,Unresolved,,Scott Chen,Scott Chen,Mon; 11 Oct 2010 18:12:35 +0000,Thu; 13 Jan 2011 02:29:07 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2125
MAPREDUCE-2126,Improvement,Minor,jobtracker,JobQueueJobInProgressListener's javadoc is inconsistent with source code,JobQueueJobInProgressListener. has  {@link #JobQueueJobInProgressListener(Collection)}  in Javadoc. But it does not have the corresponding constructor. It has constructor JobQueueJobInProgressListener(MapJobSchedulingInfo; JobInProgress jobQueue). So  {@link JobQueueJobInProgressListener(Collection)}  should be  {@link #JobQueueJobInProgressListener(Map)} .,Resolved,Fixed,,Jingguo Yao,Jingguo Yao,Tue; 12 Oct 2010 02:51:03 +0000,Thu; 7 Apr 2011 15:40:55 +0000,Fri; 22 Oct 2010 19:09:18 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2126
MAPREDUCE-2127,Bug,Major,build;pipes,mapreduce trunk builds are failing on hudson,https: build.xml:1647: exec returned: 255,Closed,Fixed,,Bruno Mah  ,Giridharan Kesavan,Tue; 12 Oct 2010 06:50:18 +0000,Tue; 15 Nov 2011 00:49:36 +0000,Fri; 29 Jul 2011 01:29:34 +0000,,0.20.203.1;0.20.204.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2127
MAPREDUCE-2128,Improvement,Minor,documentation,Add alternative search-provider to site,Use search-hadoop.com service to make available search in sources; MLs; wiki; etc. This was initially proposed on user mailing list. The search service was already added in site's skin (common for all Hadoop related projects) before so this issue is about enabling it for MapReduce.,Resolved,Fixed,,Alex Baranau,Alex Baranau,Tue; 12 Oct 2010 12:28:50 +0000,Thu; 14 Oct 2010 21:33:58 +0000,Thu; 14 Oct 2010 21:22:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2128
MAPREDUCE-2129,Bug,Major,jobtracker,Job may hang if mapreduce.job.committer.setup.cleanup.needed=false and mapreduce.map/reduce.failures.maxpercent>0,Job may hang at RUNNING state if mapreduce.job.committer.setup.cleanup.needed=false and mapreduce.map reduce.failures.maxpercent0. It happens when some tasks fail but havent reached failures.maxpercent.,Closed,Fixed,,Subroto Sanyal,Kang Xiao,Tue; 12 Oct 2010 13:15:01 +0000,Wed; 17 Oct 2012 18:27:26 +0000,Fri; 6 Jul 2012 14:25:28 +0000,,0.20.2;0.20.3;0.21.1,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2129
MAPREDUCE-2130,Improvement,Major,contrib/raid,Better distribution of files among DistRaid map tasks,Currently the map tasks get a random subset of the files to be raided. But a disproportionately large file could make a map task extremely slow. We need to give approximately the same amount of data to each map task.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Tue; 12 Oct 2010 20:48:55 +0000,Tue; 1 Aug 2017 17:12:53 +0000,Tue; 1 Aug 2017 17:12:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2130
MAPREDUCE-2131,Improvement,Major,jobtracker,Aggregate JobCounters and TaskCounters in a background thread,JobTracker.getJobCounters() aggregates the counters when getting requested. It may consume lots of CPU if the request is too often. It may be good if we aggregate them in a background thread.  Thoughts?,Open,Unresolved,,Unassigned,Scott Chen,Wed; 13 Oct 2010 16:56:36 +0000,Fri; 19 Aug 2011 11:08:24 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2131
MAPREDUCE-2132,Improvement,Major,contrib/raid,Need a command line option in RaidShell to fix blocks using raid,RaidShell currently has an option to recover a file and return the path to the recovered file. The administrator can then rename the recovered file to the damaged file.  The problem with this is that the file metadata is altered; specifically the modification time. Instead we need a way to just repair the damaged blocks and send the fixed blocks to a data node.  Once this is done; we can put automation around it.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Wed; 13 Oct 2010 19:58:47 +0000,Mon; 12 Dec 2011 06:18:29 +0000,Thu; 21 Oct 2010 20:52:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2132
MAPREDUCE-2133,Bug,Minor,,lag time for reduce speculation should start from completion of first mapper,reducers don't make any progress until first mapper finishes. if the first mapper finishes after the reduce speculation lag time - a bunch of (waiting) reducers may make some (non-zero) progress while others stay at 0 progress. this causes a few reducers to be speculated (unnecessarily) at this stage in the job.   it seems that we should not start counting towards reduce stage lag time until at least one mapper is done.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Wed; 13 Oct 2010 20:13:56 +0000,Wed; 13 Oct 2010 20:13:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2133
MAPREDUCE-2134,Bug,Major,build,ant binary-system is broken in mapreduce project.,Build failed due to unable to copy the commons instrumented jar. I could see the following error in the log.  binary-system:      copy Copying 5 files to  system,Resolved,Fixed,,Konstantin Boudnik,Vinay Kumar Thota,Thu; 14 Oct 2010 05:22:05 +0000,Thu; 7 Apr 2011 15:40:53 +0000,Thu; 21 Oct 2010 22:17:22 +0000,,0.21.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2134
MAPREDUCE-2135,Bug,Major,task,Need a counter for map task output file size,"With MapReduce trunk;  The FileSystem counter FILE_BYTES_WRITTEN is a lot less than ""Map output bytes"" counter even when map output compression is OFF. I think this FILE_BYTES_WRITTEN signifies the bytes written to local file system. So it should be more than map output bytes(in the counters shown below; 210 Vs 19200000). Right ?  Here are some counters from map task of wordcount example:   Counters for attempt_201010141448_0001_m_000000_0  FileInputFormatCounters 	BYTES_READ 	9;600;000  FileSystemCounters 	FILE_BYTES_READ 	92 	FILE_BYTES_WRITTEN 	210 	HDFS_BYTES_READ 	9;600;107  Map-Reduce Framework 	Combine input records 	2;400;000 	Combine output records 	8 	CPU_MILLISECONDS 	4;810 	Failed Shuffles 	0 	GC time elapsed (ms) 	73 	Map input records 	600;000 	Map output bytes 	19;200;000 	Map output records 	2;400;000 	Merged Map outputs 	0 	PHYSICAL_MEMORY_BYTES 	131;518;464 	Spilled Records 	16 	SPLIT_RAW_BYTES 	107 	VIRTUAL_MEMORY_BYTES 	581;021;696",Open,Unresolved,,Unassigned,Ravi Gummadi,Thu; 14 Oct 2010 09:20:56 +0000,Tue; 26 Oct 2010 07:51:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2135
MAPREDUCE-2136,Bug,Minor,contrib/gridmix,Misspelt Configuration Parameter gridmix.throttle.reducess.max-slot-share-per-job,"Via MAPREDUCE-1936; we introduced a new configuration parameter gridmix.throttle.reducess.max-slot-share-per-job that contains a misspelling (""reducess"") that is sure to trip users.  (As if the one in gridmix.user.resolve.class was not bad enough.)",Open,Unresolved,,Unassigned,Ranjit Mathew,Thu; 14 Oct 2010 11:05:50 +0000,Thu; 14 Oct 2010 11:05:50 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2136
MAPREDUCE-2137,Bug,Major,contrib/gridmix,Mapping between Gridmix jobs and the corresponding original MR jobs is needed,"Consider a trace file ""trace1"" obtained by running Rumen on a set of MR jobs' history logs. When gridmix runs simulated jobs from ""trace1""; it may skip some of the jobs from the trace file for some reason like out-of-order-jobs. Now use Rumen to generate trace2 from the history logs of gridmix's simulated jobs. Now; to compare and analyze the gridmix's simulated jobs with original MR jobs; we need a mapping between them.",Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 15 Oct 2010 09:57:31 +0000,Tue; 15 Nov 2011 00:48:54 +0000,Fri; 27 May 2011 04:37:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2137
MAPREDUCE-2138,Task,Major,contrib/gridmix;test,Gridmix tests with different time interval mr traces (1min; 3min and 5min).,1. Generate input data based on cluster size and create the synthetic jobs by using the 1 min folded MR trace and submit the jobs with below arguments.  GRIDMIX_JOB_TYPE = LoadJob GRIDMIX_USER_RESOLVER = SubmitterUserResolver GRIDMIX_SUBMISSION_POLICY = STRESS Input Size = 400 MB * No. of nodes in cluster. TRACE_FILE = 1 min folded trace. Verify each job status and summary(QueueName; UserName; StatTime; FinishTime; maps; reducers and counters etc) after completion of execution.  2. Generate input data based on cluster size and create the synthetic jobs by using the 3 min folded MR trace and submit the jobs with below arguments.  GRIDMIX_JOB_TYPE = LoadJob GRIDMIX_USER_RESOLVER = RoundRobinUserResolver GRIDMIX_SUBMISSION_POLICY = Replay Input Size = 200 MB * No. of nodes in cluster. TRACE_FILE = 3 min folded trace. PROXY_USERS = proxy users file path. Verify each job status; submitted user and summary(QueueName; UserName; StatTime; FinishTime; maps; reducers and counters etc) after completion of execution.  3. Generate input data based on cluster size and create the synthetic jobs by using the 5 min folded MR trace and submit the jobs with below arguments.  GRIDMIX_JOB_TYPE = SleepJob GRIDMIX_USER_RESOLVER = EchoUserResolver GRIDMIX_MIN_FILE = 100 MB GRIDMIX_SUBMISSION_POLICY = Serial Input Size = 300 MB * No. of nodes in cluster. TRACE_FILE = 5 min folded trace. Verify each job status; file size and summary(QueueName; UserName; StatTime; FinishTime; maps; reducers and counters etc) after completion of execution.,Closed,Duplicate,NULL,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 18 Oct 2010 10:39:33 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Wed; 15 Jun 2011 16:43:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2138
MAPREDUCE-2139,Task,Major,test,Gridmix test for submitting jobs with different traces and runtime options.,1.Generate input data based on cluster size and create the synthetic jobs by using the 7 min folded MR trace and submit the jobs with below arguments.  GRIDMIX_JOB_TYPE = SleepJob GRIDMIX_USER_RESOLVER = SubmitterUserResolver GRIDMIX_MIN_FILE = 200 MB GRIDMIX_SUBMISSION_POLICY = STRESS GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false Input Size = 400 MB * No. of nodes in cluster. TRACE_FILE = 7 min folded trace. Verify each job status; summary(QueueName; UserName; StatTime; FinishTime; maps; reducers and counters etc) after completion of execution. Make sure the queue should be default queue name.  2. Generate input data based on cluster size and create the synthetic jobs by using the 10 min folded MR trace and submit the jobs with below arguments.  GRIDMIX_JOB_TYPE = SleepJob GRIDMIX_USER_RESOLVER = RoundRobinUserResolver GRIDMIX_MIN_FILE = 200 MB GRIDMIX_SUBMISSION_POLICY = SERIAL GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false SLEEPJOB_MAPTASK_ONLY = true GRIDMIX_SLEEP_MAX_MAP_TIME = 10 sec Input Size = 250 MB * No. of nodes in cluster. TRACE_FILE = 10 min folded trace. Verify each job status; summary(QueueName; UserName; StatTime; FinishTime; maps and counters etc) after completion of execution. Make sure the reducers should be zero.  3. Generate input data based on cluster size and create the synthetic jobs by using the 12 min folded MR trace and submit the jobs with below arguments.  GRIDMIX_JOB_TYPE = SleepJob GRIDMIX_USER_RESOLVER = SubmitterUserResolver GRIDMIX_MIN_FILE = 200 MB GRIDMIX_SUBMISSION_POLICY = STRESS GRIDMIX_SLEEP_MAX_MAP_TIME = 10 sec GRIDMIX_SLEEP_MAX_REDUCE_TIME = 5 sec Input Size = 150 MB * No. of nodes in cluster. TRACE_FILE = 12 min folded trace. Verify each job status; summary(QueueName; UserName; StatTime; FinishTime; maps;reducers and counters etc) after completion of execution.,Open,Unresolved,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 18 Oct 2010 14:36:14 +0000,Thu; 19 May 2011 05:05:28 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2139
MAPREDUCE-2140,Improvement,Trivial,,Re-generate fair scheduler design doc PDF,The Fair Scheduler contains a design document in src designdoc that is included both as a Latex file and as a PDF. However; the PDF that's currently there is not generated properly and has some question marks for section references. I'd like to regenerate it and commit the new one. There is no patch to attach because this just requires running pdflatex and committing a binary file.,Resolved,Fixed,,Matei Zaharia,Matei Zaharia,Tue; 19 Oct 2010 00:43:41 +0000,Thu; 7 Apr 2011 15:40:50 +0000,Tue; 19 Oct 2010 01:47:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2140
MAPREDUCE-2141,Improvement,Minor,,"Add an ""extra data"" field to Task for use by Mesos",In order to support running Hadoop on the Mesos cluster manager (http: ); I'd like to add an extra String field to the Task class to allow extra data (a Mesos task ID) to be associated with each task. This should have no impact on normal operation other than making the serialized form of Task a few bytes longer. In the Mesos support patch for Hadoop; this field is set by a pluggable Hadoop scheduler implementation to allow code on the TaskTracker side to see which Mesos task corresponds to each Hadoop task.,Resolved,Fixed,,Matei Zaharia,Matei Zaharia,Tue; 19 Oct 2010 00:49:09 +0000,Thu; 7 Apr 2011 15:40:50 +0000,Thu; 11 Nov 2010 03:45:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2141
MAPREDUCE-2142,Task,Major,,Refactor RaidNode to remove dependence on map reduce,I am refactoring the RaidNode code as follows: The base class RaidNode will contain the common functionality needed for raiding files. The derived class LocalRaidNode contains an implementation of RaidNode that performs raiding locally. The derived class DistRaidNode performs raiding using map reduce jobs. This way; only DistRaidNode has a dependency on map reduce code and RaidNode and LocalRaidNode can be moved to HDFS.,Closed,Fixed,,Patrick Kling,Patrick Kling,Tue; 19 Oct 2010 05:29:00 +0000,Mon; 12 Dec 2011 06:18:31 +0000,Mon; 8 Nov 2010 08:49:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2142
MAPREDUCE-2143,Bug,Major,harchive,HarFileSystem is not able to handle spaces in its path,If the Path to the HAR contains spaces; Path.getFileSystem() fails. The problem is in HarFileSystem.initialize(); which uses URI.toString() to get a string for getting to the .har suffix. URI.toString() returns a percent-encoded string when the path contains spaces. When this string is subsequently used to get the _index file; we get a FileNotFoundException. The fix is to use URI.getPath().,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Tue; 19 Oct 2010 17:26:56 +0000,Mon; 12 Dec 2011 06:19:28 +0000,Mon; 25 Oct 2010 18:59:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2143
HDFS-1474,Bug,Major,build,ant binary-system is broken,Build failed due to unable to copy the commons instrumented jar. I could see the following error in the log.,Resolved,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Thu; 21 Oct 2010 05:37:15 +0000,Fri; 22 Oct 2010 00:10:23 +0000,Thu; 21 Oct 2010 23:21:26 +0000,,0.21.1,,,,https://issues.apache.org/jira/browse/HDFS-1474
MAPREDUCE-2145,Improvement,Major,,upgrade clover on the builds servers to v 3.0.2,upgrade clover on the builds servers to v 3.0.2; as the mr builds requires the latest version of clover for better coverage reporting...,Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Thu; 21 Oct 2010 18:58:14 +0000,Mon; 12 Dec 2011 06:19:37 +0000,Thu; 21 Oct 2010 19:15:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2145
MAPREDUCE-2146,Bug,Minor,contrib/raid,Raid should not affect access time of a source file,After a file is read for creating a raid parity file; the access time should be set back to the value before the read. The read by RAID code is not an application read and should not affect the access time.,Resolved,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Thu; 21 Oct 2010 21:58:04 +0000,Thu; 7 Apr 2011 15:40:51 +0000,Wed; 27 Oct 2010 05:23:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2146
MAPREDUCE-2147,Improvement,Trivial,jobtracker,JobInProgress has some redundant lines in its ctor,In the ctor of JobInProgress class that's used by the JT; lines that create the various lists of TIPs are repeated for no purpose. Might've been due to an overlook I think.  Attaching a patch that removes these unnecessary repeats of re-init.,Resolved,Fixed,,Harsh J,Harsh J,Fri; 22 Oct 2010 06:33:29 +0000,Thu; 7 Apr 2011 15:40:51 +0000,Fri; 22 Oct 2010 17:51:24 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2147
MAPREDUCE-2148,Improvement,Major,task,More precise documentation for setOutputValueGroupingComparator,The Javadoc of JobConf#setOutputValueGroupingComparator method explains the usage of a comparator for grouping keys. org.apache.hadoop.examples.SecondarySort uses such a comparator. In SecondarySort; all the 2 parts of IntPair is used for key sorting. The first part of IntPair is used for partition and grouping. When the first parts of several IntPairs are equal to each other; it is very possible that these IntPairs are not equal to each other. These IntPairs will be grouped in a single invocation of reduce method since group comparator only use the first part of IntPairs. However; reduce method only accepts a single key object. In such kind of situations; the first IntPair is used as the key in reduce method.  I have checked the source code of Task.ValuesIterator whose logic is consistent with the above behaviour.  I think that such behavior of grouping comparator should be documented in JobConf#setOutputValueGroupingComparator.  I am happy to provide  a patch if some committer think that this is an issue.,Open,Unresolved,,Unassigned,Jingguo Yao,Fri; 22 Oct 2010 13:59:39 +0000,Fri; 22 Oct 2010 14:01:23 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2148
MAPREDUCE-2149,Bug,Major,distcp,Distcp : setup with update is too slow when latency is high,"If you run distcp with '-update' option; for each of the files present on source cluster setup invokes a separate RPC to destination cluster to fetch file info.  Usually this overhead is not very noticeable when both cluster are geographically close to each other. But if the latency is large; setup could take couple of orders of magnitude longer.  E.g. : source has 10k directories; each with about 10 files; round trip latency between source and destination is 75 ms (typical for coast-to-coast clusters).  If we run distcp on source cluster; set up would take about 2.5 hours irrespective of whether destination has these files or not. '-lsr' on the same dest dir from source cluster would take up to 12 min (depending on how many directories already exist on dest).    	A fairly simple fix to how setup() iterates should bring the set up time to same as '-lsr'. I will have a patch for this.. (though 12 min is too large). 	A more scalable option is to differ update check to mappers.",Resolved,Fixed,,Raghu Angadi,Raghu Angadi,Mon; 25 Oct 2010 16:14:12 +0000,Thu; 24 Aug 2017 23:55:21 +0000,Tue; 8 Nov 2016 15:21:02 +0000,,0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2149
MAPREDUCE-2150,Improvement,Major,contrib/raid,RaidNode should periodically fix corrupt blocks,(Recreating HDFS-1171 since RAID is in mapreduce)  RaidNode currently does not fix missing blocks. The missing blocks have to be fixed using RaidShell. This task proposes that recovery be more automated: 1. RaidNode periodically fetches a list of corrupt files from the NameNode 2. If the corrupt files can be fixed using RAID; it should generate the block. 3. Choose a datanode and send the block contents along with checksum to the datanode.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Mon; 25 Oct 2010 20:42:56 +0000,Thu; 2 May 2013 02:29:33 +0000,Fri; 29 Oct 2010 01:25:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2150
MAPREDUCE-2151,New Feature,Major,tools/rumen,[rumen] Add a map of jobconf key-value pairs in LoggedJob,It'd be useful to retain application level configuration settings in LoggedJob.,Closed,Duplicate,MAPREDUCE-2153,Hong Tang,Hong Tang,Tue; 26 Oct 2010 00:54:02 +0000,Tue; 15 Nov 2011 00:48:43 +0000,Fri; 24 Jun 2011 05:46:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2151
MAPREDUCE-2152,Improvement,Major,,Use Configuration object instead of Properties in TraceBuilder,Currently; TraceBuilder has its own mapping of old and new mapreduce configuration properties. This is fine till now because there are only few(3 or 4) configuration properties of interest. But as we are planning to bring in more and more configuration properties into the trace file(9 properties are needed for emulating distributed cache usage in gridmix and about 5 properties are needed for emulating data compression in gridmix jobs and few other properties like io.sort.mb; io.sort.factor which should ideally be set for gridmix jobs); it is better to make TraceBuilder use Configuration object. This avoids code duplication regarding mapping between deprecated configration properties and current new configuration properties.,Open,Unresolved,,Unassigned,Ravi Gummadi,Tue; 26 Oct 2010 05:59:34 +0000,Tue; 26 Oct 2010 05:59:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2152
MAPREDUCE-2153,Improvement,Major,tools/rumen,Bring in more job configuration properties in to the trace file,To emulate distributed cache usage in gridmix jobs; there are 9 configuration properties needed to be available in trace file:  (1) mapreduce.job.cache.files (2) mapreduce.job.cache.files.visibilities (3) mapreduce.job.cache.files.filesizes (4) mapreduce.job.cache.files.timestamps  (5) mapreduce.job.cache.archives (6) mapreduce.job.cache.archives.visibilities (7) mapreduce.job.cache.archives.filesizes (8) mapreduce.job.cache.archives.timestamps  (9) mapreduce.job.cache.symlink.create  To emulate data compression in gridmix jobs; trace file should contain the following configuration properties: (1) mapreduce.map.output.compress (2) mapreduce.map.output.compress.codec (3) mapreduce.output.fileoutputformat.compress (4) mapreduce.output.fileoutputformat.compress.codec (5) mapreduce.output.fileoutputformat.compress.type  Ideally; gridmix should set many job specific configuration properties like io.sort.mb; io.sort.factor; etc when running simulated jobs to get the same effect of original real job in terms of spilled records; number of merges; etc.  TraceBuilder should bring in all these properties into the generated trace file.,Closed,Fixed,,Rajesh Balamohan,Ravi Gummadi,Tue; 26 Oct 2010 06:07:38 +0000,Tue; 15 Nov 2011 00:48:09 +0000,Thu; 28 Apr 2011 05:49:44 +0000,,0.23.0,,MAPREDUCE-2407;MAPREDUCE-2408;MAPREDUCE-2725,,https://issues.apache.org/jira/browse/MAPREDUCE-2153
MAPREDUCE-2154,Bug,Major,contrib/gridmix,Gridmix mapper doesn't emit the correct map output records while comparing with json file.,I ran Gridmix with a trace file and compared the job history information against the trace after completion of job. The map output records in a job history have not matched with the map output records in a trace file.  For reproducing the issue; please download the attached trace file and run the gridmix. Later compare the map output records in a job history with a trace file.,Open,Unresolved,,Amar Kamat,Vinay Kumar Thota,Tue; 26 Oct 2010 08:35:14 +0000,Wed; 1 Jun 2011 03:33:38 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2154
MAPREDUCE-2155,Improvement,Major,contrib/raid,RaidNode should optionally dispatch map reduce jobs to fix corrupt blocks (instead of fixing locally),Recomputing blocks based on parity information is expensive. Rather than doing this locally at the RaidNode; we should run map reduce jobs. This will allow us to quickly fix a large number of corrupt or missing blocks.,Closed,Fixed,,Patrick Kling,Patrick Kling,Tue; 26 Oct 2010 17:06:58 +0000,Thu; 2 May 2013 02:29:33 +0000,Tue; 30 Nov 2010 06:25:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2155
MAPREDUCE-2156,Improvement,Major,contrib/raid,Raid-aware FSCK,Currently; FSCK reports files as corrupt even if they can be fixed using parity blocks. We need a tool that only reports files that are irreparably corrupt (i.e.; files for which too many data or parity blocks belonging to the same stripe have been lost or corrupted).,Closed,Fixed,,Patrick Kling,Patrick Kling,Tue; 26 Oct 2010 17:16:06 +0000,Thu; 2 May 2013 02:29:34 +0000,Fri; 3 Dec 2010 06:00:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2156
MAPREDUCE-2157,Bug,Major,,safely handle InterruptedException and interrupted status in MR code,taskLauncher thread exits on interruptedException and on Interrupt conditions without checking for any shutdown flag:       while (!Thread.interrupted())  {         ...         }  catch (InterruptedException e)  {            return;  AsyncAppender.html,Open,Unresolved,,Joydeep Sen Sarma,Joydeep Sen Sarma,Tue; 26 Oct 2010 17:50:53 +0000,Tue; 10 Jul 2012 21:27:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2157
MAPREDUCE-2158,Improvement,Major,task-controller,Remove need for taskcontroller.cfg,"The taskcontroller.cfg configuration file seems unnecessary. It's parsed by the task-controller binary; and the path to it is baked into that binary at compile-time. It contains only 3 values; none of which are secret; all of which are also specified in either core-site.xml or mapred-site.xml. It seems like getting rid of taskcontroller.cfg will simplify configuration; and have no impact on the security of the system  I suggest we either:   	Pass these values as arguments to task-controller when we execute it. 	Use xerces to enable the task-controller to parse *-site.xml.    Of these two options; I think option 1 seems the cleanest easiest. Either would be backward-compatible with existing configurations.",Open,Unresolved,,Aaron T. Myers,Aaron T. Myers,Wed; 27 Oct 2010 00:10:23 +0000,Wed; 27 Oct 2010 00:10:23 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2158
MAPREDUCE-2159,Improvement,Major,contrib/raid,Provide metrics for RaidNode,"It will be useful to have the following metrics for RAID:  	files raided 	files too new to be raided 	files too small to be raided 	number of blocks fixed using raid.",Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 27 Oct 2010 18:57:31 +0000,Tue; 1 Aug 2017 17:12:49 +0000,Tue; 1 Aug 2017 17:12:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2159
MAPREDUCE-2160,Bug,Major,,DistCp shouldn't attempt to copy files open for writing,Copying a file while it is being written leads to self-evident consistency issues and copy failures.,Open,Unresolved,,Unassigned,Dmitriy V. Ryaboy,Wed; 27 Oct 2010 19:30:56 +0000,Wed; 27 Oct 2010 19:30:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2160
MAPREDUCE-2161,Bug,Major,,DistCp should double-check copy size when expectation is unmet,DistCp checks if the file size on the destination matches the file size at the source in order to do a basic sanity check. When this fails; DistCp logs something along the lines of   io.IOException: File size not matched: copied 3451980786 bytes (3.2g) to tmpfile (=hdfs: file)  and attempts to retry. The expected file size is picked up during initialization. This expectation can be incorrect for at least 2 reasons: you are copying a file which was being written to at the time distcp was started (which is a bug in and of itself); or the file was replaced at the source between the time the DistCp job was started and the time it actually tried to copy the file.  It would make sense to get the current the size of the origin file when this condition is encountered; and proceed if the newly reported file size matches that of the file copied.,Open,Unresolved,,Unassigned,Dmitriy V. Ryaboy,Wed; 27 Oct 2010 19:37:08 +0000,Wed; 27 Oct 2010 19:37:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2161
MAPREDUCE-2162,Bug,Major,,speculative execution does not handle cases where stddev > mean well,the new speculation code only speculates tasks whose progress rate deviates from the mean progress rate of a job by more than some multiple (typically 1.0) of stddev. stddev can be larger than mean. which means that if we ever get into a situation where this condition holds true - then a task with even 0 progress rate will not be speculated.  it's not clear that this condition is self-correcting. if a job has thousands of tasks - then one laggard task; inspite of not being speculated for a long time; may not be able to fix the condition of stddev  mean.  we have seen jobs where tasks have not been speculated for hours and this seems one explanation why this may have happened. here's an example job with stddev  mean:  DataStatistics: count is 6; sum is 1.7141054797775723E-8; sumSquares is 2.9381575958035014E-16 mean is 2.8568424662959537E-9 std() is 6.388093955645905E-9,Open,Unresolved,,Joydeep Sen Sarma,Joydeep Sen Sarma,Thu; 28 Oct 2010 01:02:39 +0000,Thu; 2 Dec 2010 00:24:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2162
MAPREDUCE-2163,Bug,Major,test,MiniMRCluster does not start correctly.,Test code written against MiniMRCluster does not execute correctly. The MiniDFSCluster instance comes up alright; but when the MiniMRCluster starts up; one gets hundreds of stack-traces of the following kind:    INFO ipc.Server: IPC Server handler 2 on 61176; call getBuildVersion() from 127.0.0.1:61181: error:  1393)  It would appear that the hadoop-mapred-test-0.22.0-SNAPSHOT.jar hosted on Apache might be missing the srcChecksum element; wherever HadoopVersionAnnotation is being used.,Open,Unresolved,,Unassigned,Mithun Radhakrishnan,Thu; 28 Oct 2010 10:39:28 +0000,Thu; 28 Oct 2010 10:48:28 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2163
MAPREDUCE-2164,Bug,Critical,test,MapredTestDriver.java compilation fails on trunk,compile-mapred-test:     mkdir Created dir:  testshell        2 errors,Resolved,Cannot Reproduce,,Unassigned,Giridharan Kesavan,Thu; 28 Oct 2010 22:40:53 +0000,Fri; 29 Oct 2010 04:22:18 +0000,Fri; 29 Oct 2010 04:22:18 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2164
MAPREDUCE-2165,Sub-task,Major,contrib/streaming,Add support for skipping records in streaming for new api.,nan,Resolved,Won't Fix,,Unassigned,Amareshwari Sriramadasu,Fri; 29 Oct 2010 10:25:44 +0000,Mon; 19 Dec 2011 15:00:39 +0000,Mon; 19 Dec 2011 15:00:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2165
MAPREDUCE-2166,Bug,Minor,task,map.input.file is not set,"Hadoop does not set the ""map.input.file"" variable. I tried the fallowing and all I get is ""null"".  public class Map extends MapperObject; Text; LongWritable; Text {     public void map(Object key; Text value; Context context)            throws IOException; InterruptedException  {        Configuration conf = context.getConfiguration();        System.out.println(conf.get(""map.input.file""));    }     protected void setup(Context context) throws IOException;            InterruptedException {       Configuration conf = context.getConfiguration();       System.out.println(conf.get(""map.input.file""));   } }",Resolved,Not A Problem,,Unassigned,Rares Vernica,Thu; 4 Jun 2009 14:55:48 +0000,Tue; 22 Jul 2014 20:23:48 +0000,Tue; 22 Jul 2014 20:23:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2166
MAPREDUCE-2167,Improvement,Major,contrib/raid,Faster directory traversal for raid node,"The RaidNode currently iterates over the directory structure to figure out which files to RAID. With millions of files; this can take a long time - especially if some files are already RAIDed and the RaidNode needs to look at parity files   parity file HARs to determine if the file needs to be RAIDed.  The directory traversal is encapsulated inside the class DirectoryTraversal; which examines one file at a time; using the caller's thread.  My proposal is to make this multi-threaded as follows:  	use a pool of threads inside DirectoryTraversal 	The caller's thread is used to retrieve directories; and each new directory is assigned to a thread in the pool. The worker thread examines all the files the directory. 	If there sub-directories; those are added back as workitems to the pool.    Comments?",Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Fri; 29 Oct 2010 19:00:41 +0000,Mon; 12 Dec 2011 06:18:58 +0000,Fri; 12 Nov 2010 00:02:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2167
MAPREDUCE-2168,Improvement,Major,,We should  implement limits on shuffle connections to TaskTracker per job,As trailing map tasks will be attacked by all reduces simultaneously; all the worker threads that for the http server of a TaskTracker may be occupied  by one job's reduce tasks to fetch map outputs. Then this tasktracker's iowait and load will be very high (100+ in our cluster; we set tasktracker.http.threads with 100). What's more; other job's reduces have to wait some time (may be several minutes) to connect to the TaskTracker to fetch there map's outputs. So I think we should implement limits on shuffle connections: 1. limit the worker threads' number maybe percent  occupied  the same job's reduces ; 2. limit the worker threads' number serving the same map output simultaneously. Thoughts?   ps: we are using hadoop 0.19.,Open,Unresolved,,Unassigned,Liyin Liang,Mon; 1 Nov 2010 12:56:09 +0000,Mon; 1 Nov 2010 16:03:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2168
MAPREDUCE-2169,Task,Major,contrib/raid,Integrated Reed-Solomon code with RaidNode,Scott Chen recently checked in an implementation of  the Reed Solomon code. This task will track the integration of the code with RaidNode.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Mon; 1 Nov 2010 19:57:02 +0000,Mon; 12 Dec 2011 06:18:47 +0000,Fri; 12 Nov 2010 00:18:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2169
YARN-349,New Feature,Major,nodemanager,Send out last-minute load averages in TaskTrackerStatus,Load averages could be useful in scheduling. This patch looks to extend the existing Linux resource plugin (via  ,Open,Unresolved,MAPREDUCE-1438,Unassigned,Harsh J,Mon; 1 Nov 2010 20:04:45 +0000,Wed; 8 Mar 2017 12:22:20 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-349
MAPREDUCE-2171,Improvement,Major,jobtracker;tasktracker,job recovery mechanism,A job recovery mechanism to enable a job to re-execute only failed task upon job failed or jobtracker tasktracker restart.,Open,Unresolved,,Unassigned,Kang Xiao,Tue; 2 Nov 2010 09:25:43 +0000,Wed; 3 Nov 2010 02:30:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2171
MAPREDUCE-2172,Bug,Major,,test-patch.properties contains incorrect/version-dependent values of OK_FINDBUGS_WARNINGS and OK_RELEASEAUDIT_WARNINGS,Running ant test-patch with an empty patch yields 25 findbugs warning and 3 release audit warnings (rather than the 0 findbugs warnings and 1 release audit warning specified in test-patch.properties):,Closed,Fixed,,Nigel Daley,Patrick Kling,Wed; 3 Nov 2010 02:24:54 +0000,Tue; 15 Nov 2011 00:49:34 +0000,Fri; 19 Nov 2010 06:27:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2172
MAPREDUCE-2173,Bug,Major,,Race condition in TestBlockFixer causes intermittent failure,TestBlockFixer sometimes fails in reportCorruptBlocks because a corrupt block is deleted before in.readFully is called. This causes a BlockMissingException instead of the expected ChecksumException.,Closed,Fixed,,Patrick Kling,Patrick Kling,Wed; 3 Nov 2010 02:46:16 +0000,Mon; 12 Dec 2011 06:19:16 +0000,Mon; 8 Nov 2010 08:34:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2173
MAPREDUCE-2174,Improvement,Major,,Introduce timeout in bin/slaves.sh,If connection to one slave has problem; slaves.sh appears to hang. We can incorporate timeout mechanism by using the script from Dmitry V Golovashkin,Resolved,Not A Problem,,Unassigned,Ted Yu,Wed; 3 Nov 2010 17:51:56 +0000,Sun; 8 Feb 2015 18:03:38 +0000,Sun; 8 Feb 2015 18:03:38 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2174
MAPREDUCE-2175,Bug,Major,jobtracker,speculation framework does not update job progress rate with time causing false speculation,When considering task speculation - the job's overall progress rate for the given task type and the individual task's progress rate are compared. When doing so - the task's current progress rate is considered. However the job's overall progress rate is only only updated when a task's progress report is received.  This causes weirdness if a particular task does not report for a while. The job's progress rate is not updated - but the task's progress rate decays. For single task jobs - it causes speculation almost inevitably.   We need to update the job's overall progress rate as the task's progress rate changes.,Resolved,Duplicate,MAPREDUCE-2062,Unassigned,Joydeep Sen Sarma,Wed; 3 Nov 2010 17:53:30 +0000,Wed; 3 Nov 2010 18:06:07 +0000,Wed; 3 Nov 2010 18:06:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2175
MAPREDUCE-2176,Bug,Major,,ant test-patch failing on a clean checkout,ant test-patch fails for a dummy patch on CHANGES.txt:,Resolved,Duplicate,MAPREDUCE-2172,Unassigned,Ramkumar Vadali,Fri; 5 Nov 2010 01:28:22 +0000,Fri; 5 Nov 2010 18:23:51 +0000,Fri; 5 Nov 2010 18:23:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2176
MAPREDUCE-2177,Bug,Major,tasktracker,The wait for spill completion should call Condition.awaitNanos(long nanosTimeout),We sometimes saw maptask timeout in cdh3b2. Here is log from one of the maptasks:  2010-11-04 10:34:23;820 INFO org.apache.hadoop.mapred.MapTask: Spilling map output: buffer full= true 2010-11-04 10:34:23;820 INFO org.apache.hadoop.mapred.MapTask: bufstart = 119534169; bufend = 59763857; bufvoid = 298844160  2010-11-04 10:34:23;820 INFO org.apache.hadoop.mapred.MapTask: kvstart = 438913; kvend = 585320; length = 983040 2010-11-04 10:34:41;615 INFO org.apache.hadoop.mapred.MapTask: Finished spill 3 2010-11-04 10:35:45;352 INFO org.apache.hadoop.mapred.MapTask: Spilling map output: buffer full= true  2010-11-04 10:35:45;547 INFO org.apache.hadoop.mapred.MapTask: bufstart = 59763857; bufend = 298837899; bufvoid = 298844160 2010-11-04 10:35:45;547 INFO org.apache.hadoop.mapred.MapTask: kvstart = 585320; kvend = 731585; length = 983040  2010-11-04 10:45:41;289 INFO org.apache.hadoop.mapred.MapTask: Finished spill 4  Note how long the last spill took.  In MapTask.  the following code waits for spill to finish: while (kvstart != kvend)  { reporter.progress(); spillDone.await(); }  In trunk code; code is similar.  There is no timeout mechanism for Condition.await(). In case the SpillThread takes long before calling spillDone.signal(); we would see timeout. Condition.awaitNanos(long nanosTimeout) should be called.,Open,Unresolved,,Unassigned,Ted Yu,Sun; 7 Nov 2010 00:57:39 +0000,Tue; 7 Jun 2011 15:15:24 +0000,,,0.20.2,,,MAPREDUCE-2187,https://issues.apache.org/jira/browse/MAPREDUCE-2177
MAPREDUCE-2178,Bug,Major,security;task-controller,Race condition in LinuxTaskController permissions handling,The linux-task-controller executable currently traverses a directory heirarchy and calls chown chmod on the files inside. There is a race condition here which can be exploited by an attacker; causing the task-controller to improprly chown an arbitrary target file (via a symlink) to the user running a MR job. This can be exploited to escalate to root.  this issue was raised and discussed on the security@ list over the last couple of months,Resolved,Fixed,,Benoy Antony,Todd Lipcon,Tue; 9 Nov 2010 02:18:26 +0000,Thu; 2 May 2013 02:29:37 +0000,Tue; 5 Jun 2012 02:38:34 +0000,,0.22.0,,MAPREDUCE-2376;MAPREDUCE-2266;MAPREDUCE-2371;HADOOP-7338,,https://issues.apache.org/jira/browse/MAPREDUCE-2178
MAPREDUCE-2179,Bug,Blocker,contrib/raid,RaidBlockSender.java compilation fails,https: consoleFull   Mapreduce trunk compilation is broken with   compile:      echo contrib: raid       2 errors,Closed,Fixed,,Ramkumar Vadali,Giridharan Kesavan,Tue; 9 Nov 2010 05:46:09 +0000,Mon; 12 Dec 2011 06:19:00 +0000,Tue; 9 Nov 2010 07:32:58 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2179
MAPREDUCE-2180,Test,Minor,contrib/fair-share,Add coverage of fair scheduler servlet to system test,MAPREDUCE-2051 added a system test for the fair scheduler which starts a minicluster and runs a couple jobs with preemption on. I recently found a deadlock in a previous version of the scheduler that was due to lock inversion between the scheduler servlet and some JT internals. I'd like to modify the existing system test to also hit the  scheduler servlet; allowing jcarder to detect such lock inversions in the future.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 9 Nov 2010 22:28:21 +0000,Thu; 7 Apr 2011 15:40:41 +0000,Thu; 20 Jan 2011 00:15:37 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2180
MAPREDUCE-2181,Bug,Major,job submission;jobtracker,mapreduce.jobtracker.staging.root.dir default is unreasonable,The default for mapreduce.jobtracker.staging.root.dir is set to ${hadoop.tmp.dir} user (as is suggested by the description of that configuration) and then fix LocalJobRunner to use a different configuration  perhaps mapreduce.localjobrunner.staging.root.dir  to make it clear that it's a local path. That one could legitimately default to something inside hadoop.tmp.dir.,Open,Unresolved,,Unassigned,Todd Lipcon,Wed; 10 Nov 2010 01:07:23 +0000,Wed; 10 Nov 2010 02:50:14 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2181
MAPREDUCE-2182,Bug,Minor,contrib/vaidya,vaidya does not compile,Vaidya no longer compiles. It's not built by default.,Open,Unresolved,,Unassigned,Eli Collins,Thu; 11 Nov 2010 05:50:47 +0000,Thu; 11 Nov 2010 05:50:47 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2182
MAPREDUCE-2183,New Feature,Minor,build,Adding new target to build.xml to run test-core without compiling,While testing Apache Harmony Select (lightweight version of Harmony) with Hadoop mapreduce we had to first build with Harmony and then test using Harmony Select using the test-core target. This was done in an effort to investigate any issues with Harmony Select in running common. However; the test-core target also compiles the classes which we are unable to do with Harmony Select. A new target is proposed that only runs the tests without compiling them.,Resolved,Won't Fix,,Unassigned,Guillermo Cabrera,Thu; 11 Nov 2010 14:37:47 +0000,Thu; 17 Mar 2016 16:20:29 +0000,Thu; 17 Mar 2016 16:20:29 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2183
MAPREDUCE-2184,Improvement,Major,contrib/raid,Port DistRaid.java to new mapreduce API,DistRaid. was implemented with the older mapred API; this task is for porting it to the new API,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Fri; 12 Nov 2010 19:43:04 +0000,Mon; 12 Dec 2011 06:19:57 +0000,Mon; 22 Nov 2010 23:46:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2184
MAPREDUCE-2185,Bug,Major,job submission,Infinite loop at creating splits using CombineFileInputFormat,This is caused by a missing block in HDFS. So the block's locations are empty. The following code adds the block to blockToNodes map but not to rackToBlocks map. Later on when generating splits; only blocks in rackToBlocks are removed from blockToNodes map. So blockToNodes map can never become empty therefore causing infinite loop,Closed,Fixed,,Ramkumar Vadali,Hairong Kuang,Fri; 12 Nov 2010 20:12:31 +0000,Tue; 15 Nov 2011 00:48:27 +0000,Mon; 6 Jun 2011 22:25:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2185
MAPREDUCE-2186,Improvement,Major,contrib/raid,DistributedRaidFileSystem should implement getFileBlockLocations(),If a RAIDed file has missing blocks; DistributedRaidFileSystem.getFileBlockLocations() would return no block locations. This could lead a client to believe that the file is not readable. But if parity data is available; the file actually is readable.  It would be better to implement getFileBlockLocations() and return the location of the parity blocks that would be needed to reconstruct the missing block.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Fri; 12 Nov 2010 21:45:38 +0000,Mon; 23 May 2011 17:39:31 +0000,Mon; 23 May 2011 17:39:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2186
MAPREDUCE-2187,Bug,Major,,map tasks timeout during sorting,During the execution of a large job; the map tasks timeout:     The bug is in the fact that the mapper has already finished; and; according to the logs; the timeout occurs during the merge sort phase. The intermediate data generated by the map task is quite large. So I think this is the problem.  The logs show that the merge-sort was running for 10 minutes when the task was killed. I think the mapred.Merger should call Reporter.progress() somewhere.,Closed,Fixed,,Anupam Seth,Gianmarco De Francisci Morales,Mon; 15 Nov 2010 17:29:44 +0000,Wed; 19 Oct 2011 00:26:05 +0000,Mon; 1 Aug 2011 22:53:51 +0000,,0.20.2;0.20.205.0,,,MAPREDUCE-2177,https://issues.apache.org/jira/browse/MAPREDUCE-2187
MAPREDUCE-2188,Bug,Major,,The new API MultithreadedMapper doesn't call the initialize method of the RecordReader,The wrapping RecordReader in the Multithreaded Mapper is never initialized. With HADOOP-6685; this becomes a problem because the ReflectionUtils.copy requires a non-null configuration.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Mon; 15 Nov 2010 23:55:45 +0000,Mon; 12 Dec 2011 06:18:31 +0000,Fri; 4 Feb 2011 03:40:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2188
MAPREDUCE-2189,Bug,Major,contrib/raid,RAID Parallel traversal needs to synchronize stats,The implementation of multi-threaded directory traversal does not update stats in a thread-safe manner,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Tue; 16 Nov 2010 05:27:04 +0000,Tue; 1 Aug 2017 17:09:55 +0000,Tue; 1 Aug 2017 17:09:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2189
MAPREDUCE-2190,New Feature,Minor,,Temporary Fix when using Apache Harmony; can't handle default access modifier in JvmContext.java,Using Apache Harmony Select as the JRE to test Hadoop Map Reduce; however; we wanted to introduce a temporary fix for anyone working with Hadoop and Apache Harmony.,Open,Unresolved,,Unassigned,Guillermo Cabrera,Tue; 16 Nov 2010 16:41:43 +0000,Tue; 16 Nov 2010 17:48:55 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2190
MAPREDUCE-2191,Bug,Major,build,Findbugs reports 13 warnings on trunk,"Findbugs reports 13 warnings on trunk:  Warning Type	Number Bad practice Warnings	1 Correctness Warnings	5 Multithreaded correctness Warnings	6 Performance Warnings	1 Total	13",Resolved,Duplicate,MAPREDUCE-2193,Unassigned,Eli Collins,Wed; 17 Nov 2010 20:21:33 +0000,Mon; 5 Sep 2011 19:02:30 +0000,Mon; 5 Sep 2011 18:47:56 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2191
MAPREDUCE-2192,Task,Major,contrib/gridmix,Implement gridmix system tests with different time intervals for MR streaming job traces.,Develop gridmix system tests for below scenarios by using different time intervals of  MR streaming jobs.  1. Generate input data based on cluster size and create the synthetic jobs by using the 2 min folded MR streaming jobs trace and submit the jobs with below arguments. GRIDMIX_JOB_TYPE = LOADJOB GRIDMIX_USER_RESOLVER = SubmitterUserResolver GRIDMIX_SUBMISSION_POLICY = STRESS GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = True Input Size = 250 MB * No. of nodes in cluster. MINIMUM_FILE_SIZE=150MB TRACE_FILE = 2 min folded trace. Verify JobStatus for each job; input split size for each job and summary (QueueName; UserName; StatTime; FinishTime; maps; reducers and counters etc) after completion of execution.  2.  Generate input data based on cluster size and create the synthetic jobs by using the 3 min folded MR streaming jobs trace and submit the jobs with below arguments. GRIDMIX_JOB_TYPE = LoadJob GRIDMIX_USER_RESOLVER = RoundRobinUserResolver GRIDMIX_BYTES_PER_FILE = 150 MB GRIDMIX_SUBMISSION_POLICY = REPLAY GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = True Input Size = 200 MB * No. of nodes in cluster. PROXY_USERS = proxy users file path TRACE_FILE = 3 min folded trace. Verify JobStatus for each job; input split size for each job and summary (QueueName; UserName; StatTime; FinishTime; maps; reducers and counters etc) after completion of execution.  3. Generate input data based on cluster size and create the synthetic jobs by using the 5 min MR streaming jobs trace and submit the jobs with below arguments. GRIDMIX_JOB_TYPE = LoadJob GRIDMIX_USER_RESOLVER = SubmitterUserResolver GRIDMIX_SUBMISSION_POLICY = SERIAL GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false GRIDMIX_KEY_FRC = 0.5f Input Size = 200MB * No. of nodes in cluster. TRACE_FILE = 5 min folded trace. Verify JobStatus for each job and summary (QueueName; UserName; StatTime; FinishTime; MAPS; REDUCERS and COUNTERS etc) after completion of execution.,Closed,Duplicate,MAPREDUCE-2138,Vinay Kumar Thota,Vinay Kumar Thota,Thu; 18 Nov 2010 15:02:08 +0000,Tue; 15 Nov 2011 00:48:49 +0000,Wed; 15 Jun 2011 16:44:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2192
MAPREDUCE-2193,Bug,Blocker,,13 Findbugs warnings on trunk and branch-0.22,There are 13 findbugs warnings on trunk.  See attached html file.  These must be fixed or filtered out to get back to 0 warnings.  The OK_FINDBUGS_WARNINGS property in src test-patch.properties should also be set to 0 in the patch that fixes this issue.,Resolved,Not A Problem,,Unassigned,Nigel Daley,Fri; 19 Nov 2010 06:06:15 +0000,Sat; 7 Jul 2012 12:49:41 +0000,Sat; 7 Jul 2012 12:49:40 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2193
MAPREDUCE-2194,Bug,Major,,Local mode seems to be broken in Cloudera's 737 release,"We have upgraded our dev environment from Cloudera's 0.20.2-228-cloudera to 0.20.2-737-cloudera  Version 228 worked great for us. In version 737 we are getting the following exception:  (LocalJobRunner. 212)  We have tried to set job.getConfiguration().setBoolean(""mapred.reducer.new-api""; true) but that did not resolve the issue.",Resolved,Invalid,,Unassigned,Alex Rovner,Fri; 19 Nov 2010 16:40:57 +0000,Fri; 19 Nov 2010 16:49:08 +0000,Fri; 19 Nov 2010 16:49:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2194
MAPREDUCE-2195,Bug,Major,test,New property for local conf directory in system-test-mapreduce.xml file.,As its counter-part HDFS-1167: new parameter needs to be added to the system-test configuration file to serve 'cluster restart with new  configuration' feature,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Fri; 19 Nov 2010 22:14:15 +0000,Mon; 12 Dec 2011 06:19:54 +0000,Fri; 19 Nov 2010 23:25:29 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2195
MAPREDUCE-2196,Improvement,Minor,,Wrong usage of {@link} tag in the javadoc for MultithreadedMapRunner and MultithreadedMapper,{@link}  tag is not used correctly for MultithreadedMapRunner and MultithreadedMapper. So the  oc for these two classes is not generated correctly. The patch will also fix https: HADOOP-4928.,Open,Unresolved,,Jingguo Yao,Jingguo Yao,Sat; 20 Nov 2010 15:28:26 +0000,Mon; 21 Mar 2011 10:12:55 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2196
MAPREDUCE-2197,Bug,Major,,ant javadoc complains the missing of ExcludePrivateAnnotationsStandardDoclet,"When running ""ant  oc 1 error",Open,Unresolved,,Unassigned,Jingguo Yao,Sat; 20 Nov 2010 15:54:11 +0000,Thu; 10 Feb 2011 06:06:11 +0000,,,0.21.0,,,MAPREDUCE-2315,https://issues.apache.org/jira/browse/MAPREDUCE-2197
MAPREDUCE-2198,New Feature,Major,contrib/fair-share,Allow FairScheduler to control the number of slots on each TaskTracker,We can set the number of slots on the TaskTracker to be high and let FairScheduler handles the slots. This approach allows us to change the number of slots on each node dynamically. The administrator can change the number of slots with a CLI tool.  One use case of this is for upgrading the MapReduce. Instead of restarting the cluster; we can run the new MapReduce on the same cluster. And use the CLI tool to gradually migrate the slots. This way we don't lost the progress fo the jobs that's already executed.,Closed,Won't Fix,,Scott Chen,Scott Chen,Tue; 23 Nov 2010 02:38:17 +0000,Tue; 15 Nov 2011 00:49:36 +0000,Thu; 15 Sep 2011 05:09:43 +0000,,0.23.0,,,MAPREDUCE-2108,https://issues.apache.org/jira/browse/MAPREDUCE-2198
MAPREDUCE-2199,Bug,Major,build,build is broken 0.22 branch creation,hdfs and common dep versions weren't updated properly.,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Tue; 23 Nov 2010 21:47:04 +0000,Tue; 15 Nov 2011 00:49:43 +0000,Tue; 23 Nov 2010 22:03:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2199
MAPREDUCE-2200,Bug,Major,test,TestUmbilicalProtocolWithJobToken is failing without Krb evironment: needs to be conditional,TestUmbilicalProtocolWithJobToken requires Krb environment to be set. For testing some 'pseudo' environment is needed (similar to HDFS-1284).,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Wed; 24 Nov 2010 18:23:18 +0000,Mon; 12 Dec 2011 06:18:33 +0000,Thu; 25 Nov 2010 00:31:02 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2200
MAPREDUCE-2201,Improvement,Major,contrib/fair-share,Quicker preemption causes excessive preemption in FairScheduler,One problem we are seeing is where FairScheduler repeatedly preempts for the same job. This is presumably because our preemption interval is set to a low number (1 minute). FS queues up N tasks to be killed - but in 1 min it is not able to kill  and schedule new tasks on all these slots. As a result; after 1 min - it again preempts a whole bunch of tasks.  We could (and probably will) workaround this by increasing the preemption interval. However - this gives us a hard tradeoff between accurate preemption and timely preemption. Not good. Ideally we want to make the first set of preemptions quickly (to provide responsive behavior to new jobs for example) - but wait (to make sure that the kill actions have actually been processed) thereafter.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Wed; 24 Nov 2010 23:48:30 +0000,Thu; 25 Nov 2010 22:43:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2201
MAPREDUCE-2202,Improvement,Major,,Generalize CLITest structure and interfaces to facilitate upstream adoption (e.g. for web or system testing),Counterpart of HADOOP-7014 and HDFS-1486,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Thu; 25 Nov 2010 00:32:23 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Sun; 17 Apr 2011 02:20:33 +0000,,0.23.0,,HDFS-1486;HADOOP-7014,,https://issues.apache.org/jira/browse/MAPREDUCE-2202
MAPREDUCE-2203,Improvement,Trivial,,Wong javadoc for TaskRunner's appendJobJarClasspaths method," {@link Configuration.getJar()} ) should be "" {@link JobConf.getJar()} )""",Closed,Fixed,,Jingguo Yao,Jingguo Yao,Sun; 28 Nov 2010 03:05:31 +0000,Tue; 15 Nov 2011 00:49:19 +0000,Mon; 28 Feb 2011 05:54:20 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2203
MAPREDUCE-2204,Task,Major,contrib/gridmix,Implement gridmix system tests with different time intervals of  high ram job traces.,Implement gridmix system tests with different time intervals of High Ram map reduce jobs with below scenarios.  1) Generate input data based on cluster size and create the synthetic jobs by using the 2 min MR High RAM jobs trace and submit the jobs with below arguments. GRIDMIX_JOB_TYPE = SleepJob GRIDMIX_USER_RESOLVER = SubmitterUserResolver GRIDMIX_SUBMISSION_POLICY = SERIAL GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false Input Size = 200 MB * No. of nodes in cluster. TRACE_FILE = 5 min folded trace. GRIDMIX_SLEEP_MAP_MAX_TIME=5 sec.                                                                  GRIDMIX_SLEEP_REDUCE_MAX_TIME=5 sec. Verify JobStatus for each job and summary (QueueName; UserName; StatTime; FinishTime; MAPS; REDUCERS and COUNTERS etc) after completion of execution.  2) Generate input data based on cluster size and create the synthetic jobs by using the 3 min MR High RAM jobs trace and submit the jobs with below arguments. GRIDMIX_JOB_TYPE = LoadJob GRIDMIX_USER_RESOLVER = RoundRobinUserResolver GRIDMIX_SUBMISSION_POLICY = STRESS GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false BYTES_PER_FILE = 200 MB Input Size = 400 MB * No. of nodes in cluster. TRACE_FILE = 3 min folded trace. Verify JobStatus for each job and summary (QueueName; UserName; StatTime; FinishTime; MAPS; REDUCERS and COUNTERS etc) after completion of execution.   3) Generate input data based on cluster size and create the synthetic jobs by using the 5 min MR High RAM jobs trace and submit the jobs with below arguments. GRIDMIX_JOB_TYPE = LoadJob GRIDMIX_USER_RESOLVER = EchoUserResolver GRIDMIX_SUBMISSION_POLICY = Replay GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false Input Size = 300 MB * No. of nodes in cluster. TRACE_FILE = 5 min folded trace. Verify JobStatus for each job and summary (QueueName; UserName; StatTime; FinishTime; MAPS; REDUCERS and COUNTERS etc) after completion of execution.,Closed,Duplicate,MAPREDUCE-2517,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 29 Nov 2010 10:35:28 +0000,Tue; 15 Nov 2011 00:48:18 +0000,Wed; 15 Jun 2011 11:09:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2204
MAPREDUCE-2205,Bug,Major,contrib/fair-share,FairScheduler should not re-schedule jobs that have just been preempted,"We have hit a problem with the preemption implementation in the FairScheduler where the following happens:   	job X runs short of fair share or min share and requests pools (in sorted) order until all the slots are exhausted. this leads to lower priority jobs also getting scheduled (that may have just been preempted).",Resolved,Not A Problem,,Scott Chen,Joydeep Sen Sarma,Tue; 30 Nov 2010 02:18:43 +0000,Thu; 16 Dec 2010 19:51:52 +0000,Thu; 16 Dec 2010 19:51:52 +0000,,,,,MAPREDUCE-1204,https://issues.apache.org/jira/browse/MAPREDUCE-2205
MAPREDUCE-2206,Improvement,Major,jobtracker,The task-cleanup tasks should be optional,For job does not use OutputCommitter.abort(); this should be able to turn off. This improves the latency of the job because failed tasks are often the bottleneck of the jobs.,Closed,Fixed,,Scott Chen,Scott Chen,Tue; 30 Nov 2010 06:11:57 +0000,Tue; 15 Nov 2011 00:49:28 +0000,Mon; 28 Feb 2011 22:41:19 +0000,,0.23.0,,HIVE-1833,MAPREDUCE-2207,https://issues.apache.org/jira/browse/MAPREDUCE-2206
MAPREDUCE-2207,Improvement,Major,jobtracker,Task-cleanup task should not be scheduled on the node that the task just failed,Currently the task-cleanup task always go to the same node that the task just failed. There is a higher chance that it hits a bad node. This should be changed.,Closed,Fixed,,Liyin Liang,Scott Chen,Tue; 30 Nov 2010 21:35:19 +0000,Tue; 15 Nov 2011 00:50:01 +0000,Fri; 7 Jan 2011 23:38:04 +0000,,0.23.0,,,MAPREDUCE-2206,https://issues.apache.org/jira/browse/MAPREDUCE-2207
MAPREDUCE-2208,New Feature,Trivial,,Flexible CSV text parser InputFormat,CSVTextInputFormat is a configurable CSV parser tuned to most of the csv-style datasets I've found. The Hadoop samples I've seen all FileInputFormat and MapperLongWritable;Text. They drop the Longwritable key and parse the Text value as a CSV line. But; they are all custom-coded for the format.  CSVTextInputFormat takes any csv-encoded file and rearrange the fields into the format required by a Mapper. You can drop fields  rearrange them. There is also a random sampling option to make training src.  This is compiled against hadoop-0.0.20.,Open,Unresolved,,Unassigned,Lance Norskog,Fri; 3 Dec 2010 03:59:14 +0000,Wed; 20 Mar 2013 18:58:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2208
MAPREDUCE-2209,Bug,Minor,,TaskTracker's heartbeat hang for several minutes when copying large job.jar from HDFS,If a job's jar file is very large; e.g 200m+; the TaskTracker's heartbeat hang for several minutes when localizing the job. The jstack of related threads are as follows:,Open,Unresolved,,Liyin Liang,Liyin Liang,Fri; 3 Dec 2010 09:15:43 +0000,Sat; 7 Jul 2012 13:09:09 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2209
MAPREDUCE-2210,Bug,Major,contrib/fair-share,Preemption does not obey job priority,"Preemption; as it currently works; kills running tasks that are ""unfair"" in terms of the amount of task attention used by one job compared to another.  The bug is that pre-emption occurs such that HIGH priority jobs have their tasks killed when the cluster is filled with lower-priority jobs. Pre-emption should only be allowed to kill tasks for jobs with equal or lower priority.",Resolved,Not A Problem,,Unassigned,Adam Kramer,Mon; 6 Dec 2010 06:31:49 +0000,Mon; 7 Feb 2011 23:23:58 +0000,Mon; 7 Feb 2011 23:23:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2210
MAPREDUCE-2211,Bug,Major,contrib/streaming,java.lang.OutOfMemoryError occurred while running the high ram streaming job.,I had generated the 3GB input data by using the random text writer. Later I submitted the high ram streaming job in the command line. However; I found that an out of memory error in one of the task  org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 149),Open,Unresolved,,Unassigned,Vinay Kumar Thota,Tue; 7 Dec 2010 06:56:55 +0000,Wed; 22 Dec 2010 04:43:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2211
MAPREDUCE-2212,Improvement,Major,task,MapTask and ReduceTask should only compress/decompress the final map output file,Currently if we set mapred.map.output.compression.codec 1. MapTask will compress every spill; decompress every spill; merge and compress the final map output file 2. ReduceTask will decompress; merge and compress every map output file. And repeat the compression decompress the data again and again during merge sort.  We should only compress the final map output file that will be transmitted over the network.,Closed,Won't Fix,,Scott Chen,Scott Chen,Tue; 7 Dec 2010 19:49:42 +0000,Tue; 15 Nov 2011 00:49:07 +0000,Thu; 16 Dec 2010 19:53:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2212
MAPREDUCE-2213,Bug,Major,contrib/gridmix,[Gridmix] Gridmix doesnt work with LocalJobRunner,Gridmix fails when used with LocalJobRunner in the data generation phase.,Open,Unresolved,,Unassigned,Amar Kamat,Wed; 8 Dec 2010 06:30:53 +0000,Wed; 8 Dec 2010 06:33:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2213
MAPREDUCE-2214,Bug,Major,,TaskTracker should release slot if task is not launched,TaskTracker.TaskInProgress.launchTask() does not launch a task if it is not in an expected state. However; in the case where the task is not launched; the slot is not released. We have observed this in production - the task was in SUCCEEDED state by the time launchTask() got to it and then the slot was never released. It is not clear how the task got into that state; but it is better to handle the case.,Open,Unresolved,,Ramkumar Vadali,Ramkumar Vadali,Wed; 8 Dec 2010 20:47:02 +0000,Wed; 7 Sep 2011 08:09:16 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2214
MAPREDUCE-2215,Bug,Major,contrib/raid,A more elegant FileSystem#listCorruptFileBlocks API (RAID changes),Map reduce changes related to HADOOP-7060 and HDFS-1533.,Closed,Fixed,,Patrick Kling,Patrick Kling,Thu; 9 Dec 2010 02:34:26 +0000,Thu; 2 May 2013 02:29:34 +0000,Thu; 9 Dec 2010 23:57:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2215
MAPREDUCE-2216,Bug,Major,jobtracker,speculation should normalize progress rates based on amount of input data,We frequently see skews in data distribution both on the mappers and reducers. The small ones finish quickly and the longer ones immediately get speculated. We should normalize progress rates used by speculation with some metric correlated to the amount of data processed by the task (like bytes read of rows processed). That will prevent these unnecessary speculations.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Thu; 9 Dec 2010 20:07:02 +0000,Sun; 12 Dec 2010 17:10:46 +0000,,,,,,MAPREDUCE-718,https://issues.apache.org/jira/browse/MAPREDUCE-2216
MAPREDUCE-2217,Bug,Major,jobtracker,The expire launching task should cover the UNASSIGNED task,The ExpireLaunchingTask thread kills the task that are scheduled but not responded. Currently if a task is scheduled on tasktracker and for some reason tasktracker cannot put it to RUNNING. The task will just hang in the UNASSIGNED status and JobTracker will keep waiting for it.  JobTracker.ExpireLaunchingTask should be able to kill this task.,Closed,Fixed,,Karthik Kambatla,Scott Chen,Tue; 14 Dec 2010 00:19:54 +0000,Mon; 3 Nov 2014 18:05:57 +0000,Thu; 3 Jan 2013 11:51:27 +0000,,0.23.0;1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2217
MAPREDUCE-2218,Improvement,Major,jobtracker,schedule additional tasks when killactions are being dispatched,we see a very high turnaround time for preemption (from the time preemption happens to the time other jobs are scheduled). part of the reason is that we do not dispatch new tasks until the TT confirms termination of killed tasks. The high turnaround time causes all kinds of issues (we keep issuing preemptions repeatedly. other jobs of higher priority arrive and get scheduled).  One remediation is that one can dispatch additional tasks equal to the number of tasks killed whenever we send killaction to a TT. that would reduce the turnaround time somewhat.,Open,Unresolved,,Unassigned,Joydeep Sen Sarma,Tue; 14 Dec 2010 23:38:07 +0000,Wed; 22 Dec 2010 14:14:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2218
MAPREDUCE-2219,Bug,Major,jobtracker,JT should not try to remove mapred.system.dir during startup,During startup; the JT tries to clean up mapred.system.dir by recursively removing it and then recreating it. This requires that mapred.system.dir is inside a directory owned by the mapred user. For example; if set to  system must be owned by the mapred account. This isn't documented properly and also seems unnecessary. Instead we can remove the contents of mapred.system.dir instead of the directory itself.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 15 Dec 2010 22:11:29 +0000,Mon; 12 Dec 2011 06:19:33 +0000,Fri; 7 Jan 2011 02:17:10 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2219
MAPREDUCE-2220,Bug,Minor,documentation,Fix new API FileOutputFormat-related typos in mapred-default.xml,"there're two typos:  	mapreduce.output.fileoutputformat.compression.type instead of mapreduce.output.fileoutputformat.compress.type 	mapreduce.output.fileoutputformat.compression.codec instead of mapreduce.output.fileoutputformat.compress.codec    in mapred-default. Trivial patch to fix.",Closed,Fixed,,Rui KUBO,Rui KUBO,Thu; 16 Dec 2010 07:06:12 +0000,Thu; 11 Oct 2012 17:48:52 +0000,Sun; 8 Jul 2012 17:25:22 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2220
MAPREDUCE-2221,Bug,Major,,Remove fault injection artifacts from the default build and push to maven for Map-Reduce,The current build always generates fault injection artifacts and pushes them to Maven. Most developers have no need for these artifacts and no users need them.,Open,Unresolved,,Luke Lu,Arun C Murthy,Fri; 17 Dec 2010 18:43:51 +0000,Wed; 7 Sep 2011 08:31:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2221
MAPREDUCE-2222,Bug,Major,,Ivy resolve force mode should be turned off by default,cf. HADOOP-7068,Closed,Fixed,,Luke Lu,Luke Lu,Fri; 17 Dec 2010 22:39:03 +0000,Mon; 12 Dec 2011 06:19:24 +0000,Wed; 11 May 2011 04:20:23 +0000,,,,,HADOOP-7068,https://issues.apache.org/jira/browse/MAPREDUCE-2222
MAPREDUCE-2223,Bug,Minor,test,TestMRCLI might fail on Ubuntu with default /etc/hosts,"Depending on the order of entries in  hosts; TestCLI can fail. This is because it sets fs.default.name to ""localhost""; and then the bound IPC socket on the NN side reports its hostname as ""foobar-host"" if the entry for 127.0.0.1 lists ""foobar-host"" before ""localhost"". This seems to be the default in some versions of Ubuntu.",Resolved,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Sat; 18 Dec 2010 03:10:08 +0000,Thu; 7 Apr 2011 15:40:43 +0000,Thu; 23 Dec 2010 00:10:13 +0000,,0.21.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2223
MAPREDUCE-2224,Bug,Critical,tasktracker,Synchronization bugs in JvmManager,JvmManager.JvmManagerForType has several HashMap members that are inconsistently synchronized. I've seen sporadic NPEs in the 0.20 version of this code which has similar bugs.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Sun; 19 Dec 2010 03:48:19 +0000,Tue; 5 Jun 2012 07:25:57 +0000,Tue; 28 Dec 2010 05:44:48 +0000,,0.22.0,,,MAPREDUCE-2244,https://issues.apache.org/jira/browse/MAPREDUCE-2224
MAPREDUCE-2225,Improvement,Blocker,job submission,MultipleOutputs should not require the use of 'Writable',MultipleOutputs right now requires for Key value classes aren't doing so.  With support for alternates like Avro serialization; using Writables isn't necessary and thus the MO class must not strictly check for them.  And since comparators may be given separately; key class doesn't need to be checked for implementing a comparable (although it is good design if the key class does implement Comparable at least).  Am not sure if this brings about an incompatible change (does Java have BIC? No idea).,Closed,Fixed,,Harsh J,Harsh J,Sun; 19 Dec 2010 17:07:44 +0000,Tue; 15 Nov 2011 00:48:37 +0000,Wed; 2 Mar 2011 05:32:24 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2225
MAPREDUCE-2226,Improvement,Major,,TaggedInputSplit should be public,Currently it's not possible to get at the original InputSplits when using MultipleInputs. This is because TaggedInputSplit (used by DelegatingInputFormat used by MultipleInputs) is not public. This means things like the following do not work:     This prevents users from getting at input split specific data.,Open,Unresolved,,E. Sammer,E. Sammer,Mon; 20 Dec 2010 07:26:09 +0000,Thu; 18 Jul 2013 18:09:29 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2226
MAPREDUCE-2227,Bug,Major,build,update the pom template's dependency list,update the pom template's in the ivy folder to point to latest set of dependencies.,Resolved,Won't Fix,,Giridharan Kesavan,Giridharan Kesavan,Tue; 21 Dec 2010 19:38:38 +0000,Thu; 17 Mar 2016 16:22:15 +0000,Thu; 17 Mar 2016 16:22:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2227
MAPREDUCE-2228,Bug,Major,build,Remove java5 dependencies from build,As the first short-term step let's remove JDK5 dependency from build(s),Resolved,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Wed; 22 Dec 2010 05:18:25 +0000,Sat; 12 Feb 2011 14:30:42 +0000,Tue; 4 Jan 2011 02:58:05 +0000,,0.21.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2228
MAPREDUCE-2229,Bug,Major,examples,Initialize reader in Sort example,"As described in paragraph ""Total Sort"" in HTDG book; page 223; I tried to create a Hadoop job to sort globally some input; using InputSampler with TotalOrderPartitioner.  Please run the mapreduce Sort example with the following arguments to reproduce the exception.    The issue is already described there:  	http: msg03947.html  We need to initialize the reader to avoid the NPE occuring when generating the partition file:     Right now; this initialization only happens in runNewMapper in org.apache.hadoop.mapred.MapTask; but the sampling is performed before the job started. TeraInputFormat class for the TeraSort has its own writePartitionFile method. This is the  oc comment of createRecordReader method in InputFormat class:",Resolved,Duplicate,MAPREDUCE-1820,Unassigned,Alexis,Thu; 23 Dec 2010 03:20:43 +0000,Mon; 7 Mar 2011 23:05:52 +0000,Mon; 7 Mar 2011 23:05:52 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2229
MAPREDUCE-2230,Bug,Major,test,Fault-injection tests are executed multiple times if invoked with run-test-hdfs-fault-inject target,When invoked with run-test-hdfs-fault-inject target fault injection tests are getting executed 4 times.,Resolved,Won't Fix,,Konstantin Boudnik,Konstantin Boudnik,Thu; 23 Dec 2010 05:33:56 +0000,Wed; 7 Oct 2015 19:47:43 +0000,Wed; 7 Oct 2015 19:47:43 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2230
MAPREDUCE-2231,New Feature,Major,jobtracker,Blacklisted TT reset time should be configurable,"A TaskTracker in the blacklist will be reset to healthy state after a day. ""after a day"" should be configurable.",Open,Unresolved,,Unassigned,Bochun Bai,Fri; 24 Dec 2010 07:50:54 +0000,Wed; 7 Sep 2011 08:09:07 +0000,,,,,,MAPREDUCE-1966,https://issues.apache.org/jira/browse/MAPREDUCE-2231
MAPREDUCE-2232,Bug,Major,,Add missing methods to TestMapredGroupMappingServiceRefresh,HADOOP-6864 added new methods to the GroupMappingServiceProvider interface; so MR trunk no longer compiles.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Sat; 25 Dec 2010 21:20:04 +0000,Thu; 7 Apr 2011 15:40:46 +0000,Sun; 26 Dec 2010 02:34:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2232
MAPREDUCE-2233,Bug,Major,task-controller,LinuxTaskController throws NPE when task fails to start,When the LinuxTaskController is incorrectly configured (eg wrong permissions or path) an NPE is thrown when it tries to kill the failed tasks; since there is no known pid.,Resolved,Duplicate,MAPREDUCE-2244,Todd Lipcon,Todd Lipcon,Mon; 27 Dec 2010 03:02:10 +0000,Wed; 5 Jan 2011 20:58:19 +0000,Wed; 5 Jan 2011 20:58:19 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2233
MAPREDUCE-2234,Sub-task,Major,tasktracker,If Localizer can't create task log directory; it should fail on the spot,"Currently; it simply emits a warning. Then; when the taskjvm.sh tries to pipe its output into this directory; it fails with a strange error code like ""exit code: 1"" which is not intuitive to ops. Instead it should simply throw an exception at initialization time rather than attempting to run the task.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 27 Dec 2010 03:36:57 +0000,Mon; 12 Dec 2011 06:20:01 +0000,Thu; 6 Jan 2011 20:00:23 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2234
MAPREDUCE-2235,Bug,Major,jobtracker,"JobTracker ""over-synchronization"" makes it hang up in certain cases ","There is a genaral problem in JobTracker. calls fork())   in our case it's about 1-2 seconds. So job tracker can't handle high frequency job submits.  Except of that; as heartbeat() method is also synchronized JT stops to process heart-beat as ""this"" monitor is being held by submit job. That makes JT thins that a lot of TaskTrackers are down.  Following solution could help:  ""chmod"" is being called from submitJob() method under following line:  JobInProgress job = new JobInProgress(jobId; this; this.conf);  This block could be taken away from synchronized code:  public JobStatus submitJob(JobID jobId) throws IOException {     synchronized (this)  {         .... the rest     }       on state of JobTracker. Also this line      JobInProgress job = new JobInProgress(jobId; this; this.conf);      synchronized (this)  {          .... the rest     }",Resolved,Duplicate,MAPREDUCE-1354,Unassigned,Vladimir Klimontovich,Mon; 27 Dec 2010 15:25:31 +0000,Mon; 3 Jan 2011 20:29:03 +0000,Mon; 3 Jan 2011 20:29:03 +0000,,0.20.1;0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2235
MAPREDUCE-2236,Bug,Critical,,No task may execute due to an Integer overflow possibility,If the attempts is configured to use Integer.MAX_VALUE; an overflow occurs inside TaskInProgress; and thereby no task is attempted by the cluster and the map tasks stay in pending state forever.  For example; here's a job driver that causes this:    The above code will not let any map task run. Additionally; a log would be created inside JobTracker logs with the following information that clearly shows the overflow:    The issue lies inside the TaskInProgress class ( TaskInProgress. ; at line 1018 (trunk); part of the getTaskToRun(String taskTracker) method.    Since all three variables being added are integer in type; one of them being Integer.MAX_VALUE makes the condition fail with an overflow; thereby logging and returning a null as the result is negative.  One solution would be to make one of these variables into a long; so the addition does not overflow?,Resolved,Not A Problem,,Harsh J,Harsh J,Wed; 29 Dec 2010 19:39:43 +0000,Mon; 28 Sep 2015 21:10:34 +0000,Sun; 11 Dec 2011 20:23:24 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2236
MAPREDUCE-2237,Bug,Major,jobtracker,Lost heartbeat response containing MapTask throws NPE when it is resent,When the JT sends a heartbeat response; it records it in trackerToHeartbeatResponseMap. But after MapTask writes its input split; it sets that split to null (assumedly to save memory?). So; if the heartbeat response is lost; and the JT needs to resend it; it will throw NPE since the split information has been lost.,Resolved,Not A Problem,MAPREDUCE-2464,Devaraj K,Todd Lipcon,Wed; 29 Dec 2010 22:14:50 +0000,Mon; 28 Sep 2015 21:10:32 +0000,Wed; 28 Mar 2012 12:18:00 +0000,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2237
MAPREDUCE-2238,Bug,Critical,build;test,Undeletable build directories ,The MR hudson job is failing; looks like it's due to a test chmod'ing a build directory so the checkout can't clean the build dir.  https: attempt_20101230131139886_0001_m_000000_0,Closed,Fixed,,Todd Lipcon,Eli Collins,Mon; 3 Jan 2011 22:57:22 +0000,Mon; 12 Dec 2011 06:19:42 +0000,Tue; 25 Jan 2011 01:11:02 +0000,,0.22.0,,HADOOP-7110,MAPREDUCE-842;MAPREDUCE-1972,https://issues.apache.org/jira/browse/MAPREDUCE-2238
MAPREDUCE-2239,Improvement,Major,contrib/raid,BlockPlacementPolicyRaid should call getBlockLocations only when necessary,Currently BlockPlacementPolicyRaid calls getBlockLocations for every chooseTarget(). This puts pressure on NameNode. We should avoid calling if this file is not raided or a parity file.,Closed,Fixed,,Scott Chen,Scott Chen,Tue; 4 Jan 2011 01:48:58 +0000,Tue; 15 Nov 2011 00:49:36 +0000,Fri; 4 Mar 2011 18:07:31 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2239
MAPREDUCE-2240,Bug,Major,contrib/raid,DistBlockFixer could sleep indefinitely,DistributedBlockFixer computes its sleep interval based on the amount of time spent in fixing jobs. This computation has a bug which can result in the sleep interval becoming negative; which would make the distributed block fixer sleep indefinitely,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Tue; 4 Jan 2011 21:15:45 +0000,Tue; 1 Aug 2017 17:12:51 +0000,Tue; 1 Aug 2017 17:12:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2240
MAPREDUCE-2241,Test,Trivial,task-controller;test,ClusterWithLinuxTaskController should accept relative path on the command line,Currently if you pass a relative path for the -Dtaskcontroller-path option when running these tests; it fails in a fairly unintuitive way. We should absolutize it inside the tests to make it easier for people to run them.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 5 Jan 2011 02:00:37 +0000,Thu; 7 Apr 2011 15:40:50 +0000,Mon; 7 Mar 2011 03:31:03 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2241
MAPREDUCE-2242,Bug,Major,task-controller,LinuxTaskController doesn't properly escape environment variables,"LinuxTaskController currently just writes ""export FOO=bar"" pairs into taskjvm.sh; which fails if the value has multiple words or contains a space. This is causing TestDebugScriptWithLinuxTaskController among others to fail on trunk with the following message:   since it generated a taskjvm.sh including the following:",Open,Unresolved,,Todd Lipcon,Todd Lipcon,Wed; 5 Jan 2011 02:34:31 +0000,Thu; 2 May 2013 02:29:35 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2242
MAPREDUCE-2243,Improvement,Minor,jobtracker;tasktracker,Close all the file streams propely in a finally block to avoid their leakage.,"In the following classes streams should be closed in finally block to avoid their leakage in the exceptional cases.  CompletedJobStatusStore. -----------------------------------  while (reader.next(key; value))  { 	      parts.add(key); 	      key = ReflectionUtils.newInstance(keyClass; conf); 	    } reader.close();",Closed,Fixed,,Devaraj K,Bhallamudi Venkata Siva Kamesh,Wed; 5 Jan 2011 11:29:14 +0000,Tue; 15 Nov 2011 00:48:20 +0000,Mon; 1 Aug 2011 14:12:06 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2243
MAPREDUCE-2244,Bug,Major,task-controller;tasktracker,TestKillSubProcessesWithLinuxTaskController failing on trunk,MAPREDUCE-2224 introduced a change such that the Linux Task Controller no longer will kill descendant processes of a successful child JVM. This is causing TestKillSubProcessesWithLinuxTaskController to fail.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Wed; 5 Jan 2011 20:22:14 +0000,Thu; 2 May 2013 02:29:35 +0000,,,0.22.0,,,MAPREDUCE-2224,https://issues.apache.org/jira/browse/MAPREDUCE-2244
MAPREDUCE-2245,Improvement,Minor,contrib/raid,Failure metrics for block fixer,Publish file fixing failure metrics for the block fixer.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 5 Jan 2011 20:34:28 +0000,Tue; 1 Aug 2017 17:12:55 +0000,Tue; 1 Aug 2017 17:12:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2245
MAPREDUCE-2246,Improvement,Major,contrib/raid,Timeout for fixing a file,"If the DistBlockFixer takes a long time to to fix a file; it would be better to ""timeout"" and try again in a new MR job.",Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 5 Jan 2011 20:37:45 +0000,Tue; 1 Aug 2017 17:12:54 +0000,Tue; 1 Aug 2017 17:12:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2246
MAPREDUCE-2247,Improvement,Minor,,Use readlink to get absolute paths in the scripts,MR side of HADOOP-7089.,Closed,Won't Fix,,Eli Collins,Eli Collins,Thu; 6 Jan 2011 01:57:12 +0000,Fri; 7 Jan 2011 18:39:02 +0000,Fri; 7 Jan 2011 18:38:56 +0000,,,,,HADOOP-7089,https://issues.apache.org/jira/browse/MAPREDUCE-2247
MAPREDUCE-2248,Improvement,Major,,DistributedRaidFileSystem should unraid only the corrupt block,DistributedRaidFileSystem unraids the entire file if it hits a corrupt block. It is better to unraid just the corrupt block and use the rest of the file as normal. This becomes really important when we have tera-byte sized files.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Thu; 6 Jan 2011 08:46:52 +0000,Tue; 15 Nov 2011 00:49:14 +0000,Thu; 13 Jan 2011 00:32:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2248
MAPREDUCE-2249,Improvement,Major,,Better to check the reflexive property of the object while overriding equals method of it,It is better to check the reflexive property of the object while overriding equals method of it.  It improves the performance when a heavy object is compared to itself.,Closed,Fixed,,Devaraj K,Bhallamudi Venkata Siva Kamesh,Thu; 6 Jan 2011 10:04:18 +0000,Tue; 15 Nov 2011 00:48:15 +0000,Fri; 8 Jul 2011 00:01:06 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2249
MAPREDUCE-2250,Improvement,Trivial,contrib/raid,Fix logging in raid code.,There are quite a few error messages being logged with a log level of info. That should be fixed to help debugging.,Closed,Fixed,,Ramkumar Vadali,Ramkumar Vadali,Mon; 10 Jan 2011 18:42:50 +0000,Tue; 15 Nov 2011 00:49:15 +0000,Mon; 24 Jan 2011 23:08:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2250
MAPREDUCE-2251,Bug,Major,,Remove mapreduce.job.userhistorylocation config,Best I can tell; this config parameter is no longer used as of MAPREDUCE-157 but still exists in the code and in mapred-default.xml. We should remove it to avoid user confusion.,Closed,Fixed,,Harsh J,Todd Lipcon,Mon; 10 Jan 2011 19:34:12 +0000,Sun; 8 Jul 2012 16:18:51 +0000,Mon; 7 Mar 2011 03:40:00 +0000,,0.22.0,,,MAPREDUCE-157,https://issues.apache.org/jira/browse/MAPREDUCE-2251
MAPREDUCE-2252,Bug,Critical,jobtracker,XSS injection in JobHistoryParser,"A malicious user can copy a job history file to another location to which both the user and the JT have access to; and then modify the ""taskid"" field of a ""TaskStarted"" event in the JSON to include a script tag. This will be printed unescaped in the 500 error that is produced.",Resolved,Not A Problem,,Unassigned,Todd Lipcon,Mon; 10 Jan 2011 23:37:37 +0000,Wed; 21 Sep 2011 16:52:10 +0000,Wed; 21 Sep 2011 16:52:10 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2252
MAPREDUCE-2253,Bug,Critical,,Servlets should specify content type,HADOOP-7093 will change the default content-type to text octet-stream,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 11 Jan 2011 00:41:04 +0000,Mon; 12 Dec 2011 06:18:47 +0000,Wed; 26 Jan 2011 19:36:58 +0000,,0.22.0,,,HADOOP-7093,https://issues.apache.org/jira/browse/MAPREDUCE-2253
MAPREDUCE-2254,Improvement,Major,,Allow setting of end-of-record delimiter for TextInputFormat,It will be useful to allow setting the end-of-record delimiter for TextInputFormat. The current implementation hardcodes ' n').,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 11 Jan 2011 00:57:43 +0000,Wed; 30 Sep 2015 14:29:15 +0000,Thu; 24 Feb 2011 07:10:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2254
MAPREDUCE-2255,Improvement,Trivial,documentation,correct example code in /api/org/apache/hadoop/util/Tool.html,a trivial mistake in example code. But I wondered where Sort() was come from for a few days.    int res = ToolRunner.run(new Configuration(); new Sort(); args);    int res = ToolRunner.run(new Configuration(); new MyApp(); args);,Resolved,Duplicate,HADOOP-6504,Unassigned,minoru nishikubo,Tue; 11 Jan 2011 09:46:12 +0000,Fri; 14 Jan 2011 06:49:20 +0000,Fri; 14 Jan 2011 06:49:20 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2255
MAPREDUCE-2256,Bug,Major,contrib/fair-share,FairScheduler fairshare preemption from multiple pools may preempt all tasks from one pool causing that pool to go below fairshare.,Scenarios: You have a cluster with 600 map slots and 3 pools.  Fairshare for each pool is 200 to start with.  Fairsharepreemption timeout is 5 mins. 1)  Pool1 schedules 300 map tasks first 2)  Pool2 then schedules another 300 map tasks 3)  Pool3 demands 300 map tasks but doesn't get any slot as all slots are taken. 4)  After 5 mins pool3 should preempt 200 map-slots.  Instead of peempting 100 slots each from pool1 and pool2; the bug would cause it to preempt all 200 slots from pool2 (last started) causing it to go below fairshare.  This is happening because the preemptTask method is not reducing the tasks left from a pool while preempting the tasks.    The above scenario could be an extreme case but some amount of excess preemption would happen because of this bug.  The patch I created was for 0.22.0 but the code fix should work on 0.21  as well as looks like it has the same bug.,Closed,Fixed,,Priyo Mustafi,Priyo Mustafi,Tue; 11 Jan 2011 18:05:15 +0000,Mon; 12 Dec 2011 06:19:13 +0000,Tue; 1 Feb 2011 01:40:34 +0000,,0.21.1;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2256
HADOOP-11794,Improvement,Major,tools/distcp,Enable distcp to copy blocks in parallel,The minimum unit of work for a distcp task is a file. We have files that are greater than 1 TB with a block size of  1 GB. If we use distcp to copy these files; the tasks either take a long long long time or finally fails. A better way for distcp would be to copy all the source blocks in parallel; and then stich the blocks back to files at the destination via the HDFS Concat API (HDFS-222),Resolved,Fixed,,Yongjun Zhang,dhruba borthakur,Tue; 11 Jan 2011 18:30:16 +0000,Wed; 13 Sep 2017 06:22:31 +0000,Sat; 15 Apr 2017 15:18:21 +0000,,0.21.0,,HDFS-1776,HDFS-222;HADOOP-14764;HADOOP-14866,https://issues.apache.org/jira/browse/HADOOP-11794
MAPREDUCE-2258,Bug,Major,task,IFile reader closes stream and compressor in wrong order,In IFile.Reader.close(); we return the decompressor to the pool and then call close() on the input stream. This is backwards and causes a rare race in the case of LzopCodec; since LzopInputStream makes a few calls on the decompressor object inside close(). If another thread pulls the decompressor out of the pool and starts to use it in the meantime; the first thread's close() will cause the second thread to potentially miss pieces of data.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 12 Jan 2011 19:19:35 +0000,Tue; 15 Nov 2011 00:48:19 +0000,Wed; 18 May 2011 18:58:58 +0000,,0.22.0,,,HADOOP-4162;HADOOP-4195,https://issues.apache.org/jira/browse/MAPREDUCE-2258
MAPREDUCE-2259,Improvement,Trivial,documentation,Hadoop Streaming JAR location might be updated,examples in docs hadoop-$HADOOP-VERSION-streaming.jar for someone could not find the streaming archive.,Resolved,Duplicate,MAPREDUCE-1772,Unassigned,minoru nishikubo,Thu; 13 Jan 2011 01:06:15 +0000,Fri; 14 Jan 2011 07:06:50 +0000,Fri; 14 Jan 2011 07:06:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2259
MAPREDUCE-2260,Improvement,Major,build,Remove auto-generated native build files,The repo currently includes the automake and autoconf generated files for the native build. Per discussion on HADOOP-6421 let's remove them and use the host's automake and autoconf. We should also do this for libhdfs and fuse-dfs.,Closed,Fixed,,Roman Shaposhnik,Roman Shaposhnik,Thu; 13 Jan 2011 01:12:32 +0000,Thu; 7 Apr 2011 15:40:55 +0000,Tue; 1 Feb 2011 05:19:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2260
MAPREDUCE-2261,New Feature,Major,,Fair Multiple Task Assignment Scheduler (Assigning multiple tasks per heart beat),Functionality wise the Fair Multiple Task Assignment Scheduler behaves the same way except the assignment of Tasks. Instead of assigning a single Task per heartbeat; it checks for all the jobs if any local or non-local Task that can be launched.  Fair Multiple Task Assignment Scheduler has the advantage of assigning multiple jobs per heart beat interval depending upon the slots available on the Task Tracker; by configuring the number of parallel tasks to be executed in a Task Tracker at any point of time. The advantages are as follows:  a) Parallel Execution allows tasks be to submitted and processed in parallel independent of the status of other tasks. b) More number of tasks is assigned in a heartbeat interval and consequently multitasking capability increases. c) With multi task assignment; Task Tracker efficiency is increased.,Resolved,Invalid,,Unassigned,Devaraj K,Thu; 13 Jan 2011 13:22:09 +0000,Wed; 16 Mar 2011 05:13:02 +0000,Fri; 25 Feb 2011 16:37:04 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2261
MAPREDUCE-2262,Bug,Major,capacity-sched,Capacity Scheduler unit tests fail with class not found,Currently the ivy.xml file for the capacity scheduler doesn't include the commons-cli; leading to class not found exceptions.,Resolved,Fixed,,Owen O'Malley,Owen O'Malley,Thu; 13 Jan 2011 19:12:07 +0000,Thu; 13 Jan 2011 19:35:26 +0000,Thu; 13 Jan 2011 19:35:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2262
MAPREDUCE-2263,Improvement,Major,,MapReduce side of HADOOP-6904,Make changes in Map Reduce to incorporate HADOOP-6904.,Closed,Fixed,,Hairong Kuang,Hairong Kuang,Thu; 13 Jan 2011 23:36:18 +0000,Thu; 2 May 2013 02:29:35 +0000,Fri; 28 Jan 2011 23:16:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2263
MAPREDUCE-2264,Bug,Major,jobtracker,Job status exceeds 100% in some cases ,I'm looking now at my jobtracker's list of running reduce tasks. One of them is 120.05% complete; the other is 107.28% complete.  I understand that these numbers are estimates; but there is no case in which an estimate of 100% for a non-complete task is better than an estimate of 99.99%; nor is there any case in which an estimate greater than 100% is valid.  I suggest that whatever logic is computing these set 99.99% as a hard maximum.,Closed,Fixed,MAPREDUCE-3267;MAPREDUCE-428,Devaraj K,Adam Kramer,Fri; 14 Jan 2011 02:27:02 +0000,Thu; 17 Jul 2014 17:55:50 +0000,Tue; 29 Jan 2013 19:40:23 +0000,,0.20.2;0.20.205.0,critical-0.22.0,,MAPREDUCE-4965;HADOOP-5210;HADOOP-5572,https://issues.apache.org/jira/browse/MAPREDUCE-2264
MAPREDUCE-2265,Improvement,Critical,build;task-controller;tasktracker,task-controller and jsvc should install into sbin/<platform>/ directory,"Currently the task-controller and jsvc ""live"" in the bin  {jsvc;task-controller}  Note this is not an incompatible change since these components were not present in any prior apache release.",Resolved,Won't Fix,,Todd Lipcon,Todd Lipcon,Fri; 14 Jan 2011 08:07:48 +0000,Thu; 20 Oct 2011 22:50:38 +0000,Thu; 20 Oct 2011 22:50:38 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2265
MAPREDUCE-2266,Bug,Major,task-controller;tasktracker,JvmManager sleeps between SIGTERM and SIGKILL while holding many TT locks,Between sending a task SIGTERM and SIGKILL; the JvmManager will sleep for sleepTimeBeforeSigKill millis. But in many call heirarchies this is done while holding important locks like the TT lock and the JvmManagerForType lock. With the default 5 second sleep; this prevents other tasks from getting scheduled and reduces scheduling throughput.,Resolved,Won't Fix,,Unassigned,Todd Lipcon,Sat; 15 Jan 2011 01:26:01 +0000,Tue; 10 Mar 2015 03:12:31 +0000,Tue; 10 Mar 2015 03:12:31 +0000,,0.22.0,,MAPREDUCE-2178,,https://issues.apache.org/jira/browse/MAPREDUCE-2266
MAPREDUCE-2267,Improvement,Major,contrib/raid,Parallelize reading of blocks within a stripe,RAID code has several instances where several blocks of data have to be read to perform an operation. For example; computing a parity block requires reading the blocks of the source file. Similarly; generating a fixed block requires reading a parity block and the good blocks from the source file. These read operations proceed sequentially currently. RAID code should use a thread pool to increase the parallelism and thus reduce latency.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Sat; 15 Jan 2011 01:30:12 +0000,Tue; 1 Aug 2017 17:10:09 +0000,Tue; 1 Aug 2017 17:10:09 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2267
MAPREDUCE-2268,Bug,Major,tasktracker,With JVM reuse; JvmManager doesn't delete last workdir properly,In JvmManager; when a Jvm exits; it tries to delete the workdir for initalContext.task which is null; hence throwing NPE. Currently this NPE is swallowed into the abyss.  We should catch exceptions out of the JvmRunner thread; add a test case that verifies this functionality; and fix this code to properly grab the last task.,Resolved,Won't Fix,,Unassigned,Todd Lipcon,Sat; 15 Jan 2011 01:38:20 +0000,Tue; 10 Mar 2015 03:11:34 +0000,Tue; 10 Mar 2015 03:11:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2268
MAPREDUCE-2269,Bug,Minor,tools/rumen,Rumen TopologyBuilder ignores hostname info in ReduceAttemptFinishedEvent,Rumen's TopologyBuilder component attempts to build up a view of a complete cluster over time by processing many jobs' history files (per discussion with Dick King).  It appears to be designed to take a greedy approach to this; pulling hostnames and rack info out of any JobHistory events that have them.  In particular; it pulls split locations out of TaskStartedEvent and hostnames out of TaskAttemptUnsuccessfulCompletionEvent (used for all task types) and TaskAttemptFinishedEvent (used only for setup and cleanup task attempts).  It omits hostnames in TaskAttemptStartedEvents produced by map attempts (perhaps intentional given the split info from TaskStartedEvents?) and in ReduceAttemptFinishedEvents (apparently unintentional).  The latter resulted in an empty topology and an ArrayIndexOutOfBoundsException in a reduce-only unit test (TestTaskPerformanceSplitTranscription modified for an upcoming feature).  I'm not sure if this is intended behavior or a bug; feel free to close if the former.  It seemed like TaskAttemptFinishedEvent might have been mistakenly believed to cover REDUCE_ATTEMPT_FINISHED.  (If so; the fix to TopologyBuilder. is trivial.),Open,Unresolved,,Unassigned,Greg Roelofs,Sat; 15 Jan 2011 01:49:44 +0000,Sat; 15 Jan 2011 01:49:44 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2269
MAPREDUCE-2270,Test,Major,,CLONE -Implement a Map-Reduce application which can be used to reliably launch speculative tasks,It would be very useful to have a reliable test case to help launch speculative tasks (maps and reduces to ensure that the speculative tasks are launched in a reliable and repeatable manner.  Thoughts?,Open,Unresolved,,Unassigned,aditya sundar,Wed; 19 Jan 2011 05:17:06 +0000,Wed; 19 Jan 2011 05:17:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2270
MAPREDUCE-2271,Bug,Blocker,jobtracker,TestSetupTaskScheduling failing in trunk,This test case is failing in trunk after the commit of MAPREDUCE-2207,Closed,Fixed,,Liyin Liang,Todd Lipcon,Wed; 19 Jan 2011 06:07:19 +0000,Tue; 15 Nov 2011 00:49:59 +0000,Wed; 26 Jan 2011 18:16:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2271
MAPREDUCE-2272,Bug,Trivial,tasktracker,Job ACL file should not be executable,For some reason the job ACL file is localized with permissions 700. This doesn't make sense; since it's not executable. It should be 600.,Resolved,Fixed,,Harsh J,Todd Lipcon,Wed; 19 Jan 2011 06:22:52 +0000,Thu; 7 Apr 2011 15:40:53 +0000,Mon; 7 Mar 2011 03:10:53 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2272
MAPREDUCE-2273,Bug,Blocker,,TaskLogServlet does not set content type,"TaskLogServlet has never set the content type; even though it can serve plain text or HTML; but since HADOOP-7093 the problem has been highlighted since it serves HTML as ""text html"").",Resolved,Duplicate,MAPREDUCE-2253,Unassigned,Tom White,Wed; 19 Jan 2011 19:51:23 +0000,Wed; 19 Jan 2011 20:07:00 +0000,Wed; 19 Jan 2011 20:07:00 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2273
MAPREDUCE-2274,Improvement,Minor,contrib/raid,Generalize block fixer scheduler options,The Raid block fixer currently allows the specification of the fair scheduler pool name. This is not generic since it assumes usage of the fair scheduler. Also this does not allow multiple options to be set; just the pool name. This is similar to MAPREDUCE-1818,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 19 Jan 2011 22:56:20 +0000,Tue; 1 Aug 2017 17:12:54 +0000,Tue; 1 Aug 2017 17:12:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2274
MAPREDUCE-2275,Improvement,Major,contrib/raid,RaidNode should monitor and fix blocks that violate RAID block placement ,When files are RAIDed; it is important to keep blocks in each RAID stripe and the corresponding parity blocks on as many different machines as possible. This ensures minimal probability of data loss when data nodes go dead.  BlockPlacementPolicyRaid ensures that parity blocks are not located on the same machines as the source blocks. But source blocks placement is not controlled directly in this manner. Instead; source blocks are allowed to be created using the default policy. After a source file is RAIDed; its replication is increased; and then decreased. BlockPlacementPolicyRaid then tries to keep the source blocks well-located when excess blocks are deleted. This is not guaranteed to ensure the correct block placement for RAID.  Also; if blocks are moved around by the balancer; the block placement could be violated.  We need periodic monitoring of block placement of RAIDed files and the corresponding parity blocks.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 19 Jan 2011 23:10:14 +0000,Tue; 1 Aug 2017 17:12:59 +0000,Tue; 1 Aug 2017 17:12:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2275
MAPREDUCE-2276,Bug,Major,,Fix build failure introduced by HDFS-1547,MiniDFSCluster#startDataNodes() method signature changes introduced by HDFS-1547 breaks the mapreduce build,Closed,Duplicate,HDFS-1585,Suresh Srinivas,Suresh Srinivas,Thu; 20 Jan 2011 00:06:12 +0000,Tue; 15 Nov 2011 00:50:15 +0000,Thu; 20 Jan 2011 00:10:22 +0000,,0.23.0,,HDFS-1547,,https://issues.apache.org/jira/browse/MAPREDUCE-2276
MAPREDUCE-2277,Bug,Minor,capacity-sched,TestCapacitySchedulerWithJobTracker fails sometimes,Sometimes the testJobTrackerIntegration test fails on my Hudson. It seems the issue is that it doesn't ever wait for the first job to complete before checking its success status. Since the two jobs are in different queues; the first job may complete after the second job.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 20 Jan 2011 21:11:05 +0000,Thu; 7 Apr 2011 15:40:52 +0000,Tue; 25 Jan 2011 22:59:02 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2277
MAPREDUCE-2278,Bug,Major,distributed-cache;tasktracker,DistributedCache shouldn't hold a ref to JobConf,The reference is unnecessary; leads to a memory leak.,Resolved,Fixed,,Chris Douglas,Arun C Murthy,Thu; 20 Jan 2011 22:04:14 +0000,Mon; 31 Oct 2011 04:56:23 +0000,Mon; 31 Oct 2011 04:56:23 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2278
MAPREDUCE-2279,Bug,Major,contrib/raid,Improper byte -> int conversion in DistributedRaidFileSystem,When return a byte value from DistributedRaidFileSystem.read(); we should do 0xff  byteVal. Otherwise the returned int value will be incorrectly negative. This is a regression from MAPREDUCE-2248,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Fri; 21 Jan 2011 02:44:31 +0000,Tue; 1 Aug 2017 17:12:50 +0000,Tue; 1 Aug 2017 17:12:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2279
MAPREDUCE-2280,Improvement,Minor,contrib/eclipse-plugin,The mapreducer wizard of eclipse-plugin should generate sample code using new API,The mapreducer wizard of eclipse-plugin; NewDriverWizard; NewMapperWizard and NewReducerWizard components generate sample code with deprecated API; better to using new mapreducer API to generate sample code.,Resolved,Won't Fix,,Unassigned,Wei Yongjun,Fri; 21 Jan 2011 04:32:58 +0000,Mon; 9 Mar 2015 23:07:59 +0000,Mon; 9 Mar 2015 23:07:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2280
MAPREDUCE-2281,Bug,Major,,Fix javac; javadoc; findbugs warnings,Split from HADOOP-6642,Closed,Fixed,,Po Cheung,Po Cheung,Fri; 21 Jan 2011 19:00:50 +0000,Mon; 12 Dec 2011 06:18:34 +0000,Tue; 1 Feb 2011 10:01:58 +0000,,0.20.2,,,HADOOP-6642,https://issues.apache.org/jira/browse/MAPREDUCE-2281
MAPREDUCE-2282,Bug,Blocker,test,MapReduce tests don't compile following HDFS-1561,TestMRServerPorts depends on TestHDFSServerPorts which was changed by HDFS-1561; resulting in a compilation failure.,Closed,Fixed,,Konstantin Shvachko,Tom White,Fri; 21 Jan 2011 21:47:24 +0000,Mon; 12 Dec 2011 06:19:54 +0000,Sat; 22 Jan 2011 22:09:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2282
MAPREDUCE-2283,Bug,Blocker,contrib/raid,TestBlockFixer hangs initializing MiniMRCluster,TestBlockFixer (a raid contrib test) is hanging the precommit testing on Hudson,Closed,Fixed,,Ramkumar Vadali,Nigel Daley,Wed; 26 Jan 2011 18:04:48 +0000,Mon; 12 Dec 2011 06:19:34 +0000,Fri; 28 Jan 2011 00:24:42 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2283
MAPREDUCE-2284,Bug,Critical,test,TestLocalRunner.testMultiMaps times out,This test has timed out in a number of Hudson builds.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 27 Jan 2011 18:37:37 +0000,Mon; 12 Dec 2011 06:20:00 +0000,Mon; 7 Mar 2011 20:40:52 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2284
MAPREDUCE-2285,Bug,Blocker,test,MiniMRCluster does not start after ant test-patch,Any test using MiniMRCluster hangs in the MiniMRCluster constructor after running ant test-patch. Steps to reproduce:  1. ant -Dpatch.file=dummy patch to CHANGES.txt  -Dforrest.home=path to forrest -Dfindbugs.home=path to findbugs -Dscratch.dir= streaming)  Expected result: Test should succeed Actual result: Test hangs  in MiniMRCluster.init. This does not happen if we run ant clean after ant test-patch  Test output:    Stack trace:,Closed,Fixed,,Todd Lipcon,Ramkumar Vadali,Thu; 27 Jan 2011 20:15:28 +0000,Mon; 12 Dec 2011 06:19:29 +0000,Sun; 6 Feb 2011 19:52:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2285
MAPREDUCE-2286,Sub-task,Trivial,benchmarks;client;contrib/streaming;jobtracker;pipes,ASF mapreduce,This sub-net ensures versions in description; however projects or manufacturing will have to be in working conditioning in the time of unknown versions.,Resolved,Incomplete,,Miguel Ochoa,Miguel Ochoa,Fri; 28 Jan 2011 04:55:51 +0000,Fri; 4 Jan 2013 02:42:10 +0000,Sun; 12 Jun 2011 17:51:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2286
MAPREDUCE-2287,New Feature,Major,security,add Kerberos HTTP SPNEGO authentication support to Hadoop JT/NN/DN/TT web-consoles,This JIRA is for the MAPRED portion of HADOOP-7119,Resolved,Not A Problem,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 28 Jan 2011 06:20:27 +0000,Thu; 4 Aug 2011 17:26:07 +0000,Thu; 4 Aug 2011 17:26:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2287
MAPREDUCE-2288,New Feature,Major,jobtracker,JT Availability,This is an umbrella jira; like HDFS-1064; for discussing and providing references to jobtracker availability jiras (eg from JT restart on a host or to cross host fail-over).,Resolved,Won't Fix,,Unassigned,Eli Collins,Fri; 28 Jan 2011 07:48:40 +0000,Wed; 30 Jul 2014 17:03:16 +0000,Wed; 30 Jul 2014 17:03:16 +0000,,,,,MAPREDUCE-65;MAPREDUCE-225;MAPREDUCE-737;MAPREDUCE-2648;YARN-149;HDFS-1064,https://issues.apache.org/jira/browse/MAPREDUCE-2288
MAPREDUCE-2289,Bug,Major,job submission,Permissions race can make getStagingDir fail on local filesystem,"I've observed the following race condition in TestFairSchedulerSystem which uses a MiniMRCluster on top of RawLocalFileSystem:  	two threads call getStagingDir at the same time 	Thread A checks fs.exists(stagingArea) and sees false 	 		Calls mkdirs(stagingArea; JOB_DIR_PERMISSIONS) 		 			mkdirs calls the Java mkdir API which makes the file with umask-based permissions 		 		 	 	 	Thread B runs; checks fs.exists(stagingArea) and sees true 	 		checks permissions; sees the default permissions; and throws IOE 	 	 	Thread A resumes and sets correct permissions",Closed,Fixed,,Ahmed Radwan,Todd Lipcon,Fri; 28 Jan 2011 21:04:00 +0000,Mon; 6 May 2013 04:07:35 +0000,Mon; 25 Jun 2012 21:40:13 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2289
MAPREDUCE-2290,Bug,Major,test,TestTaskCommit missing getProtocolSignature override,Fixes an MR compilation error; HADOOP-6904 added a new implementation of getProtocolSignature but TestTaskCommit doesn't override it.,Closed,Fixed,,Eli Collins,Eli Collins,Sat; 29 Jan 2011 06:50:22 +0000,Thu; 7 Apr 2011 15:40:37 +0000,Sat; 29 Jan 2011 07:08:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2290
MAPREDUCE-2291,Improvement,Major,jobtracker,TaskTracker Decommission that waits for all map(intermediate) outputs to be pulled ,On our clusters; users were getting affected when ops were decommissioning a large number of TaskTracker nodes.   Correct me if I'm wrong; but current decommission of TaskTrackers only waits for the running tasks to finish but not the jobs where map outputs are kept on that decommissioning tasktrackers.  Any ways we can handle this better?,Open,Unresolved,,Unassigned,Koji Noguchi,Mon; 31 Jan 2011 16:49:03 +0000,Mon; 31 Jan 2011 16:49:03 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2291
MAPREDUCE-2292,Improvement,Minor,contrib/fair-share,Provide a shell interface for querying the status of FairScheduler,It will be useful if we have some shell interface to obtain some status in FairScheduler.  Just like we can use bin hadoop job -list|-list-trackers|-kill-task|... to obtain JobTracker information.,Open,Unresolved,,Unassigned,Scott Chen,Tue; 1 Feb 2011 02:46:11 +0000,Thu; 3 Feb 2011 20:04:02 +0000,,,,,,MAPREDUCE-2298,https://issues.apache.org/jira/browse/MAPREDUCE-2292
MAPREDUCE-2293,Improvement,Minor,,Enhance MultipleOutputs to allow additional characters in the named output name,Currently you are only allowed to use alpha-numeric characters in a named output name in the MultipleOutputs class.  This is a bit of an onerous restriction; as it would be extremely convenient to be able to use non alpha-numerics in the name too.  (E.g.; a '.' character would be very helpful; so that you can use the named output name for holding a file name useful to have this fixed though!,Open,Unresolved,,Unassigned,David Rosenstrauch,Tue; 1 Feb 2011 16:38:01 +0000,Wed; 26 Oct 2016 14:50:39 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2293
MAPREDUCE-2294,Bug,Blocker,,Mumak won't compile in MR trunk,HADOOP-6904 added a required getProtocolSignature() method for protocols; but the mock JT in Mumak doesn't implement this. So; MR trunk is currently failing.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 1 Feb 2011 20:51:58 +0000,Mon; 12 Mar 2012 05:51:52 +0000,Tue; 1 Feb 2011 22:41:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2294
HADOOP-7129,Bug,Major,,Typo in method name getProtocolSigature,HADOOP-6904 introduced a method ProtocolSignature#getProtocolSigature; which obviously has a typo. Let's not maintain an API with a typo in it.  Annoyingly this will require commits to all three subprojects to fix,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 1 Feb 2011 20:54:43 +0000,Wed; 9 Feb 2011 11:18:06 +0000,Wed; 9 Feb 2011 01:39:18 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-7129
MAPREDUCE-2296,Bug,Trivial,,Fix references to misspelled message name getProtocolSigature,HADOOP-7129 fixed the typo; need to update usages in MR.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 1 Feb 2011 22:26:51 +0000,Thu; 7 Apr 2011 15:40:38 +0000,Thu; 3 Feb 2011 21:39:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2296
MAPREDUCE-2297,Bug,Minor,tasktracker,All map reduce tasks are failing if we give invalid path jar file for Job,This can be reproduced by giving the invalid jar file for the Job or it can be reproduced from hive.   In hive-default.xml  property namehive.aux.jars.path property  If we configure an invalid path for jar file; It is making all map reduce tasks to fail even those jobs are not depending on this jar file and it is giving the below exception.,Resolved,Not A Problem,,Devaraj K,Devaraj K,Thu; 3 Feb 2011 15:57:50 +0000,Wed; 28 Mar 2012 12:15:18 +0000,Wed; 28 Mar 2012 12:15:17 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2297
MAPREDUCE-2298,Improvement,Major,contrib/fair-share,FairScheduler status page allows users to set pool and priority,The FairScheduler status page should allow users to view status without enabling admin functions like set pool and set priority.  One proposal is to disable all admin commands from the FairScheduler status page to make it read only. We would have to provide an alternate administration interface; for example via shell (MAPREDUCE-2292).,Resolved,Duplicate,HADOOP-5485,Unassigned,Patrick Angeles,Thu; 3 Feb 2011 15:58:57 +0000,Thu; 3 Feb 2011 19:44:18 +0000,Thu; 3 Feb 2011 19:44:18 +0000,,,,,HADOOP-5485;MAPREDUCE-2292,https://issues.apache.org/jira/browse/MAPREDUCE-2298
MAPREDUCE-2299,Bug,Major,jobtracker,In the Job Tracker UI -> task details page; machine and logs links are navigating to page not found error.,1. In the page showing All task attempts-On clicking of machine link is navigating to page not found error. 2. In the page showing All task attempts-On clicking of Task logs Link is navigating to page not found error.,Open,Unresolved,,Unassigned,Devaraj K,Thu; 3 Feb 2011 16:05:22 +0000,Thu; 24 Feb 2011 15:53:53 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2299
MAPREDUCE-2300,Bug,Blocker,,TestUmbilicalProtocolWithJobToken failing,Testcase: testJobTokenRpc took 0.678 sec         Caused an ERROR null  102),Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 3 Feb 2011 18:38:50 +0000,Thu; 7 Apr 2011 15:40:47 +0000,Thu; 3 Feb 2011 21:12:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2300
MAPREDUCE-2301,Bug,Minor,,TestDataDrivenDBInputFormat fails if port 9001 is occupied,If you have any process listening on port 9001 (the default hsqldb port) then TestDataDrivenDBInputFormat will fail with:  Connection is broken:  net.BindException: Address already in use,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Thu; 3 Feb 2011 22:03:31 +0000,Mon; 30 Jan 2012 13:42:39 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2301
MAPREDUCE-2302,Improvement,Major,contrib/raid,Add static factory methods in GaloisField,GaloisField is immutable and should be kept reuse after creation to avoid redundant calculation of the multiplication and division tables.,Closed,Fixed,,Scott Chen,Scott Chen,Thu; 3 Feb 2011 22:09:08 +0000,Tue; 15 Nov 2011 00:49:28 +0000,Wed; 2 Mar 2011 21:49:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2302
MAPREDUCE-2303,Improvement,Major,contrib/raid,RAID BlockFixer should choose targets better,The RAID BlockFixer chooses the destination of the generated block at random. It avoids nodes that have a corrupt replica of the block; but does not do anything beyond that. It needs to avoid data nodes that have a replica of any source or parity block in the block's stripe.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Fri; 4 Feb 2011 18:59:41 +0000,Tue; 1 Aug 2017 17:12:55 +0000,Tue; 1 Aug 2017 17:12:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2303
MAPREDUCE-2304,Bug,Minor,test,TestMRCLI fails when hostname has a hyphen (-),TestMRCLI fails with below  Comparator: RegexpComparator Comparision result:   fail Expected output: [mv: Wrong FS: har: lab-something.host.com:34039,Resolved,Fixed,,Priyo Mustafi,Priyo Mustafi,Fri; 4 Feb 2011 19:04:51 +0000,Sat; 6 Aug 2011 01:23:48 +0000,Fri; 4 Feb 2011 23:36:33 +0000,,0.22.0,,,HDFS-2232,https://issues.apache.org/jira/browse/MAPREDUCE-2304
MAPREDUCE-2305,Bug,Minor,jobtracker;tasktracker,The status in the UI can be updated periodically without refreshing the page.,If we want to know the latest information in Job Tracker and Task Trackers; we need to refresh the corresponding pages every time. Instead it can be reloaded (refreshed) periodically.,Open,Unresolved,,Unassigned,Devaraj K,Mon; 7 Feb 2011 13:47:21 +0000,Mon; 7 Feb 2011 13:47:21 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2305
MAPREDUCE-2306,Bug,Minor,jobtracker,It is better to give Job start time instead of JobTracker start time in the JobTracker UI->Home.,In the log details; for each job it is giving JobTracker start time and also In the JobTracker UI-Home it is giving Start time of JobTracker. It is better to give JobId start time instead of JobTracker start time in Job Tracker UI home.,Resolved,Duplicate,MAPREDUCE-1541,Devaraj K,Devaraj K,Mon; 7 Feb 2011 13:50:21 +0000,Sat; 9 Apr 2011 06:28:48 +0000,Thu; 10 Feb 2011 04:57:01 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2306
MAPREDUCE-2307,Bug,Minor,contrib/fair-share,Exception thrown in Jobtracker logs; when the Scheduler configured is FairScheduler.,If we try to start the job tracker with fair scheduler using the default configuration; It is giving the below exception.,Closed,Fixed,,Devaraj K,Devaraj K,Tue; 8 Feb 2011 14:57:28 +0000,Tue; 15 Nov 2011 00:49:12 +0000,Tue; 5 Apr 2011 21:51:17 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2307
MAPREDUCE-2308,Bug,Minor,,Sort buffer size (io.sort.mb) is limited to < 2 GB,I have MapReduce jobs that use a large amount of per-task memory; because the algorithm I'm using converges faster if more data is together on a node.  I have my JVM heap size set at 3200 MB; and if I use the popular rule of thumb that io.sort.mb should be ~70% of that; I get 2240 MB.  I rounded this down to 2048 MB; but map tasks crash with :    MapTask.MapOutputBuffer implements its buffer with a byte[] of size io.sort.mb (in bytes); and is sanity checking the size before allocating the array.  The problem is that Java arrays can't have more than 2^31 - 1 elements (even with a 64-bit JVM); and this is a limitation of the Java language specificiation itself.  As memory and data sizes grow; this would seem to be a crippling limtiation of Java.  It would be nice if this ceiling were documented; and an error issued sooner; e.g. in jobtracker startup upon reading the config.  Going forward; we may need to implement some array of arrays hack for large buffers.,Open,Unresolved,MAPREDUCE-5705,Unassigned,Jay Hacker,Tue; 8 Feb 2011 14:58:51 +0000,Sun; 5 Jan 2014 03:12:42 +0000,,,0.20.1;0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2308
MAPREDUCE-2309,Bug,Minor,jobtracker,While querying the Job Statics from the command-line; if we give wrong status name then there is no warning or response.,If we try to get the jobs information by giving the wrong status name from the command line interface; it is not giving any warning or response.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Tue; 8 Feb 2011 14:59:24 +0000,Thu; 17 Jan 2013 13:06:25 +0000,Thu; 17 Jan 2013 13:06:25 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2309
MAPREDUCE-2310,Bug,Minor,tasktracker,If we stop Job Tracker; Task Tracker is also getting stopped.,If we execute stop-jobtracker.sh for stopping Job Tracker; Task Tracker is also stopping.  This is not applicable for the latest (trunk) code because stop-jobtracker.sh file is not coming.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Tue; 8 Feb 2011 15:03:37 +0000,Sun; 29 Jan 2012 02:10:25 +0000,Sun; 29 Jan 2012 02:10:21 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2310
MAPREDUCE-2311,Bug,Blocker,contrib/fair-share,TestFairScheduler failing on trunk,Most of the test cases in this test are failing on trunk; unclear how long since the contrib tests weren't running while the core tests were failed.,Closed,Fixed,,Scott Chen,Todd Lipcon,Wed; 9 Feb 2011 01:30:12 +0000,Tue; 15 Nov 2011 00:48:22 +0000,Wed; 9 Feb 2011 22:23:32 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2311
MAPREDUCE-2312,Bug,Minor,,Better error handling in RaidShell,If there is an error trying to find the parity information for a corrupt file; RaidShell should print it as corrupt; instead of bailing.,Open,Unresolved,,Ramkumar Vadali,Ramkumar Vadali,Wed; 9 Feb 2011 01:52:31 +0000,Wed; 9 Feb 2011 01:52:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2312
MAPREDUCE-2313,Bug,Major,,RAID code does not close some opened streams,There are some instances where opened streams are not closed; leading to a file descriptor leak.,Open,Unresolved,,Ramkumar Vadali,Ramkumar Vadali,Wed; 9 Feb 2011 21:53:52 +0000,Wed; 9 Feb 2011 21:53:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2313
MAPREDUCE-2314,Improvement,Major,build,configure files that are generated as part of the released tarball need to have executable bit set,Currently the configure files that are packaged in a tarball are rw-rw-r-,Closed,Fixed,,Roman Shaposhnik,Roman Shaposhnik,Wed; 9 Feb 2011 23:05:21 +0000,Mon; 12 Dec 2011 06:19:27 +0000,Tue; 15 Feb 2011 21:10:45 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2314
MAPREDUCE-2315,Bug,Blocker,,javadoc is failing in nightly,Last nightly build failed to publish  oc: error - Cannot find doclet class org.apache.hadoop.classification.tools.ExcludePrivateAnnotationsStandardDoclet,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 10 Feb 2011 06:00:21 +0000,Mon; 12 Dec 2011 06:19:59 +0000,Thu; 10 Feb 2011 07:46:04 +0000,,0.22.0,,,MAPREDUCE-1947;MAPREDUCE-2197,https://issues.apache.org/jira/browse/MAPREDUCE-2315
MAPREDUCE-2316,Improvement,Major,capacity-sched;documentation,Update docs for CapacityScheduler,Need to update CS docs,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 10 Feb 2011 11:39:47 +0000,Thu; 25 Aug 2011 20:20:21 +0000,Wed; 27 Apr 2011 18:43:11 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2316
MAPREDUCE-2317,Bug,Minor,harchive,HadoopArchives throwing NullPointerException while creating hadoop archives (.har files),While we are trying to run hadoop archive tool in widows using this way; it is giving the below exception.   org.apache.hadoop.tools.HadoopArchives -archiveName temp.har D: temp      I see the code flow to handle this feature in windows also;,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 10 Feb 2011 12:10:55 +0000,Tue; 15 Nov 2011 00:49:24 +0000,Fri; 22 Apr 2011 20:43:47 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2317
MAPREDUCE-2318,Bug,Major,,Simulator tests time out sometimes on trunk,In the following trunk build: https:  several simulator tests timed out:  org.apache.hadoop.mapred.TestSimulatorDeterministicReplay.testMain org.apache.hadoop.mapred.TestSimulatorEndToEnd.testMain org.apache.hadoop.mapred.TestSimulatorSerialJobSubmission.testMain org.apache.hadoop.mapred.TestSimulatorStressJobSubmission.testMain,Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 10 Feb 2011 18:47:21 +0000,Thu; 10 Feb 2011 18:47:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2318
MAPREDUCE-2319,Improvement,Major,,MultithreadedMapper doesn't update completion percentage before mapper is finished,MultithreadedMapper runs multiple threads in one mapper; but it doesn't update the completion percentage before all the threads are completed.  If is better to update the completion percentage when threads are running to reflect real progress.  The code is like this: runners = new ArrayList(numberOfThreads);         for(int i = 0; i  numberOfThreads; i++)         {             MapRunner thread = new MapRunner(context);             thread.start();             runners.add(i; thread);         }          for(int i = 0; i  numberOfThreads; i++)         {             MapRunner thread = (MapRunner)runners.get(i);             thread.join();   wait             ...                },Open,Unresolved,,Unassigned,Forest Tan,Fri; 11 Feb 2011 08:16:22 +0000,Fri; 11 Feb 2011 08:16:22 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2319
MAPREDUCE-2320,Improvement,Minor,contrib/raid,RAID DistBlockFixer should limit pending jobs instead of pending files,DistBlockFixer limits the number of files being fixed simultaneously to avoid an unlimited backlog. This limits the number of parallel jobs though; and if one job has a long running task; it prevents newer jobs being started. Instead; it should have a limit on running jobs. That way; one long running task will not block other jobs.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Fri; 11 Feb 2011 17:57:07 +0000,Tue; 1 Aug 2017 17:10:26 +0000,Tue; 1 Aug 2017 17:10:25 +0000,,0.20.2;0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2320
MAPREDUCE-2321,Bug,Major,,TT should fail to start on secure cluster when SecureIO isn't available,When security is enabled; the TT requires SecureIO JNI extensions to be available. Currently the user doesn't notice this until jobs start failing with mysterious fetch failures and exceptions spew all over the log. Instead the TT should check that the JNI library is available and fail to start if it's not.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Fri; 11 Feb 2011 20:33:52 +0000,Fri; 11 Feb 2011 20:33:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2321
MAPREDUCE-2322,Bug,Minor,,Throw better error message when malformed filenames in history dir,I've occasionally seen an IndexOutOfBoundsException visiting jobhistory.jsp because some file makes it into the history log directory. We should filter these out and throw a more useful exception if a malformed one somehow makes it to the comparator,Open,Unresolved,,Albert Sunwoo,Todd Lipcon,Fri; 11 Feb 2011 23:16:34 +0000,Thu; 2 Jun 2011 01:09:30 +0000,,,0.22.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2322
MAPREDUCE-2323,New Feature,Major,contrib/fair-share,Add metrics to the fair scheduler,It would be useful to be able to monitor various metrics in the fair scheduler; like demand; fair share; min share; and running task count.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Sun; 13 Feb 2011 03:20:44 +0000,Tue; 15 Nov 2011 00:48:53 +0000,Wed; 6 Jul 2011 05:12:00 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2323
MAPREDUCE-2324,Bug,Major,,Job should fail if a reduce task can't be scheduled anywhere,"If there's a reduce task that needs more disk space than is available on any mapred.local.dir in the cluster; that task will stay pending forever. For example; we produced this in a QA cluster by accidentally running terasort with one reducer - since no mapred.local.dir had 1T free; the job remained in pending state for several days. The reason for the ""stuck"" task wasn't clear from a user perspective until we looked at the JT logs.  Probably better to just fail the job if a reduce task goes through all TTs and finds that there isn't enough space.",Closed,Fixed,,Robert Joseph Evans,Todd Lipcon,Mon; 14 Feb 2011 18:09:39 +0000,Wed; 23 Nov 2011 18:11:40 +0000,Mon; 1 Aug 2011 22:49:39 +0000,,0.20.2;0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2324
MAPREDUCE-2325,Bug,Minor,client,Mark o.a.h.mapreduce.TaskReport as public?,o.a.h.mapreduce.TaskReport is returned by Job.getTaskReports(TaskType); which is marked as Public Evolving. TaskReport; however; is marked as Private. This looks like an oversight: The last time it was mentioned in HADOOP-1623; Tom White suggested that it should be Public; but all of the patches continued to use Private.  If this isn't supposed to be public; where is the best place to get the list of running tasks (not just completed ones)?,Open,Unresolved,,Unassigned,Tim Yates,Mon; 14 Feb 2011 23:44:49 +0000,Thu; 24 Feb 2011 05:40:52 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2325
MAPREDUCE-2326,Improvement,Major,,Port gridmix changes from hadoop-0.20.100 to trunk,We have some changes to gridmix in hadoop-0.20.100. Uber jira to track merges to trunk.,Closed,Fixed,,Unassigned,Arun C Murthy,Tue; 15 Feb 2011 01:09:53 +0000,Tue; 15 Nov 2011 00:48:33 +0000,Wed; 15 Jun 2011 16:40:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2326
MAPREDUCE-2327,Bug,Blocker,,MapTask doesn't need to put username information in SpillRecord,"This is an amendment to MAPREDUCE-2096 that's found in Yahoo's 0.20.100 branch.  This bug causes task failures in the following case:  	Cluster is not set up with LinuxTaskController (ie not secured cluster) 	Job submitter is not the same as the user running the TT 	Map output is more than one spill's worth    The issue is that UserGroupInformation's view of the current user is the job submitter; but on disk the spill files will be owned by the TT user. SecureIO will then fail when constructing the spill record.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 15 Feb 2011 01:40:48 +0000,Mon; 12 Dec 2011 06:18:54 +0000,Tue; 17 May 2011 03:39:50 +0000,,0.22.0,,MAPREDUCE-2445,,https://issues.apache.org/jira/browse/MAPREDUCE-2327
MAPREDUCE-2328,Bug,Major,,memory-related configurations missing from mapred-default.xml,HADOOP-5881 added new configuration parameters for memory-based scheduling; but they weren't added to mapred-default.xml,Open,Unresolved,,Unassigned,Todd Lipcon,Tue; 15 Feb 2011 01:50:58 +0000,Wed; 8 Mar 2017 12:16:07 +0000,,,0.22.0,newbie,MAPREDUCE-3223,,https://issues.apache.org/jira/browse/MAPREDUCE-2328
MAPREDUCE-2329,Bug,Minor,contrib/raid,RAID BlockFixer should exclude temporary files,RAID BlockFixer should exclude files matching the pattern ^ .*,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Tue; 15 Feb 2011 18:23:02 +0000,Tue; 1 Aug 2017 17:12:49 +0000,Tue; 1 Aug 2017 17:12:49 +0000,,0.20.2;0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2329
MAPREDUCE-2330,New Feature,Major,,Forward port MapReduce server MXBeans,Some JMX classes e.g.; JobTrackerMXBean and TaskTrackerMXBean in 0.20.100~ needs to be forward ported to 0.23 in some fashion; depending on how MapReduce 2.0 emerges.  Note; similar item for HDFS; HDFS-1318 is already in 0.22.,Resolved,Won't Fix,,Unassigned,Luke Lu,Tue; 15 Feb 2011 21:37:27 +0000,Tue; 10 Mar 2015 01:27:55 +0000,Tue; 10 Mar 2015 01:27:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2330
MAPREDUCE-2331,Test,Major,,Add coverage of task graph servlet to fair scheduler system test,Would be useful to hit the TaskGraph servlet in the fair scheduler system test. This way; when run under JCarder; it will check for any lock inversions in this code.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 16 Feb 2011 03:04:05 +0000,Tue; 15 Nov 2011 00:48:24 +0000,Mon; 7 Mar 2011 07:57:58 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2331
MAPREDUCE-2332,Improvement,Major,,Improve error messages when MR dirs on local FS have bad ownership,A common source of user difficulty on a secure cluster is understanding which paths should be owned by which users. The task log directory in particular is often missed; since it has to be owned by mapred but may be inside a logs dir which has different ownership. Right now the user has to spelunk in the code to understand the exception they get if this dir has bad ownership.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Wed; 16 Feb 2011 07:31:15 +0000,Mon; 31 Oct 2011 18:27:56 +0000,,,0.22.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2332
MAPREDUCE-2333,Bug,Minor,contrib/raid,RAID jobs should delete temporary files in the event of filesystem failures,If the creation of a parity file or parity file HAR fails due to a filesystem level error; RAID should delete the temporary files. Specifically; datanode death during parity file creation would cause FSDataOutputStream.close() to throw an IOException. The RAID code should delete such a file.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 16 Feb 2011 23:31:12 +0000,Tue; 1 Aug 2017 17:12:50 +0000,Tue; 1 Aug 2017 17:12:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2333
MAPREDUCE-2334,Improvement,Trivial,contrib/raid,Update BlockPlacementPolicyRaid,Update BlockPlacementPolicyRaid for the recent changes of BlockPlacementPolicy.,Resolved,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Thu; 17 Feb 2011 08:12:02 +0000,Thu; 7 Apr 2011 15:40:48 +0000,Fri; 18 Feb 2011 16:04:55 +0000,,,,,HDFS-1629,https://issues.apache.org/jira/browse/MAPREDUCE-2334
MAPREDUCE-2335,Bug,Major,,mapreduce.CounterGroup constructor should not be public,MAPREDUCE-980 (made into 0.21+) changed the constructor from package protected to public. As we all know: nothing good happens after making a constructor public; especially for public facing APIs. There is no other use of the constructor outside the EventReader yet. To avoid another API change debacle in case of external user usage and later we decide to refactor counters for more efficient internal implementations (e.g. a la MAPREDUCE-901); we should make the Counter CounterGroup constructors package private; and provide a method to addGroup to Counters. Or at least make the constructor @InterfaceAudience.Private.,Open,Unresolved,,Unassigned,Luke Lu,Thu; 17 Feb 2011 23:35:13 +0000,Thu; 17 Feb 2011 23:44:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2335
MAPREDUCE-2336,Bug,Major,documentation,Tool-related packages should be in the Tool javadoc group,Some of the tool packages are mistakenly in the general group.,Closed,Fixed,,Tom White,Tom White,Fri; 18 Feb 2011 00:41:41 +0000,Mon; 12 Dec 2011 06:19:09 +0000,Mon; 7 Mar 2011 21:48:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2336
MAPREDUCE-2337,Improvement,Major,,Remove dependence of public MapReduce API on classes in server package,Cluster#getJobTrackerState() returns a org.apache.hadoop.mapreduce.server.jobtracker.State enum; which makes the API in o.a.h.mapreduce have a dependency on the server package. It would be better to make the public API self-contained by using an equivalent enum in the Cluster class.,Closed,Fixed,,Tom White,Tom White,Fri; 18 Feb 2011 01:48:50 +0000,Thu; 2 May 2013 02:29:38 +0000,Fri; 8 Apr 2011 04:11:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2337
MAPREDUCE-2338,Improvement,Major,,Deprecate field selection methods on JobConf,KeyFieldBasedComparator and KeyFieldBasedPartitioner are libraries so should not appear as getters and setters in JobConf. For the new API there are getters and setters on KeyFieldBasedComparator and KeyFieldBasedPartitioner themselves - we should add the equivalent to the old API and deprecate the references in JobConf.,Open,Unresolved,,James Warren,Tom White,Fri; 18 Feb 2011 18:15:26 +0000,Sat; 30 Jun 2012 17:16:48 +0000,,,,newbie,MAPREDUCE-4253,,https://issues.apache.org/jira/browse/MAPREDUCE-2338
MAPREDUCE-2339,Improvement,Major,jobtracker,optimize JobInProgress.getTaskInProgress(taskid),JobInProgress.getTaskInProgress(taskid) use a linner search to get the TaskInProgress object by taskid. In fact; it can be replaced by much more efficient array index operation.,Open,Unresolved,,Unassigned,Kang Xiao,Sat; 19 Feb 2011 12:12:54 +0000,Fri; 16 Dec 2011 10:56:46 +0000,,,0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2339
MAPREDUCE-2340,Improvement,Major,jobtracker,optimize JobInProgress.initTasks(),JobTracker's hostnameToNodeMap cache can speed up JobInProgress.initTasks() and JobInProgress.createCache() significantly. A test for 1 job with 100000 maps on a 2400 cluster shows nearly 10 and 50 times speed up for initTasks() and createCache().,Patch Available,Unresolved,,Unassigned,Kang Xiao,Mon; 21 Feb 2011 04:56:58 +0000,Fri; 8 May 2015 19:16:52 +0000,,,0.20.1;0.21.0,BB2015-05-TBR;critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-2340
MAPREDUCE-2341,Bug,Major,tasktracker,Map and Reduce task JVMs are hanging infinitely ,Description:  When launching Mapreduce application; the property mapred.job.reuse.jvm.num.tasks has been set to 0; as a result the task JVM(MAP or Reduce JVM) is hanging indefinitely and finally being killed by Tasktracker.  Steps to Reproduce ------------------ 1) Set the mapred.job.reuse.jvm.num.tasks property in mapred-site.xml to 0 2) Execute the wordcount example; child JVM is hanging indefinitely and finally killed by Tasktracker,Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Mon; 21 Feb 2011 09:36:16 +0000,Mon; 21 Feb 2011 09:40:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2341
MAPREDUCE-2342,Bug,Major,contrib/mrunit,mrunit shall pass Configuration in constructors,"MrUnit shall pass Configuration in constructors rather then create a new one.  For example MockOutputCollector does not get user provided ""io.serializations"". So one can't test with custom serializers (like AvroWrapper).",Resolved,Invalid,,Unassigned,Jan Prach,Wed; 23 Feb 2011 13:34:11 +0000,Sun; 17 Jul 2011 22:02:11 +0000,Sun; 17 Jul 2011 22:02:10 +0000,,0.20.2;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2342
MAPREDUCE-2343,Bug,Major,tools/rumen, repeated replace() function calls damage the performance,In the file           consecutive replace() is called to remove the special characters.  It's 5+ times slower than using a for loop replace them all.   This bug has the same problem as the MySQL bug : http: bug.php?id=45699,Open,Unresolved,MAPREDUCE-2380,Unassigned,Xiaoming Shi,Wed; 23 Feb 2011 20:14:43 +0000,Fri; 13 May 2016 23:11:48 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2343
MAPREDUCE-2344,Bug,Minor,,Exclude second Ant JAR from classpath in MR builds,Counterpart of HDFS-798,Resolved,Won't Fix,,Konstantin Boudnik,Konstantin Boudnik,Thu; 24 Feb 2011 04:01:08 +0000,Mon; 2 Apr 2012 06:16:58 +0000,Mon; 2 Apr 2012 06:16:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2344
MAPREDUCE-2345,Improvement,Major,jobtracker,Optimize jobtracker's  memory usage  ,Too many tasks will eat up a considerable amount of JobTracker's heap space. According to our observation; 50GB heap size can support to 5;000;000 tasks; so we should optimize jobtracker's memory usage for more jobs and tasks. Yourkit  profile show that counters; duplicate strings; task waste too much memory. Our optimization around these three points reduced jobtracker's memory to 1 3.,Resolved,Won't Fix,,Unassigned,MengWang,Fri; 25 Feb 2011 03:25:56 +0000,Mon; 9 Mar 2015 22:48:40 +0000,Mon; 9 Mar 2015 22:48:40 +0000,,0.21.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2345
MAPREDUCE-2346,Bug,Minor,client,JobClient's isSuccessful and isComplete API's can throw NPE in some cases,"Description:   	Submit a job to the job tracker and let the job complete its execution through one of the job client's submitJob APIs. 	Jobclient returns a handle to the job; in the form of a RunningJob object. Client can use this object to check whether job is sucessful or whether job is completed. 	Reduce the following property mapred.jobtracker.retirejob.interval.By default this value is 1 day. I reduced it to 5 min. 	Set the property mapred.job.tracker.persist.jobstatus.active to false. 	Call either isComplete or isSuccessful APIs; after mapred.jobtracker.retirejob.interval time period; previously mentioned APIs throw NPE.    Below I am attaching stack trace",Resolved,Won't Fix,,Devaraj K,Bhallamudi Venkata Siva Kamesh,Fri; 25 Feb 2011 09:23:13 +0000,Tue; 29 May 2012 18:50:02 +0000,Sun; 29 Jan 2012 02:08:24 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2346
MAPREDUCE-2347,Bug,Major,contrib/raid,RAID blockfixer should check file blocks after the file is fixed,After a file is fixed by the block fixer; all its blocks should be checked for the presence of replicas. If any block still is missing valid replicas; it should be fixed again,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Mon; 28 Feb 2011 21:13:42 +0000,Tue; 1 Aug 2017 17:12:51 +0000,Tue; 1 Aug 2017 17:12:51 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2347
MAPREDUCE-2348,Bug,Blocker,contrib/mumak,TestSimulator* failed on trunk,All Failed Tests,Resolved,Later,,Todd Lipcon,Scott Chen,Mon; 28 Feb 2011 21:40:05 +0000,Thu; 7 Apr 2011 15:40:54 +0000,Thu; 17 Mar 2011 05:31:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2348
MAPREDUCE-2349,Improvement,Major,task,speed up list[located]status calls from input formats,when a job has many input paths - listStatus - or the improved listLocatedStatus - calls (invoked from the getSplits() method) can take a long time. Most of the time is spent waiting for the previous call to complete and then dispatching the next call.   This can be greatly speeded up by dispatching multiple calls at once (via executors). If the same filesystem client is used - then the calls are much better pipelined (since calls are serialized) and don't impose extra burden on the namenode while at the same time greatly reducing the latency to the client. In a simple test on non-peak hours; this resulted in the getSplits() time reducing from about 3s to about 0.5s.,Closed,Fixed,,Siddharth Seth,Joydeep Sen Sarma,Tue; 1 Mar 2011 22:47:41 +0000,Thu; 10 Apr 2014 13:11:47 +0000,Thu; 20 Mar 2014 02:50:05 +0000,,,,,MAPREDUCE-5603,https://issues.apache.org/jira/browse/MAPREDUCE-2349
MAPREDUCE-2350,Bug,Major,,"LocalJobRunner uses ""mapred.output.committer.class"" configuration property to retrieve the OutputCommitter (regardless of whether the old API is used or the new API)","LocalJobRunner uses the ""mapred.output.committer.class"" configuration property to retrieve the output committer for the job; which can be different from the Output Committer returned from OutputFormat.getOutputCommitter(TaskAttemptContext context). So; two different output committers can be used in the same job.  See line 324 in org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter outputCommitter = job.getOutputCommitter();  Need to modify this behavior to check if the new or the old API is used; and then return the correct output committer.",Resolved,Duplicate,MAPREDUCE-3563,Devaraj K,Ahmed Radwan,Tue; 1 Mar 2011 22:53:45 +0000,Tue; 23 Jun 2015 16:33:01 +0000,Thu; 12 Feb 2015 10:15:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2350
MAPREDUCE-2351,Improvement,Major,,mapred.job.tracker.history.completed.location should support an arbitrary filesystem URI,Currently; mapred.job.tracker.history.completed.location is resolved relative to the default filesystem. If not set it defaults to history  URI) or an arbitrary Hadoop filesystem.,Closed,Fixed,,Tom White,Tom White,Wed; 2 Mar 2011 00:52:18 +0000,Fri; 21 Jun 2013 06:03:31 +0000,Thu; 3 Mar 2011 21:36:22 +0000,,0.23.0;1-win;1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2351
MAPREDUCE-2352,Improvement,Minor,contrib/raid,RAID blockfixer can use a heuristic to find unfixable files ,It is possible to have corrupt files that were never RAIDed. In such a case; there is no use in trying to submit a block fixer job for that file. The RAID code has the function filterUnfixableSourceFiles() that checks for the presence of parity files for each source file. This is too expensive; since a lot of the parity files can be HARed. Instead; we can use a heuristic where we just check for the presence of the parent directory in the parity space. If the parent directory is absent; the parity file cannot be present; and the source file would be unfixable.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 2 Mar 2011 21:13:12 +0000,Tue; 1 Aug 2017 17:12:52 +0000,Tue; 1 Aug 2017 17:12:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2352
MAPREDUCE-2353,Improvement,Major,security;task;tasktracker,Make the MR changes to reflect the API changes in SecureIO library,Make the MR changes to reflect the API changes in SecureIO library. Specifically; the 'group' argument is never used in the SecureIO library; and hence the API changes.,Resolved,Fixed,,Benoy Antony,Devaraj Das,Thu; 3 Mar 2011 12:23:09 +0000,Fri; 13 Dec 2013 17:09:17 +0000,Fri; 13 Dec 2013 17:09:17 +0000,,0.22.0,,HADOOP-7115,,https://issues.apache.org/jira/browse/MAPREDUCE-2353
MAPREDUCE-2354,Improvement,Major,task;tasktracker,Shuffle should be optimized,Our study shows that shuffle is a performance bottleneck of mapreduce computing. There are some problems of shuffle: (1)Shuffle and reduce are tightly-coupled; usually shuffle phase doesn't consume too much memory and CPU; so theoretically; reducetasks's slot can be used for other computing tasks when copying data from maps. This method will enhance cluster utilization. Furthermore; should shuffle be separated from reduce? Then shuffle will not use reduce's slot;we need't distinguish between map slots and reduce slots at all. (2)For large jobs; shuffle will use too many network connections; Data transmitted by each network connection is very little; which is inefficient. From 0.21.0 one connection can transfer several map outputs; but i think this is not enough. Maybe we can use a per node shuffle client progress(like tasktracker) to shuffle data for all reduce tasks on this node; then we can shuffle more data trough one connection. (3)Too many concurrent connections will cause shuffle server do massive random IO; which is inefficient. Maybe we can aggregate http request(like delay scheduler); then random IO will be sequential. (4)How to manage memory used by shuffle efficiently. We use buddy memory allocation; which will waste a considerable amount of memory. (5)If shuffle separated from reduce; then we must figure out how to do reduce locality? (6)Can we store map outputs in a Storage system(like hdfs)? (7)Can shuffle be a general data transfer service; which not only for map reduce paradigm?,Open,Unresolved,,Unassigned,MengWang,Fri; 4 Mar 2011 11:01:18 +0000,Mon; 9 Mar 2015 20:29:12 +0000,,,0.20.1,mapreduce;shuffle,,,https://issues.apache.org/jira/browse/MAPREDUCE-2354
MAPREDUCE-2355,Improvement,Major,jobtracker,Add an out of band heartbeat damper,We should have a configurable knob to throttle how many out of band heartbeats are sent.,Resolved,Fixed,,Arun C Murthy,Owen O'Malley,Fri; 4 Mar 2011 16:46:30 +0000,Fri; 30 Nov 2012 19:53:17 +0000,Fri; 30 Nov 2012 19:53:17 +0000,,,,,MAPREDUCE-4478,https://issues.apache.org/jira/browse/MAPREDUCE-2355
MAPREDUCE-2356,Bug,Major,,A task succeeded even though there were errors on all attempts.,"From Luke Lu:  Here is a summary of why the failed map task was considered ""successful"" (Thanks to Mahadev; Arun and Devaraj for insightful discussions).  1. The map task was hanging BEFORE being initialized (probably in localization; but it doesn't matter in this case). Its state is UNASSIGNED.  2. The jt decided to kill it due to timeout and scheduled a cleanup task on the same node.  3. The cleanup task has the same attempt id (by design.) but runs in a different JVM. Its initial state is FAILED_UNCLEAN.  4. The JVM of the original attempt is getting killed; while proceeding to setupWorkDir and throwed an IllegalStateException while FileSystem.getLocal; which causes taskFinal.taskCleanup being called in Child; and triggered the NPE due to the task is not yet initialized (committer is null). Before the NPE; however it sent a statusUpdate to TT; and in tip.reportProgress; changed the task state (currently FAILED_UNCLEAN) to UNASSIGNED.  5. The cleanup attempt succeeded and report done to TT. In tip.reportDone; the isCleanup() check returned false due to the UNASSIGNED state and set the task state as SUCCEEDED.",Closed,Fixed,,Luke Lu,Owen O'Malley,Fri; 4 Mar 2011 17:03:33 +0000,Fri; 2 Sep 2011 22:13:24 +0000,Thu; 25 Aug 2011 20:08:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2356
MAPREDUCE-2357,Bug,Major,task,When extending inputsplit (non-FileSplit); all exceptions are ignored,if you're using a custom RecordReader InputFormat setup and using an InputSplit that does NOT extend FileSplit; then any exceptions you throw in your RecordReader.nextKeyValue() function are silently ignored.,Closed,Fixed,,Luke Lu,Owen O'Malley,Fri; 4 Mar 2011 17:12:45 +0000,Fri; 2 Sep 2011 22:13:23 +0000,Thu; 25 Aug 2011 20:08:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2357
MAPREDUCE-2358,Bug,Major,,MapReduce assumes HDFS as the default filesystem,Mapred assumes hdfs as the default fs even when defined otherwise.,Closed,Fixed,,Krishna Ramachandran,Owen O'Malley,Fri; 4 Mar 2011 17:43:36 +0000,Fri; 2 Sep 2011 22:13:23 +0000,Thu; 25 Aug 2011 20:08:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2358
MAPREDUCE-2359,Bug,Major,,Distributed cache doesn't use non-default FileSystems correctly,We are passing fs.deafult.name as viewfs: ,Closed,Fixed,,Krishna Ramachandran,Owen O'Malley,Mon; 7 Mar 2011 21:24:15 +0000,Fri; 2 Sep 2011 22:13:23 +0000,Thu; 25 Aug 2011 20:08:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2359
MAPREDUCE-2360,Bug,Major,client,Pig fails when using non-default FileSystem,The job client strips the file system from the user's job jar; which causes breakage when it isn't the default file system.,Closed,Fixed,,Unassigned,Owen O'Malley,Mon; 7 Mar 2011 21:34:13 +0000,Fri; 2 Sep 2011 22:13:19 +0000,Thu; 25 Aug 2011 20:08:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2360
MAPREDUCE-2361,Bug,Major,task,Distributed Cache is not adding files to class paths correctly,I am trying to add files into class path using: DistributedCache.addFileToClassPath  If file path is relative path like:  a.jar,Open,Unresolved,,Chris Douglas,Owen O'Malley,Mon; 7 Mar 2011 21:40:26 +0000,Fri; 11 Mar 2011 04:51:12 +0000,,,,,,MAPREDUCE-1581;MAPREDUCE-752,https://issues.apache.org/jira/browse/MAPREDUCE-2361
MAPREDUCE-2362,Bug,Major,test,Unit test failures: TestBadRecords and TestTaskTrackerMemoryManager,Fix unit-test failures: TestBadRecords (NPE due to rearranged MapTask code) and TestTaskTrackerMemoryManager (need hostname in output-string pattern).,Closed,Fixed,,Greg Roelofs,Owen O'Malley,Mon; 7 Mar 2011 21:44:43 +0000,Fri; 2 Sep 2011 22:13:18 +0000,Thu; 25 Aug 2011 20:08:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2362
MAPREDUCE-2363,Sub-task,Major,capacity-sched,Bad error messages for queues without acls,When a queue is built without any access rights; the error message is very bad.,Closed,Duplicate,MAPREDUCE-2411,Dick King,Owen O'Malley,Mon; 7 Mar 2011 21:56:11 +0000,Fri; 2 Sep 2011 22:17:59 +0000,Fri; 1 Apr 2011 02:10:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2363
MAPREDUCE-2364,Bug,Major,tasktracker,Shouldn't hold lock on rjob while localizing resources.,There is a deadlock while localizing resources on the TaskTracker.,Closed,Fixed,,Devaraj Das,Owen O'Malley,Mon; 7 Mar 2011 22:09:18 +0000,Thu; 26 Apr 2012 22:24:12 +0000,Thu; 25 Aug 2011 20:12:21 +0000,,0.20.203.0,,,MAPREDUCE-4088,https://issues.apache.org/jira/browse/MAPREDUCE-2364
MAPREDUCE-2365,Bug,Major,,Add counters for FileInputFormat (BYTES_READ) and FileOutputFormat (BYTES_WRITTEN),MAP_INPUT_BYTES and MAP_OUTPUT_BYTES will be computed using the difference between FileSystem counters before and after each next(K;V) and collect write op.  In case compression is being used; these counters will represent the compressed data sizes. The uncompressed size will not be available.  This is not a direct back-port of 5710. (Counters will be computed in MapTask instead of in individual RecordReaders).  0.20.100 -    New API - MAP_INPUT_BYTES will be computed using this method    Old API - MAP_INPUT_BYTES will remain unchanged.  0.23 -    New API - MAP_INPUT_BYTES will be computed using this method    Old API - MAP_INPUT_BYTES likely to use this method,Closed,Fixed,,Siddharth Seth,Owen O'Malley,Mon; 7 Mar 2011 22:19:46 +0000,Fri; 14 Oct 2011 09:01:30 +0000,Wed; 13 Jul 2011 23:36:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2365
MAPREDUCE-2366,Bug,Major,tasktracker,TaskTracker can't retrieve stdout and stderr from web UI,Problem where the task browser UI can't retrieve the stdxxx printouts of streaming jobs that abend in the unix code; in the common case where the containing job doesn't reuse JVM's.,Closed,Fixed,,Dick King,Owen O'Malley,Mon; 7 Mar 2011 22:27:50 +0000,Fri; 2 Sep 2011 22:13:21 +0000,Thu; 25 Aug 2011 20:08:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2366
MAPREDUCE-2367,Improvement,Minor,,Allow using a file to exclude certain tests from build,"It would be nice to be able to exclude certain tests when running builds. For example; when a test is ""known flaky""; you may want to exclude it from the main Hudson job; but not actually disable it in the codebase (so that it still runs as part of another Hudson job; for example).",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 7 Mar 2011 22:48:06 +0000,Tue; 15 Nov 2011 00:49:07 +0000,Sat; 12 Mar 2011 00:58:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2367
MAPREDUCE-2368,Bug,Major,contrib/raid,RAID DFS regression,The patch for MAPREDUCE-2248 did not handle zero-length files correctly; which leads to ArrayIndexOutOfBoundsException when opening a zero-length file. That case needs special handling.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Tue; 8 Mar 2011 07:34:03 +0000,Tue; 10 Mar 2015 03:15:34 +0000,Tue; 10 Mar 2015 03:15:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2368
MAPREDUCE-2369,Improvement,Minor,client,Using TableMapper Iterable IntWritables not passed to the reducer in order put by mapper,For mapper class:       class Mapper1 extends TableMapperImmutableBytesWritable;IntWritable With reducer class:      class Reducer1 extends TableReducerImmutableBytesWritable;IntWritable; ImmutableBytesWritable  IterableIntWritable values are usually received by the reducer in the order the values are written to the context by the mapper. However in my testing about 5% of cases; the same order is not maintained; and the ability of the reducer to categorize a value by order lost. Chronological order guaranteed would serve as a facility for identification by the reducer.,Resolved,Invalid,,Unassigned,Bob Cummins,Tue; 8 Mar 2011 13:32:26 +0000,Tue; 8 Mar 2011 19:41:00 +0000,Tue; 8 Mar 2011 17:52:45 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2369
MAPREDUCE-2370,Bug,Minor,job submission,JobConf.findContainingJar incorrectly transforms paths containing '+' character,Due to the usage of URLDecoder in JobConf#findContainingJar; the path will be incorrectly modified if it contains the '' character.  URLDecoder is intended for HTML form data (application hadoop-tools-0.20.38.jar):,Resolved,Duplicate,MAPREDUCE-714,Unassigned,Tony Valderrama,Tue; 8 Mar 2011 18:38:44 +0000,Tue; 8 Mar 2011 18:44:40 +0000,Tue; 8 Mar 2011 18:44:02 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2370
MAPREDUCE-2371,Improvement,Major,,TaskLogsTruncater does not need to check log ownership when running as Child,Before MAPREDUCE-2178; it used to be that the TaskLogsTruncater had to use the SecureIO API to open the task logs before truncation; to avoid an attack where the user would symlink in something that the TT had access to but not the user. After MAPREDUCE-2178; this truncation is done as the user rather than as the TT; so we don't need to perform this check.  Not performing the check avoids a fork() call which we've found to be troublesome since it doubles vmem consumption and thus requires that users bump mapred.child.ulimit to 2x the expected child heap size.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 8 Mar 2011 20:59:01 +0000,Tue; 10 Mar 2015 01:01:40 +0000,Tue; 10 Mar 2015 01:01:40 +0000,,0.23.0,,MAPREDUCE-2178,,https://issues.apache.org/jira/browse/MAPREDUCE-2371
MAPREDUCE-2372,Improvement,Major,task,TaskLogAppender mechanism shouldn't be set in log4j.properties,The TaskLogAppender log4j appender relies on using log4j.properties to pass in some Java system properties into properties of the logger. This is problematic since we've often found that users have customized log4j.properties and don't upgrade it when they upgrade the version of Hadoop.  Since this is really an internal mechanism of how the task runner passes task info to the TLA; we shouldn't rely on these settings in log4j.properties at all. Rather; we should just get the system properties directly from System.getProperty.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 9 Mar 2011 20:05:58 +0000,Mon; 12 Dec 2011 06:19:37 +0000,Thu; 19 May 2011 20:16:25 +0000,,0.22.0,,,HADOOP-7308,https://issues.apache.org/jira/browse/MAPREDUCE-2372
MAPREDUCE-2373,Improvement,Major,,When tasks exit with a nonzero exit status; task runner should log the stderr as well as stdout,Currently; if the taskjvm.sh script fails to exec  for some reason; it prints its error message to stderr. This doesn't make it to the logs anywhere. Logging the stderr is very useful to understand why taskjvm.sh failed to start the Child jvm.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Wed; 9 Mar 2011 21:39:12 +0000,Thu; 2 May 2013 02:29:37 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2373
MAPREDUCE-2374,Bug,Major,,Text File Busy errors launching MR tasks,"Some very small percentage of tasks fail with a ""Text file busy"" error.  The following was the original diagnosis:  Our use of PrintWriter in TaskController.writeCommand is unsafe; since that class swallows all IO exceptions. We're not currently checking for errors; which I'm seeing result in occasional task failures with the message ""Text file busy"" - assumedly because the close() call is failing silently for some reason. .. but turned out to be another issue as well (see below)",Closed,Fixed,,Andy Isaacson,Todd Lipcon,Wed; 9 Mar 2011 22:04:19 +0000,Thu; 7 Feb 2013 04:29:40 +0000,Thu; 23 Aug 2012 18:32:30 +0000,,0.22.0,,,MAPREDUCE-4857,https://issues.apache.org/jira/browse/MAPREDUCE-2374
MAPREDUCE-2375,Improvement,Minor,,Improve exception thrown by SpillRecord for bad spill index,In trying to debug some issues on a cluster that was seeing shuffle fetch failures; I found the IOException thrown by the SpillRecord constructor to be insufficient. An improved exception would have more details about the file path; offset; etc.,Closed,Won't Fix,,Todd Lipcon,Todd Lipcon,Wed; 9 Mar 2011 22:58:42 +0000,Tue; 15 Nov 2011 00:49:22 +0000,Fri; 11 Mar 2011 04:31:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2375
MAPREDUCE-2376,Bug,Major,task-controller;test,test-task-controller fails if run as a userid < 1000,test-task-controller tries to verify that the task-controller won't run on behalf of users with uid  1000. This makes the test fail when running in some test environments - eg our hudson jobs internally run as a system user with uid 101.,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Fri; 11 Mar 2011 20:40:14 +0000,Wed; 17 Oct 2012 21:59:50 +0000,,,0.20.205.0;0.22.0,,MAPREDUCE-2178,HADOOP-8499,https://issues.apache.org/jira/browse/MAPREDUCE-2376
MAPREDUCE-2377,Bug,Major,task-controller,task-controller fails to parse configuration if it doesn't end in \n,If the task-controller.cfg file doesn't end in a newline; it fails to parse properly.,Closed,Fixed,HADOOP-7476,Benoy Antony,Todd Lipcon,Fri; 11 Mar 2011 20:42:36 +0000,Wed; 17 Oct 2012 18:27:24 +0000,Thu; 7 Jun 2012 19:45:18 +0000,,0.22.0,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-2377
MAPREDUCE-2378,Bug,Major,,Reduce fails when running on 1 small file. ,If i run the wordcount example on 1 small (less than 2MB) file i get the following error:  log4j:ERROR Failed to flush writer;  152)   If i run the wordcount test with 2 files; it works fine.   I have actually repeated this with my own code. I am working on something that requires me to map reduce a small file and I had to work around the problem by splitting the file into 2 1MB pieces for my job to run.   All our jobs that run on 1 single larger file (over 1GB) work flawlessly. I am not exactly sure the threshold; From the testing i have done it seems to be any file smaller than the default HDFS block size (64MB) Sometimes it seems random in the 5-64MB range. But its 100% for the 5MB and smaller files.,Resolved,Cannot Reproduce,,Unassigned,Simon Dircks,Fri; 11 Mar 2011 23:18:59 +0000,Thu; 17 Jul 2014 15:22:59 +0000,Thu; 17 Jul 2014 15:22:59 +0000,,0.21.0,1;failed;file;log4j;reduce;single;small;tiny,,,https://issues.apache.org/jira/browse/MAPREDUCE-2378
MAPREDUCE-2379,Bug,Major,distributed-cache;documentation,Distributed cache sizing configurations are missing from mapred-default.xml,"MAPREDUCE-1538 added mapreduce.tasktracker.cache.local.numberdirectories which is not documented in mapred-default.xml 	When MAPREDUCE-711 moved DistributedCache into the mapred project; the local.cache.size parameter was left in core-default.xml instead of moved to mapred-default.xml. It has since been renamed to mapreduce.tasktracker.cache.local.size",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 11 Mar 2011 23:33:38 +0000,Tue; 15 Nov 2011 00:49:04 +0000,Mon; 14 Mar 2011 08:25:32 +0000,,0.22.0,,,HADOOP-7184,https://issues.apache.org/jira/browse/MAPREDUCE-2379
MAPREDUCE-2380,Bug,Major,tools/rumen,Multiple replace function call can be replaced with a single for loop to improve performance ,4 consecutive replace() is called to remove the special characters.  It's 3+ times slower than using a for loop  replace them all.    This bug has the same problem as the MySQL bug : http: bug.php?id=45699,Open,Unresolved,MAPREDUCE-2343,Unassigned,Xiaoming Shi,Sun; 13 Mar 2011 03:15:44 +0000,Fri; 13 May 2016 23:11:49 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2380
MAPREDUCE-2381,Improvement,Major,,JobTracker instrumentation not consistent about error handling,In the current code; if the class specified by the JobTracker instrumentation config property is not there; the JobTracker fails to start with a ClassNotFound.  If it's there; but it can't load for whatever reason; the JobTracker continues with the default.  Having two different error-handling routes is a bit confusing; I propose to move one line so that it's consistent.  (On the TaskTracker instrumentation side; if any of the multiple instrumentations aren't available; the default is used.)  The attached patch merely moves a line inside of the try block that's already there.,Closed,Fixed,,Philip Zeyliger,Philip Zeyliger,Mon; 14 Mar 2011 01:56:16 +0000,Tue; 15 Nov 2011 00:48:27 +0000,Wed; 18 May 2011 18:54:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2381
MAPREDUCE-2382,Improvement,Minor,client,Key/Value ordering within a single key/value set when multiple values exist for a key,&gt;The context of this issue is entirely within one key value sets as they are funneled to a reducer  by mappers.&lt;  When mapper writes multiple values for a key; the underlying collection class maps each of the values to the key; but not always in chronological order. If chronological order were guaranteed each of the values mapped to the key; each of the values could be understood as specific and different parameters between the mapper and the reducer.  I've done little tricks like having the mapper flag one a the values by making it a  negative number; which the reducer recognizes and can write it to hbase as a unique column value.This is a kluge workaround which it would be nice to not have to do.  Used to formulate this suggestion: TableMapperImmutableBytesWritable;IntWritable TableReducerImmutableBytesWritable;IntWritable; ImmutableBytesWritable,Resolved,Not A Problem,,Unassigned,Bob Cummins,Mon; 14 Mar 2011 12:37:03 +0000,Tue; 15 Mar 2011 15:16:10 +0000,Tue; 15 Mar 2011 15:16:10 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2382
MAPREDUCE-2383,Task,Major,distributed-cache;documentation,Improve documentation of DistributedCache methods,Users find the various methods in DistributedCache confusing - it's not clearly documented what the difference is between addArchiveToClassPath vs addFileToClassPath. We should improve the docs to clarify this and perhaps add an example that uses the DistributedCache.,Closed,Fixed,,Harsh J,Todd Lipcon,Mon; 14 Mar 2011 19:53:57 +0000,Mon; 12 Dec 2011 06:18:35 +0000,Thu; 12 May 2011 07:21:42 +0000,,0.22.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2383
MAPREDUCE-2384,Improvement,Major,job submission;test,The job submitter should make sure to validate jobs before creation of necessary files,"In 0.20.x 1.x; 0.21; 0.22 the MapReduce job submitter writes some job-necessary files to the JT FS before checking for output specs or other job validation items. This appears unnecessary to do.  This has since been silently fixed in the rewrite of the MRApp (called MRv2) in the MAPREDUCE-279 dump thats now replaced the older MR (or; MRv1 now). However; we can still do with a test case to prevent regressing again.  Original description below:   When I read the source code of MapReduce in Hadoop 0.21.0; sometimes it made me confused about error response. For example:         1. JobSubmitter checking output for each job. MapReduce makes rule to limit that each job output must be not exist to avoid fault overwrite. In my opinion; MR should verify output at the point of client submitting. Actually; it copies related files to specified target and then; doing the verifying.          2. JobTracker.   Job has been submitted to JobTracker. In first step; JT create JIT object that is very ""huge"" . Next step; JT start to verify job queue authority and memory requirements.          In normal case; verifying client input then response immediately if any cases in fault. Regular logic can be performed if all the inputs have passed.           It seems like that those code does not make sense for understanding. Is only my personal opinion? Wish someone help me to explain the details. Thanks!",Resolved,Fixed,MAPREDUCE-432,Harsh J,Denny Ye,Tue; 15 Mar 2011 04:42:02 +0000,Thu; 12 May 2016 18:23:21 +0000,Mon; 28 May 2012 13:16:03 +0000,,0.21.0,,,MAPREDUCE-3154,https://issues.apache.org/jira/browse/MAPREDUCE-2384
MAPREDUCE-2385,Bug,Major,contrib/fair-share,All test cases failed in TestFairScheduler,All test cases failed due to there is no #canBeSpeculated(long) method at inner class FakeTaskInProgress. Each case may call the #update() method in FairScheduler; using #canBeSpeculated(long) method in TaskInProgress if no override at FakeTaskInProgress.  It can be fixed like this: class FakeTaskInProgress extends TaskInProgress {   ... },Open,Unresolved,,Unassigned,Denny Ye,Tue; 15 Mar 2011 07:28:12 +0000,Tue; 15 Mar 2011 07:28:12 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2385
MAPREDUCE-2386,Bug,Major,tasktracker,TT jetty server stuck in tight loop around epoll_wait,In some load testing; I got a TaskTracker into a state where its Jetty server is in a tight loop calling epoll_wait; which is returning EINVAL:  pid 19573 epoll_wait(157; 40829000; 8192; 0) = -1 EINVAL (Invalid argument)  It's not responding to any HTTP connections - connections are accepted and then just hang.,Open,Unresolved,MAPREDUCE-2530;MAPREDUCE-5949,Unassigned,Todd Lipcon,Wed; 16 Mar 2011 04:55:46 +0000,Mon; 7 Jul 2014 09:39:22 +0000,,,0.23.0;1.0.3,,,MAPREDUCE-2389;HADOOP-7191;MAPREDUCE-1950;MAPREDUCE-2530,https://issues.apache.org/jira/browse/MAPREDUCE-2386
MAPREDUCE-2387,Bug,Major,,Potential Resource leak in IOUtils.java,In the above code if any exception throws from the out.close() statement; in.close() statement will not execute and the input stream will not be closed.,Resolved,Duplicate,HADOOP-7194,Unassigned,Devaraj K,Wed; 16 Mar 2011 05:04:40 +0000,Wed; 16 Mar 2011 09:51:49 +0000,Wed; 16 Mar 2011 09:51:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2387
MAPREDUCE-2388,Bug,Major,jobtracker,Map tasks with no locality hints should not always be considered off-rack,"When a map task has no locality hints; it's currently always considered ""off-rack"". This has a couple side effects which aren't great; most notably that most schedulers will only assign one off-rack task per heartbeat. This limits the scheduling throughput of these jobs.  It's unclear that it's always correct to schedule them as ""node-local"" either; though most examples I can think of are probably better treated this way.",Open,Unresolved,,Unassigned,Todd Lipcon,Wed; 16 Mar 2011 06:20:35 +0000,Wed; 16 Mar 2011 06:27:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2388
MAPREDUCE-2389,Bug,Major,tasktracker,Spurious EOFExceptions reading SpillRecord index files,"In large jobs; I see around 1 shuffle fetch out of every million fetches fail with an EOFException reading the SpillRecord index file. After lots of investigation; including systemtap; it looks like the read() syscall is actually returning a premature ""0"" result for no reason; so this is likely a kernel or filesystem bug which is exacerbated by some workload the TT does.",Open,Unresolved,,Unassigned,Todd Lipcon,Wed; 16 Mar 2011 06:51:05 +0000,Thu; 4 Apr 2013 19:12:40 +0000,,,0.22.0,,,MAPREDUCE-2386;MAPREDUCE-2980,https://issues.apache.org/jira/browse/MAPREDUCE-2389
MAPREDUCE-2390,Bug,Major,jobtracker;tasktracker,JobTracker and TaskTrackers fail with a misleading error if one of the mapreduce.cluster.dir has unusable permissions / is unavailable.,To reproduce; have a mapred.local.dir property set to a few directories. Before starting up the JT; set one of these directories' permission as 'd---------'; and then start the JT  solution soon.,Resolved,Duplicate,MAPREDUCE-1382,Harsh J,Harsh J,Wed; 16 Mar 2011 19:46:14 +0000,Sat; 11 Jun 2011 18:37:59 +0000,Sat; 11 Jun 2011 18:37:59 +0000,,0.20.2,configuration;directory-permissions;mapreduce,,,https://issues.apache.org/jira/browse/MAPREDUCE-2390
MAPREDUCE-2391,Improvement,Major,contrib/fair-share,Improve fair-scheduler documentation regarding 'weight' parameter,The weight that is displayed on the FairSchedulerServlet is the 'job' weight; which is not to be confused with 'pool' weight which is specified in the configuration (fair-scheduler.xml or whathaveyou).  The pool weight influences the fair-share allocation for a pool (and by extension the jobs within a pool).  The job weight affects a job's share or priority within a pool. This is affected by priority and also if you specify sizebasedweight=true or if you specify a class for mapred.fairscheduler.weightadjuster (for example; org.apache.hadoop.mapred.NewJobWeightBooster). This is the weight that shows up on the FairSchedulerServlet.  This can be quite confusing; and is worth documenting.,Open,Unresolved,,Unassigned,Patrick Angeles,Wed; 16 Mar 2011 20:36:27 +0000,Wed; 16 Mar 2011 20:36:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2391
MAPREDUCE-2392,Bug,Major,,TaskTracker shutdown in the tests sometimes take 60s,There are a lot of the following in the test logs:     Note there is over one minute between the first line and the second.,Closed,Fixed,,Tom White,Tom White,Thu; 17 Mar 2011 05:16:35 +0000,Mon; 12 Dec 2011 06:18:38 +0000,Thu; 17 Mar 2011 21:21:01 +0000,,,,,HADOOP-6762,https://issues.apache.org/jira/browse/MAPREDUCE-2392
MAPREDUCE-2393,Bug,Major,contrib/fair-share,No total min share limitation of all pools,hi; there is no limitation about min share of all pools with cluster total shares. User can define arbitrary amount of min share for each pool. It has such description in fair scheduler design document; but no regular code.  It may critical for slot distribution. One pool can hold all cluster slots to meet it's min share that greater than cluster total slots very much. If that case has happened; we should scaled down proportionally.,Resolved,Won't Fix,,Unassigned,Denny Ye,Thu; 17 Mar 2011 05:47:58 +0000,Fri; 8 May 2015 10:41:31 +0000,Fri; 8 May 2015 10:41:31 +0000,,0.21.0,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-2393
MAPREDUCE-2394,Bug,Blocker,,JUnit output format doesn't propagate into some contrib builds,Some of the contribs seem to have an issue where the test.junit.output.format property isn't propagating down into their builds. So; Hudson is unable to parse the test output; and we see failed builds with no actual parsed test results showing what failed.  This is at least true for contrib raid but maybe others as well.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 17 Mar 2011 17:49:18 +0000,Mon; 12 Dec 2011 06:19:53 +0000,Thu; 17 Mar 2011 18:15:28 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2394
MAPREDUCE-2395,Bug,Critical,contrib/raid,TestBlockFixer timing out on trunk,In recent Hudson builds; TestBlockFixer has been timing out. Not clear how long it has been broken since MAPREDUCE-2394 was hiding the RAID tests from Hudson's test result parsing.,Closed,Fixed,,Ramkumar Vadali,Todd Lipcon,Thu; 17 Mar 2011 18:00:34 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Thu; 7 Apr 2011 00:01:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2395
MAPREDUCE-2396,Bug,Major,,InMemFSMergeThread.doInMemMerge() miss the last MapOutput for each merge round  ,"In ReduceTask.shuffleInMemory(); once a new MapOutput is read; the ramManager.closeInMemoryFile() is called to notify waitForDataToMerge()  to check if a in memory merge is required. If the threshold is met; the doInMemMerge() may start before the MapOutput just read been added to mapOutputsFilesInMemory. So the ""dataAvailable.notify();"" should be removed and let the noteCopiedMapOutput() notify the merge.",Open,Unresolved,,Unassigned,Elton Tian,Sat; 19 Mar 2011 02:08:15 +0000,Tue; 10 Jul 2012 21:27:09 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2396
MAPREDUCE-2397,Improvement,Trivial,jobtracker,Allow user to sort jobs in different sections (Completed; Failed; etc.) by the various columns available,It would be nice (IMHO) to be able to sort the tables on the jobtracker.jsp page by any column (jobID would be most logical at first) so that one could eliminate scrolling all of the time.  Perhaps also have the page save the user's sorting preferences per table too.,Resolved,Won't Fix,,Unassigned,Stephen Tunney,Sat; 19 Mar 2011 04:24:05 +0000,Tue; 17 Mar 2015 08:52:12 +0000,Tue; 17 Mar 2015 08:52:12 +0000,,,interface;jsp;page;user;web,,,https://issues.apache.org/jira/browse/MAPREDUCE-2397
MAPREDUCE-2398,Bug,Minor,benchmarks,MRBench: setting the baseDir parameter has no effect,The optional -baseDir parameter lets user specify the base DFS path for output ...); even though the user-supplied location for -baseDir is created (and eventually deleted again) on HDFS.  The bug affects at least Hadoop 0.20.2 and the current trunk (r1082703) as of March 21; 2011.,Resolved,Fixed,,Wilfred Spiegelenburg,Michael Noll,Mon; 21 Mar 2011 09:33:18 +0000,Tue; 30 Aug 2016 01:20:53 +0000,Thu; 21 Apr 2016 12:28:32 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2398
MAPREDUCE-2399,Improvement,Major,,The embedded web framework for MAPREDUCE-279,Discuss the web framework which is a part of MAPREDUCE-279.,Resolved,Fixed,,Luke Lu,Arun C Murthy,Mon; 21 Mar 2011 15:51:48 +0000,Wed; 8 Feb 2012 02:35:14 +0000,Mon; 9 Jan 2012 07:54:06 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2399
MAPREDUCE-2400,Sub-task,Major,client,Remove Cluster's dependency on JobTracker,Introduce a factory using ServiceLoader to remove the direct dependency.,Resolved,Fixed,MAPREDUCE-1678,Tom White,Tom White,Tue; 22 Mar 2011 04:40:15 +0000,Thu; 21 Jul 2011 11:37:37 +0000,Tue; 12 Jul 2011 17:11:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2400
MAPREDUCE-2401,Bug,Major,contrib/fair-share,Can not change scheduling mode of default pool,hi gays    When client submitted a job; Fair Scheduler chose default pool (by mapreduce.job.user.name) if client undefined property 'mapred.fairscheduler.pool'. This default pool's schedulingMode field was judged by that it had been created. Client can not modify scheduling mode between jobs in this default pool by allocation file reconfiguration no longer.,Open,Unresolved,,Unassigned,Denny Ye,Wed; 23 Mar 2011 08:26:35 +0000,Tue; 17 May 2011 08:07:48 +0000,,,0.20.1,fair;scheduler,MAPREDUCE-2107,,https://issues.apache.org/jira/browse/MAPREDUCE-2401
MAPREDUCE-2402,Improvement,Minor,contrib/fair-share,Dump scheduling detail if any jobs are running,Currently; fair scheduler dumps scheduling detail to local log file; and it always doing continually regardless system is idle. Log file will be larger along. In my opinion; I only want the concrete scheduling detail when any jobs are coming; not anytime. I sincerely hope it can by applied in next release.,Open,Unresolved,,Unassigned,Denny Ye,Wed; 23 Mar 2011 09:02:57 +0000,Wed; 23 Mar 2011 09:02:57 +0000,,,0.21.0,fair;scheduler,,,https://issues.apache.org/jira/browse/MAPREDUCE-2402
MAPREDUCE-2403,Improvement,Major,mrv2,MR-279: Improve job history event handling in AM to log to HDFS,Improve the job history event handling in the application master to log to HDFS in the staging directory for the job and also move it to the required location for the job history server to use.,Closed,Fixed,,Krishna Ramachandran,Mahadev konar,Wed; 23 Mar 2011 23:28:52 +0000,Tue; 15 Nov 2011 00:49:58 +0000,Thu; 24 Mar 2011 04:32:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2403
HADOOP-7209,Improvement,Major,,Extensions to FsShell,"Our project; Pig; exposes FsShell functionality to our end users through a shell command. We want to use this command with no modifications to make sure th we would like to be expanded implemented:  	rm -f 	rmdir ---ignore-fail-on-non-empty 	mkdir -p",Resolved,Fixed,,Daryn Sharp,Olga Natkovich,Fri; 25 Mar 2011 00:17:49 +0000,Mon; 24 Sep 2012 17:35:13 +0000,Mon; 16 Apr 2012 13:42:06 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/HADOOP-7209
MAPREDUCE-2405,Improvement,Major,mrv2,MR-279: Implement uber-AppMaster (in-cluster LocalJobRunner for MRv2),Port MAPREDUCE-1220 to MRv2.  This is an optimization for small jobs wherein all tasks run on the same node in the same JVM container.,Closed,Fixed,,Greg Roelofs,Mahadev konar,Sat; 26 Mar 2011 01:39:37 +0000,Tue; 15 Nov 2011 00:48:43 +0000,Fri; 8 Apr 2011 02:55:29 +0000,,,,,MAPREDUCE-1220,https://issues.apache.org/jira/browse/MAPREDUCE-2405
MAPREDUCE-2406,Bug,Minor,,Failed validate copy in distcp,Each time the distcp is done; validateCopy(srcstat; absdst) will be called.  When doing distcp; if the -pb(preserve block size) is not set; the dst will use the default block size. However; if the src file use block size other than the default block size; and -pb is not set; after copying; the src and dst will have different block size. It will not pass the validateCopy check in this case.,Open,Unresolved,,Unassigned,Rosie Li,Mon; 28 Mar 2011 20:44:51 +0000,Mon; 19 Dec 2011 12:29:02 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2406
MAPREDUCE-2407,New Feature,Major,contrib/gridmix,Make Gridmix emulate usage of Distributed Cache files,Currently Gridmix emulates disk IO load only. This JIRA is to make Gridmix emulate Distributed Cache load as defined by the job-trace.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Tue; 29 Mar 2011 09:26:37 +0000,Tue; 15 Nov 2011 00:49:32 +0000,Mon; 23 May 2011 14:37:16 +0000,,0.23.0,,MAPREDUCE-2153,,https://issues.apache.org/jira/browse/MAPREDUCE-2407
MAPREDUCE-2408,New Feature,Major,contrib/gridmix,Make Gridmix emulate usage of data compression,Currently Gridmix emulates disk IO load only. This JIRA is to make Gridmix emulate load due to data compression as defined by the job-trace.,Closed,Fixed,,Amar Kamat,Ravi Gummadi,Tue; 29 Mar 2011 09:29:24 +0000,Tue; 15 Nov 2011 00:48:46 +0000,Fri; 27 May 2011 06:26:14 +0000,,,,MAPREDUCE-2153,,https://issues.apache.org/jira/browse/MAPREDUCE-2408
MAPREDUCE-2409,Bug,Major,distributed-cache,Distributed Cache does not differentiate between file /archive for files with the same path,If a 'global' file is specified as a 'file' by one job - subsequent jobs cannot override this source file to be an 'archive' (until the TT cleans up it's cache or a TT restart). The other way around as well - 'archive' to 'file'  In case of an accidental submission using the wrong type - some of the tasks for the second job will end up seeing the source file as an archive; others as a file.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 30 Mar 2011 01:23:12 +0000,Fri; 2 Sep 2011 22:13:19 +0000,Thu; 21 Jul 2011 01:59:31 +0000,,0.20.203.0;0.20.203.1;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2409
MAPREDUCE-2410,Improvement,Minor,contrib/streaming;documentation,document multiple keys per reducer oddity in hadoop streaming FAQ,"Hi; for a newcomer to hadoop streaming; it comes as a surprise that the reducer receives arbitrary keys; unlike the ""real"" hadoop where a reducer works on a single key. An explanation for this is @ http: browser  I suggest to add this to the FAQ of hadoop streaming",Resolved,Fixed,,Harsh J,Dieter Plaetinck,Wed; 30 Mar 2011 07:53:05 +0000,Mon; 16 May 2011 20:07:12 +0000,Thu; 12 May 2011 07:16:07 +0000,,0.20.2,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2410
MAPREDUCE-2411,Bug,Minor,,When you submit a job to a queue with no ACLs you get an inscrutible NPE,With this patch we'll check for that; and print a message in the logs.  Then at submission time you find out about it.,Closed,Fixed,,Dick King,Dick King,Thu; 31 Mar 2011 00:00:40 +0000,Fri; 2 Sep 2011 22:13:19 +0000,Fri; 1 Apr 2011 02:15:21 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2411
MAPREDUCE-2412,Bug,Minor,,When you submit a job on a non-existent queue; you get an opaque NPE,nan,Resolved,Duplicate,MAPREDUCE-2411,Dick King,Dick King,Thu; 31 Mar 2011 00:04:58 +0000,Fri; 1 Apr 2011 02:41:24 +0000,Fri; 1 Apr 2011 02:41:24 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2412
MAPREDUCE-2413,Sub-task,Major,task-controller;tasktracker,TaskTracker should handle disk failures at both startup and runtime,"At present; TaskTracker doesn't handle disk failures properly both at startup and runtime.  (1) Currently TaskTracker doesn't come up if any of the mapred-local-dirs is on a bad disk. TaskTracker should ignore that particular mapred-local-dir and start up and use only the remaining good mapred-local-dirs. (2) If a disk goes bad while TaskTracker is running; currently TaskTracker doesn't do anything special. This results in either    (a) TaskTracker continues to ""try to use that bad disk"" and this results in lots of task failures and possibly job failures(because of multiple TTs having bad disks) and eventually these TTs getting graylisted for all jobs. And this needs manual restart of TT with modified configuration of mapred-local-dirs avoiding the bad disk. OR    (b) Health check script identifying the disk as bad and the TT gets blacklisted. And this also needs manual restart of TT with modified configuration of mapred-local-dirs avoiding the bad disk.  This JIRA is to make TaskTracker more fault-tolerant to disk failures solving (1) and (2). i.e. TT should start even if at least one of the mapred-local-dirs is on a good disk and TT should adjust its in-memory list of mapred-local-dirs and avoid using bad mapred-local-dirs.",Closed,Fixed,,Ravi Gummadi,Bharath Mundlapudi,Thu; 31 Mar 2011 18:43:44 +0000,Thu; 29 Aug 2013 04:30:11 +0000,Fri; 22 Apr 2011 23:07:56 +0000,,0.20.204.0,,MAPREDUCE-2415,MAPREDUCE-2850;MAPREDUCE-2928;MAPREDUCE-2959,https://issues.apache.org/jira/browse/MAPREDUCE-2413
MAPREDUCE-2414,Improvement,Major,mrv2,MR-279: Use generic interfaces for protocols,Use generic interfaces for protocols for MAPREDUCE-279.,Closed,Fixed,,Siddharth Seth,Arun C Murthy,Thu; 31 Mar 2011 22:08:40 +0000,Tue; 15 Nov 2011 00:48:29 +0000,Mon; 4 Apr 2011 18:18:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2414
MAPREDUCE-2415,Sub-task,Major,task-controller;tasktracker,Distribute TaskTracker userlogs onto multiple disks,Currently; userlogs directory in TaskTracker is placed under hadoop.log.dir like hadoop.log.dir userlogs. I am proposing to spread these userlogs onto multiple configured mapred.local.dirs to strengthen TaskTracker reliability w.r.t disk failures.,Closed,Fixed,,Bharath Mundlapudi,Bharath Mundlapudi,Fri; 1 Apr 2011 08:03:59 +0000,Thu; 2 May 2013 02:30:53 +0000,Fri; 22 Apr 2011 23:13:52 +0000,,0.20.204.0,,MAPREDUCE-2413,MAPREDUCE-2804;MAPREDUCE-4481;MAPREDUCE-2851;MAPREDUCE-2846,https://issues.apache.org/jira/browse/MAPREDUCE-2415
MAPREDUCE-2416,Bug,Major,contrib/gridmix,In Gridmix; in RoundRobinUserResolver; the list of groups for a user obtained from users-list-file is incorrect,"RoundRobinUserResolver.parseUserList() has a bug in obtaining list of groups for each user  in the sense that the list is not cleared before obtaining groups list for the next user. So if the first line has some groups; then from 2nd line onwards; the validation of ""whether the users(in the next lines) are also having group names in those lines"" is useless as the list is already nonempty.  For example; users-list-file content as shown below also is valid as per parseUserList(): ------------------ user1;group1 user2; user3; user4; ------------------",Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 1 Apr 2011 09:23:51 +0000,Tue; 15 Nov 2011 00:50:04 +0000,Fri; 29 Apr 2011 03:53:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2416
MAPREDUCE-2417,Bug,Major,contrib/gridmix,In Gridmix; in RoundRobinUserResolver mode; the testing/proxy users are not associated with unique users in a trace,As per the Gridmix documentation; the testing users should associate with unique user in the trace. However; currently the gridmix impersonate the users based on job irrespective of user.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 1 Apr 2011 09:31:53 +0000,Thu; 2 Feb 2012 07:45:34 +0000,Thu; 28 Apr 2011 08:10:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2417
MAPREDUCE-2418,Bug,Minor,,Errors not shown in the JobHistory servlet (specifically Counter Limit Exceeded),Job error details are not displayed in the JobHistory servlet. e.g. Errors like 'Counter limit exceeded for a job'.  jobdetails.jsp has 'Failure Info'; but this is missing in jobdetailshistory.jsp,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 1 Apr 2011 18:37:38 +0000,Fri; 2 Sep 2011 22:13:23 +0000,Thu; 25 Aug 2011 20:12:20 +0000,,0.20.203.0;0.20.203.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2418
MAPREDUCE-2419,Task,Minor,jobtracker,Jobs stall forever if mapred.task.cache.levels is set to 0.,"It seems that mapred.task.cache.levels is used by JobTracker to create task caches for nodes at various levels. This makes data-locality scheduling possible. If I set mapred.task.cache.levels to 0 (to disable task caching) and use default network topology; then mapreduce job will stall forever. The reason is JobInProgress::findNewMapTask always returns -1. Field ""nonRunningMapCache"" is empty and field ""nonLocalMaps"" is also empty.    I can think of two possible fixes.  1) If mapred.task.cache.levels is set 0; Hadoop should fall back to some default caching strategy. E.g. put all tasks into JobInProgress::nonLocalMaps. 2) ignore values less than 1",Open,Unresolved,,Unassigned,Zhenhua (Gerald) Guo,Fri; 1 Apr 2011 20:58:02 +0000,Fri; 1 Apr 2011 20:58:02 +0000,,,0.20.1;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2419
MAPREDUCE-2420,Bug,Major,,JobTracker should be able to renew delegation token over HTTP,in case JobTracker has to talk to a NameNode running a different version (RPC version mismatch); Jobtracker should be able to fall back to HTTP renewal.  Example of the case - running distcp between different versions using hfpt.,Closed,Fixed,,Boris Shkolnik,Boris Shkolnik,Tue; 5 Apr 2011 03:27:58 +0000,Tue; 5 Jun 2012 13:53:46 +0000,Thu; 28 Apr 2011 23:11:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2420
MAPREDUCE-2421,Sub-task,Major,client,Remove JobHistory's dependency on JobTracker,The direct dependency can be removed by introducing a callback inteface. This is for MAPREDUCE-1638.,Open,Unresolved,,Tom White,Tom White,Wed; 6 Apr 2011 23:24:15 +0000,Fri; 22 Jul 2011 23:17:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2421
MAPREDUCE-2422,Sub-task,Major,client,Removed unused internal methods from DistributedCache,DistributedCache has a number of deprecated methods that are no longer used ever since TrackerDistributedCacheManager was introduced in MAPREDUCE-476. Removing these methods (which are not user-facing) will make it possible to complete MAPREDUCE-1638 by keeping DistributedCache in the API tree; and TrackerDistributedCacheManager; TaskDistributedCacheManager in the implementation tree.,Closed,Fixed,,Tom White,Tom White,Thu; 7 Apr 2011 04:30:31 +0000,Tue; 15 Nov 2011 00:48:36 +0000,Fri; 6 May 2011 22:47:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2422
MAPREDUCE-2423,Wish,Trivial,jobtracker,Monitoring the job tracker ui of hadoop using other open source monitoring tools like Nagios,I just wish if there is a way I can write monitors to check my hadoop job tracker UI using my existing Nagios infrastructure. As this would help me in keeping everything centrally located and hence under manageable limits.,Resolved,Invalid,,Unassigned,Saurabh Mishra,Thu; 7 Apr 2011 11:56:41 +0000,Sun; 26 Jun 2011 20:34:51 +0000,Sun; 26 Jun 2011 20:34:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2423
MAPREDUCE-2424,Improvement,Major,mrv2,MR-279: counters/UI/etc. for uber-AppMaster (in-cluster LocalJobRunner for MRv2),"Polish uber-AM (MAPREDUCE-2405).  Specifically:  	uber-specific counters (""command-line UI"") 	GUI indicators 	 		RM all-containers level 		multi-job app level if exists 		single-job level 	 	 	fix uber-decision (""is this a small job?""): 	 		memory criterion 		input-bytes criterion 	 	 	disable speculation 	isUber() method (somewhere) for unit tests to use 	delete (most of) old UberTask code (MAPREDUCE-1220; came in with initial MR-279 branch) 	implement non-RPC; local version of umbilical 	AM restart (default 4 tries) on another node on any task-attempt failure 	uber-specific metrics? 	rename configurables? (still ""ubertask""-based)",Closed,Fixed,,Greg Roelofs,Greg Roelofs,Fri; 8 Apr 2011 03:18:21 +0000,Tue; 15 Nov 2011 00:48:48 +0000,Fri; 15 Apr 2011 20:40:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2424
MAPREDUCE-2425,New Feature,Major,contrib/mumak,Distributed simulator for stressing JobTracker and NameNode,Hadoop need a tool for stressing JobTracker and NameNode. Mumak introduced a simulated JobTracker; whose behavior doesn't exactly like that of the real JobTracker. Even more; mumak can't simulate a large cluster with quite a lot of jobs run on it. On the other hand; Gridmix v3 need hundreds of physical nodes to replay job stories.   You can think this tool a complementation of mumak and gridmix v3. We successfully used this tool to simulate a 12000 nodes cluster through 4 real machines.  I've talk to Hong Tang and Scott Chen offline; they suggested me contributing this tool to the hadoop community.,Resolved,Won't Fix,,Unassigned,Min Zhou,Fri; 8 Apr 2011 04:00:07 +0000,Tue; 10 Mar 2015 01:58:19 +0000,Tue; 10 Mar 2015 01:58:19 +0000,,,benchmark;hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2425
MAPREDUCE-2426,Test,Trivial,contrib/fair-share,Make TestFairSchedulerSystem fail with more verbose output,"The TestFairSchedulerSystem test failed here: https: svg""));. We should make the assertion failure include the value of contents",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 8 Apr 2011 16:42:14 +0000,Tue; 15 Nov 2011 00:50:03 +0000,Fri; 8 Apr 2011 18:26:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2426
MAPREDUCE-2427,Bug,Major,jobtracker,JT should ensure history directory is a directory,If the JT history directory doesn't exist or isn't a directory retired job files are renamed to a file called 'history' and eventually start overwriting each other. The JT should ensure 'history' exists and is a directory before performing the move.,Resolved,Won't Fix,,Unassigned,E. Sammer,Fri; 8 Apr 2011 16:55:32 +0000,Mon; 9 Mar 2015 21:32:43 +0000,Mon; 9 Mar 2015 21:32:43 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2427
MAPREDUCE-2428,Bug,Blocker,,start-mapred.sh script fails if HADOOP_HOME is not set,MapReduce portion of HADOOP-6953,Closed,Fixed,,Tom White,Tom White,Fri; 8 Apr 2011 22:24:54 +0000,Thu; 2 May 2013 02:29:38 +0000,Tue; 26 Apr 2011 03:34:03 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2428
MAPREDUCE-2429,Bug,Major,tasktracker,Check jvmid during task status report,Currently TT doens't check to ensure jvmid is relevant during communication with the Child via TaskUmbilicalProtocol.,Closed,Fixed,,Siddharth Seth,Arun C Murthy,Fri; 8 Apr 2011 22:37:42 +0000,Thu; 2 May 2013 02:29:41 +0000,Thu; 25 Aug 2011 20:12:21 +0000,,0.21.0;0.22.0;0.23.0,,,MAPREDUCE-2443;MAPREDUCE-2447,https://issues.apache.org/jira/browse/MAPREDUCE-2429
MAPREDUCE-2430,Task,Major,,Remove mrunit contrib,"As per vote on general@ (http: mrunit A link to the incubator project should be added to our website ""related projects"" section.",Closed,Fixed,,Nigel Daley,Nigel Daley,Sun; 10 Apr 2011 05:54:33 +0000,Tue; 15 Nov 2011 00:49:03 +0000,Sun; 12 Jun 2011 01:04:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2430
MAPREDUCE-2431,Improvement,Major,,MR-279: re-enable Avro RPC tests,MAPREDUCE-2414 added Protobuf as an RPC serialization to the MAPREDUCE-279 branch.  In doing so; it disabled unit tests for the Avro-based RPC serialization in that branch.  This issue proposes to re-enable those tests.,Open,Unresolved,,Doug Cutting,Doug Cutting,Mon; 11 Apr 2011 22:01:51 +0000,Tue; 3 May 2011 00:13:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2431
MAPREDUCE-2432,Improvement,Major,mrv2,MR-279: Install sanitized poms for downstream sanity,"Due to MNG-4223; the installed POMs of MR-279 is downstream hostile. E.g.; it's impossible to use versions of hadoop-mapreduce-client-core.version in ivy other than 1.0-SNAPSHOT without changing the multiple POMs; rendering the version properties (hadoop-mapreduce.version and yarn.version) practically useless.  This patch will install POMs with version (only) properties expanded. This patch also use inheritance and dependencyManagement to make POMs DRYer. It could use further cleanup to reduce ""unnecessary"" dependencies in some modules; but it's a working start.  To see the patch work; apply the patch and do a mvn clean install -P-cbuild -DskipTests to make sure sane POMs are installed and then working on individual test issues.",Closed,Fixed,,Luke Lu,Luke Lu,Tue; 12 Apr 2011 19:05:46 +0000,Tue; 15 Nov 2011 00:48:10 +0000,Wed; 13 Apr 2011 19:42:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2432
MAPREDUCE-2433,Bug,Blocker,mrv2,MR-279: YARNApplicationConstants hard code app master jar version,YARNApplicationConstants hard code version string in HADOOP_MAPREDUCE_CLIENT_APP_JAR_NAME and consequently YARN_MAPREDUCE_APP_JAR_PATH  This is a blocker.,Closed,Fixed,,Mahadev konar,Luke Lu,Tue; 12 Apr 2011 23:33:31 +0000,Tue; 15 Nov 2011 00:49:11 +0000,Thu; 28 Apr 2011 21:17:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2433
MAPREDUCE-2434,New Feature,Major,mrv2,MR-279: ResourceManager metrics,Hierarchical scheduler metrics; per queue; per user (default off),Closed,Fixed,,Luke Lu,Luke Lu,Wed; 13 Apr 2011 01:18:52 +0000,Tue; 15 Nov 2011 00:49:36 +0000,Sat; 30 Apr 2011 07:25:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2434
YARN-3317,Improvement,Major,,MR-279: Modularize web framework and webapps,The patch moves the web framework out of yarn-common into a separate module: yarn-web.  It also decouple webapps into separate modules jars to allow webapp updates independent of servers. Servers use ServiceLoader to discover its webapp modules.,Open,Unresolved,,Luke Lu,Luke Lu,Wed; 13 Apr 2011 02:11:27 +0000,Mon; 9 Mar 2015 23:12:18 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-3317
MAPREDUCE-2436,Improvement,Major,contrib/raid,RAID block fixer should prioritize block fix operations,The RAID block fixer submits mapreduce jobs to fix corrupt files. This is OK for XOR RAID; but with Reed-Solomon RAID; there can be large number of corrupt files when even a single datanode goes dead. With Reed-SOlomon RAID; it is better to categorize corrupt files based on urgency. Files with only one corrupt block can be treated as lower priority than those with more number of corrupt blocks.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 13 Apr 2011 19:15:18 +0000,Tue; 1 Aug 2017 17:12:53 +0000,Tue; 1 Aug 2017 17:12:53 +0000,,0.20.2;0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2436
MAPREDUCE-2437,Bug,Blocker,test,SLive should process only part* files while generating the report.,SliveTest when producing the final report scans all files in the reduce output directory. The directory now may contain _SUCCESS and _logs entries. SliveTest should process only files starting with part*.,Closed,Fixed,,Konstantin Shvachko,Konstantin Shvachko,Wed; 13 Apr 2011 22:03:23 +0000,Mon; 12 Dec 2011 06:19:14 +0000,Thu; 14 Apr 2011 17:44:07 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2437
MAPREDUCE-2438,New Feature,Major,mrv2,MR-279: WebApp for Job History,Add webapp for job history server in MR-279 branch.,Closed,Fixed,,Krishna Ramachandran,Mahadev konar,Thu; 14 Apr 2011 23:17:48 +0000,Tue; 15 Nov 2011 00:49:11 +0000,Fri; 15 Apr 2011 00:37:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2438
MAPREDUCE-2439,Bug,Major,mrv2,MR-279: Fix YarnRemoteException to give more details.,Fix YarnRemoteException to add more details.,Closed,Fixed,,Siddharth Seth,Mahadev konar,Fri; 15 Apr 2011 00:53:08 +0000,Tue; 15 Nov 2011 00:48:31 +0000,Fri; 15 Apr 2011 01:32:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2439
MAPREDUCE-2440,Bug,Major,mrv2,MR-279: Name clashes in TypeConverter,public static TaskTrackerInfo[] fromYarn(ListNodeManagerInfo nodes) has the same erasure as public static JobStatus[] fromYarn(ListApplication applications)  Not detected by the current JDK 6 but still wrong according to the JLS 8.4.2.  See also: http: view_bug.do?bug_id=6182950  The patch renames the former signature to fromYarnNodes and the later fromYarnApps.,Closed,Fixed,,Luke Lu,Luke Lu,Fri; 15 Apr 2011 21:51:05 +0000,Tue; 15 Nov 2011 00:49:27 +0000,Mon; 18 Apr 2011 21:49:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2440
MAPREDUCE-2441,Bug,Critical,capacity-sched,regression: maximum limit of -1 + user-lmit math appears to be off,The math around the slot usage when maximum-capacity=-1 appears to be faulty.  See comments.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Fri; 15 Apr 2011 23:00:53 +0000,Wed; 2 Nov 2011 17:38:27 +0000,Wed; 2 Nov 2011 17:38:27 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2441
MAPREDUCE-2442,New Feature,Major,contrib/raid,Add a JSP page for RaidNode,nan,Resolved,Won't Fix,,Scott Chen,Scott Chen,Sun; 17 Apr 2011 20:01:20 +0000,Tue; 1 Aug 2017 17:12:53 +0000,Tue; 1 Aug 2017 17:12:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2442
MAPREDUCE-2443,Bug,Minor,test,Fix FI build - broken after MR-2429,src TaskAspect.aj:72 warning advice defined in org.apache.hadoop.mapred.TaskAspect has not been applied Xlint:adviceDidNotMatch  After the fix in MR-2429; the call to ping in TaskAspect needs to be fixed.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 19 Apr 2011 02:49:31 +0000,Fri; 2 Sep 2011 22:13:23 +0000,Tue; 19 Apr 2011 03:08:49 +0000,,0.20.204.0,,,MAPREDUCE-2429,https://issues.apache.org/jira/browse/MAPREDUCE-2443
MAPREDUCE-2444,Bug,Major,tasktracker,error connect tasktracker for jobtracker,"In TaskTracker. on create connection to JobTracker we check compare build version  if(!VersionInfo.getBuildVersion().equals(jobTrackerBV))   but  public static String getBuildVersion(){     return VersionInfo.getVersion() +     "" from "" + VersionInfo.getRevision() +     "" by "" + VersionInfo.getUser() +     "" source checksum "" + VersionInfo.getSrcChecksum(); }  in result identical version srcChecksum but compiled different users incompatible",Resolved,Duplicate,NULL,Unassigned,Alexey Diomin,Thu; 21 Apr 2011 09:26:43 +0000,Thu; 17 Jul 2014 15:29:19 +0000,Thu; 17 Jul 2014 15:29:19 +0000,,0.20.1,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2444
MAPREDUCE-2445,Bug,Major,security;test,TestMiniMRWithDFSWithDistinctUsers is very broken,"This test has a number of issues:  	it side steps the normal job submission API for no apparent reason; manually writing splits file and uploading submission files. (but forgets to upload the job jar; so the jobs all fail) 	it doesn't call waitForCompletion; or check job status (so it doesn't notice that the jobs all fail) 	it doesn't verify in any way that the job output is owned by the user who supposedly ran the job 	it shuts down DFS before MR    These all conspire to make it pass; but it isn't actually testing anything.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 22 Apr 2011 02:35:00 +0000,Mon; 12 Dec 2011 06:20:07 +0000,Thu; 28 Apr 2011 01:50:44 +0000,,0.22.0,,MAPREDUCE-2327,,https://issues.apache.org/jira/browse/MAPREDUCE-2445
MAPREDUCE-2446,Improvement,Major,contrib/streaming;pipes;task,HCE 2.0,Enhancing MapReduce by Task-level Optimization. Except for yielding speedups of up to 130% on original Streaming Program; Hce 2.0 provides some more flexible programming interfaces including c++;   python; etc.,Resolved,Duplicate,MAPREDUCE-2841,Unassigned,Dong Yang,Fri; 22 Apr 2011 13:30:40 +0000,Fri; 6 Nov 2015 01:47:46 +0000,Fri; 6 Nov 2015 01:47:46 +0000,,,,,MAPREDUCE-1270,https://issues.apache.org/jira/browse/MAPREDUCE-2446
MAPREDUCE-2447,Bug,Minor,,Set JvmContext sooner for a task - MR2429,TaskTracker.validateJVM() is throwing NPE when setupWorkDir() throws IOException. This is because taskFinal.setJvmContext() is not executed yet,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 22 Apr 2011 18:27:59 +0000,Fri; 2 Sep 2011 22:13:21 +0000,Thu; 21 Jul 2011 21:06:43 +0000,,0.20.204.0,,,MAPREDUCE-2429,https://issues.apache.org/jira/browse/MAPREDUCE-2447
MAPREDUCE-2448,Bug,Minor,contrib/raid;test,NoSuchMethodError: org.apache.hadoop.hdfs.TestDatanodeBlockScanner.corruptReplica(..),nan,Resolved,Fixed,,Eli Collins,Tsz Wo Nicholas Sze,Fri; 22 Apr 2011 20:40:38 +0000,Wed; 4 May 2011 14:57:33 +0000,Mon; 25 Apr 2011 16:58:32 +0000,,,,,HDFS-1562,https://issues.apache.org/jira/browse/MAPREDUCE-2448
MAPREDUCE-2449,Improvement,Minor,contrib/eclipse-plugin,"Allow for command line arguments when performing ""Run on Hadoop"" action.","It is currently not possible to specify command line arguments when creating a run configuration for ""Run on Hadoop."" This patch adds a text box to the RunOnHadoopWizard dialog for providing command line arguments. The arguments are then stored as part of the run configuration. Additionally (as a result); this patch prevents the creation of duplicate run configuration creation by seeing if the original configuration has been changed first.",Closed,Fixed,,Jeff Zemerick,Jeff Zemerick,Sat; 23 Apr 2011 14:42:34 +0000,Tue; 15 Nov 2011 00:49:18 +0000,Thu; 19 May 2011 06:31:35 +0000,,0.20.2,features;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-2449
MAPREDUCE-2450,Bug,Major,,Calls from running tasks to TaskTracker methods sometimes fail and incur a 60s timeout,I'm seeing some map tasks in my jobs take 1 minute to commit after they finish the map computation. On the map side; the output looks like this:  code 2009-03-02 21:30:54;384 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=MAP; sessionId= - already initialized 2009-03-02 21:30:54;437 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 800 2009-03-02 21:30:54;437 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 300 2009-03-02 21:30:55;493 INFO org.apache.hadoop.mapred.MapTask: data buffer = 239075328 code  Note that the task actually seemed to commit - it didn't get speculatively executed or anything. However; the job wasn't able to continue until this one task was done. Both parties seem to think the channel was closed. How does the channel get closed externally? If closing it from outside is unavoidable; maybe the right thing to do is to set a much lower timeout; because 1 minute delay can be pretty significant for a small job.,Closed,Fixed,,Rajesh Balamohan,Matei Zaharia,Tue; 3 Mar 2009 05:56:48 +0000,Tue; 10 Mar 2015 04:32:32 +0000,Tue; 17 Jan 2012 06:13:30 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2450
MAPREDUCE-2451,Bug,Trivial,jobtracker,Log the reason string of healthcheck script,The information on why a specific TaskTracker got blacklisted is not stored anywhere. The jobtracker web ui will show the detailed reason string until the TT gets unblacklisted.  After that it is lost.,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 25 Apr 2011 17:35:26 +0000,Fri; 2 Sep 2011 22:13:24 +0000,Tue; 10 May 2011 05:28:16 +0000,,0.20.204.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2451
MAPREDUCE-2452,Bug,Major,jobtracker,Delegation token cancellation shouldn't hold global JobTracker lock,Currently; when the JobTracker cancels a job's delegation token (at the end of the job); it holds the global lock. This is not desired.,Closed,Fixed,,Devaraj Das,Devaraj Das,Mon; 25 Apr 2011 18:44:43 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Fri; 3 Jun 2011 22:21:04 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2452
MAPREDUCE-2453,Bug,Minor,,DBinputFormat throws OutOfMemory exceptions when importing large tables from PostgreSQL.,"DBinputFormat throws OutOfMemory exceptions and Java heap space errors when importing large tables from PostgreSQL. This is because loading the whole resultset into memory at the same time. As a consequence; the Java heap space is exhausted. Also; this problem happens with DataDrivenDBInputFormat.  I suggest utilizing ""Fetch Size"" parameter of JDBC within DBInputFormat.  I made patches as follows:  modifying org.apache.hadoop.mapreduce.lib.db.DBInputFormat.   creating org.apache.hadoop.mapreduce.PostgreSQLDBRecordReader.    adding JDBC options of fetch size; which are setFetchSize() and setAutoCommit().  I also modified DataDrivenDBinputFormat in the same way as DBInputFormat.",Open,Unresolved,,Unassigned,Tomoya Tainaka,Tue; 26 Apr 2011 01:59:14 +0000,Tue; 26 Apr 2011 02:12:18 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2453
MAPREDUCE-2454,New Feature,Minor,,Allow external sorter plugin for MR,Define interfaces and some abstract classes in the Hadoop framework to facilitate external sorter plugins both on the Map and Reduce sides.,Closed,Fixed,,Mariappan Asokan,Mariappan Asokan,Tue; 26 Apr 2011 18:46:24 +0000,Thu; 12 May 2016 18:22:26 +0000,Sat; 15 Dec 2012 20:49:20 +0000,,2.0.0-alpha;2.0.2-alpha;3.0.0-alpha1,features;performance;plugin;sort,,MAPREDUCE-4049;MAPREDUCE-4039;MAPREDUCE-4891;MAPREDUCE-4482,https://issues.apache.org/jira/browse/MAPREDUCE-2454
MAPREDUCE-2455,Sub-task,Major,build;client,Remove deprecated JobTracker.State in favour of JobTrackerStatus,MAPREDUCE-2337 deprecated getJobTrackerState() on ClusterStatus; this issue is to remove the getter (in favour of getJobTrackerStatus(); which will remain) so there is no longer a direct dependency of the public API on JobTracker. This is for MAPREDUCE-1638.,Closed,Fixed,,Tom White,Tom White,Tue; 26 Apr 2011 21:38:01 +0000,Tue; 15 Nov 2011 00:49:30 +0000,Tue; 31 May 2011 16:06:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2455
MAPREDUCE-2456,Improvement,Trivial,jobtracker,"Show the reducer taskid and map/reduce tasktrackers for ""Failed fetch notification #_ for task attempt..."" log messages","This jira is to provide more useful log information for debugging the ""Too many fetch-failures"" error.  Looking at the JobTracker node; we see messages like this: ""2010-12-14 00:00:06;911 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #8 for task attempt_201011300729_189729_m_007458_0"".  I would be useful to see which reducer is reporting the error here.  So; I propose we add the following to these log messages:   1. reduce task ID   2. TaskTracker nodenames for both the mapper and the reducer",Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Wed; 27 Apr 2011 21:29:28 +0000,Fri; 2 Sep 2011 22:13:22 +0000,Tue; 10 May 2011 20:19:15 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2456
MAPREDUCE-2457,Bug,Critical,jobtracker,job submission should inject group.name (on the JT side),Until Hadoop 0.20; the JobClient was injecting the property 'group.name' on the JobConf submitted to the JobTracker.  Since Hadoop 0.21; due to security related changes; this is not done anymore.  This breaks backwards compatibility for jobs components that expect the 'group.name' to be automatically set at submission time.  An example of a component being affected by this change is the FairScheduler where it is common to use the group.name as pool name. Different from other properties; a special characteristic of the group.name is that its value cannot be tampered by a user.  For security reasons this should not be done (as it was done before) in the JobClient side. Instead; it should be done in the JobTracker when the JobConf is received.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 28 Apr 2011 05:13:05 +0000,Mon; 12 Dec 2011 06:19:41 +0000,Mon; 2 May 2011 23:19:53 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2457
MAPREDUCE-2458,Bug,Major,mrv2,MR-279: Rename sanitized pom.xml in build directory to work around IDE bug,The sanitized pom.xml in target directory apparently triggered a bug in NetBeans (http: show_bug.cgi?id=198162) causing it to fail to recognize the generated sources. The work-around is to rename the generated pom.xml to saner-pom.xml,Closed,Fixed,,Luke Lu,Luke Lu,Thu; 28 Apr 2011 17:51:34 +0000,Tue; 15 Nov 2011 00:50:00 +0000,Fri; 29 Apr 2011 00:15:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2458
MAPREDUCE-2459,Improvement,Major,harchive,Cache HAR filesystem metadata,Each HAR file system has two index files that contains information on how files are stored in the part files. During the block location calculation; these indexes are reread for every file in the archive. Caching the indexes and the status of the part files will greatly reduce the number of name node operations during the job setup time.,Closed,Fixed,MAPREDUCE-865,Mac Yang,Mac Yang,Fri; 29 Apr 2011 01:15:26 +0000,Mon; 22 Jul 2013 14:57:22 +0000,Fri; 20 May 2011 15:20:35 +0000,,,,,HADOOP-9757,https://issues.apache.org/jira/browse/MAPREDUCE-2459
MAPREDUCE-2460,Bug,Blocker,,TestFairSchedulerSystem failing on Hudson,Seems to have been failing for a while. For example: https: ,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 29 Apr 2011 02:11:18 +0000,Tue; 15 Nov 2011 00:49:15 +0000,Mon; 2 May 2011 23:06:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2460
MAPREDUCE-2461,Bug,Major,,Hudson jobs failing because mapred staging directory is full,All of the tests that submit MR jobs are failing on the h7 build machine. This is because the staging directory is entirely full:  hudson@h7:  | wc -l 31999  This makes me think that there's some bug where we're leaking things in the staging directory. I will manually clean this for now; but we should investigate.,Resolved,Fixed,,Unassigned,Todd Lipcon,Fri; 29 Apr 2011 02:48:19 +0000,Mon; 9 Mar 2015 20:35:26 +0000,Mon; 9 Mar 2015 20:35:19 +0000,,0.23.0;1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2461
MAPREDUCE-2462,Improvement,Minor,mrv2,MR 279: Write job conf along with JobHistory; other minor improvements,Write the job xml along with the job history file. Split some common functionality into a helper class; etc.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sat; 30 Apr 2011 03:53:14 +0000,Tue; 15 Nov 2011 00:49:44 +0000,Mon; 2 May 2011 06:06:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2462
MAPREDUCE-2463,Bug,Major,jobtracker,Job History files are not moving to done folder when job history location is hdfs location,"If ""mapreduce.jobtracker.jobhistory.location"" is configured as HDFS location then either during initialization of Job Tracker (while moving old job history files) or after completion of the job; history files are not moving to done and giving following exception.",Closed,Fixed,MAPREDUCE-1986,Devaraj K,Devaraj K,Mon; 2 May 2011 06:35:07 +0000,Tue; 15 Nov 2011 00:49:24 +0000,Thu; 28 Jul 2011 04:14:32 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2463
MAPREDUCE-2464,Bug,Major,jobtracker,NullPointerException is coming in the job tracker when job tracker resends the previous heartbeat response.,Over the network; the heartbeat response sent by Job Tracker to Task Tracker might get lost. When Task Tracker sends the old heart beat again to Job Tracker then Job Tracker finds and ignores it saying duplicate and resends the old heartbeat response which it is maintaining in a map. If the response contains LaunchTaskAction for MapTask; then the NullPointerException is throwing.,Resolved,Duplicate,MAPREDUCE-2237,Devaraj K,Devaraj K,Mon; 2 May 2011 14:21:59 +0000,Mon; 2 May 2011 19:13:44 +0000,Mon; 2 May 2011 19:13:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2464
MAPREDUCE-2465,Bug,Blocker,contrib/raid,HDFS raid not compiling after federation merge,The RAID contrib is no longer compiling now that federation has been merged; due to some API changes in LocatedBlock and FSDataset.,Resolved,Not A Problem,,Ramkumar Vadali,Todd Lipcon,Mon; 2 May 2011 20:59:02 +0000,Thu; 12 May 2011 03:31:48 +0000,Thu; 12 May 2011 03:31:17 +0000,,0.23.0,,,MAPREDUCE-2467,https://issues.apache.org/jira/browse/MAPREDUCE-2465
MAPREDUCE-2466,Bug,Blocker,,TestFileInputFormat.testLocality failing after federation merge,This test is failing; I believe due to federation merge. It's only finding one location for the test file instead of the expected two.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 2 May 2011 23:47:27 +0000,Tue; 15 Nov 2011 00:49:15 +0000,Tue; 3 May 2011 00:34:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2466
MAPREDUCE-2467,Bug,Major,contrib/raid,HDFS-1052 changes break the raid contrib module in MapReduce,Raid contrib module requires changes to work with the federation changes made in HDFS-1052.,Closed,Fixed,,Suresh Srinivas,Suresh Srinivas,Tue; 3 May 2011 00:27:07 +0000,Tue; 15 Nov 2011 00:48:53 +0000,Wed; 11 May 2011 17:35:59 +0000,,0.23.0,,HDFS-1052;HDFS-1888,MAPREDUCE-2465,https://issues.apache.org/jira/browse/MAPREDUCE-2467
MAPREDUCE-2468,New Feature,Major,mrv2,MR-279: Metrics for shuffle,Metrics for MR shuffle service.,Resolved,Fixed,,Luke Lu,Luke Lu,Tue; 3 May 2011 01:58:52 +0000,Tue; 3 May 2011 22:53:09 +0000,Tue; 3 May 2011 22:53:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2468
MAPREDUCE-2469,Improvement,Major,task,Task counters should also report the total heap usage of the task,Currently; the task counters report VSS and RSS usage of the task. The task counter should also report the total heap usage of the task also. The task might be configured with a max heap size of M but the task's total heap usage might only be H; where H  M. In such a case; knowing only M doesn't provide a complete picture of the task's memory usage.,Closed,Fixed,,Amar Kamat,Amar Kamat,Tue; 3 May 2011 04:35:37 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Thu; 2 Jun 2011 03:16:23 +0000,,0.23.0,mapreduce,MAPREDUCE-2107,MAPREDUCE-2777,https://issues.apache.org/jira/browse/MAPREDUCE-2469
MAPREDUCE-2470,Bug,Major,client,Receiving NPE occasionally on RunningJob.getCounters() call,This is running in a Java daemon that is used as an interface (Thrift) to get information and data from MR Jobs. Using JobClient.getJob(JobID) I successfully get a RunningJob object (I'm checking for NULL); and then rarely I get an NPE when I do RunningJob.getCounters(). This seems to occur after the daemon has been up and running for a while; and in the event of an Exception; I close the JobClient; set it to NULL; and a new one should then be created on the next request for data. Yet; I still seem to be unable to fetch the Counters. Below is the stack trace.    619),Closed,Fixed,,Robert Joseph Evans,Aaron Baff,Tue; 3 May 2011 22:08:34 +0000,Tue; 15 Nov 2011 00:48:42 +0000,Wed; 25 May 2011 09:09:41 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2470
MAPREDUCE-2471,New Feature,Major,,MapReduce Math Library,This is an umbrella JIRA for a MapReduce math library.  The core algorithms are MapReduce-Sum; MapReduce-FFT; MapReduce-Multiplication; etc.,Open,Unresolved,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 4 May 2011 01:28:46 +0000,Tue; 21 Jun 2011 21:10:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2471
MAPREDUCE-2472,Bug,Major,task-controller,Extra whitespace in mapred.child.java.opts breaks JVM initialization,"When creating taskjvm.sh; we split mapred.child. opts on "" "" and then create a quoted argument for each of those results. So; if you have an extra space anywhere in this configuration; you get an argument '' in the child command line; which the JVM interprets as an empty class name. This results in a ClassNotFoundException and the task cannot run.",Closed,Fixed,,Aaron T. Myers,Todd Lipcon,Wed; 4 May 2011 06:29:00 +0000,Mon; 12 Dec 2011 06:19:05 +0000,Wed; 4 May 2011 20:24:00 +0000,,0.20.2;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2472
MAPREDUCE-2473,New Feature,Major,jobtracker,MR portion of HADOOP-7214 - Hadoop /usr/bin/groups equivalent,nan,Closed,Fixed,,Aaron T. Myers,Aaron T. Myers,Wed; 4 May 2011 08:00:55 +0000,Thu; 2 May 2013 02:29:38 +0000,Fri; 13 May 2011 00:01:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2473
MAPREDUCE-2474,Improvement,Minor,documentation,Add docs to the new API Partitioner on how to access Job Configuration data,The new Partitioner interface does not extend Configurable classes as the old one and thus need to carry a tip on how to implement a custom partitioner that needs to feed off the Job Configuration data to work.  Attaching a patch that adds in the  oc fix.,Closed,Fixed,,Harsh J,Harsh J,Thu; 5 May 2011 09:14:41 +0000,Tue; 15 Nov 2011 00:48:17 +0000,Thu; 5 May 2011 15:40:37 +0000,,0.21.0,documentation;partitioners,,,https://issues.apache.org/jira/browse/MAPREDUCE-2474
MAPREDUCE-2475,Bug,Major,test,Disable IPV6 for junit tests,"IPV6 addresses not handles currently in the common library methods. IPV6 can return address as ""0:0:0:0:0:0:port"". Some utility methods such as NetUtils#createSocketAddress(); NetUtils#normalizeHostName(); NetUtils#getHostNameOfIp() to name a few; do not handle IPV6 address and expect address to be of format host:port.  Until IPV6 is formally supported; I propose disabling IPV6 for junit tests to avoid problems seen in HDFS-1891.",Closed,Fixed,,Suresh Srinivas,Suresh Srinivas,Thu; 5 May 2011 22:17:29 +0000,Tue; 15 Nov 2011 00:50:00 +0000,Fri; 6 May 2011 02:47:16 +0000,,0.23.0,,,HADOOP-7261;HDFS-1891,https://issues.apache.org/jira/browse/MAPREDUCE-2475
MAPREDUCE-2476,New Feature,Major,build,Set mapreduce scheduler to capacity scheduler for RPM/Debian packages by default,Hadoop RPM Debian package is default to use the default scheduler.  It would be nice to setup the packages to use capacity scheduler instead.,Resolved,Won't Fix,,Eric Yang,Eric Yang,Thu; 5 May 2011 22:18:25 +0000,Thu; 2 May 2013 02:29:39 +0000,Thu; 5 May 2011 23:12:12 +0000,,0.20.203.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2476
MAPREDUCE-2477,Bug,Major,,MR client uses fs.default.name as provided from the JobTracker instead of local value,Initially opened against Pig; but this seems to be a MR bug.   When submitting a MapReduce job; the client uses the fs.default.name supplied to it by the JobTracker (via core-site.xml on the master typically) during the staging phase. After that; the client then uses the fs.default.name from it's local configs. This seems like a bug to me. Expected behavior would be to always use the local value.  I found this bug when the server configs were set to not use a FQDN for fs.default.name. This caused the client to fail because it didn't have the same default DNS domain.,Open,Unresolved,,Unassigned,Bill Graham,Wed; 4 May 2011 04:09:25 +0000,Thu; 5 May 2011 22:59:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2477
MAPREDUCE-2478,Improvement,Major,mrv2,MR 279: Improve history server,Index based jobId search in the history server. Faster jobList loading.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sun; 8 May 2011 22:17:27 +0000,Tue; 15 Nov 2011 00:48:45 +0000,Tue; 10 May 2011 09:48:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2478
MAPREDUCE-2479,Improvement,Major,tasktracker,Backport MAPREDUCE-1568 to hadoop security branch,nan,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 9 May 2011 16:32:30 +0000,Fri; 2 Sep 2011 22:13:21 +0000,Mon; 16 May 2011 22:53:26 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2479
MAPREDUCE-2480,Bug,Major,mrv2,MR-279: mr app should not depend on hard-coded version of shuffle,The following commit introduced a dependency of shuffle with hard-coded version for mr app:,Closed,Fixed,,Luke Lu,Luke Lu,Mon; 9 May 2011 22:53:19 +0000,Tue; 15 Nov 2011 00:48:51 +0000,Tue; 10 May 2011 18:38:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2480
MAPREDUCE-2481,Bug,Major,task,SocketTimeoutException is coming in the reduce task when the data size is very high,SocketTimeoutException is coming when reduce task tries to read MapTaskCompletionEventsUpdate object from task tracker; it is able to read reset; TaskCompletionEvent.taskId; TaskCompletionEvent.idWithinJob properties and it is failing for reading the property isMap in TaskCompletionEvent which is of type boolean. This exception is coming multiple times.      org.mortbay.jetty.EofException is also coming many times in the logs as described in MAPREDUCE-5.,Open,Unresolved,,Unassigned,Devaraj K,Tue; 10 May 2011 13:47:06 +0000,Wed; 28 Mar 2012 11:14:34 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2481
MAPREDUCE-2482,Bug,Major,contrib/raid,Enable RAID contrib in trunk,The RAID contrib project can be re-enabled since federation related changes are now in.,Resolved,Duplicate,MAPREDUCE-2467,Ramkumar Vadali,Ramkumar Vadali,Tue; 10 May 2011 19:50:30 +0000,Tue; 10 May 2011 19:58:32 +0000,Tue; 10 May 2011 19:58:32 +0000,,0.20.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2482
MAPREDUCE-2483,Bug,Major,build,Clean up duplication of dependent jar files,For trunk; the build and deployment tree look like this:  hadoop-common-0.2x.y hadoop-hdfs-0.2x.y hadoop-mapred-0.2x.y  Technically; mapred's the third party dependent jar files should be fetch from hadoop-common and hadoop-hdfs.  However; it is currently fetching from hadoop-mapred lib only.  It would be nice to eliminate the need to repeat duplicated jar files at build time.  There are two options to manage this dependency list; continue to enhance ant build structure to fetch and filter jar file dependencies using ivy.  On the other hand; it would be a good opportunity to convert the build structure to maven; and use maven to manage the provided jar files.,Closed,Fixed,,Eric Yang,Eric Yang,Wed; 11 May 2011 18:15:17 +0000,Tue; 15 Nov 2011 00:49:24 +0000,Thu; 19 May 2011 17:51:40 +0000,,0.23.0,,HADOOP-6255,HADOOP-7289,https://issues.apache.org/jira/browse/MAPREDUCE-2483
MAPREDUCE-2484,Bug,Trivial,capacity-sched,divideAndCeil should not use LOG.info or have a more meaningful message,divideAndCeil has      which should either be a debug message or something more meaningful if it really needs to be LOG.info.,Resolved,Not A Problem,,Stefan H  bner,Allen Wittenauer,Wed; 11 May 2011 21:32:18 +0000,Tue; 27 Dec 2011 09:06:46 +0000,Tue; 27 Dec 2011 09:06:45 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2484
MAPREDUCE-2485,Improvement,Major,pipes,reinitialize CLASSPATH variable when executing Mapper/Reducer code,We're using pipes; and using libhdfs inside our mapper and reducer code.  We've determined that we need to execute a putenv call in order for libhdfs to actually have access to the CLASSPATH.  Ideally; it should just use the CLASSPATH we set when the job was executed.  For some more context; see these threads: https: 25830,Resolved,Invalid,,Unassigned,Tom Melendez,Wed; 11 May 2011 22:03:29 +0000,Mon; 23 May 2011 23:18:08 +0000,Mon; 23 May 2011 23:18:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2485
MAPREDUCE-2486,Bug,Blocker,,0.22 - snapshot incorrect dependency published in .pom files,"The pom at https:  publishes a dependency on hadoop-common version ""0.22.0-dev-SNAPSHOT"" while hadoop-common only publishes ""0.22.0-SNAPSHOT"" (no -dev).",Closed,Fixed,,Todd Lipcon,Dmitriy V. Ryaboy,Wed; 11 May 2011 22:59:20 +0000,Mon; 12 Dec 2011 06:18:35 +0000,Wed; 11 May 2011 23:33:31 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2486
MAPREDUCE-2487,Bug,Minor,,ChainReducer uses MAPPER_BY_VALUE instead of REDUCER_BY_VALUE,On line 293 of o.a.h.mapred.lib.Chain in setReducer(...):  reducerConf.setBoolean(MAPPER_BY_VALUE; byValue);  this should be REDUCER_BY_VALUE.  http: Chain. 293,Resolved,Fixed,,Devaraj K,Forrest Vines,Wed; 11 May 2011 23:18:10 +0000,Wed; 29 Jun 2011 14:42:49 +0000,Mon; 6 Jun 2011 18:33:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2487
MAPREDUCE-2488,Bug,Major,jobtracker,getLocalityLevel returns incorrect result,"This line int level = this.maxLevel; initializes variable ""level"" to ""this.maxLevel"". If the real locality level is larger than maxLevel; the method ""getLocalityLevel"" always returns ""this.maxLevel""; which is incorrect. To make it work; I change it  int level = Integer.MAX_VALUE;",Open,Unresolved,,Unassigned,Zhenhua (Gerald) Guo,Thu; 12 May 2011 06:18:24 +0000,Thu; 12 May 2011 06:19:13 +0000,,,0.21.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2488
MAPREDUCE-2489,Bug,Major,jobtracker,Jobsplits with random hostnames can make the queue unusable,We saw an issue where a custom InputSplit was returning invalid hostnames for the splits that were then causing the JobTracker to attempt to excessively resolve host names.  This caused a major slowdown for the JobTracker.  We should prevent invalid InputSplit hostnames from affecting everyone else.  I propose we implement some verification for the hostnames to try to ensure that we only do DNS lookups on valid hostnames (and fail otherwise).  We could also fail the job after a certain number of failures in the resolve.,Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Thu; 12 May 2011 19:31:58 +0000,Thu; 2 May 2013 02:29:39 +0000,Thu; 11 Aug 2011 20:42:57 +0000,,0.20.205.0;0.23.0,,HADOOP-7499,,https://issues.apache.org/jira/browse/MAPREDUCE-2489
MAPREDUCE-2490,Improvement,Trivial,jobtracker,Log blacklist debug count,Gain some insight into blacklist increments decrements by enhancing the debug logging,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 12 May 2011 20:34:51 +0000,Fri; 2 Sep 2011 22:13:21 +0000,Fri; 20 May 2011 22:55:04 +0000,,0.20.204.0;0.22.0,,,MAPREDUCE-1966,https://issues.apache.org/jira/browse/MAPREDUCE-2490
MAPREDUCE-2491,Improvement,Major,,LocalJobRunner should support JobHistory logging,While testing new features; developers often rely on LocalJobRunner for quickly checking the feature behavior. It would be useful if LocalJobRunner logs the job's runtime information using JobHistory.,Open,Unresolved,,Unassigned,Amar Kamat,Fri; 13 May 2011 04:02:40 +0000,Fri; 13 May 2011 04:02:40 +0000,,,0.23.0,localjobrunner,,,https://issues.apache.org/jira/browse/MAPREDUCE-2491
MAPREDUCE-2492,Improvement,Major,task,[MAPREDUCE] The new MapReduce API should make available task's progress to the task,There is no way to get the task's current progress in the new MapReduce API. It would be nice to make it available so that the task (map reduce) can use it.,Closed,Fixed,,Amar Kamat,Amar Kamat,Fri; 13 May 2011 05:53:09 +0000,Tue; 15 Nov 2011 00:49:27 +0000,Mon; 23 May 2011 17:13:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2492
MAPREDUCE-2493,Bug,Major,mrv2,New Api FileOutputFormat does not honour user specified OutputCommitter,o.a.h.mapreduce.lib.output.FileOutputFormat always uses the default FileOutputCommitter. It ignores the user specified OutputCommitter.,Open,Unresolved,,Bhallamudi Venkata Siva Kamesh,Sharad Agarwal,Fri; 13 May 2011 06:36:54 +0000,Tue; 10 Mar 2015 04:31:54 +0000,,,0.23.0;2.0.0-alpha,,,MAPREDUCE-3130,https://issues.apache.org/jira/browse/MAPREDUCE-2493
MAPREDUCE-2494,Improvement,Major,distributed-cache,Make the distributed cache delete entires using LRU priority,Currently the distributed cache will wait until a cache directory is above a preconfigured threshold.  At which point it will delete all entries that are not currently being used.  It seems like we would get far fewer cache misses if we kept some of them around; even when they are not being used.  We should add in a configurable percentage for a goal of how much of the cache should remain clear when not in use; and select objects to delete based off of how recently they were used; and possibly also how large they are how difficult is it to download them again.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 13 May 2011 15:51:19 +0000,Wed; 21 Nov 2012 11:07:26 +0000,Mon; 1 Aug 2011 21:41:47 +0000,,0.20.205.0;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2494
MAPREDUCE-2495,Improvement,Minor,distributed-cache,The distributed cache cleanup thread has no monitoring to check to see if it has died for some reason,The cleanup thread in the distributed cache handles IOExceptions and the like correctly; but just to be a bit more defensive it would be good to monitor the thread; and check that it is still alive regularly; so that the distributed cache does not fill up the entire disk on the node.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 13 May 2011 15:54:25 +0000,Fri; 2 Sep 2011 22:13:20 +0000,Wed; 25 May 2011 02:23:26 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2495
MAPREDUCE-2496,Improvement,Major,build,ivy: test conf should not extend common conf,Similar improvement as HADOOP-7289.,Resolved,Duplicate,MAPREDUCE-2483,Eric Yang,Tsz Wo Nicholas Sze,Sat; 14 May 2011 01:39:30 +0000,Tue; 17 May 2011 22:15:49 +0000,Tue; 17 May 2011 22:15:49 +0000,,,,,HADOOP-7289,https://issues.apache.org/jira/browse/MAPREDUCE-2496
MAPREDUCE-2497,Bug,Trivial,,missing spaces in error messages,"Error message(s) are missing spaces.  Here's an example output:     WARN mapred.JobClient: Error reading task outputhttp: JobClient.       LOG.warn(""Error reading task output"" + ioe.getMessage());   The 1st arg to LOG.warn should end with a ' '.  There may be other instances of this problem in the source base.",Closed,Fixed,,Eli Collins,Robert Henry,Sun; 15 May 2011 17:07:01 +0000,Tue; 15 Nov 2011 00:49:06 +0000,Tue; 17 May 2011 21:26:02 +0000,,0.20.2,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2497
MAPREDUCE-2498,Bug,Major,contrib/raid,TestRaidShellFsck failing on trunk,TestRaidShellFsck.testFileBlockAndParityBlockMissingHar2 has been failing the last several builds:  Error Message: parity file not HARed after 40s   666),Resolved,Won't Fix,,Ramkumar Vadali,Todd Lipcon,Mon; 16 May 2011 17:18:42 +0000,Mon; 9 Mar 2015 20:32:20 +0000,Mon; 9 Mar 2015 20:32:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2498
MAPREDUCE-2499,Task,Major,,MR part of HADOOP-7291,The hudson-test-patch target needs to be updated to not pass python.home since this argument is no longer needed.,Closed,Fixed,,Eli Collins,Eli Collins,Mon; 16 May 2011 21:51:40 +0000,Tue; 17 May 2011 15:40:05 +0000,Mon; 16 May 2011 22:42:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2499
MAPREDUCE-2500,Bug,Major,mrv2,MR 279: PB factories are not thread safe,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Mon; 16 May 2011 23:46:12 +0000,Tue; 15 Nov 2011 00:49:06 +0000,Wed; 18 May 2011 00:07:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2500
MAPREDUCE-2501,Improvement,Major,mrv2,MR-279: Attach sources in builds,Attach sources to builds for various reasons; one of which is better debuggability on clusters.,Closed,Fixed,,Luke Lu,Luke Lu,Tue; 17 May 2011 02:02:51 +0000,Tue; 15 Nov 2011 00:49:06 +0000,Tue; 5 Jul 2011 23:56:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2501
MAPREDUCE-2502,Improvement,Trivial,job submission,JobSubmitter should use mapreduce.job.maps,JobSubmitter should use mapreduce.job.maps instead of the deprecated mapred.map.tasks.,Resolved,Fixed,,Eli Collins,Eli Collins,Tue; 17 May 2011 02:53:57 +0000,Wed; 18 May 2011 15:43:19 +0000,Wed; 18 May 2011 04:34:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2502
MAPREDUCE-2503,Bug,Minor,tasktracker,Job submission fails if mapreduce.cluster.local.dir is given URIs,Job submission (specifically TaskTracker#localizeJobJarFile) fails if mapreduce.cluster.local.dir has a URI with a scheme (eg file: mr1) vs just the path component. MR configuration parameters should accept full URIs to be consistent with common and HDFS.,Open,Unresolved,,Ke Zhu,Eli Collins,Tue; 17 May 2011 04:26:39 +0000,Mon; 29 Sep 2014 08:25:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2503
MAPREDUCE-2504,Bug,Major,mrv2,MR 279: race in JobHistoryEventHandler stop ,The condition to stop the eventHandling thread currently requires it to be 'stopped' AND interrupted. If an interrupt arrives after a take; but before handleEvent is called - the interrupt status ends up being handled by hadoop.util.Shell.runCommand() - which ignores it (and in the process resets the flag). The eventHandling thread subsequently hangs on eventQueue.take() This currently randomly fails unit tests - and can hang MR AMs.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 17 May 2011 16:34:12 +0000,Tue; 15 Nov 2011 00:48:17 +0000,Wed; 18 May 2011 00:16:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2504
MAPREDUCE-2505,Improvement,Minor,contrib/fair-share;documentation,Explain how to use ACLs in the fair scheduler,The fair scheduler already works with the ACL system introduced through the mapred.queue.* parameters; but the documentation doesn't explain how to use this. We should add a paragraph or two about it.,Resolved,Fixed,,Matei Zaharia,Matei Zaharia,Tue; 17 May 2011 20:18:24 +0000,Fri; 20 May 2011 03:32:29 +0000,Wed; 18 May 2011 18:52:49 +0000,,0.20.2;0.20.203.0;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2505
MAPREDUCE-2506,Improvement,Major,,Create a compatible interface for frameworks that need to clone MapReduce context objects.,In 0.21 we moved the org.apache.hadoop.mapreduce context objects to interfaces.  That made the APIs much better; but broke backwards compatibility for frameworks that need to clone them.,Open,Unresolved,,Unassigned,Owen O'Malley,Tue; 17 May 2011 20:28:14 +0000,Tue; 17 May 2011 21:28:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2506
MAPREDUCE-2507,Bug,Trivial,contrib/vaidya,vaidya script uses the wrong path for hadoop-core due to jar renaming,Another fallout of the incompatible jar renaming.  I sure hope Maven was worth it.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 17 May 2011 22:22:11 +0000,Wed; 2 Nov 2011 17:37:56 +0000,Wed; 2 Nov 2011 17:37:56 +0000,,0.20.203.0,,,MAPREDUCE-2508,https://issues.apache.org/jira/browse/MAPREDUCE-2507
MAPREDUCE-2508,Bug,Trivial,contrib/vaidya,vaidya script uses the wrong path for vaidya jar due to jar renaming,This clearly wasn't tested in 203.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Tue; 17 May 2011 22:25:43 +0000,Tue; 29 May 2012 18:50:14 +0000,Wed; 2 Nov 2011 17:37:32 +0000,,,,,MAPREDUCE-2507,https://issues.apache.org/jira/browse/MAPREDUCE-2508
MAPREDUCE-2509,Bug,Major,mrv2,MR-279: Fix NPE in UI for pending attempts,The task attempts page gets a 500 (and NPE in the AM logs) if the attempt is pending (not running yet).,Closed,Fixed,,Luke Lu,Luke Lu,Wed; 18 May 2011 01:27:51 +0000,Tue; 15 Nov 2011 00:49:29 +0000,Wed; 18 May 2011 01:40:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2509
MAPREDUCE-2510,Bug,Major,,TaskTracker throw OutOfMemoryError after upgrade to jetty6,Our product cluster's TaskTracker sometimes throw OutOfMemoryError after upgrade to jetty6. The exception in TT's log is as follows: 2011-05-17 19:16:40;756 ERROR org.mortbay.log: Error for  mapOutput   522),Resolved,Fixed,,Unassigned,Liyin Liang,Wed; 18 May 2011 02:14:41 +0000,Wed; 20 Jul 2011 13:57:10 +0000,Wed; 20 Jul 2011 13:57:10 +0000,,,,MAPREDUCE-143,,https://issues.apache.org/jira/browse/MAPREDUCE-2510
MAPREDUCE-2511,Bug,Major,,Progress reported by map tasks of a map-only job is incorrect,For a map task of a map-reduce job; the progress bar is (logically) split into 2 distinct phases 1. Map Phase 2. Sort Phase  The map phase manages 66% of the overall tasks progress while the sort phase governs the rest i.e 33%.   For a map task of a map-only job; there is no sort phase. Hence the entire map phase should govern 100% of the task's progress. Currently; the progress bar is split divided into 66%-33% irrespective of whether the job has reducers or not (i.e whether there is a sort phase or not).,Resolved,Duplicate,MAPREDUCE-2492,Amar Kamat,Amar Kamat,Wed; 18 May 2011 09:43:47 +0000,Mon; 23 May 2011 17:15:12 +0000,Mon; 23 May 2011 17:15:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2511
MAPREDUCE-2512,Improvement,Major,task,wait(5000) and notify() mechanism can be implemented instead of sleep(5000) in reduce task when there are no copies in progress and no new copies to schedule,Here if we have no copies in flight and we can't schedule anything new; it is going to wait for 5000 millis. Instead of waiting for 5000 millis; this thread can wait with timeout and GetMapEventsThread can notify it if gets new map completion events earlier than 5000 millis time.,Resolved,Won't Fix,,Unassigned,Devaraj K,Wed; 18 May 2011 15:48:34 +0000,Thu; 19 Apr 2012 05:07:09 +0000,Thu; 19 Apr 2012 05:07:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2512
MAPREDUCE-2513,Improvement,Major,,Improvements in Job Tracker UI for monitoring and managing the map reduce jobs,It will be helpful to the user running job through UI 3. User wants to change the priority of a job  4. User wants to get the scheduling information of jobs 5. User wants to delete the logs of Jobs and tasks 6. Only authorized users to be able to perform the above operations through task management UI 7. Pagination support for the jobs listing,Resolved,Not A Problem,,Devaraj K,Devaraj K,Wed; 18 May 2011 15:50:46 +0000,Sun; 29 Jan 2012 02:05:54 +0000,Sun; 29 Jan 2012 02:05:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2513
MAPREDUCE-2514,Bug,Trivial,tasktracker,ReinitTrackerAction class name misspelled RenitTrackerAction in task tracker log,nan,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 18 May 2011 21:03:21 +0000,Fri; 2 Sep 2011 22:13:19 +0000,Fri; 20 May 2011 22:50:01 +0000,,0.20.205.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2514
MAPREDUCE-2515,Bug,Major,jobtracker,MapReduce references obsolete options,Option topology.node.switch.mapping.impl has been renamed to net.topology.node.switch.mapping.impl; JT still uses old name. Likewise; JT uses old names for several other since-renamed options.,Resolved,Fixed,,Ari Rabkin,Ari Rabkin,Wed; 18 May 2011 21:45:14 +0000,Thu; 19 May 2011 15:44:55 +0000,Thu; 19 May 2011 01:55:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2515
MAPREDUCE-2516,Bug,Minor,,option to control sensitive web actions,as per HADOOP-7302; webinterface.private.actions should not be in trunk. But it should be here; and should have a clearer name.,Resolved,Fixed,,Ari Rabkin,Ari Rabkin,Wed; 18 May 2011 23:48:26 +0000,Fri; 20 May 2011 15:39:52 +0000,Fri; 20 May 2011 03:45:11 +0000,,0.22.0,,,HADOOP-7302,https://issues.apache.org/jira/browse/MAPREDUCE-2516
MAPREDUCE-2517,Task,Major,contrib/gridmix,Porting Gridmix v3 system tests into trunk branch.,Porting of girdmix v3 system tests into trunk branch.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Thu; 19 May 2011 04:59:26 +0000,Thu; 23 Aug 2012 23:05:36 +0000,Fri; 27 May 2011 10:41:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2517
MAPREDUCE-2518,Bug,Major,distcp,missing t flag in distcp help message '-p[rbugp]','t: modification and access times' flag is defined but missing in distcp help message '-prbugp'. should be changed to -prbugpt.,Closed,Fixed,,Wei Yongjun,Wei Yongjun,Thu; 19 May 2011 06:53:45 +0000,Tue; 15 Nov 2011 00:50:10 +0000,Thu; 19 May 2011 22:40:26 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2518
MAPREDUCE-2519,Bug,Major,,Progress reported by a reduce task executed via LocalJobRunner is incorrect,ReduceTask splits its progress reporting into 3 phases 1. Copy 2. Shuffule 3. Reduce  When the reduce task is run using a LocalJobRunner; the copy phase is ignored (skipped) but the progress is not updated. This results in a mismatch in the Reduce task's progress.,Resolved,Duplicate,MAPREDUCE-2492,Amar Kamat,Amar Kamat,Thu; 19 May 2011 08:26:19 +0000,Mon; 23 May 2011 17:15:37 +0000,Mon; 23 May 2011 17:15:37 +0000,,0.23.0,localjobrunner;progress;reduce,,,https://issues.apache.org/jira/browse/MAPREDUCE-2519
MAPREDUCE-2520,Bug,Minor,,InputSampler.RandomSampler only accepts Text keys,"I want to do a total sort on some data whose key type is Writable but not Text.  I wrote an InputSampler.RandomSampler object following the example in the ""Total Sort"" section of Hadoop: The Definitive Guide.  When I call InputSampler.writePartitionFile() I get a runtime class cast exception because my key type cannot be cast to Text.  Specifically the issue seems to be the following section of InputSampler.getSample():      K key = reader.getCurrentKey();     ....     Text keyCopy = WritableUtils.Textclone((Text)key; job.getConfiguration());  You can only use a RandomSampler on data with Text keys despite the fact that InputSampler takes Key; Value generic parameters.  InputSampler.getSample() should be changed to cast the key to type K instead of type Text.",Resolved,Invalid,,Unassigned,William McNeill,Thu; 19 May 2011 17:01:54 +0000,Thu; 19 May 2011 22:32:25 +0000,Thu; 19 May 2011 22:03:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2520
MAPREDUCE-2521,New Feature,Major,build,Mapreduce RPM integration project,This jira is corresponding to HADOOP-6255 and associated directory layout change. The patch for creating Mapreduce rpm packaging should be posted here for patch test build to verify against mapreduce svn trunk.,Closed,Fixed,,Eric Yang,Eric Yang,Thu; 19 May 2011 20:16:43 +0000,Tue; 15 Nov 2011 00:48:26 +0000,Fri; 27 May 2011 17:04:46 +0000,,,,HADOOP-6255,MAPREDUCE-2559,https://issues.apache.org/jira/browse/MAPREDUCE-2521
MAPREDUCE-2522,Sub-task,Major,mrv2,MR 279: Security for JobHistory service,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 19 May 2011 23:20:31 +0000,Tue; 15 Nov 2011 00:49:06 +0000,Tue; 24 May 2011 21:34:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2522
MAPREDUCE-2523,Bug,Major,test,TestTaskContext should cleanup its temporary files/folders on completion,"TestTaskContext creates ""in"" and ""out"" folders in the current working directory. Ideally these files should go under ""test.build.data"" or "" tmp"". Also the testcase should delete these files on completion.",Closed,Duplicate,MAPREDUCE-2492,Amar Kamat,Amar Kamat,Fri; 20 May 2011 04:42:12 +0000,Tue; 15 Nov 2011 00:48:54 +0000,Mon; 23 May 2011 17:14:49 +0000,,,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-2523
MAPREDUCE-2524,Improvement,Minor,tasktracker,Backport trunk heuristics for failing maps when we get fetch failures retrieving map output during shuffle,The heuristics for failing maps when we get map output fetch failures during the shuffle is pretty conservative in 20. Backport the heuristics from trunk which are more aggressive; simpler; and configurable.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 20 May 2011 14:06:18 +0000,Fri; 2 Sep 2011 22:13:22 +0000,Sat; 4 Jun 2011 01:00:05 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2524
MAPREDUCE-2525,Bug,Minor,jobtracker,State of the checkboxes are not matching with Select All / Deselect All button; after refreshing jobtracker.jsp,"These are the steps to reproduce;   	Select all the running jobs. 	Refresh the jobtracker.jsp page. 	After refreshing; Deselect All button becomes Select All; however all the selected check boxes remain in the select state only.",Resolved,Won't Fix,,Devaraj K,Devaraj K,Fri; 20 May 2011 14:15:34 +0000,Mon; 28 Sep 2015 21:10:30 +0000,Sun; 29 Jan 2012 02:04:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2525
MAPREDUCE-2526,New Feature,Major,jobtracker,Forward port MAPREDUCE-1966 Add task tracker graylisting,The current heuristic of rolling up fixed number of job failures per tracker isn't working well; we need better design heuristics.,Open,Unresolved,,Unassigned,Jonathan Eagles,Fri; 20 May 2011 20:04:12 +0000,Fri; 20 May 2011 20:05:03 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2526
MAPREDUCE-2527,New Feature,Major,mrv2,MR-279: Metrics for MRAppMaster,nan,Closed,Fixed,,Luke Lu,Luke Lu,Fri; 20 May 2011 23:58:18 +0000,Tue; 15 Nov 2011 00:48:09 +0000,Thu; 26 May 2011 02:44:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2527
HADOOP-7354,Bug,Major,,NullPointerException in the job tracker UI; when we perform kill or change the priority of jobs without selecting the any job.,If we click on Kill Selected Jobs or Change button without selecting any job; it is giving the below exception in the UI.,Closed,Duplicate,HADOOP-7440,Devaraj K,Devaraj K,Mon; 23 May 2011 05:41:33 +0000,Tue; 15 Nov 2011 00:50:23 +0000,Tue; 5 Jul 2011 22:10:34 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/HADOOP-7354
MAPREDUCE-2529,Bug,Major,tasktracker,Recognize Jetty bug 1342 and handle it,We are seeing many instances of the Jetty-1342 (http: JETTY-1342). The bug doesn't cause Jetty to stop responding altogether; some fetches go through but a lot of them throw exceptions and eventually fail. The only way we have found to get the TT out of this state is to restart the TT.  This jira is to catch this particular exception (or perhaps a configurable regex) and handle it in an automated way to either blacklist or shutdown the TT after seeing it a configurable number of them.,Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 24 May 2011 15:05:19 +0000,Fri; 2 Sep 2011 22:13:23 +0000,Sun; 5 Jun 2011 05:23:26 +0000,,0.20.204.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2529
MAPREDUCE-2530,Bug,Major,tasktracker, TaskTracker jetty stuck in a tight loop,"We are seeing some TaskTracker jetty servers stuck in a tight loop. This appears to be related to Jetty bug 937 (http: JETTY-937).   stack trace for this thread 15993(0x3e79) showing a loop in jetty.   ""21006965@qtp-11400638-0 - Acceptor0 SelectChannelConnector@0.0.0.0:50060"" prio=10 tid=0x08e6d400 nid=0x3e79 runnable 0xaddfb000     582)",Resolved,Duplicate,MAPREDUCE-2386,Thomas Graves,Thomas Graves,Tue; 24 May 2011 15:21:56 +0000,Fri; 3 Jun 2011 16:35:25 +0000,Fri; 3 Jun 2011 16:35:25 +0000,,0.20.204.0,,,MAPREDUCE-2386,https://issues.apache.org/jira/browse/MAPREDUCE-2530
MAPREDUCE-2531,Bug,Blocker,client,org.apache.hadoop.mapred.jobcontrol.getAssignedJobID throw class cast exception ,When using a combination of the mapred and mapreduce APIs (PIG) it is possible to have the following exception  Caused by:  1325)         ... 29 more  This is because the JobID is just downcast.  It should be calling JobID.downgrade,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 24 May 2011 16:07:06 +0000,Tue; 15 Nov 2011 00:49:59 +0000,Wed; 5 Oct 2011 07:42:30 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2531
MAPREDUCE-2532,New Feature,Major,mrv2,MR-279: Metrics for NodeManager,Metrics for node manager. Requires a recent (last night) update of hadoop common in the yahoo-merge branch.,Closed,Fixed,,Luke Lu,Luke Lu,Tue; 24 May 2011 16:15:08 +0000,Tue; 15 Nov 2011 00:48:43 +0000,Thu; 26 May 2011 03:00:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2532
MAPREDUCE-2533,New Feature,Major,mrv2,MR-279: Metrics for reserved resource in ResourceManager,Add metrics for reserved resources.,Closed,Fixed,,Luke Lu,Luke Lu,Tue; 24 May 2011 16:23:43 +0000,Tue; 15 Nov 2011 00:48:53 +0000,Tue; 24 May 2011 21:14:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2533
MAPREDUCE-2534,Bug,Major,mrv2,MR-279: Fix CI breaking hard coded version in jobclient pom,nan,Closed,Fixed,,Luke Lu,Luke Lu,Wed; 25 May 2011 01:02:33 +0000,Tue; 15 Nov 2011 00:49:44 +0000,Wed; 25 May 2011 01:54:50 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2534
MAPREDUCE-2535,Bug,Major,client,JobClient creates a RunningJob with null status and profile,Exception occurred because the job was retired and is removed from RetireJobCcahe and CompletedJobStatusStore. But; the JobClient creates a RunningJob with null status and profile; if getJob(JobID) is called again. So; Even-though not null check is there in the following user code; it did not help. 466             runningJob = jobClient.getJob(mapRedJobID); 467             if(runningJob != null) {  JobClient.getJob() should return null if status is null.   In trunk this is fixed by validating that the job status is not null every time it is updated; and also verifying that that the profile data is not null when created.,Resolved,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 26 May 2011 14:17:31 +0000,Mon; 6 Jun 2011 21:33:58 +0000,Mon; 6 Jun 2011 21:33:58 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2535
MAPREDUCE-2536,Test,Minor,test,TestMRCLI broke due to change in usage output,"One of the tests broke because it checks the FsShell mv usage line that is emitted after an error.  The usage was updated to from ""-mv src dst"" to ""-mv src ... dst""; so the ""..."" broke the test.",Closed,Fixed,,Daryn Sharp,Daryn Sharp,Thu; 26 May 2011 18:58:00 +0000,Tue; 15 Nov 2011 00:48:52 +0000,Thu; 26 May 2011 23:53:42 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2536
MAPREDUCE-2537,Bug,Minor,mrv2,MR-279: The RM writes its log to yarn-mapred-resourcemanager-<RM_Host>.out,nan,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 26 May 2011 20:28:40 +0000,Tue; 15 Nov 2011 00:49:01 +0000,Thu; 2 Jun 2011 23:45:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2537
MAPREDUCE-2538,Bug,Minor,,InputSampler.writePartitionFile() may write duplicate keys,"InputSampler.writePartitionFile() outputs the same key multiple times if the input samples have enough of a given key to span multiple partitions.  There is logic in the code that appears to try to avoid this; but seems incorrect:  for(int i = 1; i  numPartitions; ++i) {   int k = Math.round(stepSize * i);   while (last = k &amp; comparator.compare(sampleslast; samplesk) == 0)  {     ++k;   }   writer.append(samplesk; nullValue);   last = k; }  The while loop condition ""last = k"" is always false.  The sample comparison after the &amp; never occurs.  It's not entirely clear what the correct fix is.  The current behavior is arguably correct mathematically; though the while loop could be elided for clarity.  If bug MAPREDUCE-1987 were fixed; it would be less of a problem (for me at least); since that is where the non-uniqueness causes me problems.  Alternatively; changing the while to:  ""if( last = 0) {    while (comparator.compare(sampleslast; samplesk) = 0)) {""  or; optimized for skipping over many duplicates (but arguably less clear):  ""if (last = 0) {    while (last = k || comparator.compare(sampleslast; samplesk) = 0)) {""  would probably achieve what the original author intended.  Perhaps the behavior could be selected by a parameter; e.g. ""boolean unique"".",Open,Unresolved,,Devaraj K,Michael White,Fri; 27 May 2011 03:36:26 +0000,Mon; 9 Mar 2015 20:13:16 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2538
MAPREDUCE-2539,Bug,Major,client,NPE when calling JobClient.getMapTaskReports for retired job,When calling JobClient.getMapTaskReports for a retired job this results in a NPE.  In the 0.20.* version an empty TaskReport array was returned instead.  Caused by:  388) ......,Resolved,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 27 May 2011 18:42:17 +0000,Sat; 28 Jan 2012 14:04:18 +0000,Fri; 3 Jun 2011 11:27:54 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2539
MAPREDUCE-2540,Improvement,Major,contrib/gridmix,[Gridmix] Gridmix should faithfully emulate old and new mapred(uce) APIs,Gridmix currently submits jobs to the simulated cluster using the new MapReduce API. Since the old and new mapred(uce) APIs have different code paths; it would be useful if Gridmix faithfully emulates this behavior. Information regarding whether the original job used old or new API is captured in the job's configuration.,Open,Unresolved,,Unassigned,Amar Kamat,Sat; 28 May 2011 13:33:17 +0000,Mon; 9 Mar 2015 23:11:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2540
MAPREDUCE-2541,Bug,Critical,tasktracker,Race Condition in IndexCache(readIndexFileToCache;removeMap) causes value of totalMemoryUsed corrupt; which may cause TaskTracker continue throw Exception,The race condition goes like this: Thread1: readIndexFileToCache()  totalMemoryUsed.addAndGet(newInd.getSize()) Thread2: removeMap() totalMemoryUsed.addAndGet(-info.getSize()); When SpillRecord is being read from fileSystem; client kills the job; info.getSize() equals 0; so in fact totalMemoryUsed is not reduced; but after thread1 finished reading SpillRecord; it adds the real index size to totalMemoryUsed; which makes the value of totalMemoryUsed wrong(larger). When this value(totalMemoryUsed) exceeds totalMemoryAllowed (this usually happens when a vary large job with vary large reduce number is killed by the user; probably because the user sets a wrong reduce number by mistake); and actually indexCache has not cache anything; freeIndexInformation() will throw exception constantly.  A quick fix for this issue is to make removeMap() do nothing; let freeIndexInformation() do this job only.,Closed,Fixed,,Binglin Chang,Binglin Chang,Sat; 28 May 2011 17:34:53 +0000,Tue; 15 Nov 2011 00:48:50 +0000,Sat; 13 Aug 2011 08:20:10 +0000,,0.20.1;0.21.0;0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2541
MAPREDUCE-2542,Improvement,Major,contrib/gridmix,[Gridmix] Add support for LZO codec in Gridmix,MAPREDUCE-2408 adds compression emulation support in Gridmix. It supports the commonly used default codec (i.e Gzip). It seems that even LZO codec shows similar pattern w.r.t dictionary-word-size and compression-ratio. It would be nice to emulate LZO codec in Gridmix.,Open,Unresolved,,Unassigned,Amar Kamat,Sun; 29 May 2011 03:03:11 +0000,Mon; 9 Mar 2015 23:06:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2542
MAPREDUCE-2543,New Feature,Major,contrib/gridmix,[Gridmix] Add support for HighRam jobs,Gridmix currently ignores high ram job configuration of the original job. It would be nice if Gridmix configures the simulated job's high ram parameters such that the simulated job has same effect on the job scheduler  task-tracker as the original job.,Closed,Fixed,,Amar Kamat,Amar Kamat,Mon; 30 May 2011 06:36:54 +0000,Tue; 15 Nov 2011 00:48:21 +0000,Thu; 2 Jun 2011 13:51:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2543
MAPREDUCE-2544,Task,Major,contrib/gridmix,Gridmix compression emulation system tests.,Develop system tests for the following cases.  1. Enable a compression emulation and generated the data using gridmix and verify whether compressed input generated or not. 2. Verify a Gridmix jobs map input; map output and reduce output compression ratios against the default compression ratios. 3. Verify a Gridmix jobs map input; map output and reduce output compression ratios against user specified compression ratios. 4. Verify a Gridmix jobs map input; map output compression ratios with file output compression format is false in original trace against default compression ratios. 5. Verify a Gridmix jobs map input; map output compression ratios with file output compression format is false in original trace against user specified compression ratios. 6. Verify a Gridmix jobs reduce output with file output compression format is true in original trace against the default compression ratios. 7. Verify a Gridmix jobs reduce output with file output compression format is true in original trace against the user specified compression ratios.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Mon; 30 May 2011 08:18:57 +0000,Tue; 15 Nov 2011 00:48:30 +0000,Wed; 1 Jun 2011 13:36:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2544
MAPREDUCE-2545,Bug,Major,tools/rumen,[Rumen] Rumen incorrectly emits memory usages of map/reduce tasks,Rumen emits job and task (map reduce) memory configurations are missing.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 30 May 2011 09:21:57 +0000,Mon; 9 Mar 2015 23:05:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2545
MRUNIT-19,Bug,Minor,,MRunit ReduceDriver does not fully replicate the reducers behaviour with reusing pointers over the iterator,The MRunit ReduceDriver does not replicate the behaviour of re-using the pointer to the returned values as they are iterated over. This is a problem for testing as it does not fail when you are incorrectly storing this pointer for a value if you want to use it later on in the iteration over the values.  The behaviour should be modified so the iterator will return the same pointer every time.,Resolved,Fixed,,Brock Noland,Dan Harvey,Mon; 30 May 2011 17:13:47 +0000,Mon; 28 Nov 2011 21:30:59 +0000,Mon; 28 Nov 2011 21:30:59 +0000,,0.5.0,,,,https://issues.apache.org/jira/browse/MRUNIT-19
MAPREDUCE-2547,Bug,Blocker,test,TestDFSIO fails on a physical cluster,An attempt to run TestDSFIO on cluster fails because TestDFSIO tries to run MR job with local runner. If JT is explicitly specified via -jt cmd. arg. then everything is working as expected.,Resolved,Not A Problem,,Konstantin Boudnik,Konstantin Boudnik,Tue; 31 May 2011 01:05:21 +0000,Thu; 16 Jun 2011 23:03:10 +0000,Sun; 12 Jun 2011 06:09:24 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2547
MAPREDUCE-2548,Improvement,Major,,Log improvements in DBOutputFormat.java and CounterGroup.java,1. Instead of the printing the stack trace on the console; It can be logged.         2. Missing resource information can be logged.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Tue; 31 May 2011 05:40:28 +0000,Thu; 17 Jan 2013 13:07:10 +0000,Thu; 17 Jan 2013 13:07:10 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2548
MAPREDUCE-2549,Bug,Major,contrib/eclipse-plugin;contrib/streaming,Potential resource leaks in HadoopServer.java; RunOnHadoopWizard.java and Environment.java,nan,Closed,Fixed,,Devaraj K,Devaraj K,Tue; 31 May 2011 05:57:44 +0000,Wed; 7 Dec 2011 11:16:55 +0000,Tue; 13 Sep 2011 18:34:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2549
MAPREDUCE-2550,Bug,Blocker,build,bin/mapred no longer works from a source checkout,Developer may want to run hadoop without extracting tarball.  It would be nice if existing method to run mapred scripts from source code is preserved for developers.,Closed,Fixed,,Eric Yang,Eric Yang,Tue; 31 May 2011 17:21:31 +0000,Tue; 15 Nov 2011 00:48:07 +0000,Fri; 26 Aug 2011 18:32:01 +0000,,0.20.3,,,HDFS-2014,https://issues.apache.org/jira/browse/MAPREDUCE-2550
MAPREDUCE-2551,Improvement,Major,mrv2,MR 279: Implement JobSummaryLog,Implement JobSummary log for MR.Next,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 1 Jun 2011 01:35:12 +0000,Tue; 15 Nov 2011 00:50:08 +0000,Wed; 1 Jun 2011 15:24:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2551
MAPREDUCE-2552,Bug,Minor,mrv2,MR 279: NPE when requesting attemptids for completed jobs ,While constructing a CompletedJob instance on the JobHistory server - successfuleAttempt is not populated. Causes an NPE when listing completed attempts for a job via the CLI.  CLI: hadoop job -list-attempt-ids job_id MAP completed,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 1 Jun 2011 01:44:30 +0000,Tue; 15 Nov 2011 00:48:31 +0000,Wed; 1 Jun 2011 15:26:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2552
MAPREDUCE-2553,Improvement,Minor,distcp,missing space in the error message of distcp command,"Error message of distcp command missing space; here's an example output: $ hadoop distcp  temp ... Copy failed:   throw new IOException(""Failed to create"" + args.dst);  ""Failed to create"" should end with a ' '.",Resolved,Won't Fix,,Unassigned,Wei Yongjun,Wed; 1 Jun 2011 03:51:05 +0000,Mon; 9 Mar 2015 20:15:20 +0000,Mon; 9 Mar 2015 20:15:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2553
MAPREDUCE-2554,Task,Major,contrib/gridmix,Gridmix distributed cache emulation system tests.,1.Verify the emulation of HDFS and Local FS distributed cache files against the given input trace file. 2.Verify the Gridmix emulation of HDFS distributed cache files of different visibilities. 3.Verify the Gridmix emulation of HDFS distributed cache file which uses different jobs that are submitted with different users. 4.Verify the emulation of local FS distributed cache files. 5.Verify the Gridmix emulation of HDFS private distributed cache file. 6.Verify the Gridmix emulation of HDFS public distributed cache file. 7.Verify the Gridmix emulation of Multiple HDFS private distributed cache files. 8.Verify the Gridmix emulation of Multiple HDFS public distributed cache files.,Closed,Fixed,,Yiting Wu,Vinay Kumar Thota,Wed; 1 Jun 2011 16:40:47 +0000,Mon; 7 Jan 2013 08:48:28 +0000,Sun; 5 Jun 2011 03:04:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2554
MAPREDUCE-2555,Bug,Minor,tasktracker,JvmInvalidate errors in the gridmix TT logs,Observing a  lot of jvmValidate exceptions in TT logs for grid mix run    ************************ 2011-04-28 02:00:37;578 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 46121; call statusUpdate(attempt_201104270735_5993_m_003305_0; org.apache.hadoop.mapred.MapTaskStatus@1840a9c; org.apache.hadoop.mapred.JvmContext@1d4ab6b) from 127.0.0.1:50864: error:  1384)   *********************,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 1 Jun 2011 20:01:08 +0000,Thu; 2 May 2013 02:29:41 +0000,Thu; 25 Aug 2011 20:08:53 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2555
MAPREDUCE-2556,Bug,Major,mrv2,MR 279: NodeStatus.getNodeHealthStatus().setBlah broken,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 2 Jun 2011 00:58:08 +0000,Tue; 15 Nov 2011 00:49:32 +0000,Thu; 2 Jun 2011 01:06:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2556
MAPREDUCE-2557,Bug,Trivial,,Counters don't reset state when readFields() called,When calling readFields() on a Counters object; the internal state is not completely reset. The IdentityHashMapEnum?; Counter cache retains all previous mappings; even after the actual CounterGroups are changed. Using the same Counters pointer over and over again results in the cache always keeping the mapping for the first call to getCounter(Enum?). I've add a clear() call to the cache when readFields() is called and added a unit test to verify that it works.,Resolved,Duplicate,MAPREDUCE-6199,Unassigned,William Slacum,Thu; 2 Jun 2011 02:23:16 +0000,Tue; 17 Mar 2015 13:25:29 +0000,Tue; 17 Mar 2015 09:52:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2557
MAPREDUCE-2558,New Feature,Major,jobtracker,Add queue-level metrics 0.20-security branch,We would like to record and present the jobtracker metrics on a per-queue basis.,Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Thu; 2 Jun 2011 12:47:17 +0000,Fri; 2 Sep 2011 22:13:24 +0000,Wed; 8 Jun 2011 08:01:37 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2558
MAPREDUCE-2559,Bug,Major,build,ant binary fails due to missing c++ lib dir,"Post MAPRED-2521 ant binary fails without ""-Dcompile.c+=true -Dcompile.native=true"". The bin-package is trying to copy from the c+ lib dir which doesn't exist yet. The binary target should check for the existence of this dir or would also be reasonable to depend on the compile-c++ (since this is the binary target).",Closed,Fixed,,Eric Yang,Eric Yang,Thu; 2 Jun 2011 16:33:22 +0000,Tue; 15 Nov 2011 00:48:24 +0000,Wed; 8 Jun 2011 00:58:26 +0000,,0.20.3,,,HDFS-2022;MAPREDUCE-2521,https://issues.apache.org/jira/browse/MAPREDUCE-2559
MAPREDUCE-2560,Improvement,Major,,Support specification of codecs by name,By changing the code to take advantage of HADOOP-7323; it will be possible to specify compression codecs in configuration by name (e.g. 'gzip'); not only by classname; although that will still be supported; of course (e.g. 'org.apache.hadoop.io.compress.GzipCodec').,Open,Unresolved,,Arun Ramakrishnan,Tom White,Thu; 2 Jun 2011 21:45:30 +0000,Wed; 22 Jun 2011 22:00:13 +0000,,,,newbie,HADOOP-7323,,https://issues.apache.org/jira/browse/MAPREDUCE-2560
MAPREDUCE-2561,Improvement,Trivial,,Typo in a comment in TaskInProgress.java,"This JIRA is to track a fix to a super-trivial issue of a typo of ""receive"" misspelled as ""recieve"" in Line 563 of TaskInProgress. ",Resolved,Not A Problem,,Anupam Seth,Anupam Seth,Thu; 2 Jun 2011 22:02:31 +0000,Tue; 17 Mar 2015 05:50:05 +0000,Tue; 17 Mar 2015 05:50:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2561
MAPREDUCE-2562,Bug,Major,jobtracker,NullPointerException in Jobtracker when it is started without Name Node,It is throwing NullPointerException in job tracker logs when job tracker is started without NameNode.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Fri; 3 Jun 2011 05:43:47 +0000,Thu; 17 Jan 2013 13:08:26 +0000,Thu; 17 Jan 2013 13:08:26 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2562
MAPREDUCE-2563,Task,Major,contrib/gridmix,Gridmix high ram jobs emulation system tests.,1. Run the Gridmix with a high ram jobs trace and  verify each Gridmix job whether it honors the high ram or not. In the trace the jobs should use the high ram for both maps and reduces.  2. Run the Gridmix with a high ram jobs trace and  verify each Gridmix job whether it honors the high ram or not. In the trace the jobs should use the high ram only for maps.  3. Run the Gridmix with a high ram jobs trace and verify each Gridmix job whether it honors the high ram or not. In the trace the jobs should use the high ram only for reducers.  4. Run the Gridmix with a high ram jobs trace by disabling the emulation of high ram  and verify each Gridmix job whether it honors the high ram or not. In disable mode it should should not honor the high ram and run it as a normal job.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 3 Jun 2011 06:23:10 +0000,Tue; 15 Nov 2011 00:49:05 +0000,Tue; 14 Jun 2011 10:19:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2563
MAPREDUCE-2564,Bug,Blocker,task,NullPointerException in WritableComparator, 210)  It is easy to see why this is happening.  The WritableComparator is created in JobConf line 776:    which calls     key1; key2; and buffer end up being null. When compare() is called the NPE is thrown because buffer is null,Closed,Invalid,,Unassigned,Joseph Shraibman,Fri; 3 Jun 2011 15:37:26 +0000,Fri; 2 Sep 2011 22:17:59 +0000,Fri; 5 Aug 2011 14:33:16 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2564
MAPREDUCE-2565,Bug,Major,harchive,TestMRCLI still failing on trunk,I imagine this is related to the recent shell commands. Here is an example failed test: https: localhost:56651 Usage:  FsShell [-rm -r|-R -skipTrash src ...],Open,Unresolved,,Daryn Sharp,Todd Lipcon,Fri; 3 Jun 2011 21:57:49 +0000,Tue; 10 Jul 2012 21:27:10 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2565
MAPREDUCE-2566,Bug,Major,mrv2,MR 279: YarnConfiguration should reloadConfiguration if instantiated with a non YarnConfiguration object,YarnConfiguration(conf) uses the ctor Configuration(conf) which is effectively a clone. If the configuration object is created before YarnConfiguration has been loaded - yarn-site.xml will not be available to the configuration.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sat; 4 Jun 2011 01:26:35 +0000,Tue; 15 Nov 2011 00:49:33 +0000,Wed; 8 Jun 2011 07:14:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2566
MAPREDUCE-2567,Improvement,Major,,MapReduce portion of Pluggable interface for cluster membership,MapReduce portion of HADOOP-7359; Pluggable interface for cluster membership,Open,Unresolved,,Unassigned,Travis Crawford,Sun; 5 Jun 2011 04:52:54 +0000,Sun; 5 Jun 2011 05:47:11 +0000,,,,,HADOOP-7359,,https://issues.apache.org/jira/browse/MAPREDUCE-2567
MAPREDUCE-2568,Bug,Major,test,Fix TestFileSystem,CommandFormat which is used to parse command lines is following posix conventions of stopping at the first non-argument.  There is just one test in this file which placed an option in the middle of the args.,Open,Unresolved,,Daryn Sharp,Daryn Sharp,Mon; 6 Jun 2011 18:30:34 +0000,Wed; 6 Jul 2011 15:00:26 +0000,,,0.23.0,,,HADOOP-7341,https://issues.apache.org/jira/browse/MAPREDUCE-2568
MAPREDUCE-2569,Bug,Minor,mrv2,MR-279: Restarting resource manager with root capacity not equal to 100 percent should result in error,root.capacity is set to 90% without failure,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 6 Jun 2011 18:55:14 +0000,Tue; 15 Nov 2011 00:48:51 +0000,Tue; 14 Jun 2011 23:46:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2569
MAPREDUCE-2570,Bug,Major,contrib/raid,Bug in RAID FS (DistributedRaidFileSystem) unraid path,"The ""un-raid"" path in DistributedRaidFileSystem goes through RaidNode.unRaidCorruptBlock(); which has a bug when the parity file is inside a HAR. The temporary file that contains the recovered block contents is created in the filesystem that hosts the parity file. In case the parity file is inside a HAR; its filesystem is HarFileSystem; which is read-only. In this case the temporary file creation will fail. The fix is a one-line change to use the underlying filesystem of the HAR.",Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Mon; 6 Jun 2011 20:17:30 +0000,Tue; 1 Aug 2017 17:12:56 +0000,Tue; 1 Aug 2017 17:12:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2570
MAPREDUCE-2571,Bug,Blocker,,CombineFileInputFormat.getSplits throws a java.lang.ArrayStoreException,The getSplits methods of    org.apache.hadoop.mapred.lib.CombineFileInputFormat  not work.  ...mapred.lib.CombineFileInputFormat(0.20-style) is a proxy for ...mapreduce.lib.input.CombineFileInputFormat(0.21-style)  The 0.21-style getSplits returns ArrayList...mapreduce.lib.input.CombineFileSplit and the 0.20-style delegation calls toArray(...mapred.InputSplit[])  The ...mapreduce.lib.input.CombineFileSplit is based on ...mapreduce.InputSplit and ...mapred.InputSplit is a interface; not a super-class of ...mapreduce.InputSplit,Closed,Fixed,,Bochun Bai,Bochun Bai,Tue; 7 Jun 2011 04:16:16 +0000,Mon; 12 Dec 2011 06:19:32 +0000,Tue; 7 Jun 2011 22:08:28 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2571
MAPREDUCE-2572,Improvement,Major,distributed-cache,Throttle the deletion of data from the distributed cache,When deleting entries from the distributed cache we do so in a background thread.  Once the size limit of the distributed cache is reached all unused entries are deleted.  MAPREDUCE-2494 changes this so that entries are deleted in LRU order until the usage falls below a given threshold.  In either of these cases we are periodically flooding a disk with delete requests which can slow down all IO operations to a drive.  It would be better to be able to throttle this deletion so that it is spread out over a longer period of time.  This jira is to add in this throttling.  On investigating it seems much simpler to backport MPAREDUCE-2494 to 20S before implementing this change rather then try to implement it without LRU deletion; because LRU goes a long way towards reducing the load on the disk anyways.,Closed,Duplicate,MAPREDUCE-2969,Robert Joseph Evans,Robert Joseph Evans,Tue; 7 Jun 2011 14:01:00 +0000,Tue; 15 Nov 2011 00:48:14 +0000,Fri; 9 Sep 2011 14:03:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2572
MAPREDUCE-2573,Bug,Major,,New findbugs warning after MAPREDUCE-2494,MAPREDUCE-2494 introduced the following findbugs warning in trunk: TrackerDistributedCacheManager. 739; SIC_INNER_SHOULD_BE_STATIC; Priority: Low Should org.apache.hadoop.mapreduce.filecache.TrackerDistributedCacheManager$CacheDir be a static inner class?  This class is an inner class; but does not use its embedded reference to the object which created it.  This reference makes the instances of the class larger; and may keep the reference to the creator object alive longer than necessary.  If possible; the class should be made static.,Closed,Fixed,,Robert Joseph Evans,Todd Lipcon,Tue; 7 Jun 2011 21:56:00 +0000,Tue; 15 Nov 2011 00:50:05 +0000,Thu; 9 Jun 2011 22:46:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2573
MAPREDUCE-2574,Improvement,Major,build;test,Force entropy to come from non-true random for tests,Same as HADOOP-7335 but for MR,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Tue; 7 Jun 2011 22:03:42 +0000,Fri; 16 Dec 2011 12:26:17 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2574
MAPREDUCE-2575,Bug,Major,test,TestMiniMRDFSCaching fails if test.build.dir is set to something other than build/test,TestMiniMRDFSCaching fails if test.build.dir is set to something other than build test,Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 7 Jun 2011 22:32:42 +0000,Tue; 15 Nov 2011 00:48:49 +0000,Mon; 25 Jul 2011 04:18:53 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2575
MAPREDUCE-2576,Bug,Trivial,,Typo in comment in SimulatorLaunchTaskAction.java,"This JIRA is to track a fix to a super-trivial issue of a typo of ""or"" misspelled as ""xor "" in Line 24 of SimulatorLaunchTaskAction.java",Closed,Fixed,,Tim Sell,Sherry Chen,Wed; 8 Jun 2011 17:49:26 +0000,Tue; 15 Nov 2011 00:49:32 +0000,Thu; 16 Jun 2011 01:13:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2576
MAPREDUCE-2577,Bug,Minor,contrib/raid,RAID FS (DistributedRaidFileSystem) skip() implementation needs to be improved,MAPREDUCE-2248 implemented skip() so that it skips one byte at a time; which is bad. It should skip a larger number of bytes at a time to improve performance.,Resolved,Won't Fix,,Ramkumar Vadali,Ramkumar Vadali,Wed; 8 Jun 2011 19:32:22 +0000,Tue; 1 Aug 2017 17:12:58 +0000,Tue; 1 Aug 2017 17:12:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2577
MAPREDUCE-2578,Bug,Major,,Fix eclipse project to work out of the box,"Currently ""ant eclipse"" generates an eclipse project that doesn't actually work properly. A few issues:  	the ""testjar"" dir inside src  on the classpath breaks things since we then have two copies of every class; etc 	some parts of the code depend on hadoop.log.dir being defined; which isn't true when running junit inside a stock Eclipse setup",Resolved,Won't Fix,,Todd Lipcon,Todd Lipcon,Wed; 8 Jun 2011 19:45:32 +0000,Thu; 20 Oct 2011 22:39:46 +0000,Thu; 20 Oct 2011 22:39:46 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2578
MAPREDUCE-2579,Bug,Major,contrib/raid,The parity path is not initial correctly in BlockPlacementPolicyRaid,BlockPlacementPolicyRaid.initialize() initialize the parity paths. It uses Path.makeQualified() that requires to contact namenode but namenode is not up yet.,Resolved,Won't Fix,,Scott Chen,Scott Chen,Thu; 9 Jun 2011 00:25:21 +0000,Tue; 1 Aug 2017 17:12:57 +0000,Tue; 1 Aug 2017 17:12:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2579
MAPREDUCE-2580,Improvement,Minor,mrv2,MR 279: RM UI should redirect finished jobs to History UI,The RM UI currently has a link to the AM UI. After an application finishes (AM not available); the RM UI should link to the history UI.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 9 Jun 2011 01:41:23 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Thu; 9 Jun 2011 18:43:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2580
MAPREDUCE-2581,Bug,Trivial,,Spelling errors in log messages (MapTask),"Spelling errors in log messages (MapTask) - e.g. search for ""recieve"" (should be ""receive"").  A decent IDE should detect these errors as well.",Closed,Fixed,,Tim Sell,Dave Syer,Thu; 17 Feb 2011 12:17:55 +0000,Tue; 15 Nov 2011 00:48:42 +0000,Fri; 10 Jun 2011 02:41:19 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2581
MAPREDUCE-2582,Bug,Major,mrv2,MR 279: Cleanup JobHistory event generation,Generate JobHistoryEvents for the correct transitions. Fix missing   incorrect values being set.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 10 Jun 2011 02:26:31 +0000,Tue; 15 Nov 2011 00:50:09 +0000,Fri; 10 Jun 2011 09:16:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2582
MAPREDUCE-2583,New Feature,Major,,DistributedCache for M-R chains,Currently the DistributedCache appears to be created at the granularity of a job.  In the case of a M-R chain; it is sometimes useful to share information out-of-band (as small files in hdfs) with each task in the chain.  For instance; the first M-R phase within a two-phase M-R chain might produce useful statistics that could be used to configure the second phase.,Open,Unresolved,,Unassigned,Mitch McCuiston,Fri; 10 Jun 2011 15:57:05 +0000,Fri; 10 Jun 2011 16:47:28 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2583
MAPREDUCE-2584,Improvement,Major,task,Check for serializers early; and give out more information regarding missing serializers,As discussed on HADOOP-7328; MapReduce can handle serializers in a much better way in case of bad configuration; improper imports (Some odd Text class instead of the Writable Text set as key); etc..  This issue covers the MapReduce parts of the improvements (made to IFile; MapOutputBuffer; etc. and possible early-check of serializer availability pre-submit) that provide more information than just an NPE as is the current case.,Resolved,Not A Problem,MAPREDUCE-5728,Harsh J,Harsh J,Sat; 11 Jun 2011 18:54:06 +0000,Wed; 26 Oct 2016 14:54:43 +0000,Wed; 26 Oct 2016 14:54:35 +0000,,0.20.2,serializers;tasks,,HADOOP-8531,https://issues.apache.org/jira/browse/MAPREDUCE-2584
MAPREDUCE-2585,Improvement,Trivial,,Add dumpConfiguration option in hadoop help message,Execution of bin hadoop should show the -dumpConfiguration option introduced in MAPREDUCE-768,Resolved,Not A Problem,,V.V.Chaitanya Krishna,Ramya Sunil,Thu; 27 Aug 2009 10:58:09 +0000,Mon; 9 Mar 2015 20:24:29 +0000,Wed; 23 Jul 2014 22:08:25 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2585
MAPREDUCE-2586,Bug,Blocker,contrib/raid,mapreduce/contrib/raid not compile due to hdfs changes.,nan,Resolved,Duplicate,MAPREDUCE-2588,Bochun Bai,Bochun Bai,Mon; 13 Jun 2011 02:54:30 +0000,Mon; 13 Jun 2011 22:46:55 +0000,Mon; 13 Jun 2011 22:46:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2586
MAPREDUCE-2587,Bug,Minor,,MR279: Fix RM version in the cluster->about page ,The Resource Manager version in the Cluster-About page always shows 1.0-SNAPSHOT.,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 13 Jun 2011 15:20:20 +0000,Tue; 15 Nov 2011 00:49:58 +0000,Tue; 12 Jul 2011 14:59:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2587
MAPREDUCE-2588,Bug,Major,contrib/raid,Raid is not compile after DataTransferProtocol refactoring,Raid is directly using DataTransferProtocol.  It cannot be compiled after HDFS-2066.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Mon; 13 Jun 2011 18:02:20 +0000,Tue; 15 Nov 2011 00:48:35 +0000,Mon; 13 Jun 2011 18:17:47 +0000,,0.23.0,,,HDFS-2066,https://issues.apache.org/jira/browse/MAPREDUCE-2588
MAPREDUCE-2589,Bug,Minor,tasktracker,TaskTracker not purging userlog directories,UserLogCleaner is not robust. Leftover userlogs after a restart sometimes have to be manually cleaned. Things can accumulate over a period of time.,Closed,Won't Fix,,Sherry Chen,Sherry Chen,Mon; 13 Jun 2011 18:49:36 +0000,Wed; 19 Oct 2011 00:30:20 +0000,Tue; 26 Jul 2011 18:45:51 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2589
MAPREDUCE-2590,Task,Minor,,How to access Job Configuration file in Partitioner,I need to access Job Configuration file in partitioner to fetch some information. Generally we can access job configuration file easily in map or reduce side by this code   Configuration config = context.getConfiguration(); But this same code cannot be used in partitioner. To solve this issue I followed the patch https: MAPREDUCE-2474 but it is a doc so I downloaded the latest trunk code and generate the jar but I did not get any extra feature from that to call the job configuration file So any one knows the code to call Job Configuration file in partitioner.,Resolved,Invalid,,Unassigned,Somnath,Tue; 14 Jun 2011 09:01:49 +0000,Sun; 26 Jun 2011 21:03:34 +0000,Sun; 26 Jun 2011 21:03:34 +0000,,,configuration;hadoop;job;partitioners,,,https://issues.apache.org/jira/browse/MAPREDUCE-2590
MAPREDUCE-2591,Improvement,Major,contrib/gridmix,[Gridmix] Improve cumulative CPU usage emulation,MAPREDUCE-2106 introduced a basic cumulative cpu usage emulation in Gridmix. There are some known cases where it can be improved. The cases are 1. JVM reuse 2. Short lived maps emulating high CPU usage 3. Long running maps reducers with high CPU usage,Open,Unresolved,,Amar Kamat,Amar Kamat,Tue; 14 Jun 2011 11:55:43 +0000,Tue; 10 Mar 2015 01:24:59 +0000,,,,,,MAPREDUCE-2106,https://issues.apache.org/jira/browse/MAPREDUCE-2591
MAPREDUCE-2592,Improvement,Major,tasktracker,TT should fail task immediately if userlog dir cannot be created,"Currently; TaskRunner will log the message ""mkdirs failed. Ignoring"" if it fails to mkdir the userlog directory for a task. Then; it goes on to spawn taskjvm.sh which tries to redirect output into the userlogs dir; thus failing with exit code 1. This leads to error messages that are very hard to diagnose (""task failed with exit status 1"") in cases where the userlog directory has either become inaccessible or has reached the maximum number of dirents (32000 in ext3)",Resolved,Won't Fix,,Harsh J,Todd Lipcon,Tue; 14 Jun 2011 18:33:59 +0000,Sat; 11 Feb 2012 17:51:02 +0000,Sat; 11 Feb 2012 17:51:02 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2592
MAPREDUCE-2593,New Feature,Major,mrv2,Random read benchmark for DFS,We should have at least one  random read benchmark that can be run with rest of Hadoop benchmarks regularly.  Please provide benchmark  ideas or requirements.,Open,Unresolved,,Dave Thompson,Raghu Angadi,Wed; 30 Jan 2008 01:05:07 +0000,Thu; 17 Jul 2014 20:18:00 +0000,,,,,,HDFS-641;HDFS-1599,https://issues.apache.org/jira/browse/MAPREDUCE-2593
MAPREDUCE-2594,Improvement,Major,contrib/gridmix,[Gridmix] Improve the way Gridmix communicates specifications to map/reduce tasks ,As of now; Gridmix ships map task's specifications within job splits and reduce task's specification within the map's output (as the first key). This not only makes the Gridmix code harder to understand and manage but also makes it difficult to extend and add more data to the specification.,Open,Unresolved,,Amar Kamat,Amar Kamat,Wed; 15 Jun 2011 11:22:31 +0000,Wed; 30 Jul 2014 17:27:54 +0000,,,0.23.0,gridmix;specification-redesign,,,https://issues.apache.org/jira/browse/MAPREDUCE-2594
MAPREDUCE-2595,Bug,Minor,,MR279: update yarn INSTALL doc,yarn install doc needs to be updated after unsplit: http: INSTALL,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 15 Jun 2011 14:50:14 +0000,Tue; 15 Nov 2011 00:48:26 +0000,Wed; 15 Jun 2011 16:39:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2595
MAPREDUCE-2596,Improvement,Major,benchmarks;contrib/gridmix,Gridmix should notify job failures,Gridmix doesn't warn the user if any of the jobs in the mix fail... it probably should printout a summary of the jobs and other statistics at the end too.,Closed,Fixed,,Amar Kamat,Arun C Murthy,Fri; 3 Oct 2008 20:45:51 +0000,Tue; 15 Nov 2011 00:49:19 +0000,Fri; 8 Jul 2011 17:59:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2596
MAPREDUCE-2597,Bug,Major,,Map-side joins always empty when an input has NullWritable value,It is not uncommon to have a sorted list of data that has no specific value associated with it as input to a map-side join; e.g. as an exact-match filter.  In these cases; you would typically have a value class of NullWritable.  However; when performing a map-side join in Hadoop 0.20.2; we have found that any input that has value class of NullWritable results in the Mapper never getting called.  I found this with a 3-way map-side join; and my colleague tells me he ran into the same issue.  I have not specifically tested a 2-way join to see if the problem occurs; so it may be that the bug is specific to n-way joins for n2 (though I suspect not).  The current workaround is to use some other value type (e.g. IntWritable) and stuff an arbitrary value into it.  For a join; the value class should have no bearing on the set of keys that are considered matching.,Open,Unresolved,,Unassigned,Michael White,Wed; 15 Jun 2011 18:34:55 +0000,Wed; 15 Jun 2011 18:34:55 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2597
MAPREDUCE-2598,Bug,Minor,mrv2,MR 279: miscellaneous UI; NPE fixes for JobHistory; UI,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 15 Jun 2011 20:07:54 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Wed; 15 Jun 2011 22:44:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2598
MAPREDUCE-2599,Bug,Major,contrib/gridmix,Gridmix system tests are failing due to misconfiguration of task memory in simulated cluster when high ram job emulation enabled.,Gridmix system test are failing due to misconfiguration of task memory in simulated cluster when high ram job emulation enabled.  Girdmix scale the task memory for emulation of high ram jobs based on simulated cluster configuration and it reserved the slots based on scaled memory information of each task. Here; I found an issue; suppose if total reserved slots of either map or reduce exceeds the slot capacity then it hangs the job and failed after timeout.So; Gridmix should show either error message or bailing out before submitting the job in this condition.,Open,Unresolved,,Amar Kamat,Vinay Kumar Thota,Thu; 16 Jun 2011 10:53:37 +0000,Thu; 16 Jun 2011 10:53:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2599
MAPREDUCE-2600,Improvement,Major,mrv2,MR-279: simplify the jars ,Currently the MR-279 mapreduce project generates 59 jars from 59 source roots; which can be dramatically simplified.,Open,Unresolved,MAPREDUCE-3367,Luke Lu,Owen O'Malley,Thu; 16 Jun 2011 16:42:11 +0000,Sat; 14 Apr 2012 00:15:21 +0000,,,0.23.0,,,MAPREDUCE-3378,https://issues.apache.org/jira/browse/MAPREDUCE-2600
MAPREDUCE-2601,Improvement,Minor,contrib/fair-share,Add a filter text box to FairSchedulerServlet page,It will be useful if we can filter pool in the fairscheduler UI page.,Open,Unresolved,,Unassigned,Scott Chen,Thu; 16 Jun 2011 18:48:35 +0000,Wed; 1 Feb 2012 03:39:15 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2601
MAPREDUCE-2602,Improvement,Major,,Allow setting of end-of-record delimiter for TextInputFormat (for the old API),Since there are users who are still using the old MR API; it will be useful to modify the org.apache.hadoop.mapred.LineRecordReader and org.apache.hadoop.mapred.TextInputFormat to be able to use custom (user-specified) end-of-record delimiters. This will make use of the LineReader improvement introduced in HADOOP-7096 that enables the LineReader to break lines at user-specified delimiters.   Note: MAPREDUCE-2254 already added this improvement to the new API (but not the old API).,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Fri; 17 Jun 2011 02:14:43 +0000,Tue; 15 Nov 2011 00:48:31 +0000,Mon; 25 Jul 2011 21:42:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2602
MAPREDUCE-2603,Bug,Major,contrib/gridmix,Gridmix system tests are failing due to high ram emulation enable by default for normal mr jobs in the trace which exceeds the solt capacity.,In Gridmix high ram emulation enable by default.Because of this feature; some of the gridmix system tests are hanging for some time and then failing after timeout. Actually the failure case was occurring whenever reserved slot capacity exceeds the cluster slot capacity.So for fixing the issue by disabling the high ram emulation in the tests which are using the normal mr jobs in the traces.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Fri; 17 Jun 2011 04:26:37 +0000,Tue; 15 Nov 2011 00:48:08 +0000,Wed; 22 Jun 2011 04:50:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2603
MAPREDUCE-2604,Bug,Major,,Delegation token renewal over https in JobTracker ,Delegation token renewal in JobTracker uses https if there is a failure in creation of DistributedFileSystem. This handles the case when server is using a different version. With the changes in HADOOP-7227 the; creation of DistributedFileSystem will not fail because the creation of file system object doesn't make a connection or an rpc call. Therefore; the switchover to https should happen after an attempt to renew over rpc fails.,Open,Unresolved,,Jitendra Nath Pandey,Jitendra Nath Pandey,Fri; 17 Jun 2011 22:42:48 +0000,Mon; 9 Mar 2015 23:17:25 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2604
MAPREDUCE-2605,Bug,Minor,,Hadoop Streaming (StreamJob) does not delete temporary job/package jar,The streaming job driver (org.apache.hadoop.streaming.StreamJob) does not delete the temporary JAR file it generates after a job completes.  Without the fix;  submitAndMonitorJob() should clean up the jar_ file when done.  Or the JAR could be generatd as a tempfile and cleaned up automatically.,Resolved,Not A Problem,,Unassigned,Greg Wittel,Fri; 6 May 2011 16:31:43 +0000,Sat; 18 Jun 2011 17:18:10 +0000,Sat; 18 Jun 2011 17:18:10 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2605
MAPREDUCE-2606,Bug,Major,,Remove IsolationRunner,IsolationRunner it seems it has been broken for a while; it gives a NPE when trying to use it.  In addition; it supports only Map tasks; to use it the user must ssh to the node where the task failed; and unless the job has been configured to keep local files; the job must be run again.  Because of this; IMO; the current implementation of IsolationRunner is not of much use.  Any objection to remove it from trunk and if people have the need for such functionality to open another JIRA to build this functionality supported by the JobTracker (ie via the UI console)?,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Mon; 20 Jun 2011 22:35:43 +0000,Tue; 13 Dec 2011 06:22:12 +0000,Tue; 12 Jul 2011 00:55:01 +0000,,,,,MAPREDUCE-2637,https://issues.apache.org/jira/browse/MAPREDUCE-2606
MAPREDUCE-2607,Task,Major,,Mavenization of hadoop-mapreduce,Same as HADOOP-6671 for mapreduce,Resolved,Won't Fix,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 21 Jun 2011 17:29:22 +0000,Fri; 16 Sep 2011 14:01:22 +0000,Fri; 16 Sep 2011 14:01:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2607
MAPREDUCE-2608,Task,Major,,Mavenize mapreduce contribs,Same as HADOOP-6671 for mapreduce contribs,Resolved,Invalid,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 21 Jun 2011 17:30:08 +0000,Wed; 14 May 2014 21:09:13 +0000,Wed; 14 May 2014 21:09:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2608
MAPREDUCE-2609,Task,Major,,Mavenization of  mapreduce RPM/DEB,Mavenize RPPM DEB generation,Open,Unresolved,,Unassigned,Alejandro Abdelnur,Tue; 21 Jun 2011 17:32:23 +0000,Tue; 21 Jun 2011 17:32:23 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2609
MAPREDUCE-2610,Bug,Major,client,Inconsistent API JobClient.getQueueAclsForCurrentUser,Client needs access to the current user's queue name. Public method JobClient.getQueueAclsForCurrentUser() returns QueueAclsInfo[]. The QueueAclsInfo class has default access. A public method should not return a package-private class.  The QueueAclsInfo class; its two constructors; getQueueName; and getOperations methods should be public.,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Tue; 21 Jun 2011 17:57:04 +0000,Wed; 19 Oct 2011 00:26:04 +0000,Fri; 9 Sep 2011 19:45:51 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2610
MAPREDUCE-2611,Improvement,Major,mrv2,MR 279: Metrics; finishTimes; etc in JobHistory,nan,Closed,Fixed,,Unassigned,Siddharth Seth,Tue; 21 Jun 2011 18:44:17 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Tue; 21 Jun 2011 20:28:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2611
MAPREDUCE-2612,Improvement,Minor,,"The result returned by the wrong usage of the command ""job -counter<job-id> <group-name> <counter-name> ""is not appropriate","The result returned by Map Reduce command ""job -counterjob-id group-name counter-name "" is always zero ;when use this command with incorrect group name or counter name.  It is very easy to be misunderstood if users just make a spelling mistake. So;for more comprehensible information; more detailed results should be displayed as the following: Could not find group FileSystemCounters_err --incorrect group name   or Could not find counter FILE_BYTES_READ_err in the group FileSystemCounters --incorrect counter name",Open,Unresolved,,Unassigned,XieXianshan,Wed; 22 Jun 2011 02:18:38 +0000,Mon; 9 Mar 2015 23:24:18 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2612
MAPREDUCE-2613,Improvement,Minor,,"There is no error message displayed while mapred command ""job -list"" with incorrect genericOption -D","When specifying an invalid value for property fs.defaultFS with genericOption -D for mapred command ""job -list"";there`s no any error message saying that the value was illegal. For instance: $mapred job -D fs.defaultFS=. -list Normal end.",Open,Unresolved,,Unassigned,XieXianshan,Wed; 22 Jun 2011 05:53:44 +0000,Tue; 10 Mar 2015 01:28:53 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2613
MAPREDUCE-2614,Improvement,Minor,,Allow append arbitrary text at the end of generated query in DBOutputFormat class,"It would be wonderful if DBOutputFormat class allow addition of arbitrary text at the end of generated query. This feature can be useful for example in case of MySQL database to specify ""ON DUPLICATE KEY UPDATE ..."" part of the query.",Open,Unresolved,,Unassigned,Jarek Jarcec Cecho,Wed; 22 Jun 2011 14:00:42 +0000,Fri; 24 Jun 2011 06:03:14 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2614
MAPREDUCE-2615,Bug,Major,mrv2,MR 279: KillJob should go through AM whenever possible,KillJob currently goes directly to the RM - which effectively causes the AM and tasks to be killed via a signal. History information is not recorded in this case.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 22 Jun 2011 21:56:26 +0000,Tue; 15 Nov 2011 00:49:19 +0000,Wed; 22 Jun 2011 23:40:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2615
MAPREDUCE-2616,Improvement,Minor,contrib/gridmix,[Gridmix] InputStriper should smartly switch between compressed and uncompressed files based on the simulated job's input data characteristics,Currently; all the Gridmix input data files are located at gridmix-io-dir input (gridmix-io-dir is expected as a CLI parameter). When compression emulation is enabled; Gridmix will check for compressed files (based on suffixes) in the input folder. Gridmix will bail out if there are no compressed input files. If the input folder consists of a mix of compressed and uncompressed input files; then Gridmix will only use compressed input files for all the jobs. Gridmix should smartly assign  1. uncompressed input files for jobs the don't need input decompression  2. compressed input files for jobs that need input decompression,Open,Unresolved,,Amar Kamat,Amar Kamat,Thu; 23 Jun 2011 05:45:38 +0000,Mon; 9 Mar 2015 23:14:25 +0000,,,0.23.0,compression-emulation;gridmix,,,https://issues.apache.org/jira/browse/MAPREDUCE-2616
MAPREDUCE-2617,New Feature,Major,contrib/gridmix,[Gridmix] Gridmix should provide a tool to compare and analyze Gridmix runs,After running Gridmix; users manually process simulated job history logs (probably using Rumen) and then use some external tools to analyze it; compare it with either the original job history files or with simulated jobhistory files of other Gridmix runs and generate reports. It would be nice if Gridmix comes bundled with a set of tools to do this transparently.,Open,Unresolved,,Unassigned,Amar Kamat,Thu; 23 Jun 2011 15:05:22 +0000,Mon; 9 Mar 2015 23:15:29 +0000,,,0.23.0,analysis;gridmix;reporting,,,https://issues.apache.org/jira/browse/MAPREDUCE-2617
MAPREDUCE-2618,Bug,Major,mrv2,MR-279: 0 map; 0 reduce job fails with Null Pointer Exception,A 0 map; 0 reduce job fails with an NPE. This case works fine on hadoop-0.20.x. The job should succeed and run setup cleanup code - with no tasks.  Below is the stacktrace:    WARN mapred.ClientServiceDelegate:  StackTrace:  1400),Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Thu; 23 Jun 2011 15:46:13 +0000,Tue; 15 Nov 2011 00:50:17 +0000,Mon; 27 Jun 2011 18:57:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2618
MAPREDUCE-2619,Bug,Major,,Broken eclipse environment for mapreduce,The build.xml ant eclipse target creates a broken eclipse environment for mapreduce.  Excluding testjar test seems to solve this issue.,Closed,Duplicate,MAPREDUCE-2578,Ahmed Radwan,Ahmed Radwan,Fri; 24 Jun 2011 03:14:36 +0000,Fri; 24 Jun 2011 03:55:47 +0000,Fri; 24 Jun 2011 03:55:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2619
MAPREDUCE-2620,Bug,Major,contrib/raid,Update RAID for HDFS-2087,DataTransferProtocol was changed by HDFS-2087.  Need to update RAID.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Fri; 24 Jun 2011 17:16:49 +0000,Tue; 15 Nov 2011 00:50:09 +0000,Fri; 8 Jul 2011 00:19:50 +0000,,0.23.0,,,HDFS-2087,https://issues.apache.org/jira/browse/MAPREDUCE-2620
MAPREDUCE-2621,Bug,Minor,,"TestCapacityScheduler fails with ""Queue ""q1"" does not exist""","Error Message  Queue ""q1"" does not exist  Stacktrace   1109)  When queue name is invalid; an exception is thrown now.",Closed,Fixed,,Sherry Chen,Sherry Chen,Fri; 24 Jun 2011 22:19:52 +0000,Sat; 1 Oct 2011 19:30:19 +0000,Mon; 25 Jul 2011 02:34:11 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2621
MAPREDUCE-2622,Task,Minor,test,"Remove the last remaining reference to ""io.sort.mb""","TestLocalRunner still carries ""io.sort.mb""; which must be updated to ""mapreduce.task.io.sort.mb"" (MRJobConfig.IO_SORT_MB).",Closed,Fixed,,Harsh J,Harsh J,Sat; 25 Jun 2011 11:49:57 +0000,Tue; 15 Nov 2011 00:48:45 +0000,Mon; 25 Jul 2011 21:29:47 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2622
MAPREDUCE-2623,Improvement,Minor,test,Update ClusterMapReduceTestCase to use MiniDFSCluster.Builder,Looking at test class ClusterMapReduceTestCase it issues a warning that the dfsCluster = new MiniDFSCluster(conf; 2; reformatDFS; null); line of code is deprecated and MiniDFSCluster.Builder should be used instead. It notes that the current API will be phased out in version 24. I propose to update the test class to the most up to date code as it's referenced several places on the internet as an example of how to write a Hadoop Unit Test.,Closed,Fixed,,Harsh J,Jim Plush,Sun; 26 Jun 2011 17:53:47 +0000,Tue; 15 Nov 2011 00:49:27 +0000,Mon; 18 Jul 2011 17:27:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2623
MAPREDUCE-2624,Improvement,Major,contrib/raid,Update RAID for HDFS-2107,HDFS-2107 is going to move BlockPlacementPolicy to another package.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Sun; 26 Jun 2011 23:02:07 +0000,Tue; 15 Nov 2011 00:50:09 +0000,Wed; 29 Jun 2011 02:11:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2624
MAPREDUCE-2625,Bug,Minor,mrv2,MR-279: Add Node Manager Version to NM info page,Hadoop and YARN versions are missing from the NM info page,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 27 Jun 2011 18:52:34 +0000,Tue; 15 Nov 2011 00:50:01 +0000,Mon; 27 Jun 2011 19:10:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2625
MAPREDUCE-2626,Improvement,Major,contrib/gridmix,Maintain all the gridmix plugins in plugin.properties file.,Use a plugin.properties for CPU and Memory emulation plugins. Also it will be useful for future to add the new plugins into the file without any code changes. For user point of view; it will be easy to use the plugin by just passing the keyword instead of passing the full class name.,Open,Unresolved,,Amar Kamat,Vinay Kumar Thota,Tue; 28 Jun 2011 07:00:26 +0000,Tue; 28 Jun 2011 07:00:26 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2626
MAPREDUCE-2627,Bug,Blocker,build,guava-r09 JAR file needs to be added to mapreduce.,"Need to add the guava-r09.jar file into the ""mapreduce common"" directory; missing from build.",Resolved,Duplicate,NULL,Unassigned,Plamen Jeliazkov,Tue; 28 Jun 2011 21:29:47 +0000,Mon; 8 Aug 2011 17:04:50 +0000,Tue; 26 Jul 2011 01:40:47 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2627
MAPREDUCE-2628,Bug,Minor,mrv2,MR-279: Add compiled on date to NM and RM info/about page,Compiled on dates were present on the JobTracker UI. Bring compiled on dates to resource manager and node manager UI.   NM and RM retrieves build version for hadoop and yarn version via the getBuildVersion util api. This function used to contain the compiled on date; but since has been removed since that function is used to determine hadoop compatible versions; but was too restrictive with build date being present. Instead; a getDate call should be used to retrieve the compiled on date.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Tue; 28 Jun 2011 21:47:25 +0000,Tue; 15 Nov 2011 00:49:29 +0000,Fri; 8 Jul 2011 23:04:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2628
MAPREDUCE-2629,Improvement,Minor,task,Class loading quirk prevents inner class method compilation,"While profiling jobs like terasort and gridmix; I noticed that a method ""org.apache.hadoop.mapreduce.task.ReduceContextImpl.access $000"" is near the top. It turns out that this is because the ReduceContextImpl class has a member backupStore which is accessed from an inner class ReduceContextImpl$ValueIterator. Due to the way synthetic accessor methods work; every access of backupStore results in a call to access$000 to the outer class. For some portion of the run; backupStore is null and the BackupStore class has never been loaded by the reducer.  Due to the way the Hotspot JVM inliner works; by default it will not inline a short method where the class of of the return value object is unloaded - if you use a debug JVM with -XX:+PrintCompilation you will see a failure reason message like ""unloaded signature classes."" This causes every call to ReduceContextImpl.access$000 to be executed in the interpreter for the handful of bytecodes to return the null backupStore.",Closed,Fixed,,Eric Caspole,Eric Caspole,Tue; 28 Jun 2011 22:06:57 +0000,Tue; 15 Nov 2011 00:48:51 +0000,Fri; 21 Oct 2011 05:18:39 +0000,,0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2629
MAPREDUCE-2630,Bug,Minor,mrv2,MR-279: refreshQueues leads to NPEs when used w/FifoScheduler,The RM's admin service exposes a method refreshQueues that is used to update the queue configuration when used with the CapacityScheduler; but if it is used with the FifoScheduler; it will set the containerTokenSecretManager updateQueues methods.,Closed,Fixed,,Josh Wills,Josh Wills,Wed; 29 Jun 2011 06:38:42 +0000,Tue; 15 Nov 2011 00:50:07 +0000,Wed; 13 Jul 2011 03:02:05 +0000,,,,,MAPREDUCE-279,https://issues.apache.org/jira/browse/MAPREDUCE-2630
MAPREDUCE-2631,Bug,Major,,Potential resource leaks in BinaryProtocol$TeeOutputStream.java,In the above code; if the file.close() throws any exception out will not be closed.,Resolved,Fixed,,Sunil G,Ravi Teja Ch N V,Thu; 30 Jun 2011 05:16:48 +0000,Fri; 6 Jan 2017 08:09:19 +0000,Fri; 28 Oct 2016 00:38:06 +0000,,0.23.0,,,HDFS-1753,https://issues.apache.org/jira/browse/MAPREDUCE-2631
MAPREDUCE-2632,Improvement,Major,,Avoid calling the partitioner when the numReduceTasks is 1.,We can avoid the call to the partitioner when the number of reducers is 1.This will avoid the unnecessary computations by the partitioner.,Resolved,Fixed,,Sunil G,Ravi Teja Ch N V,Thu; 30 Jun 2011 05:31:15 +0000,Fri; 13 May 2016 05:05:54 +0000,Fri; 8 May 2015 18:55:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2632
MAPREDUCE-2633,Improvement,Minor,mrv2,MR-279: Add a getCounter(Enum) method to the Counters interface,I'm fixing a few TODOs I came across in TaskAttemptImpl. related to the fact that the MRv2 Counters interface don't expose a getCounter(Enum) method for accessing a Counter using the enum's class as the group name and the enum's value as the name of the counter.  Will add the patch momentarily.,Resolved,Fixed,,Josh Wills,Josh Wills,Thu; 30 Jun 2011 17:14:25 +0000,Thu; 7 Jul 2011 06:27:22 +0000,Thu; 7 Jul 2011 06:27:22 +0000,,,,,MAPREDUCE-279,https://issues.apache.org/jira/browse/MAPREDUCE-2633
MAPREDUCE-2634,Improvement,Minor,,MapReduce Performance Improvements using forced heartbeat ,Following are the proposals which would cause some performance optimizations over MapReduce  1.Notify TaskTracker to send heartbe to JobTracker whenever Reduce Task is completed.     These optimizations might work on small clusters but on big clusters it may be overhead.  Please let us know your views.,Open,Unresolved,,Unassigned,Abhijit Suresh Shingate,Fri; 1 Jul 2011 03:02:33 +0000,Wed; 13 Jul 2011 07:27:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2634
MAPREDUCE-2635,Bug,Blocker,jobtracker;task-controller;tasktracker,Jobs hang indefinitely on failure.,"Running the following example hangs the child job indefinitely.  public class HaltCluster {    public static void main(String[] args) throws IOException   {     JobConf jobConf = new JobConf();     prepareConf(jobConf);     if (args != null &amp; args.length  0)     {       jobConf.set(""callonceagain""; args[0]);       jobConf.setMaxMapAttempts(1);       jobConf.setJobName(""ParentJob"");      }     JobClient.runJob(jobConf);    }    public static void prepareConf(JobConf jobConf)   {     jobConf.setJarByClass(HaltCluster.class);     jobConf.set(""mapred.job.tracker""; ""&lt;jobtracker&gt;"");     jobConf.set(""fs.default.name""; ""&lt;hdfs&gt;"");     MultipleInputs.addInputPath(jobConf; new Path(""  TODO Auto-generated method stub    }  }  run using the following command   -cp &lt;classpath&gt; HaltCluster it fails to max number of attempts and quits as expected.   Also; when the jobs hang; running the child job once again; makes it come out of deadlock and completes the three jobs.",Resolved,Cannot Reproduce,,Unassigned,Sudharsan Sampath,Fri; 1 Jul 2011 06:09:07 +0000,Sat; 7 Jul 2012 13:03:06 +0000,Sat; 7 Jul 2012 13:03:06 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2635
MAPREDUCE-2636,Improvement,Minor,job submission,Scheduling over disks horizontally,Based on this message: http: browser  The JT schedules tasks on nodes based on metadata it gets from the NN. The namenode does not know on which disk a block resides. It might happen that on a node running 4 tasks; all read from the same disk. This can affect performance.  An optimization might be to schedule horizontally over disks instead of nodes. Any ideas?,Open,Unresolved,,Unassigned,Evert Lammerts,Fri; 1 Jul 2011 08:29:02 +0000,Mon; 7 Jan 2013 22:12:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2636
MAPREDUCE-2637,Improvement,Major,tasktracker,Providing options to debug the mapreduce user code (Mapper; Reducer; Combiner; Sort implementations),"Presently Hadoop provides ""mapred.child. opts"" configuration which can be used to set JVM options for Child JVM running Map or Reduce Task.  If we need to remote debug the Child JVM; we can add remote debugging options to this configuration value. But this will work only for single Child JVM. Other children will fail as the remote debugging port is already used. We cannot specify the remote debugging port dynamically. As a result; it's not possible to remote debug multiple Child JVMs. As a solution to this problem; we can provide a configuration to debug Task JVMs in this scenario.",Open,Unresolved,,Devaraj K,Devaraj K,Fri; 1 Jul 2011 15:10:59 +0000,Fri; 18 May 2012 20:19:45 +0000,,,,,,MAPREDUCE-2606,https://issues.apache.org/jira/browse/MAPREDUCE-2637
MAPREDUCE-2638,Test,Major,contrib/fair-share,Create a simple stress test for the fair scheduler,This would be a test that runs against a cluster; typically with settings that allow preemption to be exercised.,Patch Available,Unresolved,,Tom White,Tom White,Fri; 1 Jul 2011 16:46:34 +0000,Wed; 6 May 2015 03:27:15 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-2638
MAPREDUCE-2639,Improvement,Minor,mrv2,MR-279: Fixup the exponentially smoothed runtime estimator; fix a couple of bugs in DataStatistics; and do a little bit of cleanup.,A catch-all JIRA for a pass I took through the v2.app.speculate package.  1) Fixed the ExponentiallySmoothedTaskRuntimeEstimator so that it can run and pass the test defined in TestRuntimeEstimators. 2) Fixed two bugs in DataStatistics: 1) a divide by zero in the variance calculation in the case that count == 0 and 2) a synchronization issue in how the updateStatistics method was implemented; 3) A bunch of typo corrections; formatting fixes; and adding some consistency around the null value checking.  I probably need to do a couple more passes through this code to get it into better shape; but this seemed like a good start. Will attach my patch momentarily.,Open,Unresolved,,Josh Wills,Josh Wills,Mon; 4 Jul 2011 00:33:48 +0000,Fri; 29 Jul 2011 22:41:14 +0000,,,,,,MAPREDUCE-279,https://issues.apache.org/jira/browse/MAPREDUCE-2639
MAPREDUCE-2640,Task,Major,documentation,The maxRunningTasks property of the LimitTasksPerJob scheduler is ambiguous in its description; and must be updated,The property's entry in mapred-default.xml is like so:     There is no mention that this is a property exclusive to the LimitTasksPerJob scheduler alone. The doc ought to be updated to note that unless there's a plan of reusing such a property (I do not see fair or capacity schedulers utilizing this; and they use their own configs).,Resolved,Not A Problem,,Harsh J,Harsh J,Mon; 4 Jul 2011 06:44:46 +0000,Mon; 9 Jan 2012 09:56:36 +0000,Mon; 9 Jan 2012 09:56:35 +0000,,0.20.2,doc,,,https://issues.apache.org/jira/browse/MAPREDUCE-2640
MAPREDUCE-2641,Sub-task,Minor,mrv2,Fix the ExponentiallySmoothedTaskRuntimeEstimator and its unit test,Fixed the ExponentiallySmoothedTaskRuntimeEstimator so that it can run and pass the test defined for it in TestRuntimeEstimators.,Closed,Fixed,,Josh Wills,Josh Wills,Tue; 5 Jul 2011 15:13:45 +0000,Tue; 15 Nov 2011 00:50:18 +0000,Tue; 2 Aug 2011 03:57:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2641
MAPREDUCE-2642,Sub-task,Minor,mrv2,Fix two bugs in v2.app.speculate.DataStatistics,Fixes two bugs in DataStatistics: a divide by zero in the variance calculation when count == 0; and a synchronization issue in how the updateStatistics method was implemented.,Resolved,Fixed,,Josh Wills,Josh Wills,Tue; 5 Jul 2011 15:16:59 +0000,Wed; 11 Apr 2012 04:54:44 +0000,Sat; 13 Aug 2011 07:24:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2642
MAPREDUCE-2643,Sub-task,Minor,documentation;mrv2,Fixing typos/formatting/null checking in v2.app.speculate package,No functional changes in this patch: just fixing some typos in the comments; fixing some formatting issues; renaming classes for consistency; and making the null checking around Jobs Tasks more consistent.,Open,Unresolved,,Josh Wills,Josh Wills,Tue; 5 Jul 2011 15:21:40 +0000,Mon; 9 Mar 2015 23:15:12 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2643
MAPREDUCE-2644,Bug,Major,mrv2,NodeManager fails to create containers when NM_LOG_DIR is not explicitly set in the Configuration,If the yarn configuration does not explicitly specify a value for the yarn.server.nodemanager.log.dir property; container allocation will fail on the NodeManager w c it's annoying to bump into it when you're getting your first MRv2 cluster up and running.,Closed,Fixed,,Josh Wills,Josh Wills,Wed; 6 Jul 2011 01:45:53 +0000,Tue; 15 Nov 2011 00:49:16 +0000,Wed; 13 Jul 2011 04:05:00 +0000,,,,,MAPREDUCE-279,https://issues.apache.org/jira/browse/MAPREDUCE-2644
MAPREDUCE-2645,Bug,Major,mrv2,Updates to MRv2 INSTALL documentation,There are a few issues w the current INSTALL document for MRv2 that I came across when I attempted to get it running:  1) Correct the mvn arg for skipping tests; 2) Add a step to start the yarn historyserver; 3) Add instructions to explicitly build the examples jar file and specify the mapreduce.clientfactory.class.name parameter correctly for MRv2.,Resolved,Fixed,,Josh Wills,Josh Wills,Wed; 6 Jul 2011 01:51:14 +0000,Thu; 7 Jul 2011 13:46:17 +0000,Thu; 7 Jul 2011 13:02:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2645
MAPREDUCE-2646,Bug,Critical,applicationmaster;mrv2,MR-279: AM with same sized maps and reduces hangs in presence of failing maps,Currently AM can assign a container given by RM to any map or reduce. However RM allocates for a particular priority. This leads to AM and RM data structures going out of sync.,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Wed; 6 Jul 2011 05:40:42 +0000,Tue; 15 Nov 2011 00:48:37 +0000,Mon; 26 Sep 2011 13:29:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2646
MAPREDUCE-2647,New Feature,Major,tasktracker,Memory sharing across all the Tasks in the Task Tracker to improve the job performance,"If all the tasks (maps reducers can this API for reading the data from the main memory.    Example:  	Suppose in a map task; ip address is a key and it needs to get location of the ip address from a local file. In this case each map task should load the file into main memory and read from it and close it. It takes some time to open; read from the file and process every time. Instead of this; we can load the file in the task tracker memory and each task can read from the memory directly.",Resolved,Won't Fix,,Devaraj K,Devaraj K,Wed; 6 Jul 2011 10:59:14 +0000,Thu; 12 Feb 2015 10:18:51 +0000,Thu; 12 Feb 2015 10:18:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2647
MAPREDUCE-2648,New Feature,Major,,High Availability for JobTracker,In Hadoop cluster; JobTracker is responsible for managing the life cycle of MapReduce jobs. If JobTracker fails; then MapReduce service will not be available until JobTracker is restarted. We propose an automatic failover solution for JobTracker to address such single point of failure. It is based on Leader Election Framework suggested in ZOOKEEPER-1080  Please refer to attached document.,Resolved,Won't Fix,,Unassigned,Devaraj K,Wed; 6 Jul 2011 14:42:15 +0000,Wed; 30 Jul 2014 17:05:55 +0000,Wed; 30 Jul 2014 17:05:55 +0000,,,,ZOOKEEPER-1080,MAPREDUCE-2288,https://issues.apache.org/jira/browse/MAPREDUCE-2648
MAPREDUCE-2649,Bug,Major,mrv2,MR279: Fate of finished Applications on RM,Today RM keeps the references of finished application for ever. Though this is not sustainable long term; it keeps the user experience saner. Users can revisit RM UI and check the status of their apps.  We need to think of purging old references yet keeping the UX sane.,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 6 Jul 2011 17:55:47 +0000,Tue; 15 Nov 2011 00:48:06 +0000,Tue; 23 Aug 2011 01:32:51 +0000,,,,,MAPREDUCE-2941;MAPREDUCE-2953,https://issues.apache.org/jira/browse/MAPREDUCE-2649
MAPREDUCE-2650,Bug,Major,,back-port MAPREDUCE-2238 to 0.20-security,Dev had seen the attempt directory permission getting set to 000 or 111 in the CI builds and tests run on dev desktops with 0.20-security. MAPREDUCE-2238 reported and fixed the issue for 0.22.0; back-port to 0.20-security is needed.,Closed,Fixed,,Sherry Chen,Sherry Chen,Wed; 6 Jul 2011 21:18:09 +0000,Wed; 19 Oct 2011 00:26:02 +0000,Fri; 29 Jul 2011 07:53:22 +0000,,0.20.2;0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2650
MAPREDUCE-2651,Bug,Major,task-controller,Race condition in Linux Task Controller for job log directory creation,There is a rare race condition in linux task controller when concurrent task processes tries to create job log directory at the same time.,Closed,Fixed,,Bharath Mundlapudi,Bharath Mundlapudi,Wed; 6 Jul 2011 23:09:56 +0000,Tue; 5 Jun 2012 13:53:45 +0000,Tue; 26 Jul 2011 23:16:33 +0000,,0.20.204.0,,,MAPREDUCE-2657,https://issues.apache.org/jira/browse/MAPREDUCE-2651
MAPREDUCE-2652,Bug,Major,mrv2,MR-279: Cannot run multiple NMs on a single node ,"Currently in MR-279 the Auxiliary services; like ShuffleHandler; have no way to communicate information back to the applications.  Because of this the Map Reduce Application Master has hardcoded in a port of 8080 for shuffle.  This prevents the configuration ""mapreduce.shuffle.port"" form ever being set to anything but 8080.  The code should be updated to allow this information to be returned to the application master.  Also the data needs to be persisted to the task log so that on restart the data is not lost.",Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 7 Jul 2011 13:53:18 +0000,Tue; 15 Nov 2011 00:50:02 +0000,Wed; 31 Aug 2011 14:08:15 +0000,,0.23.0,,,MAPREDUCE-2750;MAPREDUCE-2947,https://issues.apache.org/jira/browse/MAPREDUCE-2652
MAPREDUCE-2653,Improvement,Major,jobtracker;tasktracker,dynamic map slots (in addition to predifined) on each node which allows to execute cpu intensive jobs along with memory intensive jobs thereby reducing wastage of cpu cycles,I have introduced process monitoring system inside tasktracker; which analyses the cpu and memory utilization of each map task and allows me to increase decrease maximum number of map slots dynamically on each node. With this I can combine cpu intensive jobs along with memory intensive jobs; thereby reducing the cpu idle time.,Open,Unresolved,,Unassigned,nandan,Thu; 7 Jul 2011 15:53:38 +0000,Wed; 24 Aug 2011 05:58:12 +0000,,,0.20.203.0,map;scheduler;tasks,,,https://issues.apache.org/jira/browse/MAPREDUCE-2653
MAPREDUCE-2654,Bug,Major,jobtracker,Missing events in Job History,nan,Open,Unresolved,,Unassigned,Keren Ouaknine,Thu; 7 Jul 2011 11:16:14 +0000,Tue; 12 Jul 2011 22:58:26 +0000,,,0.21.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-2654
MAPREDUCE-2655,Bug,Major,mrv2,MR279: Audit logs for YARN ,"We need audit logs for YARN components:  ResourceManager:  	All the refresh* protocol access points - refreshQueues; refreshNodes; refreshProxyUsers; refreshUserToGroupMappings. 	All app-submissions; app-kills to RM. 	Illegal and successful AM registrations. 	Illegal container allocations deallocations from AMs too?    NodeManager:  	Illegal container launches from AMs 	Successful container launches from AMs too?    Not sure if we need audit logs from MR AMs.",Closed,Fixed,,Thomas Graves,Thomas Graves,Thu; 7 Jul 2011 18:30:49 +0000,Fri; 11 May 2012 16:04:05 +0000,Wed; 7 Sep 2011 01:27:37 +0000,,0.23.0,,,MAPREDUCE-2942;HADOOP-8392,https://issues.apache.org/jira/browse/MAPREDUCE-2655
MAPREDUCE-2656,Sub-task,Major,,Map Reduce Tasks are continously failing; when one among the several harddisks available on the TaskTracker fails.,1. Pull out one hard disk from Task tracker node (out of 10 disks pull one). Now it is noted that some jobs are failing.  However process is continued.  2. Wait for sometime (15 mins) and pull out one disk from another Task tracker.  3. More number of jobs failed now and it can be seen from UI. Process is getting paused.  The exception can be seen in the job tracker UI for a failed job.      Task Tracker log can be seen here :      This seems to be fixed in the trunk.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Thu; 3 Feb 2011 15:51:59 +0000,Fri; 9 Sep 2011 04:55:56 +0000,Fri; 9 Sep 2011 04:55:56 +0000,,0.20.2;0.20.3,,,MAPREDUCE-2657,https://issues.apache.org/jira/browse/MAPREDUCE-2656
MAPREDUCE-2657,New Feature,Major,tasktracker,TaskTracker should handle disk failures,Umbrella for TaskTracker disk failure handling jiras.,Open,Unresolved,,Unassigned,Bharath Mundlapudi,Fri; 28 Jan 2011 21:05:14 +0000,Thu; 8 Sep 2011 21:11:53 +0000,,,0.20.203.0,,,MAPREDUCE-2656;MAPREDUCE-2651;HADOOP-7551,https://issues.apache.org/jira/browse/MAPREDUCE-2657
MAPREDUCE-2658,Bug,Major,mrv2,Problem running full map & reduce jobs on mrv2,"Following the installation instructions  org.apache.hadoop.mapred.YarnChild.main(YarnChild. 143)  The ReduceTask evaluates the isLocal flag based on the property ""mapreduce.jobtracker.address""; the default value for this property in mapred-default.xml is 'local' and this is the cause of the problem.  Setting ""mapreduce.jobtracker.address"" in the mapred-site.xml to something other than ""local"" seems to solve the problem.",Resolved,Duplicate,MAPREDUCE-3004,Ahmed Radwan,Ahmed Radwan,Thu; 7 Jul 2011 20:51:22 +0000,Thu; 22 Sep 2011 21:27:59 +0000,Thu; 22 Sep 2011 21:25:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2658
MAPREDUCE-2659,Improvement,Major,mrv2,MR-279: ShuffleHandler should use Protocol Buffers for ServiceData,Auxiliary Services (Specifically ShuffleHandler) should use ProtocolBuffers for storing retrieving data in the ByteBuffer.  Right now there are TODOs to have the format include a version number; but if we want true wire compatibility we should use the same system we are using elsewhere in the code for messages; not something invented as we go along.,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Thu; 7 Jul 2011 21:26:21 +0000,Mon; 9 Mar 2015 21:34:37 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2659
MAPREDUCE-2660,Bug,Major,,MR-279: org.apache.hadoop.mapred.CombineFileInputFormat.getSplits() throws ArrayStoreException,In branch MR-279; org.apache.hadoop.mapred.getSplits() throws RuntimeException:ArrayStoreException   The following code in trunk:    got changed to     Code in trunk works fine. We should change the code in MR-279 to the same in trunk.,Resolved,Duplicate,MAPREDUCE-2571,Amareshwari Sriramadasu,Amareshwari Sriramadasu,Fri; 8 Jul 2011 05:28:25 +0000,Wed; 13 Jul 2011 04:36:31 +0000,Tue; 12 Jul 2011 11:13:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2660
MAPREDUCE-2661,Bug,Minor,mrv2,MR-279: Accessing MapTaskImpl from TaskImpl,We are directly accessing MapTaskImpl in TaskImpl.InitialScheduleTransition.transition(..). It'll be better to reorganize the code so each subclass can provide its own behavior instead of explicitly checking for the subclass type.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Fri; 8 Jul 2011 05:43:18 +0000,Tue; 15 Nov 2011 00:48:37 +0000,Tue; 19 Jul 2011 07:42:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2661
MAPREDUCE-2662,Improvement,Major,,Gridmix v3 should bailout in cpu emulation ON; if a trace doesn't contains the cpu resource usage information.,If a trace doesn't contains the cpu resource usage information and user tries to run the Gridmix v3 with CPU emulation ON; it should bailout saying trace doesn't support cpu emulation.   It's applicable even for memory emulation feature also. So while fixing this; consider memory emulation also.,Open,Unresolved,,Amar Kamat,Vinay Kumar Thota,Fri; 8 Jul 2011 09:42:59 +0000,Mon; 11 Jul 2011 05:45:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2662
MAPREDUCE-2663,Bug,Minor,mrv2,MR-279: Refactoring StateMachineFactory inner classes,The code for ApplicableSingleTransition and ApplicableMultipleTransition inner classes is almost identical. For maintainability; it is better to refactor them into a single inner class.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Fri; 8 Jul 2011 11:20:03 +0000,Tue; 15 Nov 2011 00:49:01 +0000,Tue; 12 Jul 2011 22:05:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2663
MAPREDUCE-2664,Improvement,Major,mrv2,MR 279: Implement JobCounters for MRv2 + Fix for Map Data Locality,MRv2 is currently not setting any Job Counters.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 8 Jul 2011 17:14:10 +0000,Tue; 15 Nov 2011 00:48:16 +0000,Tue; 26 Jul 2011 06:41:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2664
MAPREDUCE-2665,Bug,Minor,mrv2,MR-279: Add hostname:port to NM and RM info/about page,Adding host port information to the RM NM info about pages,Resolved,Won't Fix,,Jonathan Eagles,Jonathan Eagles,Fri; 8 Jul 2011 20:19:21 +0000,Mon; 11 Jul 2011 15:13:23 +0000,Mon; 11 Jul 2011 15:13:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2665
MAPREDUCE-2666,Sub-task,Blocker,mrv2,MR-279: Need to retrieve shuffle port number on ApplicationMaster restart,MAPREDUCE-2652 allows ShuffleHandler to return the port it is operating on.  In the case of an ApplicationMaster crash where it needs to be restarted that information is lost.  We either need to re-query it from each of the NodeManagers or to persist it to the JobHistory logs and retrieve it again.  The job history logs is probably the simpler solution.,Closed,Fixed,,Jonathan Eagles,Robert Joseph Evans,Fri; 8 Jul 2011 20:44:22 +0000,Tue; 15 Nov 2011 00:48:18 +0000,Wed; 12 Oct 2011 23:13:04 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2666
MAPREDUCE-2667,Bug,Major,mrv2,MR279: mapred job -kill leaves application in RUNNING state,the mapred job -kill command doesn't seem to fully clean up the application.  If you kill a job and run mapred job -list again it still shows up as running:  mapred job -kill job_1310072430717_0003 Killed job job_1310072430717_0003   mapred job -list Total jobs:1 JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo job_1310072430717_0003  RUNNING 0       tgraves default NORMAL  98.139.92.22:19888 job_1310072430717_3_3  Running kill again will error out.  It also still shows up in the RM Applications UI as running with a note of: Kill Job received from client job_1310072430717_0003 Job received Kill while in RUNNING state.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 8 Jul 2011 21:20:06 +0000,Tue; 15 Nov 2011 00:48:50 +0000,Mon; 25 Jul 2011 04:30:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2667
MAPREDUCE-2668,Bug,Blocker,mrv2,MR-279: APPLICATION_STOP is never sent to AuxServices,APPLICATION_STOP is never sent to the AuxServices only APPLICATION_INIT.  This means that all map intermediate data will never be deleted.,Closed,Fixed,,Thomas Graves,Robert Joseph Evans,Mon; 11 Jul 2011 18:10:57 +0000,Tue; 25 Jun 2013 14:26:09 +0000,Tue; 11 Oct 2011 14:30:15 +0000,,0.23.0,,,YARN-886;MAPREDUCE-5329,https://issues.apache.org/jira/browse/MAPREDUCE-2668
MAPREDUCE-2669,Test,Minor,examples,Some new examples and test cases for them.,Looking to add some more examples such as Mean; Median; and Standard Deviation to the examples. I have some generic JUnit testcases as well.,Resolved,Fixed,,Plamen Jeliazkov,Plamen Jeliazkov,Mon; 11 Jul 2011 21:44:01 +0000,Thu; 12 May 2016 18:23:20 +0000,Mon; 12 Sep 2011 19:14:23 +0000,,0.22.0,,,MAPREDUCE-4981,https://issues.apache.org/jira/browse/MAPREDUCE-2669
MAPREDUCE-2670,Bug,Trivial,,Fixing spelling mistake in FairSchedulerServlet.java,Admininstration is misspelled.,Closed,Fixed,,Eli Collins,Eli Collins,Tue; 12 Jul 2011 01:41:39 +0000,Tue; 15 Nov 2011 00:48:30 +0000,Wed; 13 Jul 2011 21:17:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2670
MAPREDUCE-2671,Bug,Minor,mrv2,MR-279: Package examples; tools; test jars with the build,Jars such as examples; tools; test; streaming; gridmix has to be packaged as a part of the MR-279 builds https: ,Resolved,Fixed,,Giridharan Kesavan,Ramya Sunil,Tue; 12 Jul 2011 02:35:27 +0000,Tue; 10 Mar 2015 01:21:25 +0000,Tue; 10 Mar 2015 01:21:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2671
MAPREDUCE-2672,Improvement,Major,mrv2,MR-279: JobHistory Server needs Analysis this job,The JobHistory Server needs to implement the Analysis this job functionality from the previous server.  This should include the following info Hadoop Job ID  User :  JobName :  JobConf :  Submitted At :  Launched At :  (including duration) Finished At :  (including duration) Status :  Time taken by best performing Map task TASK_LINK: Average time taken by Map tasks: Worse performing map tasks: (including task links and duration) The last Map task TASK_LINK finished at (relative to the Job launch time):  (including duration)  Time taken by best performing shuffle TASK_LINK: Average time taken by shuffle: Worse performing Shuffles: (including task links and duration) The last Shuffle TASK_LINK finished at (relative to the Job launch time):  (including duration)  Time taken by best performing Reduce task TASK_LINK: Average time taken by Reduce tasks: Worse performing reduce tasks: (including task links and duration) The last Reduce task TASK_LINK finished at (relative to the Job launch time):  (including duration),Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 12 Jul 2011 15:42:27 +0000,Mon; 16 Mar 2015 17:57:14 +0000,Thu; 15 Sep 2011 22:23:44 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2672
MAPREDUCE-2673,Improvement,Minor,mrv2,MR-279: JobHistory Server should not refresh,The Job History Server UI is based off of the Application Master UI; which refreshes the page for jobs regularly.  The page should not refresh at all for the JobHistroy; because the job has finished and is not changing.,Closed,Duplicate,MAPREDUCE-2473,Robert Joseph Evans,Robert Joseph Evans,Tue; 12 Jul 2011 15:47:13 +0000,Tue; 15 Nov 2011 00:48:52 +0000,Mon; 19 Sep 2011 19:15:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2673
MAPREDUCE-2674,Improvement,Minor,mrv2,MR-279: JobHistory Server should not use tables for layout,The Job History Server web pages use table tags for the layout of the various elements on the page.  This is not a very maintainable way of laying out a web page.  The ideal is to let CSS do all of the layout and have the document itself just have data in it.  This is especially important because there are currently no APIs to pull some of this data out; and as such there are tools; that scrape these pages.  If we can separate out the layout then even when the layout changes the scrapers will not be impacted.   This should probably be investigated in the rest of the UI too.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Tue; 12 Jul 2011 16:07:56 +0000,Tue; 12 Jul 2011 16:07:56 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2674
MAPREDUCE-2675,Improvement,Major,mrv2,MR-279: JobHistory Server main page needs to be reformatted,"The main page of the Job History Server is based off of the Application Master code.  It needs to be reformatted to be more useful and better match what was there before.   	The Active Jobs title needs to be replaced with something more appropriate (i.e. Retired Jobs) 	The table of jobs should have the following columns in it 	Submit time; Job Id; Job Name; User and just because I think it would be useful state; maps completed; maps failed; reduces completed; reduces failed 	The table needs more advanced filtering; something like http: multi_filter.html This is to match the previous search functionality.",Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 12 Jul 2011 16:25:46 +0000,Thu; 2 May 2013 02:29:42 +0000,Mon; 12 Sep 2011 14:28:22 +0000,,0.23.0,,MAPREDUCE-2677;MAPREDUCE-2701,,https://issues.apache.org/jira/browse/MAPREDUCE-2675
MAPREDUCE-2676,Improvement,Major,mrv2,MR-279: JobHistory Job page needs reformatted,The Job page; The Maps page and the Reduces page for the job history server needs to be reformatted.  The Job Overview needs to add in the User; a link to the Job Conf; and the Job ACLs It also needs Submitted at; launched at; and finished at; depending on how they relates to Started and Elapsed.  In the attempts table we need to remove the new and the running columns In the tasks table we need to remove progress; pending; and running columns and add in a failed count column We also need to investigate what it would take to add in setup and cleanup statistics.  Perhaps these should be more generally Application Master statistics and links.  The Maps page and Reduces page should have the progress column removed.,Closed,Fixed,MAPREDUCE-2982,Robert Joseph Evans,Robert Joseph Evans,Tue; 12 Jul 2011 16:51:38 +0000,Mon; 16 Mar 2015 17:57:12 +0000,Tue; 13 Sep 2011 22:59:24 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-3037,https://issues.apache.org/jira/browse/MAPREDUCE-2676
MAPREDUCE-2677,Bug,Major,mrv2,MR-279: 404 error while accessing pages from history server,Accessing the following pages from the history server; causes 404 HTTP error 1. Cluster- About  2. Cluster - Applications 3. Cluster - Scheduler 4. Application - About,Closed,Fixed,,Robert Joseph Evans,Ramya Sunil,Tue; 12 Jul 2011 21:37:36 +0000,Tue; 15 Nov 2011 00:50:14 +0000,Thu; 8 Sep 2011 21:09:20 +0000,,0.23.0,,MAPREDUCE-2675,,https://issues.apache.org/jira/browse/MAPREDUCE-2677
MAPREDUCE-2678,Bug,Major,capacity-sched,MR-279: minimum-user-limit-percent no longer honored,MR-279: In the capacity-scheduler.xml configuration; the 'minimum-user-limit-percent' property is no longer honored.,Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Tue; 12 Jul 2011 21:51:18 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Wed; 13 Jul 2011 00:32:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2678
MAPREDUCE-2679,Improvement,Trivial,,MR-279: Merge MR-279 related minor patches into trunk,Jira to track very minor and misc. changes to trunk for MR-279,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 12 Jul 2011 23:08:17 +0000,Tue; 15 Nov 2011 00:48:48 +0000,Wed; 13 Jul 2011 06:04:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2679
MAPREDUCE-2680,Improvement,Minor,,Enhance job-client cli to show queue information for running jobs,It'd be very useful to display queue-information for running jobs alongwith jobid; user; start-time etc.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 13 Jul 2011 00:22:22 +0000,Tue; 15 Nov 2011 00:49:43 +0000,Wed; 13 Jul 2011 06:04:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2680
MAPREDUCE-2681,Improvement,Major,,Change pipes to use env vars for stdout/stderr files,Change pipes to use env vars for stdout stderr files; currently they are hard-coded. This is important for MAPREDUCE-279.,Open,Unresolved,,Vinod Kumar Vavilapalli,Arun C Murthy,Wed; 13 Jul 2011 06:27:01 +0000,Tue; 10 Mar 2015 01:42:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2681
MAPREDUCE-2682,Improvement,Trivial,,Add a -classpath option to bin/mapred,We should have a bin mapred classpath switch; MR-279 uses this in the branch.,Closed,Fixed,,Vinod Kumar Vavilapalli,Arun C Murthy,Wed; 13 Jul 2011 07:02:47 +0000,Tue; 15 Nov 2011 00:49:27 +0000,Wed; 13 Jul 2011 07:18:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2682
MAPREDUCE-2683,Bug,Major,tasktracker,some tasktracker crash,"I run a test program. tasktracker in some slave machine crash. crashed tasktracker is slave1 and salve4. slave2 and slave3 work well.   master	 version ""1.6.0_17"" 						Java(TM) SE Runtime Environment (build 1.6.0_17-b04) 						Java HotSpot(TM) Server VM (build 14.3-b01; mixed mode)",Open,Unresolved,,Unassigned,yangtao,Wed; 13 Jul 2011 09:58:49 +0000,Wed; 13 Jul 2011 10:43:54 +0000,,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2683
MAPREDUCE-2684,Bug,Major,jobtracker,Job Tracker can starve reduces with very large input.,If mapreduce.reduce.input.limit is mis-configured or if a cluster is just running low on disk space in general then reduces with large a input may never get scheduled causing the Job to never fail and never succeed; just starve until the job is killed.  The JobInProgess tries to guess at the size of the input to all reducers in a job.  If the size is over mapreduce.reduce.input.limit then the job is killed.  If it is not then findNewReduceTask() checks to see if the estimated size is too big to fit on the node currently looking for work.  If it is not then it will let some other task have a chance at the slot.  The idea is to keep track of how often it happens that a Reduce Slot is rejected because of the lack of space vs how often it succeeds and then guess if the reduce tasks will ever be scheduled.  So I would like some feedback on this.  1) How should we guess.  Someone who found the bug here suggested P1 + (P2 * S); where S is the number of successful assignments.  Possibly P1 = 20 and P2 = 2.0.  I am not really sure. 2) What should we do when we guess that it will never get a slot?  Should we fail the job or do we say; even though it might fail; well lets just schedule the it and see if it really will fail.,Resolved,Duplicate,MAPREDUCE-2324,Robert Joseph Evans,Robert Joseph Evans,Wed; 13 Jul 2011 21:37:03 +0000,Thu; 14 Jul 2011 13:23:55 +0000,Thu; 14 Jul 2011 13:23:55 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2684
MAPREDUCE-2685,Bug,Major,,Hadoop-Mapreduce-trunk build is failing,Hadoop-Mapreduce-trunk has been failing for long time.   https:   org.apache.hadoop.cli.TestMRCLI.testAll is failing since Build #697    org.apache.hadoop.fs.TestFileSystem.testCommandFormat is failing since Build #702    org.apache.hadoop.mapred.TestNodeRefresh.testBlacklistedNodeDecommissioning,Resolved,Not A Problem,,Unassigned,Devaraj K,Thu; 14 Jul 2011 15:22:34 +0000,Mon; 22 Aug 2011 14:51:05 +0000,Mon; 22 Aug 2011 14:51:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2685
MAPREDUCE-2686,Bug,Blocker,mrv2,NPE while requesting info for a non-existing job,"While performing job related operations such as job -kill; -status; -events etc for an unknown job; the following NPE is seen:  Exception in thread ""main""  1074)",Closed,Duplicate,MAPREDUCE-2925,Siddharth Seth,Ramya Sunil,Thu; 14 Jul 2011 17:46:08 +0000,Tue; 15 Nov 2011 00:50:03 +0000,Mon; 19 Sep 2011 08:14:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2686
MAPREDUCE-2687,Bug,Blocker,mrv2,Non superusers unable to launch apps in both secure and non-secure cluster,Apps of non superuser fail to succeed in both secure and non-secure environment. Only the superuser(i.e. one who started owns the mrv2 cluster) is able to launch apps successfully. However; when a normal user submits a job; the job fails.,Closed,Fixed,,Mahadev konar,Ramya Sunil,Fri; 15 Jul 2011 17:12:47 +0000,Thu; 2 May 2013 02:29:44 +0000,Tue; 6 Sep 2011 21:51:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2687
MAPREDUCE-2688,Bug,Major,,rpm should only require the same major version as common and hdfs,The rpm should only require the same version of common and hdfs be installed.,Closed,Duplicate,HDFS-2156,Unassigned,Owen O'Malley,Fri; 15 Jul 2011 17:49:26 +0000,Tue; 15 Nov 2011 00:48:09 +0000,Thu; 21 Jul 2011 19:17:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2688
MAPREDUCE-2689,Bug,Major,mrv2,InvalidStateTransisiton when AM is not assigned to a job,In cases where an AM is not being assigned to a job; RELEASED at COMPLETED invalid event is observed. This is easily reproducible in cases such as MAPREDUCE-2687.,Closed,Fixed,,Unassigned,Ramya Sunil,Fri; 15 Jul 2011 18:21:55 +0000,Tue; 15 Nov 2011 00:50:06 +0000,Wed; 10 Aug 2011 20:26:21 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2689
MAPREDUCE-2690,Bug,Major,mrv2,Construct the web page for default scheduler,"Currently; the web page for default scheduler reads as ""Under construction"". This is a long known issue; but could not find a tracking ticket. Hence opening one.",Closed,Fixed,,Eric Payne,Ramya Sunil,Fri; 15 Jul 2011 18:45:25 +0000,Tue; 15 Nov 2011 00:48:05 +0000,Fri; 9 Sep 2011 02:06:06 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2690
MAPREDUCE-2691,Improvement,Major,mrv2,Finish up the cleanup of distributed cache file resources and related tests.,Implement cleanup of distributed cache file resources,Closed,Fixed,,Siddharth Seth,Amol Kekre,Fri; 15 Jul 2011 21:47:21 +0000,Mon; 16 Mar 2015 17:57:17 +0000,Sun; 11 Sep 2011 06:29:17 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2691
MAPREDUCE-2692,New Feature,Major,mrv2,Ensure AM Restart and Recovery-on-restart is complete,Need to get AM restart and the subsequent recover after restart to work,Closed,Fixed,,Sharad Agarwal,Amol Kekre,Fri; 15 Jul 2011 22:12:04 +0000,Tue; 15 Nov 2011 00:49:26 +0000,Mon; 31 Oct 2011 04:47:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2692
MAPREDUCE-2693,Bug,Critical,mrv2,NPE in AM causes it to lose containers which are never returned back to RM,The following exception in AM of an application   619),Closed,Fixed,MAPREDUCE-3234,Hitesh Shah,Amol Kekre,Fri; 15 Jul 2011 22:33:56 +0000,Tue; 15 Nov 2011 00:48:30 +0000,Wed; 19 Oct 2011 22:03:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2693
YARN-110,Bug,Major,resourcemanager;scheduler,AM releases too many containers due to the protocol,"AM sends request asking 4 containers on host H1. 	Asynchronously; host H1 reaches RM and gets assigned 4 containers. RM at this point; sets the value against H1 to zero in its aggregate request-table for all apps. 	In the mean-while AM gets to need 3 more containers; so a total of 7 including the 4 from previous request. 	Today; AM sends the absolute number of 7 against H1 to RM as part of its request table. 	RM seems to be overriding its earlier value of zero against H1 to 7 against H1. And thus allocating 7 more containers. 	AM already gets 4 in this scheduling iteration; but gets 7 more; a total of 11 instead of the required 7.",Open,Unresolved,,Arun C Murthy,Arun C Murthy,Fri; 15 Jul 2011 22:39:02 +0000,Tue; 7 Jun 2016 13:47:03 +0000,,,,,,YARN-4879;YARN-1902;MAPREDUCE-4671,https://issues.apache.org/jira/browse/YARN-110
MAPREDUCE-2695,Bug,Blocker,mrv2,Unhealthy nodes (health-script) are still being assigned containers,Unhealthy nodes (health-script) are still being assigned containers,Closed,Invalid,,Vinod Kumar Vavilapalli,Arun C Murthy,Fri; 15 Jul 2011 23:12:15 +0000,Tue; 15 Nov 2011 00:49:20 +0000,Mon; 19 Sep 2011 07:58:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2695
MAPREDUCE-2696,Sub-task,Major,mrv2;nodemanager,Container logs aren't getting cleaned up when LogAggregation is disabled,Container logs aren't getting cleaned up when log-aggregation is disabled.,Closed,Fixed,,Siddharth Seth,Arun C Murthy,Fri; 15 Jul 2011 23:21:00 +0000,Tue; 15 Nov 2011 00:48:49 +0000,Mon; 31 Oct 2011 10:18:42 +0000,,0.23.0,,MAPREDUCE-3146,,https://issues.apache.org/jira/browse/MAPREDUCE-2696
MAPREDUCE-2697,Bug,Major,mrv2,Enhance CS to cap concurrently running jobs,Enhance CS to cap concurrently running jobs ala 0.20.203,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 15 Jul 2011 23:24:30 +0000,Tue; 15 Nov 2011 00:49:59 +0000,Mon; 5 Sep 2011 19:55:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2697
MAPREDUCE-2698,Bug,Major,mrv2,Expired NM's containers aren't being communicated to AM,Expired NM's containers aren't being communicated to AM - so the AM needs to rely on timeouts. We need to fix this.,Resolved,Duplicate,NULL,Arun C Murthy,Arun C Murthy,Fri; 15 Jul 2011 23:43:36 +0000,Thu; 4 Aug 2011 10:31:41 +0000,Thu; 4 Aug 2011 10:31:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2698
MAPREDUCE-2699,Bug,Blocker,mrv2,AM crashing because of invalid TA_CONTAINER_COMPLETED event,AM crashing because of invalid TA_CONTAINER_COMPLETED event,Closed,Duplicate,MAPREDUCE-2995,Vinod Kumar Vavilapalli,Arun C Murthy,Fri; 15 Jul 2011 23:53:42 +0000,Tue; 15 Nov 2011 00:48:41 +0000,Sat; 17 Sep 2011 08:52:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2699
MAPREDUCE-2700,New Feature,Minor,job submission,dynamic configuration of mapred.map/reduce.tasks,Since the optimal value for these 2 configuration properties heavily depends on the numer of nodes; also examined here http: HowManyMapsAndReduces  would it be not more comfortable to configure relations to numberOfNodes ? So you hav'nt to change it all the time the number of nodes changes...,Open,Unresolved,,Unassigned,Johannes Zillmann,Tue; 17 Oct 2006 15:39:00 +0000,Mon; 16 Jan 2012 10:08:57 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2700
MAPREDUCE-2701,Improvement,Major,mrv2,MR-279: app/Job.java needs UGI for the user that launched it,.  is missing some data that is needed by the Job History GUI.  It needs the UGI for the user that launched it.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Sat; 16 Jul 2011 20:13:03 +0000,Tue; 15 Nov 2011 00:48:35 +0000,Mon; 22 Aug 2011 19:38:34 +0000,,0.23.0,,MAPREDUCE-2675,,https://issues.apache.org/jira/browse/MAPREDUCE-2701
MAPREDUCE-2702,Sub-task,Blocker,applicationmaster;mrv2,[MR-279] OutputCommitter changes for MR Application Master recovery,In MR AM recovers from a crash; it only reruns the non completed tasks. The completed tasks (along with their output; if any) needs to be recovered from the previous life. This would require some changes in OutputCommitter.,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Sun; 17 Jul 2011 10:14:31 +0000,Tue; 15 Nov 2011 00:49:02 +0000,Wed; 5 Oct 2011 12:18:01 +0000,,0.23.0,,MAPREDUCE-2708,,https://issues.apache.org/jira/browse/MAPREDUCE-2702
MAPREDUCE-2703,Task,Trivial,distcp;documentation,Add a doc note about changes to io.sort.mb and io.sort.factor config params for SequenceFile sorting in DistCp,Carrying over work from MAPREDUCE-2622 and HADOOP-6801 that impacts how sequencefiles will utilize the now deprecated io.sort.mb and io.sort.factor configs (new configs are made available for it to use; see HADOOP-6801). Since DistCp is the remaining lone framework user of SequenceFile.Sorter; it will require additions to docs about new properties to control.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 17 Jul 2011 17:32:50 +0000,Sat; 12 May 2012 12:04:10 +0000,Sun; 18 Dec 2011 11:03:45 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2703
MAPREDUCE-2704,Bug,Major,,CombineFileInputFormat only works when paths are on the default filesystem,"CombineFileInputFormat constructs new Path objects by converting an existing path to a URI; and then only pulling out the ""path"" part of it. This drops the scheme and host; which makes CombineFileInputFormat fail if the paths are on a filesystem other than the default one.",Resolved,Duplicate,MAPREDUCE-1806,Unassigned,Todd Lipcon,Mon; 18 Jul 2011 03:47:26 +0000,Wed; 19 Sep 2012 19:28:52 +0000,Wed; 19 Sep 2012 19:28:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2704
MAPREDUCE-2705,Bug,Major,tasktracker,tasks localized and launched serially by TaskLauncher - causing other tasks to be delayed,The current TaskLauncher serially launches new tasks one at a time. During the launch it does the localization and then starts the map reduce task.  This can cause any other tasks to be blocked waiting for the current task to be localized and started. In some instances we have seen a task that has a large file to localize (1.2MB) block another task for about 40 minutes. This particular task being blocked was a cleanup task which caused the job to be delayed finishing for the 40 minutes.,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 18 Jul 2011 19:40:33 +0000,Wed; 19 Oct 2011 00:26:12 +0000,Thu; 4 Aug 2011 01:33:12 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2705
MAPREDUCE-2706,Bug,Major,mrv2,MR-279: Submit jobs beyond the max jobs per queue limit no longer gets logged,Submitting jobs over the queue limits used to print log messages such as these: hadoop-mapred-jobtracker-HOSTNAME.log. ... INFO org.apache.hadoop.mapred.CapacityTaskScheduler: default has 10 active tasks for user MYUSER; cannot initialize job_XXX with 10 tasks since it will exceed limit of 15 active tasks per user for this queue and hadoop-mapred-jobtracker-HOSTNAME.log ... INFO org.apache.hadoop.mapred.CapacityTaskScheduler: default already has 2 running jobs and 0 initializing jobs; cannot initialize job_XXX since it will exceeed limit of 2 initialized jobs for this queue  These log messages are useful - especially for QA and testing.,Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Mon; 18 Jul 2011 20:16:33 +0000,Tue; 15 Nov 2011 00:49:57 +0000,Wed; 10 Aug 2011 23:32:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2706
MAPREDUCE-2707,Improvement,Major,,ProtoOverHadoopRpcEngine without using TunnelProtocol over WritableRpc,ProtoOverHadoopRpcEngine is introduced in MR-279; which uses TunnelProtocol over WritableRpcEngine. This jira removes the tunnel protocol and lets ProtoOverHadoopRpcEngine directly interact with ipc.Client and ipc.Server.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Mon; 18 Jul 2011 21:32:09 +0000,Tue; 15 Nov 2011 00:48:23 +0000,Fri; 29 Jul 2011 06:49:55 +0000,,,,HADOOP-7474,,https://issues.apache.org/jira/browse/MAPREDUCE-2707
MAPREDUCE-2708,Sub-task,Blocker,applicationmaster;mrv2,[MR-279] Design and implement MR Application Master recovery,Design recovery of MR AM from crashes node failures. The running job should recover from the state it left off.,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Tue; 19 Jul 2011 04:47:09 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Mon; 24 Oct 2011 08:43:18 +0000,,0.23.0,,MAPREDUCE-2702;MAPREDUCE-3233;MAPREDUCE-2807,,https://issues.apache.org/jira/browse/MAPREDUCE-2708
MAPREDUCE-2709,Test,Major,test,Test case to ensure ReflectionUtils.setConf configures the target object only once,nan,Resolved,Invalid,,Unassigned,Sudharsan Sampath,Tue; 19 Jul 2011 06:38:25 +0000,Wed; 20 Jul 2011 11:08:22 +0000,Wed; 20 Jul 2011 06:39:06 +0000,,,,HADOOP-7425,,https://issues.apache.org/jira/browse/MAPREDUCE-2709
MAPREDUCE-2710,Bug,Major,client,Update DFSClient.stringifyToken(..) in JobSubmitter.printTokens(..) for HDFS-2161,DFSClient.stringifyToken(..) was removed by HDFS-2161.  JobSubmitter.printTokens(..) won't be compiled.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 19 Jul 2011 14:04:41 +0000,Thu; 2 May 2013 02:29:42 +0000,Tue; 19 Jul 2011 16:08:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2710
MAPREDUCE-2711,Bug,Major,contrib/raid,TestBlockPlacementPolicyRaid cannot be compiled,TestBlockPlacementPolicyRaid access internal FSNamesystem directly.  It cannot be compiled after HDFS-2147.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 19 Jul 2011 15:29:33 +0000,Mon; 16 Mar 2015 17:57:14 +0000,Fri; 9 Sep 2011 05:11:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2711
MAPREDUCE-2712,Improvement,Major,contrib/streaming,add stdin to mapdebug and reducedebug scripts in streaming,The current syntax for the mapdebug and reducedebug scripts is $script $stdout $stderr $syslog $jobconf; which seems appropriate for task failure post-analysis. But it seems more than natural to want to inspect or analyze the input to see under what input the task failed; up to rerunning the task say in debug mode or with other monitoring in place. So why not make it $script $stdin $stdout $stderr $syslog $jobconf to complete the circle? See also https: MAPREDUCE-2076,Open,Unresolved,,Unassigned,Antonio Piccolboni,Tue; 19 Jul 2011 17:25:55 +0000,Fri; 14 Oct 2011 06:01:16 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2712
MAPREDUCE-2713,New Feature,Major,mrv2,Recovery of ResourceManager,ResourceManager needs to recover from crashes to the state where it left off. All running applications should be able to join back the restarted RM. All running containers should not be affected and continue to run.,Resolved,Duplicate,MAPREDUCE-4326,Mahadev konar,Sharad Agarwal,Wed; 20 Jul 2011 06:01:16 +0000,Mon; 18 Jun 2012 17:06:40 +0000,Mon; 18 Jun 2012 17:06:40 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2713
MAPREDUCE-2714,Bug,Major,,When a job is retired by the same user's another job; its jobconf file is not deleted from the log directory of the JobTracker ,After MAPREDUCE-130; the job's conf copy will be deleted from the log directory of the JobTracker when the job is retired. However; it just works if the job is retired by RetireJobs thread of JobTracker. If a job is retired by the same user's another job; its conf copy will not be deleted. This kind of retire happens in JobTracker::finalizeJob(job); when JobTracker maintains more than MAX_COMPLETE_USER_JOBS_IN_MEMORY jobs information in memory for a given user.,Resolved,Duplicate,MAPREDUCE-757,Liyin Liang,Liyin Liang,Wed; 20 Jul 2011 07:48:03 +0000,Fri; 11 Nov 2011 06:26:45 +0000,Fri; 11 Nov 2011 06:26:45 +0000,,0.20.1;0.20.2,,,MAPREDUCE-130,https://issues.apache.org/jira/browse/MAPREDUCE-2714
MAPREDUCE-2715,Bug,Major,,submitAndMonitorJob() doesn't play nice with MultipleOutputFile,"part of submitAndMonitorJob() balks if the output directory currently exists but is non-empty:    ""Error launching job ; Output path already exists : ""  this logic actually conflicts with the ideas behind MultipleOutputFile; where the output file path is calculated later on.  it would be really nice to remove the restriction for non-empty output directories in submitAndMonitorJob() so that MultipleOutputFile becomes more useful - as it stands now; I can't; for example; specify a base output path then use MutlipleOutputFile to partition by date on a daily basis.  thanks.",Resolved,Not A Problem,,Unassigned,Geoffrey Young,Wed; 20 Jul 2011 17:56:05 +0000,Wed; 27 Jul 2011 08:25:20 +0000,Wed; 27 Jul 2011 08:25:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2715
MAPREDUCE-2716,Bug,Major,mrv2,MR279: MRReliabilityTest job fails because of missing job-file.,"The ApplicationReport should have the jobFile (e.g. hdfs: job.xml)   Without it; jobs such as MRReliabilityTest fail with the following error (caused by the fact that jobFile is hardcoded to """" in TypeConverter. 192)",Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Wed; 20 Jul 2011 21:13:36 +0000,Tue; 15 Nov 2011 00:48:09 +0000,Sat; 3 Sep 2011 06:46:47 +0000,,0.23.0,,MAPREDUCE-2726,,https://issues.apache.org/jira/browse/MAPREDUCE-2716
MAPREDUCE-2717,Improvement,Blocker,mrv2,Client should be able to know why an AM crashed.,"Today if an AM crashes; we have to dig through logs - very cumbersome. It is good to have client print some reason for AM crash. Various possible reasons for AM crash:  (1) AM container failed during localization itself.  (2) AM container launched but failed before properly starting; for e.g. due to classpath issues  (3) AM failed after starting properly.  (4) an AM is expired and killed by the RM  Potential fixes:  	For (1) and (2) the client should obtain the container-status; container diagnostics and exit code. 	For (3); the AM should set some kind of reason for failure during its heartbeat to RM and the client should obtain the same from RM.",Closed,Duplicate,MAPREDUCE-3065,Anupam Seth,Amol Kekre,Wed; 20 Jul 2011 23:43:33 +0000,Tue; 15 Nov 2011 00:48:43 +0000,Thu; 22 Sep 2011 22:35:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2717
MAPREDUCE-2718,Bug,Major,mrv2,Job fails if AppMaster is killed,Started a cluster. Sumitted a sleep job with around 10000 maps and 1000 reduces. when 5000 maps got completed; It killed AppMaster. RM web UI Application as failed. And jobclient after retry for 50 times -: {  1040) },Closed,Not A Problem,,Unassigned,Amol Kekre,Thu; 21 Jul 2011 00:04:59 +0000,Tue; 15 Nov 2011 00:48:09 +0000,Fri; 16 Sep 2011 23:38:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2718
MAPREDUCE-2719,New Feature,Major,mrv2,MR-279: Write a shell command application,With nextgen hadoop (mrv2); it is simple to write non-MR applications. Write an AplicationMaster (also corresponding simple client); to submit and run a shell command application in the cluster.,Closed,Fixed,,Hitesh Shah,Sharad Agarwal,Thu; 21 Jul 2011 05:01:20 +0000,Tue; 15 Nov 2011 00:49:59 +0000,Fri; 30 Sep 2011 22:27:12 +0000,,,,,YARN-3172;MAPREDUCE-2889;MAPREDUCE-279,https://issues.apache.org/jira/browse/MAPREDUCE-2719
YARN-3172,New Feature,Major,,MR-279: Write a simple Java application,Currently for isolation purposes; many simple  app can be written which runs in the cluster in the user space.,Open,Unresolved,,Devaraj K,Sharad Agarwal,Thu; 21 Jul 2011 05:19:53 +0000,Mon; 27 Apr 2015 12:37:11 +0000,,,,,,MAPREDUCE-2719;MAPREDUCE-279,https://issues.apache.org/jira/browse/YARN-3172
MAPREDUCE-2721,Bug,Major,tasktracker,TaskTracker is calling the close () method twice unnecessarily ,When there is a version mismatch between the JobTracker and TaskTracker; TaskTracker is calling the close () method twice. Once in the finally block of run () method and also in the shutdown () method call.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Thu; 21 Jul 2011 12:18:33 +0000,Sun; 29 Jan 2012 01:59:39 +0000,Sun; 29 Jan 2012 01:59:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2721
MAPREDUCE-2722,Bug,Major,contrib/gridmix,Gridmix simulated job's map's hdfsBytesRead counter is wrong when compressed input is used,When compressed input was used by original job's map task; then the simulated job's map task's hdfsBytesRead counter is wrong if compression emulation is enabled. This issue is because hdfsBytesRead of map task of original job is considered as uncompressed map input size by Gridmix.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 22 Jul 2011 11:25:23 +0000,Wed; 3 Sep 2014 22:45:03 +0000,Mon; 5 Mar 2012 13:45:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2722
MAPREDUCE-2723,Sub-task,Major,mrv2,MR-279: port MAPREDUCE-2324 to mrv2,MRV2 currently does not take reduce disk usage into account when trying to schedule a container.  For feature parity with the original map reduce it should be extended to allow for disk space requests within containers along with RAM requests.  We then also need to port MAPREDUCE-2324 to the scheduler to allow it to avoid starvation of containers that might never get the resources that they need.,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Fri; 22 Jul 2011 16:17:46 +0000,Thu; 30 May 2013 11:09:30 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2723
MAPREDUCE-2724,Bug,Major,task,Reducer fetcher synchronize problem,I've recently using hadoop(version 0.21.0) for some data processing; but sometimes reducer crashed. Always the log is like bellow; which tells when multi fetchers recieved mapoutput simultaneously; the merge part may fail due to some disadvantages. To verify this assumption; I then set the number of fetchers to 1 (mapreduce.reduce.shuffle.parallelcopies); after which the problem dispeared and the job works well. 2011-07-20 18:56:34;999 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher:  org.apache.hadoop.io.WritableComparator.compare(WritableComparator. 129) ... 8 more  2011-07-20 18:56:41;552 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task,Resolved,Won't Fix,,Unassigned,ShengpengYu,Sat; 23 Jul 2011 17:06:38 +0000,Tue; 10 Mar 2015 03:16:58 +0000,Tue; 10 Mar 2015 03:16:58 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2724
MAPREDUCE-2725,Improvement,Major,contrib/gridmix,Make Gridmix configure job specific config properties for the simulated jobs,As Rumen gets all the config properties into the trace file now(after MAPREDUCE-2153); Gridmix can set some of the important job-specific config properties obtained from trace to the simulated jobs. This imply that with same amount of input reduceTask; the behavior of different other things like number of spills; sizes of spills; number of intermediate merges; etc would be similar to those were seen in original job(s).,Open,Unresolved,,Ravi Gummadi,Ravi Gummadi,Mon; 25 Jul 2011 10:49:45 +0000,Mon; 25 Jul 2011 10:54:27 +0000,,,,,MAPREDUCE-2153,,https://issues.apache.org/jira/browse/MAPREDUCE-2725
MAPREDUCE-2726,Improvement,Blocker,mrv2,MR-279: Add the jobFile to the web UI,MAPREDUCE:2716 adds the jobfile information to the ApplicationReport.  With that information available; we should add the jobfile to the web UI as well.,Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Mon; 25 Jul 2011 17:32:19 +0000,Mon; 16 Mar 2015 17:57:15 +0000,Mon; 19 Sep 2011 17:05:29 +0000,,,,MAPREDUCE-2716,MAPREDUCE-3037,https://issues.apache.org/jira/browse/MAPREDUCE-2726
MAPREDUCE-2727,Bug,Major,mrv2,MR-279: SleepJob throws divide by zero exception when count = 0,When the count is 0 for mappers or reducers; a divide-by-zero exception is thrown.  There are existing checks to error out when count  0; which obviously doesn't handle the 0 case.  This is causing the MRReliabilityTest to fail.,Closed,Fixed,,Jeffrey Naisbitt,Jeffrey Naisbitt,Mon; 25 Jul 2011 17:36:49 +0000,Tue; 15 Nov 2011 00:48:29 +0000,Sat; 13 Aug 2011 20:27:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2727
MAPREDUCE-2728,Bug,Major,build,Update Mapreduce dependency of Java for deb package,Java dependency for Debian package is specified as open JDK; but it should depends on Sun version of Java.  This dependency can be implicitly defined by hadoop-common dependency.  Hence; there is no need to explicitly defined in hadoop-mapreduce.,Resolved,Won't Fix,,Eric Yang,Eric Yang,Mon; 25 Jul 2011 20:18:53 +0000,Mon; 9 Mar 2015 23:19:41 +0000,Mon; 9 Mar 2015 23:19:41 +0000,,0.23.0,,,HADOOP-7483,https://issues.apache.org/jira/browse/MAPREDUCE-2728
MAPREDUCE-2729,Improvement,Major,,"Reducers are always counted having ""pending tasks"" even if they can't be scheduled yet because not enough of their mappers have completed",In capacity scheduler; number of users in a queue needing slots are calculated based on whether users' jobs have any pending tasks. This works fine for map tasks. However; for reduce tasks; jobs do not need reduce slots until the minimum number of map tasks have been completed.  Here; we add checking whether reduce is ready to schedule (i.e. if a job has completed enough map tasks) when we increment number of users in a queue needing reduce slots.,Closed,Fixed,,Sherry Chen,Sherry Chen,Tue; 26 Jul 2011 16:21:42 +0000,Wed; 19 Oct 2011 00:26:14 +0000,Mon; 8 Aug 2011 20:09:00 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2729
MAPREDUCE-2730,Bug,Minor,mrv2,mr279: Application EXPIRED_PENDING to FAILED state transition incomplete,in mrv2 if the application fails; it currently does not set the finishTime so it shows up as being 0.,Closed,Invalid,,Thomas Graves,Thomas Graves,Tue; 26 Jul 2011 21:26:23 +0000,Tue; 15 Nov 2011 00:48:58 +0000,Thu; 4 Aug 2011 16:00:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2730
MAPREDUCE-2731,Bug,Major,jobtracker,Jobtracker should report 99% until the query is done.,"Hadoop reporting 100% complete is a lie whenever the job; task; or node is not FULLY complete. Reports of 100% due to rounding should get explicitly stuck at 99.99% until the job is complete. The current system gets things stuck at 100%; which is simply wrong.  Even when the true % complete rounds to 100; 100% is still not appropriate to report in the form of a percentage due to the semantics of percentages.  This bug occurs frequently when a small number of nodes from a task with many nodes are running very slowly (i.e.; the ""one overloaded reducer"" problem).",Open,Unresolved,,Unassigned,Adam Kramer,Wed; 27 Jul 2011 00:03:35 +0000,Wed; 27 Jul 2011 00:03:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2731
MAPREDUCE-2732,Bug,Major,test,Some tests using FSNamesystem.LOG cannot be compiled,nan,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 27 Jul 2011 06:11:40 +0000,Tue; 15 Nov 2011 00:49:15 +0000,Wed; 27 Jul 2011 06:29:08 +0000,,,,,HDFS-2200,https://issues.apache.org/jira/browse/MAPREDUCE-2732
MAPREDUCE-2733,Task,Major,,Gridmix v3 cpu emulation system tests.,1. Enable CPU emulation with default resource usage interval and run Gridmix v3 with a trace file that contains the CPU resource usage details. 2. Enable CPU emulation with custom resource usage interval and run Gridmix v3 with a trace file that contains the CPU resource usage details.  3. Disable CPU emulation and run Gridmix v3 with a trace file that contains the CPU resource usage details.  4. Enable CPU emulation with default resource usage interval and run Gridmix v3 with a trace file that doesn't contains the CPU resource usage details.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Wed; 27 Jul 2011 09:41:24 +0000,Mon; 5 Mar 2012 02:48:47 +0000,Wed; 9 Nov 2011 09:52:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2733
MAPREDUCE-2734,Improvement,Trivial,jobtracker,DistCp with FairScheduler assign all map tasks in one TT,1 Using FairScheduler. 2 distcp a directory contains 5 files.  The DistCp job will launch 5 map tasks; and FairScheduler assign them to one TaskTracker. It should be assigned different; like the original JobQueueScheduler.,Closed,Fixed,,Bochun Bai,Bochun Bai,Wed; 27 Jul 2011 11:22:01 +0000,Tue; 30 Jun 2015 07:18:58 +0000,Wed; 21 May 2014 21:23:05 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2734
MAPREDUCE-2735,Bug,Major,mrv2,MR279: finished applications should be added to an application summary log,When an application finishes it should be added to an application summary log for historical purposes.  jira MAPREDUCE-2649 is going to start purging applications from RM when certain limits are hit which makes this more critical. We also need to save the information early enough after the app finishes so we don't lose the info if the RM does get restarted.,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 27 Jul 2011 13:40:39 +0000,Tue; 15 Nov 2011 00:49:22 +0000,Thu; 1 Sep 2011 23:59:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2735
MAPREDUCE-2736,Task,Major,jobtracker;tasktracker,Remove unused contrib components dependent on MR1,As discussed on mapreduce-dev@ and general@; let's remove or disable MR1.  1. http: %3CCAPn_vTsjcErtt35RSkCykY2m+qbk3w-ZEMQKpd+wNRaYo7tc5A@mail.gmail.com%3E,Closed,Fixed,,Eli Collins,Eli Collins,Wed; 27 Jul 2011 17:09:09 +0000,Tue; 15 Nov 2011 00:48:46 +0000,Fri; 28 Oct 2011 02:02:48 +0000,,,,MAPREDUCE-2880,,https://issues.apache.org/jira/browse/MAPREDUCE-2736
MAPREDUCE-2737,Bug,Major,mrv2,Update the progress of jobs on client side,The progress of the jobs are not being correctly updated on the client side. The map progress halts at 66% and both map reduce progress % does not display 100 when the job completes.,Closed,Fixed,,Siddharth Seth,Ramya Sunil,Wed; 27 Jul 2011 18:42:36 +0000,Tue; 15 Nov 2011 00:48:35 +0000,Mon; 29 Aug 2011 20:23:31 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2737
MAPREDUCE-2738,Bug,Blocker,mrv2,Missing cluster level stats on the RM UI,"Cluster usage information such as the following are currently not available in the RM UI.    	Total number of apps submitted so far 	Total number of containers running total memory usage 	Total capacity of the cluster (in terms of memory) 	Reserved memory 	Total number of NMs - sorting based on Node IDs is an option but when there are lost NMs or restarted NMs; the node ids does not correspond to the actual value 	Blacklisted NMs - sorting based on health-status and counting manually is not very straight forward 	Excluded NMs 	Handle to the jobhistory server",Closed,Fixed,,Robert Joseph Evans,Ramya Sunil,Wed; 27 Jul 2011 19:34:46 +0000,Mon; 16 Mar 2015 17:57:16 +0000,Wed; 5 Oct 2011 14:07:14 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-3036;MAPREDUCE-3050,MAPREDUCE-2789,https://issues.apache.org/jira/browse/MAPREDUCE-2738
MAPREDUCE-2739,Bug,Minor,mrv2,MR-279: Update installation docs (remove YarnClientFactory),Need to remove reference to the YarnClinetFactory in the INSTALL instructions: https: INSTALL  The YarnClientFactory class removed (MAPRECUCE-2400 patch).,Closed,Fixed,,Bo Wang,Ahmed Radwan,Thu; 28 Jul 2011 00:18:55 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Mon; 9 Jul 2012 17:41:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2739
MAPREDUCE-2740,Bug,Major,,MultipleOutputs in new API creates needless TaskAttemptContexts,MultipleOutputs.write creates a new TaskAttemptContext; which we've seen to take a significant amount of CPU. The TaskAttemptContext constructor creates a JobConf; gets current UGI; etc. I don't see any reason it needs to do this; instead of just creating a single TaskAttemptContext when the InputFormat is created (or lazily but cached as a member),Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 28 Jul 2011 20:39:42 +0000,Tue; 15 Nov 2011 00:48:06 +0000,Mon; 1 Aug 2011 17:52:55 +0000,,0.23.0,,,MAPREDUCE-1853,https://issues.apache.org/jira/browse/MAPREDUCE-2740
MAPREDUCE-2741,Task,Major,build,Make ant build system work with hadoop-common JAR generated by Maven,Some tweaks must be done in MAPRED  its contribs ivy configuration to work with HADOOP-6671.  This wil be a temporary fix until MAPRED is mavenized.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 28 Jul 2011 23:36:47 +0000,Thu; 2 May 2013 02:29:42 +0000,Tue; 2 Aug 2011 20:50:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2741
MAPREDUCE-2742,Sub-task,Critical,mrv2;security,[MR-279] [Security] All tokens in YARN + MR should have an expiry interval ,Right now none of the tokens and secret-keys have an expiry interval. This needs to be fixed.  This ticket should also handle how to renew the tickets when necessary.,Resolved,Duplicate,YARN-39;MAPREDUCE-3940,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 03:40:45 +0000,Mon; 16 Apr 2012 18:27:17 +0000,Mon; 16 Apr 2012 18:26:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2742
YARN-51,Sub-task,Blocker,nodemanager,[MR-279] [Security] AM should not be able to abuse container tokens for repetitive container launches,ApplicationMaster should not be able to store container tokens and use the same set of tokens for repetitive container launches. The possibility of such abuse is there in the current code; we need to fix this.  A cache of recent containers on the NM along with container token expiry time should solve this.,Closed,Duplicate,MAPREDUCE-3256;YARN-62,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 03:43:39 +0000,Thu; 30 Aug 2012 01:58:23 +0000,Fri; 28 Oct 2011 15:03:01 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-51
YARN-617,Sub-task,Minor,,In unsercure mode; AM can fake resource requirements ,Without security; it is impossible to completely avoid AMs faking resources. We can at the least make it as difficult as possible by using the same container tokens and the RM-NM shared key mechanism over unauthenticated RM-NM channel.  In the minimum; this will avoid accidental bugs in AMs in unsecure mode.,Closed,Fixed,,Omkar Vinit Joshi,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 03:52:19 +0000,Tue; 27 Aug 2013 22:15:35 +0000,Fri; 17 May 2013 06:38:32 +0000,,,,YARN-613;YARN-582,YARN-713,https://issues.apache.org/jira/browse/YARN-617
YARN-3376,Bug,Trivial,nodemanager,[MR-279] NM UI should get a read-only view instead of the actual NMContext ,NMContext is modifiable; the UI should only get read-only access. Just like the AM web-ui.,Open,Unresolved,,Anupam Seth,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 03:55:31 +0000,Fri; 1 May 2015 23:03:49 +0000,,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/YARN-3376
MAPREDUCE-2746,Sub-task,Blocker,mrv2;security,[MR-279] [Security] Yarn servers can't communicate with each other with hadoop.security.authorization set to true,Because of this problem; till now; we've been testing YARN+MR with hadoop.security.authorization set to false. We need to register yarn communication protocols in the implementation of the authorization related PolicyProvider (MapReducePolicyProvider. .  Devaraj Das also found this issue independently.,Closed,Fixed,,Arun C Murthy,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 04:41:05 +0000,Thu; 12 Jun 2014 22:36:42 +0000,Tue; 25 Oct 2011 06:10:51 +0000,,0.23.0,,,HADOOP-10678,https://issues.apache.org/jira/browse/MAPREDUCE-2746
MAPREDUCE-2747,Sub-task,Blocker,mrv2;nodemanager;security,[MR-279] [Security] Cleanup LinuxContainerExecutor binary sources,There are a lot of references to the old task-controller nomenclature still; job container.  Also the configuration file is named as taskcontroller.cfg and the configured variables are also from the mapred world (mrv1). These SHOULD  be fixed before we make a release. Marking this as blocker.,Closed,Fixed,,Robert Joseph Evans,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 04:45:55 +0000,Mon; 16 Mar 2015 17:57:16 +0000,Mon; 24 Oct 2011 17:59:19 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-2988,MAPREDUCE-3171,https://issues.apache.org/jira/browse/MAPREDUCE-2747
MAPREDUCE-2748,Bug,Major,mrv2;nodemanager,[MR-279] NM should pass a whitelisted environmental variables to the container ,"This is similar to MAPREDUCE-103 . We should pass a whitelisted set of environment variables from NM env to the container. By default; we should pass HADOOP_* variables. This can be a simple configuration key that NodeManager reads.  Today; we already either pass the following correctly or assume that it works but doesn't  	YARN_HOME: ContainerLaunch#writeLaunchEnv 	HADOOP_CLIENT_OPTS: MapReduceChildJVM#setVMEnv 	JAVA_HOME: TaskAttemptImpl#createContainerLaunchContext - Works by shell-expansion. 	LD_LIBRARY_PATH: Assumed to work via shell-expansion but doesn't.",Closed,Duplicate,MAPREDUCE-3068,Unassigned,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 04:56:44 +0000,Tue; 15 Nov 2011 00:50:07 +0000,Mon; 31 Oct 2011 05:00:06 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2748
MAPREDUCE-2749,Bug,Major,mrv2,[MR-279] NM registers with RM even before it starts various servers,In case NM eventually fails to start the ContainerManager server because of say a port clash; RM will have to wait for expiry to detect the NM crash.  It is desirable to make NM register with RM only after it can start all of its components successfully.,Closed,Fixed,,Thomas Graves,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 06:35:23 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Mon; 12 Sep 2011 07:12:19 +0000,,0.23.0,,,MAPREDUCE-2750,https://issues.apache.org/jira/browse/MAPREDUCE-2749
MAPREDUCE-2750,Bug,Major,mrv2,[MR-279] NodeManager should start its servers on ephemeral ports ,There is absolutely no need for NM to start ContainerManager on a standard port; it should bind to an ephemeral port. Binding on ephemeral ports will help us start multiple NMs on a single node without any issues.  The same holds for the ResourceLocalizationService's server port and NM Http server's port.,Closed,Duplicate,MAPREDUCE-2986,Anupam Seth,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 06:42:21 +0000,Tue; 15 Nov 2011 00:49:24 +0000,Fri; 30 Sep 2011 10:24:20 +0000,,0.23.0,,,MAPREDUCE-2652;MAPREDUCE-2749,https://issues.apache.org/jira/browse/MAPREDUCE-2750
MAPREDUCE-2751,Bug,Blocker,mrv2,[MR-279] Lot of local files left on NM after the app finish.,This ticket is about app-only files which should be cleaned after app-finish.  I see these undeleted after app-finish:  *  We should check for other left-over files too; if any.,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Fri; 29 Jul 2011 12:34:50 +0000,Tue; 15 Nov 2011 00:49:27 +0000,Fri; 7 Oct 2011 15:26:48 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2751
MAPREDUCE-2752,Bug,Minor,build,Build does not pass along properties to contrib builds,Subant call to compile contribs do not pass along parameters from parent build. Properties such as hadoop-common.version; asfrepo; offline; etc. are not passed along. Result is that build not connected to Internet fails; hdfs proxy refuses to build against own recently built common but rather downloads 0.22-SNAPSHOT from apache again.,Resolved,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Fri; 29 Jul 2011 16:59:32 +0000,Mon; 22 Aug 2011 18:35:44 +0000,Mon; 8 Aug 2011 00:31:17 +0000,,0.22.0,,,MAPREDUCE-2753;HDFS-2211,https://issues.apache.org/jira/browse/MAPREDUCE-2752
MAPREDUCE-2753,Bug,Major,build,Generated POMs hardcode dependency on hadoop-common version 0.22.0-SNAPSHOT,The generated poms inject the version of mapred itself; but hardcode the version of hadoop-common they depend on. When trying to build downstream projects (HBase); then they will require hadoop-common-0.22.0-SNAPSHOT.jar instead of the version they compiled against.  When trying to do an offline build this will fail to resolve as another hadoop-common has been installed in the local maven repo. Even during online build; it should compile against the hadoop-common that hdfs compiled against.  When versions mismatch one cannot do a coherent build. That is particularly problematic when making simultaneous change in hadoop-common and hadoop-mapreduce and you want to try this locally before committing each.,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Fri; 29 Jul 2011 17:37:06 +0000,Mon; 12 Dec 2011 06:18:53 +0000,Mon; 8 Aug 2011 00:30:55 +0000,,0.22.0,,,MAPREDUCE-2752,https://issues.apache.org/jira/browse/MAPREDUCE-2753
MAPREDUCE-2754,Bug,Blocker,mrv2,MR-279: AM logs are incorrectly going to stderr and error messages going incorrectly to stdout,The log messages for AM container are going into stderr instead of syslog. Also; stderr and stdout roles are reversed.,Closed,Fixed,MAPREDUCE-2755,Ravi Teja Ch N V,Ramya Sunil,Fri; 29 Jul 2011 19:29:04 +0000,Tue; 15 Nov 2011 00:48:43 +0000,Thu; 22 Sep 2011 15:20:13 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2754
MAPREDUCE-2755,Bug,Blocker,mrv2,MR-279: AM writes logs to stderr,Currently the AM logs are written to $YARN_LOG_DIR stderr. In order to maintain consistency with other container logs; it probably should be moved to syslog.,Closed,Duplicate,MAPREDUCE-2754,Unassigned,Ramya Sunil,Fri; 29 Jul 2011 19:35:15 +0000,Tue; 15 Nov 2011 00:48:33 +0000,Tue; 20 Sep 2011 12:59:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2755
MAPREDUCE-2756,Bug,Minor,client;mrv2,JobControl can drop jobs if an error occurs,If you run a pig job with UDFs that has not been recompiled for MRV2.  There are situations where pig will fail with an error message stating that Hadoop failed and did not give a reason.  There is even the possibility of deadlock if an Error is thrown and the JobControl thread dies.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 29 Jul 2011 19:43:25 +0000,Tue; 15 Nov 2011 00:48:52 +0000,Thu; 1 Sep 2011 20:26:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2756
MAPREDUCE-2757,Bug,Blocker,mrv2,"[MR-279] Redundant ""file:"" directory created in appcache ","A redundant directory called ""file:"" is being created under ${yarn.server.nodemanager.local-dir} filecache which is empty.",Closed,Duplicate,HADOOP-7575,Jonathan Eagles,Ramya Sunil,Fri; 29 Jul 2011 20:45:01 +0000,Tue; 15 Nov 2011 00:48:11 +0000,Mon; 19 Sep 2011 05:52:37 +0000,,0.23.0,,,HADOOP-7575,https://issues.apache.org/jira/browse/MAPREDUCE-2757
YARN-3310,Improvement,Minor,,MR-279: Log info about the location of dist cache,Currently; there is no log info available about the actual location of the file archive,Open,Unresolved,,Unassigned,Ramya Sunil,Fri; 29 Jul 2011 23:35:49 +0000,Fri; 1 May 2015 20:28:07 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-3310
MAPREDUCE-2759,Improvement,Minor,tasktracker,TaskTrackerAction should follow Open Closed Principle,In the class TaskTrackerAction  there are fixed actions or directions specified from the Job Tracker to the Task Tracker.So if in the future if some more actions are specified from the Job Tracker to Task Tracker;Current implementation is breaking Open Closed Principle(Open for extension;closed for modification).As the number of actions increases in the future; the code need to be modified to incorporate the actions.,Resolved,Won't Fix,,Unassigned,Rajesh Putta,Mon; 1 Aug 2011 08:56:10 +0000,Sat; 9 May 2015 01:13:48 +0000,Sat; 9 May 2015 01:13:48 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2759
MAPREDUCE-2760,Bug,Minor,documentation,mapreduce.jobtracker.split.metainfo.maxsize typoed in mapred-default.xml,The configuration mapreduce.jobtracker.split.metainfo.maxsize is incorrectly included in mapred-default.xml as mapreduce.job.split.metainfo.maxsize. It seems that jobtracker is correct; since this is a JT-wide property rather than a job property.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 1 Aug 2011 16:59:31 +0000,Tue; 26 Mar 2013 17:12:48 +0000,Tue; 2 Aug 2011 20:05:29 +0000,,0.23.0,,,MAPREDUCE-4871,https://issues.apache.org/jira/browse/MAPREDUCE-2760
MAPREDUCE-2761,Bug,Major,task-controller;tasktracker,New TaskController code doesn't run on Windows,After MAPREDUCE-2178; TaskController assumes that pids are always available. The shell executor object that's used to launch a JVM isn't retained; but rather the pid is set when the task heartbeats. On Windows; there are no pids; and since the ShellCommandExecutor object is no longer around; we can't call process.destroy(). So; the TaskController doesn't work on Cygwin anymore.,Open,Unresolved,,Unassigned,Todd Lipcon,Mon; 1 Aug 2011 17:10:44 +0000,Tue; 2 Aug 2011 10:30:24 +0000,,,0.20.204.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2761
MAPREDUCE-2762,Bug,Blocker,mrv2,[MR-279] - Cleanup staging dir after job completion,The files created under the staging dir have to be deleted after job completion. Currently; all job.* files remain forever in the ${yarn.apps.stagingDir},Closed,Fixed,,Mahadev konar,Ramya Sunil,Mon; 1 Aug 2011 18:08:47 +0000,Tue; 15 Nov 2011 00:48:30 +0000,Tue; 18 Oct 2011 21:38:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2762
MAPREDUCE-2763,Bug,Major,mrv2,IllegalArgumentException while using the dist cache,IllegalArgumentException is seen while using distributed cache to cache some files and custom jars in classpath.  A simple way to reproduce this error is by using a streaming job: hadoop jar hadoop-streaming.jar -libjars file: path to some file#linkname  This is a regression introduced and the same command works fine on 0.20.x,Closed,Fixed,,Unassigned,Ramya Sunil,Mon; 1 Aug 2011 22:31:56 +0000,Tue; 15 Nov 2011 00:48:15 +0000,Tue; 20 Sep 2011 19:52:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2763
MAPREDUCE-2764,Bug,Major,,Fix renewal of dfs delegation tokens,"The JT may have issues renewing hftp tokens which disrupt long distcp jobs.  The problem is the JT's delegation token renewal code is built on brittle assumptions.  The token's service field contains only the ""ip:port"" pair.  The renewal process assumes that the scheme must be hdfs.  If that fails due to a VersionMismatchException; it tries https based on another assumption that it must be hftp if it's not hdfs.  A number of other exceptions; most commonly IOExceptions; can be generated which fouls up the renewal since it won't fallback to https.",Closed,Fixed,,Owen O'Malley,Daryn Sharp,Tue; 2 Aug 2011 01:13:27 +0000,Mon; 9 Mar 2015 20:16:20 +0000,Fri; 14 Oct 2011 06:20:05 +0000,,,,,HADOOP-7510;MAPREDUCE-3192,https://issues.apache.org/jira/browse/MAPREDUCE-2764
MAPREDUCE-2765,New Feature,Major,distcp;mrv2,DistCp Rewrite,"This is a slightly modified version of the DistCp rewrite th to Srikanth (Sundarrajan) and Venkatesh (Seetharamaiah); for ideas; code; reviews and guidance. Although much of the code is mine; the idea to use the DFS to implement ""dynamic"" input-splits wasn't.",Closed,Fixed,,Mithun Radhakrishnan,Mithun Radhakrishnan,Tue; 2 Aug 2011 12:04:10 +0000,Mon; 12 May 2014 03:02:01 +0000,Thu; 26 Jan 2012 06:50:14 +0000,,0.20.203.0;0.23.0,,OOZIE-611;HADOOP-6448,MAPREDUCE-4654;MAPREDUCE-5081,https://issues.apache.org/jira/browse/MAPREDUCE-2765
MAPREDUCE-2766,Sub-task,Blocker,mrv2,[MR-279] Set correct permissions for files in dist cache,Currently; the files in both public and private dist cache are having 777 permission. Also; the group ownership of files on private cache have to be set to $TT_SPECIAL_GROUP,Closed,Fixed,,Hitesh Shah,Ramya Sunil,Tue; 2 Aug 2011 20:55:02 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Mon; 31 Oct 2011 05:53:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2766
MAPREDUCE-2767,Bug,Blocker,security,Remove Linux task-controller from 0.22 branch,There's a potential security hole in the task-controller as it stands. Based on the discussion on general@; removing task-controller from the 0.22 branch will pave way for 0.22.0 release. (This was done for the 0.21.0 release as well: see MAPREDUCE-2014.) We can roll a 0.22.1 release with the task-controller when it is fixed.,Closed,Fixed,,Milind Bhandarkar,Milind Bhandarkar,Tue; 2 Aug 2011 21:10:41 +0000,Mon; 16 Mar 2015 17:49:13 +0000,Tue; 6 Sep 2011 22:42:41 +0000,,0.22.0;0.23.0;2.0.0-alpha,,,HADOOP-8357,https://issues.apache.org/jira/browse/MAPREDUCE-2767
MAPREDUCE-2768,Bug,Blocker,mrv2,[MR-279] NMs not being blacklisted as determined by health scripts,The NMs are not being blacklisted via the node health script. Below is the configuration used:  yarn.server.nodemanager.healthchecker.script.path=path to node health script which blacklists a NM yarn.server.nodemanager.healthchecker.interval=10 yarn.server.nodemanager.healthchecker.script.timeout=12  The node continues to be healthy forever.,Closed,Not A Problem,,Arun C Murthy,Ramya Sunil,Tue; 2 Aug 2011 22:02:44 +0000,Tue; 15 Nov 2011 00:48:50 +0000,Tue; 11 Oct 2011 08:03:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2768
MAPREDUCE-2769,Improvement,Minor,tasktracker,TT should give more info for failed file operations,The TT should give more info when it fail a NativeIO file operation (eg the file name).,Resolved,Won't Fix,,Unassigned,Eli Collins,Wed; 3 Aug 2011 01:47:33 +0000,Sat; 9 May 2015 01:15:18 +0000,Sat; 9 May 2015 01:15:18 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2769
MAPREDUCE-2770,Improvement,Trivial,documentation,Improve hadoop.job.history.location doc in mapred-default.xml,The documentation for hadoop.job.history.location in mapred-default.xml should indicate that this parameter can be a URI and any file system that Hadoop supports (eg hdfs and file).,Closed,Fixed,,Sandy Ryza,Eli Collins,Wed; 3 Aug 2011 02:09:18 +0000,Wed; 15 May 2013 05:15:59 +0000,Fri; 21 Sep 2012 09:05:17 +0000,,0.20.203.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2770
MAPREDUCE-2771,Improvement,Major,contrib/fair-share;documentation,The fs docs should cover mapred.fairscheduler.assignmultiple,The fs docs should cover the mapred.fairscheduler.assignmultiple* config options.  http: fair_scheduler.html,Open,Unresolved,,Unassigned,Eli Collins,Wed; 3 Aug 2011 03:12:06 +0000,Tue; 14 May 2013 05:14:40 +0000,,,1.0.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2771
MAPREDUCE-2772,Bug,Major,mrv2,MR-279: mrv2 no longer compiles against trunk after common mavenization.,mrv2 no longer compiles against trunk after common mavenization,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 3 Aug 2011 16:38:16 +0000,Tue; 15 Nov 2011 00:49:33 +0000,Wed; 3 Aug 2011 22:30:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2772
MAPREDUCE-2773,Bug,Minor,mrv2,[MR-279] server.api.records.NodeHealthStatus renamed but not updated in client NodeHealthStatus.java,On the mr279 branch; you can't successfully run the ant target from the mapreduce directory since the checkin of the RM refactor.    The issue is the NodeHealthStatus rename from org.apache.hadoop.yarn.server.api.records.NodeHealthStatus to org.apache.hadoop.yarn.api.records.NodeHealthStatus but the client mapreduce  wasn't updated with the change,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 3 Aug 2011 19:44:29 +0000,Tue; 15 Nov 2011 00:48:08 +0000,Wed; 3 Aug 2011 20:06:56 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2773
MAPREDUCE-2774,Bug,Minor,mrv2,[MR-279] Add a startup msg while starting RM/NM,Add a startup msg while starting NM RM indicating the version; build details etc. This will help in easier parsing of logs and debugging.,Closed,Fixed,,Venu Gopala Rao,Ramya Sunil,Wed; 3 Aug 2011 21:19:03 +0000,Tue; 15 Nov 2011 00:48:50 +0000,Tue; 6 Sep 2011 23:41:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2774
MAPREDUCE-2775,Bug,Blocker,mrv2,[MR-279] Decommissioned node does not shutdown,A Nodemanager which is decommissioned by an admin via refreshnodes does not automatically shutdown.,Closed,Fixed,MAPREDUCE-3874,Devaraj K,Ramya Sunil,Wed; 3 Aug 2011 22:24:12 +0000,Tue; 21 Feb 2012 05:14:03 +0000,Fri; 28 Oct 2011 17:41:40 +0000,,0.23.0,,MAPREDUCE-3270,,https://issues.apache.org/jira/browse/MAPREDUCE-2775
MAPREDUCE-2776,Bug,Major,mrv2,MR 279: Fix some of the yarn findbug warnings,Fix   ignore some of the findbug warnings in the yarn module.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 4 Aug 2011 01:33:36 +0000,Tue; 15 Nov 2011 00:50:05 +0000,Thu; 4 Aug 2011 05:34:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2776
MAPREDUCE-2777,New Feature,Major,,Backport MAPREDUCE-220 to Hadoop 20 security branch,nan,Closed,Fixed,,Amar Kamat,Jonathan Eagles,Thu; 4 Aug 2011 06:22:06 +0000,Wed; 19 Oct 2011 00:26:10 +0000,Wed; 5 Oct 2011 22:39:41 +0000,,0.20.205.0,,,MAPREDUCE-220;MAPREDUCE-2469,https://issues.apache.org/jira/browse/MAPREDUCE-2777
MAPREDUCE-2778,Sub-task,Major,,Refactor token selectors to leverage common code,The token selectors are copy-n-paste of each other.  Need to create a base class to hold the common code.,Open,Unresolved,,Daryn Sharp,Daryn Sharp,Fri; 5 Aug 2011 00:23:17 +0000,Thu; 15 Sep 2011 14:45:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2778
MAPREDUCE-2779,Bug,Major,job submission,JobSplitWriter.java can't handle large job.split file,We use cascading MultiInputFormat. MultiInputFormat sometimes generates big job.split used internally by hadoop; sometimes it can go beyond 2GB.  In JobSplitWriter.  the function that generates such file uses 32bit signed integer to compute offset into job.split.   writeNewSplits ...         int prevCount = out.size(); ...         int currCount = out.size();  writeOldSplits ...       long offset = out.size(); ...       int currLen = out.size();,Closed,Fixed,,Ming Ma,Ming Ma,Fri; 5 Aug 2011 01:32:46 +0000,Mon; 16 Mar 2015 17:42:38 +0000,Fri; 30 Sep 2011 19:22:34 +0000,,0.20.205.0;0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2779
MAPREDUCE-2780,Sub-task,Major,,Standardize the value of token service,"The token's service field must (currently) be set to ""ip:port"".  All the producers of a token are independently building the service string.  This should be done via a common method to reduce the chance of error; and to facilitate the field value being easily changed in the (near) future.",Resolved,Fixed,,Daryn Sharp,Daryn Sharp,Fri; 5 Aug 2011 01:37:01 +0000,Thu; 21 Jun 2012 15:05:22 +0000,Thu; 21 Jun 2012 15:05:22 +0000,,,,,HADOOP-7808,https://issues.apache.org/jira/browse/MAPREDUCE-2780
MAPREDUCE-2781,Bug,Minor,mrv2,mr279 RM application finishtime not set,The RM Application finishTime isn't being set.  Looks like it got lost in the RM refactor.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 5 Aug 2011 04:24:16 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Thu; 11 Aug 2011 01:09:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2781
MAPREDUCE-2782,Test,Major,mrv2,MR-279: Unit (mockito) tests for CS,Add (true) unit tests for CapacityScheduler,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 5 Aug 2011 08:46:03 +0000,Tue; 15 Nov 2011 00:49:57 +0000,Wed; 10 Aug 2011 06:05:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2782
MAPREDUCE-2783,Bug,Critical,mrv2,mr279 job history handling after killing application,The job history application tracking url handling during kill is not consistent. Currently if you kill a job that was running the tracking url points to job history; but job history server doesn't have the job.,Closed,Fixed,,Eric Payne,Thomas Graves,Fri; 5 Aug 2011 17:30:36 +0000,Tue; 30 Oct 2012 23:06:10 +0000,Fri; 7 Oct 2011 09:24:02 +0000,,0.23.0,,,YARN-165,https://issues.apache.org/jira/browse/MAPREDUCE-2783
MAPREDUCE-2784,Bug,Major,contrib/gridmix,[Gridmix] TestGridmixSummary fails with NPE when run in DEBUG mode.,TestGridmixSummary fails with NPE when run in debug mode. JobFactory tries to access the createReaderThread() API of JobStoryProducer which returns null in TestGridmixSummary's FakeJobStoryProducer.,Closed,Fixed,,Amar Kamat,Amar Kamat,Mon; 8 Aug 2011 13:16:36 +0000,Tue; 10 Mar 2015 04:31:59 +0000,Thu; 8 Sep 2011 11:30:55 +0000,,0.23.0;2.0.0-alpha,gridmix;junit,,,https://issues.apache.org/jira/browse/MAPREDUCE-2784
MAPREDUCE-2785,Bug,Minor,jobtracker,MiniMR cluster thread crashes if no hadoop log dir set,I'm marking this as minor as it is most obvious in the MiniMRCluster; but the root cause is in the JT.   If you instantiate an MiniMR Cluster without setting hadoop.job.history.location in the configuration and the system property hadoop.log.dir unset; then the JobHistory throws an NPE. In production; that would be picked up as a failure to start the JT. In the MiniMRCluster; all it does is crash the JT thread -which isn't noticed by the MiniMR cluster. You see the logged error; but the tests will just timeout waiting for things to come up   :427 CEST ERRORThread-44 org.apache.hadoop.mapred.MiniMRCluster - Job tracker crashed  662),Resolved,Cannot Reproduce,,Steve Loughran,Steve Loughran,Mon; 8 Aug 2011 16:02:52 +0000,Mon; 3 Mar 2014 10:06:15 +0000,Mon; 3 Mar 2014 10:06:15 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2785
MAPREDUCE-2786,Improvement,Minor,benchmarks,TestDFSIO should also test compression reading/writing from command-line.,"I thought it might be beneficial to simply alter the code of TestDFSIO to accept any compression codec class and allow testing for compression by a command line argument instead of having to change the config file everytime. Something like ""-compression"" would do.",Closed,Fixed,,Plamen Jeliazkov,Plamen Jeliazkov,Mon; 8 Aug 2011 17:14:32 +0000,Thu; 7 Feb 2013 00:08:02 +0000,Mon; 3 Sep 2012 18:59:39 +0000,,2.0.0-alpha,newbie,,MAPREDUCE-4985,https://issues.apache.org/jira/browse/MAPREDUCE-2786
MAPREDUCE-2787,Improvement,Major,mrv2,MR-279: Performance improvement in running Uber MapTasks,The runUberMapTasks() in org.apache.hadoop.mapred.UberTask obtains the local fileSystem and local job configuration for every task attempt.  This will have a negative performance impact.,Resolved,Won't Fix,,Ahmed Radwan,Ahmed Radwan,Mon; 8 Aug 2011 19:20:35 +0000,Thu; 11 Aug 2011 09:16:28 +0000,Thu; 11 Aug 2011 09:16:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2787
MAPREDUCE-2788,Bug,Major,mrv2,Normalize requests in FifoScheduler.allocate to prevent NPEs later,The assignContainer() method in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue can cause the scheduler to crash if the ResourseRequest capability memory == 0 (divide by zero).,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 9 Aug 2011 00:07:25 +0000,Tue; 15 Nov 2011 00:49:32 +0000,Wed; 19 Oct 2011 20:38:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2788
MAPREDUCE-2789,Bug,Major,mrv2,[MR:279] Update the scheduling info on CLI,The scheduling information such as number of containers running; memory usage and reservations per job is not available on bin mapred job -list CLI.,Closed,Fixed,,Eric Payne,Ramya Sunil,Tue; 9 Aug 2011 19:43:43 +0000,Tue; 15 Nov 2011 00:49:24 +0000,Wed; 12 Oct 2011 23:30:31 +0000,,0.23.0,,MAPREDUCE-3050,MAPREDUCE-2738;MAPREDUCE-2791;MAPREDUCE-2790,https://issues.apache.org/jira/browse/MAPREDUCE-2789
MAPREDUCE-2790,Bug,Critical,mrv2,[MR-279] Add additional field for storing the AM/job history info on CLI,bin job history information. Currently; the output reads:,Closed,Duplicate,MAPREDUCE-2789,Ravi Prakash,Ramya Sunil,Tue; 9 Aug 2011 19:51:02 +0000,Tue; 15 Nov 2011 00:48:11 +0000,Thu; 22 Sep 2011 17:02:39 +0000,,0.23.0,,MAPREDUCE-3050,MAPREDUCE-2789,https://issues.apache.org/jira/browse/MAPREDUCE-2790
MAPREDUCE-2791,Bug,Blocker,mrv2,[MR-279] Missing/incorrect info on job -status CLI ,There are a couple of details missing incorrect on the job -status command line output for completed jobs:  1. Incorrect job file 2. map() completion is always 0 3. reduce() completion is always set to 0 4. history URL is empty 5. Missing launched map tasks 6. Missing launched reduce tasks,Closed,Fixed,,Devaraj K,Ramya Sunil,Tue; 9 Aug 2011 20:14:19 +0000,Tue; 15 Nov 2011 00:48:14 +0000,Fri; 30 Sep 2011 03:11:08 +0000,,0.23.0,,,MAPREDUCE-2789,https://issues.apache.org/jira/browse/MAPREDUCE-2791
MAPREDUCE-2792,Sub-task,Blocker,mrv2;security,[MR-279] Replace IP addresses with hostnames,Currently; all the logs; UI; CLI have IP addresses of the NM RM; which are difficult to manage. It will be useful to have hostnames like in 0.20.x for easier debugging and maintenance purpose.,Closed,Fixed,,Vinod Kumar Vavilapalli,Ramya Sunil,Tue; 9 Aug 2011 22:28:54 +0000,Tue; 15 Nov 2011 00:48:10 +0000,Mon; 3 Oct 2011 23:23:17 +0000,,0.23.0,,MAPREDUCE-3013,,https://issues.apache.org/jira/browse/MAPREDUCE-2792
MAPREDUCE-2793,Bug,Critical,mrv2,[MR-279] Maintain consistency in naming appIDs; jobIDs and attemptIDs ,appIDs; jobIDs and attempt logs: attempt_1308259676864_0005_m_000024_0 mapred-local dirs are named as: container_1308259676864_0005_000024,Resolved,Fixed,,Bikas Saha,Ramya Sunil,Tue; 9 Aug 2011 22:45:29 +0000,Sat; 25 Feb 2012 13:57:46 +0000,Sat; 25 Feb 2012 02:33:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2793
MAPREDUCE-2794,Bug,Blocker,mrv2,[MR-279] Incorrect metrics value for AvailableGB per queue per user,"AvailableGB per queue is not the same as AvailableGB per queue per user when the user limit is set to 100%. i.e. if the total available GB of the cluster is 60; and queue ""default"" has 92% capacity with 100% as the user limit; AvailableGB per queue default = 55 (i.e. 0.92*60) whereas AvailableGB per queue for user ramya is 56 (however it should be 55 = 0.92*60*1)   Also; unlike the AvailableGB user is not decremented when user ramya is running apps on the ""default"" queue.",Closed,Fixed,,John George,Ramya Sunil,Wed; 10 Aug 2011 00:23:10 +0000,Tue; 15 Nov 2011 00:49:03 +0000,Fri; 7 Oct 2011 05:36:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2794
MAPREDUCE-2795,Bug,Blocker,mrv2,[MR-279] AppsKilled is never incremented,AppsKilled metrics is never incremented even though there are killed jobs in the system.,Closed,Invalid,,Devaraj K,Ramya Sunil,Wed; 10 Aug 2011 00:31:56 +0000,Mon; 16 Mar 2015 17:57:18 +0000,Wed; 19 Oct 2011 06:21:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2795
MAPREDUCE-2796,Bug,Major,mrv2,[MR-279] Start time for all the apps is set to 0,"The start time for all the apps in the output of ""job -list"" is set to 0",Closed,Fixed,,Devaraj K,Ramya Sunil,Wed; 10 Aug 2011 00:57:50 +0000,Tue; 15 Nov 2011 00:48:46 +0000,Thu; 25 Aug 2011 19:14:52 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2796
MAPREDUCE-2797,Bug,Major,contrib/raid;test,Some java files cannot be compiled,Due to the changes in HDFS-2239; the following files cannot be compiled (Thanks Amar for pointing them out.) 1. src BlockPlacementPolicyRaid.java,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 10 Aug 2011 09:36:00 +0000,Tue; 15 Nov 2011 00:50:06 +0000,Wed; 10 Aug 2011 15:56:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2797
YARN-3316,New Feature,Minor,nodemanager;resourcemanager,Make the ResourceManager; NodeManager and HistoryServer run from Eclipse.,Make the ResourceManager; NodeManager and HistoryServer run from Eclipse; so that it would be easy for development.,Open,Unresolved,,Unassigned,praveen sripati,Wed; 10 Aug 2011 13:03:40 +0000,Thu; 12 May 2016 18:29:22 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-3316
MAPREDUCE-2799,Bug,Major,mrv2,[MR-279] NPE is throwing on job -status <Invalid Job ID/Job Id doesn't exist>,nan,Resolved,Duplicate,MAPREDUCE-2686,Devaraj K,Devaraj K,Wed; 10 Aug 2011 14:42:35 +0000,Wed; 10 Aug 2011 17:35:18 +0000,Wed; 10 Aug 2011 17:35:18 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2799
MAPREDUCE-2800,Bug,Major,mrv2,clockSplits; cpuUsages; vMemKbytes; physMemKbytes is set to -1 in jhist files,clockSplits; cpuUsages; vMemKbytes; physMemKbytes  is set to -1 for all the map tasks for the last 4 progress interval in the jobhistory files.,Closed,Fixed,,Siddharth Seth,Ramya Sunil,Wed; 10 Aug 2011 18:28:03 +0000,Mon; 16 Mar 2015 17:57:13 +0000,Tue; 6 Sep 2011 23:37:31 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2800
MAPREDUCE-2801,Bug,Blocker,mrv2,Include the native libs in java.library.path ,For the child tasks in mrv2;  library.path for child tasks was set to path to native libs:$PWD,Closed,Duplicate,MAPREDUCE-2880,Robert Joseph Evans,Ramya Sunil,Wed; 10 Aug 2011 18:46:38 +0000,Tue; 15 Nov 2011 00:48:38 +0000,Sun; 18 Sep 2011 13:37:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2801
MAPREDUCE-2802,Improvement,Critical,mrv2,[MR-279] Jobhistory filenames should have jobID to help in better parsing ,For jobID such as job_1312933838300_0007; jobhistory file names are named as job%5F1312933838300%5F0007_submit_timeramyajobname_finish_time_1_1_SUCCEEDED.jhist It would be easier for parsing if the jobIDs were a part of the filenames.,Closed,Fixed,,Jonathan Eagles,Ramya Sunil,Wed; 10 Aug 2011 18:58:03 +0000,Tue; 15 Nov 2011 00:49:58 +0000,Fri; 7 Oct 2011 20:45:47 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2802
MAPREDUCE-2803,Improvement,Major,mrv2,Separate client and server configs,yarn- {site;default}.xml contains many knobs none-ops users don't need to know (e.g.; server principals and keytab locations etc.). It's confusing to users. Let's separate the server config into separate files yarn-server-{site.default}.xml  yarn common and client configs would remain in yarn-{site;default} .xml and YarnServerConfig shall read both.,Open,Unresolved,,Unassigned,Luke Lu,Wed; 10 Aug 2011 21:29:32 +0000,Thu; 12 May 2016 18:23:05 +0000,,,0.23.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2803
MAPREDUCE-2804,Bug,Blocker,,Creation of symlink to attempt log dir failed. message is not useful,In attempting to qualify the 204 RC2 release; my tasktracker logs are filled with the above message.  I'd love to do something about it; but since it doesn't tell me what exactly it is trying to symlink I cannot unless I dig into the source code.,Closed,Fixed,,Owen O'Malley,Allen Wittenauer,Wed; 10 Aug 2011 21:58:34 +0000,Fri; 2 Sep 2011 22:13:20 +0000,Thu; 25 Aug 2011 20:03:04 +0000,,0.20.204.0,,,MAPREDUCE-2846;MAPREDUCE-2415,https://issues.apache.org/jira/browse/MAPREDUCE-2804
MAPREDUCE-2805,Improvement,Minor,contrib/raid,Update RAID for HDFS-2241,nan,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Thu; 11 Aug 2011 06:57:29 +0000,Tue; 15 Nov 2011 00:48:05 +0000,Fri; 19 Aug 2011 23:31:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2805
MAPREDUCE-2806,Bug,Major,contrib/gridmix,[Gridmix] Load job fails with timeout errors when resource emulation is turned on,When the Load job's tasks are emulating cpu memory; the task-tracker kills the emulating task due to lack of status updates. Load job has its own status reporter which dies too soon.,Resolved,Fixed,,Amar Kamat,Amar Kamat,Thu; 11 Aug 2011 07:35:18 +0000,Tue; 9 Sep 2014 21:00:13 +0000,Thu; 24 Nov 2011 04:02:04 +0000,,0.23.0,gridmix;loadjob;timeout,,,https://issues.apache.org/jira/browse/MAPREDUCE-2806
MAPREDUCE-2807,Sub-task,Major,applicationmaster;mrv2;resourcemanager,MR-279: AM restart does not work after RM refactor,When the AM crashes; RM is not able to launch a new App attempt.,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Thu; 11 Aug 2011 08:54:47 +0000,Tue; 15 Nov 2011 00:50:02 +0000,Thu; 25 Aug 2011 06:37:03 +0000,,0.23.0,,MAPREDUCE-2708,,https://issues.apache.org/jira/browse/MAPREDUCE-2807
MAPREDUCE-2808,Bug,Minor,mrv2,pull MAPREDUCE-2797 into mr279 branch,The ant tar command fails in the mapreduce directory on the mr279 branch.  The issue was a change in hdfs and was fixed on trunk with jira MAPREDUCE-2797.  Pull that change into mr279.,Closed,Fixed,,Thomas Graves,Thomas Graves,Thu; 11 Aug 2011 16:19:47 +0000,Tue; 15 Nov 2011 00:48:21 +0000,Thu; 11 Aug 2011 18:32:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2808
MAPREDUCE-2809,Improvement,Major,,Refactor JobRecoveryManager into a new class file.,RecoveryManager in itself subsumes a lot of code; and should be moved out of JobTracker. ,Resolved,Won't Fix,,Unassigned,Vinod Kumar Vavilapalli,Fri; 6 Mar 2009 11:50:15 +0000,Thu; 11 Aug 2011 18:07:37 +0000,Thu; 11 Aug 2011 18:07:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2809
MAPREDUCE-2810,New Feature,Major,job submission;security,CLI interface for managing Jobtracker Queues and ACLs,"As the number of users in a hadoop cluster increases; it gets difficult to manage Queues and ACLs in mapred-site.xml .  Its good to have a CLI  interface to update mapred-site.xml and validate the configuration. The CLI should provie   	list of current ACLs 	Update and refresh ACLs",Open,Unresolved,,Unassigned,Rajiv Chittajallu,Wed; 15 Apr 2009 01:54:33 +0000,Thu; 11 Aug 2011 18:08:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2810
MAPREDUCE-2811,New Feature,Major,,Adding Multiple Reducers implementations.,Like HADOOP-372; we have a multi format Reducer too. Someone suggested that if we need different reducers and map implementations(like what i need) I was better of by writing 2 jobs. I dont quite agree. I am calculating 2 big matrices that must be calculated in the map step; summed in the reducers multiplied and then written to a file. The First mapper sums a matrix  based on the i;j th index(key) into the file and the second mapper adds the N*1  dimension vector that uses a new line as key. These keys must be passed as such to the reduce process.,Open,Unresolved,,Unassigned,Sidharth Gupta,Mon; 6 Apr 2009 18:00:01 +0000,Tue; 22 Jul 2014 18:28:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2811
MAPREDUCE-2812,New Feature,Major,,Combiner that aggregates all the mappers from a machine,From what I can tell; the Combiner just aggregates data from a single map task. It would be useful; especially during map-only jobs; to have a combiner that aggregates data from all the map tasks on a given machine. My use case for this is to vertically partition a set of records which start out in the same files. By doing this in a map-only task; way too many files are created (About 50 files are created per input split). By pumping all the data through a reducer; a lot of unnecessary overhead occurs. With the proposed feature; I would get 50*number of machines files rather than 50*number of input splits files for this use case.,Open,Unresolved,,Unassigned,Nathan Marz,Thu; 26 Feb 2009 19:06:55 +0000,Thu; 11 Aug 2011 18:11:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2812
MAPREDUCE-2813,Bug,Major,,"Tasks freeze with ""No live nodes contain current block""; job takes long time to recover",Running a recent version of trunk on 100 nodes; I occasionally see some tasks freeze at startup and hang the job. These tasks are not speculatively executed either. Here's sample output from one of them:     Note how the DFS client fails multiple times to retrieve the block; with a 2 minute wait between each one; without giving up. During this time; the task is not speculated. However; once this task finally failed; a new version of it ran successfully. Getting the input file in question with bin hadoop fs -get also worked fine.  There is no mention of the task attempt in question in the NameNode logs but my guess is that something to do with RPC queues is causing its connection to get lost; and the DFSClient does not recover.,Open,Unresolved,,Unassigned,Matei Zaharia,Fri; 27 Feb 2009 23:34:59 +0000,Thu; 11 Aug 2011 18:11:59 +0000,,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2813
MAPREDUCE-2814,Bug,Major,,Relax the strict type check by allowing subclasses pass the check,The type check like:   is used a lot when a type check is needed.  I found their uses in org.apache.hadoop.io.SequenceFile; org.apache.hadoop.mapred.IFile; org.apache.hadoop.mapred.MapTask. Because i search with(key.getClass() != keyClass); so these codes may also appear in other classes.  I suggest we can relax the strict type check by using     The error in my situation is listed below:     Float is a sub class of Type. I wish it can pass the check. I use Type instead of Float is because i can not determint exactly whether it is Float; String or  some others.,Open,Unresolved,,Unassigned,He Yongqiang,Tue; 10 Mar 2009 12:41:51 +0000,Thu; 11 Aug 2011 18:12:28 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2814
MAPREDUCE-2815,Bug,Minor,documentation,JavaDoc does not generate correctly for MultithreadedMapRunner,"The following code in MultithreadedMapRunner. does not get published to the HTML docs correctly.  This is what actually appears in the HTML docs: ""It can be used instead of the default implementation; ""  This is what should appear:  ",Closed,Fixed,MAPREDUCE-5438,Chris Palmer,Shane Butler,Mon; 22 Dec 2008 06:12:07 +0000,Fri; 24 Apr 2015 23:15:12 +0000,Tue; 24 Feb 2015 20:13:14 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2815
MAPREDUCE-2816,Bug,Major,,SortedMapWritable: inkonsistent put() and putAll() behaviour,The current SortedMapWritable implementation is breaking support for custom classes in case putAll() is used. Its important for putAll() that addToMap() will called to register all used classes. Please consider to have putAll() call put() for each map entry.  trunk:   public Writable put(WritableComparable key; Writable value)  {     addToMap(key.getClass());     addToMap(value.getClass());     return instance.put(key; value);   }    public void putAll(Map? extends WritableComparable; ? extends Writable t) {     for (Map.Entry? extends WritableComparable; ? extends Writable e:       t.entrySet())  {              instance.put(e.getKey(); e.getValue());     }   },Open,Unresolved,,Unassigned,Stefan Podkowinski,Wed; 14 Jan 2009 13:10:10 +0000,Thu; 11 Aug 2011 18:16:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2816
MAPREDUCE-2817,Bug,Minor,test,MiniRMCluster hardcodes 'mapred.local.dir' configuration to 'build/test/mapred/local',"The mapred.local.dir configuration property for the MiniMRCluster is forced to build local  This is inconvenient in different situations. For example:   	When running multiple tests using MiniMRCluster is not possible to see the end state of the dir for a particular test 	When using MiniMRCluster in another build system (i.e. Maven) that uses a different output directory (target instead build)",Resolved,Fixed,,Robert Kanter,Alejandro Abdelnur,Wed; 29 Oct 2008 06:05:27 +0000,Wed; 3 Apr 2013 22:29:53 +0000,Wed; 3 Apr 2013 22:29:53 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2817
MAPREDUCE-2818,New Feature,Trivial,,Rest API for retrieving job / task statistics ,a rest api that returns a simple JSON containing information about a given job such as:  min avg times per task; failed tasks; etc. This would be useful in order to allow external restart or modification of parameters of a run.,Resolved,Implemented,,Unassigned,Florian Leibert,Fri; 31 Oct 2008 15:55:54 +0000,Mon; 28 Sep 2015 21:10:31 +0000,Tue; 10 Jul 2012 16:21:55 +0000,,,,,YARN-2332;HDFS-453;MAPREDUCE-679;MAPREDUCE-506,https://issues.apache.org/jira/browse/MAPREDUCE-2818
MAPREDUCE-2819,Bug,Minor,test,extend JobClient.runJob(JobConf) with the ability to take a timeout; so fail better during test runs,Tests that submit jobs via JobClient hang until they are killed if something goes wrong in the back end -JobClient does not impose limits on how long runs should take; but JUnit does. If we had an overload of runJob() that took a timeout; JobClient could kill a job that was taking too long; extracting the stack trace and better diagnostics to the test reports.,Closed,Cannot Reproduce,,Steve Loughran,Steve Loughran,Wed; 12 Nov 2008 10:46:55 +0000,Tue; 30 Jun 2015 07:19:00 +0000,Mon; 3 Mar 2014 10:07:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2819
MAPREDUCE-2820,Bug,Major,,Task tracker should not ask for tasks if its temp disk space is almost full,I observed a case where a task tracker still asked for task even though the available disk space on the machine is less than 1%. Consequently; it had hard time to finish the tasks.,Resolved,Fixed,,Ravi Gummadi,Runping Qi,Wed; 27 Aug 2008 01:14:40 +0000,Fri; 18 Jul 2014 22:32:05 +0000,Fri; 18 Jul 2014 22:32:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2820
MAPREDUCE-2821,Bug,Blocker,mrv2,[MR-279] Missing fields in job summary logs ,"The following fields are missing in the job summary logs in mrv2:  	numSlotsPerMap 	numSlotsPerReduce 	clusterCapacity (Earlier known as clusterMapCapacity and clusterReduceCapacity in 0.20.x)    The first two fields are important to know if the job was a High RAM job or not and the last field is important to know the total available resource in the cluster during job execution.",Closed,Fixed,,Mahadev konar,Ramya Sunil,Thu; 11 Aug 2011 18:27:11 +0000,Tue; 15 Nov 2011 00:49:22 +0000,Tue; 25 Oct 2011 06:26:06 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2821
MAPREDUCE-2822,Bug,Major,,TaskTracker.offerService could handle IO and Remote Exceptions better,The core offerService() loop has a try catch wrapper that catches and processes exceptions. Most cause offerService() to return; which then triggers a sleep and restart in the main loop. But some exceptions are just logged and ignored; which may be inappropriate,Resolved,Incomplete,,Unassigned,Steve Loughran,Thu; 21 Aug 2008 13:11:22 +0000,Fri; 18 Jul 2014 22:16:29 +0000,Fri; 18 Jul 2014 22:16:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2822
MAPREDUCE-2823,New Feature,Major,,map-reduce doctor (Mr Doctor),Problem Description:    Users typically submit jobs with sub-optimal parameters resulting in under-utilization; black-listed task-trackers; time-outs; re-tries etc.   Issue can be mitigated by submitting job with custom Hadoop parameters.,Resolved,Duplicate,HADOOP-4179,Unassigned,Amir Youssefi,Thu; 14 Aug 2008 23:36:42 +0000,Fri; 18 Jul 2014 20:57:20 +0000,Fri; 18 Jul 2014 20:57:20 +0000,,,,,HADOOP-4179,https://issues.apache.org/jira/browse/MAPREDUCE-2823
MAPREDUCE-2824,Bug,Major,test,MiniMRCluster should have an idempotent shutdown,It looks on a quick skim-through that the org.apache.hadoop.mapred.MiniMRCluster class has nothing to stop a caller calling shutdown() more than once; with possible adverse consequences. This will normally only show up if a test fails at precisely the wrong place.,Resolved,Fixed,,Unassigned,Steve Loughran,Mon; 28 Jul 2008 13:38:09 +0000,Fri; 18 Jul 2014 18:24:54 +0000,Fri; 18 Jul 2014 18:24:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2824
MAPREDUCE-2825,Improvement,Minor,test,Factor out commonly used code in mapred testcases,The commonly used code in the testcases are made static like TestRackAwareTaskPlacement.configureJobConf(). It would be nice to factor out these apis and either add it to a class like StringUtils or into a separate dir like utils.,Resolved,Not A Problem,,Unassigned,Amar Kamat,Fri; 11 Jul 2008 06:22:51 +0000,Wed; 11 Jul 2012 08:17:45 +0000,Wed; 11 Jul 2012 08:17:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2825
MAPREDUCE-2826,Improvement,Major,,Change the job state observer classes to interfaces,Schedulers will most often want to be the observers of the job state events in a single class. Therefore; I think they should  be interfaces which can have multiple inheritance.,Resolved,Incomplete,,Vivek Ratan,Owen O'Malley,Mon; 21 Jul 2008 17:20:05 +0000,Fri; 18 Jul 2014 18:17:30 +0000,Fri; 18 Jul 2014 18:17:30 +0000,,,,,MAPREDUCE-342,https://issues.apache.org/jira/browse/MAPREDUCE-2826
MAPREDUCE-2827,Bug,Minor,,Test code can create Integer.MIN_INT when trying to create a random non-negative integer,"Sadly; Math.abs returns Integer.MIN_VALUE when passed Integer.MIN_VALUE  Thus the code in  org.apache.hadoop.mapred.TestMapRed appears to need to consider this case.  Patch below.  Index: . ===================================================================  .	(revision 8259) +++ .	(working copy) @@ -97;7 +97;9 @@        int randomCount = key.get();         for (int i = 0; i  randomCount; i++)  { -        out.collect(new IntWritable(Math.abs(r.nextInt())); new IntWritable(randomVal)); +    	int collectKey = Math.abs(r.nextInt()); +    	if (collectKey == Integer.MIN_VALUE) collectKey = Integer.MAX_VALUE; +        out.collect(new IntWritable(collectKey); new IntWritable(randomVal));        }      }      public void close() {",Resolved,Incomplete,,Unassigned,Tim Halloran,Mon; 16 Jun 2008 15:03:22 +0000,Fri; 18 Jul 2014 05:38:02 +0000,Fri; 18 Jul 2014 05:38:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2827
MAPREDUCE-2828,Bug,Minor,,SequenceFile.MergeQueue.merge inadvertently creates merge-outputs in the wrong FileSystem; at times in the InMemoryFileSystem,The offending code is:      fs is InMemoryFileSystem when ReduceTask.ReduceCopier constructs it... so the wrong FileSystem is used during intermediate merges.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Wed; 7 May 2008 05:44:45 +0000,Thu; 11 Aug 2011 18:44:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2828
MAPREDUCE-2829,Bug,Major,,TestMiniMRMapRedDebugScript times out,I am running TestMiniMRMapRedDebugScript from trunc. This is what I see in the stdout:    Stderr and debugout both say: Bailing out. BTW on Windows everything works just fine.,Resolved,Fixed,,Unassigned,Konstantin Shvachko,Thu; 22 Nov 2007 02:40:09 +0000,Thu; 17 Jul 2014 18:38:09 +0000,Thu; 17 Jul 2014 18:38:09 +0000,,,,,HADOOP-4410,https://issues.apache.org/jira/browse/MAPREDUCE-2829
MAPREDUCE-2830,Improvement,Major,documentation,Document config parameters for each Map-Reduce class/interface,I propose we add a table in the  oc for each user-facing Map-Reduce interface class. Clearly some parameters affect more than one place and they should be put in more than one table.  For e.g.  Mapper - io.sort.mb; io.sort.factor Reducer - fs.inmemory.size.mb ... etc.  It would very nice to explain how it interacts with the framework and rest of config params etc.  Thoughts?,Open,Unresolved,,Unassigned,Arun C Murthy,Tue; 30 Oct 2007 05:28:17 +0000,Thu; 17 Jul 2014 18:18:14 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2830
MAPREDUCE-2831,Improvement,Major,,Some changes to Record I/O interfaces,"I wanted to suggest some changes to the Record I O interfaces.   Under org.apache.hadoop.record; RecordInput and RecordOutput are the interfaces to serialize and deserialize basic types for Java-generated stubs. All the methods in RecordInput and RecordOutput take a parameter; a string; called 'tag'. As far as I can see; this tag is used only for XML-based serialization; to write out the name of the field th indicates whether the record is nested or not 	Currently; both startRecord() and endRecord() in  IArchive take an additional parameter; a reference to a hadoop record. This is never used anywhere not required (the corresponding methods in RecordInput and RecordOutput don't take any parameters; which is the right thing to do); and should be removed.",Open,Unresolved,,Unassigned,Vivek Ratan,Thu; 11 Oct 2007 09:32:46 +0000,Thu; 11 Aug 2011 18:55:22 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2831
MAPREDUCE-2832,Bug,Major,,sleeping with lock held in JobEndNotifier,FindBugs points out a problem in JobEndNotifier from HADOOP-1111.     I haven't tracked through the code; but I suspect it should be a wait instead of a sleep.,Open,Unresolved,,Owen O'Malley,Owen O'Malley,Mon; 8 Oct 2007 18:26:46 +0000,Thu; 11 Aug 2011 18:55:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2832
MAPREDUCE-2833,New Feature,Major,,Job Tracker needs to collect more job/task execution stats and save them to DFS file,In order to facilitate offline analysis on the dynamic behaviors and performance characterics of map reducers    The data collection should be optional. That is; a job tracker can turn off such data collection; and  in that case; it should not pay the cost.  The job tracker should organize the in memory version of the collected data in such a way that: 1. it does not consume excessive amount of memory 2. the data may be suitable for presenting through the Web status pages.  The data saved on DFS files should be in hadoop record format.,Resolved,Fixed,,Unassigned,Runping Qi,Wed; 26 Sep 2007 18:28:08 +0000,Thu; 17 Jul 2014 18:01:27 +0000,Thu; 17 Jul 2014 18:01:26 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2833
HADOOP-7540,Improvement,Major,metrics,Add dense update option for metrics2 file sink,Currently; if File sink is enabled for MRAppMaster or Resourcemanager; it does not populate the file with all the available attributes. It would be useful for debugging and admin purpose to have all the metrics populated in the file.  For eg: MRAppMaster metrics currently logs value only for JobsRunning even though the total available job level metrics are JobsCompleted; JobsFailed; JobsKilled; JobsPreparing etc,Open,Unresolved,,Luke Lu,Ramya Sunil,Thu; 11 Aug 2011 19:03:29 +0000,Sat; 22 Sep 2012 09:37:05 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/HADOOP-7540
MAPREDUCE-2835,Improvement,Major,,Make per-job counter limits configurable,The per-job counter limits introduced in MAPREDUCE-1943 are fixed; except for the total number allowed per job (mapreduce.job.counters.limit). It would be useful to make them all configurable.,Closed,Fixed,,Tom White,Tom White,Thu; 11 Aug 2011 20:35:30 +0000,Wed; 17 Oct 2012 18:27:25 +0000,Thu; 15 Mar 2012 00:33:07 +0000,,0.20.204.0,,,MAPREDUCE-901,https://issues.apache.org/jira/browse/MAPREDUCE-2835
MAPREDUCE-2836,Improvement,Minor,contrib/fair-share,Provide option to fail jobs when submitted to non-existent pools.,In some environments; it might be desirable to explicitly specify the fair scheduler pools and to explicitly fail jobs that are not submitted to any of the pools.   Current behavior of the fair scheduler is to submit jobs to a default pool if a pool name isn't specified or to create a pool with the new name if the pool name doesn't already exist. There should be a configuration option for the fair scheduler that causes it to noisily fail the job if it's submitted to a pool that isn't pre-specified or if the specified pool doesn't exist.,Closed,Fixed,,Ahmed Radwan,Jeff Bean,Thu; 11 Aug 2011 21:25:47 +0000,Wed; 17 Oct 2012 18:27:24 +0000,Fri; 16 Sep 2011 22:23:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2836
MAPREDUCE-2837,Bug,Major,,MR-279: Bug fixes ported from y-merge,Similar to MAPREDUCE-2679.,Resolved,Fixed,,Unassigned,Arun C Murthy,Thu; 11 Aug 2011 23:47:09 +0000,Mon; 15 Aug 2011 18:01:19 +0000,Fri; 12 Aug 2011 21:00:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2837
MAPREDUCE-2838,Improvement,Major,,to fix mapreduce builds to use the new hadoop common test jars,"maprecude builds are still resolving the old hadoop-common-test jars.. Instead ivy classifiers should be used to resolve the new hadoop-common test jars ; as maven publishes test jars with classifier tests and not as a separate artifact.  ivy:resolve 	SUCCESSFUL  org.apache.hadoop#hadoop-common;0.23.0-SNAPSHOT!hadoop-common.jar (1979ms) ivy:resolve downloading https: hadoop-common-test-0.23.0-20110727.191243-218.jar ... ivy:resolve ........................................................................................................................ (885kB)",Resolved,Fixed,,Arun C Murthy,Giridharan Kesavan,Thu; 11 Aug 2011 23:52:57 +0000,Wed; 24 Aug 2011 13:48:46 +0000,Tue; 23 Aug 2011 22:04:41 +0000,,0.23.0,,MAPREDUCE-2868,,https://issues.apache.org/jira/browse/MAPREDUCE-2838
MAPREDUCE-2839,Bug,Major,,MR Jobs fail on a secure cluster with viewfs,TokenCache needs to use the new FileSystem.getDelegationTokens api for it to work with viewfs.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 12 Aug 2011 05:16:32 +0000,Tue; 15 Nov 2011 00:48:34 +0000,Sat; 13 Aug 2011 20:22:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2839
MAPREDUCE-2840,Bug,Minor,mrv2,mr279 TestUberAM.testSleepJob test fails,Currently the TestUberAM.testSleepJob  is failing on the mr279 branch.   snippet of failure: junit.framework.AssertionFailedError: null    597),Closed,Fixed,,Jonathan Eagles,Thomas Graves,Fri; 12 Aug 2011 16:05:09 +0000,Tue; 15 Nov 2011 00:48:44 +0000,Mon; 17 Oct 2011 01:25:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2840
MAPREDUCE-2841,Improvement,Major,task,Task level native optimization,I'm recently working on native optimization for MapTask based on JNI.   The basic idea is that; add a NativeMapOutputCollector to handle k value type; comparator type; combiner are all compatible; then MapTask can choose to enable NativeMapOutputCollector.  This is only a preliminary test; more work need to be done. I expect better final results; and I believe similar optimization can be adopt to reduce task and shuffle too.,Resolved,Fixed,MAPREDUCE-1270;MAPREDUCE-2446,Sean Zhong,Binglin Chang,Sat; 13 Aug 2011 07:29:51 +0000,Thu; 19 Oct 2017 05:54:02 +0000,Sat; 13 Sep 2014 01:47:29 +0000,,,,,MAPREDUCE-6106;MAPREDUCE-3247;MAPREDUCE-3246;MAPREDUCE-1270;MAPREDUCE-6985;MAPREDUCE-5962;HADOOP-10855,https://issues.apache.org/jira/browse/MAPREDUCE-2841
MAPREDUCE-2842,Bug,Major,build;mrv2,Maven build issues in MR2 ,"mapreduce has not been rebased on top of trunk     	mapreduce dir packaging reusable across different components)",Resolved,Fixed,,Unassigned,Alejandro Abdelnur,Mon; 15 Aug 2011 16:50:41 +0000,Mon; 9 Mar 2015 21:35:44 +0000,Mon; 9 Mar 2015 21:35:44 +0000,,0.23.0,maven,,,https://issues.apache.org/jira/browse/MAPREDUCE-2842
MAPREDUCE-2843,Bug,Major,mrv2,[MR-279] Node entries on the RM UI are not sortable,The nodemanager entries on the RM UI is not sortable unlike the other web pages.,Closed,Fixed,,Abhijit Suresh Shingate,Ramya Sunil,Mon; 15 Aug 2011 19:24:40 +0000,Mon; 16 Mar 2015 17:57:11 +0000,Wed; 28 Sep 2011 05:37:51 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2843
MAPREDUCE-2844,Bug,Trivial,mrv2,[MR-279] Incorrect node ID info ,The node ID info for the nodemanager entires on the RM UI incorrectly displays the value of $yarn.server.nodemanager.address instead of the ID.,Closed,Fixed,,Ravi Teja Ch N V,Ramya Sunil,Mon; 15 Aug 2011 19:32:08 +0000,Tue; 15 Nov 2011 00:48:24 +0000,Thu; 8 Sep 2011 18:51:00 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2844
MAPREDUCE-2845,Bug,Minor,client;distributed-cache,Default replication level mapred.submit.replication=10 causes warnings on small clusters,"By default; the replication level for job jars; libjars and the distributed cache in general is mapred.submit.replication=10. This yields under-replication warnings for these files on small clusters (less than 10 data nodes) when using fsck (""hadoop fsck"") on their HDFS.  Example on an 8-node cluster:    job.jar:  Under replicated blk_-6996370258385460742_366223. Target Replicas is 10 but found 8 replica(s).",Open,Unresolved,,Unassigned,Christoph Schmitz,Tue; 16 Aug 2011 06:54:17 +0000,Tue; 27 Sep 2011 12:25:06 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2845
MAPREDUCE-2846,Bug,Blocker,task;task-controller;tasktracker,a small % of all tasks fail with DefaultTaskController,After upgrading our test 0.20.203 grid to 0.20.204-rc2; we ran terasort to verify operation.  While the job completed successfully; approx 10% of the tasks failed with task runner execution errors and the inability to create symlinks for attempt logs.,Closed,Fixed,,Owen O'Malley,Allen Wittenauer,Tue; 16 Aug 2011 16:38:31 +0000,Mon; 5 Sep 2011 14:23:50 +0000,Wed; 24 Aug 2011 23:57:39 +0000,,0.20.204.0,,,MAPREDUCE-2415;MAPREDUCE-2804,https://issues.apache.org/jira/browse/MAPREDUCE-2846
MAPREDUCE-2847,Improvement,Trivial,,A tiny improvement for the LOG format,"A space character is missing in the file  ""src  840):LOG.debug(""TaskInProgress adding"" + status.getNextRecordRange())"".",Resolved,Not A Problem,,XieXianshan,XieXianshan,Wed; 17 Aug 2011 15:15:01 +0000,Wed; 18 Mar 2015 10:16:03 +0000,Wed; 18 Mar 2015 10:16:03 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2847
MAPREDUCE-2848,Improvement,Major,,Upgrade avro to 1.5.2,Upgrade avro to the current version requires some code changes in mapreduce due to avro package split. The mapreduce part of the change will be part of the atomic commit of HADOOP-7264 after MAPREDUCE-279 is merged to trunk. The jira is for mapreduce change log.,Closed,Fixed,,Luke Lu,Luke Lu,Wed; 17 Aug 2011 18:36:19 +0000,Tue; 15 Nov 2011 00:48:50 +0000,Mon; 22 Aug 2011 21:46:20 +0000,,0.23.0,,MAPREDUCE-2868,,https://issues.apache.org/jira/browse/MAPREDUCE-2848
MAPREDUCE-2849,Improvement,Major,mrv2,Add javadoc and site documentation for MRv2,Need API and site documentation for MRv2. The initial patch will use maven's default apt format for site documentation.,Closed,Duplicate,MAPREDUCE-2890,Luke Lu,Luke Lu,Wed; 17 Aug 2011 20:13:39 +0000,Tue; 15 Nov 2011 00:49:27 +0000,Mon; 31 Oct 2011 04:44:38 +0000,,0.23.0,docuentation,,,https://issues.apache.org/jira/browse/MAPREDUCE-2849
MAPREDUCE-2850,Sub-task,Major,tasktracker,Add test for TaskTracker disk failure handling (MR-2413),MR-2413 doesn't have any test coverage that eg tests that the TT can survive disk failure.,Closed,Fixed,,Ravi Gummadi,Eli Collins,Wed; 17 Aug 2011 22:37:05 +0000,Wed; 17 Oct 2012 18:27:26 +0000,Thu; 3 Nov 2011 20:15:34 +0000,,0.20.204.0,,,MAPREDUCE-2413;MAPREDUCE-3419,https://issues.apache.org/jira/browse/MAPREDUCE-2850
MAPREDUCE-2851,Sub-task,Major,tasktracker;test,Add test for userlogs on multiple disks (MR-2415),MR-2415 has not test coverage that eg userlogs are in fact put on multiple disks and can survive failure of an individual disk.,Open,Unresolved,,Unassigned,Eli Collins,Wed; 17 Aug 2011 22:39:52 +0000,Tue; 14 May 2013 05:14:40 +0000,,,0.20.204.0,,,MAPREDUCE-2415,https://issues.apache.org/jira/browse/MAPREDUCE-2851
MAPREDUCE-2852,Bug,Major,tasktracker,Jira for YDH bug 2854624 ,The DefaultTaskController and LinuxTaskController reference Yahoo! internal bug 2854624:     This jira tracks this TODO. If someone w  access to Yahoo's bugzilla could update this jira with what the bug is that would be great.,Closed,Fixed,,Kihwal Lee,Eli Collins,Wed; 17 Aug 2011 22:56:05 +0000,Wed; 19 Oct 2011 00:26:10 +0000,Thu; 18 Aug 2011 21:02:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2852
MAPREDUCE-2853,New Feature,Major,benchmarks;examples,"Add ""teraread"" example","Teragen is a good benchmark of raw DFS write throughput. Terasort is a good benchmark of the whole MR system (input; shuffle; output). I've added a simple ""teraread"" example which reads through the terasort input data without performing any processing: this acts as a good benchmark of a read-only workload (similar to real-life ""find a needle in a haystack"" MR jobs)",Open,Unresolved,,Todd Lipcon,Todd Lipcon,Thu; 18 Aug 2011 01:31:19 +0000,Mon; 9 Mar 2015 23:12:48 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2853
MAPREDUCE-2854,Bug,Major,,update INSTALL with config necessary run mapred on yarn,The following config is needed to run mapreduce on yarn framework.  Document it in the INSTALL doc.  property name mapreduce.framework.name property   The INSTALL doc also still references the old 22 mapred examples jar.,Closed,Fixed,,Thomas Graves,Thomas Graves,Thu; 18 Aug 2011 15:45:34 +0000,Tue; 15 Nov 2011 00:48:48 +0000,Thu; 18 Aug 2011 21:26:17 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2854
MAPREDUCE-2855,Bug,Major,,ResourceBundle lookup during counter name resolution takes a lot of time,Loading a job status page in trunk takes a lot of time; and it seems like most of the time is spent resolving counter names. Looking through the JDK source; ResourceBundle.getBundle(String) ends up calling getClassContext() which is not very efficient. I think if we pass our own classloader manually it will be faster. In Counters.incrAllCounters; we may also be able to avoid setting the counter name if one is already set.,Resolved,Fixed,,Siddharth Seth,Todd Lipcon,Thu; 18 Aug 2011 17:04:35 +0000,Sat; 18 Aug 2012 19:22:33 +0000,Tue; 28 Feb 2012 02:02:36 +0000,,0.23.0,mrv2,,,https://issues.apache.org/jira/browse/MAPREDUCE-2855
MAPREDUCE-2856,Task,Major,,wire hadoop-mapreduce build to trunk build in Maven POM,hadoop-mapreduce is not wired to the trunk build.  The trunk pom.xml must be updated to contain.,Resolved,Duplicate,HADOOP-7560,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 18 Aug 2011 18:08:32 +0000,Thu; 2 May 2013 02:29:43 +0000,Fri; 26 Aug 2011 00:02:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2856
MAPREDUCE-2857,Bug,Minor,,When reducers are complete; trailing mappers delay job completion,Sometimes; mappers restart themselves for some reason (there are several reasons; for example; because it has lost access to the data it generated which a reducer may later need.). However; not all reducers will depend on that mapper. Accordingly;  jobs can get into a state in which all reducers have completed but some mappers are still running. This is a bug--when the reducers have completed; the job should be marked as completed immediately and any trailing map tasks killed.,Open,Unresolved,,Unassigned,Adam Kramer,Thu; 18 Aug 2011 18:38:35 +0000,Thu; 18 Aug 2011 18:38:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2857
MAPREDUCE-2858,Sub-task,Blocker,applicationmaster;mrv2;security,MRv2 WebApp Security,"In MRv2; while the system servers (ResourceManager (RM); NodeManager (NM) and NameNode (NN)) run as ""trusted"" system users; the application masters (AM) run as users who submit the application. While this offers great flexibility to run multiple version of mapreduce frameworks (including their UI) on the same Hadoop cluster; it has significant implication for the security of webapps (Please do not discuss company specific vulnerabilities here).  Requirements:   	Secure authentication for AM (for app notes of threat-modeling and counter measures will be posted on the wiki.",Closed,Fixed,,Robert Joseph Evans,Luke Lu,Thu; 18 Aug 2011 21:57:00 +0000,Tue; 15 Nov 2011 00:49:09 +0000,Wed; 26 Oct 2011 06:34:23 +0000,,0.23.0,,,MAPREDUCE-3231;MAPREDUCE-3174,https://issues.apache.org/jira/browse/MAPREDUCE-2858
MAPREDUCE-2859,Bug,Major,,mapreduce trunk is broken with eclipse plugin contrib,ant compile with eclipse home fails mapreduce trunk builds.  $ANT_HOME build.xml:62: Compile failed; see the compiler error output for details.,Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Thu; 18 Aug 2011 23:53:41 +0000,Tue; 15 Nov 2011 00:48:52 +0000,Wed; 24 Aug 2011 06:47:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2859
MAPREDUCE-2860,Bug,Major,mrv2,Fix log4j logging in the maven test cases.,At present the logging in the new test cases is broken because surefire isnt able to find the log4j properties file.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 19 Aug 2011 05:45:49 +0000,Tue; 15 Nov 2011 00:48:44 +0000,Fri; 19 Aug 2011 17:14:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2860
MAPREDUCE-2861,Bug,Major,,Modify version_control.html to reflect new path to mapreduce trunk,We need to modify http: hadoop-mapreduce.,Resolved,Invalid,,Unassigned,Vinod Kumar Vavilapalli,Fri; 19 Aug 2011 07:32:30 +0000,Mon; 26 Sep 2011 14:08:47 +0000,Mon; 26 Sep 2011 14:08:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2861
MAPREDUCE-2862,Bug,Major,,Infinite loop in CombineFileInputFormat#getMoreSplits(); with missing blocks,Hi; we met the infinite loop on CombineFileInputFormat#getMoreSplits().  At first; we lost some blocks by mis-operation . Then; one job tried to use these missing blocks. At that time getMoreSplits() goes into the infinite loop.  From our investigation; this List could be an empty array.  https:  L348  We're now creating the patch against this problem...,Open,Unresolved,,Unassigned,Kazuki Ohta,Fri; 19 Aug 2011 16:55:45 +0000,Fri; 23 Dec 2011 17:37:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2862
MAPREDUCE-2863,Improvement,Blocker,mrv2;nodemanager;resourcemanager,Support web-services for RM & NM,It will be very useful for RM and NM to support web-services to export json xml.,Closed,Fixed,YARN-990,Thomas Graves,Arun C Murthy,Fri; 19 Aug 2011 17:35:18 +0000,Tue; 4 Feb 2014 23:45:53 +0000,Tue; 13 Dec 2011 23:14:39 +0000,,0.23.0,,MAPREDUCE-3336;MAPREDUCE-3342,HADOOP-7872,https://issues.apache.org/jira/browse/MAPREDUCE-2863
MAPREDUCE-2864,Improvement,Major,jobhistoryserver;mrv2;nodemanager;resourcemanager,Renaming of configuration property names in yarn,"Now that YARN has been put in to trunk we should do something similar to MAPREDUCE-849.  We should go back and look at all of the configurations that have been added in and rename them as needed to be consistent and subdivided by component.   	We should use all lowercase in the config names. e.g.; we should use appsmanager instead of appsManager etc. 	history server config names should be prefixed with mapreduce instead of yarn.",Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 19 Aug 2011 19:40:40 +0000,Mon; 16 Mar 2015 17:57:12 +0000,Fri; 9 Sep 2011 01:59:05 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-2876,,https://issues.apache.org/jira/browse/MAPREDUCE-2864
MAPREDUCE-2865,Bug,Major,documentation;mrv2,MRV2 Job.java and others in MRv2 client need javadocs in it.,This may fall under another JIRA already filed; but Job. ocs in them.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Mon; 22 Aug 2011 13:25:29 +0000,Mon; 9 Mar 2015 23:23:12 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2865
MAPREDUCE-2866,Bug,Major,jobtracker;tasktracker,Ignoring 'duplicate' heartbeat from tracker_x:localhost/127.0.0.1:35419'; resending the previous 'lost' response message is coming continuously for some time,nan,Resolved,Not A Problem,,Devaraj K,Devaraj K,Mon; 22 Aug 2011 15:06:37 +0000,Wed; 24 Aug 2011 13:30:47 +0000,Wed; 24 Aug 2011 13:30:47 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2866
MAPREDUCE-2867,Bug,Major,,Remove Unused TestApplicaitonCleanup in resourcemanager/applicationsmanager.,TestApplicationCleanup in resourcemanager TestApplicationCleanup which tests all the cleanup code for container and applications. We should remove the unused one in the trunk.,Closed,Fixed,,Mahadev konar,Mahadev konar,Mon; 22 Aug 2011 16:48:23 +0000,Tue; 15 Nov 2011 00:48:07 +0000,Mon; 22 Aug 2011 17:16:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2867
MAPREDUCE-2868,Bug,Major,build,ant build broken in hadoop-mapreduce dir,The ant build target doesn't work in the hadoop-mapreduce directory since the mavenization of hdfs changes were checked in.  Error it gives is: ivy:resolve           :::::::::::::::::::::::::::::::::::::::::::::: ivy:resolve           ::          UNRESOLVED DEPENDENCIES         :: ivy:resolve           :::::::::::::::::::::::::::::::::::::::::::::: ivy:resolve           :: org.apache.avro#avro-ipc;working@host: not found ivy:resolve           :: org.apache.hadoop#hadoop-alfredo;working@host: not found ivy:resolve           :: commons-daemon#commons-daemon;working@host: not found ivy:resolve           ::::::::::::::::::::::::::::::::::::::::::::::  Steps I followed: check out trunk build common mapred:  mvn clean install assembly:assembly -DskipTests ant veryclean tar -Dresolvers=internal  ---- this fails,Closed,Fixed,,Mahadev konar,Thomas Graves,Mon; 22 Aug 2011 17:44:49 +0000,Tue; 15 Nov 2011 00:48:51 +0000,Tue; 23 Aug 2011 16:10:23 +0000,,,,MAPREDUCE-2838;MAPREDUCE-2848,,https://issues.apache.org/jira/browse/MAPREDUCE-2868
MAPREDUCE-2869,Sub-task,Major,,DelegationTokenRenewal should handle abstract delegation tokens,DelegationTokenRenewal only handles tokens of type DelegationTokenIdentifiers.  This precludes renewal of job manager tokens (which will be fixed on another jira).  It should accept AbstractDelegationTokenIdentifiers.,Closed,Duplicate,MAPREDUCE-2764,Daryn Sharp,Daryn Sharp,Mon; 22 Aug 2011 20:40:41 +0000,Wed; 19 Oct 2011 00:30:19 +0000,Thu; 15 Sep 2011 14:48:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2869
HADOOP-7566,Bug,Major,,MR tests are failing  webapps/hdfs not found in CLASSPATH,nan,Closed,Fixed,,Alejandro Abdelnur,Mahadev konar,Mon; 22 Aug 2011 21:50:32 +0000,Wed; 2 Jan 2013 19:36:07 +0000,Mon; 22 Aug 2011 22:25:45 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-7566
MAPREDUCE-2871,Test,Major,documentation;mrv2,Docs updates for MR2,Jira for docs changes needed to reflect MR2 (Eg the cluster setup page). If there's a lot of them this can be an umbrella jira.,Closed,Duplicate,MAPREDUCE-2890,Unassigned,Eli Collins,Mon; 22 Aug 2011 23:26:37 +0000,Tue; 15 Nov 2011 00:49:02 +0000,Mon; 31 Oct 2011 04:44:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2871
MAPREDUCE-2872,Improvement,Major,tasktracker,Optimize TaskTracker memory usage,"We observe high memory usage of framework level components on slave node; mainly TaskTracker  Child; especially for large clusters. To be clear at first; large jobs with 10000-100000 map and 10000 reduce tasks are very common in our offline cluster; and will very likely continue to grow. This is reasonable because the number of map  reduce slots are in the same range; and it's impractical for users to reduce their job's task number without execution time penalty.   High memory consumption will:  	Limit the memory used by up level application; 	Reduce page cache space; which plays a  important role in spill; merge; shuffle and even HDFS performance; 	Increase the probability of slave node OOM; which may affect storage layer(HDFS) too.    A stable TT with predictable memory behavior is desired; this also applies to Child JVM.  This issue focuses on TaskTracker memory optimization; on our cluster; TaskTracker use 600M+ memory  300%(3core) CPU at peak; and 300M+ memory  much less CPU in average; so we need to set -Xmx to 1000M for TT to prevent OOM; then the TT memory is in 200M-1200M range; and 800M in average.   Here are some ideas:    Jetty http connection use a lot memory when these are many requests in queue; we need to limit the length of the queue; combine multiple requests into one request; or use netty just like MR2  TaskCompletionEvents use a lot memory too if a job have large number of map task; this won't be a problem in MR2; but can be optimized; A typical TaskCompletionEvent object use 296 bytes memory; a job with 100000 map will use about 30M memory; problem will appear if there are some big RunningJob in a TaskTracker. There are more memory efficient implementations for TaskCompletionEvent.  IndexCache: memory of indexcache varies directly as reduce number; on large cluster 10MB of indexcache is not enough;  we set it to 100MB; again use primitive long[] instead of IndexRecord[] can save 50% of memory.  Although some of the above won't be a problem in MR-v2; since MR-v1 is still widely used; I think optimizations are needed.",Resolved,Won't Fix,,Binglin Chang,Binglin Chang,Tue; 23 Aug 2011 06:50:53 +0000,Fri; 15 May 2015 17:51:50 +0000,Fri; 15 May 2015 17:51:49 +0000,,0.20.203.0,memory;optimization,,,https://issues.apache.org/jira/browse/MAPREDUCE-2872
MAPREDUCE-2873,Test,Major,jobhistoryserver;mrv2,The MRV2 Web App Tests need to be imporved,The current set of unittests for the Application Master and the JobHistory server are very lacking.  They look like    All this example does is render the Job Page with an fake application context; but the page it is rendering does almost nothing.  Because no JobId is provided the test skips most of JobPage.  All it does is verify that not exceptions are thrown when it should attempt to verify that the correct data is returned.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Tue; 23 Aug 2011 17:51:32 +0000,Mon; 9 Mar 2015 23:05:32 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2873
MAPREDUCE-2874,Bug,Major,mrv2,ApplicationId printed in 2 different formats and has 2 different toString routines that are used,"Looks like the ApplicationId is now printed in 2 different formats.  ApplicationIdPBImpl. toString that prints it like:      return _join(""app""; id.getClusterTimestamp(); id.getId());",Closed,Fixed,,Eric Payne,Thomas Graves,Tue; 23 Aug 2011 20:46:35 +0000,Tue; 15 Nov 2011 00:48:22 +0000,Mon; 12 Sep 2011 23:18:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2874
MAPREDUCE-2875,Bug,Major,,NM does not communicate Container crash to RM,Faulty container crash detection code path in NodeManager.  Steps: Run a job.  Kill the AM container in NM.  NM logs has: org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_KILLED_ON_REQUEST at RUNNING         at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory. 685),Closed,Duplicate,MAPREDUCE-3031,Siddharth Seth,Sharad Agarwal,Wed; 24 Aug 2011 08:45:15 +0000,Tue; 15 Nov 2011 00:49:29 +0000,Wed; 19 Oct 2011 12:02:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2875
MAPREDUCE-2876,Bug,Critical,mrv2,ContainerAllocationExpirer appears to use the incorrect configs,ContainerAllocationExpirer sets the expiration interval to be RMConfig.CONTAINER_LIVELINESS_MONITORING_INTERVAL but uses AMLIVELINESS_MONITORING_INTERVAL as the interval.  This is very different from what AMLivelinessMonitor does.  There should be two configs RMConfig.CONTAINER_LIVELINESS_MONITORING_INTERVAL for the monitoring interval and RMConfig.CONTAINER_EXPIRY_INTERVAL for the expiry.,Closed,Fixed,,Anupam Seth,Robert Joseph Evans,Wed; 24 Aug 2011 20:12:42 +0000,Tue; 15 Nov 2011 00:48:23 +0000,Mon; 10 Oct 2011 03:07:36 +0000,,0.23.0,,MAPREDUCE-2864,,https://issues.apache.org/jira/browse/MAPREDUCE-2876
MAPREDUCE-2877,Bug,Major,,Add missing Apache license header in some files in MR and also add the rat plugin to the poms.,Some of the files in MR have a missing Apache header files. We also need to add the apache-rat plugin to be able to run rat automatically via the top level pom.,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 25 Aug 2011 08:20:59 +0000,Tue; 15 Nov 2011 00:50:00 +0000,Thu; 25 Aug 2011 17:17:33 +0000,,,,HADOOP-7578,,https://issues.apache.org/jira/browse/MAPREDUCE-2877
MAPREDUCE-2878,Bug,Trivial,,Fix the INSTALL file,The URL in INSTALL should be changed accordingly; after the layout of directories  has been changed. And meanwhile;the HDFS should no longer be compiled with ant but maven.,Resolved,Not A Problem,,XieXianshan,XieXianshan,Thu; 25 Aug 2011 08:51:06 +0000,Mon; 28 Sep 2015 21:10:32 +0000,Tue; 27 Dec 2011 09:32:13 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2878
MAPREDUCE-2879,Bug,Major,,Change mrv2 version to be 0.23.0-SNAPSHOT,Currently yarn.version and hadoop-mapreduce.version are set to be 1.0; clearly it's 0.23.0.   Also; we should stop using ${yarn.version} and ${hadoop-mapreduce.version} in all the poms; maven doesn't like the version substitutions - it complains bitterly!,Resolved,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 25 Aug 2011 18:32:21 +0000,Tue; 10 Jan 2012 04:44:04 +0000,Thu; 25 Aug 2011 19:14:21 +0000,,,,,MAPREDUCE-2880,https://issues.apache.org/jira/browse/MAPREDUCE-2879
MAPREDUCE-2880,Improvement,Blocker,mrv2,Fix classpath construction for MRv2,MRConstants. refers a hard-coded version of MR AM jar. The build config works around with a symlink. The deployment currently needs symlink workaround as well. We need to fix this so that we can actually launch arbitrary versions of AMs.,Closed,Fixed,MAPREDUCE-2801,Arun C Murthy,Luke Lu,Thu; 25 Aug 2011 19:17:28 +0000,Tue; 15 Nov 2011 00:48:46 +0000,Wed; 21 Sep 2011 18:54:20 +0000,,0.23.0,,MAPREDUCE-2736,MAPREDUCE-2879,https://issues.apache.org/jira/browse/MAPREDUCE-2880
MAPREDUCE-2881,Bug,Major,build,"mapreduce ant compilation fails ""java.lang.IllegalStateException: impossible to get artifacts""","ivy:resolve 	found com.cenqua.clover#clover;3.0.2 in fs ivy:resolve  ivy:resolve :: problems summary :: ivy:resolve :::: ERRORS ivy:resolve 	impossible to get artifacts when data has not been loaded. IvyNode = log4j#log4j;1.2.16 ivy:resolve  ivy:resolve :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS  BUILD FAILED  build-contrib.xml:511: impossible to resolve dependencies: 	 lang.IllegalStateException: impossible to get artifacts when data has not been loaded. IvyNode = log4j#log4j;1.2.16",Closed,Fixed,,Giridharan Kesavan,Giridharan Kesavan,Thu; 25 Aug 2011 21:58:15 +0000,Tue; 15 Nov 2011 00:50:08 +0000,Thu; 25 Aug 2011 23:10:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2881
MAPREDUCE-2882,Bug,Minor,test,TestLineRecordReader depends on ant jars,This test is currently importing an ant utility class to read a file - this dependency doesn't work in mavenized land.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 25 Aug 2011 22:34:12 +0000,Tue; 15 Nov 2011 00:48:23 +0000,Wed; 7 Sep 2011 00:16:30 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2882
MAPREDUCE-2883,Bug,Major,test,MR FI tests failing to build,running ant mvn-install in hadoop-mapreduce-project on branch-0.23 fails in the fault injection compilation,Resolved,Won't Fix,,Unassigned,Todd Lipcon,Thu; 25 Aug 2011 23:09:00 +0000,Mon; 9 Mar 2015 20:31:36 +0000,Mon; 9 Mar 2015 20:31:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2883
MAPREDUCE-2884,Bug,Major,mrv1,tmpjars not working when default filesystem mismatches between client and server,"One of the HBase tests is failing which tries to add a local file to the distributed cache using the ""tmpjars"" configuration variable. The first half of the distributedcache setup decides not to copy it to the JT; because the JT is apparently using the same filesystem; but the second half of distributedcache setup tries to check timestamps on a different filesystem where the file does not exist.",Resolved,Won't Fix,,Todd Lipcon,Todd Lipcon,Fri; 26 Aug 2011 00:10:11 +0000,Mon; 9 Mar 2015 20:33:24 +0000,Mon; 9 Mar 2015 20:33:24 +0000,,0.23.0,,HBASE-4254,,https://issues.apache.org/jira/browse/MAPREDUCE-2884
MAPREDUCE-2885,Bug,Blocker,,mapred-config.sh doesn't look for $HADOOP_COMMON_HOME/libexec/hadoop-config.sh,mapred-config.sh doesn't look for $HADOOP_COMMON_HOME hadoop-config.sh and thus fails to find it and errors out.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 26 Aug 2011 17:48:54 +0000,Tue; 15 Nov 2011 00:50:10 +0000,Fri; 26 Aug 2011 17:58:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2885
MAPREDUCE-2886,Bug,Critical,mrv2,Fix Javadoc warnings in MapReduce.,On the current trunk and 0.23; there are 73  oc warnings which is causing the buildbot to -1 every patch in MR. We need to fix this to stabilize the CI precommit builds.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 26 Aug 2011 19:55:56 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Mon; 29 Aug 2011 23:31:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2886
MAPREDUCE-2887,Improvement,Major,,MR changes to match HADOOP-7524 (multiple RPC protocols),nan,Closed,Fixed,,Sanjay Radia,Sanjay Radia,Fri; 26 Aug 2011 21:47:22 +0000,Thu; 2 May 2013 02:29:43 +0000,Sat; 3 Sep 2011 00:48:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2887
MAPREDUCE-2888,Bug,Trivial,build,saveVersion.sh doesn't work when svn copy is staged,The build fails with an error on the sed command; since saveVersion.sh doesn't correctly grab the URL.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 26 Aug 2011 21:47:54 +0000,Mon; 9 Mar 2015 21:58:17 +0000,Mon; 9 Mar 2015 21:58:17 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2888
MAPREDUCE-2889,Sub-task,Critical,documentation;mrv2,Add docs for writing new application frameworks,We need to add docs for writing new application frameworks; including examples;  ocs and sample apps.,Closed,Fixed,,Hitesh Shah,Arun C Murthy,Sun; 28 Aug 2011 04:56:35 +0000,Tue; 15 Nov 2011 00:48:08 +0000,Sat; 1 Oct 2011 05:25:59 +0000,,0.23.0,,MAPREDUCE-2891;MAPREDUCE-2897;MAPREDUCE-2898,MAPREDUCE-2719,https://issues.apache.org/jira/browse/MAPREDUCE-2889
MAPREDUCE-2890,Improvement,Blocker,documentation;mrv2,Documentation for MRv2,Let's use this jira to track docs for all of MRv2.,Closed,Fixed,,Unassigned,Arun C Murthy,Sun; 28 Aug 2011 05:45:05 +0000,Tue; 15 Nov 2011 00:50:04 +0000,Mon; 17 Oct 2011 02:19:55 +0000,,,,,MAPREDUCE-2894,https://issues.apache.org/jira/browse/MAPREDUCE-2890
MAPREDUCE-2891,Sub-task,Major,documentation;mrv2,Docs for core protocols in yarn-api - AMRMProtocol,We need to add docs for AMRMProtocol,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sun; 28 Aug 2011 05:46:49 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Sun; 28 Aug 2011 11:43:02 +0000,,,,MAPREDUCE-2889,MAPREDUCE-2892,https://issues.apache.org/jira/browse/MAPREDUCE-2891
MAPREDUCE-2892,Sub-task,Blocker,mr-am;mrv2;resourcemanager,Improvements to AM apis,"Some api changes before we declare yarn apis as stable:   	FinishApplicationMasterRequest doesn't need to send out 'tracking url'. 	FinishApplicationMasterRequest shouldn't use 'string' as final state - it's got to be an enum and we need to use that enum appropriately in the RM's state-machines.",Closed,Duplicate,MAPREDUCE-3098,Hitesh Shah,Arun C Murthy,Sun; 28 Aug 2011 08:04:45 +0000,Tue; 15 Nov 2011 00:50:05 +0000,Wed; 28 Sep 2011 14:10:33 +0000,,0.23.0,,,MAPREDUCE-2891,https://issues.apache.org/jira/browse/MAPREDUCE-2892
MAPREDUCE-2893,Improvement,Trivial,client,Removing duplicate service provider in hadoop-mapreduce-client-jobclient,There is duplicate provider class name in the configuration file of ClientProtocolProvider under hadoop-mapreduce-client-jobclient. Although it will be ignored.,Closed,Fixed,,Liang-Chi Hsieh,Liang-Chi Hsieh,Sun; 28 Aug 2011 09:21:39 +0000,Tue; 15 Nov 2011 00:49:28 +0000,Sun; 28 Aug 2011 10:39:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2893
MAPREDUCE-2894,Improvement,Blocker,mrv2,Improvements to YARN apis,Ticket to track improvements to YARN apis.,Closed,Fixed,,Unassigned,Arun C Murthy,Sun; 28 Aug 2011 10:59:05 +0000,Tue; 15 Nov 2011 00:48:42 +0000,Mon; 17 Oct 2011 02:21:11 +0000,,0.23.0,,,MAPREDUCE-2890,https://issues.apache.org/jira/browse/MAPREDUCE-2894
MAPREDUCE-2895,Sub-task,Major,mrv2,Merge AllocateResponse and AMResponse,We need to merge AllocateResponse and AMResponse; having them separate serves no purpose.,Closed,Won't Fix,,Unassigned,Arun C Murthy,Sun; 28 Aug 2011 11:01:23 +0000,Tue; 15 Nov 2011 00:48:47 +0000,Mon; 5 Sep 2011 23:15:18 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2895
MAPREDUCE-2896,Sub-task,Major,mrv2,Remove all apis other than getters and setters in all org/apache/hadoop/yarn/api/records/*,Remove all apis other than getters and setters in all org *.  We initially added some list manipulation methods etc. which are ungainly and need to go.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sun; 28 Aug 2011 11:20:18 +0000,Tue; 15 Nov 2011 00:48:15 +0000,Tue; 13 Sep 2011 00:07:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2896
MAPREDUCE-2897,Sub-task,Major,documentation;mrv2,Docs for core protocols in yarn-api - ClientRMProtocol,Track docs for ClientRMProtocol and related apis records.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sun; 28 Aug 2011 11:37:42 +0000,Tue; 15 Nov 2011 00:49:07 +0000,Tue; 30 Aug 2011 01:24:11 +0000,,0.23.0,,MAPREDUCE-2889,,https://issues.apache.org/jira/browse/MAPREDUCE-2897
MAPREDUCE-2898,Sub-task,Major,documentation;mrv2,Docs for core protocols in yarn-api - ContainerManager,Track docs for ContainerManager and related apis records.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sun; 28 Aug 2011 11:38:48 +0000,Tue; 15 Nov 2011 00:49:05 +0000,Mon; 29 Aug 2011 00:05:08 +0000,,0.23.0,,MAPREDUCE-2889,,https://issues.apache.org/jira/browse/MAPREDUCE-2898
MAPREDUCE-2899,Sub-task,Major,mrv2;resourcemanager,Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext,We can replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 29 Aug 2011 01:38:31 +0000,Tue; 15 Nov 2011 00:49:18 +0000,Wed; 14 Sep 2011 07:30:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2899
MAPREDUCE-2900,Sub-task,Major,mrv2;nodemanager,Replace ContainerId; Resource in ContainerLaunchContext with Container,Replace ContainerId; Resource in ContainerLaunchContext with Container,Closed,Won't Fix,,Unassigned,Arun C Murthy,Mon; 29 Aug 2011 03:39:17 +0000,Tue; 15 Nov 2011 00:48:54 +0000,Mon; 5 Sep 2011 23:20:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2900
MAPREDUCE-2901,Bug,Major,build,Build should fail sanely if protoc isn't on PATH,"It now fails ""ERROR Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (generate-sources) on project hadoop-yarn-api: Command execution failed. Process exited with an error: 1(Exit value: 1) - Help 1"".  Which doesn't help much.",Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Mon; 29 Aug 2011 07:28:39 +0000,Tue; 6 Sep 2011 21:17:13 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2901
MAPREDUCE-2902,Bug,Major,documentation,Merge DevelopingOnTrunkAfter279Merge wiki page into HowToContribute,We'll need to make http: HowToContribute the single source of truth.  Also; we'll need separate sections for building pre-0.23 and post-0.23 Hadoop.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Mon; 29 Aug 2011 07:34:52 +0000,Mon; 29 Aug 2011 07:34:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2902
MAPREDUCE-2903,Bug,Major,jobtracker,Map Tasks graph is throwing XML Parse error when Job is executed with 0 maps,nan,Closed,Fixed,MAPREDUCE-1237;HADOOP-4160,Devaraj K,Devaraj K,Mon; 29 Aug 2011 10:28:35 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Mon; 9 Jul 2012 07:15:29 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2903
MAPREDUCE-2904,Bug,Major,,HDFS jars added incorrectly to yarn classpath,nan,Closed,Fixed,,Sharad Agarwal,Sharad Agarwal,Mon; 29 Aug 2011 11:40:47 +0000,Tue; 15 Nov 2011 00:49:41 +0000,Mon; 29 Aug 2011 19:38:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2904
MAPREDUCE-2905,Bug,Major,contrib/fair-share,CapBasedLoadManager incorrectly allows assignment when assignMultiple is true (was: assignmultiple per job),We encountered a situation where in the same cluster; large jobs benefit from mapred.fairscheduler.assignmultiple; but small jobs with small numbers of mappers do not: the mappers all clump to fully occupy just a few nodes; which causes those nodes to saturate and bottleneck. The desired behavior is to spread the job across more nodes so that a relatively small job doesn't saturate any node in the cluster.  Testing has shown that setting mapred.fairscheduler.assignmultiple to false gives the desired behavior for small jobs; but is unnecessary for large jobs. However; since this is a cluster-wide setting; we can't properly tune.  It'd be nice if jobs can set a param similar to mapred.fairscheduler.assignmultiple on submission to better control the task distribution of a particular job.,Closed,Fixed,,Jeff Bean,Jeff Bean,Mon; 29 Aug 2011 17:20:13 +0000,Wed; 17 Oct 2012 18:27:24 +0000,Tue; 22 Nov 2011 19:36:13 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2905
MAPREDUCE-2906,Bug,Major,,FindBugs OutOfMemoryError,"When running the findbugs target from Jenkins; I get an OutOfMemory error. The ""effort"" in FindBugs is set to Max which ends up using a lot of memory to go through all the classes. The jvmargs passed to FindBugs is hardcoded to 512 MB max.  We can leave the default to 512M; as long as we pass this as an ant parameter which can be overwritten in individual cases through -D; or in the build.properties file (either basedir; or user's home directory).",Resolved,Not A Problem,,Joep Rottinghuis,Joep Rottinghuis,Mon; 29 Aug 2011 18:45:37 +0000,Mon; 29 Aug 2011 19:02:29 +0000,Mon; 29 Aug 2011 19:02:29 +0000,,0.22.0,,,HDFS-2297,https://issues.apache.org/jira/browse/MAPREDUCE-2906
MAPREDUCE-2907,Bug,Major,mrv2;resourcemanager,ResourceManager logs filled with [INFO] debug messages from org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue,I see a lot of info messages (probably used for debugging during development),Closed,Fixed,,Ravi Prakash,Ravi Prakash,Mon; 29 Aug 2011 21:06:17 +0000,Tue; 15 Nov 2011 00:48:40 +0000,Wed; 5 Oct 2011 11:58:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2907
MAPREDUCE-2908,Bug,Critical,mrv2,Fix findbugs warnings in Map Reduce.,In the current trunk 0.23 codebase there are 5 findbugs warnings which cause the precommit CI builds to -1 the patches.,Closed,Fixed,,Vinod Kumar Vavilapalli,Mahadev konar,Tue; 30 Aug 2011 01:31:09 +0000,Tue; 15 Nov 2011 00:48:54 +0000,Thu; 8 Sep 2011 18:28:24 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2908
MAPREDUCE-2909,Sub-task,Major,documentation;mrv2,Docs for remaining records in yarn-api,MAPREDUCE-2891 ; MAPREDUCE-2897  MAPREDUCE-2898 added  ocs - this jira is to track the remaining ones.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 30 Aug 2011 01:33:07 +0000,Tue; 15 Nov 2011 00:49:43 +0000,Fri; 16 Sep 2011 23:29:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2909
MAPREDUCE-2910,Improvement,Minor,task;tasktracker,Allow empty MapOutputFile segments,As the scale of cluster and job get larger; we see a lot of empty partitions in MapOutputFile due to large reduce numbers or partition skew. When map output compression is enabled; empty map output partitions gets larger  has additional compressor decompressor initialization overhead.  This can be optimized by allowing empty MapOutputFile segments; where the rawLength  partLength of IndexRecord all equal to 0. Corresponding support need to be added to IFile reader; writer; and reduce shuffle copier.,Open,Unresolved,,Unassigned,Binglin Chang,Tue; 30 Aug 2011 03:47:21 +0000,Tue; 10 Mar 2015 01:29:16 +0000,,,0.20.2;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2910
MAPREDUCE-2911,New Feature,Major,mrv2,Hamster: Hadoop And Mpi on the same cluSTER,MPI is commonly used for many machine-learning applications. OpenMPI (http: ); but it was kludgy. After the resource-manager separation from JobTracker in Hadoop; we have all the tools needed to make MPI a first-class citizen on a Hadoop cluster. I am currently working on the patch to make MPI an application-master. Initial version of this patch will be available soon (hopefully before September 10.) This jira will track the development of Hamster: The application master for MPI.,Resolved,Later,,Unassigned,Milind Bhandarkar,Tue; 30 Aug 2011 07:04:05 +0000,Wed; 29 Apr 2015 18:56:26 +0000,Tue; 22 May 2012 17:36:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2911
MAPREDUCE-2912,Bug,Major,build,Trunk build failing due to testcase failures from many builds,run-test-mapred:  BUILD FAILED  build.xml:848: Tests failed!  Total time: 115 minutes 23 seconds Build step 'Execute shell' marked build as failure,Resolved,Invalid,,Unassigned,Ravi Teja Ch N V,Tue; 30 Aug 2011 09:31:14 +0000,Wed; 14 Sep 2011 15:57:27 +0000,Wed; 14 Sep 2011 15:57:27 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2912
MAPREDUCE-2913,Bug,Critical,mrv2;test,TestMRJobs.testFailingMapper does not assert the correct thing.,when optimized would be     obviously these assertions will never fail.  If we remove the     the asserts no longer pass. This could be because MRApp mocks out the task launcher and never actually launches anything.,Closed,Fixed,,Jonathan Eagles,Robert Joseph Evans,Tue; 30 Aug 2011 14:12:35 +0000,Mon; 16 Mar 2015 17:57:17 +0000,Wed; 5 Oct 2011 17:10:46 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2913
MAPREDUCE-2914,Bug,Minor,jobhistoryserver,MR jobs with the corresponding apps Killed or Failed have insufficient information in their JobStatuses,For apps(not jobs) which are killed failed.,Reopened,Unresolved,,Unassigned,Jeffrey Naisbitt,Tue; 30 Aug 2011 15:13:42 +0000,Tue; 10 Mar 2015 04:32:07 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2914
MAPREDUCE-2915,Bug,Major,task-controller,LinuxTaskController does not work when JniBasedUnixGroupsNetgroupMapping or JniBasedUnixGroupsMapping is enabled,"When a job is submitted; LinuxTaskController launches the native task-controller binary for job initialization. The native program does a series of prep work and call execv() to run JobLocalizer.  It was observed that JobLocalizer does fails to run when JniBasedUnixGroupsNetgroupMapping or JniBasedUnixGroupsMapping is enabled; resulting in 100% job failures.  JobLocalizer normally does not need the native library (libhadoop) for its functioning; but enabling a JNI user-to-group mapping function cause it to load the library. However; JobLocalizer cannot locate the library since "" library.path property through task-controller. LinuxTaskController already does it when launching the task log truncater.",Closed,Fixed,,Kihwal Lee,Kihwal Lee,Wed; 31 Aug 2011 00:45:05 +0000,Tue; 25 Oct 2011 12:32:51 +0000,Fri; 9 Sep 2011 20:12:44 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2915
MAPREDUCE-2916,Bug,Major,,Ivy build for MRv1 fails with bad organization for common daemon.,This jira is to ignore ivy resolve errors because of bad poms in common daemons.,Closed,Fixed,,Mahadev konar,Mahadev konar,Wed; 31 Aug 2011 05:33:46 +0000,Tue; 15 Nov 2011 00:48:32 +0000,Wed; 31 Aug 2011 05:53:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2916
MAPREDUCE-2917,Bug,Major,mrv2;resourcemanager,Corner case in container reservations,Saw a corner case in container reservations where the node on which the AM is running was reserved; and hence never fulfilled leaving the application hanging.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 31 Aug 2011 06:44:32 +0000,Tue; 15 Nov 2011 00:49:33 +0000,Tue; 6 Sep 2011 23:04:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2917
MAPREDUCE-2918,Improvement,Major,mrv2,Provide programmatic access to use job log ,Since hadoop job task log is critical for debugging; providing a programmatic access would definitely add a big value to the end user.   Oozie users are repeatedly asking to open up the hadoop job log for them. However; Oozie doesn't have any knowledge about the log location as well as the log contents of hadoop job.   The expected programmatic access could come in any or both ways: 1. Allowing an API such as getLogPath(jobId) that returns the base HDFS path of the job directory. 2. Allowing an API such as getLog(jobId) that will return the log contents (may be as streaming output).,Open,Unresolved,,Unassigned,Mohammad Kamrul Islam,Tue; 30 Aug 2011 07:53:37 +0000,Tue; 4 Oct 2011 21:56:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2918
MAPREDUCE-2919,Improvement,Minor,jobtracker,The JT web UI should show job start times ,It would be helpful if the list of jobs in the main JT web UI (running; completed; failed..) had a column with the start time. Clicking into each job detail can get tedious.,Closed,Fixed,,Harsh J,Eli Collins,Thu; 1 Sep 2011 00:13:42 +0000,Wed; 17 Oct 2012 18:27:26 +0000,Wed; 28 Dec 2011 03:30:00 +0000,,0.20.203.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2919
MAPREDUCE-2920,Sub-task,Major,tasktracker,Local log dir links in the JT web UI are broken  ,The task log servlet can no longer access user logs because MAPREDUCE-2415 introduce symlinks to the logs and jetty is not configured by default to follow  symlinks (for security reasons).,Closed,Won't Fix,,Unassigned,Eli Collins,Thu; 1 Sep 2011 00:46:41 +0000,Wed; 22 Aug 2012 01:20:17 +0000,Thu; 3 Nov 2011 22:19:38 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2920
MAPREDUCE-2921,Sub-task,Major,tasktracker,TaskTracker won't start with failed local directory,Chmod'ing one of the mapred local directories so it's not executable will cause the TT to fail to start. Doing this after the TT has started will result in a TT that is up but can not execute tasks.,Resolved,Duplicate,HADOOP-7818,Eli Collins,Eli Collins,Thu; 1 Sep 2011 01:02:21 +0000,Fri; 11 Nov 2011 22:39:31 +0000,Fri; 11 Nov 2011 22:38:45 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2921
MAPREDUCE-2922,Bug,Minor,mrv2,create-c++-task-controller-configure called during ant build create-c++-configure and fails ,if you call ant create-c+-configure it tries to run create-c+-task-controller-configure; which fails with error about &gt;     exec Makefile.am: C objects in subdir but `AM_PROG_CC_C_O'.  We don't need to build the task-controller anymore in mrv2 so simply remove it from build.xml    cmdline used to build: ant -Dresolvers=internal -Dcompile.c+=true -Dcompile.native=true             create-c+-configure binary,Closed,Duplicate,MAPREDUCE-2767,Thomas Graves,Thomas Graves,Thu; 1 Sep 2011 16:26:59 +0000,Tue; 15 Nov 2011 00:49:34 +0000,Wed; 7 Sep 2011 14:32:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2922
MAPREDUCE-2923,Improvement,Blocker,jobhistoryserver;mrv2,Add a new record to JobHistory to record start time of each instance of AM,Add a new record to JobHistory to record start time of each instance of AM,Closed,Duplicate,MAPREDUCE-3144,Devaraj K,Arun C Murthy,Thu; 1 Sep 2011 20:29:10 +0000,Mon; 16 Mar 2015 17:57:17 +0000,Mon; 10 Oct 2011 04:55:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2923
MAPREDUCE-2924,Sub-task,Major,tasktracker,TaskTracker number of failed disks to tolerate should be configurable,Like HDFS-1161 but for the TT. The user should be able to configure how many valid disks are needed for operation. Currently the TT will start and accept tasks even if eg only 1 of its 12 disks is working; which leads to poor performance of jobs with tasks that use this machine.,Closed,Won't Fix,,Unassigned,Eli Collins,Fri; 2 Sep 2011 03:31:10 +0000,Sat; 5 Nov 2011 01:42:58 +0000,Sat; 5 Nov 2011 01:42:04 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2924
MAPREDUCE-2925,Bug,Major,mrv2,job -status <JOB_ID> is giving continuously info message for completed jobs on the console,This below message is coming continuously on the console.,Closed,Fixed,MAPREDUCE-2686,Devaraj K,Devaraj K,Fri; 2 Sep 2011 12:08:47 +0000,Mon; 16 Mar 2015 17:57:13 +0000,Mon; 19 Sep 2011 12:28:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2925
MAPREDUCE-2926,Bug,Major,mrv2,500 Error in ResourceManager UI,When accessing the resource manager UI the following is returned,Closed,Duplicate,HADOOP-7606,Robert Joseph Evans,Robert Joseph Evans,Fri; 2 Sep 2011 16:32:57 +0000,Mon; 16 Mar 2015 17:57:17 +0000,Tue; 6 Sep 2011 23:09:24 +0000,,0.23.0;2.0.0-alpha,,HADOOP-7606,,https://issues.apache.org/jira/browse/MAPREDUCE-2926
MAPREDUCE-2927,Bug,Major,mrv2,CompletedJob.isUber throws a Yarn exception which makes the JobHistory UI unusable.,CompletedJob.isUber on the MR-279 branch returns jobInfo.getIsUber() but got turned into an exception when MR-279 was merged to trunk. SVN Revision 1159166.,Closed,Duplicate,MAPREDUCE-2996;MAPREDUCE-2675,Robert Joseph Evans,Robert Joseph Evans,Fri; 2 Sep 2011 20:16:12 +0000,Mon; 16 Mar 2015 17:57:15 +0000,Tue; 13 Sep 2011 13:32:00 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2927
MAPREDUCE-2928,Sub-task,Major,tasktracker,MR-2413 improvements,Tracks improvements to MR-2413. See this comment.,Closed,Fixed,,Eli Collins,Eli Collins,Fri; 2 Sep 2011 23:45:23 +0000,Wed; 19 Oct 2011 00:26:10 +0000,Fri; 23 Sep 2011 06:47:23 +0000,,,,,MAPREDUCE-2413;MAPREDUCE-3077,https://issues.apache.org/jira/browse/MAPREDUCE-2928
MAPREDUCE-2929,Bug,Major,task-controller,Move task-controller from bin to libexec,"Linux task-controller is hard coded to $HADOOP_HOME libexec for ""ant binary"" layout; or the updated file structure layout for trunk.",Open,Unresolved,,Unassigned,Eric Yang,Sat; 3 Sep 2011 00:41:09 +0000,Tue; 6 Sep 2011 19:45:45 +0000,,,0.20.204.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2929
MAPREDUCE-2930,Improvement,Major,mrv2,Generate state graph from the State Machine Definition,It would be nice to automatically generate the state machine visualization from the state machine declaration using graphviz or some such. Some state graphs already attached to MAPREDUCE-279.,Closed,Fixed,,Binglin Chang,Sharad Agarwal,Sun; 4 Sep 2011 08:24:06 +0000,Tue; 15 Nov 2011 00:48:53 +0000,Wed; 21 Sep 2011 08:41:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2930
MAPREDUCE-2931,Improvement,Major,,CLONE - LocalJobRunner should support parallel mapper execution,The LocalJobRunner currently supports only a single execution thread. Given the prevalence of multi-core CPUs; it makes sense to allow users to run multiple tasks in parallel for improved performance on small (local-only) jobs.  It is necessary to patch back MAPREDUCE-1367 into Hadoop 0.20.X version. Also; MapReduce-434 should be submitted together.,Closed,Fixed,,Sandy Ryza,Forest Tan,Mon; 5 Sep 2011 08:46:29 +0000,Wed; 15 May 2013 05:16:14 +0000,Fri; 25 Jan 2013 10:58:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2931
MAPREDUCE-2932,Bug,Trivial,tasktracker,Missing instrumentation plugin class shouldn't crash the TT startup per design,Per the implementation of the TaskTracker instrumentation plugin implementation (from 2008); a ClassNotFoundException during loading up of an configured TaskTracker instrumentation class shouldn't have hampered TT start up at all.  But; there is one class-fetching call outside try catch itself.  Strace would appear as:,Closed,Fixed,,Harsh J,Harsh J,Mon; 5 Sep 2011 16:05:35 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Thu; 22 Sep 2011 19:23:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2932
MAPREDUCE-2933,Sub-task,Blocker,applicationmaster;mrv2;nodemanager;resourcemanager,Change allocate call to return ContainerStatus for completed containers rather than Container ,Change allocate call to return ContainerStatus for completed containers rather than Container; we should do this all the way from the NodeManager too.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 5 Sep 2011 23:08:39 +0000,Tue; 15 Nov 2011 00:48:34 +0000,Sun; 11 Sep 2011 17:29:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2933
MAPREDUCE-2934,Improvement,Major,mrv2,MR portion of HADOOP-7607 - Simplify the RPC proxy cleanup process,Once HADOOP-7607 goes in; ProtoOverHadoopRpcEngine.stopProxy will need to be removed or at least have its @Override annotation removed.,Closed,Fixed,,Aaron T. Myers,Aaron T. Myers,Tue; 6 Sep 2011 01:39:44 +0000,Tue; 10 Mar 2015 04:31:40 +0000,Fri; 9 Sep 2011 18:12:31 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2934
HDFS-2314,Bug,Major,test,MRV1 test compilation broken after HDFS-2197,Runing the following:   At the trunk level: mvn clean install package -Dtar -Pdist -Dmaven.test.skip.exec=true   In hadoop-mapreduce-project: ant jar-test -Dresolvers=internal  yields the errors:,Closed,Fixed,,Todd Lipcon,Vinod Kumar Vavilapalli,Tue; 6 Sep 2011 08:47:45 +0000,Mon; 16 Mar 2015 18:07:03 +0000,Tue; 6 Sep 2011 21:27:01 +0000,,,,MAPREDUCE-2936,HDFS-2197,https://issues.apache.org/jira/browse/HDFS-2314
MAPREDUCE-2936,Bug,Major,,Contrib Raid compilation broken after HDFS-1620,After working around MAPREDUCE-2935 by removing TestServiceLevelAuthorization and runing the following: At the trunk level: mvn clean install package -Dtar -Pdist -Dmaven.test.skip.exec=true In hadoop-mapreduce-project: ant compile-contrib -Dresolvers=internal  yields 14 errors.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 6 Sep 2011 09:01:30 +0000,Mon; 16 Mar 2015 17:52:40 +0000,Mon; 12 Sep 2011 19:50:49 +0000,,,,HDFS-2314,HDFS-1620,https://issues.apache.org/jira/browse/MAPREDUCE-2936
MAPREDUCE-2937,Bug,Critical,mrv2,Errors in Application failures are not shown in the client trace.,The client side does not show enough information on why the job failed. Here is step to reproduce it:  1) set the scheduler to be capacity scheduler with queues a; b 2) submit a job to a queue that is not a;b  The job just fails without saying why it failed. We should have enough trace log at the client side to let the user know why it failed.,Closed,Fixed,,Mahadev konar,Mahadev konar,Wed; 7 Sep 2011 03:52:19 +0000,Tue; 15 Nov 2011 00:49:07 +0000,Fri; 9 Sep 2011 02:15:43 +0000,,0.23.0,,MAPREDUCE-2952,,https://issues.apache.org/jira/browse/MAPREDUCE-2937
MAPREDUCE-2938,Bug,Trivial,mrv2;scheduler,Missing log stmt for app submission fail CS,Missing log stmt for app submission fail CS,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 7 Sep 2011 05:34:59 +0000,Tue; 15 Nov 2011 00:48:35 +0000,Wed; 7 Sep 2011 05:57:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2938
MAPREDUCE-2939,Task,Major,build,Ant setup on hadoop7 jenkins host,From the build error it looks like a) ant is not set up on the machine b) $ANT_HOME point to the wrong spot,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Wed; 7 Sep 2011 05:56:23 +0000,Mon; 12 Dec 2011 06:20:04 +0000,Wed; 21 Sep 2011 16:49:28 +0000,,0.22.0,,MAPREDUCE-2940,,https://issues.apache.org/jira/browse/MAPREDUCE-2939
MAPREDUCE-2940,Bug,Major,build,Build fails with ant 1.7.0 but works with 1.8.0,contrib builds fail when using Ant 1.7.  build.xml calls build.xml in contrib; which calls block-forensics build; which in turn uses build-contrib. The inheritAll=true overrides the basedir in ant 1.7.0 but not in 1.8.0.,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Wed; 7 Sep 2011 06:03:42 +0000,Mon; 12 Dec 2011 06:19:25 +0000,Fri; 9 Sep 2011 20:11:00 +0000,,0.22.0,,MAPREDUCE-2939,HDFS-2315,https://issues.apache.org/jira/browse/MAPREDUCE-2940
MAPREDUCE-2941,Bug,Blocker,mrv2;resourcemanager,In secure mode RM WebUI shows wrong user for application,In secure mode RM WebUI shows wrong user for application (mapred) although the RM logs show the right user (me).,Closed,Duplicate,MAPREDUCE-2953,Unassigned,Arun C Murthy,Wed; 7 Sep 2011 06:13:32 +0000,Tue; 15 Nov 2011 00:50:02 +0000,Mon; 12 Sep 2011 05:29:30 +0000,,0.23.0,,,MAPREDUCE-2649;MAPREDUCE-2953,https://issues.apache.org/jira/browse/MAPREDUCE-2941
MAPREDUCE-2942,Bug,Critical,,TestNMAuditLogger.testNMAuditLoggerWithIP failing,This is failing right after the MAPREDUCE-2655 commit; but Jenkins did report a success when that patch was submitted.,Closed,Fixed,,Thomas Graves,Vinod Kumar Vavilapalli,Wed; 7 Sep 2011 10:54:58 +0000,Tue; 10 Mar 2015 04:31:45 +0000,Thu; 8 Sep 2011 18:30:46 +0000,,2.0.0-alpha,,,MAPREDUCE-2655,https://issues.apache.org/jira/browse/MAPREDUCE-2942
MAPREDUCE-2943,Bug,Minor,distcp;mrv2,Test-failures when using local-job-runner.,"Here's an example of a failure when a test  org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod. 41)     ...  This is a DistCp(v2) test; built and run using Maven. DistCp's tests depend on the following maven artifacts: 1. hadoop-mapreduce-client-jobclient 2. hadoop-hdfs 3. hadoop-common  The failure is in spite of doing a "" conf.set(MRConfig.FRAMEWORK_NAME; ""local"");"". Vinod (KV)'s in the loop on this. It appears that the root-cause lies in org LocalClientProtocolProvider.class not being available in class-path. This might have to do with MR1 not having been maven-ized; or some such.  I haven't a clean way around this for the moment; so I'll temporarily disable this distcp-test from running. It would be nice; however; to have maven-tests that use local-job-runner to run through.",Open,Unresolved,,Unassigned,Mithun Radhakrishnan,Wed; 7 Sep 2011 11:15:34 +0000,Tue; 10 Mar 2015 04:31:42 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2943
MAPREDUCE-2944,Improvement,Trivial,client,Improve checking of input for Api displayTasks() ,The JobClient.displayTasks() will do nothing and won't throw any exception either;  while user call it with invalid type state of task. To be more friendly;it's better to remain user to check his parameters with an exception.,Resolved,Fixed,,XieXianshan,XieXianshan,Wed; 7 Sep 2011 11:21:18 +0000,Thu; 12 May 2016 18:23:07 +0000,Wed; 28 Dec 2011 14:12:18 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2944
MAPREDUCE-2945,Task,Critical,examples,Hbase Batch Import Insertion Method,Ubuntu Hadoop  Hbase From CDH3  I am trying to write Hbase Batch Import Insertion Method; I am new in Hbase  Hadoop. Can any one tell me example; Or can give info link.,Resolved,Invalid,,Unassigned,Arsalan Bilal,Wed; 7 Sep 2011 12:48:34 +0000,Wed; 7 Sep 2011 13:08:58 +0000,Wed; 7 Sep 2011 13:02:21 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2945
MAPREDUCE-2946,Bug,Major,tasktracker,TaskTrackers fail at startup,Upgrading from 0.20.204.0 to 0.20.205.0-SNAPSHOT; the TaskTrackers refused to start because the cleanup failed. I was able to start the task trackers by deleting the mapred localdirs across the cluster.  I was running with the linux task controller and security turned on.,Closed,Invalid,,Unassigned,Owen O'Malley,Wed; 7 Sep 2011 16:19:38 +0000,Wed; 19 Oct 2011 00:30:19 +0000,Wed; 7 Sep 2011 16:30:30 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2946
MAPREDUCE-2947,Bug,Major,mrv2,Sort fails on YARN+MR with lots of task failures,Karam Singh(the great man the world hardly knows about) found lots of failing tasks while running sort on a 350 node cluster. The failed tasks eventually failed the job and this happening consistently on the big cluster.  Container launch failed for container_1315410418107_0002_01_002511 : RemoteTrace:  619),Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 7 Sep 2011 17:23:18 +0000,Tue; 15 Nov 2011 00:48:13 +0000,Thu; 8 Sep 2011 18:41:21 +0000,,0.23.0,,,MAPREDUCE-2652,https://issues.apache.org/jira/browse/MAPREDUCE-2947
MAPREDUCE-2948,Bug,Major,contrib/streaming,Hadoop streaming test failure; post MR-2767,After removing LinuxTaskController in MAPREDUCE-2767; one of the tests in contrib streaming: TestStreamingAsDifferentUser. is failing since it imports import org.apache.hadoop.mapred.ClusterWithLinuxTaskController. Patch forthcoming.,Closed,Fixed,,Mahadev konar,Milind Bhandarkar,Wed; 7 Sep 2011 19:43:29 +0000,Mon; 16 Mar 2015 17:49:13 +0000,Wed; 7 Sep 2011 21:33:58 +0000,,0.22.0;0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2948
MAPREDUCE-2949,Bug,Major,mrv2;nodemanager,NodeManager in a inconsistent state if a service startup fails.,"When a service startup fails at the Nodemanager; the Nodemanager JVM doesnot exit as the following threads are still running.  Daemon Thread Timer for NodeManager metrics system (Running)	 Thread pool-1-thread-1 (Running)	 Thread Thread-11 (Running)	 Thread DestroyJavaVM (Running).  As a result; the NodeManager keeps running even though no services are started.",Closed,Fixed,,Ravi Teja Ch N V,Ravi Teja Ch N V,Thu; 8 Sep 2011 10:41:02 +0000,Tue; 10 Mar 2015 04:32:07 +0000,Wed; 14 Sep 2011 15:39:51 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2949
MAPREDUCE-2950,Bug,Major,contrib/gridmix,[Gridmix] TestUserResolve fails in trunk,TestUserResolve fails in trunk.,Closed,Fixed,,Ravi Gummadi,Amar Kamat,Thu; 8 Sep 2011 10:49:27 +0000,Tue; 10 Mar 2015 04:32:08 +0000,Wed; 5 Oct 2011 08:14:47 +0000,,2.0.0-alpha,gridmix;junit;test-user-resolve,,,https://issues.apache.org/jira/browse/MAPREDUCE-2950
MAPREDUCE-2951,Bug,Major,build;mrv2,Problem while building hadoop trunk on Windows 7,Hi All; I am facing problem with generating tar files for all hadoop modbles. The generated tar files are not correct.  For example; for hadoop-common-0.24.0-SNAPSHOT.tar.gz file fileSet   Anyone has any idea about this?   Thanks  Regards; Abhijit,Resolved,Invalid,,Unassigned,Abhijit Suresh Shingate,Thu; 8 Sep 2011 11:02:36 +0000,Tue; 10 Mar 2015 04:32:31 +0000,Wed; 30 Nov 2011 06:32:16 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2951
MAPREDUCE-2952,Bug,Blocker,mrv2;resourcemanager,Application failure diagnostics are not consumed in a couple of cases,When Container crashes; the reason for failures isn't propagated because of a bug in RMAppAttemptImpl.AMContainerCrashedTransition which simply discards the diagnostics of the container. Also RMAppAttemptImpl.diagnostics is never consumed.,Closed,Fixed,,Arun C Murthy,Vinod Kumar Vavilapalli,Thu; 8 Sep 2011 11:40:10 +0000,Tue; 15 Nov 2011 00:49:54 +0000,Sun; 25 Sep 2011 14:54:13 +0000,,0.23.0,,MAPREDUCE-2937,,https://issues.apache.org/jira/browse/MAPREDUCE-2952
MAPREDUCE-2953,Bug,Major,mrv2;resourcemanager,JobClient fails due to a race in RM; removes staged files and in turn crashes MR AM,Karam Singh ran into this multiple times. MR JobClient crashes immediately.     The client crashes due to a race in RM.  Because the client fails; it immediately removes the staged files which in turn makes the MR AM itself to crash due to failed localization on the NM.,Closed,Fixed,MAPREDUCE-2941,Thomas Graves,Vinod Kumar Vavilapalli,Thu; 8 Sep 2011 12:02:15 +0000,Tue; 15 Nov 2011 00:48:59 +0000,Fri; 9 Sep 2011 02:20:38 +0000,,0.23.0,,,MAPREDUCE-2941;MAPREDUCE-2649,https://issues.apache.org/jira/browse/MAPREDUCE-2953
MAPREDUCE-2954,Bug,Critical,mrv2,Deadlock in NM with threads racing for ApplicationAttemptId,Found this:,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Thu; 8 Sep 2011 13:28:48 +0000,Mon; 16 Mar 2015 17:57:14 +0000,Fri; 9 Sep 2011 09:52:53 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2954
MAPREDUCE-2955,Test,Major,mrv2;test,Port MR1 tests to MR2,Umbrella jira for porting MiniMR tests over to MiniYarnCluster and MiniMRYarnCluster.,Open,Unresolved,MAPREDUCE-4118,Unassigned,Eli Collins,Thu; 8 Sep 2011 17:03:32 +0000,Fri; 6 Apr 2012 19:26:05 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2955
MAPREDUCE-2956,Bug,Major,mrv2,CompositeService should try to stop all services even if one fails,Right now if one of the services fails to stop in the CompositeServices it just quits.  It should continue and try to stop all the services so it shuts down as clean as possible.,Closed,Duplicate,MAPREDUCE-2966,Abhijit Suresh Shingate,Thomas Graves,Thu; 8 Sep 2011 19:01:24 +0000,Tue; 15 Nov 2011 00:48:24 +0000,Wed; 14 Sep 2011 08:43:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2956
MAPREDUCE-2957,Sub-task,Major,tasktracker,The TT should not re-init if it has no good local dirs,The TT will currently try to re-init itself on disk failure even if it has no good local dirs. It should shutdown instead.,Closed,Fixed,,Eli Collins,Eli Collins,Thu; 8 Sep 2011 21:02:59 +0000,Wed; 17 Oct 2012 18:27:27 +0000,Mon; 24 Oct 2011 22:26:39 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2957
MAPREDUCE-2958,Bug,Critical,mrv2,mapred-default.xml not merged from mr279,I have been running wordcount out of the 23 examples jar.  It says it succeeds but doesn't actually output a file.  hadoop jar examples hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar wordcount input output2  input file is really basic: fdksajl dlkfsajlfljda;j kldfsjallj test one two test,Closed,Fixed,,Arun C Murthy,Thomas Graves,Thu; 8 Sep 2011 21:03:47 +0000,Tue; 15 Nov 2011 00:50:16 +0000,Fri; 9 Sep 2011 02:54:14 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2958
MAPREDUCE-2959,Bug,Major,tasktracker,The TT daemon should shutdown on fatal exceptions,Currently the TT daemon does not shutdown (the process still runs but fails to heartbeat) if the TT gets a fatal exception (eg due to losing all its local storage directories).,Open,Unresolved,,Unassigned,Eli Collins,Thu; 8 Sep 2011 21:15:05 +0000,Tue; 14 May 2013 05:14:46 +0000,,,0.20.204.0,,,MAPREDUCE-2413,https://issues.apache.org/jira/browse/MAPREDUCE-2959
MAPREDUCE-2960,Sub-task,Major,tasktracker,A single TT disk failure can cause the job to fail,TaskInProgress#kill in the JT fails because TaskStatus#setFinishTimes fails because no start time was set. There's no start time because TaskTracker#run (DefaultTaskController#initializeJob) failed before it was set. The fix is to have TT#launchTask set the start time before it starts the task runner; this way there's a valid start time even if TT#run fails.,Open,Unresolved,,Unassigned,Eli Collins,Thu; 8 Sep 2011 22:34:59 +0000,Tue; 14 May 2013 05:14:42 +0000,,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2960
MAPREDUCE-2961,Improvement,Blocker,mrv2,Increase the default threadpool size for container launching in the application master.,Currently the default threadpool size is 10 for launching containers in ContainerLauncherImpl. We should increase that to 100 for a reasonable default; so that container launching is not backed up by a small thread pool size.,Closed,Fixed,,Vinod Kumar Vavilapalli,Mahadev konar,Thu; 8 Sep 2011 23:17:50 +0000,Tue; 15 Nov 2011 00:48:05 +0000,Sun; 25 Sep 2011 04:51:56 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2961
MAPREDUCE-2962,Bug,Minor,,Map percentage complete calculation incorrect,"For some reason I have a job with 5000 map tasks; all of which are complete; and it's reporting 99.98% complete. The client logs show ""map 100%"" and then going back down to ""map 99%"".",Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 8 Sep 2011 23:26:04 +0000,Thu; 8 Sep 2011 23:27:12 +0000,,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2962
MAPREDUCE-2963,Bug,Critical,,TestMRJobs hangs waiting to connect to history server.,TestMRJobs is hanging waiting to connect to history server. I will post the logs next.,Closed,Fixed,,Siddharth Seth,Mahadev konar,Fri; 9 Sep 2011 00:14:10 +0000,Tue; 10 Mar 2015 04:32:27 +0000,Fri; 9 Sep 2011 03:01:57 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2963
MAPREDUCE-2964,Bug,Major,,mapreduce trunk build fails with compile-mapred-test ant target,nan,Resolved,Fixed,,Unassigned,Giridharan Kesavan,Fri; 9 Sep 2011 05:54:47 +0000,Tue; 13 Sep 2011 06:14:14 +0000,Tue; 13 Sep 2011 02:38:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2964
MAPREDUCE-2965,Bug,Blocker,mrv2,Streamline hashCode(); equals(); compareTo() and toString() for all IDs,MAPREDUCE-2954 moved these methods to the record interfaces from the PB impls for ContainerId; ApplicationId and ApplicationAttemptId. This is good as they don't need to be tied to the implementation.  We should do the same for all IDs. In fact some of these are missing for IDs like MR AM JobId; TaskId etc.,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Fri; 9 Sep 2011 06:31:48 +0000,Mon; 16 Mar 2015 17:57:13 +0000,Sun; 18 Sep 2011 08:19:09 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-3030,https://issues.apache.org/jira/browse/MAPREDUCE-2965
MAPREDUCE-2966,Improvement,Major,applicationmaster;jobhistoryserver;nodemanager;resourcemanager,Add ShutDown hooks for MRV2 processes,NodeManager registers a shudown hook in case of JVM exit. Similar way; all other processes RM; HistoryServer; MRAppMaster should also handle the shutdown gracefully in case of JVM exit.,Closed,Fixed,MAPREDUCE-2956,Abhijit Suresh Shingate,Abhijit Suresh Shingate,Fri; 9 Sep 2011 08:40:16 +0000,Mon; 16 Mar 2015 17:57:16 +0000,Wed; 14 Sep 2011 18:05:39 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2966
MAPREDUCE-2967,Bug,Major,mrv2,PB implementations of all records should have getters; setters and getProto() properly synchronized,In the past; I've been bitten by multiple; very hard-to-debug race conditions with YARN+MR which all boiled down to locking bugs in PB implementation of various records.  The main reason seems to be that while the getProto() method in each record rebuilds the protocol object; if someone accesses a filed using a getter; it returns zero or a null object. Because of this; while getProto() is in progress; hashCode(); equals(); toString() etc are all affected; leading to hard-to-debug races. I corned this down after much logging in almost all the cases.  Over time; we've fixed this for most of the ID records.  This JIRA should fix it for all the records once and for all.,Open,Unresolved,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 9 Sep 2011 09:59:50 +0000,Thu; 12 May 2016 18:23:31 +0000,,,0.23.0;3.0.0-alpha1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-2967
MAPREDUCE-2968,Bug,Major,mrv2,ContainerID record should get rid of ApplicationId field ,It already has ApplicationAttemptId field which in turn refers to ApplicationId.  I've known this for some time; but didn't do this as it will touch a lot of code even if the patch is mostly going to be mechanical dumb. But we should get this in sooner than later.,Closed,Duplicate,MAPREDUCE-2896,Arun C Murthy,Vinod Kumar Vavilapalli,Fri; 9 Sep 2011 10:05:33 +0000,Tue; 15 Nov 2011 00:49:29 +0000,Mon; 12 Sep 2011 05:34:04 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2968
MAPREDUCE-2969,Bug,Blocker,mrv2,Make the NodeManager delete unused distributed-cache entires by LRU policy,This is the same as MAPREDUCE-2494 and MAPREDUCE-2572 but for YARN MRV2.,Closed,Not A Problem,,Anupam Seth,Vinod Kumar Vavilapalli,Fri; 9 Sep 2011 10:18:22 +0000,Tue; 15 Nov 2011 00:48:28 +0000,Mon; 3 Oct 2011 20:29:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2969
MAPREDUCE-2970,Bug,Major,job submission;mrv2,Null Pointer Exception while submitting a Job; If mapreduce.framework.name property is not set.,If mapreduce.framework.name property is not set in mapred-site.xml; Null pointer Exception is thrown.   189),Closed,Fixed,,Venu Gopala Rao,Venu Gopala Rao,Fri; 9 Sep 2011 13:38:41 +0000,Mon; 16 Mar 2015 17:57:15 +0000,Wed; 21 Sep 2011 09:15:50 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2970
MAPREDUCE-2971,Bug,Blocker,mrv2,ant build mapreduce fails  protected access  jc.displayJobList(jobs);,Running the ant target in the hadoop-mapreduce-project directory fails with:  jsp-compile log4j:WARN See http: faq.html#noconfig for more info.       1 error,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 9 Sep 2011 14:18:53 +0000,Tue; 15 Nov 2011 00:48:59 +0000,Fri; 9 Sep 2011 22:46:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2971
MAPREDUCE-2972,Bug,Minor,mrv2,Running commands from the hadoop-mapreduce-test-*.jar fails with  ClassNotFoundException: junit.framework.TestCase,"Running any of the 'hadoop jar hadoop-mapreduce-test-*.jar' commands gives the following exception:   320) 	... 21 more   This happens even when just running 'hadoop jar $TEST_JAR' where it should just print the available commands. Copying the junit-*.jar from $HADOOP_MAPRED_HOME  seems to fix the problem.",Resolved,Cannot Reproduce,,Jeffrey Naisbitt,Jeffrey Naisbitt,Fri; 9 Sep 2011 15:13:10 +0000,Tue; 20 Dec 2011 23:06:52 +0000,Tue; 20 Dec 2011 23:06:52 +0000,,,,,HADOOP-7590,https://issues.apache.org/jira/browse/MAPREDUCE-2972
MAPREDUCE-2973,Bug,Minor,tasktracker,Logic for determining whether to create a new JVM can interfere with Capacity-Scheduler and JVM reuse,We use the capacity scheduler to enable jobs with large memory requirements to be run on our cluster. The individual tasks have a large initial overhead when they load cached data. Using the JVM reuse option (mapred.job.reuse.jvm.num.tasks) and by caching data in a static variable we can reduce the overhead.   The current JvmManager implementation will prefer creating new JVMs to reusing existing ones if the number of already created JVMs is less than the maximum. In the extreme case where the capacity scheduler is used to limit the number of tasks on a node to 1; but the number of map|reduce tasks per node is set to say 16; then 16 JVMs will be created before one of them is reused. Obviously; if the amount of cached data in the memory of each JVM is large; then node can rapidly run out of memory! What should really happen in this case is that the first created JVM should be reused; and others should not be spawned.  To work-around this problem on our cluster; we have modified the logic in the reapJVM() method in JvmManager to prefer to reuse an existing JVM (idle  belonging to the same job) over starting a new JVM; or killing an existing idle JVM.,Open,Unresolved,,Unassigned,Jonathon Hare,Fri; 9 Sep 2011 16:41:44 +0000,Fri; 9 Sep 2011 21:40:15 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2973
MAPREDUCE-2974,Bug,Minor,scheduler,Remove references to yui.yahooapis.com from queueinfo.jsp,"queueinfo.jsp has references to yui.yahooapis.com which is not accessible from secure networks.    link rel=""stylesheet"" type=""text script  This needs to be removed.",Open,Unresolved,,Unassigned,Priyo Mustafi,Fri; 9 Sep 2011 16:54:46 +0000,Mon; 12 Sep 2011 23:24:35 +0000,,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2974
MAPREDUCE-2975,Bug,Blocker,,ResourceManager Delegate is not getting initialized with yarn-site.xml as default configuration.,MAPREDUCE-2937 accidentally changes ResourceMgrDelegate so that it does not pick up yarn-site.xml as a default resource. Will upload patch.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 9 Sep 2011 17:17:57 +0000,Tue; 15 Nov 2011 00:48:21 +0000,Fri; 9 Sep 2011 19:01:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2975
HADOOP-7629,Bug,Major,,regression with MAPREDUCE-2289 - setPermission passed immutable FsPermission (rpc failure),MAPREDUCE-2289 introduced the following change:     JOB_DIR_PERMISSION is an immutable FsPermission which cannot be used in RPC calls; it results in the following exception:,Closed,Fixed,,Todd Lipcon,Patrick Hunt,Fri; 9 Sep 2011 17:45:14 +0000,Tue; 15 Nov 2011 00:50:51 +0000,Wed; 14 Sep 2011 06:51:46 +0000,,0.22.0,,,HDFS-2332,https://issues.apache.org/jira/browse/HADOOP-7629
MAPREDUCE-2977,Sub-task,Blocker,mrv2;resourcemanager;security,ResourceManager needs to renew and cancel tokens associated with a job,The JobTracker currently manages tokens for the applications and the resource manager needs the same functionality.,Closed,Fixed,,Arun C Murthy,Owen O'Malley,Fri; 9 Sep 2011 17:59:19 +0000,Tue; 15 Nov 2011 00:49:00 +0000,Wed; 26 Oct 2011 02:57:31 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2977
MAPREDUCE-2978,Bug,Major,mrv2,hudson findbugs not reporting properly,It seems that hudson is not properly reporting findbug failures introduced by jiras.   Here is an example where hudson gave the jira a +1 for findbugs but it really introduced a bug: https: newPatchFindbugsWarningshadoop-mapreduce-client-jobclient.html  Note that I had to enter in the extra path of hadoop-mapreduce-project to see the html file so perhaps the path it is using to do the diff is wrong.,Resolved,Fixed,,Tom White,Thomas Graves,Fri; 9 Sep 2011 19:57:09 +0000,Thu; 12 May 2016 18:23:56 +0000,Mon; 12 Sep 2011 15:13:32 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2978
MAPREDUCE-2979,Bug,Major,mrv2,Remove ClientProtocolProvider configuration under mapreduce-client-core,ClientProtocolProvider configuration exists under the job-client and core modules. It's really only required in job-client. The version in core points to JobTrackerClientProtocolProvider which causes   189),Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 9 Sep 2011 22:08:16 +0000,Mon; 16 Mar 2015 17:57:17 +0000,Mon; 12 Sep 2011 16:05:07 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2979
MAPREDUCE-2980,Bug,Major,tasktracker,Fetch failures and other related issues in Jetty 6.1.26,"Since upgrading Jetty from 6.1.14 to 6.1.26 we've had a ton of HTTP-related issues; including:  	Much higher incidence of fetch failures 	A few strange file-descriptor related bugs (eg MAPREDUCE-2389) 	A few unexplained issues where long ""fsck""s on the NameNode drop out halfway through with a ClosedChannelException    Stress tests with 10000Map x 10000Reduce sleep jobs reliably reproduce fetch failures at a rate of about 1 per million on a 25 node test cluster. These problems are all new since the upgrade from 6.1.14.",Open,Unresolved,MAPREDUCE-5588,Unassigned,Todd Lipcon,Fri; 9 Sep 2011 23:42:45 +0000,Sun; 24 Aug 2014 07:12:12 +0000,,,0.20.205.0;0.23.0,,,MAPREDUCE-2389;HBASE-5089;HADOOP-6882,https://issues.apache.org/jira/browse/MAPREDUCE-2980
MAPREDUCE-2981,Improvement,Major,contrib/fair-share,Backport trunk fairscheduler to 0.20-security branch,A lot of improvements have been made to the fair scheduler in 0.21; 0.22 and trunk; but have not been ported back to the new 0.20.20X releases that are currently considered the stable branch of Hadoop.,Closed,Fixed,,Matei Zaharia,Matei Zaharia,Sun; 11 Sep 2011 00:42:19 +0000,Wed; 19 Oct 2011 17:13:18 +0000,Sun; 11 Sep 2011 23:57:47 +0000,,0.20.205.0,,,MAPREDUCE-3206;HDFS-2342,https://issues.apache.org/jira/browse/MAPREDUCE-2981
MAPREDUCE-2982,Bug,Major,jobhistoryserver;resourcemanager,App/Tasks progress is showing as 0% in UI even if successfully completed,Application Tasks progress is showing as 0% in UI even if successfully completed as shown in the attached screen shots.,Resolved,Duplicate,MAPREDUCE-3078;MAPREDUCE-2676,Devaraj K,Devaraj K,Mon; 12 Sep 2011 15:05:18 +0000,Tue; 10 Mar 2015 04:32:15 +0000,Fri; 23 Sep 2011 09:38:33 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2982
MAPREDUCE-2983,Bug,Major,applicationmaster,All tasks are failing due to invalid shuffle port number,nan,Resolved,Not A Problem,,Unassigned,Devaraj K,Mon; 12 Sep 2011 15:13:43 +0000,Tue; 10 Mar 2015 04:32:15 +0000,Mon; 12 Sep 2011 18:07:45 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2983
MAPREDUCE-2984,Bug,Minor,mrv2;nodemanager,Throwing NullPointerException when we open the container page,nan,Closed,Fixed,,Devaraj K,Devaraj K,Mon; 12 Sep 2011 15:35:06 +0000,Tue; 15 Nov 2011 00:49:19 +0000,Mon; 26 Sep 2011 20:47:34 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2984
MAPREDUCE-2985,Bug,Major,mrv2,findbugs error in ResourceLocalizationService.handle(LocalizationEvent),"hudson mapreduce is reporting a findbugs error: https: newPatchFindbugsWarningshadoop-yarn-server-nodemanager.html  WMI 	Method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent) makes inefficient use of keySet iterator instead of entrySet iterator   Bug type WMI_WRONG_MAP_ITERATOR (click for details) In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent) At ResourceLocalizationService. line 318",Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 12 Sep 2011 18:24:07 +0000,Mon; 16 Mar 2015 17:57:16 +0000,Mon; 12 Sep 2011 21:54:46 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2985
MAPREDUCE-2986,Task,Critical,mrv2;test,Multiple node managers support for the MiniYARNCluster,The current MiniYARNCluster can only support 1 node manager; which is not enough for the full test purposes.  Would like to have a simulator that can support multiple node managers as the real scenario. This might be beneficial for hadoop users; testers and developers.,Closed,Fixed,MAPREDUCE-2750,Anupam Seth,Anupam Seth,Mon; 12 Sep 2011 19:09:15 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Thu; 27 Oct 2011 12:43:24 +0000,,0.23.0,,MAPREDUCE-3159,,https://issues.apache.org/jira/browse/MAPREDUCE-2986
MAPREDUCE-2987,Bug,Major,mrv2,RM UI display logged in user as null,"All the pages of the UI; currently show ""Logged in as: null"" instead of the correct username",Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 12 Sep 2011 20:12:22 +0000,Tue; 15 Nov 2011 00:49:01 +0000,Sat; 17 Sep 2011 05:53:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2987
MAPREDUCE-2988,Sub-task,Critical,mrv2;security;test,Reenable TestLinuxContainerExecutor reflecting the current NM code. ,TestLinuxContainerExecutor is currently disabled completely.,Closed,Fixed,,Robert Joseph Evans,Eric Payne,Mon; 12 Sep 2011 20:23:17 +0000,Mon; 16 Mar 2015 17:57:14 +0000,Mon; 10 Oct 2011 09:20:53 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-2747,,https://issues.apache.org/jira/browse/MAPREDUCE-2988
MAPREDUCE-2989,Sub-task,Critical,mrv2,JobHistory should link to task logs,The log link on the task attempt page is currently broken - since it relies on a ContainerId. We should either pass the containerId via a history event - or some kind of field with information about the log location.,Closed,Fixed,MAPREDUCE-3145,Siddharth Seth,Siddharth Seth,Mon; 12 Sep 2011 22:24:29 +0000,Tue; 10 Mar 2015 04:32:40 +0000,Fri; 28 Oct 2011 06:52:11 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-3144,HIVE-3313,https://issues.apache.org/jira/browse/MAPREDUCE-2989
MAPREDUCE-2990,Improvement,Blocker,mrv2,Health Report on Resource Manager UI is null if the NM's are all healthy.,The web UI on the RM for the link Nodes shows that Health-report as null when the NM is healthy.   This is a simple fix where in we can check for null in NodesPage.    Or something like that.,Closed,Fixed,,Subroto Sanyal,Mahadev konar,Mon; 12 Sep 2011 23:20:27 +0000,Tue; 15 Nov 2011 00:49:20 +0000,Sun; 25 Sep 2011 09:37:30 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2990
MAPREDUCE-2991,Bug,Major,scheduler,queueinfo.jsp fails to show queue status if any Capacity scheduler queue name has dash/hiphen in it.,If any queue name has a dash hiphen in it; the queueinfo.jsp doesn't show any queue information.  This is happening because the queue name is used to create  cript doesn't allow dash in variable names.,Closed,Fixed,,Priyo Mustafi,Priyo Mustafi,Mon; 12 Sep 2011 23:21:37 +0000,Mon; 16 Mar 2015 17:49:13 +0000,Thu; 15 Sep 2011 01:43:45 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2991
MAPREDUCE-2992,Bug,Minor,task-controller;test,TestLinuxTaskController is broken,"The TestLinuxTaskController is broken in ""branch-0.20-security"":  Exception message does not contain exit code22 junit.framework.AssertionFailedError: Exception message does not contain exit code22   at org.apache.hadoop.mapred.TestLinuxTaskController.validateTaskControllerSetup(TestLinuxTaskController. 90)  The test is not correctly picking the location of the task-cotroller executable. Also other changes are required (example: Check argc should be after checks for perms in task-controller main.ca; etc).",Open,Unresolved,,Ahmed Radwan,Ahmed Radwan,Tue; 13 Sep 2011 01:23:28 +0000,Tue; 13 Sep 2011 17:31:39 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2992
MAPREDUCE-2993,Bug,Major,mrv2,Hamlet HTML elements are not closed properly. Every element should have proper end tag.,Execute org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebApp.testNodesPage()  Verify the output on the console.      Many html elements does not have end tag.,Resolved,Not A Problem,,Unassigned,Abhijit Suresh Shingate,Tue; 13 Sep 2011 07:33:48 +0000,Tue; 10 Mar 2015 04:32:33 +0000,Wed; 12 Sep 2012 17:02:04 +0000,,0.23.0;2.0.0-alpha,,,YARN-2610,https://issues.apache.org/jira/browse/MAPREDUCE-2993
MAPREDUCE-2994,Bug,Major,mrv2;resourcemanager,Parse Error is coming for App ID when we click application link on the RM UI,nan,Closed,Fixed,,Devaraj K,Devaraj K,Tue; 13 Sep 2011 08:21:18 +0000,Mon; 16 Mar 2015 17:57:12 +0000,Fri; 16 Sep 2011 10:12:06 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2994
MAPREDUCE-2995,Bug,Major,mrv2,MR AM crashes when a container-launch hangs on a faulty NM,AM tries to launch containers on a faulty node which blocks several all of the StartContainer requests. Eventually; RM expires the container-allocations; informs the AM about container-expiry. But AM crashes with an INTERNAL_ERROR as the event is unexpected.    Found this on a big cluster where Karam Singh was trying to get sort running.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 13 Sep 2011 09:49:51 +0000,Tue; 15 Nov 2011 00:50:00 +0000,Tue; 13 Sep 2011 18:13:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2995
MAPREDUCE-2996,Bug,Blocker,jobhistoryserver;mrv2,Log uberized information into JobHistory and use the same via CompletedJob,We always print the uberized info on the UI to be false irrespective of whether it is uberized or not.,Closed,Fixed,,Jonathan Eagles,Vinod Kumar Vavilapalli,Tue; 13 Sep 2011 10:19:40 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Fri; 30 Sep 2011 06:50:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2996
MAPREDUCE-2997,Bug,Major,applicationmaster;mrv2,MR task fails before launch itself with an NPE in ContainerLauncher,Exception found on the AM web UI while the application is running:,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 13 Sep 2011 10:38:28 +0000,Tue; 15 Nov 2011 00:48:37 +0000,Tue; 13 Sep 2011 18:16:18 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2997
MAPREDUCE-2998,Bug,Critical,mrv2,Failing to contact Am/History for jobs: java.io.EOFException in DataInputStream,I am getting an exception frequently when running my jobs on a single-node cluster.  It happens with basically any job I run: sometimes the job will work; but most of the time I get this exception (in this case; I was running a simple wordcount from the examples jar - where I got the exception 4 times in a row; and then the job worked the fifth time I submitted it).  Sometimes restarting the namenode; resourcemanager; and historyserver helps - but not always.  Several other developers have seen this problem.     INFO mapreduce.Job: Counters: 0,Closed,Fixed,,Vinod Kumar Vavilapalli,Jeffrey Naisbitt,Tue; 13 Sep 2011 15:57:21 +0000,Mon; 16 Mar 2015 17:57:14 +0000,Wed; 21 Sep 2011 01:27:27 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2998
MAPREDUCE-2999,Bug,Critical,mrv2,hadoop.http.filter.initializers not working properly on yarn UI,"Currently httpserver only has .html""; "".jsp as user facing urls when you add a filter. For the new web framework in yarn; the pages no longer have the *.html or *.jsp and thus they are not properly being filtered.",Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 13 Sep 2011 17:17:46 +0000,Thu; 2 May 2013 02:29:44 +0000,Tue; 27 Sep 2011 17:06:33 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-2999
MAPREDUCE-3000,Bug,Major,build,Move /mapred to /user/mapred for Hadoop 0.20.205, mapred.,Closed,Not A Problem,,Eric Yang,Eric Yang,Tue; 13 Sep 2011 17:27:34 +0000,Wed; 19 Oct 2011 00:30:19 +0000,Thu; 15 Sep 2011 20:05:03 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3000
MAPREDUCE-3001,Improvement,Blocker,jobhistoryserver;mrv2,Map Reduce JobHistory and AppMaster UI should have ability to display task specific counters.,Map Reduce JobHistory and AppMaster UI should have ability to display task specific counters.  I think the best way to do this is to include in the Nav Block a task specific section with task links when a task is selected.  Counters is already set up to deal with a task passed in.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 13 Sep 2011 17:59:14 +0000,Mon; 16 Mar 2015 17:57:15 +0000,Thu; 29 Sep 2011 08:13:40 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3001
MAPREDUCE-3002,Improvement,Major,jobhistoryserver;mrv2,Delink History Context from AppContext,Currently the JobHistory Server has a HistoryContext that pretends to be a Map Reduce ApplicationMaster's AppContext so that UI pages can be shared between the two.  This is not ideal because the UIs have already diverged a lot; and we have to translate the native History Server's data into implementations of Job to provide the same interface.,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Tue; 13 Sep 2011 20:50:43 +0000,Tue; 10 Mar 2015 04:33:02 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3002
MAPREDUCE-3003,Bug,Major,build,Publish MR JARs to Maven snapshot repository,Currently this is failing since no distribution management section is defined in the POM.  https: consoleFull,Closed,Fixed,,Alejandro Abdelnur,Tom White,Tue; 13 Sep 2011 21:47:32 +0000,Mon; 16 Mar 2015 17:57:12 +0000,Wed; 19 Oct 2011 17:57:28 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-3199,,https://issues.apache.org/jira/browse/MAPREDUCE-3003
MAPREDUCE-3004,Bug,Minor,mrv2,sort example fails in shuffle/reduce stage as it assumes a local job by default ,Log trace when running sort on a single node setup:    INFO mapreduce.Job: Task Id :  org.apache.hadoop.mapred.YarnChild.main(YarnChild. 143),Closed,Fixed,,Hitesh Shah,Hitesh Shah,Wed; 14 Sep 2011 01:21:59 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Mon; 19 Sep 2011 23:18:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3004
MAPREDUCE-3005,Bug,Major,mrv2,MR app hangs because of a NPE in ResourceManager,The app hangs and it turns out to be a NPE in ResourceManager. This happened two of five times on Karam Singh's sort runs on a big cluster.,Closed,Fixed,,Arun C Murthy,Vinod Kumar Vavilapalli,Wed; 14 Sep 2011 04:29:08 +0000,Tue; 15 Nov 2011 00:49:30 +0000,Wed; 14 Sep 2011 22:48:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3005
MAPREDUCE-3006,Bug,Major,applicationmaster;mrv2,MapReduce AM exits prematurely before completely writing and closing the JobHistory file,Karam Singh was executing a sleep job with 100;000 tasks on a 350 node cluster to test MR AM's scalability and ran into this. The job ran successfully but the history was not available.  I debugged around and figured that the job is finishing prematurely before the JobHistory is written. In most of the cases; we don't see this bug as we have a 5 seconds sleep in AM towards the end.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 14 Sep 2011 11:08:42 +0000,Tue; 15 Nov 2011 00:50:10 +0000,Sun; 18 Sep 2011 07:19:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3006
MAPREDUCE-3007,Sub-task,Major,jobhistoryserver;mrv2,JobClient cannot talk to JobHistory server in secure mode,In secure mode; Jobclient cannot connect to HistoryServer. Thanks to Karam Singh for finding this out.     Am surprised no one working with YARN+MR ever ran into this!,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 14 Sep 2011 11:15:16 +0000,Tue; 15 Nov 2011 00:49:11 +0000,Thu; 15 Sep 2011 11:21:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3007
MAPREDUCE-3008,Sub-task,Major,contrib/gridmix,[Gridmix] Improve cumulative CPU usage emulation for short running tasks,CPU emulation in Gridmix fails to meet the expected target if the map has no data to sort merge. There are 2 major reasons for this: 1. The map task end immediately ends soon after the map task. The map progress is 67% while the map phase ends.  2. Currently; the sort (comparator) doesnt emulate CPU. If the map is short lived; the CPU emulation thread (spawned from the map task in cleanup) doesn't get a chance to emulate.,Closed,Fixed,,Amar Kamat,Amar Kamat,Wed; 14 Sep 2011 13:08:49 +0000,Tue; 10 Mar 2015 04:31:50 +0000,Fri; 7 Oct 2011 05:01:28 +0000,,2.0.0-alpha,cpu-emulation;gridmix,,,https://issues.apache.org/jira/browse/MAPREDUCE-3008
MAPREDUCE-3009,Bug,Major,jobhistoryserver;mrv2,RM UI -> Applications -> Application(Job History) -> Map Tasks -> Task ID -> Node link is not working,RM UI - Applications - Application(Job History) - Map Tasks - Task ID - Node link is not working. The URL contains extra ' ' which is causing the problem. Please find in the attached screen shots.,Resolved,Fixed,,chackaravarthy,chackaravarthy,Wed; 14 Sep 2011 14:04:52 +0000,Tue; 6 Mar 2012 13:30:31 +0000,Mon; 5 Mar 2012 18:46:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3009
MAPREDUCE-3010,Bug,Major,,ant mvn-install doesn't work on hadoop-mapreduce-project,Even though ant jar works; ant mvn-install fails in the compile-fault-inject step,Resolved,Invalid,,Unassigned,Ravi Prakash,Wed; 14 Sep 2011 22:26:52 +0000,Mon; 18 May 2015 16:54:53 +0000,Mon; 18 May 2015 16:54:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3010
MAPREDUCE-3011,Sub-task,Major,tasktracker,TT should remove bad local dirs from conf to prevent constant disk checking,Per HADOOP-7551 the TT does not remove bad mapred.local.dirs from the conf so after a single disk failure every call to get a local path for reading or writing results in a disk check of all configured local dirs. After detecting that a local dir is bad we should remove it from the conf so that we don't repeatedly perform this expensive operation.,Closed,Not A Problem,,Eli Collins,Eli Collins,Thu; 15 Sep 2011 04:55:51 +0000,Tue; 29 May 2012 06:32:50 +0000,Thu; 3 Nov 2011 20:11:10 +0000,,0.20.204.0,,,MAPREDUCE-3077,https://issues.apache.org/jira/browse/MAPREDUCE-3011
MAPREDUCE-3012,Task,Major,,Change org.apache.hadoop.mapred.lib.NLineInputFormat and org.apache.hadoop.mapred.MapFileOutputFormat to use new api for hadoop 0.20,This bug has been fixed for hadoop 0.21 api; but it still is open for hadoop 0.20. As 0.21 is hardly used anywhere; and 0.20 is the main version on all the clusters; I feel that the issue has to be reopened. https: MAPREDUCE-375,Resolved,Won't Fix,,Unassigned,Arsen Zahray,Thu; 15 Sep 2011 06:44:24 +0000,Tue; 10 Mar 2015 03:02:31 +0000,Tue; 10 Mar 2015 03:02:31 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3012
MAPREDUCE-3013,Sub-task,Major,mrv2;security,Remove YarnConfiguration.YARN_SECURITY_INFO,We don't need this anymore since RPC client uses SecurityUtil to pick it up via going through the providers for SecurityInfo interface.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 15 Sep 2011 07:48:05 +0000,Tue; 15 Nov 2011 00:48:16 +0000,Wed; 5 Oct 2011 11:47:29 +0000,,0.23.0,,MAPREDUCE-2792,,https://issues.apache.org/jira/browse/MAPREDUCE-3013
MAPREDUCE-3014,Improvement,Major,build,Rename and invert logic of '-cbuild' profile to 'native' and off by default,This would align MR modules with common  hdfs modules.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 15 Sep 2011 15:24:46 +0000,Mon; 16 Mar 2015 17:57:18 +0000,Fri; 7 Oct 2011 17:36:04 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3014
MAPREDUCE-3015,Sub-task,Major,tasktracker,Add local dir failure info to metrics and the web UI,Like HDFS-811 HDFS-1850 but for the TT.,Closed,Fixed,,Eli Collins,Eli Collins,Thu; 15 Sep 2011 22:47:13 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Mon; 14 Nov 2011 18:04:12 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3015
MAPREDUCE-3016,Sub-task,Major,jobtracker,Add TT local dir failure info to the JT web UI,Like HDFS-556 but for the JT. The machine list page should report local directory failures per TT.,Resolved,Duplicate,MAPREDUCE-3015,Eli Collins,Eli Collins,Thu; 15 Sep 2011 22:50:43 +0000,Thu; 3 Nov 2011 23:06:10 +0000,Thu; 3 Nov 2011 23:06:10 +0000,,0.20.204.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3016
MAPREDUCE-3017,Bug,Blocker,mrv2,The Web UI shows FINISHED for killed/successful/failed jobs.,The RM web ui shows FINISHED status for all the jobs even if they failed killed or were successful. This should be fixed. Only the jobs where the AM crashes are marked as Failed.,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 15 Sep 2011 23:59:36 +0000,Tue; 15 Nov 2011 00:50:04 +0000,Tue; 20 Sep 2011 00:02:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3017
MAPREDUCE-3018,Bug,Blocker,mrv2,Streaming jobs with -file option fail to run.,"Streaming jobs fail to run with the -file option. hadoop jar streaming.jar -input input.txt -output Out -mapper ""mapper.sh"" -reducer NONE -file path_to_mapper.sh  fails to run.",Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 16 Sep 2011 00:03:54 +0000,Tue; 15 Nov 2011 00:48:37 +0000,Wed; 21 Sep 2011 01:12:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3018
MAPREDUCE-3019,Bug,Major,mrv2,"Can't find the symbol ""YARN_MR_PREFIX"" in MRConstants.java ",Fail to compile AMConstants.  It seems this bug is caused by incomplete integration of MAPREDUCE-2864.,Resolved,Not A Problem,,XieXianshan,XieXianshan,Fri; 16 Sep 2011 03:28:40 +0000,Tue; 10 Mar 2015 04:32:24 +0000,Fri; 16 Sep 2011 07:37:35 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3019
MAPREDUCE-3020,Bug,Major,jobhistoryserver,Node link in reduce task attempt page is not working [Job History Page],RM UI - Applications - Application(Job History) - Reduce Tasks - Task ID - Node link is not working hostname for ReduceAttemptFinishedEvent is coming wrong when loading from history file.,Closed,Fixed,,chackaravarthy,chackaravarthy,Fri; 16 Sep 2011 09:20:59 +0000,Mon; 16 Mar 2015 17:57:12 +0000,Tue; 11 Oct 2011 14:13:28 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3020
MAPREDUCE-3021,Bug,Major,mrv2,"all yarn webapps use same base name of ""yarn/""","All of the yarn webapps (resource manager; node manager; app master; job history) use the same base url of  yarn"" that should be fixed up.",Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 16 Sep 2011 14:42:07 +0000,Wed; 17 Jul 2013 22:56:47 +0000,Wed; 28 Sep 2011 01:25:48 +0000,,0.23.0,,,MAPREDUCE-5397,https://issues.apache.org/jira/browse/MAPREDUCE-3021
MAPREDUCE-3022,Bug,Major,mrv2,Some Web UI links to other components don't specify path,Some of the links to other components in the web ui just specify host:port and don't add on the path.  For instance in the RM UI - the nodes page.  Each node is just listed as IP:port.  The actual path to those pages are IP:port *.  I think the links should be what that components webapp is registered at.    There may be other places too so we should search for them.,Resolved,Fixed,,Unassigned,Thomas Graves,Fri; 16 Sep 2011 14:47:34 +0000,Tue; 10 Mar 2015 01:22:12 +0000,Tue; 10 Mar 2015 01:22:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3022
MAPREDUCE-3023,Bug,Major,mrv2,Queue state is not being translated properly (is always assumed to be running),During translation of QueueInfo;   TypeConverter. 435 : queueInfo.toString(); QueueState.RUNNING; ought to be  queueInfo.toString(); QueueState.getState(queueInfo.getQueueState().toString().toLowerCase());,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 16 Sep 2011 16:18:45 +0000,Tue; 15 Nov 2011 00:50:16 +0000,Wed; 21 Sep 2011 01:32:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3023
MAPREDUCE-3024,Improvement,Major,build,Make all poms to have hadoop-project POM as common parent,in order to effectively use the Maven 'versions' plugin to update version numbers all POMs should have the hadoop-project POM as their common parent.,Resolved,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 16 Sep 2011 17:04:51 +0000,Mon; 16 Mar 2015 20:07:46 +0000,Sat; 22 Sep 2012 07:45:54 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3024
MAPREDUCE-3025,Bug,Blocker,build,Contribs not building,Contribs are not getting built. Snippet from Jenkins:  compile: subant No sub-builds to iterate on,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Fri; 16 Sep 2011 18:28:58 +0000,Mon; 12 Dec 2011 06:18:40 +0000,Tue; 20 Sep 2011 23:43:48 +0000,,0.22.0,,,HDFS-2341,https://issues.apache.org/jira/browse/MAPREDUCE-3025
MAPREDUCE-3026,Bug,Major,jobtracker,When user adds hierarchical queues to the cluster; mapred queue -list returns NULL Pointer Exception,When User adds the hierarchical queues; and try to see them from the command line using  mapred queue -list  It returns Null Pointer Exception.,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Fri; 16 Sep 2011 23:24:26 +0000,Wed; 23 Nov 2011 05:39:27 +0000,Sat; 24 Sep 2011 18:35:39 +0000,,0.22.0,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3026
MAPREDUCE-3027,Bug,Major,mrv2,MR-279: Completed container exit state needs to be enhanced to differentiate between container aborts/failures and actual application process exit codes,Currently; a completed container's exit status is set to -100 to denote the container being killed by the framework either as a result of the application releasing the container or a node failure. An application process may also return an exit code of -100 creating an ambiguity.,Resolved,Invalid,,Hitesh Shah,Hitesh Shah,Sat; 17 Sep 2011 01:37:37 +0000,Mon; 28 Sep 2015 21:10:34 +0000,Tue; 15 Nov 2011 21:44:32 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3027
MAPREDUCE-3028,Bug,Blocker,mrv2,Support job end notification in .next /0.23,Oozie primarily depends on  the job end notification to determine when the job finishes. In the current version;  job end notification is implemented in job tracker. Since job tracker will be removed in the upcoming hadoop release (.next); we wander where this support will move. I think this best effort notification could be implemented in the new Application Manager as one of the last step of job completion.  Whatever implementation will it be; Oozie badly needs this feature to be continued in next releases as well.,Closed,Fixed,,Ravi Prakash,Mohammad Kamrul Islam,Sat; 17 Sep 2011 02:07:17 +0000,Thu; 6 Sep 2012 11:44:40 +0000,Mon; 24 Oct 2011 21:01:37 +0000,,0.23.0,,,MAPREDUCE-1688,https://issues.apache.org/jira/browse/MAPREDUCE-3028
MAPREDUCE-3029,Bug,Major,contrib/eclipse-plugin,Eclipse Plugin not work on Eclipse Helios,"No response when clicking the ""New Hadoop Location"" icon in the ""Map Reduce Locations"" view.",Open,Unresolved,,Unassigned,Paul Lam,Sat; 17 Sep 2011 11:17:47 +0000,Wed; 16 Nov 2011 05:17:45 +0000,,,0.21.0,eclipse;hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3029
MAPREDUCE-3030,Bug,Blocker,mrv2;resourcemanager,RM is not processing heartbeat and continuously giving the message 'Node not found rebooting',Node Manager is registered with Resource manager and the for every heartbeat; it is printing the above message.,Closed,Fixed,,Devaraj K,Devaraj K,Mon; 19 Sep 2011 10:15:25 +0000,Mon; 16 Mar 2015 17:57:13 +0000,Mon; 19 Sep 2011 14:20:32 +0000,,0.23.0,,,MAPREDUCE-2965,https://issues.apache.org/jira/browse/MAPREDUCE-3030
MAPREDUCE-3031,Bug,Blocker,mrv2,Job Client goes into infinite loop when we kill AM,Started a cluster. Submitted a sleep job with around 10000 maps and 1000 reduces. Killed AM with kill -9 by which time already 7000 thousands maps got completed.  On the RM webUI; Application is stuck in Application.RUNNING state. And JobClient goes into an infinite loop as RM keeps telling the client that the application is running.,Closed,Fixed,MAPREDUCE-3072;MAPREDUCE-2875,Siddharth Seth,Karam Singh,Mon; 19 Sep 2011 13:13:50 +0000,Tue; 15 Nov 2011 00:50:01 +0000,Mon; 26 Sep 2011 17:32:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3031
MAPREDUCE-3032,Bug,Blocker,applicationmaster;mrv2,JobHistory doesn't have error information from failed tasks,nan,Closed,Fixed,MAPREDUCE-3120,Devaraj K,Vinod Kumar Vavilapalli,Mon; 19 Sep 2011 13:15:32 +0000,Fri; 11 Apr 2014 16:28:57 +0000,Mon; 17 Oct 2011 15:22:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3032
MAPREDUCE-3033,Bug,Blocker,job submission;mrv2,JobClient requires mapreduce.jobtracker.address config even when mapreduce.framework.name is set to yarn,If mapreduce.jobtracker.address is not set in mapred-site.xml and mapreduce.framework.name is set yarn; job submission fails :  Tried to submit sleep job with maps 1 task. Job submission failed with following exception -:,Closed,Fixed,,Hitesh Shah,Karam Singh,Mon; 19 Sep 2011 13:25:17 +0000,Tue; 15 Nov 2011 00:49:00 +0000,Mon; 10 Oct 2011 18:27:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3033
MAPREDUCE-3034,Bug,Critical,mrv2;nodemanager,NM should act on a REBOOT command from RM,RM sends a reboot command to NM in some cases; like when it gets lost and rejoins back. In such a case; NM should act on the command and reboot reinitalize itself.  This is akin to TT reinitialize on order from JT. We will need to shutdown all the services properly and reinitialize - this should automatically take care of killing of containers; cleaning up local temporary files etc.,Resolved,Fixed,,Devaraj K,Vinod Kumar Vavilapalli,Mon; 19 Sep 2011 13:57:52 +0000,Tue; 6 Mar 2012 13:30:31 +0000,Tue; 6 Mar 2012 00:53:36 +0000,,0.23.0,,,MAPREDUCE-3272,https://issues.apache.org/jira/browse/MAPREDUCE-3034
MAPREDUCE-3035,Bug,Critical,mrv2,MR V2 jobhistory does not contain rack information,When topology.node.switch.mapping.impl is set to enable rack-locality resolution via the topology script; from the RM web-UI; we can see the rack information for each node. Running a job also reveals the information about rack-local map tasks launched at end of job completion on the client side.  But the hostname field for attempts in the JobHistory does not contain this rack information.  In case of hadoop-0.20 securiy or MRV1; hostname field of job history does contain rackid hostname whereas in MRV2; hostname field only contains the hostIP. Thus this is a regression.,Closed,Fixed,,chackaravarthy,Karam Singh,Mon; 19 Sep 2011 15:21:04 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Mon; 31 Oct 2011 17:30:36 +0000,,0.23.0,,,MAPREDUCE-3317,https://issues.apache.org/jira/browse/MAPREDUCE-3035
MAPREDUCE-3036,Bug,Blocker,mrv2,Some of the Resource Manager memory metrics go negative.,ReservedGB seems to always be decremented when a container is released; even though the container never reserved any memory. AvailableGB also seems to be able to go negative in a few situations.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 19 Sep 2011 16:30:32 +0000,Mon; 16 Mar 2015 17:57:13 +0000,Wed; 21 Sep 2011 01:14:58 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-2738,,https://issues.apache.org/jira/browse/MAPREDUCE-3036
MAPREDUCE-3037,Improvement,Major,mrv2,Add a consistent method for getting the job configuration's XML within the AppMaster and the JobHistory,"We should add consistent functionality for accessing conf (a ""Configuration"" link on the left side of the UI).  It would be good to add a link there that allows the user to actually download the XML.  We could either have a conf-xml servlet or even better we could do something more REST-like by allowing requests to contain the desired format (XML; HTML; JSON; etc?).",Resolved,Won't Fix,,Unassigned,Jeffrey Naisbitt,Mon; 19 Sep 2011 17:21:05 +0000,Mon; 28 Sep 2015 21:10:30 +0000,Fri; 17 Feb 2012 22:29:15 +0000,,0.23.0,,,MAPREDUCE-2726;MAPREDUCE-2676,https://issues.apache.org/jira/browse/MAPREDUCE-3037
MAPREDUCE-3038,Bug,Blocker,mrv2,job history server not starting because conf() missing HsController,Exception starting history server.   Sep 19; 2011 6:51:53 PM com.google.inject.MessageProcessor visit INFO: An exception was caught and reported. Message: org.apache.hadoop.yarn.webapp.WebAppException: conf() not found in class org.apache.hadoop.mapreduce.v2.hs.webapp.HsController                                                                                 org.apache.hadoop.yarn.webapp.WebAppException: conf() not found in class org.apache.hadoop.mapreduce.v2.hs.webapp.HsController      org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer. 83),Closed,Fixed,,Jeffrey Naisbitt,Thomas Graves,Mon; 19 Sep 2011 18:59:20 +0000,Mon; 16 Mar 2015 17:57:17 +0000,Mon; 19 Sep 2011 22:54:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3038
MAPREDUCE-3039,Bug,Major,capacity-sched;contrib/fair-share;contrib/gridmix;contrib/mrunit;contrib/mumak;contrib/raid;contrib/streaming;jobhistoryserver,Make mapreduce use same version of avro as HBase,HBase depends on avro 1.5.3 whereas hadoop-common depends on 1.3.2. When building HBase on top of hadoop; this should be consistent. Moreover; this should be consistent between common; hdfs; and mapreduce.  Contribs seem to have declared a dependency on avro but are not in fact depending on it.,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Mon; 19 Sep 2011 19:29:05 +0000,Mon; 12 Dec 2011 06:19:25 +0000,Wed; 28 Sep 2011 03:24:57 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3039
MAPREDUCE-3040,Bug,Major,mrv2,TestMRJobs; TestMRJobsWithHistoryService; TestMROldApiJobs fail,Running org.apache.hadoop.mapreduce.v2.TestMRJobs Tests run: 4; Failures: 0; Errors: 4; Skipped: 0; Time elapsed: 6.229 sec &lt; FAILURE! Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 5.887 sec &lt; FAILURE! Running org.apache.hadoop.mapreduce.v2.TestMROldApiJobs Tests run: 2; Failures: 0; Errors: 2; Skipped: 0; Time elapsed: 6.067 sec &lt; FAILURE!  All of them have the exception:    191),Closed,Fixed,,Arun C Murthy,Thomas Graves,Mon; 19 Sep 2011 20:06:26 +0000,Tue; 15 Nov 2011 00:48:34 +0000,Tue; 20 Sep 2011 00:47:26 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3040
MAPREDUCE-3041,Bug,Blocker,mrv2,Enhance YARN Client-RM protocol to provide access to information such as cluster's Min/Max Resource capabilities similar to that of AM-RM protocol,To request a container to launch an application master; the client needs to know the min max resource capabilities so as to be able to make a proper resource request when submitting a new application.,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Mon; 19 Sep 2011 20:17:01 +0000,Tue; 15 Nov 2011 00:48:40 +0000,Wed; 28 Sep 2011 04:25:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3041
MAPREDUCE-3042,Bug,Major,mrv2;resourcemanager,YARN RM fails to start,When I build and run YARN's RM; I get an invalid host:port exception.  Looks like there's a typo in the ResourceTrackerService.,Closed,Fixed,,Chris Riccomini,Chris Riccomini,Mon; 19 Sep 2011 21:17:13 +0000,Tue; 15 Nov 2011 00:49:16 +0000,Mon; 19 Sep 2011 21:32:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3042
MAPREDUCE-3043,Bug,Major,resourcemanager,Missing containers info on the nodes page,The containers info on the nodes page on the RM seems to be missing. This was useful in understanding the usage on each of the nodemanagers.,Resolved,Fixed,,Subroto Sanyal,Ramya Sunil,Mon; 19 Sep 2011 22:29:59 +0000,Tue; 10 Mar 2015 04:30:28 +0000,Tue; 29 Apr 2014 14:46:58 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3043
MAPREDUCE-3044,Bug,Blocker,mrv2,Pipes jobs stuck without making progress,A simple example pipes job gets stuck without making any progress. The AM is launched but the maps do not make any progress.,Closed,Fixed,,Mahadev konar,Ramya Sunil,Mon; 19 Sep 2011 23:34:30 +0000,Tue; 15 Nov 2011 00:49:00 +0000,Wed; 21 Sep 2011 23:55:21 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3044
MAPREDUCE-3045,Bug,Minor,jobhistoryserver;mrv2,Elapsed time filter on jobhistory server displays incorrect table entries,The elapsed time filter on the jobhistory server filters incorrect information.  For e.g. on a cluster where the elapsed time of all the tasks is either 7 or 8sec; the filter displays non null table entries for 1sec or 3sec,Closed,Fixed,,Jonathan Eagles,Ramya Sunil,Mon; 19 Sep 2011 23:42:49 +0000,Mon; 5 Mar 2012 02:49:13 +0000,Tue; 29 Nov 2011 00:16:51 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3045
MAPREDUCE-3046,New Feature,Major,mrv2,Integrate the Twitter Storm to work with Next Gen MapReduce,Twitter has open-sourced storm (https: storm). it will be good to integrate the Next Gen Mapreduce to storm.,Open,Unresolved,,Venu Gopala Rao,Venu Gopala Rao,Tue; 20 Sep 2011 05:32:28 +0000,Tue; 10 Mar 2015 04:32:00 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3046
MAPREDUCE-3047,Improvement,Minor,,FileOutputCommitter throws wrong type of exception when calling abortTask() to handle a directory without permission,When FileOutputCommitter calls abortTask() to create a temp directory; if the user has no permission to access the directory; or a file with the same name has existed; of course it will fail; however the system will output the error information into the log file instead of throwing an exception.As a result; when the temp directory is needed later; since the temp directory hasn't been created yet; system will throw an exception to tell user that the temp directory doesn't exist.In my opinion; the exception is not exact and the error infomation will confuse users.,Open,Unresolved,,Brahma Reddy Battula,JiangKai,Tue; 20 Sep 2011 07:43:24 +0000,Sat; 7 Jan 2017 01:59:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3047
MAPREDUCE-3048,Bug,Major,build,"Fix test-patch to run tests via ""mvn clean install test""","Some tests like the ones failing at MAPREDUCE-3040 depend on the generated jars. TestMRJobs for e.g. won't run if we simply run ""mvn clean test"".  I propose that we change test-patch to run tests using ""mvn clean install test"".",Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 20 Sep 2011 07:47:04 +0000,Tue; 15 Nov 2011 00:49:18 +0000,Thu; 22 Sep 2011 06:34:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3048
MAPREDUCE-3049,Improvement,Major,mrv2,Improvements in the RM; NM; HS UI pages,For the below pages as marked in the attached UI screen shots; content div is moving to right out of the viewable area.  1. RM Cluster Overview 2. NM Application Information 3. NodeManager information 4. History Job Overview 5. History Server About,Open,Unresolved,,Unassigned,Devaraj K,Tue; 20 Sep 2011 11:10:44 +0000,Tue; 10 Mar 2015 04:31:52 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3049
MAPREDUCE-3050,Bug,Blocker,mrv2;resourcemanager,YarnScheduler needs to expose Resource Usage Information,Before the recent refactor The nodes had information in them about how much resources they were using.  This information is not hidden inside SchedulerNode.  Similarly resource usage information about an application; or in aggregate is only available through the Scheduler and there is not interface to pull it out.  We need to expose APIs to get Resource and Container information from the scheduler; in aggregate across the entire cluster; per application; per node; and ideally also per queue if applicable (although there are no JIRAs I am aware of that need this right now).,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 20 Sep 2011 17:05:13 +0000,Tue; 10 Mar 2015 04:31:39 +0000,Fri; 30 Sep 2011 22:20:31 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-2738;MAPREDUCE-2790;MAPREDUCE-2789,,https://issues.apache.org/jira/browse/MAPREDUCE-3050
MAPREDUCE-3051,Bug,Minor,mrv2,HADOOP_CONF_DIR exported twice in the classpath,HADOOP_CONF_DIR is exported twice in the classpath during RM; NM and container startup time. Not an issue so far but seems redundant.,Resolved,Duplicate,NULL,Ravi Teja Ch N V,Ramya Sunil,Tue; 20 Sep 2011 17:43:19 +0000,Tue; 10 Mar 2015 01:25:41 +0000,Tue; 10 Mar 2015 01:25:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3051
MAPREDUCE-3052,Bug,Major,mrv2,Maintain consistency in naming appIDs; jobIDs and attemptIDs,Currently; the appIDs; jobIDs and tempt and container IDs; but I'm making them more consistent.  (If any of you have preferences; let me know),Resolved,Duplicate,MAPREDUCE-2793,Jeffrey Naisbitt,Jeffrey Naisbitt,Tue; 20 Sep 2011 18:54:23 +0000,Mon; 26 Sep 2011 04:19:22 +0000,Mon; 26 Sep 2011 04:19:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3052
MAPREDUCE-3053,Bug,Major,mrv2;resourcemanager,YARN Protobuf RPC Failures in RM,"When I try to register my ApplicationMaster with YARN's RM; it fails.  In my ApplicationMaster's logs:  Exception in thread ""main""  lang.reflect.UndeclaredThrowableException  tempt - 1 timestamp - 1316556657998",Closed,Fixed,,Vinod Kumar Vavilapalli,Chris Riccomini,Tue; 20 Sep 2011 22:32:42 +0000,Tue; 15 Nov 2011 00:49:33 +0000,Sun; 25 Sep 2011 10:43:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3053
MAPREDUCE-3054,Bug,Blocker,mrv2,Unable to kill submitted jobs,"Found by Philip Su  The ""mapred job -kill"" command appears to succeed; but listing the jobs again shows that the job supposedly killed is still there.",Closed,Fixed,,Mahadev konar,Siddharth Seth,Wed; 21 Sep 2011 00:09:23 +0000,Sat; 12 Oct 2013 08:20:55 +0000,Tue; 27 Sep 2011 20:37:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3054
MAPREDUCE-3055,Bug,Minor,mrv2,Simplify parameter passing to Application Master from Client. SImplify approach to pass info such  appId; ClusterTimestamp and failcount required by App Master.,The Application master needs the application attempt id to register with the Applications Manager. To create an appAttemptId object; the appId object(needs cluster timestamp and app id) and failCount are needed.  Currently; all clients need to pass in the appId; cluster timestamp and fail count to the app master for the required objects to be constructed.   We could look at simplifying this by providing either placeholders that would have values replaced by the app master launcher or setting it  into the environment ( although that requires a set of whitelisted env vars that can only be set by the yarn framework ).,Closed,Fixed,,Vinod Kumar Vavilapalli,Hitesh Shah,Wed; 21 Sep 2011 00:43:12 +0000,Tue; 15 Nov 2011 00:50:14 +0000,Fri; 23 Sep 2011 14:12:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3055
MAPREDUCE-3056,Bug,Blocker,applicationmaster;mrv2,Jobs are failing when those are submitted by other users,MR cluster is started by the user 'root'. If any other users other than 'root' submit a job; it is failing always.  Find the conatiner logs in the comments section.,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 21 Sep 2011 09:57:48 +0000,Wed; 13 May 2015 09:54:31 +0000,Tue; 4 Oct 2011 09:40:07 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3056
MAPREDUCE-3057,Bug,Blocker,jobhistoryserver;mrv2,Job History Server goes of OutOfMemory with 1200 Jobs and Heap Size set to 10 GB,"History server was started with -Xmx10000m Ran GridMix V3 with 1200 Jobs trace in STRESS mode on 350 nodes with each node 4 NMS. All jobs finished as reported by RM Web UI and HADOOP_MAPRED_HOME mapred job -status jobid JobClient also got stuck while looking for token to connect to History server Then looked at History Server logs and found History is trowing "" lang.OutOfMemoryError: GC overhead limit exceeded"" error.  With 10GB of Heap space and 1200 Jobs; History Server should not go out of memory . No matter what are the type of jobs.",Closed,Fixed,,Eric Payne,Karam Singh,Wed; 21 Sep 2011 12:23:00 +0000,Tue; 15 Nov 2011 00:48:14 +0000,Fri; 14 Oct 2011 22:53:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3057
MAPREDUCE-3058,Bug,Critical,contrib/gridmix;mrv2,Sometimes task keeps on running while its Syslog says that it is shutdown,While running GridMixV3; one of the jobs got stuck for 15 hrs. After clicking on the Job-page; found one of its reduces to be stuck. Looking at syslog of the stuck reducer; found this: Task-logs' head:     Task-logs' tail:    Which means that tasks is supposed to have stopped within 20 secs; whereas the process itself is stuck for more than 15 hours. From AM log; also found that this task was sending its update regularly. ps -ef | grep  was also showing that process is still alive.,Closed,Fixed,,Vinod Kumar Vavilapalli,Karam Singh,Wed; 21 Sep 2011 12:53:39 +0000,Tue; 15 Nov 2011 00:48:45 +0000,Sat; 22 Oct 2011 06:15:42 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3058
MAPREDUCE-3059,Bug,Blocker,mrv2,QueueMetrics do not have metrics for aggregate containers-allocated and aggregate containers-released,QueueMetrics for ResourceManager do not have any metrics for aggregate containers-allocated and containers-released.  We need the aggregates of containers-allocated and containers-released to figure out the rate at which RM is dishing out containers. NodeManager do have containers-launched and container-released metrics; but this is not across all nodes; so to get the cluster level aggregate; we need to preprocess NM metrics from all nodes - which is troublesome.  Currently; we do have AllocatedContainers and PendingContainers which reflect the running containers given out to AMs; and containers waiting for allocation respectively.,Closed,Fixed,,Devaraj K,Karam Singh,Wed; 21 Sep 2011 13:28:41 +0000,Tue; 15 Nov 2011 00:50:01 +0000,Fri; 14 Oct 2011 22:42:37 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3059
MAPREDUCE-3060,Improvement,Major,mrv2,Generic shuffle service,When I was talking to Owen about MAPREDUCE-2600; we came across (again; talked about it with Chris before) the shuffle dependency issue. NodeManager currently has an implicit (hidden by the service plugin mechanism) dependency of a specific version of mapreduce shuffle. While this works in many cases; as long as we don't change shuffle headers and the usage of mapred security tokens; it's a hack to make things work none the less. It's generally agreed upon that nodemanager should only load generic services that are mapreduce framework neutral.  In this particular case; the right solution seems to be a generic shuffle handler that can serve data for a particular partition securely. The ShuffleHandler currently only depends on mapreduce for task tokens and shuffle header; which is only used for writing data; i.e.; the shuffle handler has no semantic dependency on mapreduce.,Open,Unresolved,,Unassigned,Luke Lu,Wed; 21 Sep 2011 16:46:34 +0000,Thu; 24 Jan 2013 15:14:56 +0000,,,0.23.0,shuffle,,MAPREDUCE-4049,https://issues.apache.org/jira/browse/MAPREDUCE-3060
YARN-321,Improvement,Minor,,[Umbrella] Generic application history service,The mapreduce job history server currently needs to be deployed as a trusted server in sync with the mapreduce runtime. Every new application would need a similar application history server. Having to deploy O(T*V) (where T is number of type of application; V is number of version of application) trusted servers is clearly not scalable.  Job history storage handling itself is pretty generic: move the logs and history data into a particular directory for later serving. Job history data is already stored as json (or binary avro). I propose that we create only one trusted application history server; which can have a generic UI (display json as a tree of strings) as well. Specific application or analytics.,Resolved,Fixed,YARN-304,Unassigned,Luke Lu,Wed; 21 Sep 2011 17:10:31 +0000,Thu; 27 Oct 2016 19:39:10 +0000,Fri; 1 May 2015 22:15:11 +0000,,,,,YARN-374;YARN-1530;YARN-2928;YARN-1701;YARN-1982;YARN-374;YARN-1452,https://issues.apache.org/jira/browse/YARN-321
MAPREDUCE-3062,Bug,Major,mrv2;nodemanager;resourcemanager,YARN NM/RM fail to start,2011-09-21 10:21:41;932 FATAL resourcemanager.ResourceManager (ResourceManager. 497)  Another copy and paste issue. Similar to https: MAPREDUCE-3042.,Closed,Fixed,,Chris Riccomini,Chris Riccomini,Wed; 21 Sep 2011 17:31:02 +0000,Tue; 15 Nov 2011 00:49:29 +0000,Wed; 21 Sep 2011 20:38:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3062
MAPREDUCE-3063,Bug,Critical,build,Mapreduce trunk Commit builds are failing,Mapreduce trunk commit builds are failing due to test failures.  See https:  for more details.,Resolved,Duplicate,MAPREDUCE-3064,Unassigned,Ramya Sunil,Wed; 21 Sep 2011 17:48:10 +0000,Wed; 21 Sep 2011 17:50:27 +0000,Wed; 21 Sep 2011 17:50:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3063
MAPREDUCE-3064,Bug,Blocker,,"27 unit test failures with  Invalid ""mapreduce.jobtracker.address"" configuration value for JobTracker: ""local""",unit test failure here: https:  +27)      org.apache.hadoop.mapred.TestCollect.testCollect     org.apache.hadoop.mapred.TestComparators.testDefaultMRComparator     org.apache.hadoop.mapred.TestComparators.testUserMRComparator     org.apache.hadoop.mapred.TestComparators.testUserValueGroupingComparator     org.apache.hadoop.mapred.TestComparators.testAllUserComparators     org.apache.hadoop.mapred.TestFileOutputFormat.testCustomFile     org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob     org.apache.hadoop.mapred.TestJavaSerialization.testWriteToSequencefile     org.apache.hadoop.mapred.TestMapOutputType.testKeyMismatch     org.apache.hadoop.mapred.TestMapOutputType.testValueMismatch     org.apache.hadoop.mapred.TestMapOutputType.testNoMismatch     org.apache.hadoop.mapred.TestMapRed.testMapred     org.apache.hadoop.mapred.TestMapRed.testNullKeys     org.apache.hadoop.mapred.TestMapRed.testCompression     org.apache.hadoop.mapred.TestMapRed.testSmallInput     org.apache.hadoop.mapred.TestMapRed.testBiggerInput     org.apache.hadoop.mapreduce.TestMapCollection.testValLastByte     org.apache.hadoop.mapreduce.TestMapCollection.testLargeRecords     org.apache.hadoop.mapreduce.TestMapCollection.testSpillPer2B     org.apache.hadoop.mapreduce.TestMapCollection.testZeroVal     org.apache.hadoop.mapreduce.TestMapCollection.testSingleRecord     org.apache.hadoop.mapreduce.TestMapCollection.testLowSpill     org.apache.hadoop.mapreduce.TestMapCollection.testSplitMetaSpill     org.apache.hadoop.mapreduce.TestMapCollection.testPostSpillMeta     org.apache.hadoop.mapreduce.TestMapCollection.testLargeRecConcurrent     org.apache.hadoop.mapreduce.TestMapCollection.testRandom     org.apache.hadoop.mapreduce.TestMapCollection.testRandomCompress   All of them have similar stack traces of:   133),Closed,Fixed,MAPREDUCE-3085,Venu Gopala Rao,Thomas Graves,Wed; 21 Sep 2011 17:49:06 +0000,Tue; 15 Nov 2011 00:49:10 +0000,Thu; 29 Sep 2011 11:16:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3064
MAPREDUCE-3065,Bug,Major,nodemanager,ApplicationMaster killed by NodeManager due to excessive virtual memory consumption,Hey Vinod;    OK; so I have a little more clarity into this.    When I bump my resource request for my AM to 4096; it runs. The important line in the NM logs is:    2011-09-21 13:43:44;366 INFO  monitor.ContainersMonitorImpl (ContainersMonitorImpl. run(402)) - Memory usage of ProcessTree 25656 for container-id container_1316637655278_0001_01_000001 : Virtual 2260938752 bytes; limit : 4294967296 bytes; Physical 120860672 bytes; limit -1 bytes    The thing to note is the virtual memory; which is off the charts; even though my physical memory is almost nothing (12 megs). I'm still poking around the code; but I am noticing th Java's Runtime exec is forking; &gt; and &gt;&gt; copying its entire JVM memory footprint for the fork. &gt;&gt;  &gt;&gt; Has anyone seen this? Am I doing something dumb? &gt;&gt;  &gt;&gt; Thanks! &gt;&gt; Chris &gt;&gt;  &gt;&gt;  &gt;,Resolved,Duplicate,MAPREDUCE-3068,Unassigned,Chris Riccomini,Wed; 21 Sep 2011 21:11:23 +0000,Fri; 13 Nov 2015 18:51:15 +0000,Fri; 13 Nov 2015 18:51:15 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3065
MAPREDUCE-3066,Bug,Major,mrv2;nodemanager,YARN NM fails to start,Please check conf.get() calls. Every time I svn up; I get one of these.   2011-09-21 15:36:33;534 INFO  service.AbstractService (AbstractService. 118),Closed,Fixed,,Chris Riccomini,Chris Riccomini,Wed; 21 Sep 2011 22:42:00 +0000,Tue; 15 Nov 2011 00:48:41 +0000,Wed; 21 Sep 2011 23:33:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3066
MAPREDUCE-3067,Bug,Blocker,mrv2,Container exit status not set properly to launched process's exit code on successful completion of process,When testing the distributed shell sample app master; the container exit status was being returned incorrectly.     INFO DistributedShell.ApplicationMaster: Got container status for containerID= container_1316629955324_0001_01_000002; state=COMPLETE; exitStatus=-1000; diagnostics=,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Thu; 22 Sep 2011 04:57:27 +0000,Tue; 15 Nov 2011 00:48:48 +0000,Tue; 27 Sep 2011 07:00:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3067
MAPREDUCE-3068,Bug,Blocker,mrv2,Should set MALLOC_ARENA_MAX for all YARN daemons and AMs/Containers,This is same as HADOOP-7154 but for yarn. RM; NM; AM and containers should all have this.,Closed,Fixed,MAPREDUCE-3065;MAPREDUCE-2748,Chris Riccomini,Vinod Kumar Vavilapalli,Thu; 22 Sep 2011 05:59:01 +0000,Fri; 13 Nov 2015 18:51:15 +0000,Tue; 18 Oct 2011 01:23:40 +0000,,0.23.0,,,HADOOP-7154,https://issues.apache.org/jira/browse/MAPREDUCE-3068
HADOOP-7671,Bug,Major,,Add license headers to hadoop-common/src/main/packages/templates/conf/,hadoop-common  not in the exclude list for apache-rat plugin . This causes 10 release audit warnings for missing license headers (in the properties and xml files like hdfs-site.xml),Closed,Fixed,,Ravi Prakash,Ravi Prakash,Thu; 22 Sep 2011 14:33:14 +0000,Tue; 15 Nov 2011 00:51:04 +0000,Fri; 23 Sep 2011 11:14:45 +0000,,0.23.0,,,HADOOP-7669,https://issues.apache.org/jira/browse/HADOOP-7671
MAPREDUCE-3070,Bug,Blocker,mrv2;nodemanager,NM not able to register with RM after NM restart,After stopping NM gracefully then starting NM; NM registration fails with RM with Duplicate registration from the node! error.,Closed,Fixed,,Devaraj K,Ravi Teja Ch N V,Thu; 22 Sep 2011 14:33:58 +0000,Wed; 30 Nov 2011 09:42:58 +0000,Fri; 21 Oct 2011 18:47:09 +0000,,0.23.0,,,MAPREDUCE-3363,https://issues.apache.org/jira/browse/MAPREDUCE-3070
MAPREDUCE-3071,Bug,Major,mrv2,app master configuration web UI link under the Job menu opens up application menu,If you go to the app master web UI for a particular job. The job menu on the left side displays links for overview; counters; configuration; etc..  If you click on the configuration one; it closes the job menu and opens the application menu on that left side. It shouldn't do this. It should leave the job menu open.,Closed,Fixed,,Thomas Graves,Thomas Graves,Thu; 22 Sep 2011 15:17:28 +0000,Tue; 15 Nov 2011 00:48:34 +0000,Tue; 27 Sep 2011 05:34:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3071
MAPREDUCE-3072,Bug,Major,nodemanager,NodeManager doesn't recognize kill -9 of AM container,If I kill -9 my application master's pid; the NM continues reporting that the container is running. I assume it should probably instead report back to the RM that the AM has died. Instead; it continues sending this status:   2011-09-22 09:33:13;352 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl. run(402)) - Memory usage of ProcessTree 27263 for container-id container_1316707951832_0001_01_000001 : Virtual 0 bytes; limit : 2147483648 bytes; Physical 0 bytes; limit -1 bytes  This status keeps being sent forever.,Resolved,Duplicate,MAPREDUCE-3031,Unassigned,Chris Riccomini,Thu; 22 Sep 2011 16:39:16 +0000,Thu; 22 Sep 2011 16:45:36 +0000,Thu; 22 Sep 2011 16:44:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3072
MAPREDUCE-3073,Bug,Blocker,,Build failure for MRv1 caused due to changes to MRConstants.,When runnning ant -Dresolvers=internal binary; the build seems to be failing with:              ^,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 22 Sep 2011 17:50:14 +0000,Tue; 15 Nov 2011 00:49:32 +0000,Thu; 22 Sep 2011 18:06:34 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3073
YARN-3311,Improvement,Major,,add location to web UI so you know where you are - cluster; node; AM; job history,Right now if you go to any of the web UIs for resource manager; node manager; app master; or job history; they look very similar but sometimes it hard to tell which page you are.  Adding a title or something that lets you know would be helpful.   Or somehow make them more seemless so one doesn't have to know.,Open,Unresolved,,Unassigned,Thomas Graves,Thu; 22 Sep 2011 17:51:29 +0000,Thu; 12 May 2016 18:30:35 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-3311
YARN-3312,Improvement,Major,,Web UI menu inconsistencies,When you go to the various web UI's the menus on the left are inconsistent and (atleast to me) sometimes confusing.   For instance if you go to the application master UI; one of the menus is Cluster. If you click on one of the Cluster links it takes you back to the RM ui and you lose the app master UI altogether. Maybe its just me but that is confusing.  I like having a link back to the cluster from AM but the way the UI is setup I would have expected it to just open that page in the middle div frame and leave the AM menus there.  Perhaps a different type of link or menu to indicate this is going to take you away from AM page.   Also; the nodes and job history UI don't have the Cluster menus at all.,Open,Unresolved,,Unassigned,Thomas Graves,Thu; 22 Sep 2011 17:56:49 +0000,Thu; 12 May 2016 18:30:34 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-3312
MAPREDUCE-3076,Bug,Blocker,test,TestSleepJob fails ,TestSleepJob fails; it was intended to be used in other tests for MAPREDUCE-2981.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 23 Sep 2011 00:47:28 +0000,Wed; 12 Sep 2012 02:27:03 +0000,Fri; 23 Sep 2011 01:07:12 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3076
MAPREDUCE-3077,Improvement,Major,tasktracker,re-enable faulty TaskTracker storage without restarting TT; when appropriate,In MAPREDUCE-2928; Ravi Gummadi proposed: we can add LocalStorage.checkBadLocalDirs() call to TT.initialize() that can do disk-health-check of bad local dirs and add dirs to the good local dirs list if they become good. and Eli Collins added: Sounds good. Since transient disk failures may cause a file system to become read-only (causing permanent failures) sometimes re-mounting is sufficient to recover in which case it makes sense to re-enable faulty disks w o TT restart.,Open,Unresolved,,Unassigned,Matt Foley,Fri; 23 Sep 2011 01:17:39 +0000,Fri; 23 Sep 2011 06:56:30 +0000,,,0.20.205.0,,,MAPREDUCE-2928;MAPREDUCE-3011,https://issues.apache.org/jira/browse/MAPREDUCE-3077
MAPREDUCE-3078,Bug,Blocker,applicationmaster;mrv2;resourcemanager,Application's progress isn't updated from AM to RM.,It helps to be able to monitor the application-progress from the RM UI itself.  Bits of it is already there; even the AM-RM API (in AllocateRequest). We just need to make sure the progress is produced and consumed properly.,Closed,Fixed,MAPREDUCE-2982,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 23 Sep 2011 08:47:25 +0000,Tue; 15 Nov 2011 00:48:36 +0000,Wed; 28 Sep 2011 07:32:34 +0000,,0.23.0,,MAPREDUCE-3089,,https://issues.apache.org/jira/browse/MAPREDUCE-3078
MAPREDUCE-3079,Bug,Major,mrv2,usercache/<user>/appcache/<appid> directory not removed when using DefaultContainerExecutor,Running with the DefaultContainerExecutor it appears that the usercache application_1316722920862_0003  This doesn't appear to happen with the LinuxContainerExecutor.,Resolved,Cannot Reproduce,,Unassigned,Thomas Graves,Fri; 23 Sep 2011 16:57:12 +0000,Mon; 9 Mar 2015 20:30:47 +0000,Mon; 9 Mar 2015 20:30:47 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3079
MAPREDUCE-3080,Bug,Major,contrib/streaming,dfs calls from streaming fails with ExceptionInInitializerError,"Dfs calls from streaming seem to fail with the following error:     commons-logging-1.1.1.jar is in the classpath. An easy way to reproduce this is; on a secure deploy; ""hadoop --config $HADOOP_CONF_DIR jar hadoop-streaming.jar -input UserInput -output Out -mapper ""hadoop --config $HADOOP_CONF_DIR dfs -help"" -reducer NONE""",Open,Unresolved,,Unassigned,Ramya Sunil,Fri; 23 Sep 2011 19:53:01 +0000,Tue; 14 May 2013 05:14:42 +0000,,,0.20.205.0,,MAPREDUCE-3112,,https://issues.apache.org/jira/browse/MAPREDUCE-3080
MAPREDUCE-3081,Bug,Major,contrib/vaidya,Change the name format for hadoop core and vaidya jar to be hadoop-{core/vaidya}-{version}.jar in vaidya.sh,Vaidya script is broken due to change in the naming convention for hadoop core jar and vaidya jar.,Closed,Fixed,,Unassigned,vitthal (Suhas) Gogate,Fri; 23 Sep 2011 21:09:25 +0000,Wed; 19 Oct 2011 00:26:05 +0000,Tue; 27 Sep 2011 19:45:20 +0000,,0.20.1;0.20.205.0;1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3081
MAPREDUCE-3082,Bug,Major,harchive,archive command take wrong path for input file with current directory,$hadoop dfs -copyFromLocal  passwd,Closed,Fixed,,John George,Rajit Saha,Sat; 24 Sep 2011 00:01:26 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Wed; 4 Apr 2012 15:31:43 +0000,,0.20.204.1;0.23.2;0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3082
MAPREDUCE-3083,Bug,Major,distributed-cache;mrv2,Distributed Cache Handling of public directories with private files,0.23 distributed cache fails to localize with public directory containing private files. 0.20 handles this a private directory. (seems to handles all directories as private),Open,Unresolved,,Siddharth Seth,Siddharth Seth,Sat; 24 Sep 2011 01:04:05 +0000,Wed; 22 Aug 2012 21:46:34 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3083
MAPREDUCE-3084,Bug,Blocker,mrv2,race when KILL_CONTAINER is received for a LOCALIZED container,Depending on when ContainersLaunch starts a container; KILL_CONTAINER when container state is LOCALIZED (LAUNCH_CONTAINER event already sent) can end up generating a CONTAINER_LAUNCHED event - which isn't handled by ContainerState: KILLING. Also; the launched container won't be killed since CLEANUP_CONTAINER would have already been processed.,Closed,Duplicate,MAPREDUCE-3240,Hitesh Shah,Siddharth Seth,Sat; 24 Sep 2011 01:14:28 +0000,Thu; 2 May 2013 02:29:45 +0000,Tue; 25 Oct 2011 01:43:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3084
MAPREDUCE-3085,Bug,Major,mrv2,Fix / remove failing tests from MrV1,30 failures. Most related to    https: #showFailuresLink  Tests like TestTaskTrackerBlackListing; which aren't relevant can probably be removed.,Resolved,Duplicate,MAPREDUCE-3064,Unassigned,Siddharth Seth,Sat; 24 Sep 2011 01:30:14 +0000,Tue; 10 Mar 2015 04:32:22 +0000,Sat; 24 Sep 2011 15:16:22 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3085
MAPREDUCE-3086,Improvement,Major,,Supporting range scan using TFile; TotalOrderPartitioner and partition index,Hive search indexed data directory,Open,Unresolved,,Binglin Chang,Binglin Chang,Sun; 25 Sep 2011 08:17:58 +0000,Fri; 6 Feb 2015 23:19:48 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3086
MAPREDUCE-3087,Bug,Critical,mrv2,CLASSPATH not the same after MAPREDUCE-2880,After MAPREDUCE-2880; my classpath was missing key jar files.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Sun; 25 Sep 2011 17:00:07 +0000,Mon; 20 Feb 2012 09:55:25 +0000,Sat; 22 Oct 2011 06:46:51 +0000,,0.23.0,,,MAPREDUCE-3389,https://issues.apache.org/jira/browse/MAPREDUCE-3087
MAPREDUCE-3088,Bug,Major,build,Clover 2.4.3 breaks build for 0.22 branch,Due to known bug in Clover 2.4.3 build for 0.22 branch is broken.,Closed,Fixed,,Konstantin Shvachko,Konstantin Shvachko,Mon; 26 Sep 2011 00:16:47 +0000,Mon; 12 Dec 2011 06:19:10 +0000,Wed; 28 Sep 2011 08:10:28 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3088
MAPREDUCE-3089,Bug,Major,applicationmaster;mrv2,Augment TestRMContainerAllocator to verify MAPREDUCE-2646,nan,Open,Unresolved,,Vinod Kumar Vavilapalli,Arun C Murthy,Mon; 26 Sep 2011 05:29:09 +0000,Mon; 9 Mar 2015 20:26:48 +0000,,,0.23.0,,MAPREDUCE-3078,,https://issues.apache.org/jira/browse/MAPREDUCE-3089
MAPREDUCE-3090,Improvement,Major,applicationmaster;mrv2,Change MR AM to use ApplicationAttemptId rather than <applicationId; startCount> everywhere,Change MR AM to use ApplicationAttemptId rather than applicationId; startCount everywhere; particularly after MAPREDUCE-3055,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 26 Sep 2011 07:11:31 +0000,Tue; 15 Nov 2011 00:48:53 +0000,Mon; 26 Sep 2011 08:46:06 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3090
YARN-3321,Sub-task,Major,nodemanager;resourcemanager,Health-Report column of NodePage should display more information.,The Health-Checker script of the Nodes can run and generate some output; error and exit code. These information is not available in the GUI.   It is possible the Health-Checker script generates some statistics about node. The same can displayed to GUI user. I suggest we display the information in pop-up balloon(using CSS Javascript)?  Any suggestions....,Open,Unresolved,,Unassigned,Subroto Sanyal,Mon; 26 Sep 2011 10:17:10 +0000,Fri; 17 Feb 2017 21:50:47 +0000,,,,javascript,,,https://issues.apache.org/jira/browse/YARN-3321
MAPREDUCE-3092,Bug,Minor,mrv2,Remove JOB_ID_COMPARATOR usage in JobHistory.java,As part of the defect MAPREDUCE-2965; JobId.compareTo() has been implemented. Usage of JOB_ID_COMPARATOR in JobHistory. can be removed because comparison is handling by JobId itself.,Closed,Fixed,,Devaraj K,Devaraj K,Mon; 26 Sep 2011 14:53:27 +0000,Mon; 16 Mar 2015 17:57:16 +0000,Tue; 27 Sep 2011 16:18:26 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3092
YARN-3313,Test,Major,test,Write additional tests for data locality in MRv2.,We should add tests to make sure data locality is in place in MRv2 (with respect to the capacity scheduler and also the matching ask of containers in the MR AM).,Open,Unresolved,,Unassigned,Mahadev konar,Mon; 26 Sep 2011 15:51:41 +0000,Thu; 12 May 2016 18:29:49 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-3313
MAPREDUCE-3094,Bug,Major,contrib/streaming,org.apache.hadoop.streaming.TestUlimit.testCommandLine fails intermittantly in 20.205.0,  INFO mapred.TaskInProgress: Error from  org.apache.hadoop.mapred.Child.main(Child. 255),Resolved,Won't Fix,,Unassigned,Nathan Roberts,Mon; 26 Sep 2011 16:59:26 +0000,Fri; 20 Mar 2015 00:40:54 +0000,Fri; 20 Mar 2015 00:40:54 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3094
MAPREDUCE-3095,Bug,Major,mrv2,fairscheduler ivy including wrong version for hdfs,fairscheduler ivy.xml includes the common version for hdfs dependency. This could break builds that have different common and hdfs version numbers. The reason we dont see it on the jenkins build is because we use the same version number for common and hdfs.,Closed,Fixed,,John George,John George,Mon; 26 Sep 2011 20:24:18 +0000,Tue; 15 Nov 2011 00:48:36 +0000,Tue; 27 Sep 2011 19:51:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3095
MAPREDUCE-3096,Task,Major,,Add a good way to control the number of map/reduce tasks per node,Currently; controlling the number of map reduce tasks is a hell.  I've tried for it many times; and it doesn't work right. Also; I am not the only one person; who seems to have this problem.  There must be a better way to do it.  Here's my proposal:  add following functions to Job: setNumberOfMappersPerNode(int); setNumberOfReducersPerNode(int); setMaxMemoryPerMapper(int); setMaxMemoryPerReducer(int);,Resolved,Won't Fix,,Unassigned,Arsen Zahray,Mon; 26 Sep 2011 20:38:35 +0000,Tue; 27 Sep 2011 07:59:29 +0000,Tue; 27 Sep 2011 07:22:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3096
MAPREDUCE-3097,Bug,Minor,,archive does not archive if the content specified is a file,archive command only archives directories. when the content specified is a file it proceeds with the archive job but does not archive the content this can be misleading as the user might think that archive was successful. We should change it to either throw an error or make it archive files.,Patch Available,Unresolved,,Unassigned,Arpit Gupta,Mon; 26 Sep 2011 20:58:30 +0000,Wed; 6 May 2015 03:27:36 +0000,,,0.20.203.0;0.20.205.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3097
MAPREDUCE-3098,Sub-task,Blocker,mrv2,Report Application status as well as ApplicationMaster status in GetApplicationReportResponse ,Currently; an application report received by the client from the RM failure); FAILED or KILLED.  The final state sent by the AM to the RM in the FinishApplicationMasterRequest should be exposed to the client as ApplicationState.,Closed,Fixed,MAPREDUCE-2892,Hitesh Shah,Hitesh Shah,Mon; 26 Sep 2011 22:09:36 +0000,Tue; 15 Nov 2011 00:49:34 +0000,Fri; 30 Sep 2011 12:55:14 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3098
MAPREDUCE-3099,Sub-task,Major,,Add docs for setting up a single node MRv2 cluster.,nan,Closed,Fixed,,Mahadev konar,Mahadev konar,Tue; 27 Sep 2011 04:19:58 +0000,Tue; 15 Nov 2011 00:49:24 +0000,Tue; 27 Sep 2011 20:44:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3099
MAPREDUCE-3100,Bug,Major,distcp,distcp with an hftp destination url fails if the destination directory does not exist,bash-3.2$ bin output_path does not exist. With failures; global counters are inaccurate; consider running with -i Copy failed:  908)   The same command works if instead of hftp default filesystem (hdfs) is used. It creates the dir if it does not exist. We should do the same for hftp. I also suspect that we have this issue with webhdfs.,Resolved,Invalid,,Unassigned,Arpit Gupta,Tue; 27 Sep 2011 04:42:44 +0000,Tue; 27 Sep 2011 05:34:56 +0000,Tue; 27 Sep 2011 05:34:56 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3100
MAPREDUCE-3101,Bug,Major,security,[Umbrella] Security issues in YARN,Most of the chassis for security in YARN is set up and is working. There are known bugs and security holes though. This JIRA is an umbrella ticket for tracking those.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Tue; 27 Sep 2011 05:15:53 +0000,Fri; 8 May 2015 18:17:06 +0000,Fri; 8 May 2015 18:17:06 +0000,,0.23.0,,,BIGTOP-418;YARN-47,https://issues.apache.org/jira/browse/MAPREDUCE-3101
MAPREDUCE-3102,Sub-task,Major,mrv2;security,NodeManager should fail fast with wrong configuration or permissions for LinuxContainerExecutor,nan,Closed,Fixed,,Hitesh Shah,Vinod Kumar Vavilapalli,Tue; 27 Sep 2011 05:27:13 +0000,Mon; 5 Mar 2012 02:49:37 +0000,Tue; 15 Nov 2011 10:33:04 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3102
MAPREDUCE-3103,Sub-task,Blocker,mrv2;security,Implement Job ACLs for MRAppMaster,nan,Closed,Fixed,,Mahadev konar,Vinod Kumar Vavilapalli,Tue; 27 Sep 2011 05:53:32 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Tue; 1 Nov 2011 01:54:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3103
MAPREDUCE-3104,Sub-task,Blocker,mrv2;resourcemanager;security,Implement Application ACLs; Queue ACLs and their interaction,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 27 Sep 2011 05:55:25 +0000,Tue; 15 Nov 2011 00:49:01 +0000,Thu; 20 Oct 2011 12:02:55 +0000,,0.23.0,,MAPREDUCE-3175,,https://issues.apache.org/jira/browse/MAPREDUCE-3104
MAPREDUCE-3105,Sub-task,Major,security,NM<->RM shared secrets should be rolled every so often. ,nan,Resolved,Duplicate,YARN-39,Unassigned,Vinod Kumar Vavilapalli,Tue; 27 Sep 2011 06:30:28 +0000,Thu; 8 Mar 2012 22:16:24 +0000,Thu; 8 Mar 2012 22:16:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3105
MAPREDUCE-3106,Bug,Blocker,,"Replacing Mapper with MultithreadedMapper causes the job to crash with ""Type mismatch in key from map"" ","I have a hadoop job; which works perfectly fine when done with a class implementing Mapper. When I do replace Mapper with MultithreadMapper; the job crashes with following message:   264)  Here are the relevant source codes:  public class MapReduceMain {  	  	public static void main(String[] args) { 		try { 			if (args.length != 2)  { 				System.err.println(""Usage: MapReduceMain input path output path""); 				System.exit(123); 			} 			Job job = new Job(); 			job.setJarByClass(MapReduceMain.class); 			job.setInputFormatClass(TextInputFormat.class); 			FileSystem fs = FileSystem.get(URI.create(args0); job.getConfiguration()); 			FileStatus[] files = fs.listStatus(new Path(args0)); 			for(FileStatus sfs:files) { 				FileInputFormat.addInputPath(job; sfs.getPath()); 			} 			FileOutputFormat.setOutputPath(job; new Path(args1));    			job.setMapperClass(MyMultithreadMapper.class); 			job.setReducerClass(MyReducer.class); 			MultithreadedMapper.setNumberOfThreads(job; MyMultithreadMapper.nThreads);  			job.setOutputKeyClass(IntWritable.class);  			job.setOutputValueClass(MyPage.class);  			job.setOutputFormatClass(SequenceFileOutputFormat.class);  			System.exit(job.waitForCompletion(true) ? 0 : 1); 		} catch (Exception e)  { 			e.printStackTrace(); 		}  	}   public class MyMultithreadMapper extends MultithreadedMapperLongWritable; Text; IntWritable; MyPage {  	ConcurrentLinkedQueueMyScraper	scrapers	= new ConcurrentLinkedQueueMyScraper();  	public static final int				nThreads	= 5;  	public VrboMultithreadMapper() { 		for (int i = 0; i  nThreads; i++)  { 			scrapers.add(new MyScraper()); 		} 	}  	public void map(LongWritable key; Text value; Context context) throws IOException; InterruptedException { 		MyScraper scraper = scrapers.poll();  		MyPage result = null; 		for (int i = 0; i  10; i++) { 			try  { 				result = scraper.scrapPage(value.toString(); true); 				break; 			}  catch (Exception e)  { 				e.printStackTrace(); 			} 		}  		if (result == null) { 			result = new MyPage(); 			result.setUrl(key.toString()); 		}  		context.write(new IntWritable(result.getUrl().hashCode()); result);  		scrapers.add(scraper); 	} }   and here's the code for the working mapper class; just to be sure:  public class MyMapper extends MapperLongWritable; Text; IntWritable;MyPage { 	MyScraper scr = new MyScraper(); 	 	public void map(LongWritable key; Text value; Context context) throws IOException; InterruptedException { 		MyPage result =null; 		for(int i=0;i10;i++){ 			try{ 				result = scr.scrapPage(value.toString(); true); 				break; 			}catch(Exception e){				e.printStackTrace();			} 		}  		if(result==null) { 			result = new MyPage(); 			result.setUrl(key.toString()); 		}  		context.write(new IntWritable(result.getUrl().hashCode());result); 	} }   This appears to be a hadoop bug",Resolved,Won't Fix,,Unassigned,Arsen Zahray,Tue; 27 Sep 2011 07:28:48 +0000,Wed; 28 Sep 2011 10:12:00 +0000,Wed; 28 Sep 2011 10:12:00 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3106
MAPREDUCE-3107,Bug,Blocker,benchmarks;mrv2,DFSIO tests are failing intermittently,"Intermittently DFSIO tests are failing either in ""read"" or ""write"" operations.  $HADOOP_COMMON_HOME hadoop-mapreduce-test*.jar TestDFSIO  -read -nrFiles 36 -fileSize 320     INFO mapreduce.Job: Counters: 44 	File System Counters 		FILE: BYTES_READ=20931 		FILE: BYTES_WRITTEN=2192966 		FILE: READ_OPS=0 		FILE: LARGE_READ_OPS=0 		FILE: WRITE_OPS=0 		HDFS: BYTES_READ=10454250228 		HDFS: BYTES_WRITTEN=0 		HDFS: READ_OPS=172 		HDFS: LARGE_READ_OPS=0 		HDFS: WRITE_OPS=0 	org.apache.hadoop.mapreduce.JobCounter 		NUM_FAILED_MAPS=6 		TOTAL_LAUNCHED_MAPS=44 		TOTAL_LAUNCHED_REDUCES=1 		DATA_LOCAL_MAPS=10 		RACK_LOCAL_MAPS=34 		SLOTS_MILLIS_MAPS=2340307 	org.apache.hadoop.mapreduce.TaskCounter 		MAP_INPUT_RECORDS=36 		MAP_OUTPUT_RECORDS=140 		MAP_OUTPUT_BYTES=2103 		MAP_OUTPUT_MATERIALIZED_BYTES=2579 		SPLIT_RAW_BYTES=5210 		COMBINE_INPUT_RECORDS=0 		COMBINE_OUTPUT_RECORDS=0 		REDUCE_INPUT_GROUPS=0 		REDUCE_SHUFFLE_BYTES=3054 		REDUCE_INPUT_RECORDS=0 		REDUCE_OUTPUT_RECORDS=0 		SPILLED_RECORDS=140 		SHUFFLED_MAPS=33 		FAILED_SHUFFLE=0 		MERGED_MAP_OUTPUTS=0 		GC_TIME_MILLIS=59933 		CPU_MILLISECONDS=159470 		PHYSICAL_MEMORY_BYTES=11310596096 		VIRTUAL_MEMORY_BYTES=31425290240 		COMMITTED_HEAP_BYTES=12728664064 	Shuffle Errors 		BAD_ID=0 		CONNECTION=0 		IO_ERROR=0 		WRONG_LENGTH=0 		WRONG_MAP=0 		WRONG_REDUCE=0 	org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter 		BYTES_READ=4058 	org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter 		BYTES_WRITTEN=0  189)",Closed,Cannot Reproduce,,John George,Rajit Saha,Tue; 27 Sep 2011 08:10:53 +0000,Tue; 15 Nov 2011 00:49:08 +0000,Fri; 14 Oct 2011 19:50:03 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3107
MAPREDUCE-3108,Bug,Minor,examples,JobTrackerClientProtocolProvider failing to build,The variable CLASSIC_FRAMEWORK_NAME can't be found while compiling TrackerClientProtocolProvider. for mapreduce-examples tarball.But i found the symbol CLASSIC_FRAMEWORK_NAME is already defined in the interface org.apache.hadoop.mapreduce.MRConfig.,Open,Unresolved,,XieXianshan,XieXianshan,Tue; 27 Sep 2011 09:44:02 +0000,Tue; 27 Sep 2011 09:44:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3108
MAPREDUCE-3109,Bug,Major,mrv2,NPE exception in the TestClass org.apache.hadoop.yarn.server.resourcemanager.Application,Method ListContainer org.apache.hadoop.yarn.server.resourcemanager.Application.getResources() throws IOException throws NPE.   This is causing TestCases to fail like: void org.apache.hadoop.yarn.server.resourcemanager.TestResourceManager.testContainerStatusesWillBeStoredInResourceManager() throws Exception with following trace:     Devraj;  Can you please take a look into it.,Closed,Cannot Reproduce,,Devaraj K,Subroto Sanyal,Tue; 27 Sep 2011 12:53:57 +0000,Tue; 15 Nov 2011 00:48:41 +0000,Mon; 31 Oct 2011 04:41:52 +0000,,0.23.0,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3109
MAPREDUCE-3110,Bug,Major,mrv2;test,TestRPC.testUnknownCall() is failing,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Devaraj K,Tue; 27 Sep 2011 13:15:44 +0000,Tue; 15 Nov 2011 00:50:04 +0000,Wed; 28 Sep 2011 06:07:33 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3110
MAPREDUCE-3111,Sub-task,Major,security,Fix log serving in NodeManager,Just noticed that the current log serving is using the raw writer (instead of Hamlet) to serve logs without escaping html.  It's actually easier cleaner to use Hamlet to serve logs:    which takes care of content escaping automatically.  I will make raw writer access package private for framework use only.,Resolved,Duplicate,MAPREDUCE-4283,Omkar Vinit Joshi,Luke Lu,Tue; 27 Sep 2011 13:29:28 +0000,Mon; 21 Apr 2014 18:25:25 +0000,Mon; 21 Apr 2014 18:17:59 +0000,,0.23.0,security;webapp,,,https://issues.apache.org/jira/browse/MAPREDUCE-3111
MAPREDUCE-3112,Bug,Major,contrib/streaming,Calling hadoop cli inside mapreduce job leads to errors,When running a streaming job with mapper  bin hadoop script will attempt to use hadoop.root.logger=INFO;TLA; but fail to initialize.,Closed,Fixed,,Eric Yang,Eric Yang,Wed; 28 Sep 2011 05:42:18 +0000,Wed; 19 Oct 2011 00:26:09 +0000,Tue; 4 Oct 2011 00:52:42 +0000,,0.20.205.0;0.23.0,,MAPREDUCE-3080,,https://issues.apache.org/jira/browse/MAPREDUCE-3112
MAPREDUCE-3113,Improvement,Minor,mrv2,the scripts yarn-daemon.sh and yarn are not working properly,When we execute them on any path but $YARN_HOME with bash -x option;it is giving the error as follows: (Of course we should set the path variable of that scritps into the .bashrc or profile in advance),Closed,Fixed,,XieXianshan,XieXianshan,Wed; 28 Sep 2011 11:14:23 +0000,Tue; 10 Mar 2015 04:32:31 +0000,Sat; 1 Oct 2011 00:01:17 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3113
MAPREDUCE-3114,Bug,Major,mrv2,Invalid ApplicationMaster URL in Applications Page,When the Application is in Accepted state and user tries to click the ApplicationMaster URL in Applications Page; it ends up in Invalid HTTP URL.  The screenshot attached with this Issue makes it more clear.  The HTTP url formed is: http: A,Closed,Fixed,,Subroto Sanyal,Subroto Sanyal,Wed; 28 Sep 2011 13:25:48 +0000,Tue; 15 Nov 2011 00:48:48 +0000,Thu; 29 Sep 2011 07:33:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3114
MAPREDUCE-3115,Bug,Major,mrv1,"OOM When the value for the property ""mapred.map.multithreadedrunner.class"" is set to MultithreadedMapper instance.",When we set the value for the property mapred.map.multithreadedrunner.class as instance of MultithreadedMapper; using MultithreadedMapper.setMapperClass(); it simply throws IllegalArgumentException. But when we set the same property; using job's conf object using job.getConfiguration().setClass(mapred.map.multithreadedrunner.class; MultithreadedMapper.class; Mapper.class); throws OOM.,Patch Available,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Wed; 28 Sep 2011 13:52:08 +0000,Wed; 6 May 2015 03:34:24 +0000,,,0.23.0;1.0.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3115
MAPREDUCE-3116,Bug,Critical,nodemanager;resourcemanager,RM and NM fail to start (webapps/cluster is missing),"When I try to start the RM; I get:  2011-09-28 10:03:42;848 FATAL resourcemanager.ResourceManager (ResourceManager. 144) 	... 4 more  I poked around a bit. When I jar -tvf my hadoop-yarn-common-0.24.0-SNAPSHOT.jar file; I see that it has:       0 Mon Sep 19 09:41:18 PDT 2011 webapps .keep path; which appears to be required by RM (as it specifies ""cluster"" as the webapp name when it starts).  I think that we need to get ""cluster"" and whatever NM's webapp name is back into the webapps directory in the jar.",Resolved,Not A Problem,,Unassigned,Chris Riccomini,Wed; 28 Sep 2011 17:10:30 +0000,Tue; 17 Mar 2015 04:02:28 +0000,Wed; 28 Sep 2011 17:40:50 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3116
MAPREDUCE-3117,Bug,Blocker,mrv2,Uber jobs are hanging,Ran a simple wordcount with uber jobs enabled and job hangs  hadoop jar hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar wordcount -Dmapreduce.job.ubertask.enable=true path to small file output dir  container syslog is filled with repeating 2011-09-28 16:55:04;157 INFO org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents request from attempt_1317246458306_0002_r_000000_0. fromEventID 0 maxEvents 10000 2011-09-28 16:55:04;157 DEBUG org.apache.hadoop.mapreduce.task.reduce.EventFetcher: Got 0 map completion events from 0 2011-09-28 16:55:04;157 DEBUG org.apache.hadoop.mapreduce.task.reduce.EventFetcher: GetMapEventsThread about to sleep for 1000,Resolved,Not A Problem,,Hitesh Shah,Jonathan Eagles,Wed; 28 Sep 2011 21:56:10 +0000,Thu; 17 Nov 2011 00:46:01 +0000,Thu; 17 Nov 2011 00:46:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3117
MAPREDUCE-3118,New Feature,Major,contrib/gridmix;tools/rumen,Backport Gridmix and Rumen features from trunk to Hadoop 0.20 security branch,Backporting all the features and bugfixes that went into gridmix and rumen of trunk to hadoop 0.20 security branch. This will enable using all these gridmix features and run gridmix rumen on the history logs of 0.20 security branch.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Thu; 29 Sep 2011 05:51:07 +0000,Wed; 17 Oct 2012 18:27:25 +0000,Tue; 18 Oct 2011 14:48:48 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3118
MAPREDUCE-3119,Bug,Minor,client;mrv1,All the job states are not displayed in the CLI,When submit a command list to list all the jobs; it is showing only Running; Succeded; Failed and Prep states only. Killed state has not been displayed in CLI.,Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Thu; 29 Sep 2011 06:25:35 +0000,Thu; 29 Sep 2011 06:27:39 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3119
MAPREDUCE-3120,Bug,Major,mrv2,JobHistory is not providing correct count failed;killed task,Please refer the attachment JobFail.PNG. Here the Job (WordCount) Failed as all Map Attempts were killed(intensionally) but; still the Table in UI shows 0 Killed Attempts and no reason for Failure is also available.,Resolved,Fixed,MAPREDUCE-3032,Subroto Sanyal,Subroto Sanyal,Thu; 29 Sep 2011 11:17:32 +0000,Mon; 16 Mar 2015 20:08:07 +0000,Fri; 11 Apr 2014 16:28:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3120
MAPREDUCE-3121,Bug,Blocker,mrv2;nodemanager,DFIP aka 'NodeManager should handle Disk-Failures In Place',This is akin to MAPREDUCE-2413 but for YARN's NodeManager. We want to minimize the impact of transient permanent disk failures on containers. With larger number of disks per node; the ability to continue to run containers on other disks is crucial.,Closed,Fixed,,Ravi Gummadi,Vinod Kumar Vavilapalli,Thu; 29 Sep 2011 14:34:12 +0000,Mon; 5 Mar 2012 02:49:18 +0000,Tue; 29 Nov 2011 23:28:55 +0000,,0.23.0,,,MAPREDUCE-3473,https://issues.apache.org/jira/browse/MAPREDUCE-3121
MAPREDUCE-3122,Bug,Major,contrib/streaming,#NAME?,When libjars option is used with streaming; the symlink to the jar file is not created in the working dir of the task. Any map HelloWorld.jar HelloWorld Hello World,Open,Unresolved,,Unassigned,Ramya Sunil,Thu; 29 Sep 2011 17:05:49 +0000,Fri; 30 Sep 2011 10:48:41 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3122
MAPREDUCE-3123,Bug,Blocker,mrv2,Symbolic links with special chars causing container/task.sh to fail,the following job throws an exception when you have the special characters in it.  hadoop jar hadoop-streaming.jar -Dmapreduce.job.acl-view-job=* -Dmapreduce.job.queuename=queue1 -files file: jackson-xc-1.7.1.jar:         619) 2011-09-27 20:58:48;951 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor: 2011-09-27 20:58:48;951 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Processing container_1317077272567_0239_01_000001 of type UPDATE_DIAGNOSTICS_MSG 2011-09-27 20:58:48;951 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container exited with a non-zero exit code 2,Closed,Fixed,,Hitesh Shah,Thomas Graves,Thu; 29 Sep 2011 19:03:45 +0000,Tue; 15 Nov 2011 00:49:14 +0000,Mon; 10 Oct 2011 03:27:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3123
MAPREDUCE-3124,Bug,Blocker,mrv2,mapper failed with failed to load native libs,hadoop jar hadoop-mapreduce-examples-*.jar sort -Dmapreduce.job.acl-view -job=* -Dmapreduce.map.output.compress=true  -Dmapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec  -Dmapreduce.output.fileoutputformat.compress=true  -Dmapreduce.output.fileoutputformat.compression.type=NONE -Dmap reduce.output.fileoutputformat.compression.codec=org.apache.hadoop.io.compress.GzipCodec  -outKey org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text  Compression textoutput-1317315994  This will fail with native libs not found error unless -Dmapred.child. classes where applicable   Also note that the error that shows up at the application master for this is terrible:  Container killed by the ApplicationMaster. Container killed on request. Exit code is 137 Too Many fetch failures.Failing the attempt,Closed,Fixed,,John George,Thomas Graves,Thu; 29 Sep 2011 22:13:44 +0000,Tue; 10 Mar 2015 04:31:51 +0000,Fri; 14 Oct 2011 01:28:14 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3124
MAPREDUCE-3125,Bug,Critical,mrv2,app master web UI shows reduce task progress 100% even though reducers not complete and state running/scheduled,ran same command as MAPREDUCE-3124. The app master web ui was displaying the reduce task progress as 100% even though the states were still running scheduled.  Each of those reduce tasks had attempts that failed or killed and another one unassigned. Attaching screenshots.,Closed,Fixed,,Hitesh Shah,Thomas Graves,Thu; 29 Sep 2011 22:29:32 +0000,Tue; 15 Nov 2011 00:50:08 +0000,Wed; 12 Oct 2011 06:53:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3125
MAPREDUCE-3126,Bug,Blocker,mrv2,mr job stuck because reducers using all slots and mapper isn't scheduled,The command in MAPREDUCE-3124 run and this job got hung with 1 Map task waiting for resources and 7 Reducers running (2 waiting).  The mapper got scheduler; then AM scheduled the reducers; the map task failed and tried to start a new attempt but reducers were using all the slots.     I will try to add some more info from the logs.,Closed,Fixed,,Arun C Murthy,Thomas Graves,Thu; 29 Sep 2011 22:52:40 +0000,Tue; 15 Nov 2011 00:48:32 +0000,Tue; 11 Oct 2011 18:25:30 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3126
MAPREDUCE-3127,Sub-task,Blocker,mrv2;resourcemanager,Unable to restrict users based on resourcemanager.admin.acls value set,Setting the following property in yarn-site.xml with user ids to restrict ability to run 'rmadmin -refreshQueues is not honoured  property nameyarn.server.resourcemanager.admin.acls property  Should it be the same for rmadmin -refreshNodes?,Closed,Fixed,,Arun C Murthy,Amol Kekre,Fri; 30 Sep 2011 09:12:58 +0000,Tue; 15 Nov 2011 00:48:33 +0000,Mon; 17 Oct 2011 04:09:50 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3127
HADOOP-7703,Bug,Major,,WebAppContext should also be stopped and cleared,1. If listener stop method throws any exception then the webserver stop method will not be called     2. also; WebAppContext stores all the context attributes; which does not get cleared if only webServer is stopped. so following calls are necessary to ensure clean and complete stop.    3. Also the WebAppContext display name can be the name passed to HttpServer instance.    instead of,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 30 Sep 2011 10:50:49 +0000,Thu; 11 Oct 2012 17:45:05 +0000,Wed; 5 Oct 2011 16:10:41 +0000,,0.24.0,,,,https://issues.apache.org/jira/browse/HADOOP-7703
HADOOP-7704,Bug,Minor,,JsonFactory can be created only once and used for every next request to create JsonGenerator inside JMXJsonServlet ,1. Currently JMXJsonServlet creates JsonFactory for every http request. Its not efficient.  JsonFactory can be created only once and used for every next request to create JsonGenerator.  2. Also following null check is not required.    Because ManagementFactory.getPlatformMBeanServer(); will not return null.  3. Move the following code to finally so that any exception should not cause skipping of close method on JsonGenerator,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 30 Sep 2011 10:53:24 +0000,Mon; 28 Sep 2015 20:58:33 +0000,Wed; 5 Oct 2011 16:11:23 +0000,,0.24.0,,,,https://issues.apache.org/jira/browse/HADOOP-7704
MAPREDUCE-3130,Bug,Major,task,Output files are not moved to job output directory after task completion,When MultipleOutputs (OutputFormat set to TextOutputFormat) is used to write output files to different namedOutputFiles; turned off normal output file generation(i.e.part-r-#reduce) by setting OutputFormat as NullOutputFormat; task output is not moved to job output directory (${mapred.output.dir}).  After the job completion; found output files in ${mapred.output.dir} _attempt-jobid-#reduce (task output directory) rather than in the ${mapred.output.dir} (job output dir),Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Fri; 30 Sep 2011 13:57:53 +0000,Mon; 28 May 2012 05:40:50 +0000,,,0.20.204.0,,,MAPREDUCE-2493,https://issues.apache.org/jira/browse/MAPREDUCE-3130
MAPREDUCE-3131,Improvement,Trivial,documentation;mrv2;scripts,Docs and Scripts for setting up single node MRV2 cluster. ,Scripts to run a single node cluster with a default configuration. Takes care of running all the daemons including hdfs and yarn.,Open,Unresolved,,Unassigned,Prashant Sharma,Fri; 30 Sep 2011 16:20:24 +0000,Thu; 12 May 2016 18:24:21 +0000,,,3.0.0-alpha1,documentation;hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3131
MAPREDUCE-3133,Improvement,Major,build,Running a set of methods in a Single Test Class,Instead of running every test method in a class; limit to specific testing methods as describe in the link below.  http: single-test.html  Upgrade to the latest version of maven-surefire-plugin that has this feature.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 30 Sep 2011 19:45:11 +0000,Tue; 15 Nov 2011 00:50:01 +0000,Thu; 13 Oct 2011 07:09:18 +0000,,0.23.0,,,HADOOP-7709;HDFS-2401,https://issues.apache.org/jira/browse/MAPREDUCE-3133
MAPREDUCE-3134,Sub-task,Blocker,documentation;mrv2;scheduler,Add documentation for CapacityScheduler,Add documentation for CapacityScheduler in MRv2 similar to http: capacity_scheduler.html.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 3 Oct 2011 00:41:16 +0000,Tue; 15 Nov 2011 00:50:05 +0000,Mon; 3 Oct 2011 19:36:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3134
MAPREDUCE-3135,Bug,Major,,Unit test org.apache.hadoop.mapred.TestJobHistoryServer fails intermittently,Every once in a while org.apache.hadoop.mapred.TestJobHistoryServer fails due to a timeout.,Resolved,Duplicate,MAPREDUCE-4798,Unassigned,Ravi Prakash,Mon; 3 Oct 2011 01:03:28 +0000,Wed; 5 Jun 2013 22:27:47 +0000,Wed; 5 Jun 2013 22:27:47 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3135
MAPREDUCE-3136,Sub-task,Blocker,documentation;mrv2,Add docs for setting up real-world MRv2 clusters,Add docs for setting up real-world MRv2 clusters - MR portion of http: cluster_setup.html,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 3 Oct 2011 06:33:07 +0000,Tue; 15 Nov 2011 00:48:31 +0000,Mon; 17 Oct 2011 02:19:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3136
MAPREDUCE-3137,Sub-task,Trivial,mrv2,Fix broken merge of MR-2719 to 0.23 branch for the distributed shell test case ,nan,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Mon; 3 Oct 2011 18:01:14 +0000,Tue; 15 Nov 2011 00:48:32 +0000,Mon; 3 Oct 2011 19:26:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3137
MAPREDUCE-3138,Bug,Blocker,client;mrv2,Allow for applications to deal with MAPREDUCE-954,MAPREDUCE-954 changed the context-objs api to interfaces. This breaks Pig. We need a bridge for them to move to 0.23.,Closed,Fixed,,Owen O'Malley,Arun C Murthy,Mon; 3 Oct 2011 23:29:55 +0000,Tue; 15 Nov 2011 00:49:16 +0000,Tue; 4 Oct 2011 00:43:39 +0000,,0.23.0,,PIG-2125,,https://issues.apache.org/jira/browse/MAPREDUCE-3138
MAPREDUCE-3139,Bug,Major,test,SlivePartitioner generates negative partitions,SlivePartitioner.getPartition() returns negative partition numbers on some occasions; which is illegal.,Closed,Fixed,,Jakob Homan,Konstantin Shvachko,Tue; 4 Oct 2011 01:41:19 +0000,Wed; 8 Feb 2012 02:49:08 +0000,Wed; 2 Nov 2011 19:57:43 +0000,,0.22.0,,,HDFS-2398,https://issues.apache.org/jira/browse/MAPREDUCE-3139
MAPREDUCE-3140,Bug,Major,mrv2,Invalid JobHistory URL for failed applications,After completion of the applications execution (application has failed though); to verify the job history; I clicked on the JobHistory hyper-link displayed as part of the application details.In this case; it is displaying http: A.,Closed,Fixed,,Subroto Sanyal,Bhallamudi Venkata Siva Kamesh,Tue; 4 Oct 2011 12:01:19 +0000,Tue; 15 Nov 2011 00:49:10 +0000,Wed; 12 Oct 2011 06:25:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3140
MAPREDUCE-3141,Sub-task,Blocker,applicationmaster;mrv2;security,Yarn+MR secure mode is broken; uncovered after MAPREDUCE-3056,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 4 Oct 2011 14:00:02 +0000,Tue; 15 Nov 2011 00:49:17 +0000,Fri; 7 Oct 2011 11:36:52 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3141
MAPREDUCE-3142,Bug,Major,test,smart-apply-patch.sh fails with errors,smart-apply-patch.sh fails with the following error,Resolved,Cannot Reproduce,,Unassigned,Amar Kamat,Wed; 5 Oct 2011 05:28:16 +0000,Tue; 10 Mar 2015 01:57:27 +0000,Tue; 10 Mar 2015 01:57:26 +0000,,,patch;test-patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3142
MAPREDUCE-3143,Bug,Major,mrv2;nodemanager,Complete aggregation of user-logs spit out by containers onto DFS,Already implemented the feature for handling user-logs spit out by containers in NodeManager. But the feature is currently disabled due to user-interface issues.  This is the umbrella ticket for tracking the pending bugs w.r.t putting container-logs on DFS.,Closed,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Wed; 5 Oct 2011 12:30:43 +0000,Sun; 1 Sep 2013 23:28:38 +0000,Wed; 2 Nov 2011 10:05:50 +0000,,0.23.0,,,YARN-85;YARN-432;MAPREDUCE-3738;MAPREDUCE-3977;MAPREDUCE-3398;MAPREDUCE-3298;YARN-431,https://issues.apache.org/jira/browse/MAPREDUCE-3143
MAPREDUCE-3144,Sub-task,Critical,mrv2,Augment JobHistory to include information needed for serving aggregated logs.,nan,Closed,Fixed,MAPREDUCE-2923,Siddharth Seth,Vinod Kumar Vavilapalli,Wed; 5 Oct 2011 13:42:03 +0000,Tue; 15 Nov 2011 00:49:05 +0000,Wed; 19 Oct 2011 05:29:19 +0000,,0.23.0,,MAPREDUCE-2989,,https://issues.apache.org/jira/browse/MAPREDUCE-3144
MAPREDUCE-3145,Sub-task,Major,mrv2;nodemanager,Fix NM UI to serve logs from DFS once application finishes,nan,Closed,Duplicate,MAPREDUCE-2989,Siddharth Seth,Vinod Kumar Vavilapalli,Wed; 5 Oct 2011 13:43:41 +0000,Tue; 15 Nov 2011 00:48:53 +0000,Mon; 17 Oct 2011 17:02:26 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3145
MAPREDUCE-3146,Sub-task,Critical,mrv2;nodemanager,Add a MR specific command line to dump logs for a given TaskAttemptID,nan,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Wed; 5 Oct 2011 13:52:00 +0000,Tue; 15 Nov 2011 00:48:34 +0000,Mon; 31 Oct 2011 06:48:17 +0000,,0.23.0,,MAPREDUCE-2696,,https://issues.apache.org/jira/browse/MAPREDUCE-3146
MAPREDUCE-3147,Improvement,Major,mrv2,Handle leaf queues with the same name properly,If there are two leaf queues with the same name; there is ambiguity while submitting jobs; displaying queue info. When such ambiguity exists; the system should ask for clarification   show disambiguated information.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 5 Oct 2011 18:20:06 +0000,Mon; 5 Mar 2012 02:49:10 +0000,Wed; 7 Dec 2011 00:40:13 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3147
MAPREDUCE-3148,Sub-task,Blocker,mrv2,Port MAPREDUCE-2702 to old mapred api,Port MAPREDUCE-2702 to old mapred api,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 6 Oct 2011 08:27:26 +0000,Tue; 15 Nov 2011 00:48:44 +0000,Tue; 11 Oct 2011 18:30:55 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3148
MAPREDUCE-3149,Bug,Major,test,add a test to verify that buildDTAuthority works for cases with no authority.,Add a test to verify that buildDTAuthority works for cases with no Authority.,Resolved,Fixed,,John George,John George,Thu; 6 Oct 2011 18:24:08 +0000,Fri; 13 May 2016 05:14:09 +0000,Wed; 19 Oct 2011 21:53:33 +0000,,2.0.0-alpha,,HADOOP-7602,,https://issues.apache.org/jira/browse/MAPREDUCE-3149
MAPREDUCE-3150,Improvement,Major,mrv2;task-controller,Allow TT to run children with an elevated oom_adj score,Some users of hadoop have run into issues where memory on the machines gets oversubscribed for various reasons. When this happens; the machines enter swap; causing things like timeouts; HBase aborts; etc. One mitigation strategy among many is to run the machines without swap; and allow the linux OOM killer to kill tasks. However; this is dangerous if the OOM killer might kill the TT; RS; DN; etc. We can set the oom_adj value in proc for the MR children in order to encourage the oom killer to kill the right thing.,Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 6 Oct 2011 22:06:56 +0000,Thu; 6 Oct 2011 22:06:56 +0000,,,0.23.0;1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3150
MAPREDUCE-3151,Bug,Major,contrib/vertica,Contrib tests failing,Jenkins builds fail: https: console,Closed,Fixed,,Joep Rottinghuis,Joep Rottinghuis,Fri; 7 Oct 2011 03:38:38 +0000,Mon; 12 Dec 2011 06:19:08 +0000,Sat; 8 Oct 2011 00:53:27 +0000,,0.22.0,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-3151
YARN-410,Bug,Major,,New lines in diagnostics for a failed app on the per-application page make it hard to read,"We need to fix the following issues on YARN web-UI:  	Remove the ""Note"" column from the application list. When a failure happens; this ""Note"" spoils the table layout. 	When the Application is still not running; the Tracking UI should be title ""UNASSIGNED""; for some reason it is titled ""ApplicationMaster"" but (correctly) links to ""#"". 	The per-application page has all the RM related information like version; start-time etc. Must be some accidental change by one of the patches. 	The diagnostics for a failed app on the per-application page don't retain new lines and wrap'em around - looks hard to read.",Closed,Fixed,,Omkar Vinit Joshi,Vinod Kumar Vavilapalli,Fri; 7 Oct 2011 09:05:34 +0000,Tue; 27 Aug 2013 22:15:46 +0000,Sat; 2 Mar 2013 01:23:45 +0000,,,usability,YARN-414,MAPREDUCE-3185,https://issues.apache.org/jira/browse/YARN-410
MAPREDUCE-3153,Bug,Major,mrv2;test,TestFileOutputCommitter.testFailAbort() is failing on trunk on Jenkins,This mostly is caused by MAPREDUCE-2702.,Closed,Fixed,,Mahadev konar,Vinod Kumar Vavilapalli,Fri; 7 Oct 2011 12:45:20 +0000,Tue; 15 Nov 2011 00:49:42 +0000,Mon; 10 Oct 2011 03:11:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3153
MAPREDUCE-3154,Improvement,Major,client;mrv2,Validate the Jobs Output Specification as the first statement in JobSubmitter.submitJobInternal(Job; Cluster) method,Presently the output specification is validated after getting new JobId from ClientRMService; Copying the job jar; Configuration file; archives etc.  Instead of that move following Job Output specification validation call to the begining of JobSubmitter.submitJobInternal(Job; Cluster) method.     This will avoid unnecessary work in case of invalid output specs.,Closed,Fixed,,Abhijit Suresh Shingate,Abhijit Suresh Shingate,Fri; 7 Oct 2011 17:18:35 +0000,Tue; 10 Mar 2015 04:32:51 +0000,Mon; 10 Oct 2011 03:30:51 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-2384,https://issues.apache.org/jira/browse/MAPREDUCE-3154
YARN-813,Improvement,Major,nodemanager,Document and likewise implement relevant checks/escape functions for what form of input is acceptable for setting up a container launch context i.e. special chars in resource names; env vars and the commands,"What should a user of yarn escape not escape when passing in input for the container launch contexts   	localized resources' names are used to create symlinks. 	Are special chars supported in symlinks or do they need to be escaped? 	Likewise for environment variables and commands.    Current implementation uses a shell script to setup the environment and launch the commands. What should the user be aware of when setting up the launch context? The input also should be such that a user should not need to change code based on what platform or flavor of shell is being used to setup the env and run the commands.",Open,Unresolved,,Unassigned,Hitesh Shah,Fri; 7 Oct 2011 23:29:12 +0000,Wed; 3 Jul 2013 23:04:19 +0000,,,2.0.4-alpha;0.23.8,,,,https://issues.apache.org/jira/browse/YARN-813
MAPREDUCE-3156,Test,Major,test,Allow TestMRCLI to be run against a cluster,Mapreduce part of HDFS-1762,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Sun; 9 Oct 2011 05:34:59 +0000,Mon; 12 Dec 2011 06:18:55 +0000,Wed; 12 Oct 2011 05:11:40 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3156
MAPREDUCE-3157,Bug,Major,tools/rumen,Rumen TraceBuilder is skipping analyzing 0.20 history files,Rumen TraceBuilder is assuming the Pre21 history file name format to be JTIdentifier_jobId_something. But it can be jobId_something also as it is now in latest 0.20.x version. This also needs to be understood by TraceBuilder.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 10 Oct 2011 10:12:51 +0000,Tue; 15 Nov 2011 00:50:09 +0000,Wed; 12 Oct 2011 10:00:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3157
MAPREDUCE-3158,Bug,Major,mrv2,Fix trunk build failures,https: ,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Mon; 10 Oct 2011 18:32:08 +0000,Tue; 15 Nov 2011 00:48:58 +0000,Tue; 11 Oct 2011 00:27:55 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3158
MAPREDUCE-3159,Bug,Blocker,mrv2,DefaultContainerExecutor removes appcache dir on every localization,The DefaultContainerExecutor currently has code that removes the application dir from appcache  in the local directories on every task localization. This causes any concurrent executing tasks from the same job to fail.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 10 Oct 2011 20:08:09 +0000,Tue; 15 Nov 2011 00:49:59 +0000,Tue; 25 Oct 2011 01:12:25 +0000,,0.23.0,,MAPREDUCE-2986,,https://issues.apache.org/jira/browse/MAPREDUCE-3159
MAPREDUCE-3160,Bug,Major,,Merge -r 1177530:1177531 from trunk to branch-0.23 to fix MAPREDUCE-2996 broke ant test compilation,I git bisected and the problem starts from adb810babaf25b9f9dae75b43d4beac782deaa01 . ant,Resolved,Invalid,,Unassigned,Ravi Prakash,Mon; 10 Oct 2011 22:22:46 +0000,Fri; 14 Oct 2011 19:42:34 +0000,Fri; 14 Oct 2011 19:42:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3160
MAPREDUCE-3161,Improvement,Minor,mrv2,Improve javadoc and fix some typos in MR2 code,Just some simple cleanup; documentation; typos in variable names; etc. The only code change is to refactor ResourceLocalizationService so each event type is handled in its own method instead of a giant switch statement (just using eclipse's Extract Method - no semantic change),Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 10 Oct 2011 22:47:08 +0000,Tue; 15 Nov 2011 00:48:45 +0000,Tue; 11 Oct 2011 04:47:49 +0000,,0.23.0,,MAPREDUCE-3162,,https://issues.apache.org/jira/browse/MAPREDUCE-3161
MAPREDUCE-3162,Improvement,Minor,mrv2;nodemanager,Separate application-init and container-init event types in NM's ApplicationImpl FSM,Currently; the ApplicationImpl receives an INIT_APPLICATION event on every container initialization. Only on the first one does it really mean to init the application; whereas all subsequent events are for specific containers. This JIRA is to separate the events into INIT_APPLICATION; sent once and only once per application; and INIT_CONTAINER; which is sent for every container. The first container sends INIT_APPLICATION followed by INIT_CONTAINER.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 10 Oct 2011 22:55:05 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Wed; 19 Oct 2011 06:43:07 +0000,,0.23.0,,MAPREDUCE-3161,,https://issues.apache.org/jira/browse/MAPREDUCE-3162
MAPREDUCE-3163,Bug,Blocker,job submission;mrv2,JobClient spews errors when killing MR2 job,"When I used the ""hadoop job"" command line to kill a running MR2 job; I got a bunch of error spew on the console; despite the kill actually taking effect.",Closed,Fixed,,Mahadev konar,Todd Lipcon,Tue; 11 Oct 2011 03:35:27 +0000,Tue; 15 Nov 2011 00:48:10 +0000,Fri; 21 Oct 2011 18:37:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3163
YARN-1743,New Feature,Major,,Statically generate event diagrams across components,We propose to statically generate the event diagrams across components. This is similar to the generation of diagrams with state transitions within a component that we already do today.  The goal is to be able to visualize the interactions through events across different components.,Open,Unresolved,,Jeff Zhang,Vinod Kumar Vavilapalli,Tue; 11 Oct 2011 05:01:54 +0000,Thu; 27 Oct 2016 19:25:40 +0000,,,,documentation;oct16-hard,,,https://issues.apache.org/jira/browse/YARN-1743
MAPREDUCE-3165,Bug,Blocker,applicationmaster;mrv2,Ensure logging option is set on child command line,Currently the logging config is set in env in MapReduceChildJVM - we need to set it on command line.,Closed,Fixed,,Todd Lipcon,Arun C Murthy,Tue; 11 Oct 2011 05:45:52 +0000,Tue; 15 Nov 2011 00:48:44 +0000,Tue; 18 Oct 2011 21:46:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3165
MAPREDUCE-3166,Bug,Major,tools/rumen,Make Rumen use job history api instead of relying on current history file name format,Rumen should not depend on the regular expression of job history file name format and should use the newly added api like isValidJobHistoryFileName(); getJobIDFromHistoryFilePath().,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Tue; 11 Oct 2011 06:25:52 +0000,Tue; 15 Nov 2011 00:49:58 +0000,Wed; 12 Oct 2011 12:21:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3166
MAPREDUCE-3167,Bug,Minor,mrv2,container-executor is not being packaged with the assembly target.,Looks like MAPREDUCE-2988 broke this. This is a temporary fix until we get a full fledged maven dist tar working. Trivial fix.,Closed,Fixed,,Mahadev konar,Mahadev konar,Tue; 11 Oct 2011 06:33:41 +0000,Tue; 15 Nov 2011 00:50:11 +0000,Tue; 11 Oct 2011 07:02:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3167
MAPREDUCE-3168,Bug,Major,contrib/gridmix,[Gridmix] TestCompressionEmulationUtils fails after MR-3158,TestCompressionEmulationUtils fails after MAPREDUCE-3158 as it uses local job-runner to run jobs.,Resolved,Duplicate,MAPREDUCE-3462,Amar Kamat,Amar Kamat,Tue; 11 Oct 2011 10:55:46 +0000,Tue; 10 Mar 2015 04:32:40 +0000,Tue; 9 Sep 2014 20:27:43 +0000,,2.0.0-alpha,compression-emulation;gridmix;local-job-runner,,MAPREDUCE-3462,https://issues.apache.org/jira/browse/MAPREDUCE-3168
MAPREDUCE-3169,Improvement,Major,mrv1;mrv2;test,Create a new MiniMRCluster equivalent which only provides client APIs cross MR1 and MR2,"Many dependent projects like HBase; Hive; Pig; etc; depend on MiniMRCluster for writing tests. Many users do as well. MiniMRCluster; however; exposes MR implementation details like the existence of TaskTrackers; JobTrackers; etc; since it was used by MR1 for testing the server implementations as well.  This JIRA is to create a new interface which could be implemented either by MR1 or MR2 that exposes only the client-side portions of the MR framework. Ideally it would be ""recompile-compatible"" with MiniMRCluster for most applications; and the MR1 implementation could be backported to 20x branch. Thus; dependent projects like HBase could migrate to this implementation and test against both MR1 and MR2. We can also use this to port over the current functional tests that use only the client-side features of MiniMRCluster.",Closed,Fixed,,Ahmed Radwan,Todd Lipcon,Tue; 11 Oct 2011 18:53:18 +0000,Thu; 2 May 2013 02:29:46 +0000,Thu; 17 Nov 2011 23:21:04 +0000,,0.23.0,,MAPREDUCE-3369;HBASE-4813,,https://issues.apache.org/jira/browse/MAPREDUCE-3169
MAPREDUCE-3170,Bug,Critical,build;mrv1;mrv2,Trunk nightly commit builds are failing.,Looks like the trunk commit builds are failing after MAPREDUCE-3148 and MAPREDUCE-3126  were committed. I suspect its MAPREDUCE-3148.,Closed,Fixed,,Hitesh Shah,Mahadev konar,Wed; 12 Oct 2011 00:55:13 +0000,Tue; 15 Nov 2011 00:48:33 +0000,Fri; 14 Oct 2011 01:19:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3170
MAPREDUCE-3171,Improvement,Major,build,normalize nodemanager native code compilation with common/hdfs native,Use same build pattern as used by common hdfs native,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 12 Oct 2011 01:41:52 +0000,Mon; 16 Mar 2015 17:57:13 +0000,Wed; 12 Oct 2011 20:41:00 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-2747,https://issues.apache.org/jira/browse/MAPREDUCE-3171
YARN-64,Improvement,Major,resourcemanager,Add cluster-level stats availabe via RPCs,MAPREDUCE-2738 already added the stats to the UI. It'll be helpful to add them to YarnClusterMetrics and make them available via the command-line RPC.,Open,Unresolved,,Ravi Teja Ch N V,Vinod Kumar Vavilapalli,Wed; 12 Oct 2011 05:14:01 +0000,Fri; 8 May 2015 07:24:41 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-64
MAPREDUCE-3173,Bug,Critical,mrv2,MRV2 UI doesn't work properly without internet,When we try access the MRV2 UI; it is always giving the below message in the UI even if the  script enabled in the browser.    It is trying to download these below css js files from internet and finally ending up with the above message. For loading the page also it is taking long time.,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 12 Oct 2011 10:21:19 +0000,Thu; 12 May 2016 18:22:35 +0000,Wed; 2 May 2012 14:44:31 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3173
MAPREDUCE-3174,Improvement,Major,mrv2,app master UI goes away when app finishes - not very user friendly,A user can go to the application master UI to see the stats on the app; but as soon as the app finishes that UI goes away and user is left with nothing.  A redirect to history server or similar would be much better.,Open,Unresolved,,Unassigned,Thomas Graves,Wed; 12 Oct 2011 17:51:08 +0000,Sat; 7 Jan 2017 01:59:56 +0000,,,0.23.0,,,MAPREDUCE-2858,https://issues.apache.org/jira/browse/MAPREDUCE-3174
MAPREDUCE-3175,Sub-task,Blocker,mrv2,Yarn httpservers not created with access Control lists,RM; NM; job history; and application master httpservers are not created with access Control lists. I believe this means that anyone can access any of the standard servlets that check to see if the user has administrator access - like  stacks; etc and ops has no way to restrict access to these things.,Closed,Fixed,,Jonathan Eagles,Thomas Graves,Wed; 12 Oct 2011 18:03:08 +0000,Tue; 15 Nov 2011 00:49:30 +0000,Thu; 27 Oct 2011 06:10:40 +0000,,0.23.0,,MAPREDUCE-3104;HADOOP-7764,,https://issues.apache.org/jira/browse/MAPREDUCE-3175
MAPREDUCE-3176,Bug,Blocker,mrv2;test,ant mapreduce tests are timing out,Secondary YARN builds started taking inordinately long and lots of tests started failing. Usually the secondary build would take ~ 2 hours. But recently even after 7 hours it wasn't done.,Closed,Fixed,,Hitesh Shah,Ravi Prakash,Wed; 12 Oct 2011 20:22:43 +0000,Tue; 15 Nov 2011 00:48:52 +0000,Wed; 19 Oct 2011 17:58:57 +0000,,0.23.0,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3176
MAPREDUCE-3177,Bug,Critical,build,mapreduce tar layout does not conform new layout,The tar generated by MR does not follow the layout of common  hdfs; instead; it uses a arbitrary layout which is also different from the old legacy layout (there is a modules  directory with all the MR jars),Resolved,Duplicate,MAPREDUCE-3366,Mahadev konar,Alejandro Abdelnur,Wed; 12 Oct 2011 21:59:19 +0000,Tue; 10 Mar 2015 04:31:44 +0000,Fri; 16 Dec 2011 09:18:13 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3177
MAPREDUCE-3178,Bug,Blocker,mrv2,Capacity Schedular shows incorrect cluster information in the RM logs,When we start the NM; after stopping it (in a quick session) CS shows incorrect information about clusterResource in the logs.  I have encountered this issue in a pseudo cluster mode and steps to reproduce are  1) start the YARN cluster 2) stop a NM and start the NM again (in a quick session)  There should be a NM running in the cluster however as I observed RM detects NM as dead; after default time since its actual unavailability(In this case NM has been stopped).  If you start your NM before this time (default time); ResourceTracker throws IOEx; however; CS adds the NM's capacity to the clusterResource.   After elapsed time (default time) when RM detects NM as dead; RM removes the NM and hence capacity of the cluster will be subtracted by the amount NM capacity.  Eventually there is no NM running in the cluster; but capacity of the cluster is NM's capacity (by default),Resolved,Duplicate,MAPREDUCE-2775,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Thu; 13 Oct 2011 14:26:42 +0000,Mon; 24 Oct 2011 18:35:20 +0000,Mon; 24 Oct 2011 18:35:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3178
MAPREDUCE-3179,Bug,Major,mrv2;test,Incorrect exit code for hadoop-mapreduce-test tests when exception thrown,Exit code for test jar is 0 despite exception thrown  hadoop jar hadoop-mapreduce-test-0.23.0-SNAPSHOT.jar loadgen -Dmapreduce.job.acl-view -m 18 -r 0 -outKey org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text -indir nonexistentdir  Loadgen output snippet org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs: nonexistentdir          org.apache.hadoop.util.RunJar.main(RunJar. 189) -bash-3.2$ echo $? 255,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 13 Oct 2011 16:22:16 +0000,Tue; 10 Mar 2015 04:32:03 +0000,Wed; 19 Oct 2011 22:55:25 +0000,,0.20.205.0;0.23.0;2.0.0-alpha,,,HADOOP-7744;HDFS-2445,https://issues.apache.org/jira/browse/MAPREDUCE-3179
MAPREDUCE-3180,Bug,Trivial,,TaskTracker.java.orig accidentally checked in to 0.20-security-205,The file src TaskTracker. orig was accidentally checked in as part of r1179465.  It is only in 0.20-security-205; not 0.20-security.  If there is a 0.20.205.1; remove it then.,Closed,Fixed,,Matt Foley,Matt Foley,Thu; 13 Oct 2011 21:12:12 +0000,Mon; 28 Nov 2011 09:17:55 +0000,Thu; 10 Nov 2011 02:00:56 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3180
MAPREDUCE-3181,Bug,Blocker,mrv2,Terasort fails with Kerberos exception on secure cluster,We are seeing the following Kerberos exception upon trying to run terasort on secure single and multi-node clusters using the latest build from branch 0.23.   189)  Adding debug output shows that the job configuration is not loading up yarn-site.xml causing the above failure to happen.,Closed,Fixed,,Arun C Murthy,Anupam Seth,Thu; 13 Oct 2011 21:16:35 +0000,Tue; 15 Nov 2011 00:48:39 +0000,Wed; 19 Oct 2011 20:29:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3181
MAPREDUCE-3182,Bug,Minor,documentation;mrv2;test,loadgen ignores -m command line when writing random data,If no input directories are specified; loadgen goes into a special mode where random data is generated and written. In that mode; setting the number of mappers (-m command line option) is overridden by a calculation. Instead; it should take into consideration the user specified number of mappers and fall back to the calculation. In addition; update the documentation as well to match the new behavior in the code.,Open,Unresolved,,Chen He,Jonathan Eagles,Thu; 13 Oct 2011 21:55:25 +0000,Sat; 7 Jan 2017 01:59:50 +0000,,,0.23.0;2.3.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3182
MAPREDUCE-3183,Bug,Trivial,build,hadoop-assemblies/src/main/resources/assemblies/hadoop-mapreduce-dist.xml missing license header,Re-assigning as this is part of the mavenization related changes and requires a delayed merge to the 23 branch.,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Thu; 13 Oct 2011 22:28:52 +0000,Mon; 16 Mar 2015 17:57:15 +0000,Thu; 13 Oct 2011 23:17:10 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3183
MAPREDUCE-3184,Improvement,Major,jobtracker,Improve handling of fetch failures when a tasktracker is not responding on HTTP,"On a 100 node cluster; we had an issue where one of the TaskTrackers was hit by MAPREDUCE-2386 and stopped responding to fetches. The behavior observed was the following:  	every reducer would try to fetch the same map task; and fail after ~13 minutes. 	At th TT should be re-run.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 14 Oct 2011 00:01:06 +0000,Tue; 11 Mar 2014 17:34:43 +0000,Thu; 27 Oct 2011 03:53:36 +0000,,0.20.205.0,,,MAPREDUCE-5588,https://issues.apache.org/jira/browse/MAPREDUCE-3184
MAPREDUCE-3185,Bug,Critical,mrv2,RM Web UI does not sort the columns in some cases.,"While running lots of jobs on a MRv2 cluster the RM web UI shows this error on loading the RM web UI:  ""DataTables warning (table id = 'apps'): Added data (size 8) does not match known number of columns (9)""  After ignoring the error; the column sorting on Web UI stops working.",Closed,Fixed,,Jonathan Eagles,Mahadev konar,Fri; 14 Oct 2011 01:09:05 +0000,Tue; 15 Nov 2011 00:50:18 +0000,Fri; 28 Oct 2011 06:05:01 +0000,,0.23.0,,,YARN-410,https://issues.apache.org/jira/browse/MAPREDUCE-3185
MAPREDUCE-3186,Bug,Blocker,mrv2,User jobs are getting hanged if the Resource manager process goes down and comes up while job is getting executed.,"If the resource manager is restarted while the job execution is in progress; the job is getting hanged. UI shows the job as running. In the RM log; it is throwing an error ""ERROR org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AppAttemptId doesnt exist in cache appattempt_1318579738195_0004_000001"" In the console MRAppMaster and Runjar processes are not getting killed",Closed,Fixed,,Eric Payne,Ramgopal N,Fri; 14 Oct 2011 08:59:50 +0000,Tue; 15 Nov 2011 00:48:40 +0000,Fri; 28 Oct 2011 01:42:03 +0000,,0.23.0,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3186
MAPREDUCE-3187,Improvement,Minor,mrv2,Add names for various unnamed threads in MR2,Simple patch to add thread names for all the places we use Executors; etc.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 14 Oct 2011 17:56:02 +0000,Tue; 15 Nov 2011 00:48:24 +0000,Sun; 16 Oct 2011 19:30:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3187
MAPREDUCE-3188,Bug,Major,mrv2,Lots of errors in logs when daemon startup fails,Since the MR2 daemons are made up of lots of component services; if one of those components fails to start; it will cause the others to shut down as well; even if they haven't fully finished starting up. Currently; this causes the error output to have a bunch of NullPointerExceptions; IllegalStateExceptions; etc; which mask the actual root cause error at the top.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 14 Oct 2011 17:59:24 +0000,Tue; 15 Nov 2011 00:48:45 +0000,Wed; 19 Oct 2011 23:00:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3188
MAPREDUCE-3189,Improvement,Major,mrv2,Add link decoration back to MR2's CSS,I found the MRv2 web UI very difficult to use because it's not clear which items are links and which aren't. I'd like to change the CSS so that links are underlined; making it easier to see them (since they're also not in any different color),Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 14 Oct 2011 18:17:31 +0000,Tue; 15 Nov 2011 00:48:38 +0000,Mon; 17 Oct 2011 02:25:43 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3189
MAPREDUCE-3190,Improvement,Major,mrv2,bin/yarn should barf early if HADOOP_COMMON_HOME or HADOOP_HDFS_HOME are not set,Currently; if these env vars are not set when you run bin hdfs to the classpath. Rather; we should check for these env vars in the wrapper script and display a reasonable error message.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 14 Oct 2011 18:22:54 +0000,Tue; 15 Nov 2011 00:48:51 +0000,Mon; 17 Oct 2011 02:15:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3190
MAPREDUCE-3191,Bug,Trivial,,docs for map output compression incorrectly reference SequenceFile,The documentation currently says that map output compression uses SequenceFile compression. This hasn't been true in several years; since we use IFile for intermediate data now.,Closed,Fixed,,Chen He,Todd Lipcon,Fri; 14 Oct 2011 18:30:01 +0000,Tue; 9 Sep 2014 20:26:40 +0000,Wed; 16 Apr 2014 18:22:36 +0000,,0.23.0,documentation;noob,,,https://issues.apache.org/jira/browse/MAPREDUCE-3191
MAPREDUCE-3192,Bug,Major,,Fix Javadoc warning in JobClient.java and Cluster.java,Javadoc warnings in JobClient. need to be fixed.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Fri; 14 Oct 2011 18:57:11 +0000,Tue; 15 Nov 2011 00:49:15 +0000,Sat; 15 Oct 2011 01:27:05 +0000,,0.23.0,,,MAPREDUCE-2764,https://issues.apache.org/jira/browse/MAPREDUCE-3192
MAPREDUCE-3193,Bug,Major,mrv1;mrv2,FileInputFormat doesn't read files recursively in the input path dir, io.FileNotFoundException is thrown;if input file is more than one folder level deep and the job is getting failed. Example:Input file is  input.txt,Closed,Fixed,MAPREDUCE-1577,Devaraj K,Ramgopal N,Mon; 17 Oct 2011 10:00:32 +0000,Thu; 12 May 2016 18:24:14 +0000,Tue; 2 Jul 2013 22:07:58 +0000,,0.23.2;2.0.0-alpha;3.0.0-alpha1,,,HIVE-4750,https://issues.apache.org/jira/browse/MAPREDUCE-3193
MAPREDUCE-3194,Bug,Major,mrv2,mapred mradmin command is broken in mrv2,"$mapred  mradmin   Exception in thread ""main""  248) Could not find the main class: org.apache.hadoop.mapred.tools.MRAdmin.  Program will exit.",Closed,Fixed,,Jason Lowe,Siddharth Seth,Mon; 17 Oct 2011 16:17:03 +0000,Mon; 5 Mar 2012 02:49:31 +0000,Wed; 25 Jan 2012 21:31:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3194
HADOOP-7755,Bug,Blocker,build,Detect MapReduce PreCommit Trunk builds silently failing when running test-patch.sh,MapReduce PreCommit build is silently failing only running a very small portion of tests. The build then errors out; yet +1 it given to the patch.  Last known Success build - 307 tests run and passed https: console  This message is automatically generated.,Resolved,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 17 Oct 2011 17:47:53 +0000,Wed; 28 Mar 2012 09:21:57 +0000,Tue; 18 Oct 2011 23:50:06 +0000,,0.23.0;0.24.0,,,,https://issues.apache.org/jira/browse/HADOOP-7755
MAPREDUCE-3196,Bug,Major,mrv2,TestLinuxContainerExecutorWithMocks fails on Mac OSX,TestLinuxContainerExecutorWithMocks uses  true which isn't present.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 17 Oct 2011 22:27:12 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Mon; 17 Oct 2011 22:44:35 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3196
MAPREDUCE-3197,Bug,Major,mrv2,TestMRClientService failing on building clean checkout of branch 0.23,"A clean checkout of the branch 0.23 source tree does not pass TestMRClientService#test(); which fails with the error message ""Num diagnostics is not correct expected 2 but was:1 upon running ""mvn clean install assembly:assembly"" inside MR directory.",Closed,Fixed,,Mahadev konar,Anupam Seth,Mon; 17 Oct 2011 22:28:15 +0000,Tue; 15 Nov 2011 00:49:09 +0000,Tue; 18 Oct 2011 05:13:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3197
MAPREDUCE-3198,Bug,Trivial,mrv2,Change mode for hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/resources/mock-container-executor to 755 ,The file is checked in with 644 permissions. TestLinuxContainerExecutorWithMocks changes the file mode to add executable permission if needed resulting in a modified file for 'git svn status' when tests are run.,Closed,Fixed,,Arun C Murthy,Hitesh Shah,Tue; 18 Oct 2011 00:51:46 +0000,Tue; 15 Nov 2011 00:48:20 +0000,Mon; 31 Oct 2011 05:30:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3198
MAPREDUCE-3199,Bug,Major,mrv2;test,TestJobMonitorAndPrint is broken on trunk,I bisected this down to MAPREDUCE-3003 changes. The parent project for client-core changed to hadoop-project which doesn't have the log4j configuration unlike the previous parent hadoop-mapreduce-client.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 18 Oct 2011 10:31:24 +0000,Tue; 15 Nov 2011 00:50:03 +0000,Wed; 19 Oct 2011 18:03:56 +0000,,0.23.0,,MAPREDUCE-3003,,https://issues.apache.org/jira/browse/MAPREDUCE-3199
MAPREDUCE-3200,Bug,Blocker,mrv2,Job got failed with FileNotFoundException during ResourceLocalization,The exception trace is as follows,Resolved,Duplicate,MAPREDUCE-3537,Siddharth Seth,Ramgopal N,Tue; 18 Oct 2011 10:49:08 +0000,Tue; 13 Dec 2011 22:11:48 +0000,Tue; 13 Dec 2011 22:11:47 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3200
MAPREDUCE-3201,Bug,Minor,mrv2,Even though jobs are getting failed on particular NM; it is not getting blacklisted,nan,Resolved,Fixed,,Unassigned,Ramgopal N,Tue; 18 Oct 2011 11:04:47 +0000,Fri; 20 Mar 2015 00:49:02 +0000,Fri; 20 Mar 2015 00:49:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3201
MAPREDUCE-3202,New Feature,Major,jobhistoryserver,Integrating Hadoop Vaidya with Job History UI in Hadoop 2.0 ,Hadoop Vaidya provides a detailed analysis of the M R job in terms of various execution inefficiencies and the associated remedies that user can easily understand and fix. This Jira patch integrates it with Job History UI under Hadoop 2.0 branch.,Patch Available,Unresolved,,vitthal (Suhas) Gogate,vitthal (Suhas) Gogate,Tue; 18 Oct 2011 18:21:26 +0000,Tue; 21 Jul 2015 18:47:47 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3202
MAPREDUCE-3203,Bug,Major,mrv2,Fix some javac warnings in MRAppMaster.,MAPREDUCE-2762 accidentally introduced a couple of   warnings.,Closed,Fixed,,Mahadev konar,Mahadev konar,Tue; 18 Oct 2011 22:12:12 +0000,Tue; 15 Nov 2011 00:49:19 +0000,Tue; 18 Oct 2011 22:48:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3203
MAPREDUCE-3204,Bug,Major,build,mvn site:site fails on MapReduce,This problem does not happen on 0.23. See details in the next comment.,Closed,Fixed,,Alejandro Abdelnur,Suresh Srinivas,Tue; 18 Oct 2011 22:36:10 +0000,Mon; 16 Mar 2015 17:57:12 +0000,Thu; 20 Oct 2011 21:39:30 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3204
MAPREDUCE-3205,Improvement,Blocker,mrv2;nodemanager,MR2 memory limits should be pmem; not vmem,"Currently; the memory resources requested for a container limit the amount of virtual memory used by the container. On my test clusters; at least; Java processes take up nearly twice as much vmem as pmem - a Java process running with -Xmx500m uses 935m of vmem and only about 560m of pmem.  This will force admins to either under-utilize available physical memory; or oversubscribe it by configuring the available resources on a TT to be larger than the true amount of physical RAM.  Instead; I would propose that the resource limit apply to pmem; and allow the admin to configure a ""vmem overcommit ratio"" which sets the vmem limit as a function of pmem limit.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 19 Oct 2011 01:14:41 +0000,Tue; 15 Nov 2011 00:49:22 +0000,Wed; 26 Oct 2011 23:58:24 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3205
MAPREDUCE-3206,Bug,Major,contrib/fair-share,FairScheduler breaks writing of job tokens to MR system dir when using kerberos auth,Using the FairScheduler with kerberos authentication does not appear to work with 0.20.205.0.  When submitting a job; execution fails when storing the delegation tokens for the job:     The problem seems to have been introduced by the backported changes in MAPREDUCE-2981; which shifted the execution of JobTracker.initJob(); and hence JobInProgress.generateAndStoreTokens(); to underneath the call path for the RPC invocation.  As a result; the DFS write in TokenStorage.writeTokenStorageFile() in done under a UGI.doAs() block as the RPC client remote user; without a TGT for negotiating the connection.  Does this analysis seem right?  Previously it seems that JobTracker.initJob() was only called in a separate thread so it was picking up the credentials obtained for the configured JobTracker kerberos principal.  The same job runs successfully in a build with MAPREDUCE-2981 reverted.,Open,Unresolved,,Unassigned,Gary Helmling,Wed; 19 Oct 2011 01:20:34 +0000,Tue; 10 Jul 2012 21:27:09 +0000,,,0.20.205.0,,,MAPREDUCE-2981,https://issues.apache.org/jira/browse/MAPREDUCE-3206
MAPREDUCE-3207,Sub-task,Minor,mrv2,TestMRCLI failing on trunk  ,Failing tests:   7: Archive: Deleting a file in archive   8: Archive: Renaming a file in archive,Resolved,Won't Fix,,Unassigned,Hitesh Shah,Wed; 19 Oct 2011 01:48:30 +0000,Mon; 9 Mar 2015 20:29:49 +0000,Mon; 9 Mar 2015 20:29:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3207
MAPREDUCE-3208,Bug,Minor,mrv2,NPE while flushing TaskLogAppender,NPE will be throwed out while calling flush() of TaskLogAppender;if the QuietWriter isn't initialized in advance.,Closed,Fixed,,liangzhaowang,liangzhaowang,Wed; 19 Oct 2011 02:55:48 +0000,Tue; 10 Mar 2015 04:32:56 +0000,Wed; 19 Oct 2011 22:40:30 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3208
MAPREDUCE-3209,Bug,Major,build;mrv2,Jenkins reports 160 FindBugs warnings,See https: newPatchFindbugsWarningshadoop-mapreduce-client-core.html,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 19 Oct 2011 04:39:19 +0000,Tue; 15 Nov 2011 00:49:03 +0000,Fri; 28 Oct 2011 02:41:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3209
YARN-80,Improvement,Major,capacityscheduler,Support delay scheduling for node locality in MR2's capacity scheduler,The capacity scheduler in MR2 doesn't support delay scheduling for achieving node-level locality. So; jobs exhibit poor data locality even if they have good rack locality. Especially on clusters where disk throughput is much better than network capacity; this hurts overall job performance. We should optionally support node-level delay scheduling heuristics similar to what the fair scheduler implements in MR1.,Closed,Fixed,,Arun C Murthy,Todd Lipcon,Wed; 19 Oct 2011 07:15:13 +0000,Thu; 7 Nov 2013 13:29:01 +0000,Fri; 7 Sep 2012 05:12:20 +0000,,,,,MAPREDUCE-4305,https://issues.apache.org/jira/browse/YARN-80
MAPREDUCE-3211,Bug,Major,job submission;mrv2,"Fetch failures if used ephemeral port for property ""mapreduce.shuffle.port"". ",To reproduce the bug.   Use the following property in mapred-site.xml  configuration     property       name mapreduce.framework.name property  Then try to start the yarn daemons.  And submit the job. (which would eventually fail).  Also observe NM logs. It says shuffle handler service started at port 0;,Resolved,Duplicate,MAPREDUCE-2986,Prashant Sharma,Prashant Sharma,Wed; 19 Oct 2011 09:48:16 +0000,Mon; 28 Sep 2015 21:10:31 +0000,Thu; 20 Oct 2011 05:28:06 +0000,,2.0.0-alpha,ShuffleHandler,,,https://issues.apache.org/jira/browse/MAPREDUCE-3211
MAPREDUCE-3212,Bug,Minor,mrv2,Message displays while executing yarn command should be proper,execute yarn command without any arguments. It displays   . Rather the message should be,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Wed; 19 Oct 2011 13:36:50 +0000,Tue; 15 Nov 2011 00:49:15 +0000,Wed; 19 Oct 2011 22:44:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3212
MAPREDUCE-3213,Bug,Major,mrv2,AM should kill all running tasks on a node when it gets marked as blacklisted,nan,Open,Unresolved,,Unassigned,Hitesh Shah,Wed; 19 Oct 2011 17:05:12 +0000,Mon; 9 Mar 2015 20:39:11 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3213
MAPREDUCE-3214,Bug,Major,mrv2;test,ant mapreduce tests failing,Umbrella jira for various test failures,Resolved,Fixed,,Unassigned,Hitesh Shah,Wed; 19 Oct 2011 20:41:37 +0000,Mon; 9 Mar 2015 22:47:41 +0000,Mon; 9 Mar 2015 22:47:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3214
MAPREDUCE-3215,Sub-task,Minor,mrv2,org.apache.hadoop.mapreduce.TestNoJobSetupCleanup failing on trunk,Testcase: testNoJobSetupCleanup took 13.271 sec         FAILED Number of part-files is 0 and not 1 junit.framework.AssertionFailedError: Number of part-files is 0 and not 1         at org.apache.hadoop.mapreduce.TestNoJobSetupCleanup.submitAndValidateJob(TestNoJobSetupCleanup. 70),Closed,Fixed,,Hitesh Shah,Hitesh Shah,Wed; 19 Oct 2011 20:44:39 +0000,Mon; 5 Mar 2012 02:49:21 +0000,Thu; 3 Nov 2011 13:22:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3215
MAPREDUCE-3216,Sub-task,Minor,mrv2,ant test TestNoDefaultsJobConf fails on trunk,Testcase: testNoDefaults took 4.703 sec         Caused an ERROR Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.  83),Closed,Duplicate,MAPREDUCE-3321,Hitesh Shah,Hitesh Shah,Wed; 19 Oct 2011 20:47:44 +0000,Tue; 15 Nov 2011 00:50:15 +0000,Tue; 1 Nov 2011 00:57:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3216
MAPREDUCE-3217,Sub-task,Minor,mrv2;test,ant test TestAuditLogger fails on trunk,Testcase: testKeyValLogFormat took 0.096 sec Testcase: testAuditLoggerWithoutIP took 0.005 sec Testcase: testAuditLoggerWithIP took 0.417 sec         Caused an ERROR  150),Closed,Fixed,,Devaraj K,Hitesh Shah,Wed; 19 Oct 2011 20:51:14 +0000,Mon; 5 Mar 2012 02:48:52 +0000,Fri; 4 Nov 2011 09:03:43 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3217
MAPREDUCE-3218,Sub-task,Minor,mrv2;test,ant test TestTokenCache failing on trunk,Testcase: testTokenCache took 11.607 sec Testcase: testLocalJobTokenCache took 12.224 sec Testcase: testGetTokensForNamenodes took 0.009 sec Testcase: testGetTokensForHftpFS took 0.676 sec Testcase: testGetJTPrincipal took 0.023 sec         FAILED Failed to substitute HOSTNAME_PATTERN with hostName expected:jt foo@BAR but was:null         at org.apache.hadoop.mapreduce.security.TestTokenCache.testGetJTPrincipal(TestTokenCache. 392)  Testcase: testGetTokensForViewFS took 0.019 sec,Closed,Duplicate,MAPREDUCE-3321,Hitesh Shah,Hitesh Shah,Wed; 19 Oct 2011 20:54:03 +0000,Tue; 15 Nov 2011 00:49:57 +0000,Tue; 1 Nov 2011 01:00:52 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3218
MAPREDUCE-3219,Sub-task,Minor,mrv2;test,ant test TestDelegationToken failing on trunk,Testcase: testDelegationToken took 2.043 sec         Caused an ERROR Client Hitesh tries to renew a token with renewer specified as alice          org.apache.hadoop.mapreduce.Cluster.renewDelegationToken(Cluster. 397),Closed,Fixed,,Hitesh Shah,Hitesh Shah,Wed; 19 Oct 2011 20:56:26 +0000,Mon; 5 Mar 2012 02:49:17 +0000,Fri; 4 Nov 2011 07:50:52 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3219
MAPREDUCE-3220,Sub-task,Minor,mrv2;test,ant test TestCombineOutputCollector failing on trunk,Testsuite: org.apache.hadoop.mapred.TestCombineOutputCollector Tests run: 2; Failures: 2; Errors: 0; Time elapsed: 1.591 sec  Testcase: testCustomCollect took 0.363 sec         FAILED  taskReporter.progress(); Never wanted here: -  org.apache.hadoop.mapred.TestCombineOutputCollector.testDefaultCollect(TestCombineOutputCollector. 139),Closed,Fixed,,Devaraj K,Hitesh Shah,Wed; 19 Oct 2011 20:58:50 +0000,Tue; 15 Nov 2011 00:49:04 +0000,Tue; 1 Nov 2011 01:05:21 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3220
MAPREDUCE-3221,Sub-task,Minor,mrv2;test,ant test TestSubmitJob failing on trunk,Testcase: testJobWithInvalidMemoryReqs took 2.588 sec Testcase: testSecureJobExecution took 4.089 sec         FAILED  270),Closed,Fixed,,Devaraj K,Hitesh Shah,Wed; 19 Oct 2011 21:00:31 +0000,Mon; 5 Mar 2012 02:49:06 +0000,Thu; 3 Nov 2011 12:27:56 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3221
MAPREDUCE-3222,Sub-task,Minor,mrv2,ant test TestTaskContext failing on trunk,Testcase: testContextStatus took 29.977 sec         FAILED null expected:map[  sort] but was:map[] junit.framework.ComparisonFailure: null expected:map[  sort] but was:map[]         at org.apache.hadoop.mapreduce.TestTaskContext.testContextStatus(TestTaskContext. 120)  Testcase: testMapContextProgress took 17.371 sec Testcase: testReduceContextProgress took 16.267 sec,Resolved,Won't Fix,,Unassigned,Hitesh Shah,Wed; 19 Oct 2011 21:02:54 +0000,Mon; 9 Mar 2015 20:30:15 +0000,Mon; 9 Mar 2015 20:30:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3222
MAPREDUCE-3223,Bug,Major,documentation;mrv2,Remove MR1 configs from mapred-default.xml,All of the MRv1 configs are still in mapred-default.xml. This is confusing when trying to make config changes. Since a lot of the input mapred-site.xml for now; and once that dependency is broken; we can remove them entirely.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 19 Oct 2011 23:51:42 +0000,Thu; 12 May 2016 18:22:34 +0000,Fri; 28 Sep 2012 15:09:42 +0000,,0.23.0,,MAPREDUCE-2328,MAPREDUCE-5762,https://issues.apache.org/jira/browse/MAPREDUCE-3223
MAPREDUCE-3225,Bug,Minor,mrv2,Killing an unkown job throws NPE.,On a job -kill of an unkown job; the code currently throws a NPE. Stack trace on the next comment.,Resolved,Cannot Reproduce,,Hitesh Shah,Mahadev konar,Thu; 20 Oct 2011 04:58:14 +0000,Wed; 9 Nov 2011 19:48:10 +0000,Wed; 9 Nov 2011 19:48:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3225
MAPREDUCE-3226,Bug,Blocker,mrv2;task,Few reduce tasks hanging in a gridmix-run,In a gridmix run with ~1000 jobs; one job is getting stuck because of 2-3 hanging reducers. All of the them are stuck after downloading all map outputs and have the following thread dump.     Thanks to Karam Singh for helping track this down.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 20 Oct 2011 06:38:04 +0000,Tue; 15 Nov 2011 00:49:11 +0000,Thu; 20 Oct 2011 22:45:21 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3226
YARN-3117,Bug,Major,documentation,Conflicting information in the YARN-Docs,For building the yarn binaries; information in the README file in the hadoop-yarn is    But while executing the above cmd; getting the following error,Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Thu; 20 Oct 2011 08:55:26 +0000,Thu; 29 Jan 2015 22:33:37 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-3117
MAPREDUCE-3228,Bug,Blocker,applicationmaster;mrv2,MR AM hangs when one node goes bad,Found this on one of the gridmix runs; again. One of the nodes went real bad; the job had three containers running on the node. Eventually; AM marked the tasks as timedout and initiated cleanup of the failed containers via stopContainer(). The later got stuck at the faulty node; the tasks are stuck in FAIL_CONTAINER_CLEANUP stage and the job lies in there waiting for ever.  Thanks to Karam Singh for helping with this.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 20 Oct 2011 12:12:15 +0000,Tue; 15 Nov 2011 00:48:16 +0000,Thu; 27 Oct 2011 17:31:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3228
YARN-48,Sub-task,Major,,Tests for verifying application-acl checks on the web-UI,MAPREDUCE-3104 added application-acls. We need tests which pull the web-pages with various login users and validate the authorization checks.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 20 Oct 2011 12:20:00 +0000,Mon; 27 Aug 2012 20:55:57 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-48
MAPREDUCE-3230,Bug,Blocker,client;mrv2,No information about Data Local maps from Job client CLI and in JobHistory ,Size of cluster is 350 NMs. I have topology.node.switch.mapping.impl set to enable rack-locality. Ran randomwriter sort and scan jobs. Both jobs ran completed successfully.  On Job client sort job says :    JobHistory files also don't have information about Data Local Maps.  There used to be information about data local maps before; till about a month back; like so:  For sort with 349 NMs :,Closed,Not A Problem,,Unassigned,Karam Singh,Thu; 20 Oct 2011 12:24:11 +0000,Tue; 15 Nov 2011 00:49:16 +0000,Thu; 20 Oct 2011 18:16:14 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3230
MAPREDUCE-3231,Improvement,Major,mrv2,Improve Application Master And Job History UI Security,I propose a stripped down JSON based protocol for creating safe user generate web pages.  This JIRA is intended first of all as a place for a discussion about this proposal; and then if there are no serious objections this will be an Umbrella JIRA to implement the changes proposed.,Open,Unresolved,,Luke Lu,Robert Joseph Evans,Thu; 20 Oct 2011 15:32:58 +0000,Mon; 31 Oct 2011 13:46:03 +0000,,,0.23.0,,,MAPREDUCE-2858,https://issues.apache.org/jira/browse/MAPREDUCE-3231
MAPREDUCE-3232,Bug,Major,,AM should  handle reboot from Resource Manager,When the RM doesn't have last response id for app attempt(or the request response id is less than the last response id); RM sends reboot response but AM doesn't handle this.,Resolved,Not A Problem,,Devaraj K,Devaraj K,Thu; 20 Oct 2011 15:41:11 +0000,Tue; 10 Mar 2015 04:32:18 +0000,Thu; 17 Jan 2013 13:14:49 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3232
MAPREDUCE-3233,Sub-task,Blocker,mrv2,AM fails to restart when first AM is killed,Set yarn.resourcemanager.am.max-retries=5 in yarn-site.xml. Started yarn cluster. Sumbitted Sleep Job of 100K maps tasks as following -: $HADOOP_COMMON_HOME hadoop-test.jar sleep -m 100000 -r 0 -mt 1000 -rt 1000  when around 53K tasks go; login node running AppMaster; and killed AppMaster with kill -9  Resource Manager tried restart AM uptio max-retris but failed with following -:,Closed,Fixed,,Mahadev konar,Karam Singh,Thu; 20 Oct 2011 16:23:08 +0000,Tue; 15 Nov 2011 00:50:08 +0000,Sat; 22 Oct 2011 08:11:26 +0000,,0.23.0,,MAPREDUCE-2708,,https://issues.apache.org/jira/browse/MAPREDUCE-3233
MAPREDUCE-3234,Bug,Blocker,mrv2,Locality scheduling broken due to mismatch between IPs and hosts,I noticed that; on a single-rack cluster; I wasn't getting hardly any data locality. The issue appears to be the code in RMContainerAllocator which changes the resource requests to use IP addresses instead of hostnames:   However; at least on my cluster; the resource manager sees node resources as hostnames; not IPs. Removing this code fixed data locality.,Resolved,Duplicate,MAPREDUCE-2693,Unassigned,Todd Lipcon,Thu; 20 Oct 2011 16:58:35 +0000,Sat; 22 Oct 2011 06:20:57 +0000,Sat; 22 Oct 2011 06:20:13 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3234
MAPREDUCE-3235,Improvement,Major,performance;task,Improve CPU cache behavior in map side sort,"When running oprofile on a terasort workload; I noticed that a large amount of CPU usage was going to MapTask$MapOutputBuffer.compare. Upon disassembling this and looking at cycle counters; most of the cycles were going to memory loads dereferencing into the array of key-value data  implying expensive cache misses. This can be avoided as follows:  	rather than simply swapping indexes into the kv array; swap the entire meta entries in the meta array. Swapping 16 bytes is only negligibly slower than swapping 4 bytes. This requires adding the value-length into the meta array; since we used to rely on the previous-in-the-array meta entry to determine this. So we replace INDEX with VALUELEN and avoid one layer of indirection. 	introduce an interface which allows key types to provide a 4-byte comparison proxy. For string keys; this can simply be the first 4 bytes of the string. The idea is that; if stringCompare(key1.proxy(); key2.proxy()) != 0; then compare(key1; key2) should have the same result. If the proxies are equal; the normal comparison method is used. We then include the 4-byte proxy as part of the metadata entry; so that for many cases the indirection into the data buffer can be avoided.    On a terasort benchmark; these optimizations plus an optimization to WritableComparator.compareBytes dropped the aggregate mapside CPU millis by 40%; and the compare() routine mostly dropped off the oprofile results.",Open,Unresolved,,Todd Lipcon,Todd Lipcon,Thu; 20 Oct 2011 17:30:18 +0000,Thu; 15 Aug 2013 18:47:11 +0000,,,0.23.0,,,MAPREDUCE-1639;MAPREDUCE-4755,https://issues.apache.org/jira/browse/MAPREDUCE-3235
MAPREDUCE-3236,Bug,Major,jobtracker;security,Distcp with hdfs:// passed with error in JT log while copying from .20.204  to .20.205 ( with useIp=false),"I tried to copy file from .20.204 to .20.205 by distcp over hdfs:  while using hadoop.security.token.service.use_ip=false in core-site.xml. The copy was successful but found error "" org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal:"" exception in .20.205 JT.",Open,Unresolved,,Daryn Sharp,Rajit Saha,Thu; 13 Oct 2011 22:24:46 +0000,Tue; 24 Feb 2015 22:37:56 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3236
MAPREDUCE-3237,Improvement,Major,client,Move LocalJobRunner to hadoop-mapreduce-client-core module,LocalJobRunner works independently of MR1 (jobtracker and tasktrackers) and MR2 (YARN). The MR1 directory is being kept around only to support unit tests; so LocalJobRunner should be moved out to somewhere more permanent.,Resolved,Fixed,,Tom White,Tom White,Thu; 20 Oct 2011 21:10:03 +0000,Wed; 8 Feb 2012 02:50:04 +0000,Tue; 1 Nov 2011 03:20:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3237
MAPREDUCE-3238,Improvement,Trivial,mrv2,Small cleanup in SchedulerApp,"While reading this code; I did a little bit of cleanup:  	added some  oc 	rather than using a MapPriority; Integer for keeping counts; switched to Guava's HashMultiset; which makes a simpler API.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 21 Oct 2011 05:10:21 +0000,Mon; 5 Mar 2012 02:48:51 +0000,Sun; 27 Nov 2011 23:50:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3238
MAPREDUCE-3239,Improvement,Minor,mrv2,Use new createSocketAddr API in MRv2 to give better error messages on misconfig,HADOOP-7749 added a NetUtils call which will include the configuration name as part of the exception message. This is handy if you accidentally specify some invalid string; or forget to specify a required parameter. This JIRA is to make MR2 use the new API.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 21 Oct 2011 05:50:38 +0000,Tue; 15 Nov 2011 00:49:17 +0000,Fri; 21 Oct 2011 21:37:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3239
MAPREDUCE-3240,Bug,Blocker,mrv2;nodemanager,NM should send a SIGKILL for completed containers also,This is to address the containers which exit properly after spawning sub-processes themselves. We don't want to leave these sub-process-tree or else they can pillage the NM's resources.  Today; we already have code to send SIGKILL to the whole process-trees (because of single sessionId resulting from  setsid) when the container is alive. We need to obtain the PID of the containers when they start and use that PID to send signal for completed containers' case also.,Closed,Fixed,MAPREDUCE-3260;MAPREDUCE-3084,Hitesh Shah,Vinod Kumar Vavilapalli,Fri; 21 Oct 2011 14:38:08 +0000,Tue; 15 Nov 2011 00:48:08 +0000,Thu; 27 Oct 2011 12:04:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3240
MAPREDUCE-3241,Bug,Major,,(Rumen)TraceBuilder throws IllegalArgumentException,When we run the TraceBuilder; we get this exception. Output of the TraceBuilder doesn't contain the map and reduce task information.,Resolved,Fixed,,Amar Kamat,Devaraj K,Fri; 21 Oct 2011 16:25:33 +0000,Tue; 10 Mar 2015 04:32:22 +0000,Mon; 31 Oct 2011 15:54:05 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3241
MAPREDUCE-3242,Bug,Major,mrv2,Trunk compilation broken with bad interaction from MAPREDUCE-3070 and MAPREDUCE-3239.,Looks like patch command threw away some of the changes when I committed MAPREDUCE-3239 after MAPREDUCE-3070.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 21 Oct 2011 22:15:25 +0000,Tue; 15 Nov 2011 00:49:20 +0000,Fri; 21 Oct 2011 22:47:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3242
MAPREDUCE-3243,Bug,Major,contrib/streaming;mrv2,Invalid tracking URL for streaming jobs,"The tracking URL for streaming jobs currently display ""http: A""",Closed,Fixed,,Jonathan Eagles,Ramya Sunil,Sat; 22 Oct 2011 00:46:22 +0000,Mon; 5 Mar 2012 02:49:42 +0000,Mon; 14 Nov 2011 22:47:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3243
MAPREDUCE-3244,Improvement,Minor,,Make nodes fail/succeed based on return codes (regardless of pending data),If I were to run a MR job with a script like 'head -n10' for some reason; each node would execute head -n10 (good); and output 10 rows (good) and then the 'head' program would return success and quit (good); and all the nodes would fail (bad) because there's a ton of pending data (irrelevant).  For purposes of streaming data through programs; Hadoop should trust the program's return code.,Open,Unresolved,,Unassigned,Adam Kramer,Sat; 22 Oct 2011 00:58:38 +0000,Sat; 22 Oct 2011 00:58:38 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3244
YARN-3314,Test,Major,test,Write an integration test for validating MR AM restart and recovery,This; so that we can catch bugs like MAPREDUCE-3233.  We need one with recovery disabled i.e. for only restart and one for restart+recovery.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Sat; 22 Oct 2011 08:13:41 +0000,Mon; 9 Mar 2015 21:42:26 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-3314
MAPREDUCE-3246,Improvement,Major,task,Make Task extensible to support modifications of Task or even alternate programming paradigms,One of MRv2's goal is to support alternate programming paradigms; but building a application using YARN from the bottom is not trivial. In fact most component of MapReduce can be reused; mostly the scheduler ReduceTask. I just post my initial thoughts here for opinions. If this change is OK; I can submit a patch; this is just a trivial work.,Open,Unresolved,,Binglin Chang,Binglin Chang,Sat; 22 Oct 2011 09:03:25 +0000,Sun; 27 Nov 2011 14:37:35 +0000,,,0.23.0,,,MAPREDUCE-3247;MAPREDUCE-2841,https://issues.apache.org/jira/browse/MAPREDUCE-3246
MAPREDUCE-3247,New Feature,Major,task,Add hash aggregation style data flow and/or new API,In many join v pairs to free some memory; if the memory consumption reach io.sort.mb,Open,Unresolved,,Unassigned,Binglin Chang,Sat; 22 Oct 2011 12:44:18 +0000,Tue; 11 Dec 2012 01:59:16 +0000,,,0.23.0,api;perfomance,,MAPREDUCE-3246;MAPREDUCE-2841,https://issues.apache.org/jira/browse/MAPREDUCE-3247
MAPREDUCE-3248,Bug,Blocker,test,Log4j logs from unit tests are lost,Can't find log4j logs in tests; all of them complain:     I suspect MAPREDUCE-3199.,Resolved,Fixed,,Vinod Kumar Vavilapalli,Arun C Murthy,Mon; 24 Oct 2011 05:20:54 +0000,Tue; 10 Mar 2015 04:32:02 +0000,Tue; 25 Oct 2011 01:01:21 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3248
MAPREDUCE-3249,Sub-task,Blocker,applicationmaster;mrv2,Recovery of MR AMs with reduces fails the subsequent generation of the job,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Mon; 24 Oct 2011 09:07:46 +0000,Tue; 15 Nov 2011 00:48:39 +0000,Mon; 24 Oct 2011 21:18:03 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3249
MAPREDUCE-3250,Sub-task,Blocker,applicationmaster;mrv2,When AM restarts; client keeps reconnecting to the new AM and prints a lots of logs.,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Mon; 24 Oct 2011 10:19:19 +0000,Tue; 15 Nov 2011 00:48:40 +0000,Wed; 26 Oct 2011 04:34:26 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3250
MAPREDUCE-3251,Task,Critical,mrv2,Network ACLs can prevent some clients to talk to MR ApplicationMaster,In 0.20.xxx; the JobClient while polling goes to JT to get the job status. With YARN; AM can be launched on any port and the client will have to have ACL open to that port to talk to AM and get the job status. When the client is within the same grid network access to AM is not a problem. But some applications may have one installation per set of clusters and may launch jobs even across such sets (on job trackers in another set of clusters). For that to work only the JT port needs to be open currently. In case of YARN; all ports will have to be opened up for things to work. That would be a security no-no.  There are two possible solutions:   1) Make the job client only talk to RM (as an option) to get the job status.    2) Limit the range of ports AM can listen on.  Option 2) may not be favorable as there is no direct OS API to find a free port.,Closed,Fixed,,Anupam Seth,Anupam Seth,Mon; 24 Oct 2011 15:40:35 +0000,Mon; 5 Mar 2012 02:49:45 +0000,Tue; 10 Jan 2012 23:10:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3251
MAPREDUCE-3252,Bug,Critical,mrv2;task,MR2: Map tasks rewrite data once even if output fits in sort buffer,I found that; even if the output of a map task fits entirely in its sort buffer; it was rewriting the output entirely rather than just renaming the first spill into place. This is due to RawLocalFileSystem.rename() falling back to a copy if renameTo() fails. The first rename attempt was failing because no one has called mkdir for the output directory yet.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Mon; 24 Oct 2011 20:50:54 +0000,Tue; 15 Nov 2011 00:48:24 +0000,Mon; 24 Oct 2011 22:31:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3252
MAPREDUCE-3253,Bug,Blocker,mrv2,ContextFactory throw NoSuchFieldException,I see exceptions from ContextFactory when I am running Pig unit test: Caused by:  126),Closed,Fixed,,Arun C Murthy,Daniel Dai,Mon; 24 Oct 2011 20:59:49 +0000,Tue; 15 Nov 2011 00:49:29 +0000,Tue; 25 Oct 2011 18:13:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3253
MAPREDUCE-3254,Bug,Blocker,contrib/streaming;mrv2,Streaming jobs failing with PipeMapRunner ClassNotFoundException,ClassNotFoundException: org.apache.hadoop.streaming.PipeMapRunner encountered while running streaming jobs. Stack trace in the next comment.,Closed,Fixed,,Arun C Murthy,Ramya Sunil,Mon; 24 Oct 2011 22:03:50 +0000,Tue; 15 Nov 2011 00:49:01 +0000,Thu; 27 Oct 2011 02:45:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3254
MAPREDUCE-3255,Improvement,Major,mrv2,"MR2 needs a counter analogous to ""slot seconds""","In older versions of MR; we have a SLOT_MILLIS counter which counts how many seconds each task (and job) used of map reduce slots. Since we no longer have the concept of a ""slot"" in MR2; we should change this counter to be something like ""RAM-megabyte-seconds"" - ie each task is charged for its resource requirement * the number of seconds it occupied those resources.  Ideally these would be collected by the NodeManager rather than the children; so that they could be used for billing purposes; but a first cut of the counters through the MR framework itself would probably still be useful in more trusting environments.",Open,Unresolved,,Unassigned,Todd Lipcon,Tue; 25 Oct 2011 00:58:05 +0000,Tue; 25 Oct 2011 18:05:44 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3255
MAPREDUCE-3256,Sub-task,Blocker,applicationmaster;mrv2;nodemanager;security,Authorization checks needed for AM->NM protocol,"We already authenticate requests to NM from any AM. We also need to authorize the requests; otherwise a rogue AM; but with proper tokens and thus authenticated to talk to NM; could either launch or kill a container with different ContainerID. We have two options:  	Remove the explicit passing of the ContainerId as part of the API and instead get it from the RPC layer. In this case; we will need a ContainerToken for each container. 	Do explicit authorization checks without relying on getting ContainerID from the RPC.    One ContainerToken per container is a serious restriction. We anyways want to be able to use application-ACLS to; say; stop containers owned by others. So I am going to take the later route of explicit checks.",Closed,Fixed,YARN-51,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 25 Oct 2011 05:39:49 +0000,Tue; 15 Nov 2011 00:48:06 +0000,Sat; 29 Oct 2011 09:37:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3256
MAPREDUCE-3257,Sub-task,Blocker,applicationmaster;mrv2;resourcemanager;security,Authorization checks needed for AM->RM protocol,This is like MAPREDUCE-3256; but for AM-RM protocol.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 25 Oct 2011 06:55:20 +0000,Tue; 15 Nov 2011 00:49:19 +0000,Thu; 27 Oct 2011 06:23:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3257
MAPREDUCE-3258,Bug,Blocker,mrv2,Job counters missing from AM and history UI,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 25 Oct 2011 06:57:19 +0000,Tue; 15 Nov 2011 00:48:36 +0000,Fri; 28 Oct 2011 05:07:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3258
MAPREDUCE-3259,Bug,Blocker,mrv2;nodemanager,ContainerLocalizer should get the proper java.library.path from LinuxContainerExecutor,As seen in MAPREDUCE-2915;  library.path is set.,Closed,Fixed,,Kihwal Lee,Kihwal Lee,Tue; 25 Oct 2011 10:14:34 +0000,Mon; 16 Mar 2015 17:57:14 +0000,Thu; 27 Oct 2011 08:31:30 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3259
MAPREDUCE-3260,Bug,Critical,mrv2;resourcemanager,Yarn app stuck in KILL_WAIT state,"Last night I killed an MR2 app using ""hadoop job -kill"". This morning I noticed it's still running; but in ""KILL_WAIT"" state with no tasks running.",Resolved,Duplicate,MAPREDUCE-3240,Unassigned,Todd Lipcon,Tue; 25 Oct 2011 16:15:05 +0000,Thu; 27 Oct 2011 06:37:33 +0000,Tue; 25 Oct 2011 17:43:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3260
MAPREDUCE-3261,Bug,Major,applicationmaster,AM unable to release containers,"I'm probably doing something wrong here; but I can't figure it out.  My ApplicationMaster is sending an AllocateRequest with ContainerIds to release. My ResourceManager logs say:  2011-10-25 10:02:52;236 WARN  resourcemanager.RMAuditLogger (RMAuditLogger. logFailure(207)) - USER=criccomi	IP=127.0.0.1	OPERATION=AM Released Container	TARGET=FifoScheduler	RESULT=FAILURE	DESCRIPTION=Trying to release container not owned by app or with invalid id	PERMISSIONS=Unauthorized access or invalid container	APPID=application_1319485153554_0028	CONTAINERID=container_1319485153554_0028_01_000003  The container ID is valid; as is the app id:  criccomi@criccomi-ld logs$ pwd  stdout  The containers are still running.  My code to start a container; and then to release it:       I have double checked that my ContainerIds are accurate; and they are.  Any idea what I'm doing wrong here?",Closed,Fixed,,Unassigned,Chris Riccomini,Tue; 25 Oct 2011 17:11:24 +0000,Mon; 16 Mar 2015 17:57:11 +0000,Tue; 25 Oct 2011 17:41:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3261
MAPREDUCE-3262,Bug,Critical,mrv2;nodemanager,A few events are not handled by the NodeManager in failure scenarios,Need to handle kill container event in localization failed state.  Need to handle resource localized in localization failed state.,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Tue; 25 Oct 2011 17:42:25 +0000,Tue; 15 Nov 2011 00:49:18 +0000,Mon; 31 Oct 2011 11:31:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3262
MAPREDUCE-3263,Bug,Blocker,build;mrv2,compile-mapred-test target fails,Compile mapred test target is broken due to which the builds are not archiving the test jars.,Closed,Fixed,,Hitesh Shah,Ramya Sunil,Tue; 25 Oct 2011 17:52:54 +0000,Tue; 15 Nov 2011 00:48:32 +0000,Wed; 26 Oct 2011 02:11:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3263
MAPREDUCE-3264,Bug,Blocker,mrv2,mapreduce.job.user.name needs to be set automatically,Currently in MR2 I have to manually specify mapreduce.job.user.name for each job. It's not picking it up from the security infrastructure; at least when running with DefaultContainerExecutor. This is obviously incorrect.,Closed,Fixed,,Arun C Murthy,Todd Lipcon,Tue; 25 Oct 2011 19:09:43 +0000,Tue; 15 Nov 2011 00:49:10 +0000,Thu; 27 Oct 2011 06:05:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3264
MAPREDUCE-3265,Improvement,Blocker,mrv2,Reduce log level on MR2 IPC construction; etc,Currently MR's IPC logging is very verbose. For example; I see a lot of:    INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocol ... when submitting a job. This should be DEBUG level.,Closed,Fixed,,Arun C Murthy,Todd Lipcon,Tue; 25 Oct 2011 19:13:33 +0000,Mon; 5 Mar 2012 02:49:12 +0000,Wed; 23 Nov 2011 22:06:56 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3265
MAPREDUCE-3266,Improvement,Minor,mrv2;nodemanager,NM resource allocation should be in MB; not GB,Currently; the resource allocation for tasks on the NM is expressed in GB. This is inconsistent with the per-task resources which are in units of MBs. We should use MB throughout for better consistency.,Resolved,Duplicate,MAPREDUCE-3205,Unassigned,Todd Lipcon,Tue; 25 Oct 2011 19:15:45 +0000,Wed; 26 Oct 2011 21:29:54 +0000,Wed; 26 Oct 2011 21:29:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3266
MAPREDUCE-3267,Bug,Major,mrv2;task,MR2 reduce tasks showing >100% complete,"My job is currently showing 100% reduce completion. Some reduce tasks are much higher than 100% complete. they appear to be in the ""last merge pass"" stage",Resolved,Duplicate,MAPREDUCE-2264,Ravi Prakash,Todd Lipcon,Tue; 25 Oct 2011 20:14:32 +0000,Mon; 28 Jan 2013 23:03:52 +0000,Mon; 28 Jan 2013 23:03:52 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3267
YARN-284,Improvement,Major,scheduler,YARN capacity scheduler doesn't spread MR tasks evenly on an underutilized cluster,The fair scheduler in MR1 has the behavior that; if a job is submitted to an under-utilized cluster and the cluster has more open slots than tasks in the job; the tasks are spread evenly throughout the cluster. This improves job latency since more spindles and NICs are utilized to complete the job. In MR2 I see this issue causing significantly longer job runtimes when there is excess capacity in the cluster  especially on reducers which sometimmes end up clumping together on a smaller set of nodes which then become disk network constrained.,Resolved,Implemented,,Unassigned,Todd Lipcon,Tue; 25 Oct 2011 20:39:53 +0000,Sat; 22 Dec 2012 05:50:35 +0000,Sat; 22 Dec 2012 00:42:34 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-284
MAPREDUCE-3269,Bug,Blocker,mrv2,Jobsummary logs not being moved to a separate file,The jobsummary logs are not being moved to a separate file. Below is the configuration in log4j.properties:,Closed,Fixed,,Mahadev konar,Ramya Sunil,Tue; 25 Oct 2011 21:07:54 +0000,Tue; 15 Nov 2011 00:49:05 +0000,Wed; 26 Oct 2011 02:15:32 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3269
MAPREDUCE-3270,Bug,Major,mrv2,Decommissioned node not removed from active NM list,"A decommissioned node is not being removed from the ""Total nodes"" list and is not added to the ""Decommissioned nodes"" list.  The list of nodes to decommission is added in a file defined by ""yarn.resourcemanager.nodes.exclude-path"" and excluded via refreshNodes CLI.",Resolved,Duplicate,MAPREDUCE-2775,Unassigned,Ramya Sunil,Tue; 25 Oct 2011 21:26:05 +0000,Mon; 31 Oct 2011 05:03:24 +0000,Mon; 31 Oct 2011 05:03:24 +0000,,0.23.0,,MAPREDUCE-2775,,https://issues.apache.org/jira/browse/MAPREDUCE-3270
MAPREDUCE-3271,Bug,Critical,mrv2,Lost nodes list and count not updated,"When nodemanagers are lost; the ""Lost Nodes"" list and the count is not incremented. Either we;  1. Fix the lost nodes list when a nodemanager is lost - The problem with tracking lost nodes is; if the nodemanager joins back; there would be duplicate entries in active and lost nodes with different port numbers. 2. Do not track lost nodemanagers",Resolved,Duplicate,MAPREDUCE-3360,Jason Lowe,Ramya Sunil,Tue; 25 Oct 2011 23:31:13 +0000,Thu; 12 Jan 2012 21:42:09 +0000,Wed; 4 Jan 2012 16:05:35 +0000,,0.23.0,,,MAPREDUCE-3363,https://issues.apache.org/jira/browse/MAPREDUCE-3271
MAPREDUCE-3272,Bug,Critical,mrv2,Lost NMs fail to rejoin,Lost nodemanagers fail to join back.   When the NM is lost; RM log reads   When the NM joins back; RM log reads,Resolved,Duplicate,MAPREDUCE-3034,Jonathan Eagles,Ramya Sunil,Tue; 25 Oct 2011 23:47:18 +0000,Thu; 8 Dec 2011 00:39:48 +0000,Wed; 30 Nov 2011 20:38:14 +0000,,0.23.0,,,MAPREDUCE-3034,https://issues.apache.org/jira/browse/MAPREDUCE-3272
MAPREDUCE-3273,Improvement,Minor,documentation,mapreduce.cluster.adminstrators should be included in mapred-default.xml,nan,Open,Unresolved,,Unassigned,Eli Collins,Wed; 26 Oct 2011 01:18:18 +0000,Tue; 14 May 2013 05:14:44 +0000,,,0.20.205.0,noob,,,https://issues.apache.org/jira/browse/MAPREDUCE-3273
MAPREDUCE-3274,Bug,Blocker,applicationmaster;mrv2,Race condition in MR App Master Preemtion can cause a dead lock,There appears to be a race condition in the MR App Master in relation to preempting reducers to let a mapper run.  In the particular case that I have been debugging a reducer was selected for preemption that did not have a container assigned to it yet. When the container became available that reduce started running and the previous TA_KILL event appears to have been ignored.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 26 Oct 2011 20:48:46 +0000,Mon; 16 Mar 2015 17:57:18 +0000,Sun; 30 Oct 2011 11:34:05 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3274
MAPREDUCE-3275,Improvement,Critical,documentation;mrv2,Add docs for WebAppProxy,In my haste to get the WebAppProxy code in the documentation for it was neglected.  This is to fix that.  Docs need to be added to ClusterSetup.html about how to configure and use the WebAppProxy.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 26 Oct 2011 21:50:31 +0000,Tue; 10 Mar 2015 04:32:05 +0000,Mon; 31 Oct 2011 17:35:09 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3275
MAPREDUCE-3276,Bug,Major,contrib/streaming,hadoop dfs -copyToLocal/copyFromLocal called within Hadoop Streaming returns early,I'm using the Cloudera hadoop realease 0.20.2.+737 to parallelize bash scripts with Hadoop Streaming.  Below is an example script that i've been running which simply copies a file from hdfs to a local node.     Surprisingly; the copy call returns before the file is copied; if the file is sufficiently large; and the while loop spins for several iterations.  I'm seeing similar behavior with copyFromLocal.  I've asked about this issue on other forms and no one else seems to have had the problem; although I don't know how many peoplpe are attempting to do this particular task.  Has this been fixed in more recent versions of hadoop?,Resolved,Later,,Unassigned,Keith Stevens,Wed; 26 Oct 2011 22:04:14 +0000,Tue; 27 Jan 2015 19:27:43 +0000,Tue; 27 Jan 2015 19:27:43 +0000,,0.20.2,hadoop;shell;streaming,,,https://issues.apache.org/jira/browse/MAPREDUCE-3276
MAPREDUCE-3277,Bug,Critical,,TestSeveral is failing in 0.23,Haven't looked into it yet; but TestSeveral has been failing in the 0.23 MR build since 10 24,Resolved,Duplicate,MAPREDUCE-3318,Unassigned,Todd Lipcon,Wed; 26 Oct 2011 23:55:16 +0000,Fri; 4 Nov 2011 07:53:48 +0000,Fri; 4 Nov 2011 07:53:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3277
MAPREDUCE-3278,Improvement,Major,mrv1;performance;task,0.20: avoid a busy-loop in ReduceTask scheduling,"Looking at profiling results; it became clear that the ReduceTask has the following busy-loop which was causing it to suck up 100% of CPU in the fetch phase in some configurations:  	the number of reduce fetcher threads is configured to more than the number of hosts 	therefore ""busyEnough()"" never returns true 	the ""scheduling"" portion of the code can't schedule any new fetches; since all of the pending fetches in the mapLocations buffer correspond to hosts that are already being fetched (the hosts are in the uniqueHosts map) 	getCopyResult() immediately returns null; since there are no completed maps. Hence ReduceTask spins back and forth between trying to schedule things (and failing); and trying to grab completed results (of which there are none); with no waits.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 27 Oct 2011 04:42:15 +0000,Wed; 17 Oct 2012 18:27:26 +0000,Thu; 3 Nov 2011 19:41:26 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3278
MAPREDUCE-3279,Bug,Major,mrv2,TestJobHistoryParsing broken,Broken after 3264; the test was verifying against the default user.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 27 Oct 2011 07:59:27 +0000,Tue; 15 Nov 2011 00:49:58 +0000,Thu; 27 Oct 2011 08:30:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3279
MAPREDUCE-3280,Bug,Major,applicationmaster;mrv2,MR AM should not read the username from configuration,MR AM reads the value for mapreduce.job.user.name from the configuration in several places. It should instead get the app-submitter name from the RM.  Once that is done; we can remove the default value for mapreduce.job.user.name from mapred-default.xml,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 27 Oct 2011 10:31:01 +0000,Mon; 5 Mar 2012 02:48:59 +0000,Thu; 10 Nov 2011 17:31:24 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3280
MAPREDUCE-3281,Bug,Blocker,test,TestLinuxContainerExecutorWithMocks failing on trunk.,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 27 Oct 2011 15:04:53 +0000,Tue; 15 Nov 2011 00:49:06 +0000,Thu; 27 Oct 2011 20:40:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3281
MAPREDUCE-3282,Bug,Critical,mrv2,bin/mapred job -list throws exception,"bin mapred job -list throws exception when mapreduce.framework.name is set to ""yarn""",Closed,Fixed,,Arun C Murthy,Ramya Sunil,Thu; 27 Oct 2011 18:10:52 +0000,Tue; 15 Nov 2011 00:48:29 +0000,Fri; 28 Oct 2011 01:19:31 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3282
MAPREDUCE-3283,Bug,Minor,scripts,mapred classpath CLI does not display the complete classpath,"bin yarn classpath does not display the complete classpath. Below is how the classpath looks like:    ""*"" has to be substituted with the actual jars. Also; $HADOOP_CONF_DIR appears twice in the classpath",Closed,Fixed,,Varun Saxena,Ramya Sunil,Thu; 27 Oct 2011 18:18:15 +0000,Fri; 10 Apr 2015 20:19:44 +0000,Wed; 21 Jan 2015 21:53:42 +0000,,0.23.0;2.6.0,newbie,,HADOOP-7779;HADOOP-10903,https://issues.apache.org/jira/browse/MAPREDUCE-3283
MAPREDUCE-3284,Bug,Major,mrv2,bin/mapred queue fails with JobQueueClient ClassNotFoundException,bin mapred queue fails with the following exception:,Closed,Fixed,,Arun C Murthy,Ramya Sunil,Thu; 27 Oct 2011 18:39:55 +0000,Tue; 15 Nov 2011 00:49:14 +0000,Thu; 27 Oct 2011 23:22:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3284
MAPREDUCE-3285,Bug,Blocker,mrv2,Tests on branch-0.23 failing ,Most are failing with some kerberos login exception:  Running org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks Tests run: 3; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 0.548 sec &lt; FAILURE!  Running org.apache.hadoop.yarn.server.resourcemanager.TestAppManager Tests run: 8; Failures: 0; Errors: 6; Skipped: 0; Time elapsed: 0.125 sec &lt; FAILURE! Running org.apache.hadoop.yarn.server.resourcemanager.TestRMAuditLogger Tests run: 3; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 0.065 sec &lt; FAILURE!  Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationCleanup Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 0.033 sec &lt; FAILURE!  Running org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 0.024 sec &lt; FAILURE!  Running org.apache.hadoop.yarn.server.resourcemanager.TestRM Tests run: 3; Failures: 0; Errors: 3; Skipped: 0; Time elapsed: 0.072 sec &lt; FAILURE! Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 90.167 sec &lt; FAILURE! Running org.apache.hadoop.yarn.server.resourcemanager.TestFifoScheduler Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 0.056 sec &lt; FAILURE!  TestLinuxContainerExecutorWithMocks is tracked via MAPREDUCE-3281,Closed,Fixed,,Siddharth Seth,Arun C Murthy,Thu; 27 Oct 2011 18:53:12 +0000,Tue; 15 Nov 2011 00:49:00 +0000,Fri; 28 Oct 2011 02:24:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3285
MAPREDUCE-3286,Test,Major,mrv2,Unit tests for MAPREDUCE-3186 - User jobs are getting hanged if the Resource manager process goes down and comes up while job is getting executed.,"If the resource manager is restarted while the job execution is in progress; the job is getting hanged. UI shows the job as running. In the RM log; it is throwing an error ""ERROR org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AppAttemptId doesnt exist in cache appattempt_1318579738195_0004_000001"" In the console MRAppMaster and Runjar processes are not getting killed",Resolved,Invalid,,Eric Payne,Eric Payne,Thu; 27 Oct 2011 19:40:16 +0000,Wed; 1 Apr 2015 18:45:27 +0000,Wed; 1 Apr 2015 18:45:27 +0000,,0.23.0,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3286
MAPREDUCE-3287,Bug,Major,documentation,The Watch link on the main page goes to a private video,Link 3 under the Getting Started header takes me to a private video. Due to vimeo's setup I can't determine even what user is hosting the video to contact them personally.,Open,Unresolved,,Unassigned,Jason Mattax,Thu; 27 Oct 2011 22:05:32 +0000,Wed; 4 Jan 2012 02:49:38 +0000,,,,documentation,,,https://issues.apache.org/jira/browse/MAPREDUCE-3287
MAPREDUCE-3288,Bug,Blocker,mrv2,Mapreduce 23 builds failing,Hadoop mapreduce 0.23 builds are failing.,Closed,Fixed,,Mahadev konar,Ramya Sunil,Thu; 27 Oct 2011 23:29:43 +0000,Tue; 15 Nov 2011 00:50:16 +0000,Fri; 28 Oct 2011 04:43:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3288
MAPREDUCE-3289,Improvement,Major,mrv2;nodemanager;performance,Make use of fadvise in the NM's shuffle handler,Using the new NativeIO fadvise functions; we can make the NodeManager prefetch map output before it's send over the socket; and drop it out of the fs cache once it's been sent (since it's very rare for an output to have to be re-sent). This improves IO efficiency and reduces cache pollution.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 28 Oct 2011 00:07:38 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Thu; 2 Aug 2012 22:00:14 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3289
MAPREDUCE-3290,Bug,Major,mrv2,list-active-trackers throws NPE,bin mapred -list-active-trackers throws NPE in mrV2. Trace in the next comment.,Closed,Fixed,,Arun C Murthy,Ramya Sunil,Fri; 28 Oct 2011 01:09:49 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Fri; 28 Oct 2011 05:44:50 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3290
MAPREDUCE-3291,Bug,Blocker,mrv2,App fail to launch due to delegation token not found in cache,"In secure mode; saw an app failure due to ""org.apache.hadoop.security.token.SecretManager$InvalidToken: token (HDFS_DELEGATION_TOKEN token id for user) can't be found in cache"" Exception in the next comment.",Closed,Fixed,,Robert Joseph Evans,Ramya Sunil,Fri; 28 Oct 2011 01:55:08 +0000,Wed; 11 Jan 2012 05:54:07 +0000,Sun; 6 Nov 2011 23:08:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3291
MAPREDUCE-3292,Bug,Critical,mrv2,In secure mode job submission fails with Provider org.apache.hadoop.mapreduce.security.token.JobTokenIndentifier$Renewer not found.,This happens when you submit a job to a secure cluster. Also; its only the first time the error shows up. On the next submission of the job; the job passes.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 28 Oct 2011 02:00:36 +0000,Tue; 15 Nov 2011 00:50:13 +0000,Fri; 28 Oct 2011 06:15:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3292
MAPREDUCE-3293,Bug,Major,mrv2,Reason for application failure is not correctly reported,"When apps fail; the reason for failure is not correctly reflected in the UI. For one such app failure; the UI reports ""Application appID failed 1 times due to . Failing the application."" which is not very helpful.",Resolved,Incomplete,,Unassigned,Ramya Sunil,Fri; 28 Oct 2011 02:14:33 +0000,Mon; 9 Mar 2015 21:43:02 +0000,Mon; 9 Mar 2015 21:43:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3293
MAPREDUCE-3294,Improvement,Major,mrv2,Log the reason for killing a task during speculative execution,"The reason for killing a speculated task has to be logged. Currently; a speculated task is killed with a note of ""Container killed by the ApplicationMaster. Container killed on request. Exit code is 137"" which is not very useful. Better logging of this message stating the task was killed due to completion of its speculative task would be useful.  Also; this message is lost once the app is moved to history. All we are left with is a list of killed tasks without a reason being notified to the user.",Resolved,Duplicate,MAPREDUCE-5692,Unassigned,Ramya Sunil,Fri; 28 Oct 2011 02:52:01 +0000,Mon; 20 Jun 2016 21:40:47 +0000,Mon; 20 Jun 2016 21:40:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3294
MAPREDUCE-3295,Bug,Critical,,TestAMAuthorization failing on branch 0.23.,The test seems to fail both on Mac and linux. Trace in the next comment.,Closed,Fixed,,Unassigned,Mahadev konar,Fri; 28 Oct 2011 04:35:50 +0000,Tue; 15 Nov 2011 00:48:35 +0000,Fri; 28 Oct 2011 20:02:21 +0000,,0.23.0,,HADOOP-7741,,https://issues.apache.org/jira/browse/MAPREDUCE-3295
MAPREDUCE-3296,Bug,Major,build,Pending(9) findBugs warnings,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 28 Oct 2011 05:34:58 +0000,Tue; 15 Nov 2011 00:48:21 +0000,Fri; 28 Oct 2011 07:44:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3296
MAPREDUCE-3297,Task,Major,mrv2,Move Log Related components from yarn-server-nodemanager to yarn-common,or to a separate module.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 28 Oct 2011 08:46:01 +0000,Mon; 5 Mar 2012 02:48:44 +0000,Thu; 3 Nov 2011 08:08:00 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3297
MAPREDUCE-3298,Improvement,Major,mrv2,Improvements to the aggregated log format,"allow easier access to different log types. 	store information about containers which may have been skipped because of the aggregation policy. 	add a comparator etc.",Open,Unresolved,,Siddharth Seth,Siddharth Seth,Fri; 28 Oct 2011 08:48:04 +0000,Sun; 26 Feb 2012 05:44:10 +0000,,,0.23.0,,,MAPREDUCE-3143,https://issues.apache.org/jira/browse/MAPREDUCE-3298
MAPREDUCE-3299,Improvement,Minor,mrv2,Add AMInfo table to the AM job page,JobHistory has a table to list all AMs. A similar table can be added to the AM for info on past failed AMs and the current running one.,Closed,Fixed,,Jonathan Eagles,Siddharth Seth,Fri; 28 Oct 2011 08:49:49 +0000,Mon; 5 Mar 2012 02:49:34 +0000,Tue; 10 Jan 2012 22:28:40 +0000,,0.23.0,,,MAPREDUCE-3350,https://issues.apache.org/jira/browse/MAPREDUCE-3299
YARN-197,New Feature,Major,,Add a separate log server,Currently; the job history server is being used for log serving. A separate log server can be added which can deal with serving logs; along with other functionality like log retention; merging; etc.,Resolved,Won't Fix,,Unassigned,Siddharth Seth,Fri; 28 Oct 2011 08:52:42 +0000,Fri; 1 May 2015 20:30:09 +0000,Fri; 1 May 2015 20:30:09 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-197
YARN-194,Bug,Major,nodemanager,Log handling in case of NM restart.,Currently; if an NM restarts - existing logs will be left around till they're manually cleaned up. The NM could be improved to handle these files.,Reopened,Unresolved,YARN-1313,Omkar Vinit Joshi,Siddharth Seth,Fri; 28 Oct 2011 08:54:36 +0000,Wed; 16 Oct 2013 13:24:14 +0000,,,0.23.4,,,YARN-592;YARN-71,https://issues.apache.org/jira/browse/YARN-194
MAPREDUCE-3302,Improvement,Minor,client,Remove the last dependency call from org.apache.hadoop.record package in MR.,SecureShuffleUtils provides the following helper:     The Utils class used there is org.apache.hadoop.record.Utils. With the record common package going away via HADOOP-7781; the internal (and also deprecated on the whole) compareBytes utility must be moved elsewhere.  The Utils#compareBytes contains:     Which looks like it can be replaced inline; as it appears to be a dummy wrapper call. I'll put up a patch with this inline replacement shortly for review.,Resolved,Fixed,,Harsh J,Harsh J,Fri; 28 Oct 2011 10:54:40 +0000,Thu; 12 May 2016 18:23:15 +0000,Fri; 25 May 2012 13:22:06 +0000,,3.0.0-alpha1,,HADOOP-7781,,https://issues.apache.org/jira/browse/MAPREDUCE-3302
MAPREDUCE-3303,Task,Minor,,MR part of removing RecordIO (HADOOP-7781),This is the MR part of removing deprecated RecordIO packages - parented by HADOOP-7781.  Basically; we need to remove  avro.apache.org),Resolved,Invalid,,Harsh J,Harsh J,Fri; 28 Oct 2011 14:23:59 +0000,Mon; 28 Sep 2015 21:10:33 +0000,Sun; 11 Dec 2011 20:25:36 +0000,,0.23.0,,HADOOP-7781,,https://issues.apache.org/jira/browse/MAPREDUCE-3303
MAPREDUCE-3304,Bug,Major,mrv2;test,TestRMContainerAllocator#testBlackListedNodes fails intermittently,Thanks to Hitesh for verifying!  The heartbeat event should be drained before the schedule call.  Hitesh  I can see this test fail intermittently on my Mac OSX 10.5 and Fedora 14 machines.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 28 Oct 2011 14:46:04 +0000,Tue; 15 Nov 2011 00:48:12 +0000,Fri; 28 Oct 2011 18:46:59 +0000,,0.23.0,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3304
YARN-3315,Bug,Major,,Fix -list-blacklisted-trackers to print the blacklisted NMs,"bin mapred job -list-blacklisted-trackers currently prints ""getBlacklistedTrackers - Not implemented yet"" This is a long pending issue.  Could not find a tracking ticket; hence opening one.",Resolved,Not A Problem,,Unassigned,Ramya Sunil,Fri; 28 Oct 2011 16:39:46 +0000,Mon; 29 Jun 2015 11:43:45 +0000,Mon; 29 Jun 2015 11:43:45 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-3315
MAPREDUCE-3306,Bug,Blocker,mrv2;nodemanager,Cannot run apps after MAPREDUCE-2989,Seeing this in NM logs when trying to run jobs.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 28 Oct 2011 16:59:34 +0000,Tue; 15 Nov 2011 00:48:12 +0000,Fri; 28 Oct 2011 19:53:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3306
MAPREDUCE-3307,Improvement,Blocker,mrv2,Improve logging on the console during job execution,There is a lot of redundant information being printed on the console and a not so intuitive flow of events. We should improve the logging on console during job execution. More details in the next comment.,Resolved,Duplicate,MAPREDUCE-3265,Arun C Murthy,Ramya Sunil,Fri; 28 Oct 2011 19:13:32 +0000,Mon; 21 Nov 2011 19:55:24 +0000,Mon; 21 Nov 2011 19:55:24 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3307
MAPREDUCE-3308,Bug,Critical,mrv2,MR builds failing due to download failure,"MR builds are failing due to unresolved dependencies.  ivy:resolve :: problems summary :: ivy:resolve :::: WARNINGS ivy:resolve 		FAILED      org.apache.commons#commons-daemon;1.0.3!commons-daemon.jar:  (0ms) ivy:resolve 	==== fs: tried ivy:resolve 	   commons-daemon-1.0.3.jar ivy:resolve 		:::::::::::::::::::::::::::::::::::::::::::::: ivy:resolve 		::              FAILED DOWNLOADS            :: ivy:resolve 		:: ^ see resolution messages for details  ^ :: ivy:resolve 		:::::::::::::::::::::::::::::::::::::::::::::: ivy:resolve 		:: org.apache.commons#commons-daemon;1.0.3!commons-daemon.jar ivy:resolve 		:::::::::::::::::::::::::::::::::::::::::::::: ivy:resolve  ivy:resolve :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS",Resolved,Not A Problem,,Giridharan Kesavan,Ramya Sunil,Fri; 28 Oct 2011 21:53:38 +0000,Wed; 8 Feb 2012 02:53:22 +0000,Wed; 8 Feb 2012 02:53:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3308
MAPREDUCE-3309,Improvement,Major,mrv2,Report the AM of an application in the UI,Make provision to report the AM hostname of an application in the RM local dirs (MAPREDUCE-2793); debugging is all the more harder.,Resolved,Won't Fix,,Jonathan Eagles,Ramya Sunil,Fri; 28 Oct 2011 22:14:41 +0000,Wed; 16 Nov 2011 17:32:31 +0000,Wed; 16 Nov 2011 17:32:31 +0000,,0.23.0,,MAPREDUCE-3342,,https://issues.apache.org/jira/browse/MAPREDUCE-3309
MAPREDUCE-3310,Improvement,Major,client,Custom grouping comparator cannot be set for Combiners,Combiners are often described as 'Reducers running on the Map side'.  As Reducers; Combiners are fed K; {V}; where {V}  is built by grouping values associated with the 'same' key.  For Reducers; the comparator used for grouping values can be set independently of that used to sort the keys (using Job.setGroupingComparatorClass).  Such a configuration is not possible for Combiners; meaning some things done in Reducers cannot be done in Combiners (such as secondary sort).  It would be handy to have a Job.setCombinerGroupingComparatorClass method that would allow the setting of the grouping comparator used when applying a Combiner.,Closed,Fixed,,Alejandro Abdelnur,Mathias Herberts,Sat; 29 Oct 2011 17:22:38 +0000,Mon; 24 Feb 2014 20:58:20 +0000,Mon; 6 Jan 2014 18:46:59 +0000,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3310
MAPREDUCE-3311,Task,Major,build,Bump jetty to 6.1.26,MapReduce part of HADOOP-7450,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Sat; 29 Oct 2011 22:48:56 +0000,Thu; 2 May 2013 02:29:45 +0000,Thu; 17 Nov 2011 01:46:54 +0000,,0.22.0,,MAPREDUCE-3396,,https://issues.apache.org/jira/browse/MAPREDUCE-3311
MAPREDUCE-3312,Bug,Major,mrv2,Make MR AM not send a stopContainer w/o corresponding start container,This is a follow on to MAPREDUCE-3274.  It is possible; although rare; for the MR AM to send a stop container before it sends a start container.  This needs to stop that from happening.  If a stop is found first it should prevent the start from being sent.  It tries to do this; but only if the stop is currently pending.,Closed,Fixed,MAPREDUCE-3622,Robert Joseph Evans,Robert Joseph Evans,Sun; 30 Oct 2011 00:21:35 +0000,Tue; 10 Mar 2015 04:32:23 +0000,Tue; 10 Jan 2012 02:17:23 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3312
MAPREDUCE-3313,Bug,Blocker,mrv2;test,TestResourceTrackerService failing in trunk some times,TestResourceTrackerService is failing in trunk sometimes with the following error:  testDecommissionWithIncludeHosts(org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService)  Time elapsed: 0.876 sec  &lt; ERROR!  70),Closed,Fixed,,Hitesh Shah,Ravi Gummadi,Sun; 30 Oct 2011 15:51:58 +0000,Tue; 15 Nov 2011 00:49:31 +0000,Mon; 31 Oct 2011 03:33:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3313
YARN-195,Sub-task,Major,resourcemanager,AM should have a way of telling RM to not allocate containers on some nodes,The AM blacklists certain nodes due to task failures but the RM does not know of this and can allocate blacklisted nodes to the AM again and again.   RM should support a protocol that allows AM to inform the RM of nodes that it should not allocate to it.,Resolved,Fixed,,Hitesh Shah,Hitesh Shah,Mon; 31 Oct 2011 05:07:52 +0000,Wed; 24 Jul 2013 18:03:31 +0000,Wed; 24 Jul 2013 18:03:31 +0000,,0.23.4,,,YARN-398,https://issues.apache.org/jira/browse/YARN-195
YARN-3307,New Feature,Major,,Master-Worker Application on YARN,Currently master worker scenarios are forced fit into Map-Reduce. Now with YARN; these can be first class and would benefit real near realtime workloads and be more effective in using the cluster resources.,Open,Unresolved,,Sharad Agarwal,Sharad Agarwal,Mon; 31 Oct 2011 10:30:45 +0000,Thu; 12 May 2016 18:30:30 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-3307
MAPREDUCE-3316,Bug,Major,resourcemanager,Rebooted link is not working properly,While clicking on the Rebooted Nodes link; it is showing the following error message              Sorry; got error 500,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Mon; 31 Oct 2011 12:42:52 +0000,Tue; 15 Nov 2011 00:48:59 +0000,Tue; 1 Nov 2011 04:09:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3316
MAPREDUCE-3317,Bug,Major,tools/rumen,Rumen TraceBuilder is emiting null as hostname,Trace generated by Rumen TraceBuilder contains null as hostname even though hostName and rackName are seen in history file. This is after MAPREDUCE-3035.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 31 Oct 2011 17:48:24 +0000,Tue; 15 Nov 2011 00:49:21 +0000,Tue; 1 Nov 2011 04:33:57 +0000,,0.23.0,,,MAPREDUCE-3035,https://issues.apache.org/jira/browse/MAPREDUCE-3317
MAPREDUCE-3318,Sub-task,Major,mrv2,ant test TestSeveral timing out in commit builds,nan,Resolved,Fixed,MAPREDUCE-3277,Unassigned,Hitesh Shah,Mon; 31 Oct 2011 21:00:18 +0000,Mon; 9 Mar 2015 21:46:13 +0000,Mon; 9 Mar 2015 21:46:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3318
MAPREDUCE-3319,Bug,Blocker,examples,multifilewc from hadoop examples seems to be broken in 0.20.205.0,nan,Closed,Fixed,,Subroto Sanyal,Roman Shaposhnik,Mon; 31 Oct 2011 21:41:36 +0000,Wed; 28 Dec 2011 10:03:29 +0000,Thu; 15 Dec 2011 09:10:57 +0000,,0.20.205.0,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3319
MAPREDUCE-3320,Bug,Major,mrv2,Error conditions in web apps should stop pages from rendering.,There are several places in the web apps where an error condition should short circuit the page from rendering; but it does not.  Ideally the web app framework should be extended to support exceptions similar to Jersey that can have an HTTP return code associated with them.  Then all of the places that produce custom error pages can just throw these exceptions instead.,Resolved,Invalid,,Robert Joseph Evans,Robert Joseph Evans,Tue; 1 Nov 2011 00:47:55 +0000,Tue; 10 Mar 2015 04:31:54 +0000,Thu; 26 Jul 2012 20:16:14 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3320
MAPREDUCE-3321,Bug,Minor,mrv2,Disable some failing legacy tests for MRv2 builds to go through,By-product of MR-3214. Disable tests for the short term until fixes are available for all tests.,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Tue; 1 Nov 2011 00:52:10 +0000,Tue; 15 Nov 2011 00:49:23 +0000,Tue; 1 Nov 2011 00:59:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3321
MAPREDUCE-3322,Improvement,Major,documentation;mrv2,Create a better index.html for maven docs,Create a better index.html for maven docs.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 1 Nov 2011 01:16:57 +0000,Tue; 15 Nov 2011 00:48:20 +0000,Tue; 1 Nov 2011 02:02:08 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3322
MAPREDUCE-3323,Improvement,Major,distributed-cache;tasktracker,Add new interface for Distributed Cache; which special  for Map or Reduce;but not Both.,We put some file into Distributed Cache; but sometimes; only Map or Reduce use thses cached files; not useful for both. but TaskTracker always download cached files from HDFS; if there are some little bit big files in cache; it's time expensive.  so; this patch add some new API in the DistributedCache. as follow:  addArchiveToClassPathForMap addArchiveToClassPathForReduce  addFileToClassPathForMap addFileToClassPathForReduce  addCacheFileForMap addCacheFileForReduce  addCacheArchiveForMap addCacheArchiveForReduce   New API doesn't affect original interface. User can use these features like the following two methods:  1)  hadoop job **** -files file1 -mapfiles file2 -reducefiles file3 -archives arc1 -maparchives arc2 -reduce archives arc3  2) DistributedCache.addCacheFile(conf; file1); DistributedCache.addCacheFileForMap(conf; file2); DistributedCache.addCacheFileForReduce(conf; file3);  DistributedCache.addCacheArchives(conf; arc1); DistributedCache.addCacheArchivesForMap(conf; arc2); DistributedCache.addCacheFArchivesForReduce(conf; arc3);   These two methods have the same result; That's mean:   You put six files to the distributed cache: file1 ~ file3; arc1 ~ arc3;  but file1 and arc1 are cached for both map and reduce; file2 and arc2 are only cached for map; file3 and arc3 are only cached for reduce;,Resolved,Won't Fix,,Unassigned,Azuryy(Chijiong),Tue; 1 Nov 2011 08:26:11 +0000,Tue; 10 Mar 2015 03:06:03 +0000,Tue; 10 Mar 2015 03:06:03 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3323
MAPREDUCE-3324,Bug,Critical,jobhistoryserver;mrv2;nodemanager,Not All HttpServer tools links (stacks;logs;config;metrics) are accessible through all UI servers,Nodemanager has no tools listed under tools UI. Jobhistory server has no logs tool listed under tools UI.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Tue; 1 Nov 2011 16:52:36 +0000,Mon; 5 Mar 2012 02:49:55 +0000,Mon; 14 Nov 2011 21:32:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3324
MAPREDUCE-3325,Improvement,Major,mrv2,Improvements to CapacityScheduler doc,"I noticed the following issues with the capacity scheduler doc: . rmadmin -refreshQueues""",Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 1 Nov 2011 17:39:50 +0000,Mon; 5 Mar 2012 02:49:45 +0000,Mon; 14 Nov 2011 22:04:04 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3325
MAPREDUCE-3326,Bug,Critical,mrv2,RM web UI scheduler link not as useful as should be,The resource manager web ui page for scheduler doesn't have all the information about the configuration like the jobtracker page used to have.  The things it seems to show you are the current queues - each queues used; set; and max percent and then what apps are running in that queue.    It doesn't list any of yarn.scheduler.capacity.maximum-applications; yarn.scheduler.capacity.maximum-am-resource-percent; yarn.scheduler.capacity.queue-path.user-limit-factor; yarn.scheduler.capacity.queue-path.minimum-user-limit-percent; queue state; active users and percent used by user,Closed,Fixed,,Jason Lowe,Thomas Graves,Tue; 1 Nov 2011 17:45:30 +0000,Tue; 10 Mar 2015 04:31:46 +0000,Thu; 5 Jan 2012 19:53:27 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3326
MAPREDUCE-3327,Bug,Critical,mrv2,RM web ui scheduler link doesn't show correct max value for queues,Configure a cluster to use the capacity scheduler and then specifying a maximum-capacity  100% for a queue.  If you go to the RM Web UI and hover over the queue; it always shows the max at 100%.,Closed,Fixed,,Anupam Seth,Thomas Graves,Tue; 1 Nov 2011 20:20:25 +0000,Mon; 5 Mar 2012 02:48:48 +0000,Fri; 9 Dec 2011 01:44:47 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3327
MAPREDUCE-3328,Bug,Critical,mrv2,mapred queue -list output inconsistent and missing child queues,"When running mapred queue -list on a 0.23.0 cluster with capacity scheduler configured with child queues.  In my case I have queues default; test1; and test2.  test1 has subqueues of a1; a2.  test2 has subqueues of a3 and a4.   	the child queues do not show up 	The output of maximum capacity doesn't match the format of the current capacity and capacity.  the latter two use float while the maximum is specified as int:    Queue Name : default  Queue State : running  Scheduling Info : queueName: ""default""; capacity: 0.7; maximumCapacity: 90.0; currentCapacity: 0.0; state: Q_RUNNING;   ====================== Queue Name : test  Queue State : running  Scheduling Info : queueName: ""test""; capacity: 0.2; maximumCapacity: -1.0; currentCapacity: 0.0; state: Q_RUNNING;   ====================== Queue Name : test2  Queue State : running  Scheduling Info : queueName: ""test2""; capacity: 0.1; maximumCapacity: 5.0; currentCapacity: 0.0; state: Q_RUNNING;   ======================   here default is configured to have capacity=70% and maximum capacity = 90%",Closed,Fixed,,Ravi Prakash,Thomas Graves,Tue; 1 Nov 2011 20:35:58 +0000,Mon; 5 Mar 2012 02:49:19 +0000,Mon; 12 Dec 2011 23:59:52 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3328
MAPREDUCE-3329,Bug,Blocker,mrv2,capacity schedule maximum-capacity allowed to be less then capacity,"When configuring the capacity scheduler capacity and maximum-capacity; it allows the maximum-capacity to be less then the capacity.  I did not test to see what true limit is; I assume maximum capacity.  output from mapred queue -list where capacity = 10%; max capacity = 5%.  Queue Name : test2  Queue State : running  Scheduling Info : queueName: ""test2""; capacity: 0.1; maximumCapacity: 5.0; currentCapacity: 0.0; state: Q_RUNNING;",Closed,Fixed,,Arun C Murthy,Thomas Graves,Tue; 1 Nov 2011 20:41:22 +0000,Mon; 5 Mar 2012 02:49:27 +0000,Wed; 23 Nov 2011 01:47:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3329
MAPREDUCE-3330,Bug,Minor,mrv2,resources/capacity-scheduler.xml description of user-limit-factor is wrong,The description of user-limit-factor is wrong in hadoop-yarn property,Open,Unresolved,,Unassigned,Thomas Graves,Tue; 1 Nov 2011 20:55:13 +0000,Tue; 1 Nov 2011 20:55:13 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3330
MAPREDUCE-3331,Improvement,Minor,mrv2,Improvement to single node cluster setup documentation for 0.23,This JIRA is to track some minor corrections and suggestions for improvement for the documentation for the setup of a single node cluster using 0.23 currently available at http: SingleCluster.html,Closed,Fixed,,Anupam Seth,Anupam Seth,Tue; 1 Nov 2011 22:15:27 +0000,Mon; 5 Mar 2012 02:49:18 +0000,Tue; 15 Nov 2011 02:07:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3331
MAPREDUCE-3332,Bug,Trivial,contrib/raid,contrib/raid compile breaks due to changes in hdfs/protocol/datatransfer/Sender#writeBlock related to checksum handling ,                         ^,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Tue; 1 Nov 2011 22:49:17 +0000,Tue; 15 Nov 2011 00:48:14 +0000,Tue; 1 Nov 2011 23:10:57 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3332
MAPREDUCE-3333,Bug,Blocker,applicationmaster;mrv2,MR AM for sort-job going out of memory,Karam Singh just found this. The usual sort job on a 350 node cluster hung due to OutOfMemory and eventually failed after an hour instead of the usual odd 20 minutes.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 2 Nov 2011 14:00:54 +0000,Fri; 18 Jul 2014 14:05:27 +0000,Wed; 9 Nov 2011 13:46:34 +0000,,0.23.0,,MAPREDUCE-3355,YARN-2314;HADOOP-7317,https://issues.apache.org/jira/browse/MAPREDUCE-3333
MAPREDUCE-3334,Improvement,Minor,,TaskRunner should log its activities,TaskRunner has little to no information that it logs; making it impossible to debug when something goes wrong.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Wed; 2 Nov 2011 17:19:24 +0000,Wed; 2 Nov 2011 19:03:29 +0000,Wed; 2 Nov 2011 19:03:29 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3334
MAPREDUCE-3335,Bug,Major,build,rat check seems to be broken,The rat check seems broken; we don't get warned for files without license headers.,Resolved,Won't Fix,,Unassigned,Arun C Murthy,Wed; 2 Nov 2011 17:48:02 +0000,Mon; 9 Mar 2015 21:47:46 +0000,Mon; 9 Mar 2015 21:47:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3335
MAPREDUCE-3336,Bug,Critical,mrv2,com.google.inject.internal.Preconditions not public api - shouldn't be using it,com.google.inject.internal.Preconditions does not exist in guice 3.0 and from in guice 2.0 it was an internal api and shouldn't have been used.   We should use com.google.common.base.Preconditions instead.  This is currently being used in hadoop-mapreduce-project  ,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 2 Nov 2011 21:35:43 +0000,Mon; 5 Mar 2012 02:48:53 +0000,Wed; 9 Nov 2011 12:43:18 +0000,,0.23.0,,MAPREDUCE-2863,,https://issues.apache.org/jira/browse/MAPREDUCE-3336
MAPREDUCE-3337,Bug,Blocker,mrv2,Missing license headers for some files,Missing apache license headers for some files,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 3 Nov 2011 06:37:32 +0000,Tue; 15 Nov 2011 00:50:10 +0000,Thu; 3 Nov 2011 07:17:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3337
MAPREDUCE-3338,Bug,Major,mrv2;test,Remove hardcoded version of mr-app jar from the tests,MiniMRYarnCluster and its related tests; and TestDistributedShell depend on a hard-coded version of mr-app jar. We need to figure out if we can avoid this. Otherwise; for every release; we have to keep changing these files manually - a pain.,Resolved,Duplicate,MAPREDUCE-3370,Ahmed Radwan,Vinod Kumar Vavilapalli,Thu; 3 Nov 2011 08:14:49 +0000,Wed; 9 Nov 2011 12:26:09 +0000,Wed; 9 Nov 2011 12:25:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3338
MAPREDUCE-3339,Bug,Blocker,mrv2,Job is getting hanged indefinitely;if the child processes are killed on the NM.  KILL_CONTAINER eventtype is continuosly sent to the containers that are not existing,I have only one NM running. I have submitted a job and all the child processes on the NM got killed continuosly.This made the Job to hang indefinitely.  In the NM logs it is logging WARN message :org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: KILL_CONTAINER sent to absent container container_1320301910500_0004_01_001359,Closed,Fixed,,Siddharth Seth,Ramgopal N,Thu; 3 Nov 2011 10:03:04 +0000,Thu; 3 Oct 2013 20:44:37 +0000,Tue; 20 Dec 2011 23:28:23 +0000,,0.23.0,,,MAPREDUCE-5559,https://issues.apache.org/jira/browse/MAPREDUCE-3339
MAPREDUCE-3340,Bug,Major,mrv2,Deprecate Job.setJobSetupCleanupNeeded(),We should deprecate the setJobSetupCleanupNeeded() API. It was originally added for performance reasons to avoid launching new JVMs altogether for job-setup and job-cleanup. With Yarn and MRAppMaster; setup and cleanup are run inside the AM itself and so nothing much can be gained by making them optional.  Before 0.23; we could disable set up and cleanup; yet obtain the output when using FileOutputCommitter in the job-output directory. But post 0.23.0; that won't be the case because of the nested temporary directories to support AM recoverability. So it makes sense to not have cleanupJob optional.,Open,Unresolved,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 3 Nov 2011 13:46:16 +0000,Thu; 12 May 2016 18:24:29 +0000,,,0.23.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3340
MAPREDUCE-3341,Improvement,Major,mrv2,Enhance logging of initalized queue limit values,"Currently the RM log shows only a partial set of the limits that are configured when a queue is initialized   reinitialized.  For example; this is what is currently shown in the RM log for an initialized queue:  	datestamp INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default; capacity=0.25; asboluteCapacity=0.25; maxCapacity=25.0; asboluteMaxCapacity=0.25; userLimit=100; userLimitFactor=20.0; maxApplications=2500; maxApplicationsPerUser=50000; state=RUNNING; acls=ADMINISTER_QUEUE:SUBMIT_JOB:*ADMINISTER_JOBS:    Breaking down the line above; shows:   capacity=0.25 asboluteCapacity=0.25 maxCapacity=25.0 asboluteMaxCapacity=0.25 userLimit=100 userLimitFactor=20.0 maxApplications=2500 maxApplicationsPerUser=50000  It might be nice if we could include more information such as maxActiveApplications; maxActiveApplicationsPerUser; utilization; and usedCapacity along with information on how each of these is computed (i.e. formulae used) (Thanks to Phil Su for requesting this).",Closed,Fixed,,Anupam Seth,Anupam Seth,Thu; 3 Nov 2011 15:49:23 +0000,Mon; 5 Mar 2012 02:49:50 +0000,Mon; 14 Nov 2011 22:41:26 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3341
MAPREDUCE-3342,Bug,Critical,jobhistoryserver;mrv2,JobHistoryServer doesn't show job queue,The job history server doesn't show the queue the jobwas run in.  It is inserted into the job history file.  It seems like this should be part of the Job interface.  JobImpl current gets it from the job config to insert into the history.,Closed,Fixed,,Jonathan Eagles,Thomas Graves,Thu; 3 Nov 2011 21:52:04 +0000,Mon; 5 Mar 2012 02:49:45 +0000,Tue; 8 Nov 2011 07:31:41 +0000,,0.23.0,,MAPREDUCE-3309;MAPREDUCE-2863,,https://issues.apache.org/jira/browse/MAPREDUCE-3342
MAPREDUCE-3343,Bug,Major,mrv1,TaskTracker Out of Memory because of distributed cache,This Out of Memory happens when you run large number of jobs (using the distributed cache) on a TaskTracker.   Seems the basic issue is with the distributedCacheManager (instance of TrackerDistributedCacheManager in TaskTracker. ; this gets created during TaskTracker.initialize(); and it keeps references to TaskDistributedCacheManager for every submitted job via the jobArchives Map; also references to CacheStatus via cachedArchives map. I am not seeing these cleaned up between jobs; so this can out of memory problems after really large number of jobs are submitted. We have seen this issue in a number of cases.,Closed,Fixed,,yunjiong zhao,Ahmed Radwan,Thu; 3 Nov 2011 23:42:04 +0000,Sun; 18 Mar 2012 06:12:12 +0000,Mon; 28 Nov 2011 09:23:42 +0000,,0.20.205.0,mapreduce;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3343
MAPREDUCE-3344,Bug,Major,,o.a.h.mapreduce.Reducer since 0.21 blindly casts to ReduceContext.ValueIterator,0.21 mapreduce.Reducer introduced a blind cast to ReduceContext.ValueIterator. There should an instanceof check around this block to ensure we don't throw a CastClassException:,Closed,Fixed,,Brock Noland,Brock Noland,Fri; 4 Nov 2011 02:01:57 +0000,Tue; 10 Mar 2015 04:32:57 +0000,Mon; 7 Nov 2011 20:18:21 +0000,,0.21.0;0.22.0;0.23.0;0.23.1;2.0.0-alpha,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-3344
MAPREDUCE-3345,Bug,Major,mrv2;resourcemanager,Race condition in ResourceManager causing TestContainerManagerSecurity to fail sometimes,See https: ,Closed,Fixed,,Hitesh Shah,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 09:05:06 +0000,Mon; 5 Mar 2012 02:49:33 +0000,Tue; 8 Nov 2011 07:58:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3345
MAPREDUCE-3346,Bug,Blocker,tools/rumen,Rumen LoggedTaskAttempt  getHostName call returns hostname as null,After MAPREDUCE-3035 and MAPREDUCE-3317 Now MRV2 job history contains hostName and rackName. when rumen trace builder is ran on jobhistory; its generated trace contains hostname in form of  hostName :  hostname  But getHostName for LoggedTaskAttempt returns hostname as null Seems that TraceBuilder is setting hostName properly but JobTraceReader is not able read it.,Closed,Fixed,,Amar Kamat,Karam Singh,Fri; 4 Nov 2011 10:01:17 +0000,Mon; 5 Mar 2012 02:48:37 +0000,Tue; 8 Nov 2011 04:49:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3346
MAPREDUCE-3347,Bug,Major,mrv2,Resource manager is not respawning MRAppMaster process if it goes down in the middle of job execution and the job is getting failed.,ApplicationMaster service should recover the job if MRAppMaster process goes down in the middle of job execution.If not MRAppMaster process becomes the single point of failure for the job and losses the advantage of MRV1 framework.,Resolved,Invalid,,Unassigned,Ramgopal N,Fri; 4 Nov 2011 11:06:54 +0000,Sat; 5 Nov 2011 04:58:37 +0000,Sat; 5 Nov 2011 04:58:37 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3347
MAPREDUCE-3348,Bug,Major,mrv2,mapred job -status fails to give info even if the job is present in History,It is trying to get the app report from the RM  for the job; RM throws exception when it doesn't find and then it is giving the same exception without trying from History Server.,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 4 Nov 2011 12:29:10 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Fri; 9 Mar 2012 18:55:42 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3348
MAPREDUCE-3349,Bug,Blocker,mrv2,No rack-name logged in JobHistory for unsuccessful tasks,Found this while running jobs on a cluster with Karam Singh.  This is because TaskAttemptUnsuccessfulCompletionEvent history record doesn't have a rack field.,Closed,Fixed,MAPREDUCE-3381,Amar Kamat,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 12:39:42 +0000,Mon; 5 Mar 2012 02:49:06 +0000,Wed; 21 Dec 2011 03:13:23 +0000,,0.23.0,hostname;rackname;rumen;unsuccessful,,,https://issues.apache.org/jira/browse/MAPREDUCE-3349
MAPREDUCE-3350,Bug,Critical,mrv2;webapps,Per-app RM page should have the list of application-attempts like on the app JHS page,nan,Closed,Fixed,,Jonathan Eagles,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 12:48:33 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Mon; 4 Jun 2012 17:44:23 +0000,,0.23.0,,,MAPREDUCE-3299,https://issues.apache.org/jira/browse/MAPREDUCE-3350
MAPREDUCE-3351,Bug,Major,applicationmaster;mrv2,TaskAttempt's state string is not consumed by MR AM web-UI,Jobs like random-writer use the state string to report the amount of work they have completed. JT used to print this on UI; AM webapp should do the same.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 12:50:09 +0000,Mon; 9 Mar 2015 21:50:28 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3351
MAPREDUCE-3352,Bug,Major,mrv2,Separate installation of mapreduce libraries from YARN_HOME,Time and again; I am running into scenarios where I just want to fix bugs in mapreduce app; replace the mapreduce libraries without bringing down YARN daemons and NM installation.  Today; we have separate HADOOP_MAPRED_HOME and YARN_HOME; but the installation directory is the same. We need to separate this.  We will need this eventually anyways; as MR is strictly a user-land library; just like PIG; HIVE etc.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 13:03:00 +0000,Fri; 4 Nov 2011 13:03:00 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3352
MAPREDUCE-3353,Bug,Major,applicationmaster;mrv2;resourcemanager,Need a RM->AM channel to inform AMs about faulty/unhealthy/lost nodes,When a node gets lost or turns faulty; AM needs to know about that event so that it can take some action like for e.g. re-executing map tasks whose intermediate output live on that faulty node.,Closed,Fixed,,Bikas Saha,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 13:14:51 +0000,Tue; 10 Mar 2015 04:31:03 +0000,Mon; 26 Mar 2012 05:48:39 +0000,,0.23.0,,MAPREDUCE-3921,,https://issues.apache.org/jira/browse/MAPREDUCE-3353
MAPREDUCE-3354,Bug,Blocker,jobhistoryserver;mrv2,JobHistoryServer should be started by bin/mapred and not by bin/yarn,JobHistoryServer belongs to mapreduce land.,Closed,Fixed,,Jonathan Eagles,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 13:20:03 +0000,Mon; 5 Mar 2012 02:48:48 +0000,Mon; 6 Feb 2012 23:13:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3354
MAPREDUCE-3355,Bug,Blocker,applicationmaster;mrv2,AM scheduling hangs frequently with sort job on 350 nodes,Another collaboration with Karam Singh. Sort job hangs not so rarely on a 350 node cluster. Found this in AM logs:,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 4 Nov 2011 13:48:54 +0000,Mon; 5 Mar 2012 02:48:37 +0000,Wed; 16 Nov 2011 15:40:28 +0000,,0.23.0,,MAPREDUCE-3333,,https://issues.apache.org/jira/browse/MAPREDUCE-3355
MAPREDUCE-3356,Bug,Major,distributed-cache;test,TestTrackerDistributedCacheManager fails on branch-20-security,The testReferenceCount and testPublicPrivateCache tests fail reproducibly on branch-20-security. Details in follow up comment.,Resolved,Duplicate,MAPREDUCE-1549,Unassigned,Eli Collins,Fri; 4 Nov 2011 16:11:32 +0000,Tue; 29 May 2012 18:50:55 +0000,Fri; 18 Nov 2011 23:24:14 +0000,,0.20.205.0,,,MAPREDUCE-1549,https://issues.apache.org/jira/browse/MAPREDUCE-3356
MAPREDUCE-3357,Bug,Major,distributed-cache;test,TestMRWithDistributedCache fails on branch-20-security,TestMRWithDistributedCache testLocalJobRunner fails on branch-20-security:,Resolved,Won't Fix,,Unassigned,Eli Collins,Fri; 4 Nov 2011 16:15:43 +0000,Sat; 26 Nov 2016 01:52:22 +0000,Sat; 26 Nov 2016 01:52:22 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3357
MAPREDUCE-3358,Bug,Major,jobtracker,TestNodeRefresh fails on branch-20-security,TestNodeRefresh testMRRefreshRecommissioning fails on branch-20-security:,Open,Unresolved,,Unassigned,Eli Collins,Fri; 4 Nov 2011 16:17:37 +0000,Tue; 14 May 2013 05:14:41 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3358
MAPREDUCE-3359,Improvement,Major,mrv2,Yarn clients / AM should be able to provide config options to the RM / NM,The RM and NM do not read a job's configuration. Clients  NM on a per app basis - like the Log Retention policy; token cancellation.,Resolved,Won't Fix,,Robert Joseph Evans,Siddharth Seth,Fri; 4 Nov 2011 19:08:18 +0000,Sat; 5 Nov 2011 01:10:16 +0000,Sat; 5 Nov 2011 01:10:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3359
MAPREDUCE-3360,Improvement,Critical,mrv2,Provide information about lost nodes in the UI.,Currently there is no information provided about lost nodes. Provide information in the UI.,Closed,Fixed,MAPREDUCE-3271,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Sat; 5 Nov 2011 09:28:09 +0000,Tue; 10 Sep 2013 13:34:44 +0000,Thu; 26 Jan 2012 22:59:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3360
HDFS-3544,Improvement,Major,contrib/raid,Ability to use SimpleRegeratingCode to fix missing blocks,ReedSolomon encoding (n; k) has n storage nodes and can tolerate n-k failures. Regenerating a block needs to access k blocks. This is a problem when n and k are large. Instead; we can use simple regenerating codes (n; k; f) that does first does ReedSolomon (n;k) and then does XOR with f stripe size. Then; a single disk failure needs to access only f nodes and f can be very small.,Resolved,Won't Fix,,Unassigned,dhruba borthakur,Sat; 5 Nov 2011 18:22:29 +0000,Fri; 7 Oct 2016 20:34:01 +0000,Fri; 7 Oct 2016 20:31:23 +0000,,,,,,https://issues.apache.org/jira/browse/HDFS-3544
MAPREDUCE-3362,Bug,Major,jobhistoryserver;jobtracker,Job always stay at 'Pending' status and cannot finish several days,Our jobs are always keeping  actual finishedMap counter; so the cleanup task cannot runs.,Open,Unresolved,,Unassigned,Denny Ye,Mon; 7 Nov 2011 06:59:28 +0000,Tue; 10 Jul 2012 21:27:08 +0000,,,0.20.2,jobtracker,,,https://issues.apache.org/jira/browse/MAPREDUCE-3362
MAPREDUCE-3363,Bug,Critical,mrv2,"The ""totalnodes""  and ""memorytotal"" fields show wrong information if the nodes are going down and coming up early(before 10min) ",The node details is not moved from Totalnodes to lostnodes for 600000 ms.So if the node is going down and coming up before the expiry interval; the cluster status in terms of the total nodes and Total cluster memory displays wrong values.  Atleast; if the same node is coming up again...should not consider as new node.No point of time duplicate nodes should be displayed in Totalnodes list.,Resolved,Won't Fix,MAPREDUCE-3585,Unassigned,Ramgopal N,Mon; 7 Nov 2011 07:03:56 +0000,Tue; 10 Mar 2015 04:32:38 +0000,Fri; 17 Feb 2012 00:34:29 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-3271;YARN-41;MAPREDUCE-3070,https://issues.apache.org/jira/browse/MAPREDUCE-3363
MAPREDUCE-3364,Bug,Major,mrv2,"Job executed through ftp file system is failing with ""java.io.IOException: Seek not supported""",Instead of hdfs file as input to the job;i have given local file through ftp as input and executed a job.The job is failing with ERROR Error:  142)    The same job is successfully getting executed in V1.,Open,Unresolved,,Unassigned,Ramgopal N,Mon; 7 Nov 2011 10:32:04 +0000,Thu; 17 Mar 2016 23:21:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3364
MAPREDUCE-3365,Improvement,Trivial,contrib/fair-share,Uncomment eventlog settings from the documentation,"Two fair scheduler debug options ""mapred.fairscheduler.eventlog.enabled"" and ""mapred.fairscheduler.dump.interval"" are commented out in fair scheduler doc file. It's useful for debugging.",Closed,Fixed,,Sho Shimauchi,Sho Shimauchi,Mon; 7 Nov 2011 12:19:28 +0000,Wed; 17 Oct 2012 18:27:28 +0000,Tue; 8 Nov 2011 02:11:38 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3365
MAPREDUCE-3366,Bug,Major,mrv2,Mapreduce component should use consistent directory structure layout as HDFS/common,Directory structure for MRv2 layout looks like:     The directory structure layout should be updated to reflect changes implemented in HADOOP-6255.,Closed,Fixed,MAPREDUCE-3416;MAPREDUCE-3177,Eric Yang,Eric Yang,Mon; 7 Nov 2011 16:59:07 +0000,Thu; 2 May 2013 02:29:46 +0000,Fri; 16 Dec 2011 09:17:29 +0000,,0.23.0,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3366
MAPREDUCE-3367,Improvement,Major,build;mrv2,Consolidate MRv2 maven modules,Maven modules for MRv2 has been splitter into many small pieces; like this:     The excessive use of directory structure is slowing down development and compile time.  For example; hadoop-yarn-server-tests and hadoop-yarn-site should not be stand alone modules.  There are better ways to organize the source code.  The proposal is to rearrange the code to:     This is a nice to have for 0.23; but optional.,Resolved,Duplicate,MAPREDUCE-2600,Eric Yang,Eric Yang,Mon; 7 Nov 2011 17:20:51 +0000,Mon; 7 Nov 2011 17:50:29 +0000,Mon; 7 Nov 2011 17:50:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3367
MAPREDUCE-3368,Bug,Critical,build;mrv2,compile-mapred-test fails,compile-mapred-test target is failing once again. Details: https: consoleFull,Closed,Fixed,,Hitesh Shah,Ramya Sunil,Mon; 7 Nov 2011 18:48:06 +0000,Mon; 5 Mar 2012 02:49:17 +0000,Wed; 9 Nov 2011 06:29:17 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3368
MAPREDUCE-3369,Improvement,Major,mrv1;mrv2;test,Migrate MR1 tests to run on MR2 using the new interfaces introduced in MAPREDUCE-3169,"This ticket tracks the migration of MR1 tests (currently residing in ""hadoop-mapreduce-project "") to run on MR2. The migration is using the new interfaces introduced in MAPREDUCE-3169.",Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Mon; 7 Nov 2011 20:38:40 +0000,Mon; 5 Mar 2012 02:49:42 +0000,Thu; 1 Dec 2011 22:34:51 +0000,,0.23.0,,MAPREDUCE-3169,,https://issues.apache.org/jira/browse/MAPREDUCE-3369
MAPREDUCE-3370,Bug,Major,mrv2;test,MiniMRYarnCluster uses a hard coded path location for the MapReduce application jar,MiniMRYarnCluster uses a hard coded relative path location for the MapReduce application jar. It is better to have this location as a system property so tests can pick the application jar regardless of their working directory.,Closed,Fixed,MAPREDUCE-3338,Ahmed Radwan,Ahmed Radwan,Mon; 7 Nov 2011 20:49:09 +0000,Thu; 2 May 2013 02:30:58 +0000,Fri; 11 Nov 2011 08:56:00 +0000,,0.23.0,,,MAPREDUCE-5147,https://issues.apache.org/jira/browse/MAPREDUCE-3370
MAPREDUCE-3371,Improvement,Minor,documentation;mrv2,Review and improve the yarn-api javadocs.,Review and improve the yarn-api  ocs.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Mon; 7 Nov 2011 21:10:09 +0000,Mon; 5 Mar 2012 02:49:41 +0000,Sun; 27 Nov 2011 23:17:42 +0000,,0.23.0,documentation,,,https://issues.apache.org/jira/browse/MAPREDUCE-3371
MAPREDUCE-3372,Bug,Major,,HADOOP_PREFIX cannot be overriden,"hadoop-config.sh forces HADOOP_prefix to a specific value: export HADOOP_PREFIX=`dirname ""$this""` ..  It would be nice to make this overridable.",Closed,Fixed,,Bruno Mah  ,Bruno Mah  ,Mon; 7 Nov 2011 22:28:13 +0000,Mon; 5 Mar 2012 02:48:49 +0000,Fri; 18 Nov 2011 05:15:49 +0000,,0.23.0;0.23.1,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3372
MAPREDUCE-3373,Bug,Major,,"Hadoop scripts unconditionally source ""$bin""/../libexec/hadoop-config.sh.",It would be nice to be able to specify some other location for hadoop-config.sh,Closed,Fixed,,Bruno Mah  ,Bruno Mah  ,Tue; 8 Nov 2011 00:05:08 +0000,Mon; 5 Mar 2012 02:49:47 +0000,Fri; 18 Nov 2011 01:06:27 +0000,,0.23.0;0.23.1,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3373
MAPREDUCE-3374,Bug,Major,task-controller,src/c++/task-controller/configure is not set executable in the tarball and that prevents task-controller from rebuilding,ant task-controller fails because src configure is not set executable,Closed,Fixed,,Unassigned,Roman Shaposhnik,Tue; 8 Nov 2011 00:47:35 +0000,Wed; 28 Dec 2011 10:03:30 +0000,Thu; 10 Nov 2011 01:11:12 +0000,,0.20.205.0,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3374
MAPREDUCE-3375,Task,Major,,Memory Emulation system tests.,1. Test the Gridmix memory emulation feature for gridmix jobs with default progress interval; different input data; submission policies and user resolver modes . Verify the maps phase of total heap usage of gridmix jobs with corresponding the original job in the trace.  2. Test the Gridmix memory emulation feature for gridmix jobs with custom progress interval; different input data; submission policies and user resolver modes . Verify the maps phase of total heap usage of gridmix jobs with corresponding the original job in the trace.  3. Test the Gridmix memory emulation feature for gridmix jobs with default progress interval; different input data; submission policies and user resolver modes. Verify the maps and reduces phase of total heap usage metric of gridmix jobs with corresponding the original job in the trace.  4. Disable Gridmix memory emulation option and verify the jobs whether it emulates the heap memory or not.,Closed,Fixed,,Vinay Kumar Thota,Vinay Kumar Thota,Tue; 8 Nov 2011 08:18:39 +0000,Mon; 5 Mar 2012 02:49:18 +0000,Tue; 15 Nov 2011 01:52:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3375
MAPREDUCE-3376,Bug,Major,mrv1;mrv2,Old mapred API combiner uses NULL reporter,The OldCombinerRunner class inside Task. uses a NULL Reporter.  If the combiner code runs for an extended period of time; even with reporting progress as it should; the map task can timeout and be killed.  It appears that the NewCombinerRunner class uses a valid reporter and as such is not impacted by this bug.,Closed,Fixed,,Subroto Sanyal,Robert Joseph Evans,Tue; 8 Nov 2011 16:25:50 +0000,Tue; 10 Mar 2015 04:31:57 +0000,Tue; 20 Dec 2011 22:02:23 +0000,,0.20.205.0;0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3376
MAPREDUCE-3377,Bug,Major,,Compatibility issue with 0.20.203.,I have an OutputFormat which implements Configurable.  I set new config entries to a job configuration during checkOutputSpec() so that the tasks will get the config entries through the job configuration.  This works fine in 0.20.2; but stopped working starting from 0.20.203.  With 0.20.203; my OutputFormat still has the configuration set; but the copy a task gets does not have the new entries that are set as part of checkOutputSpec().    I believe that the problem is with JobClient.  The job configuration needs to wait till checkOutputSpec() is returned before being cloned and submitted.,Closed,Fixed,,Jane Chen,Jane Chen,Tue; 8 Nov 2011 19:47:08 +0000,Tue; 29 May 2012 06:33:43 +0000,Thu; 29 Mar 2012 07:55:03 +0000,,0.20.203.0,,MAPREDUCE-1600,,https://issues.apache.org/jira/browse/MAPREDUCE-3377
MAPREDUCE-3378,Improvement,Major,build,Create a single 'hadoop-mapreduce' Maven artifact,In 0.23.0 there are multiple artifacts (hadoop-mapreduce-client-app; hadoop-mapreduce-client-common; hadoop-mapreduce-client-core; etc). It would be simpler for users to declare a dependency on hadoop-mapreduce (much like there's hadoop-common and hadoop-hdfs). (This would also be a step towards MAPREDUCE-2600.),Resolved,Won't Fix,,Unassigned,Tom White,Tue; 8 Nov 2011 20:38:47 +0000,Sat; 14 Apr 2012 00:17:18 +0000,Fri; 13 Apr 2012 23:52:04 +0000,,0.23.0,,,MAPREDUCE-2600;HADOOP-8009;HADOOP-8278,https://issues.apache.org/jira/browse/MAPREDUCE-3378
MAPREDUCE-3379,Bug,Major,mrv2;nodemanager,LocalResourceTracker should not tracking deleted cache entries,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 8 Nov 2011 23:37:39 +0000,Mon; 5 Mar 2012 02:49:36 +0000,Fri; 11 Nov 2011 06:32:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3379
MAPREDUCE-3380,Sub-task,Blocker,mr-am;mrv2,Token infrastructure for running clients which are not kerberos authenticated,The JobClient.getDelegationToken() method is returning NULL; this makes Oozie fail when trying to get the delegation token to use it for starting a job.  What is seems to be happing is that Jobclient.getDelegationToken() calls Cluster.getDelegationToken() that calls YarnRunner.getDelegationToken() that calls ResourceMgrDelegate.getDelegationToken(). And the last one is not implemented. (Thanks Ahmed for tracing this in MR2 code),Closed,Fixed,,Mahadev konar,Alejandro Abdelnur,Wed; 9 Nov 2011 01:13:40 +0000,Mon; 5 Mar 2012 02:49:28 +0000,Wed; 11 Jan 2012 01:57:04 +0000,,0.23.0,,,OOZIE-565,https://issues.apache.org/jira/browse/MAPREDUCE-3380
MAPREDUCE-3381,Bug,Major,tools/rumen,[Rumen] TestRumenJobTraces fails after MAPREDUCE-3035,TestRumenJobTraces fails after MAPREDUCE-3035. The issue is due to the null value passed for rackName.,Resolved,Duplicate,MAPREDUCE-3349,Amar Kamat,Amar Kamat,Wed; 9 Nov 2011 01:19:33 +0000,Tue; 10 Mar 2015 04:31:44 +0000,Wed; 9 Nov 2011 12:14:06 +0000,,0.23.1;2.0.0-alpha,hostname;rumen;test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3381
MAPREDUCE-3382,Bug,Critical,applicationmaster;mrv2,Network ACLs can prevent AMs to ping the Job-end notification URL,MAPREDUCE-3028 added support for job-end notification from MR AMs after the job finishes. Network ACLs can have an implication on this one - outgoing connections from the compute nodes may be restricted in some settings and so job-end notification( that can originate from the AMs which may run on random nodes in the cluster) may have issues.,Closed,Fixed,,Ravi Prakash,Vinod Kumar Vavilapalli,Wed; 9 Nov 2011 03:43:06 +0000,Mon; 5 Mar 2012 02:49:49 +0000,Tue; 10 Jan 2012 21:09:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3382
MAPREDUCE-3383,Bug,Major,,Duplicate job.getOutputValueGroupingComparator() in ReduceTask,This is probably just a small error by mistake.,Resolved,Fixed,,Binglin Chang,Binglin Chang,Wed; 9 Nov 2011 08:08:53 +0000,Tue; 30 Aug 2016 01:20:52 +0000,Fri; 8 May 2015 20:51:44 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3383
MAPREDUCE-3384,Improvement,Major,,Add warning message for underflow or overflow,When we call the function reduce() of LongSumReducer;the result may overflow or underflow. We should have a warning message to users if overflow underflow occurs for all these classes;,Open,Unresolved,MAPREDUCE-3385,Brahma Reddy Battula,JiangKai,Wed; 9 Nov 2011 09:22:51 +0000,Wed; 24 Jun 2015 11:28:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3384
MAPREDUCE-3385,Improvement,Minor,,Add warning message for the overflow in reduce() of org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer,When we call the function reduce() of IntSumReducer;the result may overflow. We should send a warning message to users if overflow occurs.,Resolved,Duplicate,MAPREDUCE-3384,Unassigned,JiangKai,Wed; 9 Nov 2011 09:45:02 +0000,Mon; 8 Jun 2015 13:42:40 +0000,Mon; 8 Jun 2015 13:42:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3385
MAPREDUCE-3386,Bug,Major,contrib/gridmix;contrib/streaming,Streaming and Gridmix tests are failing in trunk,Streaming and Gridmix tests are failing. Following error occurs in TestGridmixSummary:,Resolved,Cannot Reproduce,,Unassigned,Amar Kamat,Wed; 9 Nov 2011 10:00:53 +0000,Mon; 28 Sep 2015 21:10:29 +0000,Thu; 5 Jan 2012 07:10:54 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3386
MAPREDUCE-3387,Bug,Critical,mrv2,A tracking URL of N/A before the app master is launched breaks oozie,When oozie launches a map ; which MR and others now do.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 9 Nov 2011 15:21:20 +0000,Tue; 10 Mar 2015 04:32:11 +0000,Fri; 16 Dec 2011 23:43:44 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3387
MAPREDUCE-3388,Bug,Critical,contrib/streaming;mrv2,Streaming task with special char gets wrong output ,In 0.20.204:    Output:    For 0.23:    Output:    The contents of input.txt are as follows:,Resolved,Invalid,,Robert Joseph Evans,Robert Joseph Evans,Wed; 9 Nov 2011 16:24:19 +0000,Tue; 10 Mar 2015 04:32:13 +0000,Thu; 8 Dec 2011 22:13:54 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3388
MAPREDUCE-3389,Bug,Critical,mrv2,MRApps loads the 'mrapp-generated-classpath' file with classpath from the build machine,The 'mrapp-generated-classpath' file contains the classpath from where Hadoop was build. This classpath is not useful under any circumstances.  For example the content of the 'mrapp-generated-classpath' in my dev environment is:   xmlenc-0.52.jar,Closed,Fixed,MAPREDUCE-3428,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 9 Nov 2011 22:30:52 +0000,Tue; 10 Mar 2015 04:32:02 +0000,Mon; 5 Dec 2011 18:04:47 +0000,,0.23.0;0.23.1;2.0.0-alpha,bigtop,,MAPREDUCE-3616;MAPREDUCE-3087;MAPREDUCE-3505;MAPREDUCE-3509,https://issues.apache.org/jira/browse/MAPREDUCE-3389
MAPREDUCE-3390,Bug,Minor,mrv2,NPE while submitting job,Caused by:  571),Resolved,Fixed,,John George,John George,Thu; 10 Nov 2011 03:52:56 +0000,Mon; 9 Mar 2015 21:51:32 +0000,Mon; 9 Mar 2015 21:51:32 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3390
MAPREDUCE-3391,Bug,Minor,applicationmaster,Connecting to CM is logged as Connecting to RM,In class org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster,Closed,Fixed,,Subroto Sanyal,Subroto Sanyal,Thu; 10 Nov 2011 06:45:22 +0000,Mon; 5 Mar 2012 02:49:47 +0000,Tue; 20 Dec 2011 23:14:26 +0000,,0.23.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-3391
MAPREDUCE-3392,Sub-task,Blocker,,Cluster.getDelegationToken() throws NPE if client.getDelegationToken() returns null.,Caused by:  551),Closed,Fixed,,John George,John George,Thu; 10 Nov 2011 15:31:52 +0000,Tue; 10 Mar 2015 04:32:26 +0000,Thu; 10 Nov 2011 19:22:48 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3392
MAPREDUCE-3393,Bug,Major,mrv2,TestMRJobs; TestMROldApiJobs; and TestUberAM failures,Check out branch 0.23 and run mvn test from hadoop-mapreduce-project directory  -------------------------------------------------------  T E S T S ------------------------------------------------------- Running org.apache.hadoop.mapred.TestClientServiceDelegate Tests run: 6; Failures: 0; Errors: 0; Skipped: 0; Time elapsed: 5.717 sec Running org.apache.hadoop.mapred.TestClientRedirect Tests run: 1; Failures: 0; Errors: 0; Skipped: 0; Time elapsed: 15.436 sec Running org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider Tests run: 2; Failures: 0; Errors: 0; Skipped: 0; Time elapsed: 0.975 sec Running org.apache.hadoop.mapreduce.v2.TestMRJobs Tests run: 4; Failures: 3; Errors: 1; Skipped: 0; Time elapsed: 67.999 sec &lt; FAILURE! Running org.apache.hadoop.mapreduce.v2.TestYARNRunner Tests run: 3; Failures: 0; Errors: 0; Skipped: 0; Time elapsed: 11.976 sec Running org.apache.hadoop.mapreduce.v2.TestMROldApiJobs Tests run: 2; Failures: 2; Errors: 0; Skipped: 0; Time elapsed: 31.879 sec &lt; FAILURE! Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService ^NRunning org.apache.hadoop.mapreduce.v2.TestUberAM Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 101.096 sec &lt; FAILURE!  Results :  Failed tests:   testSleepJob(org.apache.hadoop.mapreduce.v2.TestMRJobs)   testRandomWriter(org.apache.hadoop.mapreduce.v2.TestMRJobs)   testDistributedCache(org.apache.hadoop.mapreduce.v2.TestMRJobs)   testJobSucceed(org.apache.hadoop.mapreduce.v2.TestMROldApiJobs): Job expected to succeed failed   testJobFail(org.apache.hadoop.mapreduce.v2.TestMROldApiJobs)  Tests in error:    testFailingMapper(org.apache.hadoop.mapreduce.v2.TestMRJobs): 0   org.apache.hadoop.mapreduce.v2.TestUberAM: Failed to Start org.apache.hadoop.mapreduce.v2.TestMRJobs  Tests run: 19; Failures: 5; Errors: 2; Skipped: 0,Resolved,Duplicate,MAPREDUCE-3407,Thomas Graves,Thomas Graves,Fri; 11 Nov 2011 17:27:52 +0000,Wed; 30 Nov 2011 06:18:12 +0000,Wed; 30 Nov 2011 06:18:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3393
MAPREDUCE-3394,Improvement,Trivial,task,Add log guard for a debug message in ReduceTask,There's a LOG.debug message in ReduceTask that stringifies a task ID and uses a non-negligible amount of CPU in some cases. We should guard it with isDebugEnabled,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 11 Nov 2011 23:05:40 +0000,Wed; 17 Oct 2012 18:27:28 +0000,Tue; 15 Nov 2011 00:42:35 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3394
MAPREDUCE-3395,Improvement,Trivial,documentation,Add mapred.disk.healthChecker.interval to mapred-default.xml,Let's add mapred.disk.healthChecker.interval to mapred-default.xml.,Closed,Fixed,,Eli Collins,Eli Collins,Sat; 12 Nov 2011 02:34:30 +0000,Wed; 17 Oct 2012 18:27:25 +0000,Sat; 12 Nov 2011 14:23:05 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3395
MAPREDUCE-3396,Bug,Major,contrib/mumak,Mumak compilation is broken (for a while?),contrib mumak compilation is broken because of the missing commons-lang dependency,Resolved,Duplicate,MAPREDUCE-3311,Konstantin Boudnik,Konstantin Boudnik,Sun; 13 Nov 2011 20:57:51 +0000,Wed; 16 Nov 2011 03:05:03 +0000,Wed; 16 Nov 2011 03:05:03 +0000,,0.22.0,,MAPREDUCE-3311,,https://issues.apache.org/jira/browse/MAPREDUCE-3396
MAPREDUCE-3397,Sub-task,Major,task,Support no sort dataflow in map output and reduce merge phrase,"In our experience; many data aggregation style queries jobs don't need to sort the intermediate data. In fact reducer side can use hashmap or even array to do application level aggregations. For example; consider computing CTR using display log  click log in sponsored search. Map side just emit (adv_id; clk_cnt; dis_cnt); reduce side aggregate clk_cnt and dis_cnt for every adv_id; cause adv_id is integer; we can partition adv_id by range:  	 	 		reduce0: 0-100000 		reduce1: 100000-200000 		... 		reduceM: xxx-max adv-id Then the reducer can use an array(for example: int 10000002) to store the aggregated clk_cnt  dis_cnt; and we don't need the framework to sort intermediate data anymore. By supporting no sort; we can gain a lot of performance improvements: 	 	   	Eliminate map side sort  merge.   KV paris need to sort by partition first; but this can be done using a liner time counting sort; which is much faster than quick sort.   Just merge spill segments one by one; doesn't need to use heap merge. 	Eliminate shuffle phrase barrier; reducer can start to processing data before all map output data are copied  merged.    For most cases; memory won't be a problem; cause keys are divided to many partitions; each reducers only process a small subset of the global key set.",Open,Unresolved,,Binglin Chang,Binglin Chang,Mon; 14 Nov 2011 10:10:44 +0000,Thu; 12 Jan 2012 17:56:21 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3397
MAPREDUCE-3398,Bug,Blocker,mrv2;nodemanager,Log Aggregation broken in Secure Mode,Log aggregation in secure mode does not work with MAPREDUCE-2977. The nodemanager relies on the users credentials to write out logs to HDFS. These credentials are currently cancelled once a job completes; before the NM can write out the logs.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 15 Nov 2011 05:20:35 +0000,Mon; 5 Mar 2012 02:49:24 +0000,Wed; 14 Dec 2011 20:00:30 +0000,,0.23.0,,,MAPREDUCE-3143,https://issues.apache.org/jira/browse/MAPREDUCE-3398
MAPREDUCE-3399,Sub-task,Blocker,mrv2;nodemanager,ContainerLocalizer should request new resources after completing the current one,Currently; the ContainerLocalizer to NM heartbeats to the NM every second. Not very significant; but this causes a ~4second delay in jobs (job jar; splits; etc). Instead; it should heartbeat to ask for additional resources to localize as soon as the previous one is localzied. There's already a TODO in the ContainerLocalizer for this.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 15 Nov 2011 05:29:17 +0000,Mon; 5 Mar 2012 02:49:40 +0000,Tue; 27 Dec 2011 18:28:32 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3399
MAPREDUCE-3400,Task,Major,jobhistoryserver;mrv2,Change JobHistoryParser to @InterfaceAudience:public,There's several tools outside of MapReduce which may be used to process MR job history files. Instead of these tools writing their own parser; they could use the MR JobHistoryParser.,Open,Unresolved,,Unassigned,Siddharth Seth,Tue; 15 Nov 2011 05:32:20 +0000,Tue; 15 Nov 2011 05:32:20 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3400
HADOOP-11695,New Feature,Minor,documentation,Make single node secure cluster setup documentation for 0.23,This JIRA is to track creation of documentation for the setup of a secure single node cluster.,Open,Unresolved,,Anupam Seth,Anupam Seth,Tue; 15 Nov 2011 14:56:34 +0000,Mon; 9 Mar 2015 21:53:08 +0000,,,,,,,https://issues.apache.org/jira/browse/HADOOP-11695
MAPREDUCE-3402,Sub-task,Blocker,applicationmaster;mrv2,AMScalability test of Sleep job with 100K 1-sec maps regressed into running very slowly,The world was rosier before October 19-25; Karam Singh says.  The 100K 1 second sleep job used to take around 800mins or 13-14 mins. It now runs till 45 mins and still manages to complete only about 45K tasks.  One more of the flurry of commits for 0.23.0 deserve(s) the blame.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 15 Nov 2011 15:27:02 +0000,Mon; 5 Mar 2012 02:49:50 +0000,Mon; 9 Jan 2012 23:29:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3402
MAPREDUCE-3403,New Feature,Major,job submission,Speculative Execution: Put to sleep a reducer when queue is full and a mapper needs to speculate,"When forcing multiple reduce tasks to be launched by applying the setNumReduceTasks() method on a Job object; and running on input data which has one significantly longer map (and consequently reduce) task;   	a speculative reduce task was not launched; even with a longer running reducer only 4 reduce tasks were launched     	the spec launch of map tasks was inhibited by the setNumReduceTasks() method applied; so even with -Dmapreduce.job.maps.speculative.execution=true we only had 4 map tasks launched. The exact same code with the setNumReduceTasks() method taken out; and on the same input data set; consistently launched 5 mappers as expected.    Testing info:  3. modified WordCount to force 4 reducers being launched; by adding:      job.setNumReduceTasks(4);   hardwire 4 reducers for now     System.out.println("" n"");  to the Job object. This causes 4 reduce tasks to be launched; oddly though it inhibits the map task from speculative launch. So the same job code; without the setNumReduceTasks() method; will launch 5 mappers as described in case #2. When this method is added; that same job will only launch 4 mappers; as well as 4 reducers; otherwise the job successfully completes.  output snippet with setNumReduceTasks():          org.apache.hadoop.mapreduce.JobCounter                 TOTAL_LAUNCHED_MAPS=4                 TOTAL_LAUNCHED_REDUCES=4                 RACK_LOCAL_MAPS=4                 SLOTS_MILLIS_MAPS=190787                 SLOTS_MILLIS_REDUCES=572554",Open,Unresolved,,Unassigned,patrick white,Tue; 15 Nov 2011 19:10:09 +0000,Tue; 17 Jan 2012 16:42:54 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3403
MAPREDUCE-3404,Bug,Critical,job submission;mrv2,Speculative Execution: speculative map tasks launched even if -Dmapreduce.map.speculative=false,When forcing a mapper to take significantly longer than other map tasks; speculative map tasks are launched even if the mapreduce.job.maps.speculative.execution parameter is set to 'false'.  Testcase: ran default WordCount job with spec execution set to false for both map and reduce but still saw a fifth mapper task launch; ran job as follows:  hadoop --config config  jar    file_of_words.out  output snippet:          org.apache.hadoop.mapreduce.JobCounter                 NUM_FAILED_MAPS=1                 TOTAL_LAUNCHED_MAPS=5                 TOTAL_LAUNCHED_REDUCES=1                 RACK_LOCAL_MAPS=5                 SLOTS_MILLIS_MAPS=279653                 SLOTS_MILLIS_REDUCES=211474,Closed,Fixed,,Eric Payne,patrick white,Tue; 15 Nov 2011 19:18:07 +0000,Mon; 5 Mar 2012 02:49:34 +0000,Fri; 13 Jan 2012 23:44:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3404
MAPREDUCE-3405,Bug,Critical,capacity-sched;contrib/fair-share,MAPREDUCE-3015 broke compilation of contrib scheduler tests,MAPREDUCE-3015 added a new argument to the TaskTrackerStatus constructor; which is used by a few of the scheduler tests; but didn't update those tests. So; the contrib test build is now failing on 0.20-security,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 15 Nov 2011 21:39:30 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Tue; 15 Nov 2011 21:48:03 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3405
MAPREDUCE-3406,Improvement,Major,mrv2,Add node information to bin/mapred job -list-attempt-ids and other improvements,From Ramya Sunil Providing the NM information where the containers are scheduled in bin mapred job -list-attempt-ids will be helpful in automation; debugging and to avoid grepping through the AM logs.  From my own observation; the list-attempt-ids should list the attempt ids and not require the arguments. The arguments if given; can be used to filter the results. From the usage: -list-attempt-ids job-id task-type task-state&#93;. Valid values for task-type are MAP REDUCE JOB_SETUP JOB_CLEANUP TASK_CLEANUP. Valid values for task-state are running; completed,Resolved,Duplicate,MAPREDUCE-3662,Ravi Prakash,Ravi Prakash,Tue; 15 Nov 2011 22:26:43 +0000,Mon; 28 Sep 2015 21:10:32 +0000,Wed; 16 Apr 2014 15:26:54 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3406
MAPREDUCE-3407,Bug,Minor,mrv2,Wrong jar getting used in TestMR*Jobs* for MiniMRYarnCluster,pom for mapreduce-client-jobclient sets system property to incorrect jar name.,Closed,Fixed,MAPREDUCE-3393,Hitesh Shah,Hitesh Shah,Tue; 15 Nov 2011 23:40:54 +0000,Tue; 10 Mar 2015 04:32:26 +0000,Wed; 16 Nov 2011 16:32:43 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3407
MAPREDUCE-3408,Bug,Major,mrv2;nodemanager;resourcemanager,yarn-daemon.sh unconditionnaly sets yarn.root.logger,yarn-daemon.sh unconditionnaly sets yarn.root.logger which then prevent any override from happening. From .  would be taken.  I don't really have any preference toward any of these solutions. What would you recommend? What is the Apache Hadoop way for this matter?  Note: This is probably happening as well for the other daemons; and I will take a look at it once this issue is resolved.,Closed,Fixed,,Bruno Mah  ,Bruno Mah  ,Wed; 16 Nov 2011 01:35:13 +0000,Mon; 5 Mar 2012 02:48:52 +0000,Tue; 22 Nov 2011 22:36:28 +0000,,0.23.0;0.23.1,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3408
MAPREDUCE-3409,Bug,Major,mrv2,Incorrect custom task status when running on MR2,"To reproduce this problem:  1- In your mapper setup() set:      2- When the job finishes:     The returned status from reports0.getState() is ""SUCCEEDED"" as opposed to the expected ""myStatus"" value.  This exact code work fine on MR1. I saw this issue when tried running the TestTaskContext test cases on MR2.",Open,Unresolved,,Unassigned,Ahmed Radwan,Wed; 16 Nov 2011 07:57:46 +0000,Mon; 9 Apr 2012 23:53:54 +0000,,,0.23.0,,MAPREDUCE-3427,,https://issues.apache.org/jira/browse/MAPREDUCE-3409
YARN-952,Bug,Major,capacityscheduler,Capacity scheduler reconfiguration of queues does not work for add sub-queues to an existing queue,If we have an existing queue configuration such as   root     and we least implies that only deletion is not supported).,Resolved,Later,MAPREDUCE-4430,Unassigned,Anupam Seth,Wed; 16 Nov 2011 17:08:33 +0000,Tue; 23 Jul 2013 17:15:56 +0000,Wed; 8 Aug 2012 05:27:45 +0000,,,,,YARN-11,https://issues.apache.org/jira/browse/YARN-952
MAPREDUCE-3411,Improvement,Minor,mrv2,Performance Upgrade for jQuery,jQuery 1.6.4 is almost twice as fast as current version 1.4.4 on modern browsers on some operations. There are also many modern browser compatibility fixes  http: 15,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 16 Nov 2011 18:11:44 +0000,Tue; 10 Mar 2015 04:32:46 +0000,Tue; 22 Nov 2011 22:49:09 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3411
MAPREDUCE-3412,Bug,Major,,'ant docs' is broken,'ant docs' no longer work.,Closed,Fixed,,Amar Kamat,Amar Kamat,Wed; 16 Nov 2011 18:27:47 +0000,Tue; 10 Mar 2015 04:32:47 +0000,Tue; 22 Nov 2011 09:53:56 +0000,,2.0.0-alpha,docs,,,https://issues.apache.org/jira/browse/MAPREDUCE-3412
MAPREDUCE-3413,Bug,Minor,mrv2,RM web ui applications not sorted in any order by default,nan,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 16 Nov 2011 19:27:22 +0000,Tue; 10 Mar 2015 04:32:48 +0000,Mon; 28 Nov 2011 00:01:23 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3413
MAPREDUCE-3414,Bug,Major,,maven artifacts (0.20.205.0) has incorrect dependencies; leading to infinite loop in MiniMRCluster in unit tests,"(hadoop 0.20.205.0; perhaps more)  A simple unit test using MiniMRCluster will:   	Crash if jackson-jaxrs is not in scope 	Hang forever if jackson-jaxrs is in scope but jersey-core is not    Hadoop does not declare eitehr of these required dependencies in hadoop-core or hadoop-test poms.   hadoop-test should at minimum include both of these declared in its pom.  The reproducible case is here: https: hadoop_dependency_bug  ""mvn test"" works fine as is; but if you comment out the explicit dependencies in the pom you'll get the errors above. Comment out jersey-core it will spin forever. Comment out jackson-jaxrs and it will crash.  Both cases demonstrate that the dependency in the hadoop-test (and implicit hadoop-core) are not specified correctly in the pom.",Open,Unresolved,,Unassigned,Scott Carey,Wed; 16 Nov 2011 20:03:43 +0000,Wed; 16 Nov 2011 20:03:43 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3414
MAPREDUCE-3415,Improvement,Major,mrv2,improve MiniMRYarnCluster & DistributedShell JAR resolution ,"Current JAR resolution assumes the following:   	The class used for JAR lookup is effectively in a JAR 	A System property is set for testing with the location of the JAR    The problem with #1 is that in some cases (when using the class in the same Maven module where the class is; the class is not in a JAR but in a directory 'target test-classes').  The problem with #2 is the JAR does not exists at the time of running the test (packaging comes after test and we are not doing integration testing yet thus won't work)  In addition; this is required for streaming testcases; to have the JAR with streaming classes for testing.",Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 16 Nov 2011 20:19:58 +0000,Tue; 10 Mar 2015 04:32:52 +0000,Thu; 17 Nov 2011 23:21:39 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3415
MAPREDUCE-3416,Improvement,Major,mrv2,Rename {start;stop}-all.sh to {start;stop}-yarn.sh for consistency with HDFS,There are already  {start;stop}-all.sh scripts for starting and stopping all Hadoop daemons which conflict with the YARN {start;stop} -all.sh scripts. The latter should be renamed  {start;stop} -yarn.sh.,Resolved,Duplicate,MAPREDUCE-3366,Jonathan Eagles,Tom White,Wed; 16 Nov 2011 20:23:54 +0000,Mon; 12 Dec 2011 17:28:52 +0000,Mon; 12 Dec 2011 17:24:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3416
MAPREDUCE-3417,Bug,Blocker,mrv2,job access controls not working app master and job history UI's,"tested with security on; no filters defined for httpserver; job acls set so that only I could view modify the job.  Then went to the web ui to app master and job history server and both allowed me to view the job details.  The webui shows the user ""webuser"".   The RM properly rejected my request although it was using user ""Dr.Who"".       The exception shown in the log is:   WARN security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: No such user           org.apache.hadoop.mapreduce.v2.app.webapp.AppController.job(AppController. 97)",Closed,Fixed,,Jonathan Eagles,Thomas Graves,Wed; 16 Nov 2011 21:00:28 +0000,Mon; 5 Mar 2012 02:49:22 +0000,Sat; 4 Feb 2012 01:23:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3417
MAPREDUCE-3418,Bug,Major,,If map output is not found; shuffle runs in tight loop,Sharad Agarwal bumped into this while simulating fetch failures.   Removed the map output directory. Shuffle runs in tight loop throwing :  2011-06-01 09:02:20;511 WARN org.apache.hadoop.mapreduce.task.reduce.Fetcher: Invalid map id   149)   Fetch failure is not triggered.,Open,Unresolved,,John George,John George,Wed; 16 Nov 2011 21:27:55 +0000,Sat; 7 Jan 2017 01:59:55 +0000,,,0.23.0;2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3418
MAPREDUCE-3419,Bug,Major,tasktracker;test,Don't mark exited TT threads as dead in MiniMRCluster  ,MAPREDUCE-2850 flagged all TT threads that exited in the MiniMRCluster as dead; this breaks a number of the other tests that use MiniMRCluster across restart.,Closed,Fixed,,Eli Collins,Eli Collins,Wed; 16 Nov 2011 22:14:42 +0000,Wed; 17 Oct 2012 18:27:28 +0000,Fri; 18 Nov 2011 00:26:55 +0000,,1.1.0,,,MAPREDUCE-2850,https://issues.apache.org/jira/browse/MAPREDUCE-3419
MAPREDUCE-3420,Bug,Major,mrv2,[Umbrella ticket] Make uber jobs functional,Umbrella jira for getting uber jobs to work correctly with YARN MRv2,Closed,Fixed,,Unassigned,Hitesh Shah,Thu; 17 Nov 2011 00:38:29 +0000,Tue; 10 Mar 2015 04:32:08 +0000,Tue; 10 Jan 2012 02:11:21 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3420
MAPREDUCE-3421,Sub-task,Major,mrv2,Error in MR AM shutdown when running an uber-job,Exception thrown during the un-registration process in the ContainerAllocator#stop. Exception trace in next comment.,Resolved,Duplicate,MAPREDUCE-3426,Hitesh Shah,Hitesh Shah,Thu; 17 Nov 2011 00:44:38 +0000,Tue; 10 Mar 2015 04:32:09 +0000,Mon; 12 Dec 2011 22:02:57 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3421
MAPREDUCE-3422,Bug,Major,mrv2,Counter display names are not being picked up,"When running a job I see ""MAP_INPUT_RECORDS"" rather than ""Map input records"" for the counter name. To fix this the resource bundle properties files need to be moved to the src resources tree.",Closed,Fixed,,Jonathan Eagles,Tom White,Thu; 17 Nov 2011 06:18:41 +0000,Tue; 10 Mar 2015 04:32:03 +0000,Fri; 16 Dec 2011 03:13:53 +0000,,0.23.0;0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3422
MAPREDUCE-3423,Bug,Major,mrv2,Fetcher Thread should log proper exception,Exception should be logged properly when there is any while deserializing Shuffle Header information .,Open,Unresolved,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Thu; 17 Nov 2011 18:20:04 +0000,Tue; 10 Mar 2015 04:32:17 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3423
MAPREDUCE-3424,Sub-task,Minor,tasktracker,Some LinuxTaskController cleanup,MR-2415 had some tabs and weird indenting and spacing. Also would be more clear if LTC explicitly overrides createLogDir. Let's clean this up.,Closed,Fixed,,Eli Collins,Eli Collins,Thu; 17 Nov 2011 19:56:13 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Wed; 23 Nov 2011 04:18:39 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3424
MAPREDUCE-3425,Sub-task,Major,mrv2,uber job hangs and fails to get killed properly on a job kill signal,nan,Resolved,Cannot Reproduce,,Unassigned,Hitesh Shah,Thu; 17 Nov 2011 22:44:27 +0000,Mon; 28 Sep 2015 21:10:29 +0000,Tue; 10 Jan 2012 01:51:18 +0000,,0.23.0;0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3425
MAPREDUCE-3426,Sub-task,Blocker,mrv2,uber-jobs tried to write outputs into wrong dir,Incorrect setup of the uber tasks causes tasks to try to write intermidiate outputs into dirs that the user does not have permissions to write to on a secure cluster.,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Fri; 18 Nov 2011 00:38:43 +0000,Tue; 10 Mar 2015 04:31:41 +0000,Tue; 13 Dec 2011 23:43:20 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3426
MAPREDUCE-3427,Bug,Blocker,contrib/streaming;mrv2,streaming tests fail with MR2,After Mavenizing streaming and getting its testcases to use the MiniMRCluster wrapper (MAPREDUCE-3169); 4 testcases fail to pass.  Following is an assessment of those failures. Note that the testcases have been tweaked only to set the streaming JAR and yarn as the  framework.  (If these issues are unrelated we should create sub-tasks for each one of them).  TestStreamingCombiner; fails because returned counters don't match assertion. However; counters printed in the test output indicate values that would satisfy the assertion. As Tom has indicated it seems MR YARN  run.  TestStreamingStatus fails in validateTaskStatus() in the following assertion     TestUlimit fails with,Closed,Fixed,,Hitesh Shah,Alejandro Abdelnur,Fri; 18 Nov 2011 04:41:23 +0000,Tue; 10 Mar 2015 04:31:47 +0000,Wed; 1 Feb 2012 23:06:56 +0000,,0.23.1;2.0.0-alpha,,MAPREDUCE-3409,,https://issues.apache.org/jira/browse/MAPREDUCE-3427
MAPREDUCE-3428,Bug,Major,mrv2,MR AppMaster CLASSPATH is dependent on the compile-time environment ,"The CLASSPATH for the MapReduce Application master is set using compile time path information; which is typically different from run-time. This will cause failure when running on different environments.  Specifically; the YarnRunner; and as part ApplicationSubmissionContext creation; sets the classpath for the application master using MRApps.setClasspath(environment); and then the setMRFrameworkClasspath(..) method uses compile time path information present in the ""mrapp-generated-classpath"" file (created at compile-time).",Resolved,Duplicate,MAPREDUCE-3389,Unassigned,Ahmed Radwan,Fri; 18 Nov 2011 10:04:45 +0000,Thu; 8 Dec 2011 00:16:30 +0000,Fri; 2 Dec 2011 19:51:08 +0000,,0.23.0,bigtop,,MAPREDUCE-3509,https://issues.apache.org/jira/browse/MAPREDUCE-3428
MAPREDUCE-3429,Bug,Major,capacity-sched;contrib/gridmix,Few contrib tests are failing because of the missing commons-lang dependency,As the result of MAPREDUCE-3311 fix a transient commons-lang isn't available anymore to contrib tests. This causing silent failure with timeout. The problem is only seeing if tests are ran with -Dtest.output=yes,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Fri; 18 Nov 2011 15:54:37 +0000,Mon; 12 Dec 2011 06:19:47 +0000,Fri; 18 Nov 2011 16:49:22 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3429
MAPREDUCE-3430,Improvement,Major,mrv2,Shell variable expansions in yarn shell scripts should be quoted,The various yarn shell scripts assume that JAVA_HOME; HADOOP_COMMON_HOME; YARN_CONFIG_DIR etc are all in directories without spaces. This likely to break on windows; where JAVA_HOME is often C: Java  They all need reviewing; and ideally testing on a machine that has everything installed into directories with spaces.,Open,Unresolved,,Unassigned,Steve Loughran,Fri; 18 Nov 2011 16:03:01 +0000,Fri; 18 Nov 2011 16:03:01 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3430
MAPREDUCE-3431,Bug,Minor,resourcemanager,NPE in Resource Manager shutdown,bringing up a resource manager failed; shutdown triggered an NPE,Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 18 Nov 2011 16:24:14 +0000,Tue; 10 Mar 2015 04:31:56 +0000,Fri; 16 Mar 2012 13:37:49 +0000,,0.23.0;2.0.0-alpha,yarn,,YARN-117,https://issues.apache.org/jira/browse/MAPREDUCE-3431
MAPREDUCE-3432,Bug,Minor,mrv2,Yarn doesn't work if JAVA_HOME isn't set,libexec hadoop-config.sh does reliably work out JAVA_HOME for many platforms. unfortunately; the yarn scripts don't use it. As such you get told off when you try to run yarn     To make things more interesting; if you set the value in the shell; it still doesn't propagate down to the scripts,Resolved,Not A Problem,,Unassigned,Steve Loughran,Fri; 18 Nov 2011 15:23:49 +0000,Sun; 8 Feb 2015 18:18:55 +0000,Sun; 8 Feb 2015 18:18:55 +0000,,0.23.0,,,HADOOP-7894,https://issues.apache.org/jira/browse/MAPREDUCE-3432
MAPREDUCE-3433,Sub-task,Major,client;mrv2,Finding counters by legacy group name returns empty counters,Attempting to find counters with a legacy group name (e.g. org.apache.hadoop.mapred.Task$Counter rather than the new org.apache.hadoop.mapreduce.TaskCounter) returns empty counters. This causes TestStreamingCombiner to fail when run with YARN.,Closed,Fixed,,Tom White,Tom White,Fri; 18 Nov 2011 19:03:13 +0000,Mon; 5 Mar 2012 02:49:11 +0000,Tue; 29 Nov 2011 05:13:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3433
MAPREDUCE-3434,Bug,Blocker,mrv2,Nightly build broken ,https:   Results :  Failed tests:   testSleepJob(org.apache.hadoop.mapreduce.v2.TestMRJobs)   testRandomWriter(org.apache.hadoop.mapreduce.v2.TestMRJobs)   testDistributedCache(org.apache.hadoop.mapreduce.v2.TestMRJobs)  Tests in error:    org.apache.hadoop.mapreduce.v2.TestMROldApiJobs: Failed to Start org.apache.hadoop.mapreduce.v2.TestMROldApiJobs   org.apache.hadoop.mapreduce.v2.TestUberAM: Failed to Start org.apache.hadoop.mapreduce.v2.TestMRJobs  Likely due to either of: MAPREDUCE-3415. improve MiniMRYarnCluster  DistributedShell JAR resolution (tucu) MAPREDUCE-3169. Create a new MiniMRCluster equivalent which only provides client APIs cross MR1 and MR2. (Ahmed via tucu),Closed,Fixed,,Hitesh Shah,Hitesh Shah,Fri; 18 Nov 2011 23:13:51 +0000,Tue; 10 Mar 2015 04:32:51 +0000,Mon; 21 Nov 2011 18:28:43 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3434
HADOOP-7907,Bug,Blocker,build,hadoop-tools JARs are not part of the distro,After mavenizing streaming; the hadoop-streaming JAR is not part of the final tar.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Sat; 19 Nov 2011 01:16:37 +0000,Thu; 2 May 2013 02:29:48 +0000,Fri; 6 Jan 2012 00:18:03 +0000,,0.23.1;0.24.0,,,HADOOP-7935,https://issues.apache.org/jira/browse/HADOOP-7907
MAPREDUCE-3436,Bug,Major,mrv2;webapps,JobHistory webapp address should use the host from the jobhistory address,On the following page : http: configuration,Closed,Fixed,,Ahmed Radwan,Bruno Mah  ,Sat; 19 Nov 2011 02:29:25 +0000,Mon; 5 Mar 2012 02:48:47 +0000,Tue; 7 Feb 2012 20:57:55 +0000,,0.23.0;0.23.1,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3436
MAPREDUCE-3437,Bug,Blocker,build;mrv2,Branch 23 fails to build with Failure to find org.apache.hadoop:hadoop-project:pom:0.24.0-SNAPSHOT,INFO Scanning for projects... ERROR The build could not read 1 project - Help 1 ERROR    ERROR   The project org.apache.hadoop:hadoop-mapreduce-examples:0.24.0-SNAPSHOT ( UnresolvableModelException,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Sat; 19 Nov 2011 06:06:01 +0000,Mon; 5 Mar 2012 02:49:09 +0000,Mon; 21 Nov 2011 06:50:15 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3437
MAPREDUCE-3438,Bug,Major,contrib/raid,"TestRaidNode fails because of ""Too many open files""",TestRaidNode fails because it opens many connections.,Closed,Fixed,,Ramkumar Vadali,Konstantin Shvachko,Mon; 21 Nov 2011 02:36:01 +0000,Mon; 12 Dec 2011 06:20:01 +0000,Tue; 29 Nov 2011 03:44:05 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3438
MAPREDUCE-3439,New Feature,Major,contrib/gridmix,[Gridmix] Support addons in Gridmix,At times there is a need to benchmark certain Hadoop client APIs. Often; this is done by running simple  standard sort-like programs on Hadoop and then using an external utility to benchmark the APIs. But then the benchmarking results tend to be off from reality as the load on the cluster doesn't match the actual load. We believe that Gridmix3 - which is a Hadoop workload simulator - can prove useful here. Gridmix3 already provides a mechanism to load the cluster - often called as a 'test cluster' - using a real trace thus mimicking the real-life workload.  Currently; Gridmix3 consumes a representative workload trace and loads the Hadoop cluster to match what is seen in the trace. Gridmix3 can be enhanced to also support user scripts (hereby referred as 'addons') which will be loaded within Gridmix3 and will get updates like 1. Job submission 2. Job completion 3. Cluster status  These addons can also ping access a live; close-to-real-life Hadoop cluster. This will allow users to benchmark the Hadoop cluster while it is running.,Open,Unresolved,,Amar Kamat,Amar Kamat,Mon; 21 Nov 2011 04:11:16 +0000,Mon; 9 Mar 2015 22:06:38 +0000,,,,addons;gridmix;gridmix3,,,https://issues.apache.org/jira/browse/MAPREDUCE-3439
YARN-89,Sub-task,Major,nodemanager,Add tests for testing other NM components with disk failures,Add more tests to test other components when disks fail.,Open,Unresolved,,Unassigned,Ravi Gummadi,Mon; 21 Nov 2011 11:38:25 +0000,Wed; 26 Sep 2012 04:29:48 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-89
YARN-90,Sub-task,Major,nodemanager,NodeManager should identify failed disks becoming good again,MAPREDUCE-3121 makes NodeManager identify disk failures. But once a disk goes down; it is marked as failed forever. To reuse that disk (after it becomes good); NodeManager needs restart. This JIRA is to improve NodeManager to reuse good disks(which could be bad some time back).,Closed,Fixed,YARN-1196;YARN-1380;YARN-2473;YARN-4011;YARN-2488,Varun Vasudev,Ravi Gummadi,Mon; 21 Nov 2011 11:53:07 +0000,Wed; 25 Nov 2015 04:11:15 +0000,Tue; 21 Oct 2014 17:44:34 +0000,,,,,YARN-2839;YARN-2799,https://issues.apache.org/jira/browse/YARN-90
MAPREDUCE-3442,Bug,Minor,,Progress-report RPC clients should wait for the RPC to complete before sending another progress report,The Progress-report IPC clients don't wait for an invoked IPC to complete before sending another progress report. Since in the IPC server; handlers execute as threads; an old progress report might overwrite the status sent by a newer progress report. Making the progress report IPC methods return a boolean or something; and having the clients wait for the response to a progress report before sending the next one; should handle the issue.,Open,Unresolved,,Unassigned,Devaraj Das,Tue; 10 Apr 2007 06:38:21 +0000,Mon; 21 Nov 2011 13:54:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3442
MAPREDUCE-3443,Bug,Blocker,mrv2,Oozie jobs are running as oozie user even though they create the jobclient as doAs.,Oozie is having issues with job submission; since it does the following:     In 0.20.2** this works because the JT proxy is created as soon as we call new JobClient(). But in 0.23 this is no longer true since the client has to talk to multiple servers (AM JHS). To keep this behavior we will have to store the ugi in new JobClient() and make sure all the calls are run with a doAs() inside the jobclient.,Closed,Fixed,,Mahadev konar,Mahadev konar,Mon; 21 Nov 2011 17:39:02 +0000,Mon; 5 Mar 2012 02:49:33 +0000,Thu; 1 Dec 2011 20:45:14 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3443
MAPREDUCE-3444,Bug,Blocker,mrv2,trunk/0.23 builds broken ,https: ,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Mon; 21 Nov 2011 18:49:08 +0000,Tue; 10 Mar 2015 04:32:37 +0000,Mon; 21 Nov 2011 20:59:03 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3444
MAPREDUCE-3445,Bug,Major,build;mrv2,'Users' directory in hadoop-mapreduce-project with eclipse files,'Users' directory is now being created in hadoop-mapreduce-project with eclipse files; looks like recent mavenization changes?,Open,Unresolved,,Unassigned,Arun C Murthy,Mon; 21 Nov 2011 18:53:02 +0000,Mon; 21 Nov 2011 20:25:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3445
MAPREDUCE-3446,Improvement,Major,,Move hadoop-examples to hadoop-mapreduce-client/hadoop-examples?,Should we consider moving hadoop-examples to hadoop-mapreduce-client hadoop-examples?,Open,Unresolved,,Unassigned,Arun C Murthy,Mon; 21 Nov 2011 18:56:35 +0000,Sun; 11 Dec 2011 04:05:19 +0000,,,,,,MAPREDUCE-3492,https://issues.apache.org/jira/browse/MAPREDUCE-3446
MAPREDUCE-3447,Bug,Blocker,mrv2,mapreduce examples not working,"Since the mavenization went in the mapreduce examples jar no longer works.    $ hadoop jar . hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar  wordcount input output Exception in thread ""main""  193)",Closed,Fixed,,Mahadev konar,Thomas Graves,Mon; 21 Nov 2011 19:02:28 +0000,Mon; 5 Mar 2012 02:48:39 +0000,Mon; 21 Nov 2011 20:52:15 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3447
MAPREDUCE-3448,Bug,Minor,mrv2,TestCombineOutputCollector javac unchecked warning on mocked generics,  2 warnings,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 21 Nov 2011 20:58:20 +0000,Tue; 10 Mar 2015 04:32:33 +0000,Tue; 29 Nov 2011 23:35:08 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3448
MAPREDUCE-3449,Improvement,Major,,Port Mumak to work with MRv2 ResourceManager,It would be very useful to port Mumak-like functionality for simulation for YARN ResourceManager.,Open,Unresolved,,Unassigned,Arun C Murthy,Tue; 22 Nov 2011 01:46:33 +0000,Sun; 3 Nov 2013 03:11:49 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3449
MAPREDUCE-3450,Bug,Major,mr-am;mrv2,NM port info no longer available in JobHistory,The NM RPC port used to be part of the hostname field in JobHistory. That seems to have gone missing. Required for the task log link on the history server.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 22 Nov 2011 03:26:18 +0000,Mon; 5 Mar 2012 02:49:12 +0000,Wed; 30 Nov 2011 08:45:41 +0000,,0.23.0,,MAPREDUCE-3463,,https://issues.apache.org/jira/browse/MAPREDUCE-3450
MAPREDUCE-3451,New Feature,Major,mrv2;scheduler,Port Fair Scheduler to MR2,The Fair Scheduler is in widespread use today in MR1 clusters; but not yet ported to MR2. This is to track the porting of the Fair Scheduler to MR2 and will be updated to include design considerations and progress.,Closed,Fixed,,NO NAME,NO NAME,Tue; 22 Nov 2011 04:03:22 +0000,Thu; 2 May 2013 02:30:52 +0000,Fri; 13 Jul 2012 00:48:39 +0000,,,,,MAPREDUCE-4462;MAPREDUCE-4441;MAPREDUCE-4439;MAPREDUCE-4440;MAPREDUCE-4468,https://issues.apache.org/jira/browse/MAPREDUCE-3451
MAPREDUCE-3452,Bug,Major,mrv2,fifoscheduler web ui page always shows 0% used for the queue,When the fifo scheduler is configured to be on; go to the RM web ui page and click the scheduler link.  Hover over the default queue to see the used%.  It always shows used% as 0.0% even when jobs are running.,Closed,Fixed,,Jonathan Eagles,Thomas Graves,Tue; 22 Nov 2011 06:18:15 +0000,Tue; 10 Mar 2015 04:32:11 +0000,Thu; 1 Dec 2011 08:46:04 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3452
MAPREDUCE-3453,Bug,Major,mrv2,RM web ui application details page shows RM cluster about information,"Go to the RM Web ui page.  Click on the Applications link; then click on a particular application. The applications details page inadvertently includes the RM about page information after the application details:  Cluster ID: 	1321943597242 ResourceManager state: 	STARTED ResourceManager started on: 	22-Nov-2011 06:33:17 ResourceManager version: 	0.23.0-SNAPSHOT from 1203458 by user source checksum 0c288fc0971ed28c970272a62f547eae on Tue Nov 22 06:31:09 UTC 2011 Hadoop version: 	0.23.0-SNAPSHOT from 1204629 by user source checksum 421c41e5cfbed4a9d473b123425ad94f on Tue Nov 22 06:29:17 UTC 2011",Closed,Fixed,,Jonathan Eagles,Thomas Graves,Tue; 22 Nov 2011 06:56:16 +0000,Mon; 5 Mar 2012 02:49:44 +0000,Fri; 2 Dec 2011 22:55:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3453
MAPREDUCE-3454,Bug,Major,contrib/gridmix,[Gridmix] TestDistCacheEmulation is broken,TestDistCacheEmulation is broken as 'MapReduceTestUtil' no longer exists.,Closed,Fixed,,Hitesh Shah,Amar Kamat,Tue; 22 Nov 2011 09:01:31 +0000,Tue; 10 Mar 2015 04:32:14 +0000,Tue; 22 Nov 2011 19:50:01 +0000,,2.0.0-alpha,gridmix,,,https://issues.apache.org/jira/browse/MAPREDUCE-3454
MAPREDUCE-3455,Bug,Major,mrv2,TokenCache should only call getDelegationToken if getDelegationTokens does not return valid tokens,Currently getDelegationToken is called irrespective of whether getDelegationTokens gives back valid tokens.,Open,Unresolved,,Unassigned,Siddharth Seth,Tue; 22 Nov 2011 22:09:52 +0000,Tue; 22 Nov 2011 22:09:52 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3455
MAPREDUCE-3456,Bug,Blocker,mrv2,$HADOOP_PREFIX/bin/yarn should set defaults for $HADOOP_*_HOME,If the $HADOOP_PREFIX yarn should check if $HADOOP_PREFIX is set and; if it is; use that value for the 3 other HADOOP_*_HOME variables.,Closed,Fixed,,Eric Payne,Eric Payne,Tue; 22 Nov 2011 23:31:58 +0000,Mon; 5 Mar 2012 02:49:22 +0000,Sat; 3 Dec 2011 03:44:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3456
MAPREDUCE-3457,Bug,Major,build;examples,MR examples can not be built from source tarball,When attempting to build the mapreduce examples in hadoop-mapreduce-project; from the contents of the released source tarball hadoop-0.23.0-src.tar.gz; you hit a failure due to a missing file:   andrew@ubuntu-slave01: hadoop-0.23.0-src directory. I can't find any aop.xml files in the source tarball; though they're there in svn.,Open,Unresolved,,Unassigned,Andrew Bayer,Wed; 23 Nov 2011 00:40:28 +0000,Wed; 23 Nov 2011 00:40:28 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3457
MAPREDUCE-3458,Bug,Major,mrv2,Fix findbugs warnings in hadoop-examples,I see 12 findbugs warnings in hadoop-examples:  https: newPatchFindbugsWarningshadoop-mapreduce-examples.html,Closed,Fixed,,Devaraj K,Arun C Murthy,Wed; 23 Nov 2011 01:47:13 +0000,Mon; 5 Mar 2012 02:49:31 +0000,Sun; 4 Dec 2011 20:00:43 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3458
MAPREDUCE-3459,Bug,Major,,ant build is broken in branch-23,ant build is broken in 0.23. A small snippet:                                          ^,Resolved,Invalid,,Unassigned,John George,Wed; 23 Nov 2011 02:22:43 +0000,Wed; 23 Nov 2011 03:14:30 +0000,Wed; 23 Nov 2011 03:14:30 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3459
MAPREDUCE-3460,Bug,Blocker,mr-am;mrv2,MR AM can hang if containers are allocated on a node blacklisted by the AM,When an AM is assigned a FAILED_MAP (priority = 5) container on a nodemanager which it has blacklisted - it tries to find a corresponding container request. This uses the hostname to find the matching container request - and can end up returning any of the ContainerRequests which may have requested a container on this node. This container request is cleaned to remove the bad node - and then added back to the RM 'ask' list. The AM cleans the 'ask' list after each heartbeat - The RM Allocator is still aware of the priority=5 container (in 'remoteRequestsTable') - but this never gets added back to the 'ask' set - which is what is sent to the RM.,Closed,Fixed,,Robert Joseph Evans,Siddharth Seth,Wed; 23 Nov 2011 04:16:55 +0000,Tue; 10 Mar 2015 04:31:52 +0000,Fri; 2 Dec 2011 22:23:13 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3460
MAPREDUCE-3461,Improvement,Major,documentation,Move hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-site to hadoop-site,Currently hadoop-mapreduce-project hadoop-yarn-site has both HDFS and MR docs; we should move it to top-level hadoop-site.,Open,Unresolved,,Unassigned,Arun C Murthy,Wed; 23 Nov 2011 06:52:28 +0000,Wed; 18 Apr 2012 20:27:51 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3461
MAPREDUCE-3462,Bug,Blocker,mrv2;test,Job submission failing in JUnit tests,When I run JUnit tests (e.g. TestDistCacheEmulation; TestSleepJob and TestCompressionEmulationUtils); I see job submission failing with the following error:,Closed,Fixed,,Ravi Prakash,Amar Kamat,Wed; 23 Nov 2011 09:06:08 +0000,Mon; 5 Mar 2012 02:48:53 +0000,Wed; 4 Jan 2012 05:40:14 +0000,,0.23.0,junit;test,,MAPREDUCE-3168,https://issues.apache.org/jira/browse/MAPREDUCE-3462
MAPREDUCE-3463,Bug,Blocker,applicationmaster;mrv2,Second AM fails to recover properly when first AM is killed with java.lang.IllegalArgumentException causing lost job,Set yarn.resourcemanager.am.max-retries=5 in yarn-site.xml. Started yarn 4 Node cluster. First Ran Randowriter Sort-validate successfully Then again sort; when job was 50% complete Login node running AppMaster; and killed AppMaster with kill -9 On Client side failed with following:    On lookig RM logs found second AM was also lauched; it was saying -:    Now looking at AM logs and found Second AM was shutdown gracefully due to :-,Closed,Fixed,,Siddharth Seth,Karam Singh,Wed; 23 Nov 2011 13:45:46 +0000,Mon; 5 Mar 2012 02:49:09 +0000,Thu; 1 Dec 2011 08:37:34 +0000,,0.23.1,,MAPREDUCE-3450,,https://issues.apache.org/jira/browse/MAPREDUCE-3463
MAPREDUCE-3464,Bug,Trivial,,mapreduce jsp pages missing DOCTYPE [post-split branches],Some jsp pages in the UI are missing a DOCTYPE declaration. This causes the pages to render incorrectly on some browsers; such as IE9. Please see parent bug HADOOP-7827 for details and patch.,Closed,Fixed,,Dave Vronay,Dave Vronay,Wed; 23 Nov 2011 18:07:42 +0000,Mon; 5 Mar 2012 02:48:51 +0000,Wed; 23 Nov 2011 18:08:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3464
MAPREDUCE-3465,Bug,Minor,mrv2,org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin fails on 0.23 ,Running org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin Tests run: 2; Failures: 0; Errors: 2; Skipped: 0; Time elapsed: 0.121 sec &lt; FAILURE! Tests in error:    testParsingProcStatAndCpuFile(org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin):  MEMINFO_943711651 (No such file or directory),Closed,Fixed,,Hitesh Shah,Hitesh Shah,Wed; 23 Nov 2011 19:12:07 +0000,Mon; 5 Mar 2012 02:48:47 +0000,Tue; 29 Nov 2011 01:15:37 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3465
MAPREDUCE-3466,Bug,Critical,,hadoop-mapreduce-tools*.jar does not seem to be updated on maven repo,I do not see any listing for hadoop-mapreduce-tools at https: . There is one for hadoop-mapred-tools but that has not been updated in a long time.,Resolved,Duplicate,NULL,Unassigned,John George,Wed; 23 Nov 2011 21:35:13 +0000,Wed; 23 Nov 2011 22:08:02 +0000,Wed; 23 Nov 2011 22:08:02 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3466
MAPREDUCE-3467,Bug,Critical,,Mavenizing har,As part of mapreduce mavenization; har should also be mavenized and added to maven repo,Resolved,Duplicate,HADOOP-7810,Unassigned,John George,Wed; 23 Nov 2011 22:32:25 +0000,Thu; 22 Dec 2011 19:00:59 +0000,Thu; 22 Dec 2011 19:00:59 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3467
MAPREDUCE-3468,Task,Major,,Change version to 0.23.1 for ant builds on the 23 branch,Maven version has been changed to 0.23.1-SNAPSHOT. The ant build files need to change as well.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 24 Nov 2011 04:13:43 +0000,Mon; 5 Mar 2012 02:49:08 +0000,Thu; 24 Nov 2011 06:09:26 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3468
MAPREDUCE-3469,Improvement,Major,,Port to 0.22 - Implement limits on per-job JobConf; Counters; StatusReport; Split-Sizes,We have come across issues in production clusters wherein users abuse counters; statusreport messages and split sizes. One such case was when one of the users had 100 million counters. This leads to jobtracker going out of memory and being unresponsive. In this jira I am proposing to put sane limits on the status report length; the number of counters and the size of block locations returned by the input split.,Resolved,Duplicate,NULL,Konstantin Shvachko,Mahadev konar,Thu; 24 Nov 2011 06:55:24 +0000,Fri; 7 Feb 2014 23:11:36 +0000,Fri; 7 Feb 2014 23:11:36 +0000,,,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-3469
MAPREDUCE-3470,Bug,Major,jobtracker,Jobtracker sets permissions on mapred.system.dir to 700 preventing non-superusers from submitting jobs to multi-user cluster,(See thread discussing here - https: how else to raise this.   Changed introduced in MAPREDUCE-2219,Closed,Duplicate,MAPREDUCE-4451,Unassigned,stephen mulcahy,Thu; 24 Nov 2011 13:59:24 +0000,Wed; 15 May 2013 05:16:07 +0000,Sat; 20 Oct 2012 09:33:44 +0000,,0.20.205.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3470
MAPREDUCE-3471,New Feature,Major,,Provide NullOutputCommitter,Hadoop by default provides only FileOutputCommitter and the same has been used internally except in the NOF. There are cases where using FOC is not much appropriate.  Example DBOutputFormat instantiates FOC; though it does nothing. I think using NOC will be much more appropriate here.  And also it can be used along with other OFs; where taking special care of the task job output directories may not be required.,Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Thu; 24 Nov 2011 18:22:42 +0000,Mon; 20 Feb 2012 08:18:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3471
MAPREDUCE-3472,Bug,Major,,Port to 0.22 - The capacity-scheduler should assign multiple tasks per heartbeat,HADOOP-3136 changed the default o.a.h.mapred.JobQueueTaskScheduler to assign multiple tasks per TaskTracker heartbeat; MAPREDUCE-517 added this to the capacity-scheduler.  We should port this to branch-0.22 too.,Open,Unresolved,,Mayank Bansal,Arun C Murthy,Thu; 24 Nov 2011 22:03:58 +0000,Tue; 10 Jul 2012 21:27:09 +0000,,,,critical-0.22.0,,,https://issues.apache.org/jira/browse/MAPREDUCE-3472
MAPREDUCE-3473,Improvement,Major,tasktracker,A single task tracker failure shouldn't result in Job failure ,Currently some task failures may result in job failures. Eg a local TT disk failure seen in TaskLauncher#run; TaskRunner#run; MapTask#run is visible to and can hang the JobClient; causing the job to fail. Job execution should always be able to survive a task failure if there are sufficient resources.,Open,Unresolved,,Unassigned,Eli Collins,Sun; 27 Nov 2011 22:16:37 +0000,Thu; 22 Dec 2011 09:03:33 +0000,,,0.20.205.0;0.23.0,,,MAPREDUCE-3121,https://issues.apache.org/jira/browse/MAPREDUCE-3473
YARN-92,Sub-task,Major,nodemanager,NM disk failure detection only covers local dirs ,This is the MR counterpart to HDFS-1848. Like HDFS volume failure detection; NM disk failure detection checks a subset of the disks; and a subset of the directories. Eg the TT and the NM do not check the root disk for errors unless a local dir resides on them. Even if a local dir resides on the root disk the disk checking code only checks the local dirs so a failure only seen when accessing a part of the disk no hosting the local dirs will not be noticed. The disk that hosts the logs; pid; tmp dirs etc is critical; so if needs to be checked as well; and the NM should shutdown if a critical disk is not available (to prevent MR issues similar to HDFS-1848 and HDFS-2095). Typically people currently work around this limitation by (aside from ignoring it) by using raid-1 for the root disk or a health script that checks the root disk health.,Open,Unresolved,,Unassigned,Eli Collins,Sun; 27 Nov 2011 22:31:16 +0000,Sat; 8 Sep 2012 00:14:54 +0000,,,,,,HDFS-2095,https://issues.apache.org/jira/browse/YARN-92
MAPREDUCE-3475,Bug,Major,jobtracker,JT can't renew its own tokens,When external systems submit jobs whose tasks need to submit additional jobs (such as oozie GSSAPI exceptions when the job is submitted.  It is also dubious for the JT to renew its token because it renders the expiry as meaningless since the JT will renew its own token until the max lifetime is exceeded.  After speaking with Owen  Jitendra; the immediate solution is for the JT to not attempt to renew its own tokens.,Resolved,Fixed,,Daryn Sharp,Daryn Sharp,Mon; 28 Nov 2011 16:04:05 +0000,Tue; 10 Mar 2015 02:50:56 +0000,Tue; 10 Mar 2015 02:50:55 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3475
MAPREDUCE-3476,Sub-task,Major,mrv2,Optimize YARN API calls,Several YARN API calls are taking inordinately long. This might be a performance blocker.,Resolved,Later,,Vinod Kumar Vavilapalli,Ravi Prakash,Mon; 28 Nov 2011 17:06:49 +0000,Tue; 22 Apr 2014 19:13:26 +0000,Tue; 22 Apr 2014 19:13:26 +0000,,0.23.0,,,MAPREDUCE-3719,https://issues.apache.org/jira/browse/MAPREDUCE-3476
MAPREDUCE-3477,Bug,Major,documentation;mrv2,Hadoop site documentation cannot be built anymore on trunk and branch-0.23,Maven fails and here is the issue I get:  ERROR Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.0:site (default-site) on project hadoop-yarn-site: Error during page generation: Error parsing ' rpm-tmp.OFegWv (%build),Closed,Fixed,,Jonathan Eagles,Bruno Mah  ,Mon; 28 Nov 2011 20:44:41 +0000,Tue; 10 Mar 2015 04:31:43 +0000,Wed; 30 Nov 2011 20:52:18 +0000,,0.23.1;2.0.0-alpha,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3477
MAPREDUCE-3478,Bug,Minor,mrv2,Cannot build against ZooKeeper 3.4.0,I tried to see if one could build Hadoop 0.23.0 against ZooKeeper 3.4.0; rather than 3.3.1 (3.3.3 does work; fwiw) and hit compilation errors:   INFO ------------------------------------------------------------------------ ERROR Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:testCompile (default-testCompile) on project hadoop-yarn-server-common: Compilation failure: Compilation failure: ERROR   150;33 cannot find symbol ERROR symbol  : class Factory ERROR location: class org.apache.zookeeper.server.NIOServerCnxn ERROR - Help 1  Presumably; Yarn needs to build against newer ZK releases eventually; hence this bug. =),Closed,Fixed,,Tom White,Andrew Bayer,Tue; 29 Nov 2011 01:03:02 +0000,Mon; 5 Mar 2012 02:49:45 +0000,Thu; 5 Jan 2012 00:16:15 +0000,,0.23.0,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3478
MAPREDUCE-3479,Bug,Major,client,JobClient#getJob cannot find local jobs,The problem is that JobClient#submitJob doesn't pass the Cluster object to Job for the submission process; which means that two Cluster objects and two LocalJobRunner objects are created. LocalJobRunner keeps an instance map of job IDs to Jobs; and when JobClient#getJob is called the LocalJobRunner with the unpopulated map is used which results in the job not being found.,Closed,Fixed,,Tom White,Tom White,Tue; 29 Nov 2011 01:10:42 +0000,Mon; 5 Mar 2012 02:49:49 +0000,Sat; 3 Dec 2011 00:23:01 +0000,,0.23.0,,,HIVE-2468,https://issues.apache.org/jira/browse/MAPREDUCE-3479
MAPREDUCE-3480,Bug,Major,,TestJvmReuse fails in 1.0,TestJvmReuse is failing in apache builds; although it passes in my local machine.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Tue; 29 Nov 2011 08:08:21 +0000,Wed; 6 Feb 2013 04:12:32 +0000,Tue; 29 Nov 2011 20:21:36 +0000,,,,,MAPREDUCE-4979,https://issues.apache.org/jira/browse/MAPREDUCE-3480
MAPREDUCE-3481,Improvement,Major,contrib/gridmix,[Gridmix] Improve STRESS mode locking,Gridmix STREES mode code doesnt sufficiently load the cluster due to improper locking.,Closed,Fixed,,Amar Kamat,Amar Kamat,Tue; 29 Nov 2011 08:58:56 +0000,Tue; 10 Mar 2015 04:32:53 +0000,Mon; 30 Jan 2012 06:27:54 +0000,,0.23.0;2.0.0-alpha,gridmix;locking;stress-mode,MAPREDUCE-3719,MAPREDUCE-1687;MAPREDUCE-3769,https://issues.apache.org/jira/browse/MAPREDUCE-3481
MAPREDUCE-3482,Improvement,Major,applicationmaster;mrv2,Enable HTTP proxy to be specified for job end notification,Courtesy Ratandeep Singh Ratti  The AM should be able to notify the job.end.notification.url. Hence this request has to go through HTTP proxy; since ACLs won't be open from the AM to external machines.,Resolved,Duplicate,MAPREDUCE-3382,Anupam Seth,Ravi Prakash,Tue; 29 Nov 2011 17:52:28 +0000,Tue; 29 Nov 2011 19:07:23 +0000,Tue; 29 Nov 2011 19:07:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3482
MAPREDUCE-3483,Bug,Major,mrv2,CapacityScheduler reserves container on same node as AM but can't ever use due to never enough avail memory,Saw a case where a job was stuck trying to get reducers.  The issue is the capacity scheduler reserved a container on the same node as the application master but there wasn't ever enough memory to run the reducer on that node.  Node total memory was 8G; Reducer needed 8G; AM was using 2G.  This particular job had 10 reducers and it was stuck waiting on the one because the AM + reserved reducer memory was already over the queue limit.,Open,Unresolved,,Arun C Murthy,Thomas Graves,Tue; 29 Nov 2011 21:10:01 +0000,Sat; 7 Jan 2017 02:00:02 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3483
MAPREDUCE-3484,Bug,Major,mr-am;mrv2,JobEndNotifier is getting interrupted before completing all its retries.,We noticed JobEndNotifier was getting an InterruptedException before completing all its retries.  To fix this; Job end notification method should be called before stop() in handle(JobFinishEvent).,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Tue; 29 Nov 2011 22:04:32 +0000,Mon; 5 Mar 2012 02:49:31 +0000,Thu; 15 Dec 2011 00:02:51 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3484
MAPREDUCE-3485,Sub-task,Major,mrv2,DISKS_FAILED -101 error code should be defined in same location as ABORTED_CONTAINER_EXIT_STATUS,With MAPREDUCE-3121; it is defined in ContainerExecutor as part of yarn-nodemanager which would be a problem for client-side code if it needs to understand the exit code.   A short term fix would be to move it into YarnConfiguration where ABORTED_CONTAINER_EXIT_STATUS is defined. A longer term fix would be to find a more formal and extensible approach for new yarn framework error codes to be added and be easily accessible to client-side code or other AMs.,Closed,Fixed,,Ravi Gummadi,Hitesh Shah,Tue; 29 Nov 2011 23:33:46 +0000,Tue; 10 Mar 2015 04:32:23 +0000,Sun; 4 Dec 2011 20:12:54 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3485
MAPREDUCE-3486,Bug,Minor,jobtracker,All jobs of all queues will be returned; whethor a particular queueName is specified or not,JobTracker.getJobsFromQueue(queueName) will return all jobs of all queues about the jobtracker even though i specify a queueName.,Patch Available,Unresolved,,XieXianshan,XieXianshan,Wed; 30 Nov 2011 13:28:43 +0000,Wed; 6 May 2015 03:33:00 +0000,,,1.1.3;1.3.0;1.2.2,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3486
MAPREDUCE-3487,Bug,Critical,mrv2,jobhistory web ui task counters no longer links to singletakecounter page,The task counters on the job history task counter web ui page ( ie host:19888 task_1322451030861_9_9_m_0) are no longer links. They are supposed to be links that take you to the singletaskcounter page and show you the task attempts that affected the counter.  Looks like MAPREDUCE-3258  changed CounterBlock. so it doesn't show the link on the counter:  if (mg == null &amp; rg == null)  {            groupRow.td().$title(counter.getName())._(counter.getDisplayName()).             _();           }  else {,Closed,Fixed,,Jason Lowe,Thomas Graves,Wed; 30 Nov 2011 19:01:48 +0000,Mon; 5 Mar 2012 02:49:40 +0000,Fri; 16 Dec 2011 01:52:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3487
MAPREDUCE-3488,Bug,Blocker,mrv2,Streaming jobs are failing because the main class isnt set in the pom files.,Streaming jobs are failing since the main MANIFEST file isnt being set in the pom files.,Closed,Fixed,,Mahadev konar,Mahadev konar,Wed; 30 Nov 2011 19:48:51 +0000,Mon; 5 Mar 2012 02:49:13 +0000,Wed; 30 Nov 2011 21:22:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3488
MAPREDUCE-3489,Bug,Minor,mrv2,EventDispatcher should have a call-back on errors for aiding tests,If one of the dispatched events generates an exception - the dispatcher kills the JVM via a System.exit. Unit tests end up not running - but they don't fail either. TestTaskAttempt is currently running like this. Previously - have seen TestRecovery and TestJobHistoryParsing do the same. Most of the tests would need to be looked at.,Open,Unresolved,,Sharad Agarwal,Siddharth Seth,Thu; 1 Dec 2011 01:13:44 +0000,Sun; 26 Feb 2012 05:30:44 +0000,,,0.23.0,,MAPREDUCE-3634,,https://issues.apache.org/jira/browse/MAPREDUCE-3489
MAPREDUCE-3490,Bug,Blocker,mr-am;mrv2,RMContainerAllocator counts failed maps towards Reduce ramp up,The RMContainerAllocator does not differentiate between failed and successful maps while calculating whether reduce tasks are ready to launch. Failed tasks are also counted towards total completed tasks.  Example. 4 failed maps; 10 total maps. Map%complete = 4 14 * 100 instead of being 0.,Closed,Fixed,,Sharad Agarwal,Siddharth Seth,Thu; 1 Dec 2011 01:17:20 +0000,Mon; 5 Mar 2012 02:49:33 +0000,Wed; 4 Jan 2012 17:12:11 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3490
MAPREDUCE-3491,Bug,Major,task-controller,TestContainerManagerWithLCE is failing,$ mvn test -Dtest=TestContainerManagerWithLCE -Dapplication.submitter=nobody -Dyarn.nodemanager.linux-container-executor.path=path of container-executor binary   TestContainerManagerWithLCE is failing with the error:  Test set: org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE ------------------------------------------------------------------------------- Tests run: 6; Failures: 5; Errors: 0; Skipped: 0; Time elapsed: 26.219 sec &lt; FAILURE! testContainerSetup(org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE)  Time elapsed: 2.476 sec  &lt; FAILURE! junit.framework.AssertionFailedError: workspace application_0_0000 doesn't exist!!   at junit.framework.Assert.fail(Assert. 83),Resolved,Fixed,,Unassigned,Ravi Gummadi,Thu; 1 Dec 2011 06:08:27 +0000,Tue; 10 Mar 2015 04:31:57 +0000,Mon; 9 Mar 2015 21:52:04 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3491
MAPREDUCE-3492,Bug,Major,examples,mapreduce examples jar is not built properly,"When I try to build examples jar using ""ant -Dresolvers=internal examples"" in trunk; the jar created in build  directory is of very small size; may be empty jar. And trying to run wordcount job gives the error:  Exception in thread ""main""  193)",Open,Unresolved,,Unassigned,Ravi Gummadi,Thu; 1 Dec 2011 09:25:18 +0000,Sun; 11 Dec 2011 04:05:19 +0000,,,,,,MAPREDUCE-3446,https://issues.apache.org/jira/browse/MAPREDUCE-3492
MAPREDUCE-3493,Bug,Minor,mrv2,Add the default mapreduce.shuffle.port property to mapred-default.xml,I faced this issue when trying to run multiple Hadoop MR2 instances on the same node. The default value for this property is hardcoded in the ShuffleHandler. class so it results in port conflicts. The issue is resolved if you set the property value in your conf files. But the absence of this property from *-default.xml files is confusing. So It'll be cleaner to move this property to mapred-default.xml; so its default value can be easily identified and changed if needed.,Closed,Fixed,,Unassigned,Ahmed Radwan,Thu; 1 Dec 2011 09:35:55 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Tue; 29 May 2012 16:16:08 +0000,,2.0.0-alpha,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-3493
YARN-41,New Feature,Major,nodemanager;resourcemanager,The RM should handle the graceful shutdown of the NM.,Instead of waiting for the NM expiry; RM should remove and handle the NM; which is shutdown gracefully.,Resolved,Fixed,YARN-2680,Devaraj K,Ravi Teja Ch N V,Thu; 1 Dec 2011 10:22:34 +0000,Tue; 30 Aug 2016 01:32:30 +0000,Thu; 4 Jun 2015 11:42:00 +0000,,,,,MAPREDUCE-3585;MAPREDUCE-3363,https://issues.apache.org/jira/browse/YARN-41
MAPREDUCE-3495,Bug,Major,build,Remove my personal email address from the pipes build file.,When I first wrote the pipes autoconf automake stuff; I incorrectly put my email address in the AC_INIT line; which means if something goes wrong; you get:    configure: WARNING:     ## Report this to my-email ##,Resolved,Duplicate,MAPREDUCE-4267,Owen O'Malley,Owen O'Malley,Thu; 1 Dec 2011 16:11:23 +0000,Sat; 7 Feb 2015 00:11:30 +0000,Sat; 7 Feb 2015 00:11:30 +0000,,,,,HDFS-2619,https://issues.apache.org/jira/browse/MAPREDUCE-3495
MAPREDUCE-3496,Bug,Major,mrv2,Yarn initializes ACL operations from capacity scheduler config in a non-deterministic order,'mapred queue -showacls' does not output put acls in a predictable manner. This is a regression from previous versions.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 1 Dec 2011 18:01:55 +0000,Tue; 10 Mar 2015 04:31:49 +0000,Tue; 6 Dec 2011 01:38:00 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3496
MAPREDUCE-3497,Bug,Major,documentation;mrv2,missing documentation for yarn cli and subcommands - similar to commands_manual.html,the yarn cli and sub-commands aren't documented anywhere.  Should have documentation similar to the commands_manual.html,Resolved,Fixed,,Thomas Graves,Thomas Graves,Thu; 1 Dec 2011 22:02:28 +0000,Mon; 5 Mar 2012 13:25:43 +0000,Sun; 4 Mar 2012 23:52:50 +0000,,0.23.0,,,HADOOP-8137,https://issues.apache.org/jira/browse/MAPREDUCE-3497
YARN-126,Bug,Major,client,yarn rmadmin help message contains reference to hadoop cli and JT,"has option to specify a job tracker and the last line for general command line syntax had ""bin hadoop command genericOptions commandOptions",Resolved,Won't Fix,,R  my Saissy,Thomas Graves,Thu; 1 Dec 2011 22:05:40 +0000,Fri; 6 Jan 2017 20:41:01 +0000,Fri; 6 Jan 2017 20:41:01 +0000,,2.0.3-alpha,usability,,,https://issues.apache.org/jira/browse/YARN-126
MAPREDUCE-3499,Bug,Blocker,mrv2;test,New MiniMR does not setup proxyuser configuration correctly; thus tests using doAs do not work,The new MiniMR implementation is not taking proxyuser settings.  Because of this; testcases using testing doAs functionality fail.  This affects all Oozie testcases that use MiniMR.,Closed,Fixed,,John George,Alejandro Abdelnur,Fri; 2 Dec 2011 00:04:38 +0000,Tue; 10 Mar 2015 04:33:03 +0000,Wed; 1 Feb 2012 17:10:44 +0000,,0.23.1;2.0.0-alpha,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3499
MAPREDUCE-3500,Bug,Major,mrv2,MRJobConfig creates an LD_LIBRARY_PATH using the platform ARCH,With HADOOP-7874 we are removing the arch from the  library.path.  The LD_LIBRARY_PATH being set should not include the ARCH.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 2 Dec 2011 00:51:25 +0000,Tue; 10 Mar 2015 04:33:03 +0000,Sat; 3 Dec 2011 01:09:27 +0000,,0.23.1;2.0.0-alpha,bigtop,,HADOOP-7874,https://issues.apache.org/jira/browse/MAPREDUCE-3500
MAPREDUCE-3501,Bug,Minor,mrv2;scheduler,Fifo scheduler does not match host requests with host:port correctly,When the Fifo scheduler receives a heartbeat from a NM the NM appears as a HOST:PORT.  When a request is made to the scheduler to have a container run on a given host that request is given just as HOST.  Right now the FIFO scheduler does not use just the HOST part of HOST:PORT for the comparison.  This is minor because very few people will run with the FIFO scheduler on a cluster at all; but it still needs ot be fixed.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Fri; 2 Dec 2011 15:44:43 +0000,Tue; 10 Mar 2015 04:32:37 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3501
MAPREDUCE-3502,Task,Major,mrv2,Review all Service.stop() operations and make sure that they work before a service is started,"MAPREDUCE-3431 has shown that some of the key services's shutdown operations are not robust against being invoked before the service is started. They need to be by   	not calling other things if the other things are null 	not being re-entrant (i.e. make synchronized if possible);    Maybe   	have a StopService operation that only stops a service if it is live 	factor out the is-running test from the base service class and make it a pre-check for all the child services; so they bail out sooner rather than later. This would be the best as it would be the one guaranteed to work consistently across all instances; so only one or two would need testing    my first iteration will skip the sync though it's something to consider.   Testing: try to create each instance; call stop() straight after construction.",Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 2 Dec 2011 17:16:23 +0000,Tue; 10 Mar 2015 04:32:33 +0000,Mon; 24 Jun 2013 15:46:02 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3502
MAPREDUCE-3503,Bug,Major,capacity-sched,capacity scheduler allow capacity greater then 100% as long as its less then 101%,When sum of all capacities =101 or 100; we got the following error when starting jobtracker. However; when the 100 = sum  101; jobtracker does not report exception and started with all queues initialized. for instance (capacity sum = 29.5+60+11.4 = 100.9) does not cause exception.,Resolved,Duplicate,MAPREDUCE-3504,Unassigned,Thomas Graves,Fri; 2 Dec 2011 20:08:43 +0000,Thu; 16 Feb 2012 12:50:13 +0000,Thu; 16 Feb 2012 12:50:13 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3503
MAPREDUCE-3504,Bug,Major,capacity-sched,capacity scheduler allow capacity greater then 100% as long as its less then 101%,When sum of all capacities =101 or 100; we got the following error when starting jobtracker. However; when the 100 = sum  101; jobtracker does not report exception and started with all queues initialized. for instance (capacity sum = 29.5+60+11.4 = 100.9) does not cause exception.,Resolved,Won't Fix,,Unassigned,Thomas Graves,Fri; 2 Dec 2011 20:08:45 +0000,Wed; 11 Mar 2015 23:36:18 +0000,Wed; 11 Mar 2015 23:36:18 +0000,,0.20.205.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3504
MAPREDUCE-3505,Bug,Major,mrv2,yarn APPLICATION_CLASSPATH needs to be overridable,Right now MRApps sets the classpath to just being mrapp-generated-classpath; its content and a hardcoded list of directories. If I understand correctly mrapp-generated-classpath is only there for testing and may change or disappear at any time  The list of hardcoded directories is defined in hadoop-mapreduce-project  at line 92. For convenience; here is its current content:    Not all deployment scenarii fit in this layout and therefore we need a standardized way to customize this class path.,Closed,Fixed,,Ahmed Radwan,Bruno Mah  ,Fri; 2 Dec 2011 23:59:10 +0000,Mon; 5 Mar 2012 02:49:41 +0000,Tue; 24 Jan 2012 18:26:27 +0000,,0.23.0,bigtop,,MAPREDUCE-3389,https://issues.apache.org/jira/browse/MAPREDUCE-3505
MAPREDUCE-3506,Bug,Minor,client;mrv2,Calling getPriority on JobInfo after parsing a history log with JobHistoryParser throws a NullPointerException,Somehow the priority field under JobHistoryParser.JobInfo is not set. Calling getPriority on Jobinfo after parsing a Job hisotry log throws NPE,Closed,Fixed,MAPREDUCE-3912,Jason Lowe,Ratandeep Ratti,Sat; 3 Dec 2011 20:51:22 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Tue; 21 Aug 2012 15:24:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3506
MAPREDUCE-3507,Improvement,Major,mrv2,Remove Cluster as a public API on the client side.,This has been a major source of grief for me when fixing MAPREDUCE-3443 and MAPREDUCE-3380. The public API of cluster is very confusing and doesnt add any value to the client side. This has caused more confusion with the current jobclient cluster interaction currently in the code base. It would be best to make this private before folks actually start using it and we will end up supporting this broken API for a long time.,Open,Unresolved,,Unassigned,Mahadev konar,Mon; 5 Dec 2011 02:59:18 +0000,Mon; 9 Mar 2015 21:53:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3507
MAPREDUCE-3508,New Feature,Major,tools/rumen,[Rumen] Rumen should provide simple trace filtering capabilities,Rumen should provide inbuilt tools to filter jobs from a given trace. Following are the usecases: 1. Select only first k jobs. 2. Select jobs with certain configuration keys set or available 3. Select jobs where the original job id matches the specified list 4. Select jobs which have at-least at-most y reduce tasks. 5. Select jobs belonging to a specific user(s) 6. Select jobs having specific name(s) and so on.,Open,Unresolved,,Amar Kamat,Amar Kamat,Mon; 5 Dec 2011 09:21:22 +0000,Mon; 9 Mar 2015 22:06:15 +0000,,,,job-filter;rumen,,,https://issues.apache.org/jira/browse/MAPREDUCE-3508
MAPREDUCE-3509,Improvement,Major,mrv2,improve MRApp generated classpath,With MAPREDUCE-3389 it is possible for downstream projects to seed the file with the required classpath for MRApp.   MRApps should resolve this patch automatically and transparent to downstream projects.,Open,Unresolved,,Unassigned,Alejandro Abdelnur,Mon; 5 Dec 2011 18:07:28 +0000,Tue; 10 Mar 2015 04:32:34 +0000,,,0.23.1;2.0.0-alpha,,,MAPREDUCE-3428;MAPREDUCE-3389,https://issues.apache.org/jira/browse/MAPREDUCE-3509
MAPREDUCE-3510,Bug,Major,capacity-sched;mrv2,Capacity Scheduler inherited ACLs not displayed by mapred queue -showacls,mapred queue -showacls does not show inherited acls,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 5 Dec 2011 21:20:33 +0000,Tue; 10 Mar 2015 04:32:39 +0000,Tue; 13 Dec 2011 00:26:20 +0000,,0.23.1;2.0.0-alpha,,MAPREDUCE-3522,,https://issues.apache.org/jira/browse/MAPREDUCE-3510
MAPREDUCE-3511,Sub-task,Blocker,mr-am;mrv2,Counters occupy a good part of AM heap,Per task counters seem to be occupying a good part of an AMs heap. Looks like more than 50% of what's used by a TaskAttemptImpl object. This could be optimized by interning strings or possibly using mrv1 counters which are optimized. Currently counters are converted from mrv1 to mrv2 format for in memory storage. The conversion could be delayed till it's actually required for RPC transfers.,Closed,Fixed,,Vinod Kumar Vavilapalli,Siddharth Seth,Tue; 6 Dec 2011 00:27:04 +0000,Mon; 5 Mar 2012 02:49:54 +0000,Mon; 9 Jan 2012 21:08:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3511
MAPREDUCE-3512,Sub-task,Blocker,mr-am;mrv2,Batch jobHistory disk flushes,The mr-am flushes each individual job history event to disk for AM recovery. The history even handler ends up with a significant backlog for tests like MAPREDUCE-3402.  History events could be batched up based on num records   TaskFinishedEvents to reduce the number of DFS writes - with the potential drawback of having to rerun some tasks during AM recovery.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 6 Dec 2011 00:33:04 +0000,Mon; 5 Mar 2012 02:49:34 +0000,Thu; 12 Jan 2012 01:44:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3512
MAPREDUCE-3513,Bug,Trivial,mrv2,Capacity Scheduler web UI has a spelling mistake for Memory.,"The web page for capacity scheduler has a column named ""Memopry Total""; a spelling mistake which needs to be fixed.",Closed,Fixed,,chackaravarthy,Mahadev konar,Tue; 6 Dec 2011 01:46:08 +0000,Mon; 5 Mar 2012 02:48:51 +0000,Fri; 9 Dec 2011 02:02:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3513
MAPREDUCE-3514,Bug,Major,jobhistoryserver;mrv2,JHS failed to start when intermediate done path is in LocalFS,This is the property I have set for intermediate done directory    After setting this property; When I started the JHS; it failed to start; and was throwing following exception,Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Tue; 6 Dec 2011 12:08:42 +0000,Tue; 10 Mar 2015 04:32:14 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3514
MAPREDUCE-3515,Bug,Major,mrv2,hadoop 0.23: native compression libraries not being loaded,I installed the hadoop package from the Bigtop hadoop 0.23 branch. Among other files; the package installs   part-r-00000.gz  so the output is compressed; but from the log message; I assume that the native library is not being loaded and that the  gzip is being used.,Resolved,Duplicate,MAPREDUCE-3500,Unassigned,Wing Yew Poon,Tue; 6 Dec 2011 22:46:53 +0000,Tue; 20 Dec 2011 23:40:29 +0000,Tue; 20 Dec 2011 23:40:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3515
MAPREDUCE-3516,Bug,Major,mrv2,Possible NPE in org.apache.hadoop.mapred.MapTask.MapOutputBuffer.collect(K key; V value; int partition),org.apache.hadoop.mapred.MapTask.MapOutputBuffer.collect accepts a pair of Key and Value. There is chance that if somehow if a Null value or Key is passed to the method; we can end up having NPE.,Open,Unresolved,,Subroto Sanyal,Subroto Sanyal,Wed; 7 Dec 2011 04:21:56 +0000,Mon; 23 Jan 2012 12:21:05 +0000,,,0.20.1;0.20.2;0.20.203.0;0.20.205.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3516
MAPREDUCE-3517,Bug,Major,task," ""map.input.path"" is null at the first split when use CombieFileInputFormat","map.input.path is null at the first split when use CombieFileInputFormat. because in runNewMapper function; mapContext instead of taskContext which is set ""map.input.path"".  so we need set ""map.input.path"" again to mapContext",Patch Available,Unresolved,,Unassigned,wanbin,Wed; 7 Dec 2011 09:59:08 +0000,Wed; 6 May 2015 03:34:42 +0000,,,0.20.203.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3517
MAPREDUCE-3518,Bug,Critical,client;mrv2,mapred queue -info <queue> -showJobs throws NPE,"mapred queue -info default -showJobs  Exception in thread ""main""  234)",Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 7 Dec 2011 22:49:40 +0000,Tue; 10 Mar 2015 04:31:50 +0000,Mon; 12 Dec 2011 23:12:15 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3518
MAPREDUCE-3519,Sub-task,Blocker,mrv2;nodemanager,Deadlock in LocalDirsHandlerService and ShuffleHandler,MAPREDUCE-3121 cloned Configuration object in LocalDirsHandlerService.init() to avoid others to access that configuration object. But since it is used in local FileSystem object creation in LocalDirAllocator.AllocatorPerContext and the same FileSystem object is used in ShuffleHandler.Shuffle.localDirAllocator; this is causing a deadlock when accessing this configuration object from LocalDirsHandlerService and ShuffleHandler along with AllocatorPerContext object.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Thu; 8 Dec 2011 05:02:53 +0000,Tue; 10 Mar 2015 04:32:58 +0000,Fri; 9 Dec 2011 23:21:04 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3519
MAPREDUCE-3520,New Feature,Major,mrv2,Allow for metrics to be exchanged between maps and reduces,Some people on the mailing lists have requested having read access in reducers to counters that were set by mappers.  I propose that we provide a new interface for doing this.  The counter data in addition to being set periodically to the Application Master would be put into the intermediate output of the mapper for each reducer and be specially marked as such.  When the reducers fetch that data they can combine it together and provide a read only interface to it.  This allows users to potentially optimize their code on the reducer side if they know some special metadata before hand.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Thu; 8 Dec 2011 16:13:28 +0000,Tue; 10 Mar 2015 04:32:52 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3520
MAPREDUCE-3521,Bug,Minor,mrv2,Hadoop Streaming ignores unknown parameters,The hadoop streaming command will ignore any command line arguments to it.     Works just fine.  This can mask issues where quotes were mistakenly missed like     Streaming should fail if it encounters an unexpected command line parameter,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 8 Dec 2011 22:12:10 +0000,Mon; 5 Mar 2012 02:49:50 +0000,Thu; 29 Dec 2011 08:25:51 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3521
MAPREDUCE-3522,Bug,Major,mrv2,Capacity Scheduler ACLs not inherited by default,Hierarchical Queues do not inherit parent ACLs correctly by default. Instead; if no value is specified for submit or administer acls; then all access is granted.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 8 Dec 2011 23:15:35 +0000,Mon; 5 Mar 2012 02:48:42 +0000,Thu; 29 Dec 2011 19:08:41 +0000,,0.23.0,,MAPREDUCE-3510,,https://issues.apache.org/jira/browse/MAPREDUCE-3522
MAPREDUCE-3523,Bug,Major,mrv2,Exclude mrapp-generated-classpath from published jars,Downstream projects will be generating their own classpath file to allow yarn to launch containers correctly in a unit-test env which may potentially create a clash if 2 versions are present.   The current code in MRApps assumes that the generated classpath is always present which may need to be addressed if this file is not present when deployed on a cluster. An option for a fix could be to pass the location of the classpath file via the MiniYarnCluster constructor and propagate that to MRApps via some form of configuration value.,Open,Unresolved,,Unassigned,Hitesh Shah,Thu; 8 Dec 2011 23:27:58 +0000,Mon; 9 Mar 2015 21:54:49 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3523
MAPREDUCE-3524,Sub-task,Blocker,benchmarks;mr-am;mrv2;performance,Scan benchmark is more than 1.5x slower in 0.23,Scan benchmark is more than 1.5X slower(almost 92% increased) in 0.23 than Hadoop-0.20.204 on 350 nodes size cluster.,Resolved,Fixed,,Unassigned,Karam Singh,Fri; 9 Dec 2011 11:03:42 +0000,Tue; 21 Feb 2012 23:10:32 +0000,Tue; 21 Feb 2012 23:10:32 +0000,,0.23.1,,MAPREDUCE-3809;MAPREDUCE-3810;MAPREDUCE-3827;MAPREDUCE-3815;MAPREDUCE-3813;MAPREDUCE-3823;MAPREDUCE-3808,MAPREDUCE-3710,https://issues.apache.org/jira/browse/MAPREDUCE-3524
MAPREDUCE-3525,Sub-task,Blocker,mrv2,Shuffle benchmark is nearly 1.5x slower in 0.23,Shuffle benchmark is nearly 1.5X slower(almost 55% increased) in 0.23 than Hadoop-0.20.204 on 350 nodes size cluster.,Closed,Fixed,,Vinod Kumar Vavilapalli,Karam Singh,Fri; 9 Dec 2011 11:07:24 +0000,Mon; 5 Mar 2012 02:48:44 +0000,Sun; 22 Jan 2012 18:16:05 +0000,,0.23.1,,MAPREDUCE-3641,,https://issues.apache.org/jira/browse/MAPREDUCE-3525
MAPREDUCE-3526,Bug,Major,mrv2,yarn-daemon unconditionnally try to chown its log directory,See: . chmod it.,Open,Unresolved,,Unassigned,Bruno Mah  ,Sat; 10 Dec 2011 00:04:43 +0000,Sat; 10 Dec 2011 00:04:43 +0000,,,0.23.0;0.23.1,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3526
MAPREDUCE-3527,Bug,Major,,Fix minor API incompatibilities between 1.0 and 0.23,There are a few minor incompatibilities that were found in HADOOP-7738 and are straightforward to fix.,Closed,Fixed,,Tom White,Tom White,Sat; 10 Dec 2011 01:26:59 +0000,Mon; 5 Mar 2012 02:48:42 +0000,Mon; 12 Dec 2011 18:39:35 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3527
MAPREDUCE-3528,Bug,Major,mr-am;mrv2,The task timeout check interval should be configurable independent of mapreduce.task.timeout,TaskHeartbeatHandler sleeps for 'mapreduce.task.timeout' - between each check. If a task NM goes bad immediately after starting a task - the timeout is detected in ~2x the configured timeout interval.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sat; 10 Dec 2011 03:31:01 +0000,Mon; 5 Mar 2012 02:49:46 +0000,Mon; 9 Jan 2012 22:38:48 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3528
MAPREDUCE-3529,Bug,Critical,mrv2,TokenCache does not cache viewfs credentials correctly,viewfs returns a list of delegation tokens for the actual namenodes. TokenCache caches these based on the actual service name - subsequent calls to TokenCache end up trying to get a new set of tokens.  Tasks which happen to access TokenCache fail when using viewfs - since they end up trying to get a new set of tokens even though the tokens are already available.      This will likely require some changes in viewfs hdfs - will open a Jira with details.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sat; 10 Dec 2011 03:46:36 +0000,Mon; 5 Mar 2012 02:49:44 +0000,Wed; 4 Jan 2012 23:08:59 +0000,,0.23.0,,PIG-2392;HADOOP-7933,,https://issues.apache.org/jira/browse/MAPREDUCE-3529
MAPREDUCE-3530,Bug,Blocker,mrv2;resourcemanager;scheduler,Sometimes NODE_UPDATE to the scheduler throws an NPE causing the scheduling to stop,Sometimes NODE_UPDATE to the scheduler throws NPE causes scheduling to stop but ResourceManager keeps on running. I have been observing intermitently for last 3 weeks. But with latest svn code. I tried to run sort twice and both times Job got stuck due to NPE.,Closed,Fixed,,Arun C Murthy,Karam Singh,Mon; 12 Dec 2011 05:36:58 +0000,Mon; 5 Mar 2012 02:49:46 +0000,Wed; 14 Dec 2011 21:24:04 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3530
MAPREDUCE-3531,Bug,Blocker,mrv2;resourcemanager;scheduler,Sometimes java.lang.IllegalArgumentException: Invalid key to HMAC computation in NODE_UPDATE also causing RM to stop scheduling ,Filling this Jira a bit late Started 350 cluster sbummited large sleep job. Foud that job was not running as RM has not allocated resouces to it.   As this stack is from 30 Nov checkou line number may be different,Closed,Fixed,,Robert Joseph Evans,Karam Singh,Mon; 12 Dec 2011 05:42:24 +0000,Mon; 5 Mar 2012 02:49:34 +0000,Thu; 15 Dec 2011 02:13:20 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3531
MAPREDUCE-3532,Bug,Critical,mrv2;nodemanager,When 0 is provided as port number in yarn.nodemanager.webapp.address; NMs webserver component picks up random port; NM keeps on Reporting 0 port to RM,I tried following -: yarn.nodemanager.address=0.0.0.0:0 yarn.nodemanager.webapp.address=0.0.0.0:0 yarn.nodemanager.localizer.address=0.0.0.0:0 mapreduce.shuffle.port=0  When 0 is provided as number in yarn.nodemanager.webapp.address.  NM instantiate WebServer as 0 piort e.g.    After that WebServer pick up some random port e.g.    And NM WebServer responds correctly but  RM's cluster Nodes page shows the following -:   Whereas NM:0 is not clickable. Seems even NM's webserver pick random port but it never gets updated and so NM report 0 as HTTP port to RM causing NM Hyperlinks un-clickable But verified that MR job runs successfully with random.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Karam Singh,Mon; 12 Dec 2011 05:59:18 +0000,Mon; 5 Mar 2012 02:49:27 +0000,Fri; 13 Jan 2012 22:23:04 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3532
MAPREDUCE-3533,Improvement,Minor,mrv2,have the service interface extend Closeable and use close() as its shutdown operation,This is probably going be marked down as a wontfix on the basis that it is (almost) encoded in the interfaces; but it may not be too late.  If the service interface interface extended Closeable and used close() instead of stop(); it would work automatically in the   automatic resource management blocks...,Closed,Fixed,,Unassigned,Steve Loughran,Mon; 12 Dec 2011 11:36:58 +0000,Tue; 10 Mar 2015 04:31:47 +0000,Fri; 14 Jun 2013 13:45:58 +0000,,0.23.0;0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3533
MAPREDUCE-3534,Sub-task,Blocker,mrv2,Compression benchmark run-time increased by 13% in 0.23,Compression runtime is increased by 13% as well as throughput is decreased by 24% in 0.23 when compared to 0.20.204 on a 350 node size cluster.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinay Kumar Thota,Mon; 12 Dec 2011 13:51:26 +0000,Mon; 5 Mar 2012 02:49:15 +0000,Mon; 23 Jan 2012 21:46:16 +0000,,0.23.1,,MAPREDUCE-3641,,https://issues.apache.org/jira/browse/MAPREDUCE-3534
MAPREDUCE-3535,Bug,Major,mrv2,Yarn service subclasses don't check for service state before executing their state change operations,Although there are checks in the lifecycle state change methods (start; stop; ...); they only get checked in the superclass. The subclasses don't check it; they don't exit the start() method if they are already started; and they don't bail out early on a stop if they are already stopped -even when the superclass returns without doing anything.  This means that calling Service.start() twice may leak resources; Service.start() twice try to shut down twice; etc. And that's on the same thread...  My preferred action here would be for the ave the operations return true if a state change took place; the implementation would be synchronised and return the correct value  The subclasses look for this and only execute their state changes took place  e.g    The Service.stop() operation is trickier as the subclasses tend to call the superclass last for a better unwinding. I think it may be safer to work the other way around; but code reviews would be need to ensure that this doesn't break assumptions in the subclass about termination order. It may be possible to do more complex designs; but it is hard to chain this down a hierarchy of classes.,Open,Unresolved,,Unassigned,Steve Loughran,Mon; 12 Dec 2011 14:22:09 +0000,Tue; 10 Mar 2015 04:32:50 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3535
MAPREDUCE-3536,Improvement,Trivial,mrv2,consider whether the same instance of a ServiceStateChangeListener should be allowed to listen to events,Currently there is no limit on the number of times a listener can register for events; it's a simple list. A service must unregister the same number of times that it registers.  Is this the desired behaviour? If so it should be documented in the Service interface rather than just implicitly in the AbstractService implementation.,Resolved,Duplicate,YARN-746,Unassigned,Steve Loughran,Mon; 12 Dec 2011 16:40:24 +0000,Wed; 18 Mar 2015 18:30:27 +0000,Wed; 18 Mar 2015 18:30:27 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3536
MAPREDUCE-3537,Bug,Blocker,,DefaultContainerExecutor has a race condn. with multiple concurrent containers,DCE relies cwd before calling ContainerLocalizer.runLocalization. However; with multiple containers setting cwd on same localFS reference leads to race.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 13 Dec 2011 01:25:04 +0000,Mon; 5 Mar 2012 02:48:43 +0000,Tue; 13 Dec 2011 06:35:43 +0000,,0.23.0,,,MAPREDUCE-3538,https://issues.apache.org/jira/browse/MAPREDUCE-3537
MAPREDUCE-3538,Bug,Major,nodemanager,DCE shouldn't directly call ContainerLocalizer.runLocalization,Leads to races like MAPREDUCE-3537. We should probably fork the localizer similar to LCE.,Open,Unresolved,,Unassigned,Arun C Murthy,Tue; 13 Dec 2011 01:29:54 +0000,Tue; 13 Dec 2011 01:30:26 +0000,,,0.23.0,,,MAPREDUCE-3537,https://issues.apache.org/jira/browse/MAPREDUCE-3538
MAPREDUCE-3539,Improvement,Trivial,,possible Cases for NullPointerException,in DistCh.java,Resolved,Not A Problem,,Unassigned,kavita sharma,Tue; 13 Dec 2011 13:10:12 +0000,Tue; 17 Mar 2015 08:51:16 +0000,Tue; 17 Mar 2015 08:51:16 +0000,,0.20.2;0.21.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3539
MAPREDUCE-3540,Bug,Major,build,saveVersion.sh script fails in windows/cygwin (hadoop-yarn-common),nan,Resolved,Invalid,MAPREDUCE-4114,Unassigned,Alejandro Abdelnur,Tue; 13 Dec 2011 16:36:52 +0000,Mon; 28 Sep 2015 21:10:31 +0000,Fri; 14 Jun 2013 12:56:45 +0000,,2.0.0-alpha,,,MAPREDUCE-3881,https://issues.apache.org/jira/browse/MAPREDUCE-3540
MAPREDUCE-3541,Bug,Blocker,mrv2,Fix broken TestJobQueueClient test,Ant build complains            client.printJobQueueInfo(root; writer);,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Tue; 13 Dec 2011 16:53:08 +0000,Mon; 5 Mar 2012 02:49:31 +0000,Wed; 14 Dec 2011 20:00:59 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3541
MAPREDUCE-3542,Bug,Major,,"Support ""FileSystemCounter"" legacy counter group name for compatibility","The group name changed from ""FileSystemCounter"" to ""org.apache.hadoop.mapreduce.FileSystemCounter""; but we should support the old one for compatibility's sake. This came up in PIG-2347.",Closed,Fixed,,Tom White,Tom White,Tue; 13 Dec 2011 21:39:00 +0000,Mon; 13 Aug 2012 08:10:12 +0000,Tue; 13 Dec 2011 23:03:37 +0000,,0.23.0,,,PIG-2347,https://issues.apache.org/jira/browse/MAPREDUCE-3542
MAPREDUCE-3543,Bug,Critical,mrv2,Mavenize Gridmix.,Gridmix codebase still resides in src contrib and needs to be compiled via ant. We should move it to maven.,Closed,Fixed,,Thomas Graves,Mahadev konar,Tue; 13 Dec 2011 23:13:35 +0000,Thu; 2 May 2013 02:29:53 +0000,Thu; 17 May 2012 15:41:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3543
MAPREDUCE-3544,Bug,Major,build;tools/rumen,gridmix build is broken; requires hadoop-archives to be added as ivy dependency,Having moved HAR tools makes gridmix to fail as HadoopArchives is not in the mr1 classpath anymore.  hadoop-archives artifact should be added to gridmix dependencies,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 14 Dec 2011 00:12:40 +0000,Tue; 10 Mar 2015 04:32:05 +0000,Wed; 14 Dec 2011 01:21:41 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3544
MAPREDUCE-3545,Bug,Major,,Remove Avro RPC,Please see the discussion in HDFS-2660 for more details. I have created a branch HADOOP-6659 to save the Avro work; if in the future some one wants to use the work that existed to add support for Avro RPC.,Closed,Fixed,,Suresh Srinivas,Suresh Srinivas,Wed; 14 Dec 2011 02:11:30 +0000,Thu; 2 May 2013 02:29:47 +0000,Wed; 14 Dec 2011 06:57:18 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3545
MAPREDUCE-3546,Bug,Critical,build;mrv2,slf4j versions mismatched between yarn and hdfs,Running a cluster on trunk; I ran into an issue caused by the differing slf4j versions between YARN and HDFS. YARN is currently using 1.6.1 whereas HDFS is using 1.5.11. Unclear whether we should upgrade HDFS or downgrade YARN.,Resolved,Duplicate,HADOOP-7934,Unassigned,Todd Lipcon,Wed; 14 Dec 2011 02:15:43 +0000,Tue; 10 Mar 2015 04:32:09 +0000,Fri; 23 Mar 2012 20:03:22 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3546
MAPREDUCE-3547,Sub-task,Critical,mrv2,finish unit tests for web services for RM and NM,Write more unit tests for the web services added for rm and nm.,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 14 Dec 2011 02:41:19 +0000,Thu; 2 May 2013 02:29:48 +0000,Thu; 29 Dec 2011 08:07:59 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3547
MAPREDUCE-3548,Sub-task,Critical,mrv2,write unit tests for web services for mapreduce app master and job history server,write more unit tests for mapreduce application master and job history server web services added in MAPREDUCE-2863,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 14 Dec 2011 02:42:49 +0000,Thu; 2 May 2013 02:29:48 +0000,Thu; 5 Jan 2012 20:02:33 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3548
MAPREDUCE-3549,Bug,Blocker,mrv2,write api documentation for web service apis for RM; NM; mapreduce app master; and job history server,write api documentation for web service apis for RM; NM; mapreduce app master; and job history server. web services were added in MAPREDUCE-2863,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 14 Dec 2011 02:44:19 +0000,Thu; 2 May 2013 02:29:48 +0000,Sat; 21 Jan 2012 00:55:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3549
MAPREDUCE-3550,Bug,Major,mrv2,RM web proxy should handle redirect of web services urls,the RM web proxy should handle the web services urls added in MAPREDUCE-2863.  The proxy does handle passing the web service urls to the AM; it just doesn't handle redirecting it after the AM goes away.,Open,Unresolved,,Thomas Graves,Thomas Graves,Wed; 14 Dec 2011 02:45:43 +0000,Sat; 7 Jan 2017 02:00:00 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3550
MAPREDUCE-3551,Bug,Major,mrv2,web proxy returns internal server error when application invalid,querying for an absent app i.e. say http: info - returns a 500 with a stack trace instead of a 404. From an api spec point of view; this is not really an error but just a not found.  This occurs with web services as well as any web ui page.,Resolved,Fixed,,Jonathan Eagles,Thomas Graves,Wed; 14 Dec 2011 02:47:17 +0000,Tue; 15 Apr 2014 20:41:46 +0000,Tue; 15 Apr 2014 20:41:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3551
MAPREDUCE-3552,Sub-task,Major,mrv2,add ability to specify the format type (xml|json) of web services when requesting it via url query param,add ability to specify the format type (xml|json) of web services when requesting it via url query param.  Perhaps ?format=xml or similar.,Open,Unresolved,,Unassigned,Thomas Graves,Wed; 14 Dec 2011 02:50:16 +0000,Sat; 7 Jan 2017 01:59:55 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3552
MAPREDUCE-3553,Sub-task,Minor,mrv2,Add support for data returned when exceptions thrown from web service apis to be in either xml or in JSON,When the web services apis for rm; nm; app master; and job history server throw an exception - like bad request; not found; they always return the data in JSON format.  It would be nice to return based on what they requested - xml or JSON.,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 14 Dec 2011 02:52:54 +0000,Mon; 5 Mar 2012 02:49:34 +0000,Thu; 12 Jan 2012 00:02:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3553
MAPREDUCE-3554,Sub-task,Major,mrv2,add job history/am hostname to web services info output  ,It would be useful to add the job history or am hostname to web services info output.   history server uri is like host:19888 info,Open,Unresolved,,Unassigned,Thomas Graves,Wed; 14 Dec 2011 03:14:10 +0000,Sat; 7 Jan 2017 02:00:01 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3554
MAPREDUCE-3555,Bug,Major,contrib/eclipse-plugin,hadoop 0.20.205.0 Eclipse Plugin does not work with Eclipse;there are two problems with it.,"I found tow problems in the eclipse plugin. 1.Plugin's build path is missing jar ;when I use DFSView; it will report  495) The point is that Job found a wrong fs; it was LocalFileSystem. By my configuration; job should be run on HDFS; but the conf which named ""mapred.job.tracker"" was overrided by default value.",Open,Unresolved,,Unassigned,Storm Lee,Wed; 14 Dec 2011 03:44:38 +0000,Sun; 25 Dec 2011 20:01:48 +0000,,,0.20.205.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3555
MAPREDUCE-3556,Bug,Major,,Resource Leaks in key flows,The key flows have potential resource leaks.,Resolved,Won't Fix,,Devaraj K,Devaraj K,Wed; 14 Dec 2011 05:47:17 +0000,Thu; 17 Jan 2013 13:12:43 +0000,Thu; 17 Jan 2013 13:12:43 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3556
MAPREDUCE-3557,Bug,Major,build,MR1 test fail to compile because of missing hadoop-archives dependency,MAPREDUCE-3544 added hadoop-archives as dependency to gridmix and raid; but missed to add it to the main ivy.xml for the MR1 testcases thus the ant target 'compile-mapred-test' fails.  I was under the impression that this stuff was not used anymore but trunk is failing on that target.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 14 Dec 2011 14:47:07 +0000,Tue; 10 Mar 2015 04:31:38 +0000,Wed; 14 Dec 2011 17:24:44 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3557
MAPREDUCE-3558,Bug,Major,mr-am;mrv2;test,Integration test needed for MRV2 job-end notification feature,We can modify port NotificationTestCase to work with MiniMRYarnCluster.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Wed; 14 Dec 2011 23:51:34 +0000,Wed; 14 Dec 2011 23:51:34 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3558
MAPREDUCE-3559,Bug,Major,mr-am;mrv2,MR AM can change to SUCCESS state but crash and fail to write JobHistory,In such corner cases; clients can see that the job has become successful but they cannot get any information from JobHistoryServer. And there is no means of figuring out what happened in the system except from the AM logs.  Ideally we should set the JobState to become SUCCESS as the last step; once everything else is done. The code changes may be a bit complicated to achieve this; but we can investigate and see.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Wed; 14 Dec 2011 23:55:04 +0000,Wed; 14 Dec 2011 23:55:04 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3559
MAPREDUCE-3560,Bug,Blocker,mrv2;resourcemanager;test,TestRMNodeTransitions is failing on trunk,Apparently Jenkins is screwed up. It is happily blessing patches; even though tests are failing.  Link to logs: https: ,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Thu; 15 Dec 2011 00:12:11 +0000,Mon; 5 Mar 2012 02:49:29 +0000,Thu; 15 Dec 2011 09:13:34 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3560
MAPREDUCE-3561,Bug,Major,mrv2;performance,[Umbrella ticket] Performance issues in YARN+MR,Been working on measuring performance of YARN+MR relative to the 0.20.xx release line together with Karam Singh.  This is an umbrella ticket to track all the issues related to performance.,Resolved,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 15 Dec 2011 01:09:12 +0000,Fri; 8 May 2015 18:11:16 +0000,Fri; 8 May 2015 18:11:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3561
MAPREDUCE-3562,Bug,Major,mrv2,Concurrency issues in MultipleOutputs;JobControl;Counters,MultipleOutputs    The close of recordwriters should be synchronized.    public void close() throws IOException; InterruptedException {      for (RecordWriter writer : recordWriters.values()) {        writer.close(context);   JobControl.     makeEscapedCompactString to be made synchronized.,Open,Unresolved,,Ravi Teja Ch N V,Ravi Teja Ch N V,Thu; 15 Dec 2011 07:06:16 +0000,Fri; 13 Jul 2012 21:12:13 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3562
MAPREDUCE-3563,Bug,Major,mrv2,LocalJobRunner doesn't handle Jobs using o.a.h.mapreduce.OutputCommitter,LocalJobRunner doesn't handle Jobs using o.a.h.mapreduce.OutputCommitter; ran into this debugging PIG-2347.,Closed,Fixed,MAPREDUCE-2350;MAPREDUCE-4280,Arun C Murthy,Arun C Murthy,Thu; 15 Dec 2011 08:21:44 +0000,Thu; 12 Feb 2015 10:15:30 +0000,Mon; 19 Dec 2011 23:08:58 +0000,,0.23.0,,,MAPREDUCE-4281,https://issues.apache.org/jira/browse/MAPREDUCE-3563
MAPREDUCE-3564,Bug,Blocker,mrv2,TestStagingCleanup and TestJobEndNotifier are failing on trunk.,From recent jenkins test runs:   -1 core tests. The patch failed these unit tests: org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier  https: ,Closed,Fixed,,Siddharth Seth,Mahadev konar,Thu; 15 Dec 2011 09:07:46 +0000,Mon; 5 Mar 2012 02:48:44 +0000,Fri; 16 Dec 2011 02:10:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3564
MAPREDUCE-3565,Bug,Minor,,Hadoop Job Counters are misleading in JT/HistoryViewer Web UI,"A sample counters taken from a webui of JT    In the above table; the ""Rack-local map tasks"" is shown as   This appears misleading to users.  This counter is available in COUNTERS but not in both MAP_COUNTERS and REDUCE_COUNTERS    Is it possible to put (NA blank) instead of 0 in unavailable counter in particular column?",Open,Unresolved,,Unassigned,Mitesh Singh Jat,Thu; 15 Dec 2011 12:20:56 +0000,Thu; 15 Dec 2011 12:20:56 +0000,,,0.20.2;0.20.204.1;0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3565
MAPREDUCE-3566,Sub-task,Critical,mr-am;mrv2,MR AM slows down due to repeatedly constructing ContainerLaunchContext,The construction of the context is expensive; includes per-task trips to NameNode for obtaining the information about job.jar; job splits etc which is redundant across all tasks.  We should have a common job-level context and a task-specific context inheriting from the common job-level context.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 15 Dec 2011 19:57:00 +0000,Mon; 5 Mar 2012 02:48:57 +0000,Thu; 5 Jan 2012 01:35:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3566
MAPREDUCE-3567,Sub-task,Major,mr-am;mrv2;performance,Extraneous JobConf objects in AM heap,MR AM creates new JobConf objects unnecessarily in a couple of places in JobImpl and TaskImpl which occupy non-trivial amount of heap.  While working with a 64 bit JVM on 100K maps jobs; with uncompressed pointers; removing those extraneous objects helped in addressing OOM with 2GB AM heap size.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 15 Dec 2011 21:44:15 +0000,Mon; 5 Mar 2012 02:49:26 +0000,Thu; 22 Dec 2011 22:36:46 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3567
MAPREDUCE-3568,Sub-task,Critical,mr-am;mrv2;performance,Optimize Job's progress calculations in MR AM,Besides catering to client requests; Job progress is calculated in every heartbeat to the RM so as to print the MR AM's progress. Today the map and reduce progresses are calculated by looking up of each task in a big map while we can simply make do with a scan and aggregate. With large number of tasks; this can make a difference.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 15 Dec 2011 22:09:54 +0000,Mon; 5 Mar 2012 02:49:41 +0000,Tue; 27 Dec 2011 19:56:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3568
MAPREDUCE-3569,Sub-task,Critical,mr-am;mrv2;performance,TaskAttemptListener holds a global lock for all task-updates,This got added via MAPREDUCE-3274. We really don't need the lock if we just implement what I mentioned on that ticket here.  This has performance implications on MR AM with lots of tasks.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 15 Dec 2011 23:13:04 +0000,Mon; 5 Mar 2012 02:49:24 +0000,Thu; 5 Jan 2012 05:21:36 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3569
MAPREDUCE-3570,Bug,Minor,examples;mrv2,SleepJob is missing from hadoop 0.23 examples,I have noticed that Sleepjob is missing from the examples in 0.23,Open,Unresolved,,Ahmed Radwan,Ahmed Radwan,Fri; 16 Dec 2011 00:00:16 +0000,Thu; 29 Dec 2011 08:11:49 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3570
MAPREDUCE-3571,Bug,Minor,examples;mrv2,SleepJob is missing from hadoop 0.23 examples,I have noticed that Sleepjob is missing from the examples in 0.23,Resolved,Duplicate,MAPREDUCE-3570,Ahmed Radwan,Ahmed Radwan,Fri; 16 Dec 2011 00:00:36 +0000,Fri; 16 Dec 2011 00:05:33 +0000,Fri; 16 Dec 2011 00:05:33 +0000,,0.23.0;0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3571
MAPREDUCE-3572,Sub-task,Critical,mr-am;mrv2;performance,MR AM's dispatcher is blocked by heartbeats to ResourceManager,All the heartbeat processing is done in RMContainerAllocator locking the object. The event processing is also locked on this; causing the dispatcher to be blocked and the rest of the AM getting stalled.  The event processing should be in a separate thread.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 16 Dec 2011 01:08:02 +0000,Mon; 5 Mar 2012 02:49:17 +0000,Thu; 5 Jan 2012 01:38:42 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3572
MAPREDUCE-3573,Bug,Minor,mrv2,Add display names for Shuffle Counters; Uber job counters,nan,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 16 Dec 2011 03:15:53 +0000,Fri; 16 Dec 2011 05:32:20 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3573
MAPREDUCE-3574,Bug,Blocker,mrv2,Streaming/tools Jar does not get includes in the tarball.,The streaming jar used to be available in the mapreduce tarballs before we created the hadoop-tools package. The streaming and tools jars are not being shipped with any tars. Our mapreduce tarballs should include the streaming and tools jar.,Resolved,Duplicate,HADOOP-7907,Unassigned,Mahadev konar,Fri; 16 Dec 2011 08:23:24 +0000,Tue; 20 Dec 2011 20:28:00 +0000,Tue; 20 Dec 2011 20:27:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3574
MAPREDUCE-3575,Bug,Blocker,mrv2,Streaming/tools Jar does not get included in the tarball.,The streaming jar used to be available in the mapreduce tarballs before we created the hadoop-tools package. The streaming and tools jars are not being shipped with any tars. Our mapreduce tarballs should include the streaming and tools jar.,Resolved,Duplicate,HADOOP-7907;MAPREDUCE-3574,Unassigned,Mahadev konar,Fri; 16 Dec 2011 08:23:25 +0000,Tue; 20 Dec 2011 20:28:20 +0000,Tue; 20 Dec 2011 19:26:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3575
MAPREDUCE-3576,Bug,Major,contrib/eclipse-plugin,Hadoop Eclipse Plugin doesn't work in OS X Lion.,"The Hadoop Eclipse plugin version 0.20.203 and 0.20.205 works on Mac OS X Snow Leopard with Eclipse 3.7.1.   It gives an error when trying to connect to the DFS saying ""Failed to login"".",Open,Unresolved,,Unassigned,Will L,Fri; 16 Dec 2011 16:34:13 +0000,Tue; 11 Sep 2012 18:15:57 +0000,,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3576
MAPREDUCE-3577,Bug,Major,mrv2,Classpath error when installing via separate tarballs,Classpath error when using the three tarballs to do a hadoop installation. In particular; HADOOP_PREFIX is guessed incorrectly in yarn-config.sh and passed to hadoop-config.sh. Work around is to manually set HADOOP_PREFIX.  Caused by:  247),Open,Unresolved,,Unassigned,Jonathan Eagles,Fri; 16 Dec 2011 21:04:26 +0000,Tue; 10 Mar 2015 04:32:38 +0000,,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3577
MAPREDUCE-3578,Bug,Major,nodemanager,"starting nodemanager as 'root' gives ""Unknown -jvm option""","running ""sudo HADOOP_ROOT .",Closed,Fixed,,Tom White,Gilad Wolff,Sat; 17 Dec 2011 01:45:42 +0000,Wed; 23 May 2012 20:28:29 +0000,Fri; 9 Mar 2012 17:39:03 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3578
MAPREDUCE-3579,Bug,Major,mrv2,ConverterUtils should not include a port in a path for a URL with no port,In ConverterUtils#getPathFromYarnURL; it's incorrectly assumed that if a URL includes a valid host it must also include a valid port.,Closed,Fixed,,Aaron T. Myers,Aaron T. Myers,Sat; 17 Dec 2011 16:49:25 +0000,Tue; 10 Mar 2015 04:32:12 +0000,Sat; 17 Dec 2011 17:38:06 +0000,,0.23.0;0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3579
MAPREDUCE-3580,Improvement,Major,security;tools/rumen,[Rumen] Rumen anonymizer should also parse and anonymize other job properties like 'mapreduce.output.fileoutputformat.compress.codec' etc,Currently; the Rumen anonymizer only parses and anonymizes job properties enumerated in MRJobConfig. Other properties like 1. compression codecs 2. output files  3. Task and Attempt level properties  should also be considered.,Open,Unresolved,,Amar Kamat,Amar Kamat,Mon; 19 Dec 2011 06:42:38 +0000,Thu; 12 May 2016 18:24:39 +0000,,,3.0.0-alpha1,anonymization;job-properties;rumen,,MAPREDUCE-778,https://issues.apache.org/jira/browse/MAPREDUCE-3580
MAPREDUCE-3581,Improvement,Major,security;tools/rumen,[Rumen] Rumen anonymizer should handle composite string data,Rumen's Anonymizer currently considers string as a single entity. At times; strings can be composed of smaller sub-strings which can be anonymized individually. Anonymizing sub-strings separately will result in retaining certain statistics like frequency ('daily'; 'weekly' etc). This was brought up by Chris while developing the Anonymizer.,Open,Unresolved,,Amar Kamat,Amar Kamat,Mon; 19 Dec 2011 06:52:25 +0000,Thu; 12 May 2016 18:24:39 +0000,,,3.0.0-alpha1,anonymization;chunking;rumen,,MAPREDUCE-778,https://issues.apache.org/jira/browse/MAPREDUCE-3581
MAPREDUCE-3582,Bug,Major,mrv2;test,Move successfully passing MR1 tests to MR2 maven tree.,This ticket will track moving mr1 tests that are passing successfully to mr2 maven tree.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 20 Dec 2011 11:53:08 +0000,Thu; 2 May 2013 02:29:48 +0000,Fri; 20 Jan 2012 19:55:03 +0000,,0.23.0,,,MAPREDUCE-3860,https://issues.apache.org/jira/browse/MAPREDUCE-3582
MAPREDUCE-3583,Bug,Critical,,ProcfsBasedProcessTree#constructProcessInfo() may throw NumberFormatException,HBase PreCommit builds frequently gave us NumberFormatException.  From https: console:    From Nicolas Sze:    I propose changing allProcessInfo to MapString; ProcessInfo so that we don't encounter this problem by avoiding parsing large integer.,Closed,Fixed,MAPREDUCE-3836,Ted Yu,Ted Yu,Tue; 20 Dec 2011 15:07:55 +0000,Thu; 9 Jan 2014 17:22:24 +0000,Thu; 23 Feb 2012 23:03:45 +0000,,0.20.205.0,,,MAPREDUCE-5715;MAPREDUCE-1201,https://issues.apache.org/jira/browse/MAPREDUCE-3583
MAPREDUCE-3584,Bug,Major,,streaming.jar -file packaging forgets timestamps,"When invoking ""hadoop jar  jars; all files will have the timestamps of when the files were unpacked. The problem is that this way meaningful information is lost. For example in my case i ship some files along with my job; and I need to compare the age (mtime) of 2 files and rebuild one of them if it's too old; but because of this hadoop behavior; my logic breaks.",Open,Unresolved,,Unassigned,Dieter Plaetinck,Tue; 20 Dec 2011 17:34:20 +0000,Tue; 20 Dec 2011 17:34:20 +0000,,,0.20.2,packaging;streaming,,,https://issues.apache.org/jira/browse/MAPREDUCE-3584
MAPREDUCE-3585,Bug,Minor,mrv2,RM unable to detect NMs restart,Suppose say in a single host; there have been multiple NMs configured. In this case; there should be mechanism to detect the NMs comeback.,Resolved,Duplicate,MAPREDUCE-3363,Unassigned,Bhallamudi Venkata Siva Kamesh,Tue; 20 Dec 2011 18:43:59 +0000,Thu; 2 May 2013 02:29:48 +0000,Thu; 26 Jan 2012 16:52:01 +0000,,,,,YARN-41,https://issues.apache.org/jira/browse/MAPREDUCE-3585
MAPREDUCE-3586,Bug,Blocker,mr-am;mrv2,Lots of AMs hanging around in PIG testing,"Daniel Dai found this. Here's what he says: I see hundreds of MRAppMaster process on my machine; and lots of tests fail for ""Too many open files"".",Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 20 Dec 2011 20:01:07 +0000,Mon; 5 Mar 2012 02:49:18 +0000,Wed; 21 Dec 2011 23:50:37 +0000,,0.23.0,,,PIG-2347,https://issues.apache.org/jira/browse/MAPREDUCE-3586
MAPREDUCE-3587,Bug,Major,mrv2,The deployment tarball should have different directories for yarn jars and mapreduce jars.,Currently all the jars in the mr tarball go to share mapreduce for clear seperation between yarn framework and mr.,Resolved,Fixed,,Unassigned,Mahadev konar,Tue; 20 Dec 2011 22:07:05 +0000,Mon; 9 Mar 2015 21:55:32 +0000,Mon; 9 Mar 2015 21:55:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3587
MAPREDUCE-3588,Bug,Blocker,,bin/yarn broken after MAPREDUCE-3366,bin yarn broken after MAPREDUCE-3366; doesn't add yarn jars to classpath. As a result no servers can be started.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 20 Dec 2011 23:27:06 +0000,Mon; 5 Mar 2012 02:49:40 +0000,Wed; 21 Dec 2011 00:07:31 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3588
MAPREDUCE-3589,Improvement,Minor,tasktracker,Add metrics to tasktracker to indicate the number of slots occupied,The number of tasks running on the tasktracker is indicated by maps reduces_running metrics. But; if multiple slots occupied by a task(capacity scheduler); we can not get info of the slot. So; add metrics to tasktracker to indicate the number of slots occupied,Open,Unresolved,,Unassigned,ade,Wed; 21 Dec 2011 10:18:09 +0000,Wed; 21 Dec 2011 10:27:09 +0000,,,0.20.203.0;0.20.205.0;0.22.0,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3589
MAPREDUCE-3590,Bug,Major,capacity-sched,CapacityScheduler: unreserve slots when no more task to run,In capacityscheduler; when tasktracker's availableSlots  job.getNumSlotsPerTask(type); and no more task of the job to run; it should be unreserved slots of the tasktracker.,Open,Unresolved,,Unassigned,ade,Wed; 21 Dec 2011 11:08:04 +0000,Wed; 21 Dec 2011 11:12:39 +0000,,,0.21.0;0.22.0,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3590
MAPREDUCE-3591,Bug,Minor,mrv2,webapps always return html on non-existent URL,If the user tries to go to a non-existent url; say rm:8088 foo; via the web ui or the web service rest api; it returns 404 and it always returns html content.  With the addition of the web service rest api it would be nice if it returned what was requested - XML or JSON.,Open,Unresolved,,Unassigned,Thomas Graves,Wed; 21 Dec 2011 16:20:31 +0000,Sat; 7 Jan 2017 01:59:57 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3591
MAPREDUCE-3592,Bug,Major,distcp,DistCp should not setTimes on directories,On finalize() stage DistCp attempts to updateDestStatus(); which includes calling setTimes(). In HDFS setTimes() is not supported for directories; therefore DistCp fails if there are directories in the tree. It looks the failure occurs only when there are no files to copy.,Open,Unresolved,,Unassigned,Konstantin Shvachko,Wed; 21 Dec 2011 18:54:45 +0000,Thu; 3 May 2012 20:19:26 +0000,,,0.22.0,,,HDFS-2712,https://issues.apache.org/jira/browse/MAPREDUCE-3592
MAPREDUCE-3593,Bug,Major,job submission,MAPREDUCE Impersonation is not working in 22,nan,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Wed; 21 Dec 2011 21:49:01 +0000,Wed; 11 Jan 2012 01:20:03 +0000,Tue; 10 Jan 2012 21:38:20 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3593
MAPREDUCE-3594,Bug,Minor,contrib/streaming,Contrib/Streaming - Test org.apache.hadoop.streaming.TestUlimit fails on VM,The TestUlimit test is as follows :   The testcse sets the upper limit for virtual memory to 768 MB in the jobconf  Start a maponly job.  Let the task get the applicable ulimit from the shell and write it as the output.  The testcase will wait for the completion of the job and compare the joboutput with the ulimit originally set in the jobconf   But this testcase fails because all the task attempts fail with the following exception    212)   So there is no job output .   The Test passes on my developer machine; but fails on the build machine which is a VM. The build machine OS is Red Hat Enterprise Linux Server release 6.1 (Santiago),Open,Unresolved,,Unassigned,Benoy Antony,Thu; 22 Dec 2011 17:40:40 +0000,Thu; 22 Dec 2011 18:18:08 +0000,,,0.22.0,,,MAPREDUCE-593,https://issues.apache.org/jira/browse/MAPREDUCE-3594
MAPREDUCE-3595,Test,Major,test,Add missing TestCounters#testCounterValue test from branch 1 to 0.23,nan,Closed,Fixed,,Tom White,Tom White,Thu; 22 Dec 2011 19:51:48 +0000,Mon; 5 Mar 2012 02:49:26 +0000,Wed; 4 Jan 2012 23:16:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3595
MAPREDUCE-3596,Bug,Blocker,applicationmaster;mrv2,Sort benchmark got hang after completion of 99% map phase,Courtesy Vinay Kumar Thota  Ran sort benchmark couple of times and every time the job got hang after completion 99% map phase. There are some map tasks failed. Also it's not scheduled some of the pending map tasks. Cluster size is 350 nodes.  Build Details: ==============  Compiled:       Fri Dec 9 16:25:27 PST 2011 by someone from branches hadoop-common  ResourceManager version:        revision 1212681 by someone source checksum on Fri Dec 9 16:52:07 PST 2011 Hadoop version:         revision 1212592 by someone Fri Dec 9 16:25:27 PST 2011,Closed,Fixed,,Vinod Kumar Vavilapalli,Ravi Prakash,Thu; 22 Dec 2011 23:52:46 +0000,Mon; 5 Mar 2012 02:49:52 +0000,Fri; 13 Jan 2012 21:18:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3596
MAPREDUCE-3597,Improvement,Major,tools/rumen,Provide a way to access other info of history file from Rumentool,"As the trace file generated by Rumen TraceBuilder is skipping some of the info like job counters; task counters; etc. we need a way to access ""other info available in history file which is not dumped to trace file"". This is useful for components which want to parse history files and get info. These components can directly use processing.",Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 23 Dec 2011 09:48:45 +0000,Tue; 10 Mar 2015 04:32:06 +0000,Fri; 23 Dec 2011 14:51:43 +0000,,0.23.1;2.0.0-alpha,,,MAPREDUCE-4356,https://issues.apache.org/jira/browse/MAPREDUCE-3597
MAPREDUCE-3598,Bug,Blocker,,Old combiner doesn't support counter; progress,After HADOOP-5382; old combiner's reduce is invoked with Reporter.NULL. So all the features in Reporter; e.g. counter; progress are not supported any more. The related code is as follows:,Resolved,Duplicate,MAPREDUCE-3376,Unassigned,Liyin Liang,Mon; 26 Dec 2011 06:04:40 +0000,Mon; 26 Dec 2011 08:37:50 +0000,Mon; 26 Dec 2011 07:53:37 +0000,,0.20.205.0,,,HADOOP-5382,https://issues.apache.org/jira/browse/MAPREDUCE-3598
MAPREDUCE-3599,Bug,Major,,Some MR1 test classes still have failures/errors after moving under MR2 mvn tree (MAPREDUCE-3582),This ticket will track needed changes to MR1 test classes that still have failures errors. If a specific classes needs a lot of changes; we can create separate tickets. A JUnit @Ignore tag was added to each of these test classes as part of MAPREDUCE-3582 patch to avoid breaking the build.  These 30 test classes are:,Open,Unresolved,,Ahmed Radwan,Ahmed Radwan,Mon; 26 Dec 2011 22:41:05 +0000,Mon; 26 Dec 2011 22:41:05 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3599
MAPREDUCE-3600,Sub-task,Major,mrv2;scheduler,Add Minimal Fair Scheduler to MR2,This covers the addition of the Fair Scheduler to the MR2 infrastructure. This patch will represent the minimum functional FairScheduler in MR2. It will be limited to a configuration file reader; functionality to calculate fair shares; and hooks into the actual MR2 scheduling code.   It will not include delay scheduling; preemption; or a web UI; which will be handled in separate JIRA's.,Resolved,Fixed,,NO NAME,NO NAME,Tue; 27 Dec 2011 01:01:50 +0000,Fri; 3 Aug 2012 17:35:30 +0000,Fri; 3 Aug 2012 17:35:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3600
MAPREDUCE-3601,Sub-task,Major,scheduler,Add Delay Scheduling to MR2 Fair Scheduler,JIRA for delay scheduling component.,Resolved,Fixed,,NO NAME,NO NAME,Tue; 27 Dec 2011 01:02:24 +0000,Fri; 3 Aug 2012 17:36:52 +0000,Fri; 3 Aug 2012 17:36:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3601
MAPREDUCE-3602,Sub-task,Major,scheduler,Add Preemption to MR2 Fair Scheduler,nan,Resolved,Fixed,,NO NAME,NO NAME,Tue; 27 Dec 2011 01:02:57 +0000,Fri; 3 Aug 2012 17:36:19 +0000,Fri; 3 Aug 2012 17:36:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3602
MAPREDUCE-3603,New Feature,Major,scheduler,Add Web UI to MR2 Fair Scheduler,nan,Resolved,Duplicate,YARN-145,Unassigned,NO NAME,Tue; 27 Dec 2011 01:03:11 +0000,Tue; 16 Apr 2013 23:30:28 +0000,Tue; 16 Apr 2013 23:30:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3603
MAPREDUCE-3604,Bug,Blocker,contrib/streaming,Streaming's check for local mode is broken,Streaming isn't checking for mapreduce.framework.name as part of check for 'local' mode.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 28 Dec 2011 06:38:24 +0000,Mon; 5 Mar 2012 02:48:46 +0000,Wed; 28 Dec 2011 18:25:37 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3604
MAPREDUCE-3605,Bug,Major,mrv2,Allow mr commands to be run via bin/hadoop,"MR command line options are not supported in bin hadoop.    A deprecated message like ""DEPRECATED: Use of this script to execute mapred command is deprecated. Instead use the mapred command for it."" should be displayed along with the correct output.",Resolved,Duplicate,HADOOP-7971,Unassigned,Ramya Sunil,Wed; 28 Dec 2011 19:49:08 +0000,Tue; 17 Jan 2012 07:01:46 +0000,Tue; 17 Jan 2012 07:01:46 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3605
MAPREDUCE-3606,Bug,Major,,"Job stats for number of maps ""mapred.map.tasks"" is always 2","I find this issue when doing Pig unit test on 205. Once I finish the job; jc.getSuccessfulJobs().get(0).getJobConf().get(""mapred.map.tasks"") always give me 2. However; the entry ""mapred.map.tasks"" inside job.xml contains correct value.  The issue does not exist on 0.20.2 or 0.23.",Open,Unresolved,,Unassigned,Daniel Dai,Thu; 29 Dec 2011 01:11:26 +0000,Thu; 29 Dec 2011 01:12:02 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3606
MAPREDUCE-3607,Improvement,Major,client,Port missing new API mapreduce lib classes to 1.x,"There are a number of classes under mapreduce.lib that are not present in the 1.x series. Including these would help users and downstream projects using the new MapReduce API migrate to later versions of Hadoop in the future.  A few examples of where this would help:  	Sqoop uses mapreduce.lib.db.DBWritable and mapreduce.lib.input.CombineFileInputFormat (SQOOP-384). 	Mahout uses mapreduce.lib.output.MultipleOutputs (MAHOUT-822). 	HBase has a backport of mapreduce.lib.partition.InputSampler and TotalOrderPartitioner (in org.apache.hadoop.hbase.mapreduce.hadoopbackport) - it would be better if it used the ones in Hadoop.",Closed,Fixed,,Tom White,Tom White,Thu; 29 Dec 2011 05:55:17 +0000,Thu; 2 May 2013 02:29:48 +0000,Tue; 24 Jan 2012 23:31:50 +0000,,1.0.0,,,SQOOP-413,https://issues.apache.org/jira/browse/MAPREDUCE-3607
MAPREDUCE-3608,Bug,Major,mrv2,MAPREDUCE-3522 commit causes compilation to fail,There are compilation errors after MAPREDUCE-3522 was committed. Some more changes were need to webapps to fix the compilation issue.,Closed,Fixed,MAPREDUCE-3611,Mahadev konar,Mahadev konar,Fri; 30 Dec 2011 00:32:31 +0000,Mon; 5 Mar 2012 02:49:42 +0000,Fri; 30 Dec 2011 02:25:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3608
MAPREDUCE-3609,Bug,Minor,,JobClient does not initialize conf member in all constructors,"The c'tor that takes a socket address does not initialize the configuration member:  public JobClient(InetSocketAddress jobTrackAddr;                     Configuration conf) throws IOException {     this.ugi = UserGroupInformation.getCurrentUser();     jobSubmitClient = createRPCProxy(jobTrackAddr; conf); }  It should call setconf(conf). This leads to an NPE if a caller instantiates a job client using the c'tor and tries to retrieve a job since the NetworkedJob c'tor tries to access the configuration.  The workaround is simple but ""ugly"" - the caller can call setconf explicitly.  I only checked on 0.20.205.0 but the problem may also exist upstream.",Open,Unresolved,,Unassigned,Gilad Wolff,Fri; 30 Dec 2011 00:49:39 +0000,Fri; 30 Dec 2011 00:49:39 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3609
MAPREDUCE-3610,Improvement,Minor,,Some parts in MR use old property dfs.block.size,Some parts in MR use old property dfs.block.size. dfs.blocksize should be used instead.,Closed,Fixed,,Sho Shimauchi,Sho Shimauchi,Sat; 31 Dec 2011 04:39:02 +0000,Mon; 5 Mar 2012 02:48:49 +0000,Wed; 4 Jan 2012 10:24:03 +0000,,,,,HDFS-1314,https://issues.apache.org/jira/browse/MAPREDUCE-3610
MAPREDUCE-3611,Bug,Critical,,trunk build failure,https: ,Resolved,Duplicate,MAPREDUCE-3608,Unassigned,Sho Shimauchi,Sat; 31 Dec 2011 08:35:22 +0000,Sat; 31 Dec 2011 08:43:53 +0000,Sat; 31 Dec 2011 08:42:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3611
MAPREDUCE-3612,Bug,Major,,Task.TaskReporter.done method blocked for some time when task is finishing,We recently have done some tests to evaluate performances of different Hadoop versions(1.0; 0.23; Baidu internal version); and found some weird results. One of them is in 1.0 Task.TaskReporter.done() takes too much time; about 2s; this is bad for small tasks. After reviewing source code and add some log; the following code block Task.TaskReporter.done      Originally line 724-730 don't exists; I don't know why it is added. If it is needed; we can replace Thread.sleep with Object.wait(timeout) and Object.notify instead; so it won't block.,Open,Unresolved,,Binglin Chang,Binglin Chang,Tue; 3 Jan 2012 12:11:35 +0000,Sat; 7 Jul 2012 00:31:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3612
MAPREDUCE-3613,Sub-task,Critical,mrv2,web service calls header contains 2 content types,when doing requesting info from the web services rest API; curl seems to return content-type of both text and json or xml:   Accept: application xml,Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 3 Jan 2012 18:11:01 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Wed; 25 Apr 2012 21:15:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3613
MAPREDUCE-3614,Bug,Major,mrv2, finalState UNDEFINED if AM is killed by hand,"Courtesy David Capwell   If the AM is running and you kill the process (sudo kill #pid); the State in Yarn would be FINISHED and FinalStatus is UNDEFINED.  The Tracking UI would say ""History"" and point to the proxy url (which will redirect to the history server).  The state should be more descriptive that the job failed and the tracker url shouldn't point to the history server.",Resolved,Fixed,,Ravi Prakash,Ravi Prakash,Tue; 3 Jan 2012 23:18:49 +0000,Sun; 4 Mar 2012 13:57:53 +0000,Sun; 4 Mar 2012 05:27:42 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3614
MAPREDUCE-3615,Bug,Blocker,mrv2,mapred ant test failures,The following mapred ant tests are failing.  This started on December 22nd.       junit Running org.apache.hadoop.mapred.TestTrackerBlacklistAcrossJobs     junit Running org.apache.hadoop.mapred.TestMiniMRDFSSort     junit Running org.apache.hadoop.mapred.TestBadRecords     junit Running org.apache.hadoop.mapred.TestClusterMRNotification     junit Running org.apache.hadoop.mapred.TestDebugScript     junit Running org.apache.hadoop.mapred.TestJobCleanup     junit Running org.apache.hadoop.mapred.TestJobClient     junit Running org.apache.hadoop.mapred.TestJobHistory     junit Running org.apache.hadoop.mapred.TestJobInProgressListener     junit Running org.apache.hadoop.mapred.TestJobKillAndFail     junit Running org.apache.hadoop.mapred.TestJvmReuse     junit Running org.apache.hadoop.mapred.TestKillSubProcesses     junit Running org.apache.hadoop.mapred.TestNodeRefresh     junit Running org.apache.hadoop.mapred.TestSetupAndCleanupFailure     junit Running org.apache.hadoop.mapred.TestTaskFail     junit Running org.apache.hadoop.mapred.TestTaskOutputSize     junit Running org.apache.hadoop.mapred.TestTaskTrackerSlotManagement     junit Running org.apache.hadoop.mapreduce.TestMRJobClient     junit Running org.apache.hadoop.mapreduce.lib.db.TestDBJob     junit Running org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 4 Jan 2012 14:30:45 +0000,Mon; 5 Mar 2012 02:49:29 +0000,Thu; 5 Jan 2012 18:49:13 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3615
MAPREDUCE-3616,Sub-task,Major,mr-am;mrv2;performance,Thread pool for launching containers in MR AM not expanding as expected,Found this while running some benchmarks on 350 nodes. The thread pool stays at 60 for a long time and only expands to 350 towards the fag end of the job.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 4 Jan 2012 17:15:32 +0000,Thu; 19 Jul 2012 17:49:51 +0000,Mon; 9 Jan 2012 22:22:04 +0000,,0.23.1,,,MAPREDUCE-3389,https://issues.apache.org/jira/browse/MAPREDUCE-3616
MAPREDUCE-3617,Bug,Major,mrv2,Remove yarn default values for resource manager and nodemanager principal,Default values should be empty since no use can be made of them without correct values defined.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 4 Jan 2012 23:27:42 +0000,Tue; 10 Mar 2015 04:32:13 +0000,Thu; 5 Jan 2012 20:12:51 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3617
MAPREDUCE-3618,Sub-task,Major,mrv2;performance,TaskHeartbeatHandler holds a global lock for all task-updates,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 5 Jan 2012 03:31:15 +0000,Mon; 5 Mar 2012 02:49:07 +0000,Wed; 11 Jan 2012 06:56:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3618
MAPREDUCE-3619,Improvement,Major,contrib/streaming;mrv2,Change streaming code to use new mapreduce api.,"If we run a streaming job with following python script as mapper or reducer; the job will throws NullPointerException.    Here is the NPE related log: 2011-12-22 14:14:06;310 WARN org.apache.hadoop.streaming.PipeMapRed:  444)  This is because the above script's ""print &gt;sys.stderr"" will invoke reporter.incrCounter() during PipeMapper|PipeReducer.configure(). While we can not get reporter in configure() function.  To fix this problem; we should change streaming code to use new-api. Then we can call context.getCounter() in Mapper|Reducer.setup() function.",Resolved,Duplicate,MAPREDUCE-1813,Unassigned,Liyin Liang,Thu; 5 Jan 2012 12:24:35 +0000,Mon; 9 Jan 2012 14:43:22 +0000,Mon; 9 Jan 2012 14:43:22 +0000,,0.23.1,,,MAPREDUCE-1122,https://issues.apache.org/jira/browse/MAPREDUCE-3619
MAPREDUCE-3620,Bug,Major,contrib/gridmix,GrimdMix Stats at the end of GridMix are not reported correctly,Courtesy Vinay Kumar Thota  Job trace contains 1205 jobs and Gridmix start processing 1200 jobs after processing. However; after completion of gridmix run; execution summary details; it showed 1196 jobs are processed and remaining 4 jobs are missing. One log shows 1196 jobs processed and another log shows 1200 jobs are processed.,Resolved,Duplicate,MAPREDUCE-3787,Amar Kamat,Ravi Prakash,Thu; 5 Jan 2012 14:28:06 +0000,Fri; 10 Feb 2012 09:27:39 +0000,Fri; 10 Feb 2012 09:27:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3620
MAPREDUCE-3621,Bug,Major,mrv2,TestDBJob and TestDataDrivenDBInputFormat ant tests fail,The following mapred ant tests fail and have been failing for a very long time:  junit Running org.apache.hadoop.mapreduce.lib.db.TestDBJob junit Running org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat,Closed,Fixed,MAPREDUCE-3984,Ravi Prakash,Thomas Graves,Thu; 5 Jan 2012 15:16:32 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Thu; 5 Apr 2012 20:15:09 +0000,,0.23.0,,,HADOOP-8180;HDFS-3109,https://issues.apache.org/jira/browse/MAPREDUCE-3621
MAPREDUCE-3622,Bug,Major,mrv2,findbug error during test-patch: org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent defines equals but not hashCode,findbug error: org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent defines equals but not hashCode  first time I see this is build 1540:  https: newPatchFindbugsWarningshadoop-mapreduce-client-app.html,Resolved,Duplicate,MAPREDUCE-3626;MAPREDUCE-3312,Unassigned,Thomas Graves,Thu; 5 Jan 2012 16:10:29 +0000,Fri; 6 Jan 2012 05:21:51 +0000,Fri; 6 Jan 2012 05:21:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3622
MAPREDUCE-3623,Sub-task,Major,mrv2,Authorization of NM <=> RM with simple authentication mistakenly attempts kerberos when yarn.nodemanager.principal is defined,MAPREDUCE-3617 addresses the default values of yarn.nodemanager.principal and yarn.resourcemanager.principal  I have enabled authorization with simple authentication. NM = RM still attempts kerberos authentication. If simple authentication is enabled yarn.nodemanager.principal and yarn.resourcemanager.principal values should be ignored and simple authentication should be used.,Resolved,Duplicate,HADOOP-9444,Omkar Vinit Joshi,Jonathan Eagles,Thu; 5 Jan 2012 17:22:02 +0000,Tue; 10 Mar 2015 04:32:29 +0000,Sat; 27 Apr 2013 01:46:54 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3623
MAPREDUCE-3624,Bug,Major,mrv2,bin/yarn script adds jdk tools.jar to the classpath.,Thanks to Roman for pointing it out. Looks like we have the following lines in bin yarn:     We dont really have a dependency on the tools jar. We should remove this.,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 5 Jan 2012 18:31:05 +0000,Mon; 5 Mar 2012 02:49:19 +0000,Fri; 6 Jan 2012 19:13:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3624
MAPREDUCE-3625,Bug,Critical,mrv2,CapacityScheduler web-ui display of queue's used capacity is broken,The display of the queue's used capacity at runtime is broken because it display's 'used' relative to the queue's capacity and not the parent's capacity as shown in the above attachment.  The display should be relative to parent's capacity and not leaf queues as everything else in the display is relative to parent's capacity.,Closed,Fixed,,Jason Lowe,Arun C Murthy,Thu; 5 Jan 2012 19:53:53 +0000,Mon; 5 Mar 2012 02:49:12 +0000,Thu; 12 Jan 2012 00:17:51 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3625
MAPREDUCE-3626,Bug,Major,mrv2,Findbugs warning in ContainerRemoteLaunchEvent,Warning: org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent defines equals but not hashCode,Resolved,Duplicate,MAPREDUCE-3622,Arun C Murthy,Arun C Murthy,Thu; 5 Jan 2012 20:09:14 +0000,Fri; 6 Jan 2012 00:23:17 +0000,Fri; 6 Jan 2012 00:23:17 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3626
MAPREDUCE-3627,Bug,Major,mrv2,ClusterSetup docs for permissions on mapreduce.jobhistory.done-dir don't match jobhistory server startup,The ClusterSetup docs for 0.23 list the permissions on mapreduce.jobhistory.done-dir should be drwxr-x---; but the job history server which will create that directory for you if its not there sets them to be 0770.,Resolved,Duplicate,NULL,Siddharth Seth,Thomas Graves,Thu; 5 Jan 2012 22:14:38 +0000,Tue; 15 Apr 2014 14:15:44 +0000,Tue; 15 Apr 2014 14:15:44 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3627
MAPREDUCE-3628,Sub-task,Major,mrv2,DFSIO read throughput is decreased by 16% in 0.23.1 than Hadoop-0.20.204 on 350 nodes size cluster.,DFSIO read throughput is decreased by 16% in 0.23 than Hadoop-0.20.204 on 350 nodes size cluster.,Resolved,Fixed,,Vinod Kumar Vavilapalli,Amol Kekre,Fri; 6 Jan 2012 01:52:32 +0000,Mon; 20 Feb 2012 22:43:27 +0000,Mon; 20 Feb 2012 22:43:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3628
MAPREDUCE-3629,Task,Major,mrv2,Remove sleep from MRAppMaster during app-finish.,MRAppMaster waits for 5 secs during app-finish; this was needed before we had client-side redirection. This affects the app execution in that; AppMaster will killed by the NM once NM gets confirmation from RM.  AppMaster should go away immediately. Also; the done call to RM from AM should be the last thing AM ever does. Otherwise; today; JobHistory writing gets interrupted if AM gets killed by the NM.,Open,Unresolved,,Unassigned,Amol Kekre,Fri; 6 Jan 2012 02:15:20 +0000,Mon; 9 Mar 2015 20:19:06 +0000,,,0.23.0,,,MAPREDUCE-4788,https://issues.apache.org/jira/browse/MAPREDUCE-3629
MAPREDUCE-3630,Task,Critical,mrv2,NullPointerException running teragen,CMD =  tasklog?plaintext=trueattemptid=attempt_1316132655177_0533_m_000001_0filter=stderr,Closed,Fixed,,Mahadev konar,Amol Kekre,Fri; 6 Jan 2012 02:28:37 +0000,Mon; 5 Mar 2012 02:48:40 +0000,Wed; 25 Jan 2012 06:31:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3630
MAPREDUCE-3631,Task,Major,mrv2,Corner case in headroom calculation,When there is a single queue and a large job fills up the whole cluster; a lost NM can lead to wrong headroom when all slots are taken up by reduces since at that point headroom isn't recomputed.,Resolved,Duplicate,MAPREDUCE-3126,Unassigned,Amol Kekre,Fri; 6 Jan 2012 02:44:28 +0000,Fri; 6 Jan 2012 05:32:25 +0000,Fri; 6 Jan 2012 05:32:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3631
MAPREDUCE-3632,Bug,Major,nodemanager,Need better error message on the Web UI when NM can't find the container logs instead of NPEno,If for some reason NM could not find container logs; then an NPE is seen while trying to access from web UI. Instead an error message should be displayed.,Resolved,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 6 Jan 2012 04:24:00 +0000,Mon; 9 Mar 2015 21:56:14 +0000,Mon; 9 Mar 2015 21:56:13 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3632
MAPREDUCE-3633,Bug,Blocker,,MAPREDUCE-1938 isn't present in 0.22 nor 0.23 nor trunk. Breaks API.,MAPREDUCE-1938 introduced an API call in JobConf and the likes. This is not present in 0.22 nor 0.23.  Even if it isn't needed; the method must be still present as @Deprecated and perhaps made defunct inside if it should not do anything.  Not having this method is API breakage.  Let me know if am grossly wrong here.,Resolved,Invalid,,Unassigned,Harsh J,Fri; 6 Jan 2012 14:45:48 +0000,Fri; 6 Jan 2012 14:54:00 +0000,Fri; 6 Jan 2012 14:54:00 +0000,,0.22.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3633
MAPREDUCE-3634,Bug,Major,mrv2,All daemons should crash instead of hanging around when their EventHandlers get exceptions,We should make sure that the daemons crash in case the dispatchers get exceptions and stop processing. That way we will be debugging RM AM crashes instead of hard-to-track hanging jobs.,Resolved,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 6 Jan 2012 18:39:53 +0000,Wed; 29 Mar 2017 22:29:41 +0000,Tue; 21 Feb 2012 05:11:37 +0000,,0.23.0,,MAPREDUCE-3489,MAPREDUCE-3846;YARN-6202,https://issues.apache.org/jira/browse/MAPREDUCE-3634
MAPREDUCE-3635,Improvement,Major,build;client,Improve Hadoop subcomponent integration in Hadoop 0.23,Please see HADOOP-7939 for a complete description and discussion. This JIRA is for patch tracking purposes only.,Resolved,Duplicate,HADOOP-7939,Roman Shaposhnik,Roman Shaposhnik,Fri; 6 Jan 2012 18:55:36 +0000,Mon; 28 Sep 2015 21:10:33 +0000,Fri; 8 Mar 2013 17:44:32 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3635
MAPREDUCE-3636,Improvement,Major,documentation,Apply audience and stability annotations to classes in MapReduce for 1.x,Port MAPREDUCE-1623 to branch-1.,Open,Unresolved,,Unassigned,Tom White,Fri; 6 Jan 2012 21:03:52 +0000,Tue; 14 May 2013 05:14:41 +0000,,,,,,HADOOP-7962,https://issues.apache.org/jira/browse/MAPREDUCE-3636
MAPREDUCE-3637,Bug,Critical,mrv2,Health checker interval does not appear to work - according to web ui,"reported by QE; I think this is probably a web ui not updating issue; but not positive.   1. The property yarn.nodemanager.health-checker.interval-ms on the RM and the DN are set to 135000 ms; or 2 minutes and 15 sec.   $ grep -A 2 ""health-checker.interval-ms"" yarn-site.xml    nameyarn.nodemanager.health-checker.interval-ms nodes); the 'last health-update' column does not get updated; except when the RM is restated.",Resolved,Cannot Reproduce,,Unassigned,Thomas Graves,Fri; 6 Jan 2012 21:15:40 +0000,Fri; 6 Jan 2012 22:29:51 +0000,Fri; 6 Jan 2012 22:29:51 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3637
MAPREDUCE-3638,Bug,Major,mrv2,Yarn trying to download cacheFile to container but Path is a local file,It looks like the AM; which is running on host1.com; is trying to access a local file but the file is on host2.com (where the command was run).  ran: hadoop --config conf InputFile#testlink          -jobconf mapred.map.tasks=1           -jobconf mapred.reduce.tasks=1          -jobconf mapred.job.name=streamingTest-610          -jobconf mapreduce.job.acl-view-job=*  failure:    INFO mapreduce.Job: Job job_1320887371559_0215 failed with state FAILED due to: Application application_1320887371559_0215 failed 1 times due to AM Container for appattempt_1320887371559_0215_000001 exited with  exitCode: -1000 due to:  619),Resolved,Invalid,,Unassigned,Thomas Graves,Fri; 6 Jan 2012 21:24:14 +0000,Wed; 29 Feb 2012 22:28:41 +0000,Wed; 29 Feb 2012 22:28:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3638
MAPREDUCE-3639,Bug,Blocker,mrv2,TokenCache likely broken for FileSystems which don't issue delegation tokens,Ref HADOOP-7963.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sat; 7 Jan 2012 04:21:59 +0000,Mon; 5 Mar 2012 02:48:47 +0000,Tue; 10 Jan 2012 01:40:29 +0000,,0.23.0,,,HADOOP-7967,https://issues.apache.org/jira/browse/MAPREDUCE-3639
MAPREDUCE-3640,Sub-task,Blocker,mrv2,AMRecovery should pick completed task form partial JobHistory files,Currently; if the JobHistory file has a partial record; AMRecovery will start from scratch. This will become more relevant after MAPREDUCE-3512.,Closed,Fixed,,Arun C Murthy,Siddharth Seth,Sat; 7 Jan 2012 23:02:47 +0000,Mon; 5 Mar 2012 02:49:28 +0000,Wed; 1 Feb 2012 23:35:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3640
MAPREDUCE-3641,Sub-task,Blocker,mrv2;scheduler,CapacityScheduler should be more conservative assigning off-switch requests,In hadoop-1; the CS is very conservative handing out off-switch assignments; we need to do the same in YARN.  We noticed performance regressions due to this; particularly for reduces.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sun; 8 Jan 2012 06:14:00 +0000,Mon; 5 Mar 2012 02:49:22 +0000,Mon; 16 Jan 2012 21:57:40 +0000,,0.23.0,,MAPREDUCE-3525;MAPREDUCE-3534,,https://issues.apache.org/jira/browse/MAPREDUCE-3641
MAPREDUCE-3642,Sub-task,Major,client,Remove hardcoded strings from the JC#displayTasks() call.,This is to address Eli's comments on the parent task:  1. The error messages should generate the lists of valid states and types from their definitions rather than hard-coding them into the error messages.  2. Aren't these types and states defined somewhere already? Seems like they're a public API and therefore shouldn't have to duplicate the definition of them in taskTypes and taskStates.,Resolved,Fixed,,Unassigned,Harsh J,Mon; 9 Jan 2012 03:25:13 +0000,Sat; 9 May 2015 14:07:54 +0000,Sat; 9 May 2015 14:07:54 +0000,,2.0.0-alpha,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-3642
MAPREDUCE-3643,Bug,Minor,,Reducer Job always goes to pending state.,I am using hadoop streaming command for map-reduce.In my job there are 4 streaming commands;i have no issues with first 3 steps but step4 job once mapper got  100% completed  directly going to pending state;even there was no error in the job tracker.  In the step4;i am merging the output(i.e step2 and step 3 output) as single output using identity reducer. I have ran this job several times there was no issues but i am facing the problem right now.  Any suggestions!,Open,Unresolved,,Unassigned,Arun Prakash,Mon; 9 Jan 2012 16:24:41 +0000,Mon; 9 Jan 2012 17:05:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3643
MAPREDUCE-3644,Bug,Major,build;mrv2,Snapshot builds have confusing jar file names in share/hadoop/mapreduce in tarball,"If you build a Hadoop tarball with a non-release version; the moduleSet used in hadoop-assemblies outputFileNameMapping"" to the binaries tag of the moduleSet.",Resolved,Fixed,,Unassigned,Andrew Bayer,Mon; 9 Jan 2012 20:08:38 +0000,Thu; 17 Mar 2016 16:31:40 +0000,Thu; 17 Mar 2016 16:31:40 +0000,,0.23.0,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-3644
MAPREDUCE-3645,Bug,Blocker,mrv1,TestJobHistory fails,"TestJobHistory fails.  &gt; org.apache.hadoop.mapred.TestJobHistory.testDoneFolderOnHDFS 	 &gt; org.apache.hadoop.mapred.TestJobHistory.testDoneFolderNotOnDefaultFileSystem 	 &gt; org.apache.hadoop.mapred.TestJobHistory.testHistoryFolderOnHDFS 	 &gt; org.apache.hadoop.mapred.TestJobHistory.testJobHistoryFile   It looks like this was introduced by MAPREDUCE-3349 and the issue is that the test expects the hostname to be in the format rackname hostname; but with 3349 it split those apart into 2 different fields.",Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 9 Jan 2012 21:43:26 +0000,Mon; 5 Mar 2012 02:48:40 +0000,Wed; 11 Jan 2012 22:55:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3645
MAPREDUCE-3646,Bug,Major,client;mrv2,"Remove redundant URL info from ""mapred job"" output","The URL information to track the job is printed for all the ""mapred job""mrv2 commands. This information is redundant and has to be removed.  E.g:",Closed,Fixed,MAPREDUCE-3690,Jonathan Eagles,Ramya Sunil,Mon; 9 Jan 2012 22:25:39 +0000,Mon; 5 Mar 2012 02:49:04 +0000,Mon; 23 Jan 2012 22:37:44 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3646
MAPREDUCE-3647,Bug,Blocker,mrv2;pipes,"Pipes job fails with ""Illegal text protocol""","Pipes job fail with ""Hadoop Pipes Exception: Illegal text protocol command""",Resolved,Not A Problem,,Mahadev konar,Ramya Sunil,Mon; 9 Jan 2012 22:29:13 +0000,Mon; 16 Jan 2012 18:51:59 +0000,Mon; 16 Jan 2012 18:51:59 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3647
MAPREDUCE-3648,Bug,Blocker,mrv2,TestJobConf failing,TestJobConf is failing:    testFindContainingJar  testFindContainingJarWithPlus    44)   Looks like perhaps a classpath issue.   TestQueueManagerRefresh also has failures and I'm wondering might be related as it doesn't seem to pick up a config file written out to build extraconf,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 9 Jan 2012 23:48:26 +0000,Mon; 5 Mar 2012 02:48:48 +0000,Wed; 11 Jan 2012 19:41:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3648
MAPREDUCE-3649,Bug,Blocker,mrv2,Job End notification gives an error on calling back.,When calling job end notification for oozie the AM fails with the following trace:,Closed,Fixed,,Ravi Prakash,Mahadev konar,Mon; 9 Jan 2012 23:53:06 +0000,Mon; 5 Mar 2012 02:49:07 +0000,Mon; 16 Jan 2012 19:40:25 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3649
MAPREDUCE-3650,Bug,Blocker,mrv2,testGetTokensForHftpFS() fails,org.apache.hadoop.mapreduce.security.TestTokenCache.testGetTokensForHftpFS  fails.  Looks like it may have been introduced with HADOOP-7808,Closed,Fixed,,Ravi Prakash,Thomas Graves,Tue; 10 Jan 2012 02:20:34 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Wed; 4 Apr 2012 16:26:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3650
MAPREDUCE-3651,Bug,Blocker,mrv2,TestQueueManagerRefresh fails,The following tests fail: org.apache.hadoop.mapred.TestQueueManagerRefresh.testRefreshWithRemovedQueues  org.apache.hadoop.mapred.TestQueueManagerRefresh.testRefreshOfSchedulerProperties   It looks like its simply trying to remove one of the queues but the remove is failing.It looks like MAPREDUCE-3328. mapred queue -list output inconsistent and missing child queues - change the getChilren routine to do a new JobQueueInfo on each one when returning it which is making the remove routine fail since they aren't the same object now.,Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 10 Jan 2012 16:04:06 +0000,Mon; 5 Mar 2012 02:49:21 +0000,Wed; 11 Jan 2012 22:35:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3651
MAPREDUCE-3652,Bug,Blocker,mrv2,org.apache.hadoop.mapred.TestWebUIAuthorization.testWebUIAuthorization fails,org.apache.hadoop.mapred.TestWebUIAuthorization.testWebUIAuthorization fails.  This is testing the old jsp web interfaces.  I think this test should just be removed.   Any objections?,Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 10 Jan 2012 16:28:28 +0000,Mon; 5 Mar 2012 02:49:45 +0000,Wed; 11 Jan 2012 23:53:35 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3652
MAPREDUCE-3653,Improvement,Major,mrv2,Improvements to CapacityScheduler doc,"I noticed the following issues with the capacity scheduler doc: . rmadmin -refreshQueues""",Resolved,Invalid,,Thomas Graves,Yoram Arnon,Tue; 10 Jan 2012 20:18:38 +0000,Tue; 10 Jan 2012 20:20:09 +0000,Tue; 10 Jan 2012 20:20:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3653
MAPREDUCE-3654,Bug,Critical,mrv2;test,"MiniMRYarnCluster should set MASTER_ADDRESS to ""local""",I needed to make the attached change in order for MiniMRCluster based HBase tests to get past job client initialization.,Resolved,Invalid,,Andrew Purtell,Andrew Purtell,Wed; 11 Jan 2012 01:10:56 +0000,Mon; 23 Jan 2012 23:07:42 +0000,Fri; 20 Jan 2012 01:25:55 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3654
YARN-152,Bug,Major,applications/distributed-shell;nodemanager,Exception from launching allocated container,I use Hadoop-Yarn to deploy my real-time distributed computation system; and I get reply from mapreduce-user@hadoop.apache.org to follow these guilders below:           http: container_1325062142731_0006_01_000001.pid 2011-12-29 15:49:16;307 DEBUG org.apache.hadoop.yarn.event.AsyncDispatcher: Dispatching the event org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ContainerLocalizationCleanupEvent.EventType: CLEANUP_CONTAINER_RESOURCES  In order to figure out the fact; I trace back to source code. I find that org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:  @Override   public int launchContainer(Container container;       Path nmPrivateContainerScriptPath; Path nmPrivateTokensPath;       String userName; String appId; Path containerWorkDir)       throws IOException {       ....        String[] sLocalDirs = getConf().getStrings(         YarnConfiguration.NM_LOCAL_DIRS;         YarnConfiguration.DEFAULT_NM_ LOCAL_DIRS);     for (String sLocalDir : sLocalDirs)  {       Path usersdir = new Path(sLocalDir; ContainerLocalizer.USERCACHE);       Path userdir = new Path(usersdir; userName);       Path appCacheDir = new Path(userdir; ContainerLocalizer.APPCACHE);       Path appDir = new Path(appCacheDir; appIdStr);       Path containerDir = new Path(appDir; containerIdStr);       lfs.mkdir(containerDir; null; false);    }   ....  lfs.mkdir(containerDir; null; false);  refer to the api of mkdir; false means cannot create parent path here if not exists. In my hadoop project; I revise  lfs.mkdir(containerDir; null; false);  to lfs.mkdir(containerDir; null; true); ; then my program goes well.,Resolved,Duplicate,YARN-253,Unassigned,Bing Jiang,Wed; 11 Jan 2012 01:33:34 +0000,Tue; 4 Dec 2012 03:55:55 +0000,Tue; 4 Dec 2012 03:55:55 +0000,,2.0.1-alpha,,,YARN-253,https://issues.apache.org/jira/browse/YARN-152
MAPREDUCE-3656,Bug,Blocker,applicationmaster;mrv2;resourcemanager,Sort job on 350 scale is consistently failing with latest MRV2 code ,With the code checked out on last two days.  Sort Job on 350 node scale with 16800 maps and 680 reduces consistently failing for around last 6 runs When around 50% of maps are completed; suddenly job jumps to failed state. On looking at NM log; found RM sent Stop Container Request to NM for AM container. But at INFO level from RM log not able find why RM is killing AM when job is not killed manually. One thing found common on failed AM logs is -: org.apache.hadoop.yarn.state.InvalidStateTransitonException With with different. For e.g. One log says -:   Whereas other logs says -:,Closed,Fixed,,Siddharth Seth,Karam Singh,Wed; 11 Jan 2012 15:45:52 +0000,Mon; 5 Mar 2012 02:48:54 +0000,Fri; 13 Jan 2012 21:33:48 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3656
MAPREDUCE-3657,Bug,Minor,build;mrv2,State machine visualize build fails,Attempting to build the state machine graphs with mvn -Pvisualize compile fails for the resourcemanager and nodemanager projects.  The build fails because org.apache.commons.logging.LogFactory isn't in the classpath.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 11 Jan 2012 17:29:43 +0000,Tue; 10 Mar 2015 04:31:49 +0000,Mon; 16 Jan 2012 21:24:16 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3657
YARN-3308,Improvement,Minor,documentation,Improvements to CapacityScheduler documentation,There are some typos and some cases of incorrect English. Also; the descriptions of yarn.scheduler.capacity.queue-path.capacity; yarn.scheduler.capacity.queue-path.maximum-capacity; yarn.scheduler.capacity.queue-path.user-limit-factor; yarn.scheduler.capacity.maximum-applications are not very clear to the uninitiated.,Open,Unresolved,,Unassigned,Yoram Arnon,Wed; 11 Jan 2012 21:30:29 +0000,Thu; 12 May 2016 18:29:09 +0000,,,3.0.0-alpha1,documentation,,,https://issues.apache.org/jira/browse/YARN-3308
MAPREDUCE-3659,Improvement,Major,security,Host-based token support,Need to port the 205 host-based token support into MR and yarn.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Thu; 12 Jan 2012 00:40:47 +0000,Tue; 10 Mar 2015 04:33:04 +0000,Thu; 10 May 2012 14:54:59 +0000,,0.23.1;2.0.0-alpha,,,HADOOP-7510,https://issues.apache.org/jira/browse/MAPREDUCE-3659
MAPREDUCE-3660,Bug,Major,task-controller,task controller uses wrong path to taskjvm.sh on windows,In 1.0.0; DefaultTaskController passes the string returned by TaskController.writeCommand to the shell.  For this to work on Windows; the path needs to be passed through FileUtil.makeShellPath to convert it into a cygwin path; which also requires backslashes instead of forward slashes.,Open,Unresolved,,Unassigned,Jonathan Matthew,Thu; 12 Jan 2012 01:31:32 +0000,Thu; 12 Jan 2012 01:33:07 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3660
MAPREDUCE-3661,Bug,Major,task-controller,JvmManager dies on windows because it doesn't have process IDs,"JvmManager.kill() throws a NumberFormatException on Windows because it doesn't have process IDs; so it passes the default empty string (set in Child.main apparently) to Integer.parseInt().  This causes the task tracker to shut down.  I'm guessing the child can't send null (rather than """") as its pid to the parent; so the parent should treat the empty string the same as null when processing the pid string.",Open,Unresolved,,Unassigned,Jonathan Matthew,Thu; 12 Jan 2012 02:00:46 +0000,Thu; 12 Jan 2012 02:03:04 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3661
MAPREDUCE-3662,Wish,Major,mrv2,Command line ask: NM info where containers are launched,Courtesy Ramya Sunil  we had requested for the NM information where the containers are scheduled to be made available in job -list-attempt-ids. This will be helpful in automation; debugging and avoid grepping through the AM logs.,Resolved,Duplicate,MAPREDUCE-3406,Unassigned,Ravi Prakash,Thu; 12 Jan 2012 05:13:53 +0000,Thu; 12 Jan 2012 22:28:01 +0000,Thu; 12 Jan 2012 22:28:01 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3662
MAPREDUCE-3663,Bug,Major,mrv2,After submitting a job. If the Runjar process gets killed ;then the job is hanging,When the job is submitted...Runjar process is created and the YarnChild processes also start running.If at this time ;the RunJar process is getting killed; the job is hanging.,Resolved,Cannot Reproduce,,Unassigned,Ramgopal N,Thu; 12 Jan 2012 14:11:15 +0000,Fri; 20 Mar 2015 00:49:38 +0000,Fri; 20 Mar 2015 00:49:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3663
MAPREDUCE-3664,Bug,Minor,documentation,HDFS Federation Documentation has incorrect configuration example,HDFS Federation documentation example (1) has the following  property     namedfs.namenode.rpc-address.ns1 Federation.html,Closed,Fixed,,Brandon Li,praveen sripati,Wed; 11 Jan 2012 16:47:29 +0000,Tue; 10 Mar 2015 04:31:48 +0000,Mon; 16 Jan 2012 22:10:45 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3664
MAPREDUCE-3665,Bug,Major,mrv2,Hadoop ignores old-style config options for enabling compressed output,Hadoop seems to ignore the config options even though they are printed as deprecation warnings in the log:  mapred.output.compress and mapred.output.compression.codec   settings that work on 0.20 but not on 0.23 mapred.output.compress=true mapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec   settings that work on 0.23 mapreduce.output.fileoutputformat.compress=true mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.BZip2Codec  This breaks backwards compatibility and causes existing jobs to fail.,Resolved,Duplicate,HADOOP-7993,Anupam Seth,Anupam Seth,Thu; 12 Jan 2012 19:18:30 +0000,Thu; 26 Jan 2012 17:52:20 +0000,Wed; 25 Jan 2012 18:46:10 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3665
MAPREDUCE-3666,Bug,Minor,documentation,Broken documentation link for r0.23.0,Apache Hadoop website has a broken link for the r0.23.0 release (http: ).,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 12 Jan 2012 20:33:34 +0000,Thu; 12 Jan 2012 20:33:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3666
MAPREDUCE-3667,Bug,Blocker,mrv2,Gridmix jobs are failing with OOM in reduce shuffle phase.,Roll up bug for gridmix3 benchmark,Resolved,Not A Problem,,Unassigned,Amol Kekre,Fri; 13 Jan 2012 18:57:48 +0000,Wed; 1 Feb 2012 19:35:24 +0000,Thu; 26 Jan 2012 05:42:01 +0000,,0.23.0,,MAPREDUCE-3719,,https://issues.apache.org/jira/browse/MAPREDUCE-3667
MAPREDUCE-3668,Bug,Blocker,client;mrv2;security,AccessControlException when running mapred job -list command,"If a user tries to examine the status of all jobs running on a secure cluster the mapred client can fail with an AccessControlException.  For example; submitting two jobs each from a different user then trying to query the status as the second user can fail like this:  $ mapred job -list all   WARN mapred.ClientServiceDelegate: Error from remote end: User user2 cannot perform operation VIEW_JOB on job_1326396427223_0001 Exception in thread ""main"" RemoteTrace:   1209)   The information provided by the command is similar to what is presented on the ResourceManager web UI; and that page has no security.  Marking this as a blocker since many of our automated acceptance tests use this command to obtain the status of jobs running in the cluster.",Resolved,Duplicate,MAPREDUCE-3720,Vinod Kumar Vavilapalli,Jason Lowe,Fri; 13 Jan 2012 19:25:08 +0000,Mon; 30 Jan 2012 23:52:04 +0000,Mon; 30 Jan 2012 23:51:41 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3668
MAPREDUCE-3669,Bug,Blocker,mrv2,Getting a lot of PriviledgedActionException / SaslException when running a job,On a secure cluster; when running a job we are seeing a lot of PriviledgedActionException  ,Closed,Fixed,,Mahadev konar,Thomas Graves,Fri; 13 Jan 2012 20:16:21 +0000,Mon; 5 Mar 2012 02:48:52 +0000,Tue; 17 Jan 2012 21:29:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3669
MAPREDUCE-3670,Task,Major,mr-am;mrv2,TaskAttemptListener should respond with errors to unregistered tasks,The TaskAttemptListener currently accepts TaskUmbilical calls from tasks which may have already been unregistered and processes updates. It should just send back Exceptions so that the tasks die. This isn't critical though - since the task container would eventually be killed by the AM (via a call to NM stopContainer).,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 13 Jan 2012 22:33:06 +0000,Fri; 13 Jan 2012 22:33:06 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3670
MAPREDUCE-3671,Sub-task,Major,mrv2;nodemanager,AM-NM RPC calls occasionally takes a long time to respond,Observed while looking at MAPREDUCE-3596 and MAPREDUCE-3656. startContainer taking over a minute in some cases; otherwise 15 seconds. Both were observed soon after reduce tasks started. Network congestion ? Need more looking into.,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 13 Jan 2012 22:37:39 +0000,Fri; 18 Apr 2014 16:24:45 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3671
MAPREDUCE-3672,Bug,Major,mr-am;mrv2,Killed maps shouldn't be counted towards JobCounter.NUM_FAILED_MAPS,We count maps that are killed; say by speculator; towards JobCounter.NUM_FAILED_MAPS. We should instead have a separate JobCounter for killed maps.  Same with reduces too.,Closed,Fixed,,Anupam Seth,Vinod Kumar Vavilapalli,Fri; 13 Jan 2012 23:46:53 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Wed; 4 Apr 2012 14:20:37 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3672
MAPREDUCE-3673,Improvement,Minor,mrv1,org.apache.hadoop.mapreduce.lib.chain.ChainMapper missing on 1.0,org.apache.hadoop.mapreduce.lib.chain.ChainMapper is missing on 1.0.  if we are using new context api; do we still the ChainMapper ChainReducer from the mapred package.,Reopened,Unresolved,,Unassigned,surajz,Tue; 10 Jan 2012 22:42:10 +0000,Thu; 2 May 2013 02:29:48 +0000,,,1.0.0;1.0.1;1.0.2;1.0.3;1.0.4;1.1.0;1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3673
MAPREDUCE-3674,Bug,Critical,jobtracker,If invoked with no queueName request param; jobqueue_details.jsp injects a null queue name into schedulers.,When you access  jobqueue_details.jsp manually; instead of via a link; it has queueName set to null internally and this goes for a lookup into the scheduling info maps as well.  As a result; if using FairScheduler; a Pool with String name = null gets created and this brings the scheduler down. I have not tested what happens to the CapacityScheduler; but ideally if no queueName is set in that jsp; it should fall back to 'default'. Otherwise; this brings down the JobTracker completely.  FairScheduler must also add a check to not create a pool with 'null' name.  The following is the strace that ensues:,Closed,Fixed,,Harsh J,Harsh J,Mon; 16 Jan 2012 03:49:46 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Fri; 20 Apr 2012 10:03:32 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3674
MAPREDUCE-3675,Bug,Minor,client,A job must not be submitted when there are no mappers to run,Right now; one's able to run a job with an empty input directory and a job is indeed scheduled.  The job runs no mappers; but any number of specified reducers are run anyway as dummy tasks.  This should be could be avoided. I do not see a use for such an allowance; and it looks mostly like a logic slip to me with empty arrays involved and accepted.  The fix could be simply in the job submission code; where we can avoid submitting if the splits are nil.,Resolved,Invalid,,Unassigned,Harsh J,Mon; 16 Jan 2012 08:23:57 +0000,Tue; 29 May 2012 19:00:44 +0000,Mon; 16 Jan 2012 19:39:21 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3675
YARN-196,Bug,Major,nodemanager,Nodemanager should be more robust in handling connection failure  to ResourceManager when a cluster is started,If NM is started before starting the RM ;NM is shutting down with the following error,Closed,Fixed,YARN-141,Xuan Gong,Ramgopal N,Mon; 16 Jan 2012 09:52:45 +0000,Thu; 12 May 2016 18:29:26 +0000,Fri; 15 Mar 2013 18:10:11 +0000,,2.0.0-alpha;3.0.0-alpha1,,,YARN-3644;YARN-479,https://issues.apache.org/jira/browse/YARN-196
MAPREDUCE-3677,Bug,Major,nodemanager,"If ""hadoop.security.authorization"" is set to true; NM is not starting.","I have the hadoop cluster setup with root user.Accidentally i have set hadoop.security.authorization to true.I have not set any permissions in policy.xml.When i am trying to start the NM with root user ...it is throwing the following error  Exception in thread ""main""  316) Could not find the main class: nodemanager.  Program will exit.",Resolved,Not A Problem,,Chen He,Ramgopal N,Mon; 16 Jan 2012 10:10:31 +0000,Fri; 25 Apr 2014 16:35:06 +0000,Fri; 25 Apr 2014 16:35:06 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3677
MAPREDUCE-3678,New Feature,Major,mrv1;mrv2,The Map tasks logs should have the value of input split it processed,It would be easier to debug some corner in tasks if we knew what was the input split processed by that task. Map reduce task tracker log should accommodate the same. Also in the jobdetails web UI; the split also should be displayed along with the Split Locations.   Sample as Input Split hdfs: offset from beginning of file  This would be much beneficial to nail down some data quality issues in large data volume processing.,Closed,Fixed,MAPREDUCE-2076,Harsh J,Bejoy KS,Mon; 16 Jan 2012 17:35:14 +0000,Fri; 15 Feb 2013 13:10:01 +0000,Tue; 9 Oct 2012 13:45:03 +0000,,1.0.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3678
MAPREDUCE-3679,Improvement,Major,mrv2,AM logs and others should not automatically refresh after every 1 second.,If you are looking through the logs for AM or containers; the page is automatically refreshed after 1 second or so which makes it problematic to search through the page or debug using the content on the page. We should not refresh the logs page. There should be a button to manually refresh if the user needs to.,Closed,Fixed,,Vinod Kumar Vavilapalli,Mahadev konar,Mon; 16 Jan 2012 19:12:26 +0000,Mon; 5 Mar 2012 02:49:14 +0000,Tue; 31 Jan 2012 04:58:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3679
MAPREDUCE-3680,Bug,Major,mrv2,FifoScheduler web service rest API can print out invalid JSON,"running a GET on the scheduler web services rest api (RM:port scheduler) with the FifoScheduler configured with no nodemanagers up yet and it prints out invalid json of NaN for the used Capacity:  {""scheduler"":{""schedulerInfo"": {""type"":""fifoScheduler"";""capacity"":1.0;""usedCapacity"":NaN;""qstate"":""RUNNING"";""minQueueMemoryCapacity"":1024;""maxQueueMemoryCapacity"":10240;""numNodes"":0;""usedNodeCapacity"":0;""availNodeCapacity"":0;""totalNodeCapacity"":0;""numContainers"":0} }}",Resolved,Fixed,,Unassigned,Thomas Graves,Tue; 17 Jan 2012 17:00:56 +0000,Sat; 11 Feb 2012 13:16:31 +0000,Fri; 10 Feb 2012 14:38:50 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3680
MAPREDUCE-3681,Bug,Critical,mrv2,capacity scheduler LeafQueues calculate used capacity wrong,In the Capacity scheduler if you configure the queues to be hierarchical where you have root - parent queue - leaf queue; the leaf queue doesn't calculate the used capacity properly. It seems to be using the entire cluster memory rather then its parents memory capacity.   In updateResource in LeafQueue:     setUsedCapacity(         usedResources.getMemory()   (clusterResource.getMemory() * capacity));  I think the clusterResource.getMemory() should be something like getParentsMemory().,Closed,Fixed,,Arun C Murthy,Thomas Graves,Tue; 17 Jan 2012 18:13:49 +0000,Mon; 5 Mar 2012 02:48:46 +0000,Tue; 24 Jan 2012 01:07:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3681
MAPREDUCE-3682,Bug,Major,mrv2,Tracker URL says AM tasks run on localhost,If you look at the task page; it will show you the node the task ran on.  For jobs that run in UberAM they point to http:   This was run on a multi node cluster.,Closed,Fixed,,Ravi Prakash,David Capwell,Tue; 17 Jan 2012 18:34:59 +0000,Thu; 11 Oct 2012 17:48:42 +0000,Wed; 4 Apr 2012 15:14:16 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3682
MAPREDUCE-3683,Bug,Blocker,mrv2,Capacity scheduler LeafQueues maximum capacity calculation issues,In the Capacity scheduler if you configure the queues to be hierarchical where you have root - parent queue - leaf queue; the leaf queue doesn't take into account its parents maximum capacity when calculate its own maximum capacity; instead it seems to use the parents capacity.  Looking at the code its using the parents absoluteCapacity and I think it should be using the parents absoluteMaximumCapacity.  It also seems to only use the parents capacity in the leaf queues max capacity calculation when the leaf queue has a max capacity configured. If the leaf queues maximum-capacity is not configured; then it can use 100% of the cluster.,Closed,Fixed,,Arun C Murthy,Thomas Graves,Tue; 17 Jan 2012 18:57:06 +0000,Mon; 5 Mar 2012 02:48:53 +0000,Wed; 25 Jan 2012 18:19:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3683
MAPREDUCE-3684,Bug,Major,client,LocalDistributedCacheManager does not shut down its thread pool,This was observed by running a Hive job in local mode. The job completed but the client process did not exit for 60 seconds.,Closed,Fixed,,Tom White,Tom White,Tue; 17 Jan 2012 22:59:06 +0000,Mon; 5 Mar 2012 02:49:18 +0000,Wed; 18 Jan 2012 18:22:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3684
MAPREDUCE-3685,Bug,Critical,mrv2,There are some bugs in implementation of MergeManager,nan,Closed,Fixed,,anty,anty.rao,Wed; 18 Jan 2012 06:35:04 +0000,Tue; 27 Aug 2013 22:21:56 +0000,Wed; 6 Mar 2013 15:06:44 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3685
MAPREDUCE-3686,Bug,Critical,mrv2,history server web ui - job counter values for map/reduce not shown properly,Looking at the job counters page on the history server for a finished job; it shows 3 columns for each counter - map; reduce; total. The total appears correct; but map and reduce columns are always zero.  If you click on a particular column it does show you the map reduce task and the value of each one.  Going to attach screenshots shortly.,Resolved,Fixed,,Bhallamudi Venkata Siva Kamesh,Thomas Graves,Wed; 18 Jan 2012 16:55:48 +0000,Mon; 27 Feb 2012 05:41:23 +0000,Sun; 26 Feb 2012 08:35:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3686
MAPREDUCE-3687,Bug,Major,mrv2,If AM dies before it returns new tracking URL; proxy redirects to http://N/A/ and doesn't return error code,I tried to turn on Uber AM and put 9223372036854775807l (last char is an L) for maxbytes.  This caused a NumberFormatException in the AM and killed it.  When I try to go to the RM proxy; it redirects me to http:  Content-Length: 0 Server: Jetty(6.1.26)  Since the AM has no tracker URL; I would expect the return code to be 400~ or 500~ and return an error.,Resolved,Fixed,,Ravi Prakash,David Capwell,Wed; 18 Jan 2012 18:03:51 +0000,Thu; 1 Mar 2012 13:58:05 +0000,Wed; 29 Feb 2012 15:23:17 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3687
MAPREDUCE-3688,Bug,Major,mr-am;mrv2,Need better Error message if AM is killed/throws exception,"We need better error messages in the UI if the AM gets killed or throws an Exception.  If the following error gets thrown:   lang.NumberFormatException: For input string: ""9223372036854775807l""   last char is an L  then the UI should say this exception.  Instead I get the following:  Application application_1326504761991_0018 failed 1 times due to AM Container for appattempt_1326504761991_0018_000001 exited with exitCode: 1 due to: Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException",Open,Unresolved,,Sandy Ryza,David Capwell,Wed; 18 Jan 2012 18:08:17 +0000,Wed; 11 Dec 2013 20:15:55 +0000,,,0.23.1,,,YARN-499;YARN-560;YARN-522,https://issues.apache.org/jira/browse/MAPREDUCE-3688
MAPREDUCE-3689,Bug,Blocker,mrv2,RM web UI doesn't handle newline in job name,a user submitted a mapreduce job with a newline ( n in the job name.,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 18 Jan 2012 18:44:15 +0000,Mon; 5 Mar 2012 02:49:22 +0000,Fri; 20 Jan 2012 21:32:36 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3689
MAPREDUCE-3690,Bug,Major,mrv2,mapred.ClientServiceDelegate.java:getProxy prints the proxy without http:// prefix,Example job client stdout capture  2012-01-18 10:30:00;980 INFO  mapred.ClientServiceDelegate (ClientServiceDelegate. getProxy(178)) - The url to track the job: machine.example.com:8088 ,Resolved,Duplicate,MAPREDUCE-3646,Jonathan Eagles,Jonathan Eagles,Wed; 18 Jan 2012 20:41:16 +0000,Thu; 19 Jan 2012 20:26:39 +0000,Thu; 19 Jan 2012 20:25:53 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3690
MAPREDUCE-3691,Bug,Critical,mrv2,webservices add support to compress response,The web services currently don't support header 'Accept-Encoding: gzip'  Given that the responses have a lot of duplicate data like the property names in JSON or the tag names in XML; it should compress very well; and would save on bandwidth and download time when fetching a potentially large response; like the ones from ws jobs,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 18 Jan 2012 20:53:52 +0000,Thu; 2 May 2013 02:29:48 +0000,Mon; 23 Jan 2012 21:28:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3691
MAPREDUCE-3692,Improvement,Blocker,mrv2,yarn-resourcemanager out and log files can get big,I'm seeing 8gb resourcemanager out files and big log files; seeing lots of repeated logs (eg every rpc call or event) looks like we're being too verbose in  a couple of places.,Closed,Fixed,,Eli Collins,Eli Collins,Thu; 19 Jan 2012 00:21:36 +0000,Mon; 5 Mar 2012 02:49:06 +0000,Tue; 24 Jan 2012 22:26:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3692
MAPREDUCE-3693,Improvement,Minor,mrv2,Add admin env to mapred-default.xml,I have noticed that org.apache.hadoop.mapred.MapReduceChildJVM doesn't forward the value of -D used to do that:     Is this a regression or a deliberate choice?,Closed,Fixed,,Roman Shaposhnik,Roman Shaposhnik,Thu; 19 Jan 2012 02:32:05 +0000,Wed; 28 Mar 2012 21:57:23 +0000,Fri; 27 Jan 2012 08:51:05 +0000,,0.23.0,,,MAPREDUCE-4072,https://issues.apache.org/jira/browse/MAPREDUCE-3693
MAPREDUCE-3694,Bug,Critical,mrv2,JobClient.getJob(JobID) broken in 0.23 for LocalJobRunner?,In LocalJobRunner; when a job is submitted through old JobClient; and when its status is queried from getJob(JobID); it returns null. The issue seen on HIVE-2708.,Resolved,Invalid,,Unassigned,Amareshwari Sriramadasu,Thu; 19 Jan 2012 06:04:00 +0000,Tue; 24 Jan 2012 06:37:31 +0000,Tue; 24 Jan 2012 06:37:31 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3694
MAPREDUCE-3695,Bug,Major,mrv2,Error:ORA 00911 invalid character(the result of mapreduce insert into oracle),"Exception occurred when the result of mapreduce insert into oracle except mysql.   org.apache.hadoop.mapred.Child.main(Child. modify as follows and exception fixed. the reason is more than a semicolon.    public String constructQuery(String table; String[] fieldNames) {     if(fieldNames == null)  {       throw new IllegalArgumentException(""Field names may not be null"");     }      StringBuilder query = new StringBuilder();     query.append(""INSERT INTO "").append(table);      if (fieldNames.length  0 &amp; fieldNames0 != null) {       query.append("" ("");       for (int i = 0; i  fieldNames.length; i++) {         query.append(fieldNamesi);         if (i != fieldNames.length - 1)  {           query.append("";"");         }       }       query.append("")"");     }     query.append("" VALUES ("");      for (int i = 0; i  fieldNames.length; i++) {       query.append(""?"");       if(i != fieldNames.length - 1)  {         query.append("";"");       }     }     query.append("");"");      return query.toString();   }",Open,Unresolved,,Unassigned,      ,Thu; 19 Jan 2012 09:45:38 +0000,Wed; 20 May 2015 22:58:21 +0000,,,2.0.0-alpha,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3695
MAPREDUCE-3696,Bug,Blocker,mrv2,MR job via oozie does not work on hadoop 23,NM throws an error on submitting an MR job via oozie on the latest Hadoop 23. *Courtesy: Mona Chitnis (ooize),Closed,Fixed,,John George,John George,Thu; 19 Jan 2012 15:00:45 +0000,Mon; 5 Mar 2012 02:49:49 +0000,Wed; 1 Feb 2012 20:46:20 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3696
MAPREDUCE-3697,Bug,Blocker,mrv2,Hadoop Counters API limits Oozie's working across different hadoop versions,Oozie uses Hadoop Counters API; by invoking Counters.getGroup(). However; in hadoop 23; org.apache.hadoop.mapred.Counters does not implement getGroup(). Its parent class AbstractCounters implements it. This is different from hadoop20X. As a result; Oozie compiled with either hadoop version does not work with the other version. A specific scenario; Oozie compiled with .23 and run against 205; does not update job status owing to a Counters API exception.  Will explicit re-compilation against the relevant hadoop jars be required each time? This will prevent launching a uniform Oozie version across different clusters.,Closed,Fixed,,Mahadev konar,John George,Thu; 19 Jan 2012 15:04:35 +0000,Thu; 2 May 2013 02:29:49 +0000,Tue; 7 Feb 2012 01:43:06 +0000,,0.23.1,,,MAPREDUCE-5055;HADOOP-7738,https://issues.apache.org/jira/browse/MAPREDUCE-3697
MAPREDUCE-3698,Sub-task,Blocker,mrv2,Client cannot talk to the history server in secure mode,nan,Closed,Fixed,,Mahadev konar,Siddharth Seth,Thu; 19 Jan 2012 19:41:55 +0000,Mon; 5 Mar 2012 02:49:50 +0000,Fri; 20 Jan 2012 20:47:29 +0000,,0.23.1,,HADOOP-7986,MAPREDUCE-3704,https://issues.apache.org/jira/browse/MAPREDUCE-3698
MAPREDUCE-3699,Bug,Major,mrv2,Default RPC handlers are very low for YARN servers,Mainly NM has a default of 5; RM has 10 and AM also has 10 irrespective of num-slots; num-nodes and num-tasks respectively. Though ideally we want to scale according to slots tasks; for now increasing the defaults should be enough.,Closed,Fixed,,Hitesh Shah,Vinod Kumar Vavilapalli,Thu; 19 Jan 2012 23:39:12 +0000,Mon; 5 Mar 2012 02:48:54 +0000,Thu; 26 Jan 2012 21:38:56 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3699
MAPREDUCE-3700,Bug,Major,mrv2,If a resource in job.jar start with ./; we cannot get it in the backend,"When testing Pig on hadoop23; I find if Pig register a script start with . scriptingudf.py"");",Open,Unresolved,,Unassigned,Daniel Dai,Thu; 19 Jan 2012 23:57:30 +0000,Fri; 8 Jun 2012 21:41:03 +0000,,,0.23.0,,PIG-2484,,https://issues.apache.org/jira/browse/MAPREDUCE-3700
MAPREDUCE-3701,Bug,Major,mrv2,Delete HadoopYarnRPC from 0.23 branch.,HadoopYarnRPC file exists in 0.23 (should have been removed with the new HadoopYarnProtoRPC). Trunk does not have this issue.,Closed,Fixed,,Mahadev konar,Mahadev konar,Fri; 20 Jan 2012 07:29:24 +0000,Mon; 5 Mar 2012 02:48:41 +0000,Fri; 20 Jan 2012 21:48:33 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3701
MAPREDUCE-3702,Bug,Critical,mrv2,internal server error trying access application master via proxy with filter enabled,I had a hadoop.http.filter.initializers in place to do user authentication; but was purposely trying to let it bypass authentication on certain pages.  One of those was the proxy and the application master main page. When I then tried to go to the application master through the proxy it throws an internal server error:  Problem accessing  mapreduce. Reason:      INTERNAL_SERVER_ERROR Caused by:   1212)   It looks like the problem is that AmIpFilter doesn't check for null returned from httpReq.getCookies(),Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 20 Jan 2012 15:38:54 +0000,Mon; 5 Mar 2012 02:49:52 +0000,Mon; 23 Jan 2012 21:27:38 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3702
MAPREDUCE-3703,Bug,Critical,mrv2;resourcemanager,ResourceManager should provide node lists in JMX output,In 0.20.*; the JMX UI for the JobTracker (http: jmx) showed lists of Live and BlackListed Nodes under the JobTrackerInfo section.  In 0.23; the ResourceManager JMX UI shows the number of active; decommissioned; lost; unhealthy; and rebooted nodes under the ClusterMetrics section; but does not give the list of nodes.  At least the list of active nodes is needed in JSON format.,Closed,Fixed,,Eric Payne,Eric Payne,Fri; 20 Jan 2012 16:46:24 +0000,Mon; 5 Mar 2012 02:49:12 +0000,Mon; 30 Jan 2012 18:51:22 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3703
MAPREDUCE-3704,Bug,Major,client;mrv2,Yarn client goes into tight loop upon connection failure,If the client fails to connect to the AM or HS; it will go into a tight loop retrying the connection.  The log rapidly grows with multiple log lines per attempt.  Based one of the logs; the client was pounding on the AM ~1000 sec.,Resolved,Not A Problem,,Unassigned,Daryn Sharp,Fri; 20 Jan 2012 17:08:53 +0000,Tue; 10 Mar 2015 04:32:45 +0000,Wed; 16 Apr 2014 21:22:38 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-3698,https://issues.apache.org/jira/browse/MAPREDUCE-3704
MAPREDUCE-3705,Bug,Blocker,mrv2,ant build fails on 0.23 branch ,running the ant build in mapreduce on the latest 23 branch fails.  Looks like the ivy properties file still has 0.24.0 and then the gridmix dependencies need to have rumen as dependency.  The gridmix errors look like:                                       ^,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 20 Jan 2012 23:14:41 +0000,Mon; 5 Mar 2012 02:49:23 +0000,Sat; 21 Jan 2012 01:17:56 +0000,,0.23.0,,,MAPREDUCE-3860,https://issues.apache.org/jira/browse/MAPREDUCE-3705
MAPREDUCE-3706,Bug,Critical,mrv2,HTTP Circular redirect error on the job attempts page,submitted job and tried to go to following url:  http:  and then click the links to get here you don't get the error.,Resolved,Fixed,MAPREDUCE-4045,Robert Joseph Evans,Thomas Graves,Sat; 21 Jan 2012 04:01:30 +0000,Fri; 4 Mar 2016 05:51:08 +0000,Wed; 29 Feb 2012 22:17:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3706
HADOOP-9469,Bug,Major,,mapreduce/yarn source jars not included in dist tarball,the mapreduce and yarn sources jars don't get included into the distribution tarball.  It seems they get built by default just aren't assembled.,Closed,Fixed,,Robert Parker,Thomas Graves,Sat; 21 Jan 2012 13:11:50 +0000,Wed; 3 Sep 2014 22:58:43 +0000,Fri; 19 Apr 2013 21:59:55 +0000,,0.23.0,,MAPREDUCE-5147,,https://issues.apache.org/jira/browse/HADOOP-9469
MAPREDUCE-3708,Bug,Major,mrv2,Metrics: Incorrect Apps Submitted Count,Submitted an application with the following configuration   In the above case; application had failed first time. So AM attempted the same application again.  While attempting the same application; Apps Submitted counter also has been incremented.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Sat; 21 Jan 2012 14:40:25 +0000,Tue; 10 Mar 2015 04:32:28 +0000,Fri; 3 Feb 2012 00:37:10 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3708
MAPREDUCE-3709,Bug,Major,mrv2;test,TestDistributedShell is failing,TestDistributedShell#testDSShell is failing the assert on line 90 on branch-23.,Closed,Fixed,,Hitesh Shah,Eli Collins,Mon; 23 Jan 2012 17:36:42 +0000,Mon; 5 Mar 2012 02:49:23 +0000,Tue; 7 Feb 2012 02:01:22 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3709
MAPREDUCE-3710,Bug,Major,mrv1;mrv2,last split generated by FileInputFormat.getSplits may not have the best locality,The last split generated by FileInputFormat.getSplits considers blkLocations.length-1 to be the hosts for the split. The last split may be larger than the rest (SPLIT_SLOP=1.1 by default) - in which case locality is picked up from a smaller block. e.g. 1027MB file with a 128MB split size. The last split ends up being 131MB. The hosts for locality end up being the nodes containing the 3MB block instead of the 128MB block.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Mon; 23 Jan 2012 19:13:10 +0000,Mon; 5 Mar 2012 02:49:54 +0000,Tue; 24 Jan 2012 21:32:59 +0000,,0.23.0;1.0.0,,,MAPREDUCE-3524,https://issues.apache.org/jira/browse/MAPREDUCE-3710
MAPREDUCE-3711,Sub-task,Blocker,mrv2,AppMaster recovery for Medium to large jobs take long time,Reported by Karam Singh  yarn.resourcemanager.am.max-retries=2 Ran test cases with sort job on 350 scale having 16800 maps and 680 reduces -: 1. After 70 secs of Job Sumbission Am is killed using kill -9; around 3900 maps were completed and 680 reduces were scheduled; Second AM got restart. Job got completed in 980 secs. AM took very less time to recover. 2. After 150 secs of Job Sumbission AM is killed using kill -9; around 90% maps were completed and 680 reduces were scheduled ; Second AM got restart Job got completed in 1000 secs. AM got revocer. 3. After 150 secs of Job Sumbission AM as killed using kill -9; almost all maps were completed and only 680 reduces were running; Recovery was too slow; AM was still revocering after 1hr :40 mis when I killed the run.,Closed,Fixed,,Robert Joseph Evans,Siddharth Seth,Mon; 23 Jan 2012 21:17:06 +0000,Tue; 10 Mar 2015 04:31:46 +0000,Sat; 4 Feb 2012 00:07:24 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3711
MAPREDUCE-3712,Bug,Blocker,mrv2,The mapreduce tar does not contain the hadoop-mapreduce-client-jobclient-tests.jar. ,Working MRv1 tests were moved into the maven build as part of MAPREDUCE-3582. Some classes like MRBench; SleepJob; FailJob which are essential for QE got moved to jobclient-tests.jar. However the tar.gz file does not contain this jar.,Closed,Fixed,,Mahadev konar,Ravi Prakash,Tue; 24 Jan 2012 00:07:43 +0000,Mon; 5 Mar 2012 02:49:54 +0000,Wed; 25 Jan 2012 00:17:23 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3712
MAPREDUCE-3713,Bug,Blocker,mrv2;resourcemanager,Incorrect headroom reported to jobs,With multiple jobs submitted per user; and multiple users submitting jobs - the headroom reported to the AppMasters is incorrect (very high). Leads to a deadlock - reduces started; map tasks not complete... and reduces are not preempted by the AM due to the incorrect headroom.,Closed,Fixed,,Arun C Murthy,Siddharth Seth,Tue; 24 Jan 2012 01:54:26 +0000,Mon; 5 Mar 2012 02:49:19 +0000,Wed; 25 Jan 2012 23:32:43 +0000,,0.23.0,,MAPREDUCE-3719,,https://issues.apache.org/jira/browse/MAPREDUCE-3713
MAPREDUCE-3714,Bug,Blocker,mrv2;task,Reduce hangs in a corner case,Karam Singh found this long time back and we(Sid I) ran into this again.  Logs to follow..,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 24 Jan 2012 02:04:27 +0000,Mon; 5 Mar 2012 02:49:18 +0000,Tue; 24 Jan 2012 23:19:09 +0000,,0.23.0,,MAPREDUCE-3719,,https://issues.apache.org/jira/browse/MAPREDUCE-3714
MAPREDUCE-3715,Bug,Minor,,FileSplit's Writable implementation discards hosts information,org.apache.hadoop.mapreduce.lib.input.FileSplit's write() does not write out hosts; and readFields() sets them to null. If this is intended then it should be documented very clearly.  But it looks more like an oversight to me.,Open,Unresolved,,Unassigned,Pavel Podgoretsky,Tue; 24 Jan 2012 09:18:20 +0000,Tue; 24 Jan 2012 12:03:58 +0000,,,0.20.2;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3715
MAPREDUCE-3716,Bug,Blocker,mrv2,java.io.File.createTempFile fails in map/reduce tasks,container-launch.sh specifies  io.tmpdir will fail when called from child container jvms.,Closed,Fixed,MAPREDUCE-3844,Jonathan Eagles,Jonathan Eagles,Tue; 24 Jan 2012 17:00:34 +0000,Mon; 5 Mar 2012 02:49:14 +0000,Tue; 31 Jan 2012 02:25:22 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3716
MAPREDUCE-3717,Bug,Blocker,mrv2,JobClient test jar has missing files to run all the test programs.,Looks like MAPREDUCE-3582 forgot to move couple of files from the ant builds. The current test jar from jobclient does not work.,Closed,Fixed,,Mahadev konar,Mahadev konar,Tue; 24 Jan 2012 19:02:24 +0000,Mon; 5 Mar 2012 02:49:29 +0000,Wed; 25 Jan 2012 06:28:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3717
MAPREDUCE-3718,Sub-task,Major,mrv2;performance,Default AM heartbeat interval should be one second,Helps in improving app performance. RM should be able to handle this; as the heartbeats aren't really costly.,Closed,Fixed,,Hitesh Shah,Vinod Kumar Vavilapalli,Tue; 24 Jan 2012 21:43:06 +0000,Mon; 5 Mar 2012 02:49:26 +0000,Thu; 26 Jan 2012 19:32:18 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3718
MAPREDUCE-3719,Sub-task,Major,mrv2;performance,Make gridmix performance on YARN+MR to match or exceed that on 1.0,nan,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Tue; 24 Jan 2012 22:48:24 +0000,Fri; 10 Feb 2012 00:41:32 +0000,Fri; 10 Feb 2012 00:40:00 +0000,,,,MAPREDUCE-3667;MAPREDUCE-3713;MAPREDUCE-3714;MAPREDUCE-3721;MAPREDUCE-3732;MAPREDUCE-3770;MAPREDUCE-3481,MAPREDUCE-3476;MAPREDUCE-3812;MAPREDUCE-3805;MAPREDUCE-3754,https://issues.apache.org/jira/browse/MAPREDUCE-3719
MAPREDUCE-3720,Bug,Major,client;mrv2,Command line listJobs should not visit each AM,When the RM has a large number of jobs; bin mapred job -status and keep the list just a list.,Closed,Fixed,MAPREDUCE-3668,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 24 Jan 2012 22:54:48 +0000,Mon; 5 Mar 2012 02:49:51 +0000,Fri; 27 Jan 2012 08:46:25 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3720
MAPREDUCE-3721,Bug,Blocker,mrv2,Race in shuffle can cause it to hang,If all current {{Fetcher}}s complete while an in-memory merge is in progress - shuffle could hang.  Specifically - if the memory freed by an in-memory merge does not bring MergeManager.usedMemory below MergeManager.memoryLimit and all current Fetchers complete before the in-memory merge completes; another in-memory merge will not be triggered - and shuffle will hang. (All new fetchers are asked to WAIT).,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 25 Jan 2012 04:31:42 +0000,Mon; 3 Dec 2012 21:30:39 +0000,Thu; 26 Jan 2012 05:41:33 +0000,,0.23.0,,MAPREDUCE-3719,MAPREDUCE-4842,https://issues.apache.org/jira/browse/MAPREDUCE-3721
MAPREDUCE-3722,Improvement,Major,contrib/gridmix,[Gridmix] Use high-RAM jobs' behavior/info in cluster overloading logic in STRESS mode,"Currently; Gridmix in STRESS mode calculates the existing load on the cluster to decide on whether to load further or not. The number of map reduce tasks of all jobs are considered in this calculation as ""each task taking single slot"". But with high RAM jobs; this is not true and so needs to fix this computation.",Open,Unresolved,,Unassigned,Ravi Gummadi,Wed; 25 Jan 2012 09:27:05 +0000,Wed; 25 Jan 2012 09:27:05 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3722
MAPREDUCE-3723,Bug,Major,mrv2;test;webapps,TestAMWebServicesJobs & TestHSWebServicesJobs incorrectly asserting tests,While testing a patch for one of the MR issues; I found TestAMWebServicesJobs  TestHSWebServicesJobs incorrectly asserting tests.  Moreover tests may fail if       where is i is index of outer loop. It should be j instead of i.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Wed; 25 Jan 2012 11:57:06 +0000,Tue; 10 Mar 2015 04:33:01 +0000,Sat; 4 Feb 2012 18:57:43 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3723
MAPREDUCE-3724,Bug,Blocker,examples;mrv2,jobclient-tests.jar 's MapredTestDriver doesn't contain the newly added examples/test programs,MR Example jobs which are used in QE have been copied (not moved) into jobclient-tests.jar. However the MapredTestsDriver. file does not include the two added tests. We should decide if we want to get rid of the mapreduce-examples.jar and move all the tests to jobclients-tests.jar; or keep the current setup.,Resolved,Won't Fix,,Unassigned,Ravi Prakash,Wed; 25 Jan 2012 18:35:59 +0000,Wed; 25 Jan 2012 21:22:35 +0000,Wed; 25 Jan 2012 21:22:35 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3724
MAPREDUCE-3725,Bug,Major,client,Hadoop 22 hadoop job -list returns user name as NULL,Hadoop 22 hadoop job -list returns user name as NULL,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Wed; 25 Jan 2012 19:26:36 +0000,Thu; 2 Feb 2012 13:20:07 +0000,Thu; 2 Feb 2012 01:00:52 +0000,,0.22.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3725
MAPREDUCE-3726,Bug,Minor,client;jobtracker,jobstatus.getjobfile should return jobtracker copy of job.xml instead of .staging copy of job.xml,jobstatus.getjobfile should return jobtracker copy of job.xml instead of .staging copy of job.xml,Open,Unresolved,,Mayank Bansal,Mayank Bansal,Wed; 25 Jan 2012 19:32:42 +0000,Mon; 30 Jul 2012 18:48:28 +0000,,,0.22.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3726
MAPREDUCE-3727,Bug,Critical,security,jobtoken location property in jobconf refers to wrong jobtoken file,Oozie launcher job (for MR Sqoop jobs.  More specifically; we are seeing this happening with certain hive queries that trigger a conditional code within their RowContainer which then uses the FileInputFormat.getSplits() and then the TokenCache tries to load credentials for a file that is for the wrong job.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 25 Jan 2012 19:33:35 +0000,Wed; 15 May 2013 05:16:12 +0000,Wed; 13 Jun 2012 18:33:37 +0000,,0.23.0;1.0.0,,HADOOP-8023,,https://issues.apache.org/jira/browse/MAPREDUCE-3727
MAPREDUCE-3728,Bug,Critical,mrv2;nodemanager,ShuffleHandler can't access results when configured in a secure mode,While running the simplest of jobs (Pi) on MR2 in a fully secure configuration I have noticed th needs to be investigated  separately.,Closed,Fixed,,Ding Yuan,Roman Shaposhnik,Wed; 25 Jan 2012 19:48:13 +0000,Tue; 30 Jul 2013 00:12:00 +0000,Wed; 29 Feb 2012 20:06:52 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3728
MAPREDUCE-3729,Bug,Critical,mrv2;test,Commit build failing TestJobClientGetJob; TestMRWithDistributedCache; TestLocalModeWithNewApis,See https: .,Resolved,Cannot Reproduce,,Robert Joseph Evans,Vinod Kumar Vavilapalli,Wed; 25 Jan 2012 23:56:34 +0000,Thu; 5 Apr 2012 14:20:08 +0000,Thu; 5 Apr 2012 14:20:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3729
MAPREDUCE-3730,Improvement,Minor,mrv2;resourcemanager,Allow restarted NM to rejoin cluster before RM expires it,"When a node in the RUNNING state (healthy or unhealthy) is rebooted; the resourcemanager rejects the nodemanager's registration request as a duplicate because it is convinced that the nodemanager is already running on that node.  It won't allow that node to rejoin the cluster until the node expiration time elapses which is 10min+ by default.  We should allow the NM to rejoin the cluster if it re-registers within the expiration timeout.  Note that this problem occurs with NMs that are configured to specific ports.  If ephemeral ports are used then a NM reboot ""works"" because the RM thinks the NM registration is for a new node.  See the discussions in MAPREDUCE-3070 and MAPREDUCE-3363.",Resolved,Fixed,,Jason Lowe,Jason Lowe,Thu; 26 Jan 2012 00:12:08 +0000,Tue; 10 Mar 2015 04:32:34 +0000,Fri; 24 Feb 2012 21:43:18 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3730
YARN-578,Sub-task,Major,nodemanager,NodeManager should use SecureIOUtils for serving and aggregating logs,Log servlets for serving logs and the ShuffleService for serving intermediate outputs both should use SecureIOUtils for avoiding symlink attacks.,Closed,Fixed,,Omkar Vinit Joshi,Vinod Kumar Vavilapalli,Thu; 26 Jan 2012 05:27:34 +0000,Tue; 27 Aug 2013 22:15:02 +0000,Thu; 30 May 2013 00:01:21 +0000,,,,YARN-649;HADOOP-9511,MAPREDUCE-5208;YARN-949,https://issues.apache.org/jira/browse/YARN-578
MAPREDUCE-3732,Bug,Blocker,mrv2;resourcemanager;scheduler,CS should only use 'activeUsers with pending requests' for computing user-limits,CS should only use 'activeUsers with pending requests' for computing user-limits; similar to what is done in hadoop-1.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Thu; 26 Jan 2012 07:51:12 +0000,Mon; 5 Mar 2012 02:49:08 +0000,Sat; 28 Jan 2012 01:54:04 +0000,,0.23.0,,MAPREDUCE-3719,,https://issues.apache.org/jira/browse/MAPREDUCE-3732
MAPREDUCE-3733,Bug,Major,,Add Apache License Header to hadoop-distcp/pom.xml,Looks like I missed the Apache Headers in the review. Adding it now.,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 26 Jan 2012 08:19:40 +0000,Mon; 5 Mar 2012 02:49:07 +0000,Thu; 26 Jan 2012 08:32:51 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3733
MAPREDUCE-3734,Improvement,Major,,Provide a way to access,nan,Resolved,Invalid,,Unassigned,Mohammad Kamrul Islam,Thu; 26 Jan 2012 08:22:35 +0000,Thu; 26 Jan 2012 08:23:32 +0000,Thu; 26 Jan 2012 08:23:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3734
MAPREDUCE-3735,Bug,Blocker,mrv2,Add distcp jar to the distribution (tar),Distcp jar isnt getting added to the tarball as of now. We need to add it along with archives streaming and others.,Closed,Fixed,,Mahadev konar,Mahadev konar,Thu; 26 Jan 2012 09:11:25 +0000,Mon; 5 Mar 2012 02:49:24 +0000,Thu; 26 Jan 2012 18:14:28 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3735
MAPREDUCE-3736,Bug,Blocker,mrv2,Variable substitution depth too large for fs.default.name causes jobs to fail,"I'm seeing the same failure as MAPREDUCE-3462 in downstream projects running against a recent build of branch-23. MR-3462 modified the tests rather than fixing the framework. In that jira Ravi mentioned ""I'm still ignorant of the change which made the tests start to fail. I should probably understand better the reasons for that change before proposing a more generalized fix."" Let's figure out the general fix (rather than require all projects to set mapreduce.job.hdfs-servers in their conf we should fix this in the framework). Perhaps we should not default this config to ""$fs.default.name""?",Resolved,Fixed,,Ahmed Radwan,Eli Collins,Thu; 26 Jan 2012 18:36:24 +0000,Wed; 15 Feb 2012 13:53:07 +0000,Tue; 14 Feb 2012 23:11:00 +0000,,0.23.1,,,HADOOP-6233;SQOOP-433,https://issues.apache.org/jira/browse/MAPREDUCE-3736
MAPREDUCE-3737,Bug,Critical,mrv2,The Web Application Proxy's is not documented very well,The Web Application Proxy is a security feature; but there is no documentation for what it does; why it does it; and more importantly what attacks it is known not protect against.  This is so that anyone addopting Hadoop can know exactly what they potential security issues they may encounter.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 26 Jan 2012 18:50:32 +0000,Mon; 5 Mar 2012 02:49:27 +0000,Thu; 26 Jan 2012 20:12:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3737
MAPREDUCE-3738,Bug,Critical,mrv2;nodemanager,NM can hang during shutdown if AppLogAggregatorImpl thread dies unexpectedly,If an AppLogAggregator thread dies unexpectedly (e.g.: uncaught exception like OutOfMemoryError in the case I saw) then this will lead to a hang during nodemanager shutdown.  The NM calls AppLogAggregatorImpl.join() during shutdown to make sure log aggregation has completed; and that method internally waits for an atomic boolean to be set by the log aggregation thread to indicate it has finished.  Since the thread was killed off earlier due to an uncaught exception; the boolean will never be set and the NM hangs during shutdown repeating something like this every second in the log file:  2012-01-25 22:20:56;366 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl: Waiting for aggregation to complete for application_1326848182580_2806,Resolved,Fixed,,Jason Lowe,Jason Lowe,Thu; 26 Jan 2012 20:57:34 +0000,Tue; 10 Mar 2015 04:31:58 +0000,Fri; 24 Feb 2012 02:14:06 +0000,,0.23.1;2.0.0-alpha,,,MAPREDUCE-3143,https://issues.apache.org/jira/browse/MAPREDUCE-3738
MAPREDUCE-3739,Bug,Major,mrv2,Document all missing default configuration values in the relevant *default.xml files.,There seem to be quite a few configuration settings that are used in the code but missing from the *default.xml files.,Open,Unresolved,,Unassigned,Hitesh Shah,Thu; 26 Jan 2012 21:30:30 +0000,Tue; 10 Mar 2015 04:31:58 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3739
MAPREDUCE-3740,Bug,Blocker,mrv2,Mapreduce Trunk compilation fails,nan,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 27 Jan 2012 11:47:26 +0000,Tue; 10 Mar 2015 04:31:47 +0000,Fri; 27 Jan 2012 21:49:43 +0000,,2.0.0-alpha,,,HADOOP-7965,https://issues.apache.org/jira/browse/MAPREDUCE-3740
MAPREDUCE-3741,Bug,Major,build,Conflicting dependency in hadoop-mapreduce-examples,Are we missing type here?,Resolved,Fixed,,Unassigned,Kihwal Lee,Fri; 27 Jan 2012 15:23:33 +0000,Mon; 9 Mar 2015 20:34:13 +0000,Mon; 9 Mar 2015 20:34:13 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3741
MAPREDUCE-3742,Bug,Blocker,mrv2,yarn logs command fails with ClassNotFoundException,"Executing ""yarn logs""   247) Could not find the main class: org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogDumper.  Program will exit.  Appears to have been caused by the code reorg in MAPREDUCE-3297.",Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 27 Jan 2012 17:30:53 +0000,Tue; 10 Mar 2015 04:32:05 +0000,Fri; 27 Jan 2012 18:54:46 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3742
YARN-432,Sub-task,Major,documentation,Documentation for Log Aggregation and log retrieval.,Retrieving logs in 0.23 is very different from what 0.20.* does. This is a very new feature which will require good documentation for users to get used to it. Lets make sure we have some solid documentation for this.,Open,Unresolved,,Vinod Kumar Vavilapalli,Mahadev konar,Fri; 27 Jan 2012 18:39:33 +0000,Sat; 7 Jan 2017 01:44:06 +0000,,,,,,HIVE-3313;MAPREDUCE-3143,https://issues.apache.org/jira/browse/YARN-432
MAPREDUCE-3744,Bug,Blocker,mrv2,"Unable to retrieve application logs via ""yarn logs"" or ""mapred job -logs""","Trying to retrieve application logs via the ""yarn logs"" shell command results in an error similar to this:  Exception in thread ""main""  checkAndGetHSProxy(257)) - Job History Server is not configured. Unable to get log information for job: job_1327694122989_0001  Even though the historyserver process is running.",Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 27 Jan 2012 20:31:19 +0000,Tue; 10 Mar 2015 04:32:41 +0000,Thu; 2 Feb 2012 01:45:30 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3744
MAPREDUCE-3745,Improvement,Major,,mapred/yarn scripts should use lib/'*' instead looping the dir for jar to create the classpath,The scripts do a for loop on the JAR contents of the directory; they should just use '' in the classpath; ie lib ''  This will reduce the length of the generated classpath significantly,Resolved,Not A Problem,,Unassigned,Alejandro Abdelnur,Fri; 27 Jan 2012 22:32:14 +0000,Tue; 10 Mar 2015 04:32:36 +0000,Thu; 8 Jan 2015 00:44:07 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3745
MAPREDUCE-3746,Bug,Critical,mrv2,Nodemanagers are not automatically shut down after decommissioning,Nodemanagers are not automatically shutdown after decommissioning. MAPREDUCE-2775 does not seem to fix the issue.,Resolved,Duplicate,MAPREDUCE-3862,Jason Lowe,Ramya Sunil,Fri; 27 Jan 2012 23:20:03 +0000,Sun; 19 Feb 2012 05:12:30 +0000,Sun; 19 Feb 2012 05:12:30 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3746
MAPREDUCE-3747,Bug,Major,mrv2,Memory Total is not refreshed until an app is launched,Memory Total on the RM UI is not refreshed until an application is launched. This is a problem when the cluster is started for the first time or when there are any lost decommissioned nodes; Memory Total has wrong value. This is a useful tool for cluster admins and has to be updated correctly without having the need to submit an app each time.,Closed,Fixed,,Arun C Murthy,Ramya Sunil,Sat; 28 Jan 2012 00:29:52 +0000,Mon; 5 Mar 2012 02:49:55 +0000,Mon; 6 Feb 2012 03:41:42 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3747
MAPREDUCE-3748,Bug,Minor,mrv2,Move CS related nodeUpdate log messages to DEBUG,Currently; the RM has nodeUpdate logs per NM per second such as the following: 2012-01-27 21:51:32;429 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: nodemanager1:port1 clusterResources: memory: 57344 2012-01-27 21:51:32;510 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: nodemanager2:port2 clusterResources: memory: 57344 2012-01-27 21:51:33;094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: nodemanager1:port1 clusterResources: memory: 57344  Debugging is difficult with huge amount of logs such as this. These logs need to be moved to DEBUG.,Closed,Fixed,,Ramya Sunil,Ramya Sunil,Sat; 28 Jan 2012 00:56:26 +0000,Mon; 5 Mar 2012 02:48:53 +0000,Tue; 31 Jan 2012 06:24:09 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3748
MAPREDUCE-3749,Bug,Blocker,mrv2,ConcurrentModificationException in counter groups,Iterating over a counter's groups while adding more groups will cause a ConcurrentModificationException.  This was found while running Hive unit tests against a recent 0.23 version.,Closed,Fixed,,Tom White,Tom White,Sat; 28 Jan 2012 01:25:15 +0000,Mon; 5 Mar 2012 02:49:14 +0000,Tue; 31 Jan 2012 18:34:24 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3749
MAPREDUCE-3750,Bug,Blocker,,ConcurrentModificationException in counter groups,Iterating over a counter's groups while adding more groups results in a ConcurrentModificationException. This was discovered while running Hive unit tests on a recent 0.23 version of Hadoop.,Resolved,Duplicate,MAPREDUCE-3749,Unassigned,Tom White,Sat; 28 Jan 2012 01:31:58 +0000,Sat; 28 Jan 2012 01:56:34 +0000,Sat; 28 Jan 2012 01:56:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3750
MAPREDUCE-3751,Improvement,Major,contrib/gridmix;mrv2,Simplify job submission in gridmix,"Currently gridmix tries to gauge cluster load etc. and throttles job submission. This makes it unpredictable and also is hard to support across MR1 and MR2.   I propose we simplify it to be:  	Replay mode - Just submit jobs in the interval as in the original trace. 	Stress mode - Compress the interval with a given factor for all jobs.",Open,Unresolved,,Unassigned,Arun C Murthy,Sat; 28 Jan 2012 03:06:24 +0000,Tue; 14 May 2013 04:33:34 +0000,,,0.23.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3751
MAPREDUCE-3752,Bug,Blocker,mrv2,Headroom should be capped by queue max-cap,Headroom should be capped by queue max-cap.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sat; 28 Jan 2012 03:16:41 +0000,Mon; 5 Mar 2012 02:49:41 +0000,Thu; 2 Feb 2012 00:42:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3752
MAPREDUCE-3753,Bug,Major,,Reduce output data is not written to disk,"I run into a critical issue with Hadoop 18.2 on my Linux boxes:  The jobs executes without any complains and they are listed in the succeeded list but there is no output data beside the ""_logs"" directory. The same code works with .17.2.1   Here are some sections of the logs:  logfile hadoop@bock:~ logfile  So what I see is that the system runs successful and it even says it writes data! (""Map-Reduce Framework.Reduce output records:12;File Systems.HDFS bytes written:1533"")  If I run the same code with .17.2.1 or in local mode with .18.2 it works and I get a part-0000 file with the expected data.   Please tell me if you need additional information.",Resolved,Incomplete,,Unassigned,Michael Fuchs,Tue; 20 Jan 2009 09:44:26 +0000,Mon; 21 Jul 2014 18:15:49 +0000,Mon; 21 Jul 2014 18:15:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3753
MAPREDUCE-3754,Bug,Major,mrv2;webapps,RM webapp should have pages filtered based on App-state,Helps a lot when we have lot of apps. Already having difficulties with gridmix with a single big list of apps of all states.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Sun; 29 Jan 2012 20:00:13 +0000,Mon; 5 Mar 2012 02:48:39 +0000,Wed; 1 Feb 2012 00:53:15 +0000,,0.23.0,,MAPREDUCE-3760,MAPREDUCE-3719,https://issues.apache.org/jira/browse/MAPREDUCE-3754
MAPREDUCE-3755,Sub-task,Major,jobhistoryserver;mrv2,Add the equivalent of JobStatus to end of JobHistory file ,In MR1 we have the notion of CompletedJobStatus store to aid fast responses to job.getStatus. We need the equivalent for MR2; an option is to add the jobStatus to the end of the JobHistory file to which the JHS can easily jump ahead to and serve the query; it should also cache this for a fair number of recently completed jobs.,Resolved,Won't Fix,,Bikas Saha,Arun C Murthy,Sun; 29 Jan 2012 23:12:12 +0000,Tue; 22 Apr 2014 17:06:36 +0000,Tue; 22 Apr 2014 17:06:36 +0000,,0.23.0,,,MAPREDUCE-4442,https://issues.apache.org/jira/browse/MAPREDUCE-3755
MAPREDUCE-3756,Improvement,Major,mrv2,Make single shuffle limit configurable,Make single shuffle limit configurable; currently it's hard-coded.,Closed,Fixed,,Hitesh Shah,Arun C Murthy,Mon; 30 Jan 2012 07:59:51 +0000,Mon; 5 Mar 2012 02:48:43 +0000,Tue; 31 Jan 2012 18:10:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3756
MAPREDUCE-3757,Bug,Major,tools/rumen,Rumen Folder is not adjusting the shuffleFinished and sortFinished times of reduce task attempts,Rumen Folder is not adjusting the shuffleFinished and sortFinished times of reduce task attempts when it is adjusting the attempt-start-time and attempt-finish-time. This is leading to wrong values which are greater than the attempt-finish-time in trace file.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Mon; 30 Jan 2012 10:07:39 +0000,Wed; 3 Sep 2014 22:45:04 +0000,Tue; 27 Mar 2012 10:42:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3757
MAPREDUCE-3758,Bug,Blocker,mrv2,NPE while submitting job through Oozie,NPE while submitting job through oozie.  Caused by:  212)         at,Resolved,Invalid,,John George,John George,Mon; 30 Jan 2012 14:37:05 +0000,Tue; 31 Jan 2012 21:26:09 +0000,Tue; 31 Jan 2012 20:23:43 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3758
MAPREDUCE-3759,Bug,Major,mrv2,ClassCastException thrown in -list-active-trackers when there are a few unhealthy nodes,"When there are a few blacklisted nodes in the cluster; ""bin mapred job -list-active-trackers"" throws "" lang.ClassCastException: org.apache.hadoop.yarn.server.resourcemanager.resource.Resources$1 cannot be cast to org.apache.hadoop.yarn.api.records.impl.pb.ResourcePBImpl""",Closed,Fixed,,Vinod Kumar Vavilapalli,Ramya Sunil,Mon; 30 Jan 2012 19:31:25 +0000,Mon; 5 Mar 2012 02:48:52 +0000,Sat; 4 Feb 2012 20:05:03 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3759
MAPREDUCE-3760,Bug,Major,mrv2,Blacklisted NMs should not appear in Active nodes list,"Blacklisted NMs appear in both ""Active Nodes"" and ""Unhealthy nodes"" on the RM UI. This should be fixed.",Closed,Fixed,,Vinod Kumar Vavilapalli,Ramya Sunil,Mon; 30 Jan 2012 20:12:23 +0000,Mon; 5 Mar 2012 02:48:42 +0000,Sat; 4 Feb 2012 01:05:36 +0000,,0.23.1,,MAPREDUCE-3754,,https://issues.apache.org/jira/browse/MAPREDUCE-3760
MAPREDUCE-3761,Improvement,Major,mrv2,AM info in job -list does not reflect the actual AM hostname,"The AM info field on ""bin appID. This info is irrelevant unless it shows the real information of where the AM was launched. This needs to be fixed to show the AM host details.",Resolved,Won't Fix,,Vinod Kumar Vavilapalli,Ramya Sunil,Mon; 30 Jan 2012 21:14:18 +0000,Tue; 10 Mar 2015 03:20:28 +0000,Tue; 10 Mar 2015 03:20:28 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3761
MAPREDUCE-3762,Bug,Critical,mrv2,Resource Manager fails to come up with default capacity scheduler configs.,Thanks to Hari Mankude for pointing out the issue. This is the stack trace for bringing up RM with default CS configs:,Closed,Fixed,,Mahadev konar,Mahadev konar,Mon; 30 Jan 2012 21:40:08 +0000,Mon; 5 Mar 2012 02:49:29 +0000,Wed; 1 Feb 2012 07:59:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3762
YARN-27,Bug,Major,,Failed refreshQueues due to misconfiguration prevents further refreshing of queues,"Stumbled upon this problem while refreshing queues with incorrect configuration. The exact scenario was: 1. Added a new queue ""newQueue"" without defining its capacity. 2. ""bin mapred queue -refreshQueues"" throws ""org.apache.hadoop.metrics2.MetricsException: Metrics source QueueMetrics;q0=root;q1=newQueue already exists!"" Also see Hadoop:name=QueueMetrics;q0=root;q1=newQueue;service=ResourceManager metrics being available even though the queue was not added.  The expected behavior would be to refresh the queues correctly and allow addition of ""newQueue"".",Closed,Fixed,,Arun C Murthy,Ramya Sunil,Mon; 30 Jan 2012 23:09:58 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Mon; 20 Aug 2012 16:44:11 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-27
MAPREDUCE-3764,Bug,Critical,mrv2,AllocatedGB etc metrics incorrect if min-allocation-mb isn't a multiple of 1GB,MutableGaugeInt incremented as allocatedGB.incr(res.getMemory()   GB * containers);  Setting yarn.scheduler.capacity.minimum-allocation-mb to 1536 - each increment is counted as 1GB. Trying to analyze the metrics - looks like the cluster is never over 67-68% utilized; depending on high ram requests.,Closed,Fixed,,Arun C Murthy,Siddharth Seth,Mon; 30 Jan 2012 23:21:35 +0000,Mon; 5 Mar 2012 02:48:44 +0000,Tue; 31 Jan 2012 08:31:34 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3764
MAPREDUCE-3765,Bug,Minor,mrv2,FifoScheduler does not respect yarn.scheduler.fifo.minimum-allocation-mb setting,FifoScheduler uses default min 1 GB regardless of the configuration value set for minimum memory allocation.,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Mon; 30 Jan 2012 23:32:51 +0000,Tue; 10 Mar 2015 04:32:00 +0000,Sat; 4 Feb 2012 22:51:50 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3765
MAPREDUCE-3766,Bug,Major,contrib/streaming,dumptb fails with filenotfound,dumptb can't find an existing file   antonio@ip-10-9-65-123:~$ hadoop jar  history,Resolved,Not A Problem,,Unassigned,Antonio Piccolboni,Tue; 31 Jan 2012 00:45:12 +0000,Tue; 31 Jan 2012 19:05:08 +0000,Tue; 31 Jan 2012 19:05:08 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3766
MAPREDUCE-3767,Bug,Major,,Fix and enable env tests in TestMiniMRChildTask,This test is ported to YARN+MR via MAPREDUCE-3716. We should try to enable the env tests also.,Resolved,Duplicate,MAPREDUCE-3854,Unassigned,Vinod Kumar Vavilapalli,Tue; 31 Jan 2012 02:26:54 +0000,Sat; 11 Feb 2012 01:04:18 +0000,Sat; 11 Feb 2012 01:04:18 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3767
MAPREDUCE-3768,Bug,Major,mrv2,MR-2450 introduced a significant performance regression (Hive),MAPREDUCE-2450 introduced; or at least triggers; a significant performance regression in Hive. With MR-2450 the execution time of TestCliDriver.skewjoin goes from 2 minutes to 15 minutes. Reverting this change from the build fixes the issue.  Here's the relevant query:     You can reproduce this by running the following from Hive 8.0 against Hadoop built from branch-23.,Open,Unresolved,,Unassigned,Eli Collins,Tue; 31 Jan 2012 03:50:48 +0000,Wed; 18 Apr 2012 20:27:51 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3768
MAPREDUCE-3769,Improvement,Minor,contrib/gridmix,[Gridmix] Improve the way job monitor maintains running jobs,Gridmix maintains a list (L) of running jobs via JobMonitor. As soon as a job is submitted; a handle for that job is cached inside the JobMonitor. The JobMonitor does the following in a thread:    Gridmix STRESS mode logic uses the list L to compute the cluster load. It iterates over map reduce progress of each and every job in L to figure out the pending+running task count. We need to investigate and optimize the JobMonitor algorithm and make sure that the total number of completed jobs in L is minimum. The overhead of polling for the map and reduce task progress of a completed job is pretty high as it incurs an additional (RPC) step of contacting the JobHistory server.,Open,Unresolved,,Unassigned,Amar Kamat,Tue; 31 Jan 2012 05:22:51 +0000,Thu; 12 May 2016 18:23:14 +0000,,,3.0.0-alpha1,gridmix;job-monitor,,MAPREDUCE-1687;MAPREDUCE-3481;MAPREDUCE-3787,https://issues.apache.org/jira/browse/MAPREDUCE-3769
MAPREDUCE-3770,Bug,Critical,tools/rumen,[Rumen] Zombie.getJobConf() results into NPE,The error trace is as follows    The bug seems to be in ZombieJob#getName() where a not-null check for jobName.getValue() is missing.,Closed,Fixed,MAPREDUCE-3797,Amar Kamat,Amar Kamat,Tue; 31 Jan 2012 06:54:50 +0000,Tue; 10 Mar 2015 04:31:43 +0000,Wed; 8 Feb 2012 11:12:43 +0000,,0.23.0;2.0.0-alpha,job-name;rumen,MAPREDUCE-3719,,https://issues.apache.org/jira/browse/MAPREDUCE-3770
MAPREDUCE-3771,Improvement,Major,,Port MAPREDUCE-1735 to trunk/0.23,Per discussion in general@; we should port MAPREDUCE-1735 to 0.23  trunk to 'undeprecate' old mapred api: http: undeprecate-mapred-apis,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Tue; 31 Jan 2012 08:20:22 +0000,Mon; 5 Mar 2012 02:49:39 +0000,Thu; 2 Feb 2012 08:39:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3771
MAPREDUCE-3772,Bug,Major,client,MultipleOutputs output lost if baseOutputPath starts with ../,"Lets say you have output directory set:  FileOutputFormat.setOutputPath(job; "" =13333 (* this using full path works *)                 list1=6667",Resolved,Invalid,,Harsh J,Radim Kolar,Tue; 31 Jan 2012 12:48:09 +0000,Tue; 1 Jan 2013 10:42:44 +0000,Tue; 1 Jan 2013 10:42:44 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3772
MAPREDUCE-3773,New Feature,Major,jobtracker,Add queue metrics with buckets for job run times,It would be nice to have queue metrics that reflect the number of jobs in each queue that have been running for different ranges of time.  Reasonable time ranges are probably 0-1 hr; 1-5 hr; 5-24 hr; 24+ hrs; but they should be configurable.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Tue; 31 Jan 2012 18:27:14 +0000,Mon; 22 Oct 2012 18:47:14 +0000,Fri; 9 Mar 2012 23:37:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3773
MAPREDUCE-3774,Bug,Major,mrv2,yarn-default.xml should be moved to hadoop-yarn-common.,yarn-default.xml right now resides in hadoop-yarn-server-common jars which is not the right thing to do since this jar might not be needed in some cases when depending upon yarn. We should move it to hadoop-yarn-common which is a required dependency for all the yarn components (client server).,Closed,Fixed,,Mahadev konar,Mahadev konar,Tue; 31 Jan 2012 21:30:06 +0000,Mon; 5 Mar 2012 02:49:04 +0000,Wed; 1 Feb 2012 19:57:04 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3774
MAPREDUCE-3775,Bug,Minor,mrv2,Change MiniYarnCluster to escape special chars in testname,"When using MiniYarnCluster with the testname set to a nested classname; the ""$"" within the class name creates issues with the container launch scripts as they try to expand the $... within the paths variables in use.",Closed,Fixed,,Hitesh Shah,Hitesh Shah,Tue; 31 Jan 2012 22:27:04 +0000,Tue; 10 Mar 2015 04:32:10 +0000,Sat; 4 Feb 2012 20:21:59 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3775
MAPREDUCE-3776,Bug,Major,mrv2,org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator fails intermittently,org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator fails intermittently,Open,Unresolved,,Unassigned,Robert Joseph Evans,Tue; 31 Jan 2012 22:59:51 +0000,Tue; 10 Mar 2015 04:32:09 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3776
MAPREDUCE-3777,Bug,Major,mrv2,used mem and util have negative values after a queue addition,After a queue addition to capacity scheduler and submission of an application; root queue utilization and used memory have negative values.,Resolved,Fixed,,Arun C Murthy,Ramya Sunil,Wed; 1 Feb 2012 00:41:51 +0000,Mon; 9 Mar 2015 21:56:47 +0000,Mon; 9 Mar 2015 21:56:47 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3777
YARN-411,Bug,Major,,Per-state RM app-pages should have search ala JHS pages,nan,Resolved,Duplicate,NULL,Unassigned,Vinod Kumar Vavilapalli,Wed; 1 Feb 2012 00:54:27 +0000,Thu; 21 Feb 2013 17:42:49 +0000,Thu; 21 Feb 2013 17:42:27 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-411
MAPREDUCE-3779,Improvement,Minor,jobtracker;tasktracker,Create hard and soft limits for job counters,The mapreduce.job.counters.limit is not overridable at the job level.  While it is necessary to limit the number of counters to reduce overhead; there are times when exceeding the limit is required.  Currently; the only solution is to increase the limit cluster wide.  I would like to see a soft limit set in the mapred-site.xml that can be overridden at the job level; in addition to the hard limit that exists today.,Resolved,Won't Fix,,Unassigned,Dave Shine,Wed; 1 Feb 2012 18:19:17 +0000,Sun; 17 Mar 2013 06:18:34 +0000,Tue; 12 Mar 2013 19:58:23 +0000,,0.23.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3779
MAPREDUCE-3780,Bug,Blocker,mrv2,RM assigns containers to killed applications,RM attempts to assign containers to killed applications. The applications were killed when they were inactive and waiting for AM allocation.,Closed,Fixed,,Hitesh Shah,Ramya Sunil,Wed; 1 Feb 2012 19:47:16 +0000,Mon; 5 Mar 2012 02:48:38 +0000,Thu; 2 Feb 2012 02:33:22 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3780
MAPREDUCE-3781,Bug,Major,mrv2,Fix history for apps which were terminated before the AM launch,Currently the history for applications which were terminated failed before the AM was launched redirects to a page that does not exist.,Resolved,Incomplete,,Unassigned,Ramya Sunil,Wed; 1 Feb 2012 20:05:25 +0000,Mon; 9 Mar 2015 21:57:30 +0000,Mon; 9 Mar 2015 21:57:30 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3781
MAPREDUCE-3782,Bug,Critical,mrv2,teragen terasort jobs fail when using webhdfs:// ,When running a teragen job with a webhdfs:  url the delegation token that is retrieved is an hdfs delegation token.   And the subsequent terasort job on the output fails with  io exception,Closed,Fixed,,Jason Lowe,Arpit Gupta,Wed; 1 Feb 2012 20:46:19 +0000,Tue; 10 Mar 2015 04:32:28 +0000,Thu; 9 Aug 2012 17:42:29 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3782
MAPREDUCE-3783,Bug,Minor,mrv2,"Fix ""queue -list"" to display the correct capacity of queues","Occasionally; the capacity of the queue as displayed by ""queue -list"" has incorrect values.  For e.g: yarn.scheduler.capacity.root.queues=a;b yarn.scheduler.capacity.root.b.queues=b1;b2;b3 yarn.scheduler.capacity.root.b.b1.capacity=30 yarn.scheduler.capacity.root.b.b2.capacity=30 yarn.scheduler.capacity.root.b.b3.capacity=40  $ mapred queue -list Queue Name : b Queue State : running Scheduling Info : Capacity: 40.0; MaximumCapacity: 1.0; CurrentCapacity: 0.0     ======================     Queue Name : b1     Queue State : running     Scheduling Info : Capacity: 30.000002; MaximumCapacity: 1.0; CurrentCapacity: 0.0     ======================     Queue Name : b2     Queue State : running     Scheduling Info : Capacity: 30.000002; MaximumCapacity: 1.0; CurrentCapacity: 0.0 ...",Open,Unresolved,,Unassigned,Ramya Sunil,Wed; 1 Feb 2012 21:30:47 +0000,Thu; 29 Nov 2012 20:58:29 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3783
MAPREDUCE-3784,Bug,Major,mrv2,maxActiveApplications(|PerUser) per queue is too low for small clusters,We ran into this issue while testing on small clusters.  On a 7node cluster with 8G per node;  for a queue with absolute capacity 30%; user limit 100%; maxActiveApplications and maxActiveApplicationsPerUser is calculated to be 1. This means that even though the queue has 17GB(0.3*8*7); only 1 user can run 1 app at a given time queuing up rest of the apps users. This hurts performance on small clusters.,Closed,Fixed,,Arun C Murthy,Ramya Sunil,Wed; 1 Feb 2012 22:46:52 +0000,Mon; 5 Mar 2012 02:49:14 +0000,Fri; 3 Feb 2012 01:18:47 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3784
HDFS-2878,Bug,Blocker,test,TestBlockRecovery does not compile,Looks like HDFS-2563 introduced a compilation error in TestBlockRecovery. We didn't catch this because of HDFS-2876.,Closed,Fixed,,Todd Lipcon,Eli Collins,Wed; 1 Feb 2012 23:59:19 +0000,Mon; 28 Sep 2015 20:58:47 +0000,Sat; 11 Feb 2012 01:21:28 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/HDFS-2878
MAPREDUCE-3786,Bug,Minor,mrv2,No checks for misconfigured userlimit,Currently; there are no checks being made for misconfigured userLimit (such as negative values values 100) This can potentially be a problem if the RM comes up with incorrect userLimit values.,Open,Unresolved,,Unassigned,Ramya Sunil,Thu; 2 Feb 2012 01:03:48 +0000,Thu; 2 Feb 2012 01:03:48 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3786
MAPREDUCE-3787,Improvement,Major,contrib/gridmix,[Gridmix] Improve STRESS mode,Gridmix STRESS mode can be improved as follows: 1. The sleep time in JobMonitor can be reduced and or made configurable 2. Map and reduce load calculation in StressJobFactory can be done in one loop 3. Updating the overload status from the job submitter thread (inline) 4. Optimizations to avoid un-necessary progress check (which inturn would result into delay),Closed,Fixed,,Amar Kamat,Amar Kamat,Thu; 2 Feb 2012 06:23:12 +0000,Tue; 10 Mar 2015 04:32:47 +0000,Thu; 23 Feb 2012 11:05:16 +0000,,2.0.0-alpha,gridmix;stress,,MAPREDUCE-3769,https://issues.apache.org/jira/browse/MAPREDUCE-3787
MAPREDUCE-3788,Improvement,Major,contrib/gridmix,[Gridmix] Investigate if Gridmix can be made YARN aware,Gridmix was written keeping in mind the monolithic JobTracker. Calls to the single JobTracker were throttled to avoid excess load. Also; polling was faster in JobTracker as the job statuses were cached even if the job was complete. In the YARN world; the situation is slightly different. To make Gridmix scalable and really a YARN scale-benchmarking tool; Gridmix should be enhanced. Some directions worth investigating are: 1. Investigate if Gridmix can cache the AM handles and poll the AM directly for map reduce task progress.  2. Can the job monitor be made multi-threaded? Each thread can poll a bunch of AMs. 3. Check if there are better ways for getting job progress updates and get away with the busy-waiting logic in Gridmix. 4. Can Gridmix be made container aware. The definition of cluster load should be container aware.,Open,Unresolved,,Unassigned,Amar Kamat,Thu; 2 Feb 2012 06:36:30 +0000,Thu; 12 May 2016 18:24:08 +0000,,,3.0.0-alpha1,gridmix;yarn,,,https://issues.apache.org/jira/browse/MAPREDUCE-3788
MAPREDUCE-3789,Bug,Critical,capacity-sched;scheduler,CapacityTaskScheduler may perform unnecessary reservations in heterogenous tracker environments,"Briefly; to reproduce:   	Run JT with CapacityTaskScheduler Say; Cluster max map = 8G; Cluster map = 2G 	Run two TTs but with varied capacity; say; one with 4 map slot; another with 3 map slots. 	Run a job with two tasks; each demanding mem worth 4 slots at least (Map mem = 7G or so). 	Job will begin running on TT #1; but will also end up reserving the 3 slots on TT #2 cause it does not check for the maximum limit of slots when reserving (as it goes greedy; and hopes to gain more slots in future). 	Other jobs that could've run on the TT #2 over 3 slots are thereby blocked out due to this illogical reservation.    I've not yet tested MR2 for this so feel free to weigh in if it affects MR2 as well.  For MR1; I've attached a test case initially to indicate this. A fix that checks reservations vs. max slots; to follow.",Closed,Fixed,,Harsh J,Harsh J,Thu; 2 Feb 2012 10:07:47 +0000,Wed; 17 Oct 2012 18:27:24 +0000,Fri; 10 Feb 2012 23:32:32 +0000,,1.1.0,,,MAPREDUCE-516,https://issues.apache.org/jira/browse/MAPREDUCE-3789
MAPREDUCE-3790,Bug,Major,contrib/streaming;mrv2,Broken pipe on streaming job can lead to truncated output for a successful job,If a streaming job doesn't consume all of its input then the job can be marked successful even though the job's output is truncated.  Here's a simple setup th behavior:,Resolved,Fixed,,Jason Lowe,Jason Lowe,Thu; 2 Feb 2012 18:04:23 +0000,Wed; 12 Apr 2017 19:57:48 +0000,Tue; 28 Feb 2012 17:47:17 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3790
MAPREDUCE-3791,Bug,Major,documentation;mrv2,can't build site in hadoop-yarn-server-common,Here's how to reproduce:,Closed,Fixed,,Mahadev konar,Roman Shaposhnik,Thu; 2 Feb 2012 18:34:14 +0000,Mon; 5 Mar 2012 02:48:47 +0000,Sat; 4 Feb 2012 18:45:40 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3791
MAPREDUCE-3792,Bug,Critical,mrv2,job -list displays only the jobs submitted by a particular user,mapred job -list lists only the jobs submitted by the user who ran the command. This behavior is different from 1.x.,Resolved,Fixed,,Jason Lowe,Ramya Sunil,Thu; 2 Feb 2012 21:42:51 +0000,Sun; 4 Mar 2012 13:57:53 +0000,Sat; 3 Mar 2012 23:45:16 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3792
YARN-104,Improvement,Major,client,Add a yarn kill command ,There currently is a mapreduce kill command to kill a single mapreduce job; but in order to better administer a grid it would be nice to be able to kill a misbehaving application no matter what AM it is running.,Resolved,Duplicate,YARN-40,Unassigned,Robert Joseph Evans,Thu; 2 Feb 2012 21:43:19 +0000,Thu; 13 Sep 2012 01:56:09 +0000,Thu; 13 Sep 2012 01:56:09 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-104
MAPREDUCE-3794,Bug,Major,mrv2,Support mapred.Task.Counter and mapred.JobInProgress.Counter enums for compatibility,The new counters are mapreduce.TaskCounter and mapreduce.JobCounter; but we should support the old ones too since they are public in Hadoop 1.x.,Closed,Fixed,,Tom White,Tom White,Thu; 2 Feb 2012 22:47:00 +0000,Mon; 5 Mar 2012 02:49:23 +0000,Tue; 7 Feb 2012 00:56:12 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3794
MAPREDUCE-3795,Bug,Major,mrv2,job -status command line output is malformed,Misses new lines after numMaps and numReduces. Caused by MAPREDUCE-3720.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 2 Feb 2012 23:49:19 +0000,Mon; 5 Mar 2012 02:49:19 +0000,Sat; 4 Feb 2012 19:36:34 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3795
YARN-193,Bug,Major,resourcemanager,Scheduler.normalizeRequest does not account for allocation requests that exceed maximumAllocation limits ,nan,Closed,Fixed,MAPREDUCE-3946;YARN-407,Zhijie Shen,Hitesh Shah,Fri; 3 Feb 2012 01:57:04 +0000,Thu; 12 May 2016 18:30:05 +0000,Sat; 6 Apr 2013 22:38:28 +0000,,2.0.2-alpha;3.0.0-alpha1,,,YARN-382,https://issues.apache.org/jira/browse/YARN-193
MAPREDUCE-3797,Bug,Major,contrib/gridmix;tools/rumen,lGridMix fails to Run with NPE with latest branch-0.23 code,GridMix fails to start trowing NPE after gendata,Resolved,Duplicate,MAPREDUCE-3770,Unassigned,Karam Singh,Fri; 3 Feb 2012 15:20:45 +0000,Sat; 4 Feb 2012 00:41:41 +0000,Sat; 4 Feb 2012 00:41:18 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3797
MAPREDUCE-3798,Test,Major,test,TestJobCleanup testCustomCleanup is failing,"File somepath _custom_cleanup missing for job job_20120203035807432_0009 	at org.apache.hadoop.mapred.TestJobCleanup.testKilledJob(TestJobCleanup. 27)",Resolved,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 3 Feb 2012 16:34:01 +0000,Wed; 22 Feb 2012 13:57:25 +0000,Tue; 21 Feb 2012 05:32:02 +0000,,0.23.0;0.23.1,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3798
MAPREDUCE-3799,Test,Major,test,TestServiceLevelAuthorization testServiceLevelAuthorization failing,"Error Message  Expected file distcache not found  Stacktrace  junit.framework.AssertionFailedError: Expected file distcache not found 	at org.apache.hadoop.mapred.TestMiniMRWithDFS.verifyContents(TestMiniMRWithDFS. 95)",Resolved,Cannot Reproduce,,Unassigned,Ravi Prakash,Fri; 3 Feb 2012 16:50:15 +0000,Mon; 13 Feb 2012 16:13:39 +0000,Mon; 13 Feb 2012 16:13:39 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3799
MAPREDUCE-3800,Test,Major,test,TestHarFileSystem testRelativeArchives,"Error Message failed test Stacktrace junit.framework.AssertionFailedError: failed test 	at org.apache.hadoop.tools.TestHarFileSystem.testRelativeArchives(TestHarFileSystem. 227)",Resolved,Cannot Reproduce,,Unassigned,Ravi Prakash,Fri; 3 Feb 2012 16:54:00 +0000,Mon; 13 Feb 2012 16:14:50 +0000,Mon; 13 Feb 2012 16:14:50 +0000,,0.23.0,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-3800
MAPREDUCE-3801,Bug,Major,mrv2,org.apache.hadoop.mapreduce.v2.app.TestRuntimeEstimators.testExponentialEstimator fails intermittently,org.apache.hadoop.mapreduce.v2.app.TestRuntimeEstimators;testExponentialEstimator fails intermittently,Open,Unresolved,,Unassigned,Robert Joseph Evans,Fri; 3 Feb 2012 17:19:02 +0000,Tue; 10 Mar 2015 04:32:04 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3801
MAPREDUCE-3802,Sub-task,Critical,applicationmaster;mrv2,If an MR AM dies twice  it looks like the process freezes,It looks like recovering from an RM AM dieing works very well on a single failure.  But if it fails multiple times we appear to get into a live lock situation.,Closed,Fixed,,Vinod Kumar Vavilapalli,Robert Joseph Evans,Fri; 3 Feb 2012 21:15:11 +0000,Tue; 10 Mar 2015 04:32:20 +0000,Tue; 14 Feb 2012 19:29:52 +0000,,0.23.1;2.0.0-alpha,,MAPREDUCE-3846,MAPREDUCE-3846,https://issues.apache.org/jira/browse/MAPREDUCE-3802
MAPREDUCE-3803,Test,Major,build,HDFS-2864 broke ant compilation,compile:      echo contrib: raid       2 errors  BUILD FAILED,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 3 Feb 2012 20:46:43 +0000,Tue; 10 Mar 2015 04:32:19 +0000,Sat; 4 Feb 2012 02:35:32 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3803
MAPREDUCE-3804,Bug,Major,jobhistoryserver;mrv2;resourcemanager,yarn webapp interface vulnerable to cross scripting attacks,Yarn webapp interface may be vulnerable to certain cross scripting attacks; injected through URL request.,Closed,Fixed,,Dave Thompson,Dave Thompson,Fri; 3 Feb 2012 21:34:56 +0000,Mon; 5 Mar 2012 02:49:54 +0000,Mon; 6 Feb 2012 22:42:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3804
MAPREDUCE-3805,Bug,Major,mr-am;mrv2,MR AM not respecting MaxReduceRampUpLimit,While running GridMixV3 with high memory reduces; we ran into issues where for jobs with significant number of maps and reduces; when the map progress hits 98-99% but still there are maps pending; reduces get every new container that RM allocates. And the job takes much longer time than with usual reduces.  For addressing precisely these issues; a configurable limit was introduced to limit the reduce ramp up. Unfortunately this limit is not working correctly.,Open,Unresolved,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 3 Feb 2012 23:51:55 +0000,Mon; 9 Mar 2015 21:58:41 +0000,,,0.23.0,,,MAPREDUCE-3719,https://issues.apache.org/jira/browse/MAPREDUCE-3805
MAPREDUCE-3806,Bug,Major,contrib/gridmix,[Gridmix] TestGridmixSubmission fails due to incorrect version of jackson,TestGridmixSubmission fails with the following error,Resolved,Cannot Reproduce,,Unassigned,Amar Kamat,Sat; 4 Feb 2012 03:14:53 +0000,Thu; 12 May 2016 18:22:32 +0000,Mon; 9 Mar 2015 20:38:22 +0000,,3.0.0-alpha1,error;gridmix;junit,,,https://issues.apache.org/jira/browse/MAPREDUCE-3806
MAPREDUCE-3807,Bug,Major,,JobTracker needs fix similar to HDFS-94,1.0 JobTracker's jobtracker.jsp page currently shows:     It could use an improvement same as HDFS-94 to reflect live heap usage more accurately.,Patch Available,Unresolved,,Unassigned,Harsh J,Sat; 4 Feb 2012 06:52:17 +0000,Wed; 6 May 2015 03:32:01 +0000,,,1.0.0,BB2015-05-TBR;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-3807
MAPREDUCE-3808,Bug,Blocker,mrv2,NPE in FileOutputCommitter when running a 0 reduce job,This was while running LoadGen.,Closed,Fixed,MAPREDUCE-3821,Robert Joseph Evans,Siddharth Seth,Sat; 4 Feb 2012 19:51:24 +0000,Tue; 10 Mar 2015 04:32:26 +0000,Mon; 6 Feb 2012 22:17:26 +0000,,0.23.0;2.0.0-alpha,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3808
MAPREDUCE-3809,Sub-task,Blocker,mrv2,Tasks may take upto 3 seconds to exit after completion,Task.TaskReporter.stopCommunicationThread can end up waiting for a thread.sleep(3000) before stopping the thread.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sun; 5 Feb 2012 20:20:47 +0000,Mon; 5 Mar 2012 02:48:58 +0000,Tue; 7 Feb 2012 00:14:59 +0000,,0.23.1;1.0.0,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3809
MAPREDUCE-3810,Sub-task,Blocker,mrv2;performance,MR AM's ContainerAllocator is assigning the allocated containers very slowly,This is mostly due to logging and other not-so-cheap operations we are doing as part of the AM-RM heartbeat cycle.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Sun; 5 Feb 2012 21:20:00 +0000,Mon; 5 Mar 2012 02:49:31 +0000,Mon; 6 Feb 2012 22:08:02 +0000,,0.23.0,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3810
MAPREDUCE-3811,Task,Critical,mrv2,Make the Client-AM IPC retry count configurable,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Sun; 5 Feb 2012 21:42:42 +0000,Fri; 8 Nov 2013 18:16:09 +0000,Tue; 7 Feb 2012 00:22:00 +0000,,0.23.0,,,MAPREDUCE-5616,https://issues.apache.org/jira/browse/MAPREDUCE-3811
MAPREDUCE-3812,Sub-task,Major,mrv2;performance,Lower default allocation sizes; fix allocation configurations and document them,"After a few performance improvements tracked at MAPREDUCE-3561; like MAPREDUCE-3511 and MAPREDUCE-3567; even a 100K maps job can also run within 1GB vmem. We earlier increased AM slot size from 1 slot to two slots to work around the issues with AM heap. Now that those are fixed; we should go back to 1GB.  This is just a configuration change.  P.s.:  	Currently min max alloc configs aren't documented and we ought to document it (i.e. MAPREDUCE-4027) 	1 GB is perhaps too high for a slot's minimum. While job defaults can be left at such values; we should lower the minimum alloc to 128 MB to allow special requests of low memory out of the box itself. Shouldn't impact MR App in any way.",Closed,Fixed,MAPREDUCE-4026;MAPREDUCE-4027,Harsh J,Vinod Kumar Vavilapalli,Sun; 5 Feb 2012 22:42:58 +0000,Fri; 7 Sep 2012 21:03:34 +0000,Mon; 23 Apr 2012 18:11:09 +0000,,0.23.0,,,MAPREDUCE-3719,https://issues.apache.org/jira/browse/MAPREDUCE-3812
MAPREDUCE-3813,Sub-task,Major,mrv2;performance,RackResolver should maintain a cache to avoid repetitive lookups.,With the current code; during task creation; we repeatedly resolve hosts and RackResolver doesn't cache any of the results. Caching will improve performance.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Sun; 5 Feb 2012 22:53:38 +0000,Mon; 5 Mar 2012 02:49:21 +0000,Mon; 6 Feb 2012 22:08:23 +0000,,0.23.0,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3813
MAPREDUCE-3814,Bug,Major,mrv1;mrv2,MR1 compile fails,"$ ant veryclean all-jars -Dversion=0.23.1 -Dresolvers=internal   BUILD FAILED  testjar"" does not exist!",Closed,Fixed,,Arun C Murthy,Arun C Murthy,Mon; 6 Feb 2012 03:43:41 +0000,Mon; 5 Mar 2012 02:49:51 +0000,Mon; 6 Feb 2012 21:05:29 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3814
MAPREDUCE-3815,Sub-task,Critical,mrv2,Data Locality suffers if the AM asks for containers using IPs instead of hostnames,BlockLocation.getHosts() returns IP addresses occasionally. Data locality is affected - since the RM requires hostnames.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Mon; 6 Feb 2012 04:20:21 +0000,Mon; 5 Mar 2012 02:49:21 +0000,Tue; 7 Feb 2012 22:00:01 +0000,,0.23.0,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3815
MAPREDUCE-3816,Bug,Critical,mrv2,capacity scheduler web ui bar graphs for used capacity wrong,The capacity scheduler web ui has bar graphs showing the capacity max capacity for each queue. The used capacity it is showing is actually the % of its parents queue it is using; which doesn't make sense on the bar graphs when compared to the capacity and max capacity of that particular queue.  The bar graphs should be using utilization so that the user can see that its using x% or the y% allocated to that queue.  I will attach some screen shots showing the issue.,Resolved,Fixed,,Thomas Graves,Thomas Graves,Mon; 6 Feb 2012 15:18:06 +0000,Wed; 29 Feb 2012 13:57:20 +0000,Tue; 28 Feb 2012 20:15:17 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3816
MAPREDUCE-3817,Bug,Major,mrv2,bin/mapred command cannot run distcp and archive jobs,nan,Closed,Fixed,,Arpit Gupta,Arpit Gupta,Mon; 6 Feb 2012 18:06:03 +0000,Tue; 10 Mar 2015 04:31:38 +0000,Tue; 7 Feb 2012 01:50:37 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3817
MAPREDUCE-3818,Bug,Blocker,build;test,Trunk MRV1 compilation is broken.,Seeing this:,Closed,Fixed,,Suresh Srinivas,Vinod Kumar Vavilapalli,Mon; 6 Feb 2012 19:40:51 +0000,Tue; 10 Mar 2015 04:31:45 +0000,Mon; 6 Feb 2012 23:17:15 +0000,,2.0.0-alpha,,,HDFS-2895,https://issues.apache.org/jira/browse/MAPREDUCE-3818
HDFS-3012,Bug,Critical,,Exception while renewing delegation token,nan,Resolved,Fixed,,Robert Joseph Evans,Ramya Sunil,Mon; 6 Feb 2012 20:27:00 +0000,Wed; 23 Sep 2015 20:39:08 +0000,Wed; 29 Feb 2012 22:11:08 +0000,,0.23.1,,,HDFS-8053,https://issues.apache.org/jira/browse/HDFS-3012
MAPREDUCE-3820,Bug,Minor,mrv2,Improve logging when containers run beyond memory limits,"When containers run beyond memory limits; they are killed without logging any useful message. Diagnostics message reads ""Task attemptID failed 0 times"" and the console output reads ""INFO mapreduce.Job: Job jobID failed with state KILLED due to:"" which are both not useful. This message has to be improved.",Open,Unresolved,,Unassigned,Ramya Sunil,Mon; 6 Feb 2012 20:33:32 +0000,Tue; 2 Jun 2015 20:07:26 +0000,,,0.23.1,,,YARN-522,https://issues.apache.org/jira/browse/MAPREDUCE-3820
MAPREDUCE-3821,Bug,Critical,mrv2,NPE while running Shuffle benchmark,hadoop jar hadoop-mapreduce-test.jar loadgen -outKey org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text The tasks fail with the following exception:,Resolved,Duplicate,MAPREDUCE-3808,Unassigned,Ramya Sunil,Mon; 6 Feb 2012 20:49:54 +0000,Mon; 6 Feb 2012 20:53:05 +0000,Mon; 6 Feb 2012 20:53:05 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3821
MAPREDUCE-3822,Bug,Critical,mrv2,TestJobCounters is failing intermittently on trunk and 0.23.,TestJobCounters fails sometimes on trunk. I have tracked it down to stats issue in FileSystem. Still working on it.,Closed,Fixed,,Mahadev konar,Mahadev konar,Mon; 6 Feb 2012 21:07:45 +0000,Mon; 5 Mar 2012 02:49:32 +0000,Wed; 8 Feb 2012 00:58:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3822
MAPREDUCE-3823,Sub-task,Major,mrv2;performance,Counters are getting calculated twice at job-finish and delaying clients.,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Mon; 6 Feb 2012 22:30:48 +0000,Mon; 5 Mar 2012 02:49:53 +0000,Tue; 7 Feb 2012 23:14:16 +0000,,0.23.0,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3823
MAPREDUCE-3824,Bug,Critical,distributed-cache,Distributed caches are not removed properly,Distributed caches are not being properly removed by the TaskTracker when they are expected to be expired.,Closed,Fixed,,Thomas Graves,Allen Wittenauer,Mon; 6 Feb 2012 22:49:48 +0000,Thu; 5 Apr 2012 18:42:08 +0000,Sun; 19 Feb 2012 23:42:27 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3824
MAPREDUCE-3825,Bug,Major,security,MR should not be getting duplicate tokens for a MR Job.,This is the counterpart to HADOOP-7967.   MR gets tokens for all input; output and the default filesystem when a MR job is submitted.   The APIs in FileSystem make it challenging to avoid duplicate tokens when there are file systems that have embedded filesystems.   Here is the original description that Daryn wrote:  The token cache currently tries to assume a filesystem's token service key.  The assumption generally worked while there was a one to one mapping of filesystem to token.  With the advent of multi-token filesystems like viewfs; the token cache will try to use a service key (ie. for viewfs) that will never exist (because it really gets the mounted fs tokens).  The descriop,Resolved,Duplicate,HADOOP-7967,Daryn Sharp,Daryn Sharp,Mon; 6 Feb 2012 23:23:12 +0000,Tue; 10 Mar 2015 04:31:55 +0000,Wed; 16 Apr 2014 22:04:19 +0000,,0.23.1;2.0.0-alpha,,HADOOP-7967,HDFS-2854;HADOOP-8048;MAPREDUCE-3849;MAPREDUCE-3850,https://issues.apache.org/jira/browse/MAPREDUCE-3825
MAPREDUCE-3826,Bug,Major,mrv2,RM UI when loaded throws a message stating Data Tables warning and then the column sorting stops working,nan,Closed,Fixed,,Jonathan Eagles,Arpit Gupta,Mon; 6 Feb 2012 23:30:01 +0000,Mon; 5 Mar 2012 02:49:41 +0000,Tue; 7 Feb 2012 23:01:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3826
MAPREDUCE-3827,Sub-task,Blocker,mrv2;performance,Counters aggregation slowed down significantly after MAPREDUCE-3749,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 7 Feb 2012 01:55:53 +0000,Mon; 5 Mar 2012 02:49:23 +0000,Wed; 8 Feb 2012 00:17:48 +0000,,0.23.0,,MAPREDUCE-3524,,https://issues.apache.org/jira/browse/MAPREDUCE-3827
MAPREDUCE-3828,Bug,Major,mrv2,Broken urls: AM tracking url and jobhistory url in a single node setup.,If the user doesn't explicitly set the yarn.resourcemanager.address conf property; in a single node setup; and tries to connect to the web UI from a remote machine; then all links (AM tracking url and jobhistory url) in the Web UI are broken (pointing to IP address 0.0.0.0).,Closed,Fixed,,Siddharth Seth,Ahmed Radwan,Tue; 7 Feb 2012 02:56:27 +0000,Mon; 5 Mar 2012 02:49:13 +0000,Wed; 8 Feb 2012 07:14:22 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3828
MAPREDUCE-3829,Bug,Major,contrib/gridmix,[Gridmix] Gridmix should give better error message when input-data directory already exists and -generate option is given,Instead of throwing exception messages on to the console; Gridmix should give better error message when input-data directory already exists and -generate option is given.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Tue; 7 Feb 2012 08:00:48 +0000,Wed; 3 Sep 2014 22:45:04 +0000,Fri; 16 Mar 2012 06:31:59 +0000,,,,,MAPREDUCE-2006,https://issues.apache.org/jira/browse/MAPREDUCE-3829
MAPREDUCE-3830,Improvement,Major,,DBOutputFormat can't support the update operation to DB,After checking the DBOutputFormat class file and found it can't support the update operation to DB; It only support the insert operation.  why it can't provide the update operation? Is it an improvement action?,Open,Unresolved,,Unassigned,xsuyu,Tue; 7 Feb 2012 10:23:14 +0000,Tue; 7 May 2013 08:55:52 +0000,,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3830
MAPREDUCE-3831,Sub-task,Major,benchmarks;mrv2;resourcemanager,RM scalability runtime is worse than 0.20.204 by 14.2%,RM scalability runtime is worse than 0.20.204 by 14.2%  Overall runtime against 0.20.204 in a 350 nodes cluster is 2155 secs. Overall runtime against .23 in 350 nodes cluster is 2462 secs.,Resolved,Fixed,,Unassigned,Vinay Kumar Thota,Tue; 7 Feb 2012 12:32:07 +0000,Thu; 16 Feb 2012 21:27:56 +0000,Thu; 16 Feb 2012 21:27:56 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3831
MAPREDUCE-3832,Bug,Major,mrv2,mapred Counters API should not extend mapreduce Counters API,The mapred (old) Counters API extends the mapreduce (new) Counters API; this effectively makes the old Counters API dependent on the new Counters API. This may affect stability and backwards forward compatibility in the old Counters API.  The new API should not pop up as dependency in the old API. Instead it should only be used in the implementation when necessary.,Open,Unresolved,,Unassigned,Alejandro Abdelnur,Tue; 7 Feb 2012 17:44:06 +0000,Tue; 21 Feb 2012 01:16:15 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3832
MAPREDUCE-3833,Bug,Major,mrv2,Capacity scheduler queue refresh doesn't recompute queue capacities properly,Refreshing the capacity scheduler configuration (e.g.: via yarn rmadmin -refreshQueues) can fail to compute the proper absolute capacity for leaf queues.,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 7 Feb 2012 19:20:59 +0000,Tue; 10 Mar 2015 04:32:19 +0000,Tue; 7 Feb 2012 22:10:17 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3833
MAPREDUCE-3834,Bug,Critical,mr-am;mrv2,If multiple hosts for a split belong to the same rack; the rack is added multiple times in the AM request table,Should be added only once - so that the RM doesn't think there's multiple rack local requests for that particular rack.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 7 Feb 2012 19:47:59 +0000,Mon; 5 Mar 2012 02:49:06 +0000,Wed; 8 Feb 2012 01:57:16 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3834
MAPREDUCE-3835,Bug,Minor,mrv2,RM capacity scheduler web UI doesn't show active users,On the jobtracker; the web ui showed the active users for each queue and how much resources each of those users were using. That currently isn't being displayed on the RM capacity scheduler web ui.,Resolved,Duplicate,YARN-249,Unassigned,Thomas Graves,Tue; 7 Feb 2012 21:49:39 +0000,Tue; 4 Dec 2012 17:07:48 +0000,Tue; 4 Dec 2012 17:07:48 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3835
MAPREDUCE-3836,Bug,Major,mrv2;test,TestContainersMonitor failing intermittently,See https:  for an example failure.,Resolved,Duplicate,MAPREDUCE-3583,Unassigned,Vinod Kumar Vavilapalli,Tue; 7 Feb 2012 22:04:24 +0000,Mon; 20 Feb 2012 04:10:22 +0000,Mon; 20 Feb 2012 04:10:21 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3836
MAPREDUCE-3837,New Feature,Major,,Job tracker is not able to recover job in case of crash and after that no user can submit job.,If job tracker is crashed while running ; and there were some jobs are running ; so if job tracker's property mapreduce.jobtracker.restart.recover is true then it should recover the job.  However the current behavior is as follows jobtracker try to restore the jobs but it can not . And after that jobtracker closes its handle to hdfs and nobody else can submit job.   Thanks; Mayank,Closed,Fixed,,Mayank Bansal,Mayank Bansal,Tue; 7 Feb 2012 23:39:32 +0000,Mon; 10 Feb 2014 07:04:44 +0000,Wed; 11 Jul 2012 16:05:07 +0000,,0.22.0;1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3837
MAPREDUCE-3838,Sub-task,Major,client,MapReduce job submission time has increased in 0.23 when compared to 0.20.206,While running Gridmix on 0.23; we found that the job submission time has increased when compared to 0.20.206.   Here are some stats:     Note that Gridmix was run using the same trace.,Open,Unresolved,,Unassigned,Amar Kamat,Wed; 8 Feb 2012 04:47:32 +0000,Sat; 7 Jan 2017 01:59:56 +0000,,,0.23.0,gridmix;job-submit-time;yarn,,,https://issues.apache.org/jira/browse/MAPREDUCE-3838
MAPREDUCE-3839,Improvement,Trivial,documentation,Improve the single node setup docs for MR,"I'm gonna be recording all nits I can about the page at http: SingleCluster.html#Setting_up_Configuration. one of the ""Add the following configs"" text is defined as a heading; while other isn't. 	The ""Create Symlinks"" and ""Running daemons"" sections do not appear in the index on top. 	Remove the ""Good luck."" at the end  Users shouldn't need luck to setup good stuff     OT comment: The ""Create Symlinks"" part is curious. That we need symlinks to run MR looks very wrong to me.",Resolved,Duplicate,HADOOP-10139,Unassigned,Harsh J,Wed; 8 Feb 2012 14:18:11 +0000,Fri; 31 Jan 2014 05:30:59 +0000,Fri; 31 Jan 2014 04:52:07 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3839
MAPREDUCE-3840,Bug,Blocker,mrv2,JobEndNotifier doesn't use the proxyToUse during connecting,I stupidly removed the proxyToUse from openConnection() in MAPREDUCE-3649.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 8 Feb 2012 15:55:58 +0000,Tue; 10 Mar 2015 04:32:38 +0000,Thu; 9 Feb 2012 18:30:00 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3840
MAPREDUCE-3841,Bug,Major,mrv2,Broken Server metrics and Local logs link under the tools menu,Local logs link redirects to the cluster page and Server metrics opens an empty page on the RM JHS homepage. So does the links from nodemanager UI.,Resolved,Duplicate,YARN-981,Jian He,Ramya Sunil,Wed; 8 Feb 2012 19:39:56 +0000,Tue; 27 Aug 2013 23:46:23 +0000,Tue; 27 Aug 2013 23:46:23 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3841
MAPREDUCE-3842,Improvement,Critical,mrv2;webapps,stop webpages from automatic refreshing,The automatic refresh makes quiet hard to look at something specific as it makes the page jump and sometime resets its position.   This is specially painful when looking at jobs with large number of tasks.,Closed,Fixed,,Thomas Graves,Alejandro Abdelnur,Wed; 8 Feb 2012 22:54:02 +0000,Thu; 11 Oct 2012 17:48:45 +0000,Fri; 8 Jun 2012 15:52:56 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3842
MAPREDUCE-3843,Bug,Critical,jobhistoryserver;mrv2,Job summary log file found missing on the RM host,This bug was found by Phil Su as part of our testing.  After MAPREDUCE-3354 went in; the Job summary log file seems to have gone missing on the RM host.  The job summary log appears to be interspersed in yarn-mapredqa-historyserver-host.out.  e.g.    INFO jobhistory.JobSummary: jobId=job_1328658619341_0011;submitTime=1328802904381;launchTime=1328802909977;firstMapTaskLaunchTime=1328802912116;firstReduceTaskLaunchTime=1328802915074;finishTime=1328802933797;resourc esPerMap=1024;resourcesPerReduce=2048;numMaps=10;numReduces=10;user=hadoopqa;queue=default;status=KILLED;mapSlotSeconds=0;reduceSlotSeconds=0  1) On the RM with older hadoop version where the job summary log does not exist mapredqa 10903  0.0  1.2 1424404 210240 ?      Sl   Feb07   0:19  * org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer  1) On the RM with older hadoop version where the job summary log does not exist jobhistory ps shows using the option: -Dmapred.jobsummary.logger=INFO;console   2) On the RM with older hadoop version where the job summary log exists jobhistory ps shows using the option: -Dmapred.jobsummary.logger=INFO;JSA  -Dmapred.jobsummary.logger=INFO;JSA,Closed,Fixed,,Anupam Seth,Anupam Seth,Thu; 9 Feb 2012 20:45:49 +0000,Mon; 5 Mar 2012 02:49:47 +0000,Fri; 10 Feb 2012 23:31:50 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3843
MAPREDUCE-3844,Bug,Blocker,mrv2,Problem in setting the childTmpDir in MapReduceChildJVM,"We have seen this issue during a Hive test. Where Hive tries to create a temp file using File.createTempFile(..) and it throws:     Because it literally sees ""$PWD tmp"" as the temp directory path.  $PWD need to be evaluated before being used in setting the property "" ",Resolved,Duplicate,MAPREDUCE-3716,Ahmed Radwan,Ahmed Radwan,Thu; 9 Feb 2012 22:39:08 +0000,Fri; 10 Feb 2012 23:10:28 +0000,Fri; 10 Feb 2012 23:10:07 +0000,,0.23.0;0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3844
MAPREDUCE-3845,Bug,Major,distcp,hadoop distcp fails to run with java.lang.NoClassDefFoundError,Here's how to reproduce:,Resolved,Duplicate,HADOOP-7999,Roman Shaposhnik,Roman Shaposhnik,Thu; 9 Feb 2012 22:50:59 +0000,Fri; 10 Feb 2012 02:24:49 +0000,Fri; 10 Feb 2012 02:24:49 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3845
MAPREDUCE-3846,Sub-task,Critical,mrv2,Restarted+Recovered AM hangs in some corner cases,Karam Singh found this while testing AM restart recovery feature. After the first generation AM crashes (manually killed by kill -9); the second generation AM starts; but hangs after a while.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 9 Feb 2012 22:51:29 +0000,Mon; 5 Mar 2012 02:49:24 +0000,Tue; 14 Feb 2012 00:14:01 +0000,,0.23.0,,MAPREDUCE-3802,MAPREDUCE-3802;MAPREDUCE-3634,https://issues.apache.org/jira/browse/MAPREDUCE-3846
MAPREDUCE-3847,Bug,Major,jobtracker;tasktracker,Job in running state without any progress and no tasks running,Hi All;  TestDFSIO program running with write option ; number of files is 250 and file size is 256 MB (block size is also 256 MB)  NN went to safemode so JT was trying to connect to NN continuously..  later NN switched and it became proper..  Then JT is trying to kill some taskattempts and it's not able to do so as the task is not in TaskInProgress state at TT side  Also TaskTracker didnt respond before 10mins to it was declared lost marking all the tasks on that.  Has someone faced similar issue?  I couldnt reproduce this problem again.  Anyone can give any directions?  Thanks in advance.  Regards; Abhijit,Resolved,Cannot Reproduce,,Unassigned,Abhijit Suresh Shingate,Fri; 10 Feb 2012 04:51:58 +0000,Fri; 8 May 2015 11:48:49 +0000,Fri; 8 May 2015 11:48:49 +0000,,0.20.1;0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3847
MAPREDUCE-3848,Improvement,Minor,mrv2,RM to issue slots on a specific machine to users with admin rights,"The RM offers slots closest to the hosts that the AM ask for; based on which machine nearby has space.  If you are using YARN to deploy admin-like applications (e.g. connectivity tests); you really do need to deploy on a specific machine; even if that machine has no free slots.  It would be useful to have an option to say ""always allocate on this machine if it is live""; and give access to that machine to admin users; even if there are no free slots on the server for normal jobs.",Open,Unresolved,,Unassigned,Steve Loughran,Fri; 10 Feb 2012 11:39:50 +0000,Tue; 10 Mar 2015 04:32:22 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3848
MAPREDUCE-3849,Improvement,Major,security,Change TokenCache's reading of the binary token file,"When obtaining the tokens for a FileSystem; the TokenCache will read the binary token file if a token is not already in the Credentials.  However; it will overwrite any existing tokens in the Credentials with the contents of the binary token file if a single token is missing.  This may cause new tokens to be replaced with invalid cancelled tokens from the binary file.  The new tokens will not be canceled; and thus ""leak"" in the namenode until they expire.  The binary tokens should be merged with; but not replace; existing tokens in the Credentials.  The code that reads the binary token file is prefaced with:    Also; the loading of the binary token file is the only reason that the TokenCache has to use getCanonicalService.  If this linkage can be broken; then the 1-to-1 filesystem to token service coupling may be removed.  And use of getCanonicalService can be removed in a subsequent jira.",Resolved,Fixed,,Daryn Sharp,Daryn Sharp,Fri; 10 Feb 2012 18:55:07 +0000,Tue; 10 Mar 2015 04:32:32 +0000,Thu; 16 Feb 2012 17:57:50 +0000,,0.23.1;2.0.0-alpha,,,MAPREDUCE-3825,https://issues.apache.org/jira/browse/MAPREDUCE-3849
MAPREDUCE-3850,Improvement,Major,security,Avoid redundant calls for tokens in TokenCache,The TokenCache will repeatedly call the same filesystem for tokens.  This is inefficient and can easily be changed to only call each filesystem once.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Fri; 10 Feb 2012 19:12:21 +0000,Tue; 10 Mar 2015 04:32:43 +0000,Tue; 8 May 2012 15:28:24 +0000,,0.23.1;2.0.0-alpha,,,MAPREDUCE-3825,https://issues.apache.org/jira/browse/MAPREDUCE-3850
MAPREDUCE-3851,Bug,Major,tasktracker,Allow more aggressive action on detection of the jetty issue,MAPREDUCE-2529 added the useful failure detection mechanism. In this jira; I propose we add a periodic check inside TT and configurable action to self-destruct. Blacklisting helps but is not enough. Hung jetty still accepts connection and it takes very long time for clients to fail out. Short jobs are delayed for hours because of this. This feature will be a nice companion to MAPREDUCE-3184.,Closed,Fixed,,Thomas Graves,Kihwal Lee,Fri; 10 Feb 2012 22:16:18 +0000,Fri; 31 Aug 2012 13:20:07 +0000,Sun; 18 Mar 2012 03:27:53 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3851
MAPREDUCE-3852,Bug,Blocker,mrv2,test TestLinuxResourceCalculatorPlugin failing,tests are failing: org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.testParsingProcStatAndCpuFile org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.testParsingProcMemFile   https: MEMINFO_238849741 (No such file or directory),Resolved,Fixed,MAPREDUCE-3853,Thomas Graves,Thomas Graves,Fri; 10 Feb 2012 22:33:03 +0000,Tue; 10 Mar 2015 04:32:40 +0000,Mon; 13 Feb 2012 05:43:22 +0000,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3852
MAPREDUCE-3853,Bug,Major,mrv2,TestLinuxResourceCalculatorPlugin is failing on trunk and 0.23 branch.,Looks like the test is failing: https: console,Resolved,Duplicate,MAPREDUCE-3852,Unassigned,Mahadev konar,Fri; 10 Feb 2012 23:07:35 +0000,Fri; 10 Feb 2012 23:13:24 +0000,Fri; 10 Feb 2012 23:13:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3853
MAPREDUCE-3854,Test,Major,mrv2,Reinstate environment variable tests in TestMiniMRChildTask,MAPREDUCE-3716 reinstated one of the tests in TestMiniMRChildTask; but there are two more which should be run.,Closed,Fixed,MAPREDUCE-3767,Tom White,Tom White,Sat; 11 Feb 2012 00:07:02 +0000,Mon; 5 Mar 2012 02:49:52 +0000,Tue; 14 Feb 2012 21:45:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3854
MAPREDUCE-3855,Bug,Minor,mrv1;test,TestSubmitJob should use FileSystem instead of private HDFS classes.,TestSubmitJob uses ClientNamenodeProtocolTranslatorPB which is marked InterfaceAudience.Private. This causes build failures in mapreduce when HDFS changes internal private classes. Test should be changed to use FileSystem.,Resolved,Duplicate,MAPREDUCE-3974,Uma Maheswara Rao G,Suresh Srinivas,Sat; 11 Feb 2012 20:53:21 +0000,Tue; 10 Mar 2015 04:32:10 +0000,Tue; 6 Mar 2012 02:05:14 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3855
MAPREDUCE-3856,Bug,Critical,mrv2,Instances of RunningJob class givs incorrect job tracking urls when mutiple jobs are submitted from same client jvm.,When multiple jobs are submitted from the same client JVM; each call to RunningJob.getTrackingURL() always returns the tracking URL from the first job.  This happens even if the jobs are submitted and the client waits for the job to complete before submitting the subsequent job. Each job runs fine and is definitely a new; unique job; but the call to getTrackingURL() still returns the URL for the first job.,Closed,Fixed,,Eric Payne,Eric Payne,Mon; 13 Feb 2012 16:33:26 +0000,Mon; 5 Mar 2012 02:49:33 +0000,Fri; 17 Feb 2012 01:03:41 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3856
MAPREDUCE-3857,Bug,Major,examples,Grep example ignores mapred.job.queue.name,Grep example creates two jobs as part of its implementation. The first job correctly uses the configuration settings. The second job ignores configuration settings.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 13 Feb 2012 22:15:08 +0000,Wed; 16 May 2012 20:45:16 +0000,Mon; 7 May 2012 06:00:22 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3857
MAPREDUCE-3858,Bug,Critical,mrv2,Task attempt failure during commit results in task never completing,On a terasort job a task attempt failed during the commit phase. Another attempt was rescheduled; but when it tried to commit it failed.     The job hung as new attempts kept getting scheduled only to fail during commit.,Closed,Fixed,,Tom White,Tom White,Tue; 14 Feb 2012 01:21:24 +0000,Fri; 17 May 2013 21:02:20 +0000,Tue; 14 Feb 2012 22:55:36 +0000,,,,,MAPREDUCE-5255,https://issues.apache.org/jira/browse/MAPREDUCE-3858
MAPREDUCE-3859,Bug,Major,capacity-sched,CapacityScheduler incorrectly utilizes extra-resources of queue for high-memory jobs,Imagine; we have a queue A with capacity 10 slots and 20 as extra-capacity; jobs which use 3 map slots will never consume more than 9 slots; regardless how many free slots on a cluster.,Closed,Fixed,,Sergey Tryuber,Sergey Tryuber,Tue; 14 Feb 2012 09:03:39 +0000,Fri; 11 Oct 2013 17:18:55 +0000,Mon; 3 Jun 2013 01:04:56 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3859
MAPREDUCE-3860,Bug,Major,tools/rumen,[Rumen] Bring back the removed Rumen unit tests,MAPREDUCE-3582 did not move some of the Rumen unit tests to the new folder and then MAPREDUCE-3705 deleted those unit tests. These Rumen unit tests need to be brought back: TestZombieJob. TestConcurrentRead.java,Open,Unresolved,HADOOP-9219,Andrey Klochkov,Ravi Gummadi,Wed; 15 Feb 2012 10:23:20 +0000,Fri; 11 Apr 2014 16:10:37 +0000,,,,,,MAPREDUCE-3705;MAPREDUCE-3582,https://issues.apache.org/jira/browse/MAPREDUCE-3860
MAPREDUCE-3861,Bug,Blocker,mrv2,Oozie job status couldn't be updated correctly after Pig job SUCCEEDED from hadoop.,Submit an Oozie job having Pig action; the job is SUCCEEDED from hadoop and the output file is generated on HDFS; but oozie status is KILLED.  Marcy Chen reported this issue while testing a pig job through oozie.,Resolved,Invalid,,John George,John George,Wed; 15 Feb 2012 14:40:48 +0000,Wed; 15 Feb 2012 19:25:51 +0000,Wed; 15 Feb 2012 19:25:51 +0000,,0.23.1;0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3861
MAPREDUCE-3862,Bug,Major,mrv2;nodemanager,Nodemanager can appear to hang on shutdown due to lingering DeletionService threads,When a nodemanager attempts to shutdown cleanly; it's possible for it to appear to hang due to lingering DeletionService threads.  This can occur when yarn.nodemanager.delete.debug-delay-sec is set to a relatively large value and one or more containers executes on the node shortly before the shutdown.  The DeletionService is never calling setExecuteExistingDelayedTasksAfterShutdownPolicy() on the ScheduledThreadPoolExecutor; and it defaults to waiting for all scheduled tasks to complete before exiting.,Resolved,Fixed,MAPREDUCE-3746,Jason Lowe,Jason Lowe,Wed; 15 Feb 2012 17:31:16 +0000,Tue; 21 Feb 2012 19:19:09 +0000,Fri; 17 Feb 2012 23:01:47 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3862
MAPREDUCE-3863,Bug,Critical,build,0.22 branch mvn deploy is not publishing hadoop-streaming JAR,Without this JAR Oozie cannot be built tested against 0.22,Resolved,Fixed,,Benoy Antony,Alejandro Abdelnur,Wed; 15 Feb 2012 18:19:09 +0000,Thu; 3 May 2012 14:07:27 +0000,Wed; 25 Apr 2012 06:14:18 +0000,,0.22.0;0.22.1,,OOZIE-672,,https://issues.apache.org/jira/browse/MAPREDUCE-3863
MAPREDUCE-3864,Improvement,Minor,documentation;security,Fix cluster setup docs for correct SNN HTTPS parameters,Currently the docs reference dfs.namenode.secondary.https-address; which does not exist. Instead it should reference dfs.namenode.secondary.https-port (new name of dfs.secondary.https.port as of HDFS-2950),Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 15 Feb 2012 18:26:55 +0000,Wed; 28 Mar 2012 09:12:17 +0000,Thu; 16 Feb 2012 05:54:22 +0000,,0.23.1,,,HDFS-2950,https://issues.apache.org/jira/browse/MAPREDUCE-3864
YARN-69,Sub-task,Major,resourcemanager,RM should throw different exceptions for while querying app/node/queue,We should distinguish the exceptions for absent app queue etc. Today everything is a YarnRemoteException. We should extend YarnRemoteException to add NotFoundException; AccessControlException etc. Today; AccessControlException exists but not as part of the protocol descriptions (i.e. only available to Java).,Open,Unresolved,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 15 Feb 2012 22:51:27 +0000,Fri; 5 Jul 2013 08:43:25 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-69
MAPREDUCE-3866,Bug,Minor,mrv2,bin/yarn prints the command line unnecessarily,For commands like rmadmin; version etc; it also prints the whole command line unnecessarily.  This was  me from long time ago; pre alpha,Resolved,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 15 Feb 2012 23:02:53 +0000,Sat; 25 Feb 2012 13:57:46 +0000,Fri; 24 Feb 2012 21:29:45 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3866
MAPREDUCE-3867,Bug,Major,test,MiniMRYarn/MiniYarn uses fixed ports,This presents issues if there are other processes using those ports. Also; if multitasking among dev environments using Mini* things start to fail.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 16 Feb 2012 00:38:41 +0000,Tue; 10 Mar 2015 04:32:20 +0000,Thu; 19 Apr 2012 20:35:11 +0000,,0.23.2;2.0.0-alpha,,,YARN-144,https://issues.apache.org/jira/browse/MAPREDUCE-3867
MAPREDUCE-3868,Bug,Major,contrib/raid,Reenable Raid,Currently Raid is outdated and not compiled. Make it compile.,Resolved,Won't Fix,,Weiyan Wang,Scott Chen,Thu; 16 Feb 2012 00:44:43 +0000,Sun; 26 Apr 2015 01:29:12 +0000,Sun; 26 Apr 2015 01:29:12 +0000,,,,,HDFS-3648;MAPREDUCE-4266,https://issues.apache.org/jira/browse/MAPREDUCE-3868
MAPREDUCE-3869,Bug,Blocker,mrv2,Distributed shell application fails with NoClassDefFoundError,Distributed shell application always fails to start the application master with the following error.,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 16 Feb 2012 09:14:22 +0000,Wed; 14 Nov 2012 00:07:45 +0000,Tue; 10 Apr 2012 00:03:24 +0000,,0.23.1,,,YARN-144,https://issues.apache.org/jira/browse/MAPREDUCE-3869
MAPREDUCE-3870,Bug,Major,mrv2,Invalid App Metrics,I have observed incorrect Apps Completed and Apps Pending metrics when an application has failed or finished (successful) after multiple attempts(failures).,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Thu; 16 Feb 2012 14:35:09 +0000,Thu; 12 May 2016 18:23:37 +0000,Mon; 21 May 2012 20:07:22 +0000,,0.23.2;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3870
MAPREDUCE-3871,Improvement,Major,distributed-cache,Allow symlinking in LocalJobRunner DistributedCache,Currently the LocalJobRunner doesn't create symlinks for files in the DistributedCache. It is safe to create symlinks if files of the same name don't exist. LocalJobRunner should also delete the symlinks when the job has completed.,Closed,Fixed,,Tom White,Tom White,Thu; 16 Feb 2012 19:57:11 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Mon; 11 Jun 2012 20:40:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3871
MAPREDUCE-3872,Bug,Major,client;mrv2,event handling races in ContainerLauncherImpl and TestContainerLauncher,TestContainerLauncher is failing intermittently for me.     Patch momentarily.,Closed,Fixed,MAPREDUCE-5080,Robert Kanter,Patrick Hunt,Thu; 16 Feb 2012 23:19:37 +0000,Tue; 27 Aug 2013 22:22:01 +0000,Thu; 21 Mar 2013 21:57:51 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3872
MAPREDUCE-3873,Bug,Minor,mrv2;nodemanager,Nodemanager is not getting decommisioned if the absolute ip is given in exclude file.,"Configure absolute ip in ""yarn.resourcemanager.nodes.exclude-path"" and try to decommission the node. It is not getting decommisioned.But if the hostname is given; decommissioning is happening.  I have also given the ip-host mapping of each machine in  hosts.(i;e in every machine the other machines ip-host mapping is specified).",Closed,Fixed,,xieguiming,Nishan Shetty,Fri; 17 Feb 2012 11:02:07 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Tue; 5 Jun 2012 23:57:09 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3873
MAPREDUCE-3874,Bug,Major,mrv1;nodemanager,Decommission nodes link is not working,Decommisioned node link  is not displaying the nodes that got decommissioned,Resolved,Duplicate,MAPREDUCE-2775,Unassigned,Nishan Shetty,Fri; 17 Feb 2012 11:39:46 +0000,Tue; 21 Feb 2012 05:14:03 +0000,Tue; 21 Feb 2012 05:13:40 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3874
HDFS-2984,Bug,Critical,benchmarks,S-live: Rate operation count for delete is worse than 0.20.204 by 28.8%,Rate operation count for delete is worse than 0.20.204.xx by 28.8%,Resolved,Cannot Reproduce,,Ravi Prakash,Vinay Kumar Thota,Fri; 17 Feb 2012 11:42:57 +0000,Thu; 15 Aug 2013 19:01:46 +0000,Thu; 15 Aug 2013 19:01:46 +0000,,0.23.1,,,HDFS-708,https://issues.apache.org/jira/browse/HDFS-2984
MAPREDUCE-3876,Bug,Major,test,vertica query; sql command not properly ended,When running a test script; we're getting a  249),Patch Available,Unresolved,,Unassigned,Joseph Doss,Fri; 17 Feb 2012 17:09:02 +0000,Wed; 6 May 2015 03:31:02 +0000,,,1.0.0,BB2015-05-TBR;hadoop;newbie;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3876
MAPREDUCE-3877,Test,Minor,mrv2,Add a test to formalise the current state transitions of the yarn lifecycle,Add a test service that counts the number of times it's state methods are called; and can be set to raise an exception on any such entry. Use it to show what the current lifecycle state model is; so that unintentional regressions can be detected.   It will also act as a foundation for intentional changes to that lifecycle,Resolved,Fixed,,Steve Loughran,Steve Loughran,Fri; 17 Feb 2012 17:39:46 +0000,Wed; 28 Mar 2012 09:11:58 +0000,Sat; 18 Feb 2012 13:26:42 +0000,,,,,YARN-117,https://issues.apache.org/jira/browse/MAPREDUCE-3877
MAPREDUCE-3878,Bug,Critical,mrv2,Null user on filtered jobhistory job page,If jobhistory job.* is filtered to bypass acl; resulting page will always show Null user. This differs from 0.20 where filtering on this page; bypasses security to allow all access to the page. essentially passes a null user to AppController where an exception is thrown. If a null user is detected; we should acl checking is disabled on this page.,Resolved,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 17 Feb 2012 22:15:41 +0000,Fri; 24 Feb 2012 13:57:44 +0000,Thu; 23 Feb 2012 15:58:13 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3878
MAPREDUCE-3879,Bug,Major,mrv2;nodemanager,yarn script has vestiges of jsvc that need to be cleaned up,If nodemanager is started under root (I know; I know). The following is displayed:     The culprit is this bit of code that looks suspiciously like what used to be in bin hdfs in support of jsvc launch:,Resolved,Duplicate,MAPREDUCE-3578,Roman Shaposhnik,Roman Shaposhnik,Sat; 18 Feb 2012 00:27:05 +0000,Fri; 30 Mar 2012 10:16:30 +0000,Fri; 30 Mar 2012 10:16:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3879
MAPREDUCE-3880,Bug,Blocker,build;mrv2,Allow for 32-bit container-executor,Currently we can't pass in -m32 to LCE build.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sat; 18 Feb 2012 06:02:10 +0000,Mon; 5 Mar 2012 02:49:12 +0000,Sat; 18 Feb 2012 06:40:05 +0000,,0.23.0,,,MAPREDUCE-3922,https://issues.apache.org/jira/browse/MAPREDUCE-3880
MAPREDUCE-3881,Bug,Minor,build,building fail under Windows,"hadoop-mapreduce-project pom.xml)             configuration               target                 mkdir dir=""${project.build.directory} execution",Resolved,Not A Problem,,Unassigned,Changming Sun,Sat; 18 Feb 2012 08:32:55 +0000,Mon; 11 May 2015 08:47:28 +0000,Mon; 11 May 2015 08:46:54 +0000,,,,,MAPREDUCE-3540,https://issues.apache.org/jira/browse/MAPREDUCE-3881
MAPREDUCE-3882,Improvement,Minor,,fix some compile warnings of hadoop-mapreduce-examples,fix some compile warnings of hadoop-mapreduce-examples,Patch Available,Unresolved,,Unassigned,Changming Sun,Sat; 18 Feb 2012 12:24:13 +0000,Thu; 25 Jun 2015 11:29:09 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3882
MAPREDUCE-3883,Improvement,Minor,documentation;mrv2,Document yarn.nodemanager.delete.debug-delay-sec configuration property,If you are using Yarn's nodemanager; you can add to your configuration:     to save the environmental directories of the applications (by default in  yarn-default.xml).,Closed,Fixed,,Eugene Koontz,Eugene Koontz,Mon; 20 Feb 2012 22:44:29 +0000,Tue; 10 Mar 2015 04:30:35 +0000,Mon; 30 Apr 2012 13:44:46 +0000,,,newbie,,MAPREDUCE-4276,https://issues.apache.org/jira/browse/MAPREDUCE-3883
MAPREDUCE-3884,Bug,Critical,mrv2,PWD should be first in the classpath of MR tasks,Currently the current directory is not part of the classpath; this is a regression from MR1 and existing applications assuming this fail to work properly.,Resolved,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 21 Feb 2012 02:19:40 +0000,Thu; 23 Feb 2012 13:55:32 +0000,Wed; 22 Feb 2012 18:03:53 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3884
MAPREDUCE-3885,Improvement,Major,mrv2,Apply the fix similar to HADOOP-8084,Apply the fix similar to HADOOP-8084,Closed,Fixed,,Devaraj Das,Devaraj Das,Tue; 21 Feb 2012 05:36:08 +0000,Tue; 10 Mar 2015 04:31:39 +0000,Thu; 1 Mar 2012 00:58:22 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3885
MAPREDUCE-3886,Improvement,Major,mrv2,add shutdown hook to shutdown a service; services to invoke,Currently the services (and their examples) don't handle KILL signals; because they don't register a shutdown hook. This means that they can't be shut down cleanly from a console without executing the service-specific commands.  Fix: add a class that takes a weak ref to a service and which registers a shutdown hook to call Service.stop on that service; catches and ignores any exceptions in the process.   The abstract service should create an register a service on service start (unless told not to); and unregister it on service stop(). This would automatically give all services the desired behaviour.   Composite services may not need this; it may be best to make registration an option that subclasses explicitly invoke in their service start methods; so only the key services get this feature.   coding: straightforward testing: manual only; kill processes by hand and look at the logs,Open,Unresolved,,Unassigned,Steve Loughran,Tue; 21 Feb 2012 12:30:39 +0000,Tue; 10 Mar 2015 04:31:50 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3886
MAPREDUCE-3887,Bug,Major,build,Jenkins mapred commit build tries an unknown target,I saw the following in the mrv1 ant build portion of Hadoop-Mapreduce-trunk-Commit. The 0.23 build might have the same thing.,Resolved,Fixed,,Unassigned,Kihwal Lee,Tue; 21 Feb 2012 15:11:48 +0000,Mon; 9 Mar 2015 22:00:37 +0000,Mon; 9 Mar 2015 22:00:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3887
YARN-71,Bug,Critical,nodemanager,Ensure/confirm that the NodeManager cleans up local-dirs on restart,We have to make sure that NodeManagers cleanup their local files on restart.  It may already be working like that in which case we should have tests validating this.,Closed,Fixed,YARN-70,Xuan Gong,Vinod Kumar Vavilapalli,Tue; 21 Feb 2012 19:18:47 +0000,Wed; 8 Apr 2015 23:03:27 +0000,Mon; 25 Mar 2013 18:27:03 +0000,,,,YARN-72,YARN-194;YARN-438;YARN-73;YARN-661,https://issues.apache.org/jira/browse/YARN-71
MAPREDUCE-3889,Bug,Critical,mrv2,job client tries to use /tasklog interface; but that doesn't exist anymore,if you specify  -Dmapreduce.client.output.filter=SUCCEEDED option when running a job it tries to fetch task logs to print out on the client side from a url like: http: tasklog?plaintext=trueattemptid=attempt_1329857083014_0003_r_000000_0filter=stdout  It always errors on this request with: Required param job; map and reduce  We saw this error when using distcp and the distcp failed. I'm not sure if it is mandatory for distcp or just informational purposes.  I'm guessing the latter.,Closed,Fixed,,Devaraj K,Thomas Graves,Tue; 21 Feb 2012 21:37:22 +0000,Thu; 12 May 2016 18:23:13 +0000,Wed; 20 Jun 2012 21:43:16 +0000,,0.23.1;2.0.0-alpha;3.0.0-alpha1,,,MAPREDUCE-4218;MAPREDUCE-4294,https://issues.apache.org/jira/browse/MAPREDUCE-3889
MAPREDUCE-3890,Bug,Major,build;mrv2,Change to nodemanager build now requires 32-bit libraries,Sometime during the last week; someone committed a change to:  hadoop-mapreduce-project value   This breaks the build on 64-bit systems that do not have 32-bit libraries installed. The change was actually not required as 64-bit support for JNI and JVMs is readily available and installed by default on many 64-bit systems. Removing the flag results in a completed and functional build.  If mandating 32-bit builds is desired; then a better solution would be to provide a configure flag such as -DHADOOP_32bit_MODE; perhaps with a corresponding flag for 64-bit. Regardless; locking the system to 32-bit builds seems a tad extreme.,Resolved,Duplicate,MAPREDUCE-3922,Ralph H Castain,Ralph H Castain,Wed; 22 Feb 2012 01:19:14 +0000,Tue; 28 Feb 2012 03:36:35 +0000,Tue; 28 Feb 2012 02:44:54 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3890
YARN-72,Bug,Major,nodemanager,NM should handle cleaning up containers when it shuts down,Ideally; the NM should wait for a limited amount of time when it gets a shutdown signal for existing containers to complete and kill the containers ( if we pick an aggressive approach ) after this time interval.   For NMs which come up after an unclean shutdown; the NM should look through its directories for existing container.pids and try and kill an existing containers matching the pids found.,Closed,Fixed,YARN-74,Sandy Ryza,Hitesh Shah,Wed; 22 Feb 2012 02:10:43 +0000,Mon; 4 Aug 2014 22:22:50 +0000,Mon; 3 Dec 2012 12:14:16 +0000,,,,YARN-71,YARN-73;YARN-495,https://issues.apache.org/jira/browse/YARN-72
MAPREDUCE-3892,Bug,Major,mrv1,runningMapTasks counter is not decremented in case of failed task-cleanup tasks.,For a map-only job; a map task has two running tempt_1 will remain KILLED_UNCLEAN status. Whats' more runningMapTasks equals one instead of zero after the job is finished. The incorrect runningMapTasks value can lead to bad scheduling decisions with our scheduler.,Open,Unresolved,,Unassigned,Liyin Liang,Wed; 22 Feb 2012 10:10:36 +0000,Wed; 22 Feb 2012 12:27:17 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3892
MAPREDUCE-3893,Bug,Critical,mrv2,allow capacity scheduler configs maximum-applications and maximum-am-resource-percent configurable on a per queue basis,The capacity scheduler configs for  maximum-applications and maximum-am-resource-percent are currently configured globally and then made proportional to each queue based on its capacity. There are times when this may not work well.  some exampless -  if you have a queue that is running on uberAM jobs; the jobs a queue is running always has a small number of containers; and then you have the opposite where in a queue with very small capacity; you may want to limit the am resources even more so you don't end up deadlocked with all your capacity being used for app masters.  I think we should make those configurable on a per queue basis.,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 22 Feb 2012 14:16:11 +0000,Mon; 12 Nov 2012 20:32:58 +0000,Mon; 23 Jul 2012 19:36:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3893
MAPREDUCE-3894,Bug,Major,build,0.23 and trunk MR builds fail intermittently,The builds occasionally report ABORTED or FAILURE; which is not caused by the new code change included in the builds. We are not sure since when they have been broken this way; but Bobby's guess is around Feb 10.,Resolved,Fixed,,Unassigned,Kihwal Lee,Wed; 22 Feb 2012 16:02:53 +0000,Tue; 10 Mar 2015 04:32:27 +0000,Wed; 31 Jul 2013 19:37:31 +0000,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3894
MAPREDUCE-3895,Improvement,Major,jobtracker;performance,Speculative execution algorithm in 1.0 is too pessimistic in many cases,"We are seeing many instances where largish jobs are ending up with 30-50% of reduce tasks being speculatively re-executed. This can be a significant drain on cluster resources.   The primary reason is due to the way progress in the reduce phase can make huge jumps in a very short amount of time. This fact leads the speculative execution code to think lots of tasks have fallen way behind the average when in fact they haven't  The important piece of the algorithm is essentially:  	Am I more than 20% behind the average progress? 	Have I been running for at least a minute? 	Have any tasks completed yet?    Unfortunately; a set of reduce tasks which spend a couple of minutes in the Copy phase; and very little time in the Sort phase; will trigger all these conditions for a large percentage of the reduce tasks. (the tasks' progress jump from 33% to 66% almost instantly which then triggers the speculation). I've seen this on several very large jobs which spend about 2 minutes in Copy; a few seconds in Sort; and 40 minutes in Reduce. These jobs launch about 30-40% additional reduce tasks which then run for almost the full 40 minutes.   This area becomes more plugable in MRv2 but for 1.0 it would be good if some portion of this algorithm could be configurable so that a job could have some degree of control (just disabling speculative execution is not really an option).",Open,Unresolved,,Unassigned,Nathan Roberts,Wed; 22 Feb 2012 16:09:10 +0000,Wed; 22 Feb 2012 20:05:44 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3895
MAPREDUCE-3896,Bug,Blocker,jobhistoryserver;mrv2,pig job through oozie hangs ,running pig job on oozie hangs due to race condition,Resolved,Fixed,,Vinod Kumar Vavilapalli,John George,Wed; 22 Feb 2012 19:03:53 +0000,Sat; 3 Mar 2012 13:58:42 +0000,Fri; 2 Mar 2012 19:30:30 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3896
MAPREDUCE-3897,Bug,Critical,mrv2,capacity scheduler - maxActiveApplicationsPerUser calculation can be wrong,The capacity scheduler calculates the maxActiveApplications and the maxActiveApplicationsPerUser based on the config yarn.scheduler.capacity.maximum-applications or default 10000.    MaxActiveApplications = max ( ceil ( clusterMemory 100) * userLimitFactor); 1)   maxActiveApplications is already multiplied by the queue absolute MAXIMUM capacity; so if max capacity  capacity and if you have user limit factor 1 (which is the default) and only 1 user is running; that user will not be allowed to use over the queue capacity; so having it relative to MAX capacity doesn't make sense.  That user could easily end up in a deadlock and all its space used by application masters.,Resolved,Fixed,,Eric Payne,Thomas Graves,Wed; 22 Feb 2012 21:41:09 +0000,Mon; 5 Mar 2012 13:25:43 +0000,Sun; 4 Mar 2012 23:48:30 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3897
MAPREDUCE-3898,Improvement,Major,,Hadoop for Windows - Interfacing with Windows to manage MR tasks,nan,Resolved,Duplicate,HADOOP-8079,Unassigned,Sanjay Radia,Wed; 22 Feb 2012 22:33:52 +0000,Tue; 10 Mar 2015 04:32:18 +0000,Mon; 4 Jun 2012 17:58:36 +0000,,1.1.0;2.0.0-alpha,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3898
YARN-744,Bug,Minor,resourcemanager,Race condition in ApplicationMasterService.allocate .. It might process same allocate request twice resulting in additional containers getting allocated.,Looks like the lock taken in this is broken. It takes a lock on lastResponse object and then puts a new lastResponse object into the map. At this point a new thread entering this function will get a new lastResponse object and will be able to take its lock and enter the critical section. Presumably we want to limit one response per app attempt. So the lock could be taken on the ApplicationAttemptId key of the response map object.,Resolved,Fixed,,Omkar Vinit Joshi,Bikas Saha,Wed; 22 Feb 2012 23:19:06 +0000,Fri; 5 Feb 2016 07:45:01 +0000,Wed; 20 Nov 2013 05:23:04 +0000,,,,,YARN-4673,https://issues.apache.org/jira/browse/YARN-744
MAPREDUCE-3900,Improvement,Major,jobhistoryserver,mr-jobhistory-daemon.sh should rely on MAPREDUCE env. variables instead of the YARN ones,It nice to see yarn-deamo.sh be split into a separate script for managing MR service(s); but once that has happened we should go all the way and make it configurable as an MR entity.,Resolved,Duplicate,MAPREDUCE-4649,Roman Shaposhnik,Roman Shaposhnik,Thu; 23 Feb 2012 00:19:29 +0000,Thu; 29 Aug 2013 15:56:29 +0000,Thu; 29 Aug 2013 15:56:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3900
MAPREDUCE-3901,Improvement,Major,jobhistoryserver;mrv2,lazy load JobHistory Task and TaskAttempt details,The job history UI and MRClientProtocol calls routed via JobHistory are very slow for large jobs. Some of this time is spent parsing the history file. A good chunk is spent pre-creating lots of objects which may never be used. Those can be create when required - bringing down the load times of job history pages and getJobReport etc calls to approximately the history file parse time.,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 23 Feb 2012 03:02:28 +0000,Sun; 4 Mar 2012 00:29:26 +0000,Tue; 28 Feb 2012 00:35:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3901
MAPREDUCE-3902,Improvement,Major,applicationmaster;mrv2,MR AM should reuse containers for map tasks; there-by allowing fine-grained control on num-maps for users without need for CombineFileInputFormat etc.,"The MR AM is now in a great position to reuse containers across (map) tasks. This is something similar to JVM re-use we had in 0.20.x; but in a significantly better manner:  	Consider data-locality when re-using containers 	Consider the new shuffle - ensure that reduces fetch output of the whole container at once (i.e. all maps)  : MAPREDUCE-4525",Open,Unresolved,,Kannan Rajah,Arun C Murthy,Thu; 23 Feb 2012 15:09:30 +0000,Mon; 8 Aug 2016 17:04:17 +0000,,,,,YARN-75,MAPREDUCE-4596;MAPREDUCE-4525,https://issues.apache.org/jira/browse/MAPREDUCE-3902
MAPREDUCE-3903,Bug,Critical,mrv2,no admin override to view jobs on mr app master and job history server,in 1.0 there was a config mapreduce.cluster.administrators that allowed administrators to view anyones job.  That no longer works on yarn. yarn has the new config yarn.admin.acl but it appears the mr app master and job history server don't use that.,Resolved,Fixed,,Thomas Graves,Thomas Graves,Thu; 23 Feb 2012 17:28:29 +0000,Thu; 1 Mar 2012 13:58:07 +0000,Wed; 29 Feb 2012 20:50:31 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3903
MAPREDUCE-3904,Bug,Major,mrv2,[NPE] Job history produced with mapreduce.cluster.acls.enabled false can not be viewed with mapreduce.cluster.acls.enabled true,Job history page displays 'null'. It looks like job history files only populate job acls when mapreduce.cluster.acls.enabled is true. Upon reading job history files; getAcls can return null; throwing an exception on the HsJobBlock page.,Resolved,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 23 Feb 2012 17:32:42 +0000,Sat; 25 Feb 2012 13:57:46 +0000,Fri; 24 Feb 2012 22:34:24 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3904
YARN-85,Sub-task,Critical,nodemanager,Allow per job log aggregation configuration,Currently; if log aggregation is enabled for a cluster - logs for all jobs will be aggregated - leading to a whole bunch of files on hdfs which users may not want. Users should be able to control this along with the aggregation policy - failed only; all; etc.,Open,Unresolved,,Unassigned,Siddharth Seth,Thu; 23 Feb 2012 19:46:04 +0000,Wed; 26 Nov 2014 01:42:56 +0000,,,,,YARN-386,YARN-221;MAPREDUCE-3143,https://issues.apache.org/jira/browse/YARN-85
MAPREDUCE-3906,Improvement,Trivial,documentation,Fix inconsistency in documentation regarding mapreduce.jobhistory.principal,"Currently the documentation on http: ..."".",Closed,Fixed,,Eugene Koontz,Eugene Koontz,Thu; 23 Feb 2012 21:14:29 +0000,Thu; 11 Oct 2012 17:48:42 +0000,Mon; 9 Jul 2012 02:14:49 +0000,,2.0.0-alpha,,,MAPREDUCE-3907,https://issues.apache.org/jira/browse/MAPREDUCE-3906
MAPREDUCE-3907,Improvement,Minor,documentation,Document entries mapred-default.xml for the jobhistory server.,The following configuration properties are documented in http: mapred-default.xml that documents these properties and provides default values.,Closed,Fixed,,Eugene Koontz,Eugene Koontz,Thu; 23 Feb 2012 21:59:31 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Mon; 9 Jul 2012 02:07:42 +0000,,2.0.0-alpha,,,MAPREDUCE-3906,https://issues.apache.org/jira/browse/MAPREDUCE-3907
MAPREDUCE-3908,Bug,Major,mrv1,jobhistory server trying to load job conf file from wrong location,I have seen a few instance where I try to click on the job configuration link from the job history server web ui and it gives a 500 message.  Looking  sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl. 2  If I go look in hdfs; it doesn't exist in the done_intermediate directory anymore; it exists in the done directory structure.  hdfs: job_1330033607650_0001_conf.xml  I'm not exactly sure how to reproduce this; but I definitely see it every once in a while.,Resolved,Duplicate,MAPREDUCE-3972,Unassigned,Thomas Graves,Thu; 23 Feb 2012 22:22:07 +0000,Wed; 18 Apr 2012 20:36:27 +0000,Wed; 18 Apr 2012 20:36:27 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3908
MAPREDUCE-3909,Improvement,Trivial,mrv2,javadoc the Service interfaces,The Service interface doesn't describe what it does.  The ServiceStateChangeListener interface doesn't define when the method is called; whether it is sync or async with a state change etc -you have to look in the code for this.  Document for others,Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 24 Feb 2012 15:27:01 +0000,Wed; 23 May 2012 20:28:27 +0000,Mon; 27 Feb 2012 16:57:41 +0000,,0.23.0;0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3909
MAPREDUCE-3910,Bug,Blocker,mrv2,user not allowed to submit jobs even though queue -showacls shows it allows,User is not allowed to submit applications to a queue even though the queue is configured correctly and mapred queue -showacls shows that the user is allowed to submit,Resolved,Fixed,,John George,John George,Fri; 24 Feb 2012 16:30:03 +0000,Sun; 26 Feb 2012 13:56:47 +0000,Sun; 26 Feb 2012 06:54:32 +0000,,0.23.1;0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3910
MAPREDUCE-3911,Bug,Major,mrv1,Pending Jobs Metric can get off if job is submitted with invalid HDFS delegation token.,If a job is submitted; but the HDFS delegation token is invalid; The pending jobs counter will be incremented; then an exception will be thrown when we cannot get an instance of FileSystem to read the jobs configuration.  The error is returned; but the pending counter is never decremented.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Fri; 24 Feb 2012 16:45:19 +0000,Mon; 27 Feb 2012 15:25:23 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3911
MAPREDUCE-3912,Bug,Major,,getPriority() method within the JobHistoryParser JobInfo class fails,"When you use the following set of statements:    The problem is that     will fail if the ""priority"" is null.   I was expecting priority to return a ""NORMAL"" value  Viraj",Resolved,Duplicate,MAPREDUCE-3506,Jason Lowe,Viraj Bhat,Thu; 23 Feb 2012 23:28:14 +0000,Mon; 28 Sep 2015 21:10:33 +0000,Mon; 20 Aug 2012 22:18:49 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3912
MAPREDUCE-3913,Bug,Critical,mrv2;webapps,RM application webpage is unresponsive after 2000 jobs,After 2000 jobs have been submitted; trying to load the resourcemanager's applications page results in the following exception on the RM:,Resolved,Fixed,,Jason Lowe,Jason Lowe,Fri; 24 Feb 2012 17:28:55 +0000,Tue; 28 Feb 2012 14:17:35 +0000,Mon; 27 Feb 2012 16:50:22 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3913
MAPREDUCE-3914,Bug,Major,pipes,Mismatched free() / delete / delete [] in HadoopPipes,When running valgrind on a simple MapReduce pipes job; valgrind identifies a mismatched new   delete [] ==20394==    at 0x4C27FF2: operator delete(void*) (vg_replace_malloc.c:387) ==20394==    by 0x4328AF: HadoopPipes::runTask(HadoopPipes::Factory const) (HadoopPipes.cc:1172) ==20394==    by 0x424C33: main (ProcessRow.cpp:118) ==20394==  Address 0x9c7b580 is 0 bytes inside a block of size 131;072 alloc'd ==20394==    at 0x4C2864B: operator new[](unsigned long) (vg_replace_malloc.c:305) ==20394==    by 0x431E6A: HadoopPipes::runTask(HadoopPipes::Factory const) (HadoopPipes.cc:1122) ==20394==    by 0x424C33: main (ProcessRow.cpp:118)  The new [] calls in Lines 1121 and 1122 of HadoopPipes.cc:         bufin = new charbufsize;         bufout = new charbufsize; should have matching delete [] calls but are instead bracketed my delete on lines 1171 and 1172:       delete bufin;       delete bufout; So these should be replaced by delete[],Resolved,Fixed,,Joe Mudd,Charles Earl,Fri; 24 Feb 2012 17:42:06 +0000,Thu; 12 May 2016 18:22:55 +0000,Fri; 6 Nov 2015 00:51:11 +0000,,0.20.205.0;0.23.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3914
MAPREDUCE-3915,Improvement,Minor,pipes,Update implementation of Hadoop pipes communication to use java.nio.channels implementation.,Can the OutputStream and InputStream implementations in Hadoop Pipes; used in BinaryProtocol. nio.channels based implementation?,Open,Unresolved,,Unassigned,Charles Earl,Fri; 24 Feb 2012 17:56:40 +0000,Fri; 24 Feb 2012 17:56:40 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3915
MAPREDUCE-3916,Bug,Critical,mrv2;resourcemanager;webapps,various issues with running yarn proxyserver,"Seem like yarn proxyserver is not operational when running out of the 0.23.1 RC2 tarball.   	Setting yarn.web-proxy.address to match yarn.resourcemanager.address doesn't disable the proxyserver (althought not setting yarn.web-proxy.address at all correctly disable it and produces a message: org.apache.hadoop.yarn.YarnException: yarn.web-proxy.address is not set so the proxy will not run). This contradicts the documentation provided for yarn.web-proxy.address in yarn-default.xml     	Setting yarn.web-proxy.address and running the service results in the following:       with the following message found in the logs:",Closed,Fixed,,Devaraj K,Roman Shaposhnik,Fri; 24 Feb 2012 18:22:30 +0000,Thu; 12 May 2016 18:22:52 +0000,Fri; 30 Mar 2012 13:42:47 +0000,,0.23.1;2.0.0-alpha;3.0.0-alpha1,mrv2,,BIGTOP-464,https://issues.apache.org/jira/browse/MAPREDUCE-3916
MAPREDUCE-3917,Bug,Major,mrv2,Use java.net.preferIPv4Stack to force IPv4 in yarn,HADOOP-6056 made the changes for hadoop cli to use  net.preferIPv4Stack to force IPv4.  We should do the same things for the yarn commands.,Open,Unresolved,,Unassigned,Thomas Graves,Fri; 24 Feb 2012 19:15:30 +0000,Sat; 7 Jan 2017 01:59:55 +0000,,,0.23.0,,,YARN-1226,https://issues.apache.org/jira/browse/MAPREDUCE-3917
MAPREDUCE-3918,Bug,Major,mrv2,proc_historyserver no longer in command line arguments for HistoryServer,This  arg is missing from the command line and needs to be replaced,Resolved,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 24 Feb 2012 20:43:55 +0000,Sat; 25 Feb 2012 13:57:46 +0000,Fri; 24 Feb 2012 23:02:20 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3918
MAPREDUCE-3919,Bug,Critical,mrv2,Redirecting to job history server takes hours,Saw the following message happening regularly; the job end up success; but reconnecting job history server takes a long time (10 hours sometimes).  2012-02-24 03:49:05;226 main INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: hrt11n31.cc1.ygridcore.net 0.0.0.0:10020. Already tried 2 time(s). 2012-02-24 18:10:49;120 main WARN  org.apache.hadoop.mapred.ClientServiceDelegate - Error from remote end: Unknown job job_1330051901509_0017 2012-02-24 18:10:49;120 main ERROR org.apache.hadoop.security.UserGroupInformation - PriviledgedActionException as:pigtester (auth:SIMPLE) cause:org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1330051901509_0017,Resolved,Invalid,,Unassigned,Daniel Dai,Fri; 24 Feb 2012 20:47:57 +0000,Mon; 18 Jul 2016 07:50:05 +0000,Mon; 27 Feb 2012 07:56:14 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3919
MAPREDUCE-3920,Bug,Major,nodemanager;resourcemanager,Revise yarn default port number selection,"The default port numbers chosen for nodemanager and resourcemanager are random and widely spread out creating unnecessary overhead in deployments where site operators care; and deploy many clusters.  Current and proposed new default ports are as follows:  Current		New		Config Property	 ------- 	             --------------- 4344		8040		yarn.nodemanager.localizer.address	 45454		8041		yarn.nodemanager.address	 9999		8042		yarn.nodemanager.webapp.address	  8030		8030(NC)	yarn.resourcemanager.scheduler.address 8025		8031		yarn.resourcemanager.resource-tracker.address 8040		8032		yarn.resourcemanager.address 8141		8033		yarn.resourcemanager.admin.address   Affected files include:  embedded defaults (YarnConfiguration. ; yarn-default.xml; documentation and unit tests.",Resolved,Fixed,,Dave Thompson,Dave Thompson,Fri; 24 Feb 2012 21:46:24 +0000,Thu; 1 Mar 2012 13:58:05 +0000,Wed; 29 Feb 2012 15:54:44 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3920
MAPREDUCE-3921,Improvement,Major,mr-am;mrv2,MR AM should act on the nodes liveliness information when nodes go up/down/unhealthy,nan,Closed,Fixed,,Bikas Saha,Vinod Kumar Vavilapalli,Fri; 24 Feb 2012 21:50:00 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Mon; 11 Jun 2012 23:17:51 +0000,,0.23.0,,MAPREDUCE-3353;MAPREDUCE-4128,MAPREDUCE-4376,https://issues.apache.org/jira/browse/MAPREDUCE-3921
MAPREDUCE-3922,Improvement,Minor,build;mrv2,Fix the potential problem compiling 32 bit binaries on a x86_64 host.,MAPREDUCE-3880 specifies that -m32 be passed to gcc to ensure that a 32-bit binary is built. On my Amazon Linux with a x86_64 architecture; I could not build the native container-executor because the configure script exited with an error when trying to use gcc (version 4.4.5) with this flag.  Adds a comment to hadoop-mapreduce-project pom.xml regarding package requirement for glibc-devel.i686 or glibc-devel.i386 package on yum-based (RHEL; Centos; Amazon) Linux distributions.,Resolved,Fixed,MAPREDUCE-3890,Hitesh Shah,Eugene Koontz,Fri; 24 Feb 2012 22:56:27 +0000,Tue; 28 Feb 2012 14:17:35 +0000,Tue; 28 Feb 2012 02:43:53 +0000,,0.23.1,bigtop;build;doc;mrv2,,MAPREDUCE-3880;HADOOP-7276,https://issues.apache.org/jira/browse/MAPREDUCE-3922
YARN-3322,Bug,Major,,RM/AM/JHS webservers should return HTTP.BadRequest for malformed requests and not HTTP.NotFound,Many webserver methods (eg. AMWebServices.getTaskAttemptFromTaskAttemptString()) return NotFound for malformed requests instead of BadRequest. This would be inconsistent with expected HTTP behavior. Would be good to fix them. NotFound should be returned for valid resources which dont exist.,Open,Unresolved,,Unassigned,Bikas Saha,Sat; 25 Feb 2012 01:33:41 +0000,Tue; 10 Mar 2015 03:19:26 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-3322
MAPREDUCE-3924,Bug,Major,,Partioning Failing in certain scenarios for Hadoop Streaming using Ruby,We noticed a wierd scenario. The partitioning option fails in scenario below. The map reduce just aggregates values like a word count. However the key is having 2 parts.  Eg: Input Records: (key1|key2&lt;tab&lt;qty1|amt1|qty2|amt2|qty3|amt3 1201|420 1|24.0|2|26.0|0|0.0 1200|420 1|24.0|2|26.0|0|0.0 1200|420 1|25.0|3|52.0|1|55.0 1403|400 1|25.0|3|52.0|1|55.0 1201|420 1|24.0|2|26.0|0|0.0 1201|420 1|24.0|2|26.0|0|0.0 1403|400 1|25.0|3|52.0|1|55.0  Partioning option: -k1;1 and Comparator option -k1;1n -k2;2n works fine and the output we get is expected output 1200|420 2|49.0|5|78.0|1|55.0 1201|420 3|72.0|6|78.0|0|0.0 1403|400 2|50.0|6|104.0|2|110.0  However if we use Partioning option: -k1;1 -k2;2 and Comparator option -k1;1n -k2;2n then the output is faulty. Seems the same key does not go to same reducer in output we see duplicate records; however this does not happen to all records. A hypothetical faulty output based on above input is: 1200|420 1|24.0|2|26.0|0|0.0 1201|420 3|72.0|6|78.0|0|0.0 1403|400 2|50.0|6|104.0|2|110.0 1200|420 1|25.0|3|52.0|1|55.0  See that records with the key (1200|420) is not aggregated. This can happen only if the record does not go to the same reducer after partioning.  Any clue why this is happening? I could not understanding what is going wrong.,Resolved,Not A Problem,,Unassigned,Subir S,Sat; 25 Feb 2012 16:01:11 +0000,Tue; 8 May 2012 18:37:47 +0000,Tue; 8 May 2012 18:37:46 +0000,,0.20.2,hadoop;map;reduce;ruby;streaming,,,https://issues.apache.org/jira/browse/MAPREDUCE-3924
MAPREDUCE-3925,Improvement,Major,contrib/gridmix,[Gridmix] Gridmix stress mode should be queue aware,Currently; the Gridmix stress mode submits jobs in the same order as seen in the trace. When Gridmix is configured to run with multiple queues; the stress mode might end up queuing lot of jobs in a single queue without really stressing the entire cluster. The goal is to make sure that each queue is loaded thus keeping the entire cluster busy.,Open,Unresolved,,Unassigned,Amar Kamat,Mon; 27 Feb 2012 04:59:02 +0000,Thu; 12 May 2016 18:22:40 +0000,,,3.0.0-alpha1,gridmix;multi-queue;stress,,,https://issues.apache.org/jira/browse/MAPREDUCE-3925
MAPREDUCE-3926,Bug,Minor,jobtracker,No information of unfinished map task in Job History; if all attempts of another map task fail.,"No information of unfinished map task in Job History; if all attempts of another map task fail.  For example;  1. The first map task's first attempt m_000000_0 was making progress  2. The second map task failed 4 times; before completion of first map task attempt.  3. Hence; a job cleanup task was launched and completed; before completion of first map task attempt.  4. After job cleanup task; runningMapCache is cleaned    5. Hence; ""Running cache for maps missing!! Job details are missing."" error comes (from retireMap() which is called after jobComplete() ) and no information is added further to Job History. Therefore; first map task's information is missing from Job History page.   I have created a sample streaming MR job; to reproduce this issue.      Input file: in1.txt is for long running map task (here first map task)     Input file: in2.txt is for failing map task (here second map task)      Running the sample streaming MR job.    Job History web UI    Above it shows; only 2 failed tasks (belong to second map task). Only from JT logs; the task tracker of first map task can be found.",Open,Unresolved,,Unassigned,Mitesh Singh Jat,Mon; 27 Feb 2012 13:11:12 +0000,Tue; 28 Feb 2012 10:29:49 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3926
MAPREDUCE-3927,Bug,Critical,mrv2,Shuffle hang when set map.failures.percent,When set mapred.max.map.failures.percent and there does have some failed maps; then shuffle will hang,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,MengWang,Mon; 27 Feb 2012 16:06:17 +0000,Tue; 10 Mar 2015 04:30:17 +0000,Mon; 11 Jun 2012 13:58:43 +0000,,0.23.3;2.0.0-alpha,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-3927
MAPREDUCE-3928,Bug,Major,applicationmaster,App GUI Cluster->Applications UI has confusing job status report,The 0.23.1 Application GUI has some potential usability issues and confusion points with respect to job status; from a user's perspective.   Currently; when starting from the App UI base link of http: KILLED  Another potential issue is that the RM and AM each have their own interpretation of a job's result; so the State and FinalStatus reported in the Cluster Metrics display may not align with the defined states in the Cluster pulldown. It would be useful to clearly delineate areas of the GUI wrt the component visible states of a user's job.,Resolved,Won't Fix,,Anupam Seth,patrick white,Mon; 27 Feb 2012 17:04:01 +0000,Wed; 11 Apr 2012 22:48:49 +0000,Wed; 11 Apr 2012 22:48:49 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3928
MAPREDUCE-3929,Bug,Major,mrv2,output of mapred -showacl is not clear,output of 'mapred queue -showacls' is not very clear. This JIRA is aimed at either fixing that or adding something to the document to make it clear.,Resolved,Fixed,,John George,John George,Mon; 27 Feb 2012 21:54:43 +0000,Tue; 10 Mar 2015 04:31:55 +0000,Sun; 4 Mar 2012 18:37:12 +0000,,0.23.2;0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3929
MAPREDUCE-3930,Bug,Critical,mrv2,The AM page for a Reducer that has not been launched causes an NPE,nan,Resolved,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 27 Feb 2012 22:28:09 +0000,Wed; 29 Feb 2012 13:57:21 +0000,Tue; 28 Feb 2012 23:54:12 +0000,,0.23.1;0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3930
MAPREDUCE-3931,Bug,Major,mrv2,MR tasks failing due to changing timestamps on Resources to download,Karam Singh reported this offline. Seems that tasks are randomly failing during gridmix runs:,Resolved,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Mon; 27 Feb 2012 22:30:59 +0000,Wed; 29 Feb 2012 13:57:21 +0000,Wed; 29 Feb 2012 04:58:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3931
MAPREDUCE-3932,Bug,Critical,mr-am;mrv2,MR tasks failing and crashing the AM when available-resources/headRoom becomes zero,Karam Singh reported this offline. One reduce task gets preempted because of zero headRoom and crashes the AM.,Closed,Fixed,MAPREDUCE-6933,Robert Joseph Evans,Vinod Kumar Vavilapalli,Mon; 27 Feb 2012 22:39:43 +0000,Fri; 4 Aug 2017 13:36:12 +0000,Wed; 11 Apr 2012 18:20:53 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3932
MAPREDUCE-3933,Bug,Major,mrv2;test,Failures because MALLOC_ARENA_MAX is not set,"We have noticed a bunch of MapReduce test failures on CentOS 6 due to ""running beyond virtual memory limits"".  These tests fail with messages of the form:    The failing tests are:    I'll upload a patch momentarily.",Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 28 Feb 2012 04:57:17 +0000,Wed; 23 May 2012 20:28:28 +0000,Wed; 29 Feb 2012 16:22:10 +0000,,0.23.0,,,HBASE-5529,https://issues.apache.org/jira/browse/MAPREDUCE-3933
MAPREDUCE-3934,Improvement,Major,distcp,RetriableCommand in distcp should not use RetryPolicy classes,It's generally not kosher for RetriableCommand to be using the RetryPolicy classes at all; since they're not really intended to be used except by RetryInvocationHandler. See HADOOP-8116 for an example of why.,Open,Unresolved,,Unassigned,Aaron T. Myers,Tue; 28 Feb 2012 16:53:43 +0000,Tue; 10 Mar 2015 04:32:17 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3934
MAPREDUCE-3935,Improvement,Major,client,Annotate Counters.Counter and Counters.Group as @Public,For clarity these inner classes should be marked as public stable.,Closed,Fixed,,Tom White,Tom White,Tue; 28 Feb 2012 18:41:17 +0000,Mon; 16 Mar 2015 06:06:30 +0000,Sat; 3 Mar 2012 00:13:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3935
MAPREDUCE-3936,Improvement,Major,mrv1,Clients should not enforce counter limits ,The code for enforcing counter limits (from MAPREDUCE-1943) creates a static JobConf instance to load the limits; which may throw an exception if the client limit is set to be lower than the limit on the cluster (perhaps because the cluster limit was raised from the default).,Resolved,Won't Fix,,Tom White,Tom White,Tue; 28 Feb 2012 18:57:44 +0000,Mon; 11 May 2015 09:36:58 +0000,Mon; 11 May 2015 09:36:58 +0000,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-3936
MAPREDUCE-3937,Bug,Minor,mrv2,docs need updating on how to start proxyserver,"The docs (http: ClusterSetup.html) on how to start the proxyserver are wrong.  It says to use yarn start; which should be use yarn_daemon.sh start proxyserver.   Also just running ""yarn"" doesn't show the proxyserver as an option.",Open,Unresolved,,Unassigned,Thomas Graves,Tue; 28 Feb 2012 23:25:58 +0000,Wed; 18 Apr 2012 19:58:22 +0000,,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3937
YARN-185,Sub-task,Major,,Add preemption to CS,Umbrella jira to track adding preemption to CS; let's track via sub-tasks.,Resolved,Duplicate,YARN-569,Arun C Murthy,Arun C Murthy,Wed; 29 Feb 2012 03:17:57 +0000,Tue; 13 May 2014 21:26:43 +0000,Tue; 4 Jun 2013 01:44:35 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-185
YARN-117,Improvement,Major,,Enhance YARN service model,Having played the YARN service model; there are some issues th lets you register unregister services to terminate; and have the relevant main() entry points tell their root services to register themselves.,Closed,Fixed,,Steve Loughran,Steve Loughran,Wed; 29 Feb 2012 10:31:06 +0000,Tue; 27 Aug 2013 22:15:44 +0000,Thu; 13 Jun 2013 16:00:25 +0000,,2.0.4-alpha,,,YARN-804;MAPREDUCE-3431;MAPREDUCE-5298;MAPREDUCE-3877,https://issues.apache.org/jira/browse/YARN-117
MAPREDUCE-3940,Sub-task,Major,mrv2;security,ContainerTokens should have an expiry interval,"RM should generate the expiry time for a container 	A ContainerToken should have its expire time encoded 	NMs should reject containers with expired tokens. 	Expiry interval for a ContainerToken is same as the expiry interval for a container.",Closed,Fixed,MAPREDUCE-2742,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 29 Feb 2012 19:26:10 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Tue; 10 Jul 2012 21:37:00 +0000,,0.23.0,,YARN-39,,https://issues.apache.org/jira/browse/MAPREDUCE-3940
YARN-49,Sub-task,Major,applications/distributed-shell,Improve distributed shell application to work on a secure cluster,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Hitesh Shah,Wed; 29 Feb 2012 19:42:26 +0000,Tue; 30 Jun 2015 07:20:29 +0000,Wed; 25 Sep 2013 23:43:16 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-49
MAPREDUCE-3942,Sub-task,Major,mrv2;security,Randomize master key generation for ApplicationTokenSecretManager and roll it every so often,"Master key for authentication of AMs need to be automatically generated. 	The key needs to be rolled every so often but AMs with old keys should continue to be able to talk to the RM.",Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 29 Feb 2012 21:47:56 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Tue; 17 Apr 2012 18:57:48 +0000,,0.23.0,,YARN-39,,https://issues.apache.org/jira/browse/MAPREDUCE-3942
YARN-39,Sub-task,Critical,,RM-NM secret-keys should be randomly generated and rolled every so often,"RM should generate the master-key randomly 	The master-key should roll every so often 	NM should remember old expired keys so that already doled out container-requests can be satisfied.",Closed,Fixed,MAPREDUCE-2742;MAPREDUCE-3105,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 29 Feb 2012 21:59:02 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Sat; 25 Aug 2012 02:27:49 +0000,,,,MAPREDUCE-3940;MAPREDUCE-3942,YARN-35,https://issues.apache.org/jira/browse/YARN-39
MAPREDUCE-3944,Sub-task,Blocker,mrv2,JobHistory web services are slower then the UI and can easly overload the JH,When our first customer started using the Job History web services today the History Server ground to a halt.  We found 250 Jetty threads stuck on the following stack trace.     HsWebServices. 188 corresponds to the  jobs service.  Looking at the code there are a number of optimizations that need to be done to improve its performance.,Resolved,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 29 Feb 2012 22:44:47 +0000,Thu; 2 May 2013 02:29:50 +0000,Tue; 6 Mar 2012 19:53:41 +0000,,0.23.1;0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3944
MAPREDUCE-3945,Sub-task,Major,mrv2;security,JobHistoryServer should store tokens to authenticate clients across restart,JobHistoryServer gives off delegation tokens so that clients can talk to it. It needs to store them off somewhere to authenticate clients across the server restart,Resolved,Duplicate,MAPREDUCE-5332,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 29 Feb 2012 23:09:18 +0000,Fri; 8 May 2015 18:22:20 +0000,Fri; 8 May 2015 18:22:20 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3945
MAPREDUCE-3946,Bug,Major,resourcemanager,If a resource requirement is higher than available on any node; job should fail early,"If you configure the NMs to have 1GB of RAM each; and then try to submit a job which has an AM resource requirement of 1.5GB; the job will neither run nor fail. Instead; it will slowly sop of all of the resources in the cluster as ""reservations"" despite the fact that it will never be able to schedule something. Instead; it should fail early indicating that the required memory allocation is infeasible.",Resolved,Duplicate,YARN-193;YARN-56,Unassigned,Todd Lipcon,Thu; 1 Mar 2012 01:18:01 +0000,Tue; 10 Mar 2015 04:33:02 +0000,Fri; 3 May 2013 23:22:44 +0000,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3946
MAPREDUCE-3947,Bug,Minor,,yarn.app.mapreduce.am.resource.mb not documented,This configuration is useful but doesn't appear to be documented anywhere.,Closed,Fixed,,Devaraj K,Todd Lipcon,Thu; 1 Mar 2012 01:18:44 +0000,Tue; 10 Mar 2015 04:33:03 +0000,Thu; 19 Apr 2012 20:38:19 +0000,,0.23.3;2.0.0-alpha,mrv2,,,https://issues.apache.org/jira/browse/MAPREDUCE-3947
MAPREDUCE-3948,Bug,Minor,resourcemanager;webapps,proxy throws UnknownHostException when following link shortly after job submission,"I submitted a job and then clicked on the link from the console quickly; before the job began to run. I saw the following exception:   269) Assumedly this is because the URL is stored as ""N A"" instead of a true null value.",Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 1 Mar 2012 01:20:12 +0000,Tue; 10 Mar 2015 04:33:01 +0000,,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3948
YARN-560,Bug,Minor,,If AM fails due to overrunning resource limits; error not visible through UI sometimes,I had a case where an MR AM eclipsed the configured memory limit. This caused the AM's container to get killed; but nowhere accessible through the web UI showed these diagnostics. I had to go view the NM's logs via ssh before I could figure out what had happened to my application.,Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 1 Mar 2012 01:21:36 +0000,Wed; 27 Aug 2014 18:52:42 +0000,,,0.23.3;2.0.0-alpha,usability,,MAPREDUCE-3688;YARN-522,https://issues.apache.org/jira/browse/YARN-560
MAPREDUCE-3950,Bug,Minor,,Configuration templates still MR1-centric,The conf files in the dist tar's share hadoop directory in the dist tar does have a yarn-site file; but is missing mapred-site.,Open,Unresolved,,Unassigned,Todd Lipcon,Thu; 1 Mar 2012 01:25:25 +0000,Tue; 10 Mar 2015 04:33:01 +0000,,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3950
MAPREDUCE-3951,Improvement,Major,scheduler,Tasks are not evenly spread throughout cluster in MR2,In MR1 (at least with the fair and fifo schedulers); if you submit a job that needs fewer resources than the cluster can provide; the tasks are spread relatively evenly across the node. For example; submitting a 100-map job to a 50-node cluster; each with 10 slots; results in 2 tasks on each machine. In MR2; however; the tasks would pile up on the first 10 nodes of the cluster; leaving the other nodes unused. This is highly suboptimal for many use cases.,Resolved,Not A Problem,,Unassigned,Todd Lipcon,Thu; 1 Mar 2012 01:27:41 +0000,Tue; 10 Mar 2015 04:32:59 +0000,Tue; 2 Apr 2013 22:10:39 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3951
MAPREDUCE-3952,Bug,Major,mrv2,In MR2; when Total input paths to process == 1; CombinefileInputFormat.getSplits() returns 0 split.,Hive get unexpected result when using MR2(When using MR1; always get expected result).  In MR2; when Total input paths to process == 1; CombinefileInputFormat.getSplits() returns 0 split.  The calling code in Hive; in Hadoop23Shims.   CombineFileSplit[] splits = (CombineFileSplit[]) super.getSplits(job; numSplits);  this get splits.length == 1.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Zhenxiao Luo,Thu; 1 Mar 2012 05:10:57 +0000,Tue; 10 Mar 2015 04:33:05 +0000,Tue; 6 Mar 2012 00:00:51 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3952
MAPREDUCE-3953,Bug,Major,,Gridmix throws NPE and does not simulate a job if the trace contains null taskStatus for a task,In a trace file; if a succeeded job contains a failed task; then that task's taskStatus will be null. This is causing NPE in Gridmix and then Gridmix is ignoring not-considering such jobs for simulation. The job could succeed even with failed tasks if the job submitter in original cluster configured that job to tolerate failures using mapreduce.map.failures.maxpercent and mapreduce.reduce.failures.maxpercent.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Thu; 1 Mar 2012 08:25:32 +0000,Wed; 3 Sep 2014 22:45:03 +0000,Wed; 21 Mar 2012 09:53:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3953
MAPREDUCE-3954,Bug,Blocker,mrv2,Clean up passing HEAPSIZE to yarn and mapred commands.,Currently the heap size for all of these is set in yarn-env.sh.  JAVA_HEAP_MAX is set to -Xmx1000m unless YARN_HEAPSIZE is set.  If it is set it will override JAVA_HEAP_MAX.  However; we do not always want to have the RM; NM; and HistoryServer with the exact same heap size.  It would be logical to have inside of yarn and mapred to set JAVA_HEAP_MAX if YARN_RESOURCEMANAGER_HEAPSIZE; YARN_NODEMANAGER_HEAPSIZE or HADOOP_JOB_HISTORYSERVER_HEAPSIZE are set respectively.  This is a bug because it is easy to configure the history server to store more entires then the heap can hold.  It is also a performance issue if we do not allow the history server to cache many entries on a large cluster.,Resolved,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 1 Mar 2012 16:54:47 +0000,Sun; 25 Aug 2013 14:32:46 +0000,Mon; 5 Mar 2012 19:07:21 +0000,,0.23.2,,,HADOOP-9902,https://issues.apache.org/jira/browse/MAPREDUCE-3954
MAPREDUCE-3955,Improvement,Blocker,mrv2,Replace ProtoOverHadoopRpcEngine with ProtobufRpcEngine.,We shouldn't have two rpc engines based on protocol buffers. ProtoOverHadoopRpcEngine in hadoop-yarn-common should be replaced by ProtobufRpcEngine in hadoop-common.,Closed,Fixed,,Jitendra Nath Pandey,Jitendra Nath Pandey,Thu; 1 Mar 2012 19:10:50 +0000,Wed; 23 May 2012 20:28:22 +0000,Thu; 29 Mar 2012 02:04:57 +0000,,0.23.2,,MAPREDUCE-4067,,https://issues.apache.org/jira/browse/MAPREDUCE-3955
MAPREDUCE-3956,Improvement,Minor,examples,Remove the use of the deprecated Syncable.sync() method,This is a part of HADOOP-8124.,Resolved,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Thu; 1 Mar 2012 19:27:06 +0000,Thu; 12 May 2016 18:24:12 +0000,Thu; 1 Mar 2012 23:55:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3956
HADOOP-8296,Bug,Minor,,hadoop/yarn daemonlog usage wrong ,$ yarn daemonlog  USAGES:  org.apache.hadoop.log.LogLevel,Closed,Fixed,,Devaraj K,Thomas Graves,Thu; 1 Mar 2012 23:16:43 +0000,Thu; 12 May 2016 18:24:30 +0000,Wed; 25 Apr 2012 18:00:34 +0000,,0.23.2;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/HADOOP-8296
MAPREDUCE-3958,Bug,Major,mrv2,RM: Remove RMNodeState and replace it with NodeState,RMNodeState is being sent over the wire after MAPREDUCE-3353. This has been done by cloning the enum into NodeState in yarn protocol records. That makes RMNodeState redundant and it should be replaced with NodeState.,Closed,Fixed,,Bikas Saha,Bikas Saha,Fri; 2 Mar 2012 01:32:18 +0000,Thu; 4 Sep 2014 01:05:58 +0000,Fri; 4 May 2012 15:51:30 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3958
MAPREDUCE-3959,Bug,Minor,client;mrv2,mapred job -status reports bad JobFile path when network ACL prevents AM access,"ClientServiceDelegate checks network ACLs; and if they prevent connecting to the AM it uses a canned job status via getNotRunningJob(null; RUNNING).  The resulting output for this canned job shows a bad path for the JobFile field; as the user in the canned field is ""N A"" and code doesn't check for that.  For example:",Open,Unresolved,,Unassigned,Jason Lowe,Fri; 2 Mar 2012 02:17:31 +0000,Fri; 2 Mar 2012 02:17:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3959
MAPREDUCE-3960,Bug,Critical,mrv2,web proxy doesn't forward request to AM with configured hostname/IP,If the host the web proxy is running on has an ip alias or similar and the config file is pointing to the hostname that is the aliased ip of the box; the web proxy will send the request from the base ip rather then the aliased ip and the AM will redirect that request to the proxy again instead of accepting it.,Resolved,Fixed,,Thomas Graves,Thomas Graves,Fri; 2 Mar 2012 19:08:48 +0000,Mon; 5 Mar 2012 13:25:42 +0000,Sun; 4 Mar 2012 21:17:00 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3960
MAPREDUCE-3961,Bug,Major,mrv2,Map/ReduceSlotMillis computation incorrect,Map ReduceSlot millis are currently computed based on a fixed container size. They should instead be based on the minimum container size offered by the cluster. There's another jira to rename these Counters - based on the resource type. This jira isn't to do that - just to fix the values.,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 2 Mar 2012 22:40:04 +0000,Wed; 7 Mar 2012 13:25:25 +0000,Tue; 6 Mar 2012 23:25:19 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3961
MAPREDUCE-3962,Bug,Major,,InverseMapper causes IntWritable type to collected as Text,When using the org.apache.hadoop.mapred.lib.InverseMapper; key;values are inversed as expected. For example (Text;IntWritable) will get inversed. However; output key;value only works if you use (Text; Text). Below is an example; where I was chaining 2 jobs:  Job 1: public static class Reduce extends MapReduceBase implements ReducerText; IntWritable; Text; IntWritable {...}  Job 2: conf.setMapperClass(InverseMapper.class); public static class Reduce extends MapReduceBase implements ReducerIntWritable; Text; Text; IntWritable {...}   I would expect this to work. When I do this; I get  lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to org.apache.hadoop.io.IntWritable  To re-inverse my key;values; I had to do this: public static class Reduce extends MapReduceBase implements ReducerText; Text; Text; Text  Notice that in order for the reducer to properly accept key;values; I had to indicate the key as Text.,Open,Unresolved,,Unassigned,Saad Patel,Fri; 2 Mar 2012 23:31:42 +0000,Thu; 8 Mar 2012 06:42:16 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3962
MAPREDUCE-3963,Bug,Critical,mrv2;nodemanager,NodeManagers die on startup if they can't connect to the RM,Steps to reproduce. Start the NM when the RM is down. The NM tries 10 times; then exits. It should keep trying forever.,Resolved,Duplicate,MAPREDUCE-3676,Unassigned,Ravi Prakash,Sat; 3 Mar 2012 00:08:14 +0000,Mon; 5 Mar 2012 16:09:07 +0000,Mon; 5 Mar 2012 16:09:07 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3963
MAPREDUCE-3964,Bug,Critical,mrv2;resourcemanager,ResourceManager does not have JVM metrics,ResourceManager is not creating a JvmMetrics instance on startup.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Sat; 3 Mar 2012 01:16:22 +0000,Tue; 10 Mar 2015 04:32:14 +0000,Mon; 5 Mar 2012 22:07:08 +0000,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3964
MAPREDUCE-3965,Bug,Minor,,JobConf.findContainingJar NPEs if it can't find the classloader of a class,"I never knew that classes may not have classloaders; but it turns out they can -in which case Object.getClass().getClassLoader() will be null ""This method will return null in such implementations if this class was loaded by the bootstrap class loader.""""  When this (rare) situation arises; JobConf.findContainingJar() NPEs; when failing with a slightly more useful error message would be preferred.",Open,Unresolved,,Unassigned,Steve Loughran,Sat; 3 Mar 2012 14:07:22 +0000,Tue; 10 Mar 2015 04:32:36 +0000,,,0.23.0;1.0.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3965
MAPREDUCE-3966,Sub-task,Major,jobhistoryserver;mrv2,Add separate cache for CompletedJobs with tasks loaded and without tasks loaded in JobHIstoryServer,After MAPREDUCE-3901; we should have separate caches for list of CompletedJob with tasks loaded and list of CompletedJob without tasks loaded. Once we have separate cache; we should increase the cache size for the list which doesn't load tasks.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Sun; 4 Mar 2012 00:10:50 +0000,Tue; 10 Feb 2015 21:38:50 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3966
MAPREDUCE-3967,Bug,Major,nodemanager,DefaultContainerExecutor cannot launch container under windows,"DefaultContainerExecutor cannot launch container under windows; because bash cannot find the WRAPPER_LAUNCH_SCRIPT.  Path wrapperScriptDst = new Path(containerWorkDir; WRAPPER_LAUNCH_SCRIPT);  String[] command =  {""bash""; ""-c"";           wrapperScriptDst.toUri().getPath().toString()} ;       LOG.info(""launchContainer: "" + Arrays.toString(command)); Suppose that  the value of 'wrapperScriptDst' is ""C: default_container_executor.sh"" Then wrapperScriptDst.toUri().getPath().toString() will be "" default_container_executor.sh""; which is a wrong path",Open,Unresolved,,Unassigned,Changming Sun,Sun; 4 Mar 2012 09:38:31 +0000,Sat; 5 May 2012 14:21:36 +0000,,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3967
MAPREDUCE-3968,Improvement,Minor,mrv1,add support for getNumMapTasks() into mapreduce JobContext,In old mapred api there was way to query number of mappers:  job.getNumMapTasks())  No such function exists in new mapreduce api,Resolved,Not A Problem,,Unassigned,Radim Kolar,Sun; 4 Mar 2012 19:56:19 +0000,Tue; 10 Mar 2015 04:30:18 +0000,Tue; 1 Jan 2013 10:33:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3968
MAPREDUCE-3969,Bug,Major,,ConcurrentModificationException in JobHistory.java,Task task_201202150320_3709_m_000148 was being marked as failed (but had not been restarted) at that moment and job execution was being freezed.,Resolved,Not A Problem,,Harsh J,Alexey Zotov,Mon; 5 Mar 2012 06:12:19 +0000,Sat; 12 May 2012 12:37:05 +0000,Sat; 12 May 2012 12:37:05 +0000,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3969
YARN-118,Sub-task,Major,,Add ServiceOperations class to aid working with Services,Add Helper methods to move things through lifecycles. init-start is common; stop-if-service!=null another. Some static methods can execute these; and even call stop() if init() raises an exception. These could go into a class ServiceOps in the same package. These can be used by those services that wrap other services; and help manage more robust shutdowns.,Closed,Fixed,,Steve Loughran,Steve Loughran,Mon; 5 Mar 2012 15:13:22 +0000,Thu; 2 May 2013 02:29:50 +0000,Thu; 15 Mar 2012 10:40:26 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-118
MAPREDUCE-3971,Sub-task,Major,mrv2,Job History web services need to have limits on the number of items they can return.,The Job History web services canput a very large load on the job history server.  We should put in a limit on the number of entries that can be returned by the web service; and also add in the ability to modify the starting location in the list; so that all entries can still be downlaoded.  Just not all at once.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Mon; 5 Mar 2012 19:14:36 +0000,Thu; 4 Jun 2015 17:32:55 +0000,,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3971
MAPREDUCE-3972,Sub-task,Major,mrv2,Locking and exception issues in JobHistory Server.,The JobHistory server's locking is inconsistent and wrong in some cases.  This is not super critical because the issues would only show up if a job is being cleaned up or moved from intermediate done to done; at the same time it is being parsed into a CompletedJob.  However the locking is slowing down the server in some cases; and is a ticking time bomb that needs to be addressed.  As part of this too we need to be sure that the Cleaner and Intermediate to Done migration threads handle exceptions properly.  Now it appears that the exception is logged; and the thread just shuts down.  This means that the history server could still be up and running for weeks and never remove old jobs.,Closed,Fixed,MAPREDUCE-4080,Robert Joseph Evans,Robert Joseph Evans,Mon; 5 Mar 2012 19:22:46 +0000,Thu; 11 Oct 2012 17:48:42 +0000,Wed; 18 Apr 2012 02:01:28 +0000,,0.23.2,,,MAPREDUCE-4055,https://issues.apache.org/jira/browse/MAPREDUCE-3972
MAPREDUCE-3973,Bug,Major,jobhistoryserver;mrv2,[Umbrella JIRA] JobHistoryServer performance improvements in YARN+MR,Few parallel efforts are happening w.r.t improving fixing issues with JobHistoryServer in MR over YARN. This is the umbrella ticket so we have the complete picture.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Mon; 5 Mar 2012 22:12:55 +0000,Thu; 11 Jun 2015 16:23:29 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3973
MAPREDUCE-3974,Bug,Blocker,,TestSubmitJob in MR1 tests doesn't compile after HDFS-1623 merge,TestSubmitJob in MR1 tests doesn't compile after HDFS-1623 merge.  'ant compile-tests' doesn't work (since it's ant for MR1).,Closed,Fixed,MAPREDUCE-3855,Aaron T. Myers,Arun C Murthy,Mon; 5 Mar 2012 22:56:11 +0000,Wed; 23 May 2012 20:28:19 +0000,Mon; 12 Mar 2012 18:30:22 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3974
MAPREDUCE-3975,Bug,Blocker,mrv2,Default value not set for Configuration parameter mapreduce.job.local.dir,"mapreduce.job.local.dir (formerly job.local.dir in 0.20) is not set by default. This is a regression from 0.20.205.  In 0.20.205; JobLocalizer.createWorkDir() constructs the ""$mapred.local.dir work"" path based on $user and $jobid; and then sets TaskTracker.JOB_LOCAL_DIR in the job's JobConf.  So far; I haven't found where this is done in 0.23. It could be that this is what should be done by LocalJobRunner.setupChildMapredLocalDirs(); but I am still investigating.",Resolved,Fixed,,Eric Payne,Eric Payne,Mon; 5 Mar 2012 23:17:55 +0000,Thu; 8 Mar 2012 19:46:50 +0000,Thu; 8 Mar 2012 19:38:49 +0000,,0.23.1;0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3975
MAPREDUCE-3976,Bug,Major,mrv2,TestRMContainerAllocator failing,The following stack trace is being generated ======== org.apache.hadoop.metrics2.MetricsException: Metrics source JvmMetrics already exists!   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod. 44) ========  This test fails when git trunk is reset to - commit 6689d99b38c7c562e8cae484207ad30ad7b56eb5 but passes when git trunk is reset to - commit f429fdaf78a02211c4faee54b1ee92822edc5741,Resolved,Fixed,,Jason Lowe,Bikas Saha,Tue; 6 Mar 2012 02:40:02 +0000,Wed; 7 Mar 2012 13:25:25 +0000,Tue; 6 Mar 2012 16:21:00 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3976
MAPREDUCE-3977,Bug,Critical,mrv2;nodemanager,LogAggregationService leaks log aggregator objects,LogAggregationService adds log aggregator objects to the appLogAggregators map but never removes them.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Tue; 6 Mar 2012 22:12:10 +0000,Wed; 7 Mar 2012 13:25:25 +0000,Tue; 6 Mar 2012 23:47:43 +0000,,0.23.1,,,MAPREDUCE-3143,https://issues.apache.org/jira/browse/MAPREDUCE-3977
MAPREDUCE-3978,Bug,Major,jobhistoryserver;mrv2,getTotalMaps; getTotalReduces is incorrect for JobHistory PartialJob,These are currently returning the number of completed map   reduce tasks - instead of the total. The information doesn't make it over to the history server via the job history file name.,Open,Unresolved,,Unassigned,Siddharth Seth,Tue; 6 Mar 2012 22:26:29 +0000,Thu; 8 Mar 2012 18:16:03 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3978
YARN-503,Sub-task,Major,resourcemanager,DelegationTokens will be renewed forever if multiple jobs share tokens and the first one sets JOB_CANCEL_DELEGATION_TOKEN to false,The first Job list of jobIds for shared tokens.,Open,Unresolved,,Daryn Sharp,Siddharth Seth,Wed; 7 Mar 2012 00:30:35 +0000,Thu; 12 May 2016 18:30:17 +0000,,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-503
MAPREDUCE-3980,Bug,Major,jobhistoryserver,mr-jobhistory-daemon.sh should look for mapred script in HADOOP_MAPRED_HOME,The following:     should be this instead:,Resolved,Duplicate,MAPREDUCE-4649,Unassigned,Roman Shaposhnik,Wed; 7 Mar 2012 02:12:34 +0000,Mon; 28 Sep 2015 21:10:30 +0000,Thu; 7 Mar 2013 18:33:10 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3980
MAPREDUCE-3981,Bug,Major,,FileNotFoundException during Mapper.setup for file embedded in job jar,"I have a job that is packaged as a jar and contains a configuration file in the root of the jar ""RankingRules.xml"".  During the mapping I'm loading this file   1035) 	... 12 more  I'm thinking a good approach is to change the code so it loads the RankingRules from an HDFS url instead of embedding them in the jar.  However I'm a little baffled as to why this should change between tasks. This job is creating about 600 map tasks and on the last run it failed after about 300 successful maps.  At the moment this is running in psuedo distributed mode so it's just one machine.",Open,Unresolved,,Unassigned,David Savage,Wed; 7 Mar 2012 15:52:43 +0000,Wed; 7 Mar 2012 15:52:43 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3981
MAPREDUCE-3982,Bug,Critical,mrv2,TestEmptyJob fails with FileNotFound,TestEmptyJob fails because teh FileOutputCommitter expects a directory to be created that is not created.  The FileOutputCommitter should either ignore the error or create the directory itself.,Resolved,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 7 Mar 2012 19:58:27 +0000,Tue; 10 Mar 2015 04:32:42 +0000,Fri; 9 Mar 2012 21:16:11 +0000,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3982
MAPREDUCE-3983,Test,Major,mrv1,TestTTResourceReporting can fail; and should just be deleted,TestTTResourceReporting can fail.  It is an ant test for task trackers which shoudl just be removed because task trackers are no longer supported outside of the ant tests.,Closed,Fixed,,Ravi Prakash,Robert Joseph Evans,Wed; 7 Mar 2012 20:34:25 +0000,Fri; 7 Sep 2012 21:03:34 +0000,Tue; 10 Apr 2012 16:17:04 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3983
MAPREDUCE-3984,Test,Major,mrv2,TestDBJob and TestDataDrivenDBInputFormat timeout,org.apache.hadoop.mapreduce.lib.db.TestDBJob.testRun and org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat.testDateSplits bith timeout.  They look like they timeout trying to shutdown the DB that is used as part of the testing.,Resolved,Duplicate,MAPREDUCE-3621,Unassigned,Robert Joseph Evans,Wed; 7 Mar 2012 20:41:09 +0000,Mon; 12 Mar 2012 16:40:16 +0000,Mon; 12 Mar 2012 16:40:03 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3984
MAPREDUCE-3985,Bug,Major,mr-am,handleTaskAttemptCompletion() called twice for same task attempt from KillWaitAttemptKilledTransition & AttemptKilledTransition,TaskImpl state changes to KILL_WAIT after an AttemptKilledTransition. When the attempt reports that it has actually been killed then KILL_WAIT transitions out via the KillWaitAttemptKilledTransition. Both these transitions send task completion events to Job with the same Killed state.  The handler simply puts them in a list and so nothing bad has happened till now.,Resolved,Not A Problem,,Bikas Saha,Bikas Saha,Wed; 7 Mar 2012 23:03:08 +0000,Wed; 7 Mar 2012 23:16:29 +0000,Wed; 7 Mar 2012 23:16:29 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3985
MAPREDUCE-3986,Bug,Major,,TaskAttemptCompletionEvent not being sent for task attempts that were killed after a sibling attempt succeeds,When TaskImpl transitions to SUCCEEDED then it kills the other running task attempts. In the SUCCEEDED state the TaskImpl state machine ignores T_ATTEMPT_KILLED events from those killed attempts. Hence those completions events are not reported to the job. Every other attempt completion event is reported to the job.,Open,Unresolved,,Bikas Saha,Bikas Saha,Thu; 8 Mar 2012 02:59:31 +0000,Tue; 10 Mar 2015 03:20:56 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3986
YARN-65,Improvement,Major,resourcemanager,Reduce RM app memory footprint once app has completed,The ResourceManager holds onto a configurable number of completed applications (yarn.resource.max-completed-applications; defaults to 10000); and the memory footprint of these completed applications can be significant.  For example; the submissionContext in RMAppImpl contains references to protocolbuffer objects and other items that probably aren't necessary to keep around once the application has completed.  We could significantly reduce the memory footprint of the RM by releasing objects that are no longer necessary once an application completes.,Resolved,Fixed,YARN-6524,Manikandan R,Jason Lowe,Thu; 8 Mar 2012 15:39:18 +0000,Tue; 3 Oct 2017 07:04:25 +0000,Tue; 26 Sep 2017 09:27:57 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/YARN-65
MAPREDUCE-3988,Bug,Major,mrv2,mapreduce.job.local.dir doesn't point to a single directory on a node.,After MAPREDUCE-3975; mapreduce.job.local.dir is set correctly for the tasks but it doesn't point to the same directory for all tasks running on the node.  It is a public API. Either we should point to a single directory or point it to all directories and change the documentation to say that it points to all dirs.,Closed,Fixed,,Eric Payne,Vinod Kumar Vavilapalli,Thu; 8 Mar 2012 19:44:58 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Tue; 3 Apr 2012 18:31:58 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3988
MAPREDUCE-3989,Improvement,Major,,cap space usage of default log4j rolling policy (mr specific changes),see HADOOP-8149 for background on this.,Closed,Fixed,,Patrick Hunt,Patrick Hunt,Thu; 8 Mar 2012 22:41:30 +0000,Mon; 16 Mar 2015 18:41:55 +0000,Thu; 29 Mar 2012 20:55:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3989
MAPREDUCE-3990,Bug,Trivial,benchmarks,MRBench allows Long-sized input-lines value but parses CLI argument as an Integer,MRBench has the following method:     The method is already set to accept a long datatype for numLines; for generating very large amount of data.  However; in MRBench#run(...); the inputLines CLI parameter is parsed via an Integer.parseInt; causing numbers passed  Integer.MAX_VALUE to throw NumberFormatExceptions as a result.  The parsing should be Long.parseLong and the inputLines datatype should be switched to the same type as passed to the method (long).,Resolved,Fixed,,Harsh J,Harsh J,Fri; 9 Mar 2012 05:11:17 +0000,Thu; 12 May 2016 18:22:33 +0000,Mon; 28 May 2012 13:27:08 +0000,,2.0.0-alpha,mrbench,,,https://issues.apache.org/jira/browse/MAPREDUCE-3990
MAPREDUCE-3991,Improvement,Trivial,documentation,Streaming FAQ has some wrong instructions about input files splitting,"Steaming docs say; at: http: streaming.html#How+do+I+process+files%2C+one+per+map%3F  ""Generate a file containing the full HDFS path of the input files. Each map task would get one file name as input.""  This is incorrect; as a file isn't split by lines; rather by size - for MR.",Closed,Fixed,,Harsh J,Harsh J,Fri; 9 Mar 2012 05:34:44 +0000,Wed; 23 May 2012 20:28:28 +0000,Fri; 9 Mar 2012 21:23:07 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3991
MAPREDUCE-3992,Bug,Major,mrv1,Reduce fetcher doesn't verify HTTP status code of response,"Currently; the reduce fetch code doesn't check the HTTP status code of the response. This can lead to the following situation:  	the map output servlet gets an IOException after setting the headers but before the first call to flush() 	this causes it to send a response with a non-OK result code; including the exception text as the response body (response.sendError() does this if the response isn't committed) 	it will still include the response headers indicating it's a valid response    In the case of a merge-to-memory; the compression codec might then try to interpret the HTML response as compressed data; resulting in either a huge allocation (OOME) or some other nasty error. This bug seems to be present in MR1; but haven't checked trunk MR2 yet.",Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 9 Mar 2012 08:42:26 +0000,Tue; 10 Mar 2015 04:32:01 +0000,Sat; 24 Mar 2012 23:38:11 +0000,,0.23.1;1.0.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3992
MAPREDUCE-3993,Bug,Major,mrv1;mrv2,Graceful handling of codec errors during decompression,When using a compression codec for intermediate compression; some cases of corrupt data can cause the codec to throw exceptions other than IOException (eg  lang.InternalError). This will currently cause the whole reduce task to fail; instead of simply treating it like another case of a failed fetch.,Closed,Fixed,,Karthik Kambatla,Todd Lipcon,Fri; 9 Mar 2012 08:44:25 +0000,Mon; 3 Nov 2014 18:05:46 +0000,Mon; 9 Jul 2012 19:22:08 +0000,,0.23.1;1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3993
MAPREDUCE-3994,Test,Major,mrv2;test,Port TestEmptyJob to maven; possibly using the MiniMRYarnCluster,TestEmptyJob started failing recently.  MAPREDUCE-3982 fixes that failure; but it would have been good to have the test as part of maven so that the failure would have been caught long before it was checked in.  The test currently uses the MRMiniCluster; but it does some things with synchronization that are not currently available in the MiniMRYarnCluster.  Before just moving the test over; we need to better understand what the intention of the test is; and if it should just be deleted; if there are other tests that cover it.,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Fri; 9 Mar 2012 14:59:31 +0000,Wed; 18 Apr 2012 19:58:21 +0000,,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3994
YARN-119,Sub-task,Minor,,Add support for  static service lifecycle listeners .,Add support to AbstractService that allow callers to register listeners for all instances. The existing listener interface could be used. This allows management tools to hook into the events.  The static listeners would be invoked for all state changes except creation (base class shouldn't be handing out references to itself at this point).  These static events could all be async; pushed through a shared ConcurrentLinkedQueue; failures logged at warn and the rest of the listeners invoked.,Resolved,Duplicate,YARN-530,Steve Loughran,Steve Loughran,Fri; 9 Mar 2012 17:14:52 +0000,Thu; 2 May 2013 02:29:50 +0000,Tue; 9 Apr 2013 22:56:19 +0000,,,management,,,https://issues.apache.org/jira/browse/YARN-119
MAPREDUCE-3996,Bug,Major,mrv2,zookeeper artifact is missing from the hadoop-dist assembly,According to maven; zookeeper happens to be a dependency of hadoop-yarn-server-common. Yet it is missing from the final distribution assembly (and hence from the binary tarball),Resolved,Not A Problem,,Unassigned,Roman Shaposhnik,Fri; 9 Mar 2012 18:09:05 +0000,Tue; 5 Jun 2012 20:03:30 +0000,Tue; 5 Jun 2012 20:03:29 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3996
MAPREDUCE-3997,Bug,Minor,,jobhistory.jsp cuts off the job name at the first underscore of the job name,For jobs whose name contains an underscore character; jobhistory.jsp cuts off the job name at the first underscore of the job name.,Open,Unresolved,,Unassigned,Bill Au,Thu; 16 Dec 2010 21:41:15 +0000,Fri; 9 Mar 2012 18:14:49 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3997
MAPREDUCE-3998,Bug,Critical,task-controller,taskjvm.sh: Permission denied,run a simple code under cdh3u3; the slave node's map task and reduce task failed; this is the error info from the tasktracker's log: 2012-03-09 17:25:56;562 WARN org.apache.hadoop.mapred.DefaultTaskController: Exit code from task is : 126 2012-03-09 17:25:56;563 WARN org.apache.hadoop.mapred.DefaultTaskController: Task wrapper stderr: bash:   is properly set,Resolved,Invalid,,Unassigned,toughman,Mon; 12 Mar 2012 06:34:35 +0000,Tue; 10 Jul 2012 21:14:34 +0000,Tue; 10 Jul 2012 21:14:34 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3998
MAPREDUCE-3999,Bug,Major,mrv2;webapps,Tracking link gives an error if the AppMaster hasn't started yet,"Courtesy Siddharth Seth  ""The MRAppMaster died before writing anything.""  Steps to generate the error: 1. Setup a queue with 1 max active application per user 2. Submit a long running job to this queue. 3. Submit another job to the queue as the same user. Access the tracking URL for job 2 directly or via Oozie (not via the RM link - which is rewritten once the app starts).  This would exist in situations where the queue doesn't have enough capacity - or for the small period of time between app submission and AM start.",Closed,Fixed,,Ravi Prakash,Ravi Prakash,Mon; 12 Mar 2012 20:35:01 +0000,Fri; 7 Sep 2012 21:03:35 +0000,Tue; 3 Apr 2012 19:39:56 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-3999
MAPREDUCE-4000,Bug,Minor,pipes,Create jobTokenPassword file fail when run hadoop pipes  locally,"Create jobTokenPassword file fail when run hadoop pipes  locally.  I have put such settings in my job conf.     This job has one map task ;and one reduce task. It will fail when running PipesReducer; because ""jobTokenPassword"" file is created at current working directory;with permission 0400.      So; it will fail at the second time.  In such situation;the application cannot be initialized; but the PipesReducer.close() method will be called after that ;so there will be NullPointer Exception raise in close() method.",Open,Unresolved,,Unassigned,Changming Sun,Tue; 13 Mar 2012 07:15:12 +0000,Tue; 1 Jan 2013 23:22:30 +0000,,,1.0.1;1.0.2;0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4000
MAPREDUCE-4001,Improvement,Minor,capacity-sched,Improve MAPREDUCE-3789's fix logic by looking at job's slot demands instead,In MAPREDUCE-3789; the fix had unfortunately only covered the first time assignment scenario; and the test had not really caught the mistake of using the condition of looking at available TT slots (instead of looking for how many slots a job's task demands).  We should change the condition of reservation in such a manner:     I had not realized during the earlier ticket that j.getNumSlotsPerTask(type) did exist.,Closed,Fixed,,Harsh J,Harsh J,Tue; 13 Mar 2012 13:11:21 +0000,Wed; 17 Oct 2012 18:27:26 +0000,Tue; 13 Mar 2012 21:32:02 +0000,,1.1.0,,,MAPREDUCE-516,https://issues.apache.org/jira/browse/MAPREDUCE-4001
MAPREDUCE-4002,Bug,Major,examples,MultiFileWordCount job fails if the input path is not from default file system,In the MultiFileWordCount#CombineFileLineRecordReader; filesystem object has been initialized in the following way     This causes; fs to be initialized with default filesystem. Therefore fs searchs for the input files on the default file system; which fails if the input path is from different source.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Tue; 13 Mar 2012 13:32:30 +0000,Tue; 10 Mar 2015 04:31:41 +0000,Sun; 20 May 2012 07:42:48 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4002
MAPREDUCE-4003,Bug,Major,task-controller;tasktracker,log.index (No such file or directory) AND Task process exit with nonzero status of 126,"hello I have dwelled on this hadoop(cdhu3) problem for 2 days;I have tried every google method.This is the issue: when ran hadoop example ""wordcount"" ;the tasktracker's log in one slave node presented such errors   1.WARN org.apache.hadoop.mapred.DefaultTaskController: Task wrapper stderr: bash:  log.index (No such file or directory)  I could not find similar issues in google;just got some posts seem a little relevant ;which suggest: A. the ulimit of hadoop user---but my ulimit is set large enough for this bundled example;B. the memory used by jvm;but my jvm only use Xmx200m;too small to exceed the limit of my machine ;C.the privilege of the mapred.local.dir and logs dir--I set them by ""chmod 777"";D .the disk space is full---there are enough space for hadoop in my log directory and mapred.local.dir.  Thanks for you all;I am really at my wit's end;I have spend days on it. I really appreciate any light!",Closed,Fixed,,Koji Noguchi,toughman,Tue; 13 Mar 2012 13:43:09 +0000,Wed; 16 May 2012 20:45:18 +0000,Tue; 10 Apr 2012 21:14:21 +0000,,0.20.205.0;1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4003
HADOOP-8225,Bug,Blocker,security,DistCp fails when invoked by Oozie,When DistCp is invoked through a proxy-user (e.g. through Oozie); the delegation-token-store isn't picked up by DistCp correctly. One sees failures such as:  ERROR main org.apache.hadoop.tools.DistCp: Couldn't complete DistCp operation:   142)  Looking over the DistCp code; one sees that HADOOP_TOKEN_FILE_LOCATION isn't being copied to mapreduce.job.credentials.binary; in the job-conf. I'll post a patch for this shortly.,Closed,Fixed,,Daryn Sharp,Mithun Radhakrishnan,Tue; 13 Mar 2012 20:33:53 +0000,Thu; 12 May 2016 18:21:31 +0000,Thu; 23 Aug 2012 18:11:31 +0000,,0.23.1;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/HADOOP-8225
MAPREDUCE-4005,Bug,Major,mrv2,AM container logs URL is broken for completed apps when log aggregation is enabled,"With log aggregation enabled and yarn.log.server.url pointing to the job history server; the AM container logs URL for a completed application fails with the error ""Cannot get container logs without an app owner"".  Looking at the code in the nodemanager to handle redirects to the log server; it appears the AM container log URL is missing a user name for the job.  I verified that tacking on the app's user name after the AM container log URL reported by the RM works.",Resolved,Fixed,,Jason Lowe,Jason Lowe,Tue; 13 Mar 2012 20:42:02 +0000,Sat; 17 Mar 2012 13:58:34 +0000,Fri; 16 Mar 2012 18:49:38 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4005
MAPREDUCE-4006,Bug,Major,jobhistoryserver;mrv2,history server container log web UI sometimes combines stderr/stdout/syslog contents together,When log aggregation is enabled; going to the job history server UI for the AM container log can show the log contents combined together.  Examples I've seen are portions of the syslog contents appended to either the stderr or stdout contents.  The log corruption does not occur when using the mapred job -logs command; so this appears to be something specific to the history server web UI.,Resolved,Fixed,,Siddharth Seth,Jason Lowe,Tue; 13 Mar 2012 21:07:39 +0000,Sat; 17 Mar 2012 13:58:34 +0000,Fri; 16 Mar 2012 20:18:11 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4006
MAPREDUCE-4007,Bug,Major,mrv2,JobClient getJob(JobID) should return NULL if the job does not exist (for backwards compatibility),To preserve backwards compatibility with MR1 JobClient.getJob() should return NULL if the job does not exist.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 13 Mar 2012 22:20:13 +0000,Tue; 10 Mar 2015 04:32:53 +0000,Wed; 14 Mar 2012 22:04:13 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4007
MAPREDUCE-4008,Bug,Major,mrv2;scheduler,ResourceManager throws MetricsException on start up saying QueueMetrics MBean already exists,nan,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 14 Mar 2012 10:08:39 +0000,Thu; 12 May 2016 18:24:48 +0000,Mon; 16 Apr 2012 18:08:53 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4008
MAPREDUCE-4009,Bug,Minor,mrv2;webapps,AM container log links need to be clicked twice to get to the actual log file,"On the RM page-click on an application-Click on the link for ""AM Container logs"" This page contains links to stdout; stderr and syslog (i.e. hostname ?start=-4096",Resolved,Duplicate,MAPREDUCE-4005,Unassigned,Ravi Prakash,Wed; 14 Mar 2012 19:03:05 +0000,Fri; 16 Mar 2012 19:39:10 +0000,Fri; 16 Mar 2012 19:39:10 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4009
MAPREDUCE-4010,Bug,Critical,mrv2,TestWritableJobConf fails on trunk,"TestWritableJobConf is currently failing two tests on trunk:   	testEmptyConfiguration 	testNonEmptyConfiguration    Appears to have been caused by HADOOP-8167.",Closed,Fixed,MAPREDUCE-4011,Alejandro Abdelnur,Jason Lowe,Wed; 14 Mar 2012 20:57:15 +0000,Tue; 10 Mar 2015 04:32:21 +0000,Fri; 16 Mar 2012 14:41:42 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4010
MAPREDUCE-4011,Bug,Major,test,fix TestWritableJobConf failures,I think I broke this testcase with HADOOP-8167 as now deprecated non-deprecated keys show in the iterator.,Closed,Duplicate,MAPREDUCE-4010,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 14 Mar 2012 21:47:44 +0000,Tue; 10 Mar 2015 04:32:24 +0000,Wed; 14 Mar 2012 21:52:52 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4011
MAPREDUCE-4012,Bug,Minor,,Hadoop Job setup error leaves no useful info to users (when LinuxTaskController is used),When distributed cache pull fail on the TaskTracker; job webUI only shows    leaving users confused.    On the TaskTracker log; there is a log with useful info,Closed,Fixed,,Thomas Graves,Koji Noguchi,Wed; 14 Mar 2012 22:57:59 +0000,Thu; 17 Oct 2013 17:50:52 +0000,Tue; 3 Apr 2012 15:44:42 +0000,,0.20.205.0;1.0.0;2.0.0-alpha,,,MAPREDUCE-5589,https://issues.apache.org/jira/browse/MAPREDUCE-4012
MAPREDUCE-4013,Bug,Blocker,mrv2,Reduce task gets stuck when a M/R job is configured to tolerate failures,When a M R job is configured to run with some tolerance to task failures (via mapreduce.map.failures.maxpercent); then the reduce task of that job gets stuck in the shuffle phase.,Resolved,Duplicate,MAPREDUCE-3927,Unassigned,Amar Kamat,Thu; 15 Mar 2012 10:31:41 +0000,Mon; 28 Sep 2015 21:10:30 +0000,Tue; 27 Mar 2012 01:37:28 +0000,,0.23.2,shuffle,,,https://issues.apache.org/jira/browse/MAPREDUCE-4013
YARN-120,Sub-task,Major,,Make yarn-common services robust,Review the yarn common services (CompositeService; AbstractLivelinessMonitor and make their service startup and especially shutdown more robust against out-of-lifecycle invocation and partially complete initialization.  Write tests for these where possible.,Resolved,Duplicate,YARN-530,Steve Loughran,Steve Loughran,Thu; 15 Mar 2012 14:28:34 +0000,Wed; 10 Sep 2014 23:16:28 +0000,Tue; 2 Apr 2013 17:48:16 +0000,,,yarn,,,https://issues.apache.org/jira/browse/YARN-120
YARN-121,Sub-task,Minor,,Yarn services to throw a YarnException on invalid state changs,the EnsureCurrentState() checks of services throw an IllegalStateException  if the state is wrong. If this was changed to YarnException. wrapper services such as CompositeService could relay this direct; instead of wrapping it in their own.  Time to implement mainly in changing the lifecycle test cases of MAPREDUCE-3939 subtasks.,Resolved,Duplicate,YARN-530,Steve Loughran,Steve Loughran,Thu; 15 Mar 2012 16:18:56 +0000,Wed; 10 Sep 2014 23:16:54 +0000,Tue; 2 Apr 2013 17:47:48 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-121
YARN-122,Sub-task,Minor,,CompositeService should clone the Configurations it passes to children,CompositeService.init(Configuration) saves the configuration passed in and passes the same instance down to all managed services. This means a change in the configuration of one child could propagate to all the others.  Unless this is desired; the configuration should be cloned for each child.  Fast and easy fix; tests can be added to those coming in MAPREDUCE-4014,Resolved,Invalid,,Unassigned,Steve Loughran,Thu; 15 Mar 2012 16:36:21 +0000,Thu; 2 May 2013 02:29:50 +0000,Tue; 9 Apr 2013 15:25:34 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-122
MAPREDUCE-4017,Improvement,Trivial,jobhistoryserver;jobtracker,Add jobname to jobsummary log,"We occasionally use jobsummary from the JobTracker to collect users' slot usage on our clusters.  It would be useful if the jobname was part of this jobsummary so that I don't need to join with other logs.  Same jobsummary.   2012-03-15 16:05:55;919 INFO mapred.JobInProgress$JobSummary: jobId=job_201202160624_1089972;submitTime=1331827523632;launchTime=1331827528197;firstMapTaskLaunchTime=1331827536917;firstReduceTaskLaunchTime=1331827541251;firstJobSetupTaskLaunchTime=1331827528200;firstJobCleanupTaskLaunchTime=1331827551655;finishTime=1331827555919;numMaps=1;numSlotsPerMap=1;numReduces=1;numSlotsPerReduce=1;user=tortuga;queue=queue1;status=SUCCEEDED;mapSlotSeconds=13;reduceSlotsSeconds=10;clusterMapCapacity=___;clusterReduceCapacity=___  I'd like to see ""jobName"" added to the end.",Closed,Fixed,,Thomas Graves,Koji Noguchi,Thu; 15 Mar 2012 20:57:52 +0000,Fri; 7 Sep 2012 21:03:34 +0000,Tue; 10 Apr 2012 20:40:06 +0000,,0.20.205.0;0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4017
MAPREDUCE-4018,Bug,Major,distributed-cache,including multiple user jar files into class path is not working,"I am trying to submit a job which is using some third-party libs. I tried both -libjars and DistributedCache directly. Both are not working until I merge all jar files into one big jar file.  The way I am using -libjars: -libjars path file2.jar""); conf; hdfs);  The error messages I observed would have been changing if I have different number of jars in the path. It looks like only one of the jars would be in the classpath for any submission. So I decided to merge all jar files into one big jar file and try again. Now it works. It looks like there is a bug to include multiple jar files into classpath.",Open,Unresolved,,Unassigned,Weili Shao,Fri; 16 Mar 2012 00:35:38 +0000,Fri; 16 Mar 2012 00:35:38 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4018
MAPREDUCE-4019,Bug,Minor,client,#NAME?,while executing    ; we are getting IllegalArgumentexception.,Closed,Fixed,MAPREDUCE-4120,Ashwin Shankar,B Anil Kumar,Fri; 16 Mar 2012 02:26:01 +0000,Thu; 12 May 2016 18:22:23 +0000,Thu; 13 Jun 2013 21:48:15 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4019
MAPREDUCE-4020,Bug,Major,mrv2;webapps,Web services returns incorrect JSON for deep queue tree,"When the capacity scheduler is configured for more than two levels of queues; the web services API returns incorrect JSON for the subQueues field of some parent queues.  The ""subQueues"" field for parent queues should always be an array; but sometimes the field appears multiple times for a queue and as what looks like a CapacityQueueInfo object instead of an array.  Besides the sometimes-an-array-sometimes-not problem; parsing the result into a JSON object causes all but the last ""subQueues"" field to be discarded since they are overwritten by subsequent fields with the same name.",Closed,Fixed,,Anupam Seth,Jason Lowe,Fri; 16 Mar 2012 04:27:44 +0000,Tue; 12 May 2015 08:18:15 +0000,Tue; 3 Apr 2012 20:43:36 +0000,,0.23.1,,,YARN-2336,https://issues.apache.org/jira/browse/MAPREDUCE-4020
YARN-123,Sub-task,Minor,,Make yarn Resource Manager services robust against shutdown,Split MAPREDUCE-3502 patches to make the RM code more resilient to being stopped more than once; or before started.  This depends on MAPREDUCE-4014.,Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 16 Mar 2012 15:16:55 +0000,Tue; 27 Aug 2013 22:15:12 +0000,Thu; 13 Jun 2013 16:56:37 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-123
YARN-124,Sub-task,Minor,,Make Yarn Node Manager services robust against shutdown,Add the nodemanager bits of MAPREDUCE-3502 to shut down the Nodemanager services. This is done by checking for fields being non-null before shutting down closing etc; and setting the fields to null afterwards -to be resilient against re-entrancy.  No tests other than manual review.,Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 16 Mar 2012 15:30:00 +0000,Tue; 27 Aug 2013 22:15:41 +0000,Thu; 13 Jun 2013 16:56:57 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-124
YARN-125,Sub-task,Minor,,Make Yarn Client service shutdown operations robust,Make the yarn client services more robust against being shut down while not started; or shutdown more than once; by null-checking fields before closing them; setting to null afterwards to prevent double-invocation. This is a subset of MAPREDUCE-3502,Closed,Fixed,,Steve Loughran,Steve Loughran,Fri; 16 Mar 2012 15:35:48 +0000,Tue; 27 Aug 2013 22:15:25 +0000,Thu; 13 Jun 2013 16:57:18 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-125
MAPREDUCE-4024,Bug,Major,mrv2,RM webservices can't query on finalStatus,The resource manager web service api to get the list of apps doesn't have a query parameter for finalStatus.  It has one for the state but since that isn't what is reported by app master so we really need to be able to query on both state and finalStatus.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 16 Mar 2012 16:42:02 +0000,Thu; 2 May 2013 02:29:51 +0000,Mon; 2 Apr 2012 21:09:57 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4024
MAPREDUCE-4025,Bug,Blocker,mr-am;mrv2,AM can crash if task attempt reports bogus progress value,If a task attempt reports a bogus progress value (e.g.: something above 1.0) then the AM can crash like this:,Resolved,Fixed,,Jason Lowe,Jason Lowe,Fri; 16 Mar 2012 20:58:25 +0000,Tue; 20 Mar 2012 21:52:16 +0000,Mon; 19 Mar 2012 20:34:11 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4025
MAPREDUCE-4026,Bug,Major,mrv2;scheduler,Lower minimum-allocation-mb to sensible defaults,"The CapacityScheduler's minimum-allocation-mb is set to 1024.  The FIFO's minimum-allocation-mb meanwhile; is 128.  I propose changing the formers' minimum to that amount as well. 1024 is way too much as a default; wastes ""slots"" on NMs - and I also do not see why CS has to deviate that settings from the FIFO default.",Resolved,Duplicate,MAPREDUCE-3812,Harsh J,Harsh J,Fri; 16 Mar 2012 21:22:24 +0000,Sat; 21 Apr 2012 19:03:48 +0000,Sat; 21 Apr 2012 19:03:03 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4026
MAPREDUCE-4027,Improvement,Minor,resourcemanager,Document the minimum-allocation-mb and maximum-allocation-mb configurations,None of the current yarn.scheduler.fifo.minimum maximum-allocation-mb are documented anywhere. Without knowledge of these params; one can't change the default allocations. And the default allocations are pretty high btw (MAPREDUCE-4026).  We should document these in the Cluster Setup page at least.,Resolved,Duplicate,MAPREDUCE-3812,Harsh J,Harsh J,Fri; 16 Mar 2012 21:40:56 +0000,Sat; 21 Apr 2012 19:04:10 +0000,Sat; 21 Apr 2012 19:03:09 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4027
MAPREDUCE-4028,Bug,Major,capacity-sched,Hadoop Capacity-Scheduler,"I config success capacity-scheduler But when i run job has error:  Queue ""default"" does not exist  this error is :    ERROR security.UserGroupInformation: PriviledgedActionException as:adtech cause:org.apache.hadoop.ipc.RemoteException:  3941)         ... 11 more   i check hadoop queue    hadoop queue -showacls Queue acls for user :  john  Queue  Operations ===================== queue1  submit-job;administer-jobs queue2  submit-job;administer-jobs queue3  submit-job;administer-jobs queue4  submit-job;administer-jobs queue5  submit-job;administer-jobs queue6  submit-job;administer-jobs  my config in mapresite.xml:         property                 namemapred.jobtracker.taskScheduler property",Resolved,Invalid,,Unassigned,cldoltd,Sun; 18 Mar 2012 09:27:59 +0000,Sun; 18 Mar 2012 15:36:41 +0000,Sun; 18 Mar 2012 12:28:42 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4028
MAPREDUCE-4029,Improvement,Major,webapps,NodeManager status web page should express 'last update' times as seconds ago,The 'Last health update' field on the MR2 apps' nodes page (at http: nodes) is a timestamp right now; which isn't really informative for what the field means. It ought to be in seconds-ago from now(); like was the case in JobTracker for heartbeats.,Open,Unresolved,,Unassigned,Harsh J,Sun; 18 Mar 2012 14:02:04 +0000,Wed; 18 Apr 2012 19:58:22 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4029
MAPREDUCE-4030,Bug,Major,mrv2,If the nodemanager on which the maptask is executed is going down before the mapoutput is consumed by the reducer;then the job is failing with shuffle error,"My cluster has 2 NM's. The value of ""mapreduce.job.reduce.slowstart.completedmaps"" is set to 1. When the job execution is in progress and Mappers has finished about 99% completion;one of the NM has gone down. The job has failed with the following trace  ""Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1  org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 152) """,Resolved,Not A Problem,,Unassigned,Nishan Shetty,Mon; 19 Mar 2012 05:42:31 +0000,Wed; 30 May 2012 11:14:54 +0000,Wed; 30 May 2012 11:14:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4030
MAPREDUCE-4031,Bug,Critical,mrv2;nodemanager,Node Manager hangs on shut down,"I have the MAPREDUCE-3862 changes which fixed this issue earlier and ""yarn.nodemanager.delete.debug-delay-sec"" set to default value but still getting this issue.",Closed,Fixed,,Devaraj K,Devaraj K,Mon; 19 Mar 2012 09:02:04 +0000,Thu; 12 May 2016 18:23:24 +0000,Fri; 22 Jun 2012 21:47:59 +0000,,0.23.2;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4031
MAPREDUCE-4032,Bug,Major,contrib/streaming,org.apache.hadoop.util.RunJar continues to run even after Hadoop Streaming Job is killed,"  INFO streaming.StreamJob:  hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201203190407_0001  Using the ""-kill"" option shown above only kills the ""org.apache.hadoop.mapred.Child"" processes; but the ""org.apache.hadoop.util.RunJar"" process continues to execute.",Open,Unresolved,,Unassigned,Rahul Rudradevan,Mon; 19 Mar 2012 11:20:47 +0000,Thu; 24 Sep 2015 16:06:56 +0000,,,1.0.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4032
MAPREDUCE-4033,Bug,Critical,mrv2,MiniMRClientClusterFactory is not setting the temp dir correctly in the conf used to init MiniMRYarnCluster,Oozie testcases are failing randomly because MR2 reports the job as unknown.  This seems to happen when Oozie queries via JobClient.getJob(JOBID) for a JOBID that just finished.     Oozie reports this error when JobClient.getJob(JOBID) returns NULL.  Looking at the mini cluster logs the job definitely run.     It seems there is a gap until the the job is avail in the JH server.   If this gap is unavoidable we need to ensure Oozie always waits at least the gap time before querying for a job.,Closed,Invalid,,Alejandro Abdelnur,Alejandro Abdelnur,Mon; 19 Mar 2012 17:28:36 +0000,Wed; 23 May 2012 20:28:25 +0000,Fri; 30 Mar 2012 11:52:38 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4033
MAPREDUCE-4034,Bug,Blocker,mrv2,Unable to view task logs on history server with mapreduce.job.acl-view-job=*,With log aggregation enabled; users other than the app owner or admins are sometimes unable to view the task logs on the history server even though they are in the ACL for the app.  The same users are able to see the configuration and counters.  Sometimes the users can see some task logs but not other task logs for the same application.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Tue; 20 Mar 2012 02:19:13 +0000,Tue; 20 Mar 2012 21:52:16 +0000,Tue; 20 Mar 2012 16:33:41 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4034
MAPREDUCE-4035,Bug,Minor,build,why is there no javadoc; sources jars published in the maven repo for hadoop-core 0.20.2*; 1.0.X?,Why is there no  oc; sources jars published in the maven repo for hadoop-core 0.20.2*; 1.0.X?,Open,Unresolved,HADOOP-8498;HADOOP-8363,Unassigned,Jim Donofrio,Tue; 20 Mar 2012 03:25:12 +0000,Fri; 16 May 2014 17:34:30 +0000,,,0.20.2;0.20.203.0;0.20.204.0;0.20.205.0;1.0.0;1.0.1;1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4035
MAPREDUCE-4036,Bug,Major,test,Streaming TestUlimit fails on CentOS 6,CentOS 6 seems to have higher memory requirements than other distros and together with the new MALLOC library makes the TestUlimit to fail with exit status 134.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 20 Mar 2012 04:36:31 +0000,Wed; 15 May 2013 05:16:16 +0000,Wed; 1 Aug 2012 17:30:06 +0000,,1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4036
MAPREDUCE-4037,Bug,Critical,mrv2,Fails to start proxy server due to webapps/proxy not found in CLASSPATH,nan,Resolved,Duplicate,MAPREDUCE-3916,Unassigned,Devaraj K,Tue; 20 Mar 2012 05:32:01 +0000,Fri; 30 Mar 2012 12:27:18 +0000,Fri; 30 Mar 2012 12:27:18 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4037
MAPREDUCE-4038,Bug,Critical,jobtracker,null pointer exception and invocationtarget exception in jobtracker logs,I have written the code for scheduling in hadoop in which i have written two function schedule() and call() the schedule function calls the resource calculator for knowing the CPU usage and reliability values(explicitly i gave) but i am getting null pointer exception in the end. even i have written the code for getting active tracker names it shows null pointer exception. help me!  ERROR IN JOB TRACKER LOG FILE  2012-03-12 14:37:01;198 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG:   ,Resolved,Invalid,,Unassigned,gan,Tue; 20 Mar 2012 05:39:39 +0000,Tue; 20 Mar 2012 05:48:27 +0000,Tue; 20 Mar 2012 05:48:26 +0000,,0.20.1,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4038
MAPREDUCE-4039,New Feature,Minor,mrv2,Sort Avoidance,"Inspired by Tenzing; in 5.1 MapReduce Enhanceemtns: Sort Avoidance. Certain operators such as hash join and hash aggregation require shuffling; but not sorting. The MapReduce API was enhanced to automatically turn off sorting for these operations. When sorting is turned off; the mapper feeds data to the reducer which directly passes the data to the Reduce() function bypassing the intermediate sorting step. This makes many SQL operators significantly more ecient.  There are a lot of applications which need aggregation only; not sorting.Using sorting to achieve aggregation is costly and inefficient. Without sorting; up application can make use of hash table or hash map to do aggregation efficiently.But application should bear in mind that reduce memory is limited; itself is committed to manage memory of reduce; guard against out of memory. Map-side combiner is not supported; you can also do hash aggregation in map side  as a workaround.  the following is the main points of sort avoidance implementation  	add a configuration parameter mapreduce.sort.avoidance; boolean type; to turn on hadoop for details. Now;I'm willing to port it into yarn. Welcome for commenting.",Open,Unresolved,,anty,anty.rao,Tue; 20 Mar 2012 07:58:04 +0000,Mon; 28 Jan 2013 21:31:42 +0000,,,0.23.2,,,MAPREDUCE-2454,https://issues.apache.org/jira/browse/MAPREDUCE-4039
MAPREDUCE-4040,Bug,Minor,jobhistoryserver;mrv2,History links should use hostname rather than IP address.,While navigating from web page (eg:  app-id ) to HS; browser displays IP address rather than hostname.       I think it is better to use hostname rather than IP address.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Tue; 20 Mar 2012 14:29:03 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Wed; 11 Apr 2012 02:53:01 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4040
MAPREDUCE-4041,Bug,Major,mrv2,TestMapredGroupMappingServiceRefresh unit test failures,"On branch-0.23 the following unit tests fail:  &gt; org.apache.hadoop.security.TestMapredGroupMappingServiceRefresh.testGroupMappingRefresh 	 &gt; org.apache.hadoop.security.TestMapredGroupMappingServiceRefresh.testRefreshSuperUserGroupsConfiguration",Resolved,Not A Problem,,Unassigned,Thomas Graves,Tue; 20 Mar 2012 20:49:33 +0000,Fri; 24 May 2013 14:47:08 +0000,Fri; 24 May 2013 14:47:08 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4041
MAPREDUCE-4042,Bug,Major,mrv2,unit test TestControlledMapReduceJob.testControlledMapReduceJob  fails,unit test TestControlledMapReduceJob.testControlledMapReduceJob  fails.  This is an ant test: ant test -Dtestcase=TestControlledMapReduceJob  error: Timeout occurred. Please note the time in the report does not reflect the time until the timeout.,Resolved,Not A Problem,,Unassigned,Thomas Graves,Tue; 20 Mar 2012 20:54:13 +0000,Fri; 24 May 2013 14:41:32 +0000,Fri; 24 May 2013 14:41:32 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4042
MAPREDUCE-4043,Bug,Blocker,mrv2;security,Secret keys set in Credentials are not seen by tasks,The following scenario works in 0.20.205 but no longer works in 0.23:  1) During job submission; a secret key is set by calling jobConf.getCredentials().addSecretKey(Text; byte[]) 2) A map task retrieves the secret key by calling jobConf.getCredentials().getSecretKey(Text)  In 205 the secret key is retrieved successfully but in 0.23 the secret key is missing.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Wed; 21 Mar 2012 01:39:13 +0000,Sat; 24 Mar 2012 13:58:26 +0000,Fri; 23 Mar 2012 20:54:43 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4043
MAPREDUCE-4044,Bug,Major,mrv2,YarnClientProtocolProvider does not honor mapred.job.tracker property,The YarnClientProtocolProvider ResourceMgrDelegate bootstrap only looks for 'yarn.resourcemanager.address'; they ignore 'mapred.job.tracker'  This breaks backward compatibility and creates issues in Oozie.,Resolved,Not A Problem,,Unassigned,Alejandro Abdelnur,Wed; 21 Mar 2012 03:42:52 +0000,Tue; 10 Mar 2015 04:31:42 +0000,Tue; 14 Aug 2012 21:27:12 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4044
MAPREDUCE-4045,Bug,Major,mrv2,RM UI -> Applications -> Application Master Link -> Job Link -> New Maps/Reduces leads to circular redirect error,nan,Resolved,Duplicate,MAPREDUCE-3706,Unassigned,Devaraj K,Wed; 21 Mar 2012 05:13:25 +0000,Fri; 4 Mar 2016 05:51:08 +0000,Fri; 4 Mar 2016 05:50:04 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4045
MAPREDUCE-4046,Bug,Major,,"Task Log stdout and stderr don't honor the property ""mapred.userlog.limit.kb""",nan,Open,Unresolved,,Unassigned,Devaraj K,Wed; 21 Mar 2012 05:36:23 +0000,Wed; 28 Mar 2012 03:43:29 +0000,,,1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4046
MAPREDUCE-4047,Bug,Major,mrv2,NullPointerException during the map task merge phase,While executing the tera sort with 1TB data; got the below exception,Open,Unresolved,,Unassigned,Devaraj K,Wed; 21 Mar 2012 09:56:28 +0000,Wed; 30 May 2012 11:06:15 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4047
MAPREDUCE-4048,Bug,Major,mrv2,NullPointerException exception while accessing the Application Master UI,nan,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 21 Mar 2012 10:01:09 +0000,Thu; 12 May 2016 18:24:20 +0000,Fri; 4 May 2012 15:05:55 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4048
MAPREDUCE-4049,Sub-task,Major,performance;task;tasktracker,plugin for generic shuffle service,"Support generic shuffle service as set of two plugins: ShuffleProvider  ShuffleConsumer. This will satisfy the following needs:  	Better shuffle and merge performance. For example: we are working on shuffle plugin that performs shuffle over RDMA in fast networks (10gE; 40gE; or Infiniband) instead of using the current HTTP shuffle. Based on the fast RDMA shuffle; the plugin can also utilize a suitable merge approach during the intermediate merges. Hence; getting much better performance. 	Satisfy MAPREDUCE-3060 - generic shuffle service for avoiding hidden dependency of NodeManager with a specific version of mapreduce shuffle (currently targeted to 0.24.0).    References:  	Hadoop Acceleration through Network Levitated Merging; by Prof. Weikuan Yu from Auburn University with others; http: pages.php?pg=products_dynproduct_family=144menu_section=69",Closed,Fixed,,Avner BenHanoch,Avner BenHanoch,Wed; 21 Mar 2012 12:19:05 +0000,Thu; 12 May 2016 18:24:16 +0000,Tue; 11 Dec 2012 14:29:10 +0000,,1.0.3;1.1.0;2.0.0-alpha;3.0.0-alpha1,merge;plugin;rdma;shuffle,,MAPREDUCE-5329;MAPREDUCE-4812;MAPREDUCE-2454;MAPREDUCE-3060;MAPREDUCE-4977,https://issues.apache.org/jira/browse/MAPREDUCE-4049
MAPREDUCE-4050,Bug,Major,mrv2,Invalid node link,When a task is in UNASSIGNED state; node link is displayed as null. But I think it is better to display the link as N A rather than null.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Wed; 21 Mar 2012 14:07:49 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Thu; 12 Apr 2012 18:41:55 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4050
MAPREDUCE-4051,Task,Major,,Remove the empty hadoop-mapreduce-project/assembly/all.xml file,"Jenkins picks up this XML and looks for ""test results"" in it. This file should be empty and removed. I could tell Jenkins not to pick this file up; but I'd rather also remove this empty file.",Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 21 Mar 2012 15:22:45 +0000,Fri; 7 Sep 2012 21:03:35 +0000,Fri; 6 Apr 2012 18:11:15 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4051
MAPREDUCE-4052,Bug,Major,job submission,Windows eclipse cannot submit job from Windows client to Linux/Unix Hadoop cluster.,"when I use the eclipse on the windows to submit the job. and the applicationmaster throw the exception: Exception in thread ""main""  248) Could not find the main class: org.apache.hadoop.mapreduce.v2.app.MRAppMaster.  Program will exit.  The reasion is : class Apps addToEnvironment function; use the private static final String SYSTEM_PATH_SEPARATOR =       System.getProperty(""path.separator"");  and will result the MRApplicationMaster classpath use the "";"" separator.  I suggest that nodemanger do the replace.",Closed,Fixed,YARN-1298;MAPREDUCE-5655,Jian He,xieguiming,Thu; 22 Mar 2012 05:01:16 +0000,Thu; 5 Feb 2015 05:17:37 +0000,Sun; 16 Mar 2014 19:15:10 +0000,,0.23.1;2.2.0,,,YARN-1824,https://issues.apache.org/jira/browse/MAPREDUCE-4052
MAPREDUCE-4053,Bug,Major,mrv2,Counters group names deprecation is wrong; iterating over group names deprecated names don't show up,This is similar to the deprecation of Configuration properties bug HADOOP-8167; interator() retrieval of counter names only returns new names.  Oozie breaks here because it is using the deprecate name and iterating over values (OOZIE-777). While it can be worked around easily in Oozie; this is breaking backwards compatibility.,Closed,Fixed,MAPREDUCE-4538;MAPREDUCE-4539,Robert Joseph Evans,Alejandro Abdelnur,Thu; 22 Mar 2012 05:14:59 +0000,Tue; 10 Mar 2015 04:32:30 +0000,Mon; 13 Aug 2012 21:54:26 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4053
HADOOP-8199,Bug,Major,,Fix issues in start-all.sh and stop-all.sh,"1. Warning message  Execute start-all.sh and stop-all.sh scripts it displays message like ""This script is Deprecated. Instead use start-dfs.sh stop yarn",Closed,Fixed,,Devaraj K,Nishan Shetty,Thu; 22 Mar 2012 08:51:26 +0000,Tue; 10 Mar 2015 02:35:08 +0000,Sun; 1 Apr 2012 19:23:40 +0000,,0.23.1,,,HADOOP-7569,https://issues.apache.org/jira/browse/HADOOP-8199
MAPREDUCE-4055,Bug,Major,mrv2,"Job history files are not getting copied from ""intermediate done"" directory to ""done"" directory ",1.Submit job 2.After successful execution of job before the Job history files are copied from intermediate done directory to done directory;NameNode got killed. 3.Restart the NameNode after mapreduce.jobhistory.move.interval-ms time is elapsed(default is 3 min). Observe that Job history files are not copied from intermediate done directory to done directory and also logs are not updated with any message  Now submit another job observe that Job history files are not copied from intermediate done directory to done directory and also nothing is logged into historyserver logs.,Resolved,Fixed,,Unassigned,Nishan Shetty,Thu; 22 Mar 2012 13:43:11 +0000,Fri; 27 Apr 2012 06:20:54 +0000,Fri; 27 Apr 2012 06:20:54 +0000,,,,,MAPREDUCE-3972,https://issues.apache.org/jira/browse/MAPREDUCE-4055
MAPREDUCE-4056,Improvement,Minor,test,Remove MR1 src/test/system,hadoop-mapreduce-project 23.,Resolved,Duplicate,HADOOP-8450,Eli Collins,Eli Collins,Thu; 22 Mar 2012 21:52:02 +0000,Fri; 22 Jun 2012 05:02:23 +0000,Sat; 2 Jun 2012 23:26:10 +0000,,,,,HADOOP-8200,https://issues.apache.org/jira/browse/MAPREDUCE-4056
MAPREDUCE-4057,Bug,Major,contrib/raid,Compilation error in RAID ,nan,Closed,Fixed,,Devaraj K,Tsz Wo Nicholas Sze,Thu; 22 Mar 2012 22:03:38 +0000,Thu; 4 Sep 2014 01:05:57 +0000,Tue; 10 Apr 2012 19:50:51 +0000,,,,,HDFS-3089,https://issues.apache.org/jira/browse/MAPREDUCE-4057
MAPREDUCE-4058,New Feature,Major,task-controller,adjustable task priority,For those of us that completely destroy our CPUs; it is beneficial to be able to run user tasks at a different priority than the tasktracker. This would allow for TTs (and by extension; DNs) to get more CPU clock cycles so that things like heartbeats don't disappear.,Resolved,Won't Fix,,Mark Wagner,Allen Wittenauer,Fri; 23 Mar 2012 01:07:01 +0000,Thu; 17 Jul 2014 15:05:39 +0000,Thu; 17 Jul 2014 15:05:38 +0000,,1.0.0,,,YARN-443,https://issues.apache.org/jira/browse/MAPREDUCE-4058
MAPREDUCE-4059,Improvement,Major,mrv2,The history server should have a separate pluggable storage/query interface,The history server currently caches all parsed jobs in RAM.  These jobs can be very large because of counters.  It would be nice to have a pluggable interface for the cacheing and querying of the cached data so that we can play around with different implementations.  Also just for cleanness of the code it would be nice to split the very large JobHistoryServer. into a few smaller ones that are more understandable and readable.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 23 Mar 2012 14:59:45 +0000,Tue; 10 Mar 2015 04:31:51 +0000,Tue; 10 Apr 2012 18:15:01 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4059
MAPREDUCE-4060,Bug,Major,build,Multiple SLF4J binding warning,This is the MAPREDUCE portion of HADOOP-8005.  We should remove slf4j from the assembly and use the one provided by hadoop-common so we don't end up with multiple binding warnings for SLF4J.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 23 Mar 2012 21:21:31 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Tue; 3 Apr 2012 14:25:10 +0000,,0.23.0,,,HADOOP-8005,https://issues.apache.org/jira/browse/MAPREDUCE-4060
MAPREDUCE-4061,Bug,Blocker,mrv2,RM only has 1 AM launcher thread,The application master launcher has a thread pool that is configured with core size 1; maximum 10.  The thread pool will not create over the core size thread unless the queue it is using is full. We are using an unbounded queue; so the thread pool will only ever create 1 thread.  We need to have more then 1 AM launch thread.  If that thread becomes hung for some reason; the RM can no longer launch any application masters.  We have seen an instance of this when a NM become unresponsive - something bad happened to host; not sure what yet.,Resolved,Fixed,,Thomas Graves,Thomas Graves,Fri; 23 Mar 2012 21:36:03 +0000,Mon; 2 Apr 2012 18:38:39 +0000,Mon; 26 Mar 2012 21:27:34 +0000,,0.23.2,,,MAPREDUCE-4062,https://issues.apache.org/jira/browse/MAPREDUCE-4061
MAPREDUCE-4062,Bug,Major,mrv2,AM Launcher thread can hang forever,"We saw an instance where the RM stopped launch Application masters.  We found that the launcher thread was hung because something weird bad happened to the NM node. Currently there is only 1 launcher thread (jira 4061 to fix that). We need this to not happen.  Even once we increase the number of threads  to  1 if that many nodes go bad the RM would be stuck.  Note that this was stuck like this for approximately 9 hours.  Stack trace on hung AM launcher:  ""pool-1-thread-1"" prio=10 tid=0x000000004343e800 nid=0x3a4c in Object.wait() 0x000000004fad2000     619)",Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 23 Mar 2012 21:42:23 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Tue; 3 Apr 2012 17:08:37 +0000,,0.23.2,,,MAPREDUCE-4061,https://issues.apache.org/jira/browse/MAPREDUCE-4062
MAPREDUCE-4063,Improvement,Minor,,make TaggedInputSplit public class for development of MultipleInput of other DB Products extension,In Trunk; org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit is not public class.  This prevents to develop other MultipleInput of DB products extension.  I make workaround file  https:   So unless a reason; TaggedInputSplit should be public,Open,Unresolved,,Unassigned,Muddy Dixon,Sun; 25 Mar 2012 08:36:37 +0000,Sun; 20 Sep 2015 22:35:00 +0000,,,0.23.1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4063
YARN-2246,Bug,Major,webapp,Job History Link in RM UI is redirecting to the URL which contains Job Id twice,nan,Closed,Fixed,,Devaraj K,Devaraj K,Sun; 25 Mar 2012 17:01:41 +0000,Tue; 30 Aug 2016 01:31:06 +0000,Tue; 10 Feb 2015 23:32:35 +0000,,,2.6.1-candidate,,,https://issues.apache.org/jira/browse/YARN-2246
MAPREDUCE-4065,Bug,Major,build,Add .proto files to built tarball,Please add the .proto files to the built tarball so that users can build 3rd party tools that use protocol buffers without having to do an svn checkout of the source code.  Sorry I don't know more about Maven; or I would provide a patch.,Resolved,Won't Fix,,Tsuyoshi Ozawa,Ralph H Castain,Sun; 25 Mar 2012 19:16:12 +0000,Fri; 19 Jun 2015 19:05:44 +0000,Fri; 19 Jun 2015 19:05:29 +0000,,0.23.2;2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4065
MAPREDUCE-4066,Bug,Minor,job submission;mrv2,"To get ""yarn.app.mapreduce.am.staging-dir"" value; should set the default value",when submit the job use the windows eclipse; and the yarn.app.mapreduce.am.staging-dir value is null.     should modify to:,Closed,Fixed,,xieguiming,xieguiming,Mon; 26 Mar 2012 06:46:53 +0000,Wed; 23 May 2012 20:28:28 +0000,Mon; 26 Mar 2012 13:33:04 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4066
MAPREDUCE-4067,Bug,Critical,,Replace YarnRemoteException with IOException in MRv2 APIs,YarnRemoteException is defined as a generic wrapper for all the exceptions in yarn. I think we should instead throw IOExceptions in the API; which can later be extended for more specialized exceptions without breaking compatibility.,Closed,Fixed,,Xuan Gong,Jitendra Nath Pandey,Mon; 26 Mar 2012 16:42:10 +0000,Tue; 27 Aug 2013 22:22:17 +0000,Mon; 13 May 2013 03:36:20 +0000,,,,MAPREDUCE-3955;YARN-142,,https://issues.apache.org/jira/browse/MAPREDUCE-4067
MAPREDUCE-4068,Bug,Blocker,mrv2,Jars in lib subdirectory of the submittable JAR are not added to the classpath,Prior to hadoop 0.23; users could add third party jars to the lib subdirectory of the submitted job jar and they become available in the task's classpath. I see this functionality was in TaskRunner. nor other places).,Closed,Fixed,,Robert Kanter,Ahmed Radwan,Mon; 26 Mar 2012 17:25:01 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Wed; 22 Aug 2012 21:23:54 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4068
MAPREDUCE-4069,Improvement,Minor,mrv2,Cleanup task tokens interface,"This tracks a couple of cleanup issues that were identified in MAPREDUCE-4043:   	It seems unnecessary to pass the job token and credentials separately when we always combine the job token into the credentials before building the container launch context.  The TaskImpl and TaskAttemptImpl constructors could simply take credentials with the job token already added rather than separate job token and credential parameters. 	It's unclear whether we still need the appTokens file that is placed into HDFS by the job submitter; localized by the NM; and finally read in by the AM. I believe the AM's credentials sent in the AM's container launch context already contains the same information.  If that's the case; we should remove the code related to the appTokens file.",Resolved,Duplicate,MAPREDUCE-5199,Unassigned,Jason Lowe,Mon; 26 Mar 2012 19:15:53 +0000,Thu; 13 Jun 2013 20:23:21 +0000,Thu; 13 Jun 2013 20:23:21 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4069
MAPREDUCE-4070,Bug,Major,mrv2,JobHistoryServer creates /tmp directory with restrictive permissions if the directory doesn't already exist.,Starting up the MapReduce JobhHistoryServer service after a clean install appears to automatically create the  tmp directory on HDFS. However; it is created with 750 permission.  Attempting to run MR jobs by other users results in the following permissions exception:,Patch Available,Unresolved,,Ahmed Radwan,Ahmed Radwan,Mon; 26 Mar 2012 21:32:08 +0000,Fri; 8 May 2015 09:06:58 +0000,,,0.23.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4070
MAPREDUCE-4071,Bug,Major,mr-am;mrv2,NPE while executing MRAppMaster shutdown hook,While running the shutdown hook of MRAppMaster; hit NPE,Patch Available,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Tue; 27 Mar 2012 08:41:40 +0000,Wed; 6 May 2015 03:27:22 +0000,,,0.23.3;2.0.0-alpha,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4071
MAPREDUCE-4072,Bug,Major,mrv2,User set java.library.path seems to overwrite default creating problems native lib loading,This was found by Peeyush Bishnoi.  While running a distributed cache example with Hadoop-0.23; tasks are failing as follows: ------------------------------------------------------------------------------------------------------------  Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException:  org.apache.hadoop.security.JniBasedUnixGroupsMapping.(JniBasedUnixGroupsMapping. io.tmpdir= tmp -Dmapred.create.symlink=yes -Dmapred.job.map.memory.mb=3072 piggeoscript.pig,Closed,Fixed,,Anupam Seth,Anupam Seth,Tue; 27 Mar 2012 18:16:32 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Tue; 3 Apr 2012 18:06:19 +0000,,,,,MAPREDUCE-3693,https://issues.apache.org/jira/browse/MAPREDUCE-4072
MAPREDUCE-4073,Bug,Critical,mrv2;scheduler,CS assigns multiple off-switch containers when using multi-level-queues,CS is supposed to be allocating a single off-switch container per node heartbeat (MAPREDUCE-3641). This works for queues directly under root; but not in the case of multi-level queues.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 27 Mar 2012 19:32:58 +0000,Fri; 7 Sep 2012 21:03:35 +0000,Thu; 5 Apr 2012 20:35:08 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4073
MAPREDUCE-4074,Bug,Major,,Client continuously retries to RM When RM goes down before launching Application Master,Client continuously tries to RM and logs the below messages when the RM goes down before launching App Master.   I feel exception should be thrown or break the loop after finite no of retries.,Closed,Fixed,,xieguiming,Devaraj K,Wed; 28 Mar 2012 10:33:38 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Thu; 19 Apr 2012 14:55:10 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4074
MAPREDUCE-4075,Bug,Major,,Incorrect NM's hyperlink and  NM's information ,"While accessing task attempt log of sucessfully completed uber-job from jobhistory SUCCESSFUL; noticed the following    	NM information displayed while accessing logs hyperlink is       	Node's hyperlink is displayed as localhost:8042    In the above case; I think we should update localhost and port numbers to reflect the actual values to make hyperlink work.",Resolved,Duplicate,MAPREDUCE-3682,Unassigned,Bhallamudi Venkata Siva Kamesh,Wed; 28 Mar 2012 12:11:57 +0000,Wed; 28 Mar 2012 14:57:40 +0000,Wed; 28 Mar 2012 14:57:40 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4075
MAPREDUCE-4076,Bug,Blocker,mrv2,Stream job fails with ZipException when use yarn jar command,Stream job fails with ZipException when use yarn jar command and executes successfully with hadoop jar command.,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 28 Mar 2012 13:35:12 +0000,Thu; 12 May 2016 18:23:39 +0000,Tue; 10 Apr 2012 21:32:16 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4076
MAPREDUCE-4077,Bug,Major,mrv2,Issues while using Hadoop Streaming job,When we use -file option it says deprecated and use -files.    But when we use -files option; it says unrecognized option.     When we use -archives option;  it says unrecognized option.    But in the options it will display the usage of the -archives.,Resolved,Not A Problem,,Devaraj K,Devaraj K,Wed; 28 Mar 2012 13:37:28 +0000,Thu; 17 Jan 2013 13:05:38 +0000,Thu; 17 Jan 2013 13:05:38 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4077
MAPREDUCE-4078,Bug,Major,,Hadoop-Mapreduce-0.23-Build - Build # 239 - Still Failing ,See https: ,Resolved,Not A Problem,,Unassigned,Devaraj K,Wed; 28 Mar 2012 13:43:02 +0000,Fri; 28 Dec 2012 12:33:41 +0000,Fri; 28 Dec 2012 12:33:41 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4078
MAPREDUCE-4079,Improvement,Blocker,mr-am;mrv2,Allow MR AppMaster to limit ephemeral port range.,Having the MapReduce Application Masters bind to any ephemeral port makes it very difficult to setup ACLs.  mapreduce.job.am-access-disabled from MAPREDUCE-3251 is not a practical permanent solution for all jobs.  Especially for tools like pig where they are not aware of mapreduce.job.am-access-disabled and may deal with it properly.  We should add in a config option that would allow someone to restrict the range of ports that the MR-AM can bind to.  It will slow down startup in some cases because we will have to probe for open ports instead of just asking the OS to find one for us.  But we can make that conditional on this config so users who do not set this config do not see any performance degradation.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 28 Mar 2012 15:45:27 +0000,Wed; 17 Jun 2015 12:46:01 +0000,Tue; 24 Apr 2012 13:07:53 +0000,,0.23.2;2.0.0-alpha,,,HADOOP-12097,https://issues.apache.org/jira/browse/MAPREDUCE-4079
MAPREDUCE-4080,Bug,Critical,jobhistoryserver;mrv2,FileNotFoundException while accessing job configuration from UI.,Tried to access the job configuration from UI; when the job history files were still in the intermediate directory. JHS displayed the configurations of the job. Again tried to access the configurations of the same job; when the job history files were in the done directory. This time got the following exception,Resolved,Duplicate,MAPREDUCE-3972,Unassigned,Bhallamudi Venkata Siva Kamesh,Thu; 29 Mar 2012 13:45:59 +0000,Tue; 10 Mar 2015 04:30:21 +0000,Thu; 29 Mar 2012 14:28:50 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4080
MAPREDUCE-4081,Bug,Blocker,build;mrv2,TestMROutputFormat.java does not compile,ERROR   36;7 class TestConfInCheckSpec is public; should be declared in a file named TestConfInCheckSpec.java,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 29 Mar 2012 14:25:38 +0000,Tue; 10 Mar 2015 04:30:23 +0000,Thu; 29 Mar 2012 15:21:13 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4081
MAPREDUCE-4082,Bug,Critical,build,hadoop-mapreduce-client-app's mrapp-generated-classpath file should not be in the module JAR,Currently the mrapp-generated-classpath file containing the 'built' classpath; which only makes sense during building testing in the machine where the build happens; is bundled in the hadoop-mapreduce-client-app JAR.  Because the file is bundled in the hadoop-mapreduce-client-app JAR; its contents are added to the classpath of all MR jobs.   All this entries are useless and just pollute the classpath.  This file should not be bundled in the hadoop-mapreduce-client-app JAR.  As an example; the contents of this file in my local built are:,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 29 Mar 2012 15:01:45 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Thu; 29 Mar 2012 21:51:40 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4082
MAPREDUCE-4083,Bug,Major,contrib/gridmix,GridMix emulated job tasks.resource-usage emulator for CPU usage throws NPE when Trace contains cumulativeCpuUsage value of 0 at attempt level,GridMix emulated job tasks.resource-usage emulator for CPU usage throws NPE when Trace contains cumulativeCpuUsage value of 0 at attempt level,Closed,Fixed,,Amar Kamat,Karam Singh,Thu; 29 Mar 2012 15:19:17 +0000,Wed; 3 Sep 2014 22:45:02 +0000,Thu; 12 Apr 2012 07:19:36 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4083
MAPREDUCE-4084,Bug,Major,tasktracker,tasktracker dies at startup with ConcurrentModificationException thrown from checkDirs(),if a directory named in mapred.local.dir is not writable at start-up; a ConcurrentModficationException is thrown.  this is caused by calling remove on a collection that is being iterated over.  patch MR2850.v1.3.patch from MAPREDUCE-2850 addresses this; but it hasn't been applied in the 1.0 releases.,Open,Unresolved,,Unassigned,Edward Seidl,Thu; 29 Mar 2012 23:18:08 +0000,Thu; 29 Mar 2012 23:18:08 +0000,,,1.0.0;1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4084
MAPREDUCE-4085,New Feature,Major,task,Kill task attempts longer than a configured queue max time,For some environments; it is desirable to have certain queues have an SLA with regards to task turnover.  (i.e.; a slot will be free in X minutes and scheduled to the appropriate job)  Queues should have a 'task time limit' that would cause task attempts over this time to be killed. This leaves open the possibility that if the task was on a bad node; it could still be rescheduled up to max.task.attempt times.,Resolved,Won't Fix,,Unassigned,Allen Wittenauer,Fri; 30 Mar 2012 01:25:09 +0000,Thu; 17 Jul 2014 15:04:50 +0000,Thu; 17 Jul 2014 15:04:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4085
YARN-101,Bug,Minor,nodemanager,If  the heartbeat message loss; the nodestatus info of complete container will loss too.,"see the red color:  org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.   protected void startStatusUpdater() {      new Thread(""Node Status Updater"") {       @Override       @SuppressWarnings(""unchecked"")       public void run() {         int lastHeartBeatID = 0;         while (!isStopped) {             Remove         i.remove();                  LOG.info(""Removed completed container "" + containerId);       }     }     nodeStatus.setContainersStatuses(containersStatuses);      LOG.debug(this.nodeId + "" sending out status for ""         + numActiveContainers + "" containers"");      NodeHealthStatus nodeHealthStatus = this.context.getNodeHealthStatus();     nodeHealthStatus.setHealthReport(healthChecker.getHealthReport());     nodeHealthStatus.setIsNodeHealthy(healthChecker.isHealthy());     nodeHealthStatus.setLastHealthReportTime(         healthChecker.getLastHealthReportTime());     if (LOG.isDebugEnabled())  {       LOG.debug(""Node's health-status : "" + nodeHealthStatus.getIsNodeHealthy()                 + ""; "" + nodeHealthStatus.getHealthReport());     }     nodeStatus.setNodeHealthStatus(nodeHealthStatus);      ListApplicationId keepAliveAppIds = createKeepAliveApplicationList();     nodeStatus.setKeepAliveApplications(keepAliveAppIds);      return nodeStatus;   }",Closed,Fixed,,Xuan Gong,xieguiming,Fri; 30 Mar 2012 05:26:56 +0000,Tue; 27 Aug 2013 22:15:29 +0000,Wed; 3 Apr 2013 16:58:03 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-101
MAPREDUCE-4087,Bug,Major,,[Gridmix] GenerateDistCacheData job of Gridmix can become slow in some cases,In map() method of GenerateDistCacheData job of Gridmix; val.setSize() is done every time based on the bytes to be written to a distributed cache file. When we try to write data to next distributed cache file in the same map task; the size of random data generated in each iteration can become small based on the particular case. This can make this dist cache data generation slow.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 30 Mar 2012 10:39:55 +0000,Wed; 3 Sep 2014 22:47:48 +0000,Sat; 31 Mar 2012 08:29:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4087
MAPREDUCE-4088,Bug,Critical,mrv1,Task stuck in JobLocalizer prevented other tasks on the same node from committing,"We saw that as a result of HADOOP-6963; one task was stuck in this  Thread 23668: (state = IN_NATIVE)  	 lang.String[]) @bci=738; line=249 (Interpreted frame)    This should never happen. A stuck task should never prevent other tasks from different jobs on the same node from committing.",Closed,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 30 Mar 2012 16:15:02 +0000,Tue; 30 Oct 2012 20:55:55 +0000,Tue; 1 May 2012 16:19:37 +0000,,0.20.205.0,,,MAPREDUCE-2364,https://issues.apache.org/jira/browse/MAPREDUCE-4088
MAPREDUCE-4089,Bug,Blocker,mrv2,Hung Tasks never time out. ,The AM will timeout a task through mapreduce.task.timeout only when it does not hear from the task within the given timeframe.  On 1.0 a task must be making progress; either by reading input from HDFS; writing output to HDFS; writing to a log; or calling a special method to inform it that it is still making progress.  This is because on 0.23 a status update which happens every 3 seconds is counted as progress.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 30 Mar 2012 18:06:52 +0000,Tue; 10 Mar 2015 04:30:50 +0000,Mon; 2 Apr 2012 20:31:42 +0000,,0.23.2;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4089
MAPREDUCE-4090,Bug,Major,mrv1;mrv2;pipes,Branch 1 pipes doesn't work on MR2 clusters,If I compile pipes examples on branch 1:      And then try to run it on an MR2 cluster; the pipes job hangs forever at map 0% reduce 0%; I can see in the maps stderr:     The issue here is that if users have older pipes job; they won't be able to run it on MR2 (without recompilation). Is this expected or there is something to be fixed so jobs can be used interchangeably? Or should we document it as an incompatibility?,Resolved,Won't Fix,,Unassigned,Ahmed Radwan,Fri; 30 Mar 2012 20:27:14 +0000,Fri; 6 Nov 2015 01:54:27 +0000,Fri; 6 Nov 2015 01:54:27 +0000,,0.23.1;1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4090
MAPREDUCE-4091,Bug,Critical,build;test,tools testcases failing because of MAPREDUCE-4082,MAPREDUCE-4082 moved the generated-classpath file used by MRApp from the main classpath to the test classpath.  The objective of MAPREDUCE-4082 was to remove the generated-classpath file from the hadoop-mapreduce-client-app JAR. I've thought that moving it to the test-classpath would do the trick.  This is breaking tools testcases (most likely) because of different classloader being used by maven for main classpath and test classpath.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 30 Mar 2012 21:08:47 +0000,Fri; 7 Sep 2012 21:03:36 +0000,Fri; 30 Mar 2012 21:32:28 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4091
MAPREDUCE-4092,Bug,Blocker,mrv2,commitJob Exception does not fail job (regression in 0.23 vs 0.20),If commitJob throws an exception JobImpl will swallow the exception with a warning and succeed the Job. This is a break from 0.20 and 1.0 where commitJob exception will fail the job  Exception logged in the AM as WARN   org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Could not do commit for Job Job still finishes as succeeded,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 30 Mar 2012 22:02:02 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Mon; 2 Apr 2012 19:56:43 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4092
MAPREDUCE-4093,Improvement,Major,mrv2,Improve RM WebApp start up when proxy address is not set,In the above code; YarnConfiguration.getProxyHostAndPort(conf) is invoking twice. getProxyHostAndPort() internally invokes getRMWebAppHostAndPort() which resolves RM web app address when proxy address is not set.,Closed,Fixed,,Devaraj K,Devaraj K,Sat; 31 Mar 2012 16:28:06 +0000,Thu; 12 May 2016 18:24:41 +0000,Thu; 19 Apr 2012 19:45:26 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4093
MAPREDUCE-4094,Bug,Major,,Mapreduce-trunk test cases are failing,https: ,Resolved,Not A Problem,MAPREDUCE-4096,Unassigned,Devaraj K,Sun; 1 Apr 2012 17:56:54 +0000,Thu; 12 May 2016 18:23:32 +0000,Mon; 31 Dec 2012 13:50:30 +0000,,3.0.0-alpha1,,,MAPREDUCE-4095,https://issues.apache.org/jira/browse/MAPREDUCE-4094
MAPREDUCE-4095,Bug,Major,,TestJobInProgress#testLocality uses a bogus topology,The following in TestJobInProgress#testLocality:     violates the check introduced by HADOOP-8159:,Closed,Fixed,,Colin P. McCabe,Eli Collins,Sat; 31 Mar 2012 02:28:40 +0000,Tue; 10 Mar 2015 04:32:29 +0000,Mon; 2 Apr 2012 20:08:54 +0000,,1.1.0;2.0.0-alpha,,,MAPREDUCE-4094,https://issues.apache.org/jira/browse/MAPREDUCE-4095
MAPREDUCE-4096,Bug,Major,test,tests seem to be randomly failing,Looking at the output from test-patch from jenkins recently it seems that tests are randomly failing:  jira MAPREDUCE-4089 is an example where 22 failed; the next time patch was put up 4 failed and in both cases the patch had nothing to do with those tests.  I also manually ran mvn test in mapreduce directory and had 20 failures and saw a couple of processes still laying around. One was using port 10020 which other tests were trying to use and you saw a bind address error come out of the tests.,Resolved,Duplicate,MAPREDUCE-4094,Unassigned,Thomas Graves,Mon; 2 Apr 2012 18:22:24 +0000,Tue; 10 Mar 2015 04:30:19 +0000,Tue; 3 Apr 2012 08:48:52 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4096
MAPREDUCE-4097,Bug,Major,build,tools testcases fail because missing mrapp-generated-classpath file in classpath,The mrapp-generated-classpath file is created in hadoop-mapreduce-client-apptarget  dir to create the classpath.  When running tools testcases from tools level; mvn uses the hadoop-mapreduce-client-app JAR from M2 cache to create the classpath.  In the later the mrapp-generated-classpath is not present.,Closed,Fixed,,Roman Shaposhnik,Alejandro Abdelnur,Mon; 2 Apr 2012 20:38:21 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Wed; 4 Apr 2012 20:25:51 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4097
MAPREDUCE-4098,Bug,Major,test,TestMRApps testSetClasspath fails,The assertion of this test is testing for equality; as the generated classpath file is in the classpath the test fails.  Instead; the test should test for the expected path elements to be in the classspath.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 3 Apr 2012 10:31:15 +0000,Wed; 23 May 2012 20:28:26 +0000,Wed; 4 Apr 2012 14:58:00 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4098
MAPREDUCE-4099,Bug,Critical,mrv2,ApplicationMaster may fail to remove staging directory,When the ApplicationMaster shuts down it's supposed to remove the staging directory; assuming properties weren't set to override this behavior. During shutdown the AM tells the ResourceManager that it has finished before it cleans up the staging directory.  However upon hearing the AM has finished; the RM turns right around and kills the AM container.  If the AM is too slow; the AM will be killed before the staging directory is removed.  We're seeing the AM lose this race fairly consistently on our clusters; and the lack of staging directory cleanup quickly leads to filesystem quota issues for some users.,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 3 Apr 2012 14:00:59 +0000,Thu; 2 Apr 2015 00:42:06 +0000,Wed; 11 Apr 2012 17:12:02 +0000,,0.23.2,,,YARN-2261,https://issues.apache.org/jira/browse/MAPREDUCE-4099
MAPREDUCE-4100,Bug,Minor,contrib/gridmix,Sometimes gridmix emulates data larger much larger then acutal counter for map only jobs,While running 1400+ jobs trace I encountered this issue. For map-only jobs; observed that some Maps generating data of around 9 GB (From HDFS_BYTES_WRITTEN) whereas actual value is around 5GB in trace. This can sometimes also cause jobs to fail intermittently.  Other GridMix version coming be Hadoop-1.1.X and above might also effected,Closed,Fixed,,Amar Kamat,Karam Singh,Tue; 3 Apr 2012 15:06:48 +0000,Wed; 3 Sep 2014 22:45:03 +0000,Thu; 19 Apr 2012 04:28:06 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4100
YARN-97,Bug,Major,nodemanager,nodemanager depends on /bin/bash,Currently nodemanager depends on bash shell. It should be well documented for system not having bash installed by default such as FreeBSD. Because only basic functionality of bash is used; probably changing bash to  bash,Resolved,Not A Problem,,Unassigned,Radim Kolar,Tue; 3 Apr 2012 18:00:23 +0000,Mon; 19 Nov 2012 18:02:21 +0000,Mon; 19 Nov 2012 18:02:21 +0000,,,patch,,,https://issues.apache.org/jira/browse/YARN-97
MAPREDUCE-4102,Bug,Major,webapps,job counters not available in Jobhistory webui for killed jobs,"Run a simple wordcount or sleep; and kill the job before it finishes.  Go to the job history web ui and click the ""Counters"" link for that job. It displays ""500 error"".  The job history log has:  Caused by: com.google.inject.ProvisionException: Guice provision errors:  2012-04-03 19:42:53;148 ERROR org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI:  job_1333482028750_0001  lang.reflect.InvocationTargetException      sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)   There are task counters available if you drill down into successful tasks though.",Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Thomas Graves,Tue; 3 Apr 2012 19:51:52 +0000,Thu; 7 Mar 2013 17:43:09 +0000,Wed; 16 May 2012 14:12:02 +0000,,0.23.2;2.0.0-alpha,,,MAPREDUCE-5023,https://issues.apache.org/jira/browse/MAPREDUCE-4102
MAPREDUCE-4103,Improvement,Major,documentation,Fix HA docs for changes to shell command fencer args,HADOOP-8007 changes the way in which shell command fencers are invoked. For whatever reason; the docs live in the MR tree. This JIRA is to update the docs.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 4 Apr 2012 07:30:34 +0000,Wed; 23 May 2012 20:28:23 +0000,Wed; 4 Apr 2012 18:46:42 +0000,,2.0.0-alpha,,,HADOOP-8007,https://issues.apache.org/jira/browse/MAPREDUCE-4103
MAPREDUCE-4104,Bug,Major,,Add support for querying based on ROWNUM to DBInputFormat,Add support for querying based on ROWNUM to DBInputFormat in addittion to LIMIT and OFFSET based query.,Open,Unresolved,,Unassigned,Joseph Doss,Mon; 5 Mar 2012 16:29:57 +0000,Tue; 10 Mar 2015 03:22:58 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4104
MAPREDUCE-4105,Bug,Major,mrv2,Yarn RackResolver ignores rack configurations,Incorrect mappings because the Yarn RackResolver ignores rack configurations. This can be verified by inspecting the resource manager web ui that lists all the nodes; all of them show up with  default-rack regardless of the output from the script specified using net.topology.script.file.name configuration property.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Thu; 5 Apr 2012 02:16:20 +0000,Wed; 23 May 2012 20:28:22 +0000,Mon; 9 Apr 2012 23:36:14 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4105
MAPREDUCE-4106,Test,Major,mrv2,Fix skipping tests in mapreduce,There are 22 tests skipping in hadoop-mapreduce-client-jobclient module; all these can be corrected as part of this umbrella jira.,Resolved,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 05:00:22 +0000,Thu; 12 May 2016 18:23:55 +0000,Fri; 28 Dec 2012 12:32:21 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4106
MAPREDUCE-4107,Sub-task,Major,mrv2,Fix tests in org.apache.hadoop.ipc.TestSocketFactory,Project : hadoop-mapreduce-client-jobclient,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 05:01:30 +0000,Thu; 12 May 2016 18:23:53 +0000,Wed; 11 Apr 2012 21:16:42 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4107
MAPREDUCE-4108,Sub-task,Major,mrv2,Fix tests in org.apache.hadoop.util.TestRunJar,Project : hadoop-mapreduce-client-jobclient,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 05:02:41 +0000,Thu; 12 May 2016 18:23:52 +0000,Tue; 10 Apr 2012 22:11:07 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4108
MAPREDUCE-4109,Bug,Blocker,applicationmaster;jobhistoryserver;mrv2,availability of a job info in HS should be atomic,It seems that the HS starts serving info about a job before it has all the info available.  In the trace below; a RunningJob throws a NPE when trying to access the counters.  This is happening on  off; thus I assume it is related to either the AM not flushing all job info to HDFS before notifying HS or the HS not loading all the job info from HDFS before start serving it.  In case it helps to diagnose the issue; this is happening in a secure cluster.  This makes Oozie to mark jobs as failed.,Closed,Invalid,,Unassigned,Alejandro Abdelnur,Thu; 5 Apr 2012 09:22:24 +0000,Wed; 23 May 2012 20:28:27 +0000,Wed; 11 Apr 2012 09:10:11 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4109
MAPREDUCE-4110,Sub-task,Major,mrv2;test,Fix tests in org.apache.hadoop.mapred.TestMiniMRClasspath & org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers,Sub Project : hadoop-mapreduce-client-jobclient,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 09:34:45 +0000,Thu; 12 May 2016 18:22:56 +0000,Fri; 6 Apr 2012 18:58:36 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4110
MAPREDUCE-4111,Sub-task,Major,mrv2;test,Fix tests in org.apache.hadoop.mapred.TestJobName,Sub Project : hadoop-mapreduce-client-jobclient,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 09:37:06 +0000,Thu; 12 May 2016 18:22:54 +0000,Fri; 6 Apr 2012 16:06:19 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4111
MAPREDUCE-4112,Sub-task,Major,mrv2;test,Fix tests org.apache.hadoop.mapred.TestClusterMapReduceTestCase,Sub Project : hadoop-mapreduce-client-jobclient,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 09:38:04 +0000,Thu; 12 May 2016 18:22:53 +0000,Fri; 6 Apr 2012 16:00:48 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4112
MAPREDUCE-4113,Sub-task,Major,mrv2;test,Fix tests org.apache.hadoop.mapred.TestClusterMRNotification,Sub Project : hadoop-mapreduce-client-jobclient,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 5 Apr 2012 09:39:46 +0000,Thu; 12 May 2016 18:22:53 +0000,Fri; 6 Apr 2012 15:51:44 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4113
MAPREDUCE-4114,Bug,Major,build,saveVersion.sh fails if build directory contains space ,if you rename build directory to something without space like  313M INFO ------------------------------------------------------------------------ mavenExecutionResult exceptions not empty message : Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (generate-version) on project hadoop-yarn-common: Command execution failed. cause : Command execution failed. Stack trace :  org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (generate-version) on project hadoop-yarn-common: Command execution failed.,Resolved,Duplicate,MAPREDUCE-3540,Unassigned,Radim Kolar,Thu; 5 Apr 2012 19:35:06 +0000,Mon; 18 Jun 2012 09:09:31 +0000,Mon; 18 Jun 2012 09:09:31 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4114
MAPREDUCE-4115,Bug,Major,build,hadoop-project-dist/pom.xml is invalid,"Mentioned POM is invalid. It fails XML validation and can not be deployed into repository with validating repository manager; such as Artifactory.  Problematic are """" inside antrun-plugin configuration. It should be   Line 342 and 379",Resolved,Invalid,,Unassigned,Radim Kolar,Thu; 5 Apr 2012 21:02:33 +0000,Tue; 10 Mar 2015 04:30:48 +0000,Tue; 10 Apr 2012 20:26:02 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4115
MAPREDUCE-4116,Bug,Major,build,Missing POM dependency for hadoop-yarn-common,hadoop-yarn-common is missing dependency on hadoop-common. some things like Configured from it are used. This dependency should be added to POM,Resolved,Incomplete,,Unassigned,Radim Kolar,Fri; 6 Apr 2012 14:31:15 +0000,Tue; 10 Mar 2015 04:30:29 +0000,Thu; 22 Nov 2012 16:29:51 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4116
MAPREDUCE-4117,Bug,Critical,client;mrv2,mapred job -status throws NullPointerException,nan,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 6 Apr 2012 17:44:55 +0000,Thu; 12 May 2016 18:24:22 +0000,Mon; 9 Apr 2012 21:56:10 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4117
MAPREDUCE-4118,Test,Major,test,Update tests to not use MiniMRCluster Internally; and filter out duplicate tests,There are a number of tests from MRV1 that are being pulled into MRV2.  Many of these tests use MiniMRCluster; but the MiniMRCluser shim was added so that projects like Oozie and Pig can have a single test that will work for either Yarn or MRV1.  Internally our tests are never going to go back to be run on MRV1 so we should update them to use the new code.  Also there are some places where older tests and newer tests are almost duplicates of one another; or where the same results are archived through through mock objects.  For the sake of runtime of the tests it would be better to remove some of these duplicates.,Resolved,Duplicate,MAPREDUCE-2955,Unassigned,Robert Joseph Evans,Fri; 6 Apr 2012 18:54:13 +0000,Thu; 12 May 2016 18:24:20 +0000,Fri; 6 Apr 2012 19:25:24 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4118
MAPREDUCE-4119,Bug,Major,jobhistoryserver,[jobhistory]  job history server can not support mutiple  yarn.app.mapreduce.am.staging-dir   directorys.,jobclient can set the yarn.app.mapreduce.am.staging-dir value ; but jobhistoryserver only read the yarn.app.mapreduce.am.staging-dir  value from conf. so; if client set different yarn.app.mapreduce.am.staging-dir value; and the jobhistoryserver can not scan the directory.,Open,Unresolved,,Unassigned,xieguiming,Sat; 7 Apr 2012 10:15:32 +0000,Sat; 7 Apr 2012 10:20:19 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4119
MAPREDUCE-4120,Bug,Blocker,client;mrv2,mapred job -list-attempt-ids fails to get attempt ids,In the above command it gives valid task-type are MAP REDUCE JOB_SETUP JOB_CLEANUP TASK_CLEANUP. If we give the task-type as MAP; it says as invalid type.     In the above command it gives valid types for task are: map; reduce; setup; cleanup.. If we give the task-type as map; it fails with the below error.,Resolved,Duplicate,MAPREDUCE-4019,Unassigned,Devaraj K,Sun; 8 Apr 2012 04:11:25 +0000,Thu; 12 May 2016 18:23:47 +0000,Mon; 9 Apr 2012 08:23:28 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4120
MAPREDUCE-4121,Improvement,Major,,dump the threads stack trace to stdout before killing a Task in timeout,"Typically when a job fails because of tasks timing out we investigate the issue by running the job again and triggering a dump of the thread stack traces of one of the tasks with jstack ""kill -3"" before it times out. It would be convenient if the Task tracker could do the same right before killing tasks in time out. This usually points at the offending code.",Resolved,Duplicate,MAPREDUCE-1119,Unassigned,Julien Le Dem,Sun; 8 Apr 2012 22:31:27 +0000,Mon; 9 Apr 2012 05:46:01 +0000,Mon; 9 Apr 2012 05:46:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4121
MAPREDUCE-4122,Bug,Major,mrv2,The MRAppmaster process killed count is being added to the Apps Pending value(with -ve sign) in Cluster Metrics page.,"Application will retry ""yarn.resourcemanager.am.max-retries"" times before the job is failed;if the MRAppmaster process is getting killed continously.This killed count is considered for Pending applications with -ve value on CLuster metrics page.   This will mis-interpret the exact number of jobs in the Pending state for the cluster.Even if the MRAppmaster kill count is monitored:should be done at the job level and not at the cluster level.",Resolved,Duplicate,MAPREDUCE-3870,Unassigned,Ramgopal N,Mon; 9 Apr 2012 08:39:32 +0000,Mon; 9 Apr 2012 09:30:44 +0000,Mon; 9 Apr 2012 09:30:44 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4122
MAPREDUCE-4123,Bug,Critical,mrv2,./mapred groups gives NoClassDefFoundError,"linux-168: mapred groups Exception in thread ""main""  316) Could not find the main class: org.apache.hadoop.mapred.tools.GetGroups.  Program will exit.",Closed,Fixed,,Devaraj K,Nishan Shetty,Mon; 9 Apr 2012 09:33:40 +0000,Thu; 12 May 2016 18:22:46 +0000,Wed; 3 Oct 2012 21:29:51 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4123
YARN-306,Sub-task,Major,scheduler,FIFO scheduler doesn't respect changing job priority,1.Submit job 2.Change the job priority using setPriority() or CLI command . mapred job-set-priority job-id priority  Observe that Job priority is not changed.,Resolved,Won't Fix,,Rohith Sharma K S,Nishan Shetty,Mon; 9 Apr 2012 10:43:57 +0000,Wed; 16 Sep 2015 16:31:16 +0000,Wed; 16 Sep 2015 13:46:24 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/YARN-306
YARN-198,Improvement,Minor,nodemanager,If we are navigating to Nodemanager UI from Resourcemanager;then there is not link to navigate back to Resource manager,If we are navigating to Nodemanager by clicking on the node link in RM;there is no link provided on the NM to navigate back to RM.  If there is a link to navigate back to RM it would be good,Closed,Fixed,,Jian He,Ramgopal N,Mon; 9 Apr 2012 10:57:08 +0000,Tue; 27 Aug 2013 22:15:21 +0000,Wed; 13 Mar 2013 04:25:56 +0000,,,usability,YARN-414,,https://issues.apache.org/jira/browse/YARN-198
MAPREDUCE-4126,Improvement,Major,performance,This is a fix both for oracle support and managing DB splits in general.,This is and addition to an older patch that addressed oracle support. We found that in large result sets; the map reduce was both splitting the results ( as expected ) and running a duplicate ( full result set ) on one node; resulting in a long runtime that should have been reduced by splitting.,Open,Unresolved,,Unassigned,Joseph Doss,Mon; 9 Apr 2012 12:01:55 +0000,Thu; 7 Jul 2016 04:14:45 +0000,,,1.0.0,hadoop;newbie;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4126
MAPREDUCE-4127,Improvement,Major,,Resource manager UI does not show the Job Priority,In RM UI the priority of job is not displayed,Resolved,Duplicate,YARN-1963,Unassigned,Nishan Shetty,Mon; 9 Apr 2012 15:31:00 +0000,Fri; 8 May 2015 10:58:32 +0000,Fri; 8 May 2015 10:58:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4127
MAPREDUCE-4128,Bug,Major,mrv2,AM Recovery expects all attempts of a completed task to also be completed.,The AM seems to assume that all attempts of a completed task (from a previous AM incarnation) would also be completed. There is at least one case in which this does not hold. Case being cancellation of a completed task resulting in a new running attempt.,Closed,Fixed,,Bikas Saha,Bikas Saha,Mon; 9 Apr 2012 18:02:38 +0000,Thu; 12 May 2016 18:23:06 +0000,Fri; 13 Apr 2012 13:49:03 +0000,,3.0.0-alpha1,,MAPREDUCE-3921,,https://issues.apache.org/jira/browse/MAPREDUCE-4128
MAPREDUCE-4129,Bug,Major,mrv2,Lots of unneeded counters log messages,Huge number of the same WARN messages are written. We only need to write each distinct message once. The messages are of the form:,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Mon; 9 Apr 2012 23:45:27 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Thu; 19 Apr 2012 20:27:03 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4129
MAPREDUCE-4130,Bug,Minor,mrv2,Jobid creation is not required if the job failed because of unavailability of input path.Can input and output paths validation can be done before job ID creation step?,If the input splits cannot be computed because the input paths doesnt exist Job is not submitted and error is thrown.But before that jobid is created which can be avoided. The sequence is  1)Output path validation 2)Jobid creation 3)Input splits computation  But if the sequence of steps is 1;3;2 ...unnecessary  jobid creation can be avoided,Open,Unresolved,,Unassigned,Ramgopal N,Tue; 10 Apr 2012 08:31:27 +0000,Tue; 10 Apr 2012 12:28:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4130
MAPREDUCE-4131,Improvement,Major,mrv2,Update the HistoryStorage interface to be more complete and robust,MAPREDUCE-4059 introduced a pluggable HistoryStorage interface.  The interface right now is very minimal and mostly is the result of refactoring moving other methods into the new interface.  We should rethink this interface so th is not returned.,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Tue; 10 Apr 2012 15:18:58 +0000,Tue; 10 Apr 2012 15:18:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4131
HDFS-3455,Improvement,Major,documentation,Add docs for NameNode initializeSharedEdits and bootstrapStandby commands,We've made the HA setup easier by adding new flags to the namenode to automatically set up the standby. But; we didn't document them yet. We should amend the HDFSHighAvailability.apt.vm docs to include this.,Open,Unresolved,,Unassigned,Todd Lipcon,Tue; 10 Apr 2012 19:44:33 +0000,Mon; 20 Jul 2015 19:57:11 +0000,,,2.0.0-alpha,newbie,,,https://issues.apache.org/jira/browse/HDFS-3455
MAPREDUCE-4133,Bug,Major,,MR over viewfs is broken,After the changes in HADOOP-8014 went in; MR programs using viewfs broke. This is because; viewfs now expects getDefaultBlockSize; getDefaultReplication; and getServerDefaults to pass in a path as an argument. In the existing MR source; these are called with no arguments.,Closed,Fixed,,John George,John George,Tue; 10 Apr 2012 19:26:30 +0000,Fri; 7 Sep 2012 21:03:34 +0000,Mon; 23 Apr 2012 19:49:59 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4133
MAPREDUCE-4134,Task,Major,mrv2,Remove references of mapred.child.ulimit etc. since they are not being used any more,Courtesy Philip Su; we found that (mapred.child.ulimit; mapreduce.map.ulimit; mapreduce.reduce.ulimit) were not being used at all. The configuration exists but is never used. Its also mentioned in mapred-default.xml and templates mapred-site.xml . Also the method getUlimitMemoryCommand in Shell. is now useless and can be removed.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Tue; 10 Apr 2012 21:26:53 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Tue; 17 Apr 2012 22:18:37 +0000,,0.23.2,,,HADOOP-8288,https://issues.apache.org/jira/browse/MAPREDUCE-4134
MAPREDUCE-4135,Bug,Major,mrv2,MRAppMaster throws IllegalStateException while shutting down,Always MRAppMaster throws IllegalStateException in the stderr while shutting down. It doesn't look good having this exception in the stderr file of MRAppMaster container.,Resolved,Duplicate,MAPREDUCE-4137,Ravi Prakash,Devaraj K,Wed; 11 Apr 2012 06:04:06 +0000,Thu; 12 May 2016 18:24:46 +0000,Tue; 10 Jul 2012 21:27:11 +0000,,2.0.0-alpha;3.0.0-alpha1,,MAPREDUCE-4157,,https://issues.apache.org/jira/browse/MAPREDUCE-4135
MAPREDUCE-4136,Bug,Major,contrib/streaming,Hadoop streaming might succeed even through reducer fails,Hadoop streaming can even succeed even though the reducer has failed. This happens when Hadoop calls PipeReducer.close(); but in the mean time the reducer has failed and the process has died. When clientOut_.flush() throws an IOException in PipeMapRed.mapRedFinish() this exception is caught but only logged. The exit status of the child process is never checked and task is marked as successful.  I've attached a patch that seems to fix it for us.,Patch Available,Unresolved,,Unassigned,Wouter de Bie,Wed; 11 Apr 2012 12:00:27 +0000,Wed; 6 May 2015 03:31:07 +0000,,,0.20.205.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4136
MAPREDUCE-4137,Bug,Major,mrv2,MRAppMaster shutdown hook should not call FileSystem.closeAll(),Filesystem.closeAll() attempts to remove the FileSystem shutdown hook.  This triggers an exception     Besides; because the FileSystem has its own shutdown hook that does a closeAll() the call from MRAppMaster is not needed.,Closed,Duplicate,MAPREDUCE-4135,Unassigned,Alejandro Abdelnur,Wed; 11 Apr 2012 14:19:59 +0000,Wed; 23 May 2012 20:28:24 +0000,Wed; 11 Apr 2012 14:42:22 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4137
MAPREDUCE-4138,Improvement,Major,,Reduce memory usage of counters due to non-static nested classes,FrameworkCounter is a non-static nested class of FrameworkCounterGroup which means it retains a reference to the outer class; which isn't really needed.,Closed,Fixed,,Tom White,Tom White,Wed; 11 Apr 2012 18:20:06 +0000,Wed; 23 May 2012 20:28:20 +0000,Thu; 26 Apr 2012 18:52:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4138
MAPREDUCE-4139,Bug,Major,mrv2,Potential ResourceManager deadlock when SchedulerEventDispatcher is stopped,When the main thread calls ResourceManager$SchedulerEventDispatcher.stop() it grabs a lock on the object; kicks the event processor thread; and then waits for the thread to exit.  However the interrupted event processor thread can end up trying to call the synchronized getConfig() method which results in deadlock.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 11 Apr 2012 21:30:36 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Tue; 17 Apr 2012 22:41:59 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4139
MAPREDUCE-4140,Bug,Major,client;mrv2,"mapreduce classes incorrectly importing ""clover.org.apache.*"" classes",A number of classes in mapreduce are importing clover.org.apache.* classes  e.g. hadoop-mapreduce-project PartialJob.java,Closed,Fixed,,Patrick Hunt,Patrick Hunt,Thu; 12 Apr 2012 00:16:24 +0000,Thu; 11 Oct 2012 17:48:42 +0000,Thu; 12 Apr 2012 16:34:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4140
MAPREDUCE-4141,Bug,Major,,clover integration broken; also mapreduce poms are pulling in clover as a dependency,Some of the poms are specifying clover as a dependency; rather than exclusively as a plugin.  Also I tried running with the clover profile on trunk and the build is failing due to some issue with protobufs code generation.,Resolved,Fixed,,Patrick Hunt,Patrick Hunt,Thu; 12 Apr 2012 00:50:04 +0000,Tue; 10 Mar 2015 04:30:38 +0000,Mon; 23 Apr 2012 22:34:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4141
MAPREDUCE-4142,Bug,Major,,MR test failures on branch-1,"The following test classes are failing on branch-1: TestJobTrackerRestartWithLostTracker; TestJobTrackerSafeMode; TestMiniMRMapRedDebugScript; TestRecoveryManager; TestTaskTrackerLocalization.  Recent MR changes; believe these tests were passing before these failures:  	MAPREDUCE-4012 Hadoop Job setup error leaves no useful info to users. (tgrav 	MAPREDUCE-1238. mapred metrics shows negative count of waiting maps and redu 	MAPREDUCE-4017. Add jobname to jobsummary log (tgraves and Koji Noguchi via 	MAPREDUCE-4003. log.index (No such file or directory) AND Task process exit",Resolved,Invalid,,Thomas Graves,Eli Collins,Thu; 12 Apr 2012 06:07:14 +0000,Sun; 6 May 2012 00:13:04 +0000,Thu; 12 Apr 2012 21:05:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4142
YARN-378,Sub-task,Major,client;resourcemanager,ApplicationMaster retry times should be set by Client,"We should support that different client or user have different ApplicationMaster retry times. It also say that ""yarn.resourcemanager.am.max-retries"" should be set by client.",Closed,Fixed,YARN-464,Zhijie Shen,xieguiming,Thu; 12 Apr 2012 12:38:44 +0000,Tue; 27 Aug 2013 22:15:18 +0000,Mon; 25 Mar 2013 22:41:04 +0000,,,usability,MAPREDUCE-5062;YARN-414,MAPREDUCE-5062;YARN-542;YARN-464,https://issues.apache.org/jira/browse/YARN-378
MAPREDUCE-4144,Bug,Critical,mrv2,ResourceManager NPE while handling NODE_UPDATE,The RM on one of our clusters has exited twice in the past few days because of an NPE while trying to handle a NODE_UPDATE:     This is very similar to the failure reported in MAPREDUCE-3005.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 12 Apr 2012 16:28:30 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Fri; 13 Apr 2012 22:26:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4144
MAPREDUCE-4145,Bug,Major,tasktracker,ConcurrentModificationException in TT if any one of the local dirs is invalid,TT won't come up; stack trace instead. Looks like the deletion of invalid dirs breaks the iterator going through the list of dirs.,Open,Unresolved,,Unassigned,Steve Loughran,Thu; 12 Apr 2012 18:10:57 +0000,Thu; 12 Apr 2012 18:11:10 +0000,,,1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4145
MAPREDUCE-4146,Improvement,Major,,Support limits on task status string length and number of block locations in branch-2,This brings MAPREDUCE-1943 to branch-2. Counter limits were introduced in MAPREDUCE-901.,Closed,Fixed,,Ahmed Radwan,Tom White,Thu; 12 Apr 2012 20:06:23 +0000,Wed; 23 Oct 2013 00:04:38 +0000,Tue; 29 May 2012 14:46:48 +0000,,,,,MAPREDUCE-5186,https://issues.apache.org/jira/browse/MAPREDUCE-4146
MAPREDUCE-4147,Bug,Major,,YARN should not have a compile-time dependency on HDFS,YARN doesn't (and shouldn't) use any HDFS-specific APIs; so it should not declare HDFS as a compile-time dependency.,Closed,Fixed,,Tom White,Tom White,Thu; 12 Apr 2012 20:23:36 +0000,Wed; 23 May 2012 20:28:27 +0000,Fri; 13 Apr 2012 00:12:21 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4147
MAPREDUCE-4148,Bug,Major,mrv2,MapReduce should not have a compile-time dependency on HDFS,MapReduce depends on HDFS's DelegationTokenIdentifier (for printing token debug information). We should remove this dependency and MapReduce's compile-time dependency on HDFS.,Closed,Fixed,,Tom White,Tom White,Thu; 12 Apr 2012 23:44:34 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Fri; 11 May 2012 15:04:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4148
MAPREDUCE-4149,Bug,Major,tools/rumen,Rumen fails to parse certain counter strings,"If a counter name contains "" {"" or ""} ""; Rumen is not able to parse it and throws ParseException.",Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Fri; 13 Apr 2012 06:14:25 +0000,Wed; 3 Sep 2014 22:45:03 +0000,Wed; 18 Apr 2012 12:04:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4149
MAPREDUCE-4150,Improvement,Major,mrv2,Versioning and rolling upgrades for MR2,"It doesn't seem that Yarn components; for example the ResourceManager or NodeManager; do build problems resulting from incompatible components trying to communicate with each other.     	Permitting a policy for running different - but compatible - versions on the same cluster (for example; in a rolling upgrade scenario). See HDFS-2983 for the corresponding HDFS implementation.",Open,Unresolved,,Unassigned,Ahmed Radwan,Fri; 13 Apr 2012 08:36:28 +0000,Sun; 28 Dec 2014 18:31:41 +0000,,,0.23.1,,,HDFS-2983;YARN-666;YARN-819;MAPREDUCE-5831,https://issues.apache.org/jira/browse/MAPREDUCE-4150
MAPREDUCE-4151,Improvement,Major,mrv2;webapps,RM scheduler web page should filter apps to those that are relevant to scheduling,On the ResourceManager's scheduler web page; the bottom of the page shows the apps block.  When the cluster has run a lot of applications (e.g.: 10;000+) loading the apps table can take a long time; and that prolongs the plotting of the queue status which is the most interesting portion of the page.  If the user is bothering to go to the scheduler page; they're probably not interested in apps that are not affecting what the scheduler is doing (e.g.: FINISHED; FAILED; KILLED; etc.).  Having the RM filter the apps for this page should significantly reduce the time it takes to load this page on the client; and it also helps reduce the amount of apps the user has to sift through when looking for the apps that are affecting what the scheduler is doing.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 13 Apr 2012 14:27:48 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Tue; 17 Apr 2012 20:08:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4151
MAPREDUCE-4152,Bug,Major,mrv2,map task left hanging after AM dies trying to connect to RM,"We had an instance where the RM went down for more then an hour.  The application master exited with ""Could not contact RM after 360000 milliseconds""  2012-04-11 10:43:36;040 INFO AsyncDispatcher event handler org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1333003059741_15999Job Transitioned from RUNNING to ERROR",Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 13 Apr 2012 15:27:33 +0000,Thu; 11 Oct 2012 17:48:47 +0000,Wed; 30 May 2012 14:55:45 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4152
YARN-98,Bug,Major,nodemanager,NM Application invalid state transition on reboot command from RM,If the RM goes down and comes back up; it tells the NM to reboot.  When the NM reboots; if it has any applications it aggregates the logs for those applications; then it transitions the app to APPLICATION_LOG_HANDLING_FINISHED. I saw a case where there was an app that was in the RUNNING state and tried to transition to APPLICATION_LOG_HANDLING_finished and it got the invalid transition.   DeletionService #12012-04-11 15:12:40;476 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Can't handle this event   619) 2012-04-11 15:12:40;476 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1333003059741_15999 transitioned from RUNNING to null,Resolved,Duplicate,YARN-495,Omkar Vinit Joshi,Thomas Graves,Fri; 13 Apr 2012 18:21:41 +0000,Mon; 15 Apr 2013 20:26:09 +0000,Mon; 15 Apr 2013 20:26:09 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-98
MAPREDUCE-4154,Bug,Major,,streaming MR job succeeds even if the streaming command fails,Hadoop 1.0.1 behaves as expected - The task fails for streaming MR job if the streaming command fails. But it succeeds in hadoop 1.0.2 .,Closed,Fixed,,Devaraj Das,Thejas M Nair,Fri; 13 Apr 2012 22:58:18 +0000,Wed; 16 May 2012 20:45:15 +0000,Thu; 19 Apr 2012 16:19:07 +0000,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4154
YARN-40,Bug,Major,client,Provide support for missing yarn commands,1. status app-id 2. kill app-id (Already issue present with Id : MAPREDUCE-3793) 3. list-apps all 4. nodes-report,Closed,Fixed,YARN-104,Devaraj K,Devaraj K,Mon; 16 Apr 2012 09:42:58 +0000,Fri; 15 Feb 2013 13:12:30 +0000,Mon; 8 Oct 2012 22:37:49 +0000,,2.0.0-alpha,,YARN-29,MAPREDUCE-4944,https://issues.apache.org/jira/browse/YARN-40
MAPREDUCE-4156,Bug,Major,build,ant build fails compiling JobInProgress,The ant build fails trying to compile jobInProgress.  Looks like TaskFinishedEvent has a new parameter (added in MAPREDUCE-4128) so we probably need to update the old mrv1 source so it atleast compiles.   compile-mapred-classes: jsp-compile 2012-04-13 08:43:33;175 WARN  main compiler.TldLocationsCache (TldLocationsCache.  1 error,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 16 Apr 2012 14:39:27 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Mon; 16 Apr 2012 20:49:33 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4156
MAPREDUCE-4157,Improvement,Major,mrv2,ResourceManager should not kill apps that are well behaved,Currently when the ApplicationMaster unregisters with the ResourceManager; the RM kills (via the NMs) all the active containers for an application.  This introduces a race where the AM may be trying to clean up and may not finish before it is killed.  The RM should give the AM a chance to exit cleanly on its own rather than always race with a pending kill on shutdown.,Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 16 Apr 2012 19:48:04 +0000,Thu; 4 Sep 2014 01:00:32 +0000,Wed; 18 Jul 2012 19:44:56 +0000,,2.0.0-alpha,,MAPREDUCE-4135,,https://issues.apache.org/jira/browse/MAPREDUCE-4157
MAPREDUCE-4158,Improvement,Major,client,Port mapreduce.MapFileOutputFormat to branch-1,MapFileOutputFormat was missed in MAPREDUCE-3607.,Open,Unresolved,,Tom White,Tom White,Tue; 17 Apr 2012 04:30:06 +0000,Tue; 24 Apr 2012 17:04:44 +0000,,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4158
MAPREDUCE-4159,Bug,Major,mrv2,"Job is running in Uber mode after setting ""mapreduce.job.ubertask.maxreduces"" to zero","1.Configure ""mapreduce.job.ubertask.enable"" to true 2.Configure ""mapreduce.job.ubertask.maxreduces"" to 0(zero) 3.Run job such that it has one reducer(more than ""mapreduce.job.ubertask.maxreduces"" value)   Observe that job is running in Uber mode instead of normal mode(non uber mode)",Closed,Fixed,,Devaraj K,Nishan Shetty,Tue; 17 Apr 2012 07:19:52 +0000,Thu; 12 May 2016 18:22:59 +0000,Thu; 19 Apr 2012 16:25:00 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4159
MAPREDUCE-4160,Bug,Major,test,some mrv1 ant tests fail with timeout - due to 4156,Looks like the old mrv1 history server is getting null error when trying to parse the a null for the TaskFinishedEvent successfulAttemptId which was added in jira 4156.  This is causing the ant tests to take like 9 hours to run.   junit  1221),Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 17 Apr 2012 15:25:45 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Tue; 17 Apr 2012 19:25:07 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4160
MAPREDUCE-4161,Sub-task,Major,client;mrv2,create sockets consistently,Use getSocketAddr from HADOOP-8286 to ensure sockets are created consistently and compatible for host-based service generation.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Tue; 17 Apr 2012 16:40:36 +0000,Tue; 10 Mar 2015 04:31:53 +0000,Wed; 18 Apr 2012 18:50:24 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4161
MAPREDUCE-4162,Sub-task,Major,client;mrv2,Correctly set token service,Use SecurityUtils.setTokenService to set token services.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Tue; 17 Apr 2012 16:42:37 +0000,Tue; 10 Mar 2015 04:31:53 +0000,Thu; 10 May 2012 14:52:08 +0000,,0.23.0;2.0.0-alpha,,HADOOP-8373,,https://issues.apache.org/jira/browse/MAPREDUCE-4162
MAPREDUCE-4163,Sub-task,Major,mrv2,consistently set the bind address,Use NetUtils.getConnectAddress for determining the bind address used for setting a token's service.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Tue; 17 Apr 2012 16:45:48 +0000,Tue; 10 Mar 2015 04:32:00 +0000,Thu; 3 May 2012 21:36:41 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4163
MAPREDUCE-4164,Bug,Major,tasktracker,Hadoop 22 Exception thrown after task completion causes its reexecution,2012-02-28 19:17:08;504 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass; with 3 segments left of total size: 1969310 bytes 2012-02-28 19:17:08;694 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000094_0 is done. And is in the process of commiting 2012-02-28 19:18:08;774 INFO org.apache.hadoop.mapred.Task: Communication exception:  1040) ... 4 more  2012-02-28 19:18:08;825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000094_0' done.   ================&gt;&gt;&gt; SHOULD be ++++++++++++++ 2012-02-28 19:17:02;214 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass; with 3 segments left of total size: 1974104 bytes 2012-02-28 19:17:02;408 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000000_0 is done. And is in the process of commiting 2012-02-28 19:17:02;519 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000000_0' done.,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Tue; 17 Apr 2012 21:30:13 +0000,Tue; 24 Apr 2012 02:09:34 +0000,Mon; 23 Apr 2012 22:27:58 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4164
MAPREDUCE-4165,Bug,Trivial,mrv2,Committing is misspelled as commiting in task logs,nan,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 18 Apr 2012 21:42:10 +0000,Fri; 7 Sep 2012 21:03:35 +0000,Thu; 19 Apr 2012 19:34:43 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4165
YARN-50,Sub-task,Blocker,,Implement renewal / cancellation of Delegation Tokens,Currently; delegation tokens issues by the RM and History server cannot be renewed or cancelled. This needs to be implemented.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 18 Apr 2012 23:42:40 +0000,Wed; 3 Sep 2014 23:25:47 +0000,Fri; 4 Jan 2013 20:31:49 +0000,,0.23.5,,,MAPREDUCE-4894,https://issues.apache.org/jira/browse/YARN-50
MAPREDUCE-4167,Bug,Major,jobhistoryserver;mrv2,Delete empty timestamped directories,Currently in the clean() method; we are deleting only the files DD) as it is. As these are empty directories; I think; we should delete these time stamped directories from FileSystem in the clean method.,Open,Unresolved,,Unassigned,Bhallamudi Venkata Siva Kamesh,Fri; 20 Apr 2012 07:23:00 +0000,Tue; 10 Mar 2015 04:30:10 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4167
MAPREDUCE-4168,New Feature,Major,,Support multiple network interfaces,Umbrella jira to track the MapReduce side of HADOOP-8198.,Reopened,Unresolved,,Unassigned,Tom White,Fri; 20 Apr 2012 17:22:43 +0000,Wed; 18 Feb 2015 09:55:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4168
MAPREDUCE-4169,Bug,Minor,mrv2,Container Logs appear in unsorted order,container logs (stdout; stderr; syslog) in the nodemanager ui and jobhistory ui appear in unsorted order where the order displayed is based on what file was created first. This jira will have the results be displayed in a consistent order.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 20 Apr 2012 19:18:28 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Thu; 26 Apr 2012 18:29:45 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4169
MAPREDUCE-4170,Bug,Minor,examples;test,"Move ""sleep"" and ""fail"" jobs from tests module to examples module","The sleep job used to be in the ""examples"" jar in MR1. I'm not quite sure when; but the sleep job has been moved to the ""tests"" module jar in MR2.",Open,Unresolved,,Unassigned,Aaron T. Myers,Fri; 20 Apr 2012 22:41:17 +0000,Wed; 3 Jun 2015 11:17:10 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4170
YARN-281,Test,Major,scheduler,Add a test for YARN Schedulers' MAXIMUM_ALLOCATION limits,We currently have tests that test MINIMUM_ALLOCATION limits for FifoScheduler and the likes; but no test for MAXIMUM_ALLOCATION yet. We should add a test to prevent regressions of any kind on such limits.,Resolved,Won't Fix,,Wangda Tan,Harsh J,Sat; 21 Apr 2012 02:08:36 +0000,Fri; 6 Feb 2015 22:53:40 +0000,Fri; 6 Feb 2015 19:57:00 +0000,,2.0.0-alpha,test,,,https://issues.apache.org/jira/browse/YARN-281
MAPREDUCE-4172,Task,Major,build,Clean up java warnings in the hadoop-mapreduce-project sub projects,"There are lots of warnings in the hadoop-mapreduce-project presently. We can clear almost all of this away:   	Unused imports 	Unused variables 	 		For loops that can be replaced with while instead to save an unused variable 	 	 	Unused methods 	Deprecation warnings where an alternative can be used (Especially SequenceFile reader writer usage and MiniDFSCluster usage) 	Deprecation warnings where an alternative isn't clear (Especially MiniMRCluster usage and DistributedCache API usage where a Job object may not be available) 	Unchecked conversions 	Raw type usage 	(etc.)    I'm going to open one sub-task per sub-project we have; with patches attached to them.",Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 05:31:32 +0000,Tue; 10 Mar 2015 04:30:32 +0000,Sun; 2 Dec 2012 05:01:28 +0000,,,,HADOOP-8301,,https://issues.apache.org/jira/browse/MAPREDUCE-4172
MAPREDUCE-4173,Sub-task,Minor,,Clean up hadoop-mapreduce-client-app,Clean up a bunch of existing   warnings in hadoop-mapreduce-client-app module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 05:33:19 +0000,Tue; 10 Mar 2015 04:30:33 +0000,Sun; 2 Dec 2012 05:00:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4173
MAPREDUCE-4174,Sub-task,Minor,build,Clean up hadoop-mapreduce-client-common,Clean up a bunch of existing   warnings in hadoop-mapreduce-client-common module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 07:02:04 +0000,Tue; 10 Mar 2015 04:30:34 +0000,Sun; 2 Dec 2012 05:00:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4174
MAPREDUCE-4175,Sub-task,Minor,build,Clean up hadoop-mapreduce-client-core,Clean up a bunch of existing   warnings in hadoop-mapreduce-client-core module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 07:02:35 +0000,Tue; 10 Mar 2015 04:30:34 +0000,Sun; 2 Dec 2012 05:00:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4175
MAPREDUCE-4176,Sub-task,Minor,build,Clean up hadoop-mapreduce-client-hs,Clean up a bunch of existing   warnings in hadoop-mapreduce-client-hs module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 13:29:31 +0000,Tue; 10 Mar 2015 04:30:24 +0000,Sun; 2 Dec 2012 04:59:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4176
MAPREDUCE-4177,Sub-task,Minor,build,Clean up hadoop-mapreduce-client-jobclient,Clean up a bunch of existing   warnings in hadoop-mapreduce-client-jobclient module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 13:30:07 +0000,Tue; 10 Mar 2015 04:30:24 +0000,Sun; 2 Dec 2012 04:59:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4177
MAPREDUCE-4178,Sub-task,Major,build,Clean up hadoop-rumen,Clean up a bunch of existing   warnings in hadoop-rumen module.,Resolved,Duplicate,HADOOP-8302,Harsh J,Harsh J,Sun; 22 Apr 2012 15:11:06 +0000,Tue; 10 Mar 2015 04:30:26 +0000,Sun; 22 Apr 2012 17:46:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4178
MAPREDUCE-4180,Sub-task,Minor,build,Clean up hadoop-streaming,Clean up a bunch of existing   warnings in hadoop-streaming module.,Resolved,Duplicate,HADOOP-8303,Harsh J,Harsh J,Sun; 22 Apr 2012 16:27:38 +0000,Tue; 10 Mar 2015 04:30:26 +0000,Sun; 22 Apr 2012 17:48:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4180
MAPREDUCE-4181,Sub-task,Minor,build,Remove the unused maybeInitBuilder() method from various classes in hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/,Clean up a bunch of existing   warnings in hadoop-yarn-api module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 17:53:27 +0000,Tue; 10 Mar 2015 04:30:28 +0000,Sun; 2 Dec 2012 04:59:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4181
MAPREDUCE-4182,Sub-task,Minor,build,Remove an used import from TestDistributedShell,Clean up a bunch of existing   warnings in hadoop-yarn-applications-distributedshell module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 17:54:15 +0000,Tue; 10 Mar 2015 04:30:27 +0000,Sun; 2 Dec 2012 04:58:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4182
MAPREDUCE-4183,Sub-task,Minor,build,Clean up yarn-common,Clean up a bunch of existing   warnings in hadoop-yarn-common module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 17:54:48 +0000,Tue; 10 Mar 2015 04:30:27 +0000,Sun; 2 Dec 2012 04:57:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4183
MAPREDUCE-4184,Sub-task,Minor,build,Clean up yarn-server-common,Clean up a bunch of existing   warnings in hadoop-yarn-server-common module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 17:55:30 +0000,Tue; 10 Mar 2015 04:30:29 +0000,Sun; 2 Dec 2012 04:57:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4184
MAPREDUCE-4185,Sub-task,Minor,build,Clean up yarn-server-nodemanager,Clean up a bunch of existing   warnings in hadoop-yarn-server-nodemanager module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 17:56:12 +0000,Tue; 10 Mar 2015 04:30:30 +0000,Sun; 2 Dec 2012 04:57:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4185
MAPREDUCE-4186,Sub-task,Minor,build,Clean up yarn-server-resourcemanager,Clean up a bunch of existing   warnings in hadoop-yarn-server-resourcemanager module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 18:02:43 +0000,Tue; 10 Mar 2015 04:30:28 +0000,Sun; 2 Dec 2012 04:56:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4186
MAPREDUCE-4187,Sub-task,Minor,build,Clean up yarn-server-tests,Clean up a bunch of existing   warnings in hadoop-yarn-server-tests module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 18:03:30 +0000,Tue; 10 Mar 2015 04:30:28 +0000,Sun; 2 Dec 2012 04:56:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4187
MAPREDUCE-4188,Sub-task,Minor,build,Clean up yarn-server-web-proxy,Clean up a bunch of existing   warnings in hadoop-yarn-server-web-proxy module.,Resolved,Won't Fix,,Harsh J,Harsh J,Sun; 22 Apr 2012 18:04:15 +0000,Tue; 10 Mar 2015 04:30:30 +0000,Sun; 2 Dec 2012 04:56:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4188
MAPREDUCE-4189,Bug,Critical,mrv2,TestContainerManagerSecurity is failing,nan,Closed,Fixed,,Devaraj K,Devaraj K,Mon; 23 Apr 2012 05:53:14 +0000,Tue; 10 Mar 2015 04:30:43 +0000,Thu; 26 Apr 2012 19:46:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4189
MAPREDUCE-4190,Improvement,Major,mrv2;webapps, Improve web UI for task attempts userlog link,Users have reported being confused about the user logs link on the MR app master and history server task attempts page.  The logs link shows up in the same column as the node link and the users didn't realize it was a separate link.    job history web address for this page is like: jobhistoryserver:19888 task_1334686840316_0003_m_000000,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 23 Apr 2012 14:19:33 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Mon; 23 Apr 2012 19:41:32 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4190
MAPREDUCE-4191,Bug,Major,mrv2;scheduler,capacity scheduler: job unexpectedly exceeds queue capacity limit by one task,While testing the queue capacity limits; it appears that the job can exceed the queue capacity limit by one task while the user limit factor is 1. It's not clear to me why this is.   Here is the steps to reproduce:  1) set yarn.app.mapreduce.am.resource.mb to 2048 (default value) 2) set yarn.scheduler.capacity.root.default.user-limit-factor to 1.0 (default) 3) set yarn.scheduler.capacity.root.default.capacity to 90 (%) 4) For a cluster with capacity of 56G; 90% rounded up is 51. 5) submit a job with large number of tasks; each task using 1G memory.  6) webui shows that the used resource is 52 G; which is 92.9% of the cluster capacity (instead of the expected 90%); and 103.2% of the queue capacity (instead of the expected 100%).,Open,Unresolved,,Thomas Graves,Thomas Graves,Mon; 23 Apr 2012 17:38:09 +0000,Sat; 7 Jan 2017 02:00:03 +0000,,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4191
MAPREDUCE-4192,Bug,Major,,the TaskMemoryManager thread is not interrupt when the TaskTracker is oedered to reinit by JobTracker,When the TaskTracker is oedered to reinit by JobTracker; it will interrupt some threads and then reinit them; but TaskTracker does not interrupt  TaskMemoryManager thread and create a new TaskMemoryManager thread again. I use the tool--jstack to find that(I reinit TaskTracker 3 times through JobTracker send TaskTrackerAction.ActionType.REINIT_TRACKER).,Open,Unresolved,,Hua xu,Hua xu,Sat; 21 Apr 2012 07:29:59 +0000,Wed; 3 Jul 2013 01:04:51 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4192
MAPREDUCE-4193,Bug,Major,documentation,broken doc link for yarn-default.xml in site.xml,the link to yarn-default.xml in site.xml is incorrect; generated docs link is broken.,Closed,Fixed,HADOOP-8824,Patrick Hunt,Patrick Hunt,Mon; 23 Apr 2012 20:39:31 +0000,Thu; 20 Sep 2012 12:40:34 +0000,Wed; 25 Apr 2012 17:25:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4193
MAPREDUCE-4194,Bug,Major,mrv2,ConcurrentModificationError in DirectoryCollection,As found as part of work on MAPREDUCE-4169; it is possible for a ConcurrentModificationException to be thrown upon disk failure. DirectoryCollection hands out its internal list structure that is accessed across multiple threads. Upon disk failure its internal list is modified; invalidating all current iterators to that structure.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Tue; 24 Apr 2012 21:42:55 +0000,Fri; 7 Sep 2012 21:03:33 +0000,Wed; 25 Apr 2012 20:54:57 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4194
MAPREDUCE-4195,Bug,Critical,jobtracker,With invalid queueName request param; jobqueue_details.jsp shows NPE,When you access  jobqueue_details.jsp manually; instead of via a link; it has queueName set to null internally and this goes for a lookup into the scheduling info maps as well.  As a result; if using FairScheduler; a Pool with String name = null gets created and this brings the scheduler down. I have not tested what happens to the CapacityScheduler; but ideally if no queueName is set in that jsp; it should fall back to 'default'. Otherwise; this brings down the JobTracker completely.  FairScheduler must also add a check to not create a pool with 'null' name.  The following is the strace that ensues:,Closed,Fixed,,Unassigned,Gera Shegalov,Wed; 25 Apr 2012 20:11:08 +0000,Wed; 15 May 2013 05:15:49 +0000,Wed; 13 Jun 2012 18:01:03 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4195
YARN-70,Bug,Major,nodemanager,nodemanager doesn't cleanup old logs/local files after restart,The nodemanager doesn't ever remove old logs or local files when it is restarted. This is very noticeable if you are using yarn.nodemanager.delete.debug-delay-sec set to  0 and restart your nodemanager.  This could happen in other situations though also; for instance if the node manager crashes is restarted with running containers.,Resolved,Duplicate,YARN-71,Unassigned,Thomas Graves,Wed; 25 Apr 2012 21:10:37 +0000,Fri; 31 Aug 2012 19:52:07 +0000,Fri; 31 Aug 2012 19:50:42 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/YARN-70
MAPREDUCE-4197,Bug,Major,,Include the hsqldb jar in the hadoop-mapreduce tar file,Courtesy Brahma   In the previuos hadoop releases(20.XX) hsqldb was provided. But in hadoop-2.0.0 it is not present.Is it intentionally deleted or missing?,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 25 Apr 2012 22:45:46 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Fri; 18 May 2012 02:59:45 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4197
MAPREDUCE-4198,Improvement,Major,,Update RackResolver and related tests to resolve host with new API from HADOOP-8304 (DNSToSwitchMapping should add interface to resolve individual host besides a list of host),HADOOP-8304  (DNSToSwitchMapping should add interface to resolve individual host besides a list of host) will induce a new API to resolve individual host rather than a list of host. Here is update on MapReduce part to use new API.,Resolved,Won't Fix,,Junping Du,Junping Du,Thu; 26 Apr 2012 03:13:49 +0000,Sun; 1 Jul 2012 10:50:14 +0000,Sun; 1 Jul 2012 10:50:14 +0000,,1.0.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4198
MAPREDUCE-4199,Improvement,Minor,mrv2,Not easy to search the property  because of splited into many parts.,"The property is splited into many parts. such as:  public static final String RM_NODES_EXCLUDE_FILE_PATH =      RM_PREFIX + ""nodes.exclude-path"";  It is inconvenient for code reader to search the code by the property name although there are some common parts for reuse.",Open,Unresolved,,Unassigned,xieguiming,Thu; 26 Apr 2012 12:45:38 +0000,Thu; 26 Apr 2012 12:45:38 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4199
MAPREDUCE-4200,Bug,Major,build,packaging tar ball of trunk failed,"A command ""mvn clean package -Dtar -DskipTests"" executed on the root directory ""hadoop-common"" failed. Its output logs are in an attached file.  A command ""mvn clean package -Pdist -DskipTests"" succeeded.",Resolved,Not A Problem,,Unassigned,Tomohiko Kinebuchi,Thu; 26 Apr 2012 15:25:40 +0000,Tue; 10 Mar 2015 04:30:24 +0000,Sun; 29 Apr 2012 09:28:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4200
MAPREDUCE-4201,Bug,Major,,Getting PID not working on Windows. Termination of Task/TaskJVM's not working,Child Task not reporting PID because of Linux specific shell script implementation. Signaling task termination currently disabled by the initial Windows patch.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Thu; 26 Apr 2012 20:26:55 +0000,Fri; 27 Apr 2012 22:57:01 +0000,Fri; 27 Apr 2012 22:57:01 +0000,,,,,MAPREDUCE-4203,https://issues.apache.org/jira/browse/MAPREDUCE-4201
MAPREDUCE-4202,Bug,Major,test,TestYarnClientProtocolProvider is broken,The test fails because a cluster is unexpectedly created with an empty conf.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Thu; 26 Apr 2012 21:13:24 +0000,Tue; 10 Mar 2015 04:32:53 +0000,Tue; 1 May 2012 16:14:58 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4202
MAPREDUCE-4203,Improvement,Major,,Create equivalent of ProcfsBasedProcessTree for Windows,ProcfsBasedProcessTree is used by the TaskTracker to get process information like memory and cpu usage. This information is used to manage resources etc. The current implementation is based on Linux procfs functionality and hence does not work on other platforms; specifically windows.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Thu; 26 Apr 2012 22:17:36 +0000,Thu; 21 Jun 2012 01:35:04 +0000,Thu; 21 Jun 2012 01:35:04 +0000,,,,MAPREDUCE-4204,MAPREDUCE-4201,https://issues.apache.org/jira/browse/MAPREDUCE-4203
MAPREDUCE-4204,Improvement,Major,,Refactor ProcfsBasedProcessTree to make the resource collection object pluggable,Making it a pluggable interface will allow replacing the procfs based implementation with ones for other platforms.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Thu; 26 Apr 2012 22:19:16 +0000,Mon; 21 May 2012 07:32:18 +0000,Sat; 28 Apr 2012 01:00:58 +0000,,,,MAPREDUCE-4203,YARN-57,https://issues.apache.org/jira/browse/MAPREDUCE-4204
MAPREDUCE-4205,Improvement,Major,mrv2,retrofit all JVM shutdown hooks to use ShutdownHookManager,to avoid JVM shutdownhook race conditions; all shutdown hooks should be retrofitted to use ShutdownHookManager (HADOOP-8325),Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 27 Apr 2012 21:08:13 +0000,Thu; 2 May 2013 02:29:52 +0000,Fri; 4 May 2012 03:21:36 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4205
MAPREDUCE-4206,Bug,Minor,mrv2,Sorting by Last Health-Update on the RM nodes page sorts does not work correctly,column is mistakenly sorted lexically,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 27 Apr 2012 22:18:54 +0000,Thu; 11 Oct 2012 17:48:47 +0000,Mon; 30 Apr 2012 15:09:49 +0000,,0.23.3;2.0.0-alpha,mrv2,,,https://issues.apache.org/jira/browse/MAPREDUCE-4206
MAPREDUCE-4207,Bug,Major,mrv1,Remove System.out.println() in FileInputFormat,MAPREDUCE-3607 accidentally left the println statement.,Closed,Fixed,,Kihwal Lee,Kihwal Lee,Fri; 27 Apr 2012 22:52:31 +0000,Wed; 16 May 2012 20:45:17 +0000,Sat; 28 Apr 2012 04:34:11 +0000,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4207
MAPREDUCE-4208,Bug,Major,,The job is hanging up but never continuing until you kill the child process ,I use the hive MR query on hbase;but the job is never end. The job is hanging but never continuing util you kill the child process    2012-04-28 18:22:33;661 Stage-1 map = 0%;  reduce = 0% 2012-04-28 18:22:59;760 Stage-1 map = 25%;  reduce = 0% 2012-04-28 18:23:04;782 Stage-1 map = 38%;  reduce = 0% 2012-04-28 18:23:07;796 Stage-1 map = 50%;  reduce = 0% 2012-04-28 18:23:08;801 Stage-1 map = 50%;  reduce = 8% 2012-04-28 18:23:17;839 Stage-1 map = 50%;  reduce = 17% 2012-04-28 18:23:19;848 Stage-1 map = 63%;  reduce = 17% 2012-04-28 18:23:32;909 Stage-1 map = 63%;  reduce = 21% 2012-04-28 18:23:57;017 Stage-1 map = 75%;  reduce = 21% 2012-04-28 18:24:09;075 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:25:09;397 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:26:09;688 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:27:09;980 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:28:10;262 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:29:10;522 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:30:10;742 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:31:10;985 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:32:11;238 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:33:11;467 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:34:11;731 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:35:11;968 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:36:12;213 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:37:12;508 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:38:12;747 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:39:12;970 Stage-1 map = 75%;  reduce = 25% 2012-04-28 18:40:13;205 Stage-1 map = 75%;  reduce = 25%  I checked the TT log;  2012-04-28 18:31:53;879 INFO org.apache.hadoop.mapred.TaskTracker: tempt_201204281725_0002_m_000002_0 0.0%     hadoop@mem1 logs$ jps 3282 Child 31547 QuorumPeerMain 1840 TaskTracker 3469 Jps 31070 HRegionServer 30120 DataNode   hadoop@mem1 logs$  kill 3282  When I kill the child process ; then the job continue and complete.  2012-04-28 18:40:51;324 Stage-1 map = 88%;  reduce = 25% 2012-04-28 18:41:04;364 Stage-1 map = 88%;  reduce = 29% 2012-04-28 18:41:31;448 Stage-1 map = 100%;  reduce = 29% 2012-04-28 18:41:43;485 Stage-1 map = 100%;  reduce = 100%,Resolved,Not A Problem,,Unassigned,ccw,Sat; 28 Apr 2012 11:10:10 +0000,Fri; 4 May 2012 15:25:20 +0000,Fri; 4 May 2012 15:25:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4208
MAPREDUCE-4209,Bug,Major,build,junit dependency in hadoop-mapreduce-client is missing scope test,pom.xml in hadoop-mapreduce-client has declared junit as compile time dependency while it must be test scope dependency.,Closed,Fixed,,Unassigned,Radim Kolar,Sun; 29 Apr 2012 10:52:06 +0000,Tue; 10 Mar 2015 04:30:42 +0000,Mon; 30 Apr 2012 14:51:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4209
MAPREDUCE-4210,Improvement,Major,webapps,Expose listener address for WebApp,It should be possible to get the listener address from a WebApp instance.  This will greatly simplify some of the yarn host port manipulation.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Mon; 30 Apr 2012 21:50:11 +0000,Tue; 10 Mar 2015 04:31:58 +0000,Wed; 2 May 2012 18:29:48 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4210
MAPREDUCE-4211,Bug,Minor,mrv2,Error conditions (missing appid; appid not found) are masked in the RM app page,nan,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Mon; 30 Apr 2012 22:17:59 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Tue; 1 May 2012 15:38:06 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4211
MAPREDUCE-4212,Test,Major,test,TestJobClientGetJob sometimes fails,TestJobClientGetJob sometimes fails because it doesn't delete the job's output dir prior to submission.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Tue; 1 May 2012 13:13:59 +0000,Tue; 10 Mar 2015 04:32:52 +0000,Tue; 1 May 2012 14:12:45 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4212
YARN-74,Bug,Major,nodemanager,nodemanager should cleanup running containers when shutdown,Currently the nodemanager doesn't cleanup running containers when it gets restarted.  This can cause containers to get lost and stick around forever.  We've seen this happen multiple times when the RM is restarted. When the RM is brought back up; it doesn't know about wh point.,Resolved,Duplicate,YARN-72,Unassigned,Thomas Graves,Tue; 1 May 2012 13:34:52 +0000,Fri; 31 Aug 2012 19:59:19 +0000,Fri; 31 Aug 2012 19:59:08 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/YARN-74
YARN-73,Bug,Major,nodemanager,nodemanager should cleanup running containers when it starts,Currently the nodemanager doesn't cleanup running containers when it gets restarted. This can cause containers to get lost and stick around forever. We've seen this happen multiple times when the RM is restarted. When the RM is brought back up; it doesn't know about wh point.,Resolved,Duplicate,YARN-438;YARN-495,Unassigned,Thomas Graves,Tue; 1 May 2012 13:39:21 +0000,Sun; 12 May 2013 00:11:32 +0000,Sun; 12 May 2013 00:10:18 +0000,,0.23.3,,,YARN-71;YARN-72,https://issues.apache.org/jira/browse/YARN-73
MAPREDUCE-4215,Bug,Major,mrv2,RM app page shows 500 error on appid parse error,For example; cluster application_1335823499485_000a has displays this error,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Tue; 1 May 2012 16:20:53 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Tue; 8 May 2012 17:16:04 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4215
MAPREDUCE-4216,Improvement,Major,mrv2,Make MultipleOutputs generic to support non-file output formats,The current MultipleOutputs implementation is tied to FileOutputFormat in such a way that it is not extensible to other types of output. It should be made more generic; such as with an interface that can be implemented for different outputs.,Patch Available,Unresolved,,Unassigned,Robbie Strickland,Tue; 1 May 2012 20:42:37 +0000,Wed; 6 May 2015 03:34:18 +0000,,,1.0.2,BB2015-05-TBR;Output,,CASSANDRA-4208,https://issues.apache.org/jira/browse/MAPREDUCE-4216
MAPREDUCE-4217,Improvement,Major,task,Task commit waits for up to 3 seconds,Following MAPREDUCE-2450; TaskReporter#stopCommunicationThread may wait up to 3 seconds (the value of PROGRESS_INTERVAL) before it returns. This can be noticeable for short running tasks.,Resolved,Duplicate,MAPREDUCE-3809,Tom White,Tom White,Tue; 1 May 2012 21:28:03 +0000,Tue; 1 May 2012 21:48:28 +0000,Tue; 1 May 2012 21:48:28 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4217
MAPREDUCE-4218,Bug,Major,,Killed MapReduce Job does not generate log in MR2 cluster,In a non-secure MR2 cluster; if a MapReduce Job is killed due to Null Pointer Exception; the log is not generated.  When running in MR1 cluster; the log is generated.,Open,Unresolved,,Unassigned,Zhenxiao Luo,Wed; 2 May 2012 00:29:40 +0000,Wed; 20 Jun 2012 08:53:57 +0000,,,,,HIVE-2804,MAPREDUCE-4294;MAPREDUCE-3889,https://issues.apache.org/jira/browse/MAPREDUCE-4218
MAPREDUCE-4219,Improvement,Major,security,make default container-executor.conf.dir be a path relative to the container-executor binary,Currently; container-executor binary has an absolute pathname of its configuration file baked in. This prevents an easy relocation of the configuration files when dealing with multiple Hadoop installs on the same node. It would be nice to at least allow for a relative path resolution starting from the location of the container-executor binary itself. Something like    Thoughts?,Closed,Fixed,,Roman Shaposhnik,Roman Shaposhnik,Mon; 30 Apr 2012 16:18:40 +0000,Wed; 23 May 2012 20:28:26 +0000,Wed; 2 May 2012 22:54:53 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4219
MAPREDUCE-4220,Bug,Minor,mrv2,RM apps page starttime/endtime sorts are incorrect,Sorting by start time and end time sort lexically instead of temporally.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 2 May 2012 20:03:07 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Mon; 7 May 2012 16:20:59 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4220
YARN-216,Improvement,Major,,Remove jquery theming support,As of today we have 9.4MB of JQuery themes in our code tree. In addition to being a waste of space; it's a highly questionable feature. I've never heard anyone complain that the Hadoop interface isn't themeable enough; and there's far more value in consistency across installations than there is in themeability. Let's rip it out.,Closed,Fixed,,Robert Joseph Evans,Todd Lipcon,Thu; 3 May 2012 01:34:07 +0000,Wed; 6 Feb 2013 17:05:21 +0000,Wed; 14 Nov 2012 19:27:47 +0000,,2.0.0-alpha,newbie,,,https://issues.apache.org/jira/browse/YARN-216
HADOOP-8357,Task,Major,security,Restore security in Hadoop 0.22 branch,This is to track changes for restoring security in 0.22 branch.,Resolved,Fixed,,Benoy Antony,Konstantin Shvachko,Fri; 4 May 2012 05:45:32 +0000,Thu; 9 May 2013 07:07:44 +0000,Thu; 9 May 2013 07:07:44 +0000,,0.22.0,,,MAPREDUCE-2767;HADOOP-4487,https://issues.apache.org/jira/browse/HADOOP-8357
HADOOP-8358,Improvement,Trivial,conf,Config-related WARN for dfs.web.ugi can be avoided.,Looks easy to fix; and we should avoid using old config params that we ourselves deprecated.,Closed,Fixed,,Harsh J,Harsh J,Fri; 4 May 2012 07:44:56 +0000,Thu; 11 Oct 2012 17:45:09 +0000,Mon; 28 May 2012 15:42:38 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/HADOOP-8358
MAPREDUCE-4224,Bug,Major,mrv2;scheduler;test,TestFifoScheduler throws org.apache.hadoop.metrics2.MetricsException ,nan,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 4 May 2012 09:53:54 +0000,Thu; 12 May 2016 18:22:20 +0000,Thu; 24 May 2012 13:17:36 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4224
MAPREDUCE-4225,Bug,Major,mrv2,RM/AM scheduling debug statement not adequate on #asks,The debug statements in the AM and RM about the scheduling ask information is not adequate.  There are many places it prints out #asks; but that just always says 1.  We need to display the # containers in that ask and possibly other info to make it useful.  It would be useful to see this on both the AM side and the RM side. The RM side should be showing the total #'s it stored for that application.,Resolved,Invalid,,Unassigned,Thomas Graves,Fri; 4 May 2012 16:30:17 +0000,Tue; 15 Apr 2014 14:22:39 +0000,Tue; 15 Apr 2014 14:22:39 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4225
MAPREDUCE-4226,Bug,Major,mrv2,ConcurrentModificationException in FileSystemCounterGroup,This was seen in a Hive job. I'll attach a failing test case.,Closed,Fixed,,Tom White,Tom White,Fri; 4 May 2012 21:04:01 +0000,Fri; 7 Sep 2012 21:03:36 +0000,Mon; 7 May 2012 19:10:35 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4226
MAPREDUCE-4227,Bug,Major,,TimeWindow statistics are not updated for TaskTrackers which have been restarted.,Whenever a TaskTracker is restarted after the JobTracker has been running for a while (an hour   day maybe); the TimeWindow statistics on the JobTracker Active nodes page are stuck at 0.,Resolved,Duplicate,MAPREDUCE-4963,Ravi Prakash,Ravi Prakash,Fri; 4 May 2012 21:09:44 +0000,Mon; 28 Jan 2013 16:11:31 +0000,Mon; 28 Jan 2013 16:11:31 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4227
MAPREDUCE-4228,Bug,Major,applicationmaster;mrv2,mapreduce.job.reduce.slowstart.completedmaps is not working properly to delay the scheduling of the reduce tasks,If no more map tasks need to be scheduled but not all have completed; the ApplicationMaster will start scheduling reducers even if the number of completed maps has not met the mapreduce.job.reduce.slowstart.completedmaps threshold.  For example; if the property is set to 1.0 all maps should complete before any reducers are scheduled.  However the reducers are scheduled as soon as the last map task is assigned to a container.  For a job with very long-running maps; a cluster with enough capacity to launch all map tasks could cause reducers to launch prematurely and waste cluster resources.  Thanks to Phil Su for discovering this issue.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 4 May 2012 21:25:22 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Tue; 26 Jun 2012 19:25:22 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4228
MAPREDUCE-4229,Improvement,Major,jobtracker,Counter names' memory usage can be decreased by interning,In our experience; most of the memory in production JTs goes to storing counter names (String objects and character arrays). Since most counter names are reused again and again; it would be a big memory savings to keep a hash set of already-used counter names within a job; and refer to the same object from all tasks.,Closed,Fixed,MAPREDUCE-4303,Miomir Boljanovic,Todd Lipcon,Fri; 4 May 2012 23:46:49 +0000,Thu; 12 May 2016 18:24:18 +0000,Tue; 23 Oct 2012 21:22:10 +0000,,1.0.2;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4229
MAPREDUCE-4230,Bug,Major,,Ensure framework counter group synchronization is correct for serialization/deserialization,FrameworkCounterGroup and FileSystemCounterGroup may be susceptible to a race outlined in https: MAPREDUCE-4226?focusedCommentId=13269657page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13269657 by Robert Joseph Evans.,Open,Unresolved,,Unassigned,Tom White,Mon; 7 May 2012 19:08:49 +0000,Wed; 23 May 2012 20:27:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4230
MAPREDUCE-4231,Bug,Major,contrib/raid,Update RAID to not to use FSInodeInfo,FSInodeInfo was removed by HDFS-3363.  We should update RAID.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 8 May 2012 00:31:27 +0000,Wed; 23 May 2012 20:28:29 +0000,Tue; 8 May 2012 17:58:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4231
MAPREDUCE-4232,Improvement,Major,distributed-cache;test,Make the distributed cache tests easier to diagnose,"We currently require that the test environment:   	Have umask of 0022. 	Have a world readable basedir (including parents)    It would be good to check for those before bothering to run tests.",Open,Unresolved,,Owen O'Malley,Owen O'Malley,Tue; 8 May 2012 06:16:28 +0000,Tue; 14 May 2013 05:14:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4232
MAPREDUCE-4233,Bug,Critical,,NPE can happen in RMNMNodeInfo.,Looks like rmcontext.getRMNodes() is not kept in sync with scheduler.getNodeReport(); so that the report can be null even though the context still knowns about the node.  The simple fix is to add in a null check.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 8 May 2012 16:29:02 +0000,Fri; 7 Sep 2012 21:03:34 +0000,Fri; 11 May 2012 20:28:56 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4233
MAPREDUCE-4234,Improvement,Minor,examples,SortValidator.java is incompatible with multi-user or parallel use (due to a /tmp file with static name),The SortValidator. file checkRecords method creates a file in the  sortvalidator directory using a static filename. This can result in failures due to name collisions when the hadoop-mapreduce-client-jobclient-*-tests jar is used by more than one task or one user simultaneously. We use this jar when testing compression codecs and after we started running tests in parallel (four at a time to reduce overall test time) we started experiencing random test failures due to name collisions. Creating a random or unique per thread filename may resolve this issue. We have developed a change to introduce per use unique file names.,Resolved,Fixed,,Robert Joseph Evans,Randy Clayton,Tue; 8 May 2012 20:34:42 +0000,Tue; 10 Mar 2015 04:30:51 +0000,Tue; 31 Jul 2012 21:41:01 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4234
MAPREDUCE-4235,Bug,Major,mrv2,Killing app can lead to inconsistent app status between RM and HS,If a client tries to kill an application that is about to complete; the application states between the ResourceManager's web UI and the history server can be inconsistent.  When the problem occurs; the ResourceManager shows the Status KILLED and the history link will redirect to a broken link.  The history link still references the ApplicationMaster which is now missing.  The history server entry will show the application state as SUCCEEDED.,Resolved,Not A Problem,,Unassigned,Jason Lowe,Tue; 8 May 2012 22:36:22 +0000,Fri; 24 May 2013 15:23:47 +0000,Fri; 24 May 2013 15:23:47 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4235
MAPREDUCE-4236,Bug,Critical,,Failing tests in branch-2,Running org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup Tests run: 2; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 7.872 sec &lt; FAILURE!  Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEvents Tests run: 3; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 3.862 sec &lt; FAILURE!  Running org.apache.hadoop.conf.TestNoDefaultsJobConf Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 10.865 sec &lt; FAILURE!  Running org.apache.hadoop.mapreduce.security.TestJHSSecurity Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 1.372 sec &lt; FAILURE!,Resolved,Not A Problem,,Unassigned,Arun C Murthy,Wed; 9 May 2012 03:17:57 +0000,Tue; 10 Jul 2012 21:11:24 +0000,Tue; 10 Jul 2012 21:11:24 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4236
MAPREDUCE-4237,Bug,Major,,TestNodeStatusUpdater can fail if localhost has a domain associated with it,On some systems; RHEL where I work; localhost can resolve to localhost.localdomain.  TestNodeStatusUpdater can fail because the nodeid containes .localdomain which is not expected by the hard coded localhost string.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 9 May 2012 19:39:48 +0000,Fri; 7 Sep 2012 21:03:32 +0000,Wed; 9 May 2012 21:12:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4237
MAPREDUCE-4238,Bug,Critical,mrv2,mavenize data_join,mavenize the contrib data_join package,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 9 May 2012 19:51:24 +0000,Fri; 9 Nov 2012 02:38:10 +0000,Tue; 15 May 2012 19:43:49 +0000,,0.23.3,,,MAPREDUCE-4270;MAPREDUCE-4783,https://issues.apache.org/jira/browse/MAPREDUCE-4238
MAPREDUCE-4239,Bug,Minor,contrib/gridmix,gridmix has 11 findbugs warnings,"jira MAPREDUCE-3543 is mavenizing gridmix.  I found that gridmix has 11 findbugs warnings while doing that jira that should be fixed or have excludes added for them.   Code	Warning Se	org.apache.hadoop.mapred.gridmix.GridmixRecord$Comparator implements Comparator but not Serializable Malicious code vulnerability Warnings  Code	Warning EI	org.apache.hadoop.mapred.gridmix.SleepJob$SleepSplit.getLocations() may expose internal representation by returning SleepJob$SleepSplit.locations EI2	new org.apache.hadoop.mapred.gridmix.SleepJob(Configuration; long; JobStory; Path; UserGroupInformation; int; int; String[]) may expose internal representation by storing an externally mutable object into SleepJob.hosts EI2	new org.apache.hadoop.mapred.gridmix.SleepJob$SleepSplit(int; long; long[]; int; String[]) may expose internal representation by storing an externally mutable object into SleepJob$SleepSplit.locations EI2	new org.apache.hadoop.mapred.gridmix.SleepJob$SleepSplit(int; long; long[]; int; String[]) may expose internal representation by storing an externally mutable object into SleepJob$SleepSplit.reduceDurations MS	org.apache.hadoop.mapred.gridmix.emulators.resourceusage.TotalHeapUsageEmulatorPlugin.ONE_MB isn't final but should be MS	org.apache.hadoop.mapred.gridmix.emulators.resourceusage.TotalHeapUsageEmulatorPlugin$DefaultHeapUsageEmulator.heapSpace isn't final but should be Multithreaded correctness Warnings  Code	Warning JLM	Synchronization performed on  util.concurrent.BlockingQueue in org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.run() Dodgy Warnings  Code	Warning REC	Exception is caught when Exception is not thrown in org.apache.hadoop.mapred.gridmix.ExecutionSummarizer.processJobState(Statistics$JobStats)",Resolved,Duplicate,MAPREDUCE-5098,Unassigned,Thomas Graves,Wed; 9 May 2012 21:02:40 +0000,Thu; 2 May 2013 02:29:52 +0000,Tue; 26 Mar 2013 20:42:23 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4239
MAPREDUCE-4240,Task,Minor,security,Revert MAPREDUCE-2767 ,MAPREDUCE-2767 removed LinuxTaskController.  This task is revert that so LinuxtaskController is introduced back.,Resolved,Fixed,,Benoy Antony,Benoy Antony,Wed; 9 May 2012 23:38:32 +0000,Thu; 2 May 2013 02:29:53 +0000,Tue; 5 Jun 2012 01:24:41 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4240
MAPREDUCE-4241,Bug,Major,build;examples,Pipes examples do not compile on Ubuntu 12.04,-lssl alone won't work for compiling the pipes examples on 12.04. -lcrypto needs to be added explicitly.,Closed,Fixed,,Andrew Bayer,Andrew Bayer,Thu; 10 May 2012 20:19:02 +0000,Wed; 17 Oct 2012 18:27:22 +0000,Thu; 10 May 2012 22:03:27 +0000,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4241
MAPREDUCE-4242,Bug,Minor,contrib/gridmix;mrv2,port gridmix tests to yarn,jira MAPREDUCE-3543 is mavenizing gridmix; however some of the tests were not pulled over since they need to be ported to Yarn.  This jira is to port the remaining tests.  The ones under  contrib system should be looked at and then there is TestSleepJob; TestGridmixSubmission; and TestDistCacheEmulation.,Resolved,Duplicate,MAPREDUCE-4991,Unassigned,Thomas Graves,Thu; 10 May 2012 20:40:28 +0000,Thu; 2 May 2013 02:29:53 +0000,Tue; 2 Apr 2013 16:21:16 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4242
MAPREDUCE-4243,Task,Minor,build,Modify mapreduce build to include task-controller,Secure hadoop requires task-controller. Task-controller has to be built as part of mapreduce build.,Resolved,Fixed,,Benoy Antony,Benoy Antony,Wed; 9 May 2012 23:24:04 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Tue; 5 Jun 2012 01:26:43 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4243
MAPREDUCE-4244,Task,Minor,security,Fix an issue related to do with setting of correct groups for tasks,There was a recent fix related supplemental groups.,Resolved,Fixed,,Benoy Antony,Benoy Antony,Wed; 9 May 2012 23:44:03 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Tue; 5 Jun 2012 02:45:56 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4244
HDFS-3403,Task,Minor,security,SecondaryNamenode doesn't start up in secure cluster,SN fails to startup due to access control error. This is an authorization issue and not authentication issue.,Resolved,Duplicate,HDFS-2264,Benoy Antony,Benoy Antony,Wed; 9 May 2012 23:46:18 +0000,Wed; 10 Oct 2012 05:29:37 +0000,Wed; 10 Oct 2012 05:27:46 +0000,,0.22.0;1.1.0;2.0.3-alpha,,,,https://issues.apache.org/jira/browse/HDFS-3403
MAPREDUCE-4246,Task,Major,security,Failure in deleting user directories in Secure hadoop,This happens when security is enabled on 22  When TaskTracker starts p; it invokes MRAsyncDiskService moves the contents of scratch 2012-04-17_16-22-03.965_0 with exception org.apache.hadoop.util.Shell$ExitCodeException:   662),Resolved,Fixed,,Benoy Antony,Benoy Antony,Thu; 10 May 2012 01:42:22 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Tue; 5 Jun 2012 07:41:09 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4246
MAPREDUCE-4247,Task,Minor,security,TestTaskTrackerLocalization fails ,There are 11 failures on TestTaskTrackerLocalization .  org.apache.hadoop.mapred.TestTaskTrackerLocalization.testUserLocalization org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobLocalization org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobLocalizationFailsIfLogDirUnwritable org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTaskLocalization org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTaskFilesRemoval org.apache.hadoop.mapred.TestTaskTrackerLocalization.testFailedTaskFilesRemoval org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTaskFilesRemovalWithJvmUse org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobFilesRemoval org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTrackerRestart org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTrackerReinit org.apache.hadoop.mapred.TestTaskTrackerLocalization.testCleanupTaskLocalization,Resolved,Fixed,,Benoy Antony,Benoy Antony,Thu; 10 May 2012 01:49:39 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Tue; 5 Jun 2012 07:57:27 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4247
MAPREDUCE-4248,Task,Minor,security,TestRecoveryManager fails,Error Message shown from jenkins  Timeout occurred. Please note the time in the report does not reflect the time until the timeout. Stacktrace  junit.framework.AssertionFailedError: Timeout occurred. Please note the time in the report does not reflect the time until the timeout.,Resolved,Fixed,,Benoy Antony,Benoy Antony,Thu; 10 May 2012 01:51:16 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Tue; 5 Jun 2012 08:23:37 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4248
MAPREDUCE-4249,Task,Minor,security,Fix failures in streaming test TestFileArgs,"The streaming (contrib module) testcase - TestFileArgs fails with the following error  testcase classname=""org.apache.hadoop.streaming.TestFileArgs"" name=""testCommandLine"" time=""28.0"" failure message=""expected:job.jar  []sidefile  tmp   but was:job.jar  [org  ]sidefile  tmp",Resolved,Fixed,,Benoy Antony,Benoy Antony,Fri; 11 May 2012 04:13:20 +0000,Tue; 5 Jun 2012 13:53:47 +0000,Tue; 5 Jun 2012 08:29:05 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4249
MAPREDUCE-4250,Bug,Major,nodemanager,hadoop-config.sh missing variable exports; causes Yarn jobs to fail with ClassNotFoundException MRAppMaster,"This is the MR side of HADOOP-8393  If you start a pseudo distributed yarn using ""start-yarn.sh"" you need to specify exports for HADOOP_COMMON_HOME; HADOOP_HDFS_HOME; YARN_HOME; YARN_CONF_DIR; and HADOOP_MAPRED_HOME in hadoop-env.sh (or elsewhere); otherwise the spawned node manager will be missing  these in it's environment. This is due to start-yarn using yarn-daemons. With this fix it's possible to start yarn (etc...) with only HADOOP_CONF_DIR specified in the environment. Took some time to track down this failure; so seems worthwhile to fix.",Closed,Fixed,,Patrick Hunt,Patrick Hunt,Fri; 11 May 2012 18:54:40 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Wed; 16 May 2012 04:20:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4250
MAPREDUCE-4251,Sub-task,Minor,mrv1,API Incompatibility - Sampler,org.apache.hadoop.mapred.lib.InputSampler#Sampler in Hadoop 0.20 has been moved to org.apache.hadoop.mapreduce.lib.partition.InputSampler#Sampler in Hadoop 0.22  The arguments of the getSample method in the Sampler class have also been changed; 0.22 use the new InputFormat; and 0.20 use the deprecated InputFormat; 0.22 use org.apache.hadoop.mapreduce.Job and 0.20use org.apache.hadoop.mapred.JobConf.  So the programs compiled with old api has to be changed.,Resolved,Duplicate,MAPREDUCE-5157,Benoy Antony,Benoy Antony,Fri; 11 May 2012 23:26:27 +0000,Mon; 13 May 2013 18:44:01 +0000,Mon; 13 May 2013 18:07:20 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4251
MAPREDUCE-4252,Bug,Major,mrv2,MR2 job never completes with 1 pending task,"This was found by ATM:  I ran a teragen with 1000 map tasks. Many task attempts failed; but after 999 of the tasks had completed; the job is now sitting forever with 1 task ""pending"".",Closed,Fixed,,Tom White,Tom White,Sat; 12 May 2012 04:39:37 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Tue; 10 Jul 2012 16:12:52 +0000,,0.23.1,,,MAPREDUCE-4607,https://issues.apache.org/jira/browse/MAPREDUCE-4252
MAPREDUCE-4253,Test,Major,client,Tests for mapreduce-client-core are lying under mapreduce-client-jobclient,Many of the tests for client libs from mapreduce-client-core are lying under mapreduce-client-jobclient.  We should investigate if this is the right thing to do and if not; move the tests back into client-core.,Reopened,Unresolved,,Tsuyoshi Ozawa,Harsh J,Sat; 12 May 2012 11:17:54 +0000,Mon; 27 Mar 2017 07:33:47 +0000,,,2.0.0-alpha,,MAPREDUCE-2338;MAPREDUCE-4683,,https://issues.apache.org/jira/browse/MAPREDUCE-4253
YARN-42,Bug,Major,nodemanager,Node Manager throws NPE on startup,NM throws NPE on startup if it doesn't have persmission's on nm local dir's,Closed,Fixed,,Devaraj K,Devaraj K,Mon; 14 May 2012 11:38:55 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Wed; 5 Sep 2012 02:49:35 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-42
MAPREDUCE-4255,Bug,Major,jobhistoryserver;mrv2,Job History Server throws NPE if it fails to get keytab,nan,Resolved,Duplicate,YARN-530,Devaraj K,Devaraj K,Mon; 14 May 2012 13:07:16 +0000,Thu; 12 May 2016 18:24:30 +0000,Sat; 7 Feb 2015 00:18:48 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4255
MAPREDUCE-4256,Improvement,Major,resourcemanager,Improve resource scheduling,"Currently resource manager supports only Memory resource during container allocation.  I propose following improvements:  1. add support for CPU utilization. Node CPU used information can be obtained by ResourceCalculatorPlugin.  2. add support for custom resources. In node configuration will be something like:  name=node.resource.GPU; value=1 (node has 1 GPU).  If job will need to use GPU for computation; it will add ""GPU=1"" requirement to its job config and Resource Manager will allocate container on node with GPU available.",Resolved,Duplicate,YARN-2,Unassigned,Radim Kolar,Mon; 14 May 2012 15:47:40 +0000,Tue; 1 Jan 2013 11:10:29 +0000,Tue; 1 Jan 2013 11:10:29 +0000,,,,YARN-2,YARN-4;YARN-3,https://issues.apache.org/jira/browse/MAPREDUCE-4256
MAPREDUCE-4257,New Feature,Major,capacity-sched;mrv2,Support fair-sharing option within a MR2 Capacity Scheduler queue,The fair scheduler can run jobs in a single pool (queue) in FIFO or fair share mode. In FIFO mode one job runs at a time; in priority order; while in fair share mode multiple jobs can run at the same time; and they share the capacity of the pool. This JIRA is to add the latter feature to Capacity Scheduler as an option - the default would remain FIFO.,Resolved,Invalid,,Karthik Kambatla,Tom White,Mon; 14 May 2012 22:16:07 +0000,Mon; 3 Nov 2014 18:05:53 +0000,Thu; 12 Jul 2012 01:33:48 +0000,,,,,YARN-2,https://issues.apache.org/jira/browse/MAPREDUCE-4257
MAPREDUCE-4258,Bug,Minor,tasktracker,container-executor can't open 2+ GB files when compiled for 32-bit ,container-executor depends on libfts; and libfts has no largefile support.  Upstream bug here: http: show_bug.cgi?id=11460  As a consequence; when compiled for 32-bit architectures; container-executor will not be able to open files larger than 2 GB.  Probably the easier thing to do is to rewrite this so that it doesn't use libfts.,Open,Unresolved,,Unassigned,Colin P. McCabe,Mon; 14 May 2012 23:27:48 +0000,Mon; 14 May 2012 23:39:59 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4258
HDFS-3424,Bug,Major,,TestDatanodeBlockScanner and TestReplication fail intermittently on Windows,The tests change the block length to corrupt the data block. If the block file is opened by the datanode then the test can concurrently modify it on Linux but such concurrent modification is not allowed by the default permissions on Windows. Since this is more of a test issue; the fix would be to have the tests make sure that the block is not open concurrently.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Tue; 15 May 2012 17:21:29 +0000,Wed; 6 Jun 2012 01:55:03 +0000,Wed; 6 Jun 2012 01:55:03 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/HDFS-3424
MAPREDUCE-4260,Improvement,Major,,Use JobObject to spawn tasks on Windows,Currently; the Windows version spawns the task as a normal cmd shell from which other downstream exe's are spawned. However; this is not bullet proof because if an intermediate process exits before its child exits; then the parent child process tree relationship cannot be constructed. Windows has a concept of JobObject that is similar to the setsid behavior used in Linux. The initial spawned task could be launched within its JobObject. Thereafter; process termination; memory management etc could be operated on the JobObject.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Tue; 15 May 2012 23:12:49 +0000,Sat; 16 Jun 2012 00:34:18 +0000,Sat; 16 Jun 2012 00:34:18 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4260
MAPREDUCE-4261,Bug,Major,mr-am;mrv2,MRAppMaster throws NPE while stopping RMContainerAllocator service,nan,Patch Available,Unresolved,,Devaraj K,Devaraj K,Wed; 16 May 2012 13:12:13 +0000,Thu; 12 May 2016 18:22:30 +0000,,,2.0.0-alpha;2.0.1-alpha;2.0.2-alpha;3.0.0-alpha1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4261
MAPREDUCE-4262,Bug,Minor,mrv2;nodemanager,"NM gives wrong log message saying ""Connected to ResourceManager"" before trying to connect",nan,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 16 May 2012 13:45:18 +0000,Thu; 12 May 2016 18:24:26 +0000,Wed; 23 May 2012 18:38:47 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4262
MAPREDUCE-4263,Bug,Major,,Use taskkill /T to terminate tasks on Windows,On Linux setsid is used to link the processes spawned by the tasks into the same session. So termination of the task terminates the entire tree. We need to do the same for Windows. This is not fool proof but should be sufficient until we have a potentially better solution in MAPREDUCE-4260.,Resolved,Fixed,,Unassigned,Bikas Saha,Wed; 16 May 2012 17:11:06 +0000,Mon; 11 Jun 2012 20:43:56 +0000,Mon; 11 Jun 2012 20:43:56 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4263
MAPREDUCE-4264,Bug,Blocker,mrv2,Got ClassCastException when using mapreduce.history.server.delegationtoken.required=true,"Oozie fails to run on branch-0.23 with the following exception. This only affects branch-0.23 not branch-2 or trunk.      INFO mapreduce.JobSubmitter: Cleaning up the staging area  job_1337177706246_0001 1177)   Note that this is caused because oozie passes in the options:  -Dmapreduce.history.server.delegationtoken.required=true -Dmapreduce.history.server.delegationtoken.renewer=""mr token""",Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 16 May 2012 19:19:28 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Thu; 17 May 2012 04:35:17 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4264
MAPREDUCE-4265,Improvement,Major,capacity-sched,Support Queue type exclusive or shared,In the current implementation Capacity; MaxCapacity are the two main parameters that can be used for sharing resources on the cluster.  But there is no feature to protect the resource of a queue. In the absence of pre-emption as a feature; if someone decides to reserve its capacity for its exclusive use;  while rest of the queues are set for sharing; it is not simply possible.  If we choose one queue to be set for exclusive use by setting Capacity=MaxCapacity; this queue gets penalized; if others choose to set for sharing with their MaxCapacity more than capacity. This is an unintended consequence. On the other hand ;  if every queue is  set to  its Capacity=MaxCapacity  the cluster is being partitioned into distinct virtual clusters. So; the suggestion is; to add an additional queue parameter  queue_type with value exclusive or shared. By default a queue is always shared type. If queue_type is exclusive; the capacity of this queue is non sharable and should be taken out from  total capacity while scheduling jobs in other queues.,Open,Unresolved,,Unassigned,Dheeren Beborrtha,Wed; 16 May 2012 23:51:30 +0000,Wed; 16 May 2012 23:51:30 +0000,,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4265
MAPREDUCE-4266,Task,Major,build,remove Ant remnants from MR,Remove:  hadoop-mapreduce-project ivy.xml,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 17 May 2012 19:30:32 +0000,Wed; 3 Sep 2014 23:17:17 +0000,Fri; 9 Nov 2012 19:03:44 +0000,,2.0.0-alpha,,,MAPREDUCE-4687;MAPREDUCE-3868,https://issues.apache.org/jira/browse/MAPREDUCE-4266
MAPREDUCE-4267,Bug,Critical,mrv2,mavenize pipes,We are still building pipes out of the old mrv1 directories using ant.  Move it over to the mrv2 dir structure.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 18 May 2012 02:07:46 +0000,Sat; 7 Feb 2015 00:11:30 +0000,Tue; 19 Jun 2012 20:12:45 +0000,,0.23.3,,,HADOOP-8451;MAPREDUCE-4353,https://issues.apache.org/jira/browse/MAPREDUCE-4267
MAPREDUCE-4269,Bug,Major,mrv2,documentation: Gridmix has javadoc warnings in StressJobFactory,nan,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Sat; 19 May 2012 06:00:44 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Mon; 21 May 2012 02:01:02 +0000,,0.23.3;2.0.0-alpha,mrv2,,,https://issues.apache.org/jira/browse/MAPREDUCE-4269
MAPREDUCE-4270,Bug,Major,mrv2,data_join test classes are in the wrong packge,There are three Sample*. org   based on their package.,Closed,Fixed,,Thomas Graves,Brock Noland,Sun; 20 May 2012 00:27:31 +0000,Tue; 10 Mar 2015 04:30:49 +0000,Tue; 19 Jun 2012 21:54:40 +0000,,0.23.3,,,MAPREDUCE-4238,https://issues.apache.org/jira/browse/MAPREDUCE-4270
MAPREDUCE-4271,Bug,Major,capacity-sched,Make TestCapacityScheduler more robust with non-Sun JDK,The capacity scheduler queue is initialized with a HashMap; the values of which are later added to a list (a queue for assigning tasks). TestCapacityScheduler depends on the order of the list hence not portable across JDKs.,Patch Available,Unresolved,,Yu Gao,Luke Lu,Sun; 20 May 2012 04:35:40 +0000,Wed; 6 May 2015 03:31:42 +0000,,,1.0.3,BB2015-05-TBR;alt-jdk;capacity,,HADOOP-8192,https://issues.apache.org/jira/browse/MAPREDUCE-4271
MAPREDUCE-4272,Bug,Major,task,SortedRanges.Range#compareTo is not spec compliant,"SortedRanges.Range#compareTo does not satisfy the requirement of Comparable#compareTo; where ""the implementor must ensure     for all x and y.""  This is manifested as TestStreamingBadRecords failures in alternative JDKs.",Closed,Fixed,,Yu Gao,Luke Lu,Sun; 20 May 2012 04:49:42 +0000,Wed; 3 Sep 2014 23:15:00 +0000,Fri; 4 Jan 2013 18:23:58 +0000,,1.0.3,alt-jdk,,HADOOP-8192,https://issues.apache.org/jira/browse/MAPREDUCE-4272
MAPREDUCE-4273,Bug,Major,client,Make CombineFileInputFormat split result JDK independent,The split result of CombineFileInputFormat depends on the iteration order of  nodeToBlocks and rackToBlocks hash maps; which makes the result HashMap implementation hence JDK dependent.  This is manifested as TestCombineFileInputFormat failures on alternative JDKs.,Patch Available,Unresolved,,Yu Gao,Luke Lu,Sun; 20 May 2012 05:16:45 +0000,Wed; 6 May 2015 03:31:55 +0000,,,1.0.3,BB2015-05-TBR,,HADOOP-8192,https://issues.apache.org/jira/browse/MAPREDUCE-4273
MAPREDUCE-4274,Improvement,Minor,performance;task,MapOutputBuffer should use native byte order for kvmeta,I don't have a benchmark to support this; but this should give a small CPU improvement on the map output buffer: currently; we create kvmeta as ByteBuffer.wrap(kvbuffer).asIntBuffer(). According to the  ocs; the resulting int buffer will inherit its byte order from the ByteBuffer it comes from; and the byte buffer defaults to BIG_ENDIAN. Thus; all of our int access to from the buffer will require byte-swapping.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Sun; 20 May 2012 21:43:35 +0000,Mon; 16 Mar 2015 18:44:37 +0000,Mon; 21 May 2012 19:07:36 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4274
YARN-57,Improvement,Major,nodemanager,Plugable process tree,Trunk version of Pluggable process tree. Work based on MAPREDUCE-4204,Closed,Fixed,,Radim Kolar,Radim Kolar,Mon; 21 May 2012 07:08:57 +0000,Wed; 3 Sep 2014 23:20:23 +0000,Fri; 7 Sep 2012 15:49:25 +0000,,,,,MAPREDUCE-4204,https://issues.apache.org/jira/browse/YARN-57
MAPREDUCE-4276,Bug,Major,mrv2,"Allow setting yarn.nodemanager.delete.debug-delay-sec property to ""-1"" for easier container debugging.","Allow setting yarn.nodemanager.delete.debug-delay-sec property to ""-1"" to have it never clear (like older TT time).",Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 22 May 2012 19:12:20 +0000,Thu; 11 Oct 2012 17:48:45 +0000,Wed; 23 May 2012 22:24:10 +0000,,2.0.0-alpha,,,MAPREDUCE-3883,https://issues.apache.org/jira/browse/MAPREDUCE-4276
YARN-1160,Improvement,Minor,resourcemanager,allow admins to force app deployment on a specific host,Currently you ask YARN to get slots on a host and it finds a slot on that machine -or; if unavailable or there is no room; on a host nearby as far as the topology is concerned.  People with admin rights should have the option to deploy a process on a specific host and have it run there even if there are no free slots -and to fail if the machine is not available. This would let you deploy admin-specific process across a cluster.,Open,Unresolved,,Unassigned,Steve Loughran,Tue; 22 May 2012 19:28:44 +0000,Thu; 12 May 2016 18:30:03 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-1160
MAPREDUCE-4278,Bug,Major,,cannot run two local jobs in parallel from the same gateway.,I cannot run two local mode jobs from Pig in parallel from the same gateway; this is a typical use case. If I re-run the tests sequentially; then the test pass. This seems to be a problem from Hadoop.  Additionally; the pig harness; expects to be able to run Pig-version-undertest against Pig-version-stable from the same gateway.   To replicate the error:  I have two clusters running from the same gateway. If I run the Pig regression suites nightly.conf in local mode in paralell - once on each cluster. Conflicts in M file.out in any of the configured local directories          org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner. 212) 2012-05-17 20:25:41;291 main INFO org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher,Closed,Fixed,,Sandy Ryza,Araceli Henley,Tue; 22 May 2012 19:52:09 +0000,Tue; 23 Jul 2013 23:11:48 +0000,Tue; 8 Jan 2013 16:38:17 +0000,,0.20.205.0,,,MAPREDUCE-5367,https://issues.apache.org/jira/browse/MAPREDUCE-4278
MAPREDUCE-4279,Bug,Major,jobtracker,getClusterStatus() fails with null pointer exception when running jobs in local mode,While migrating code from 0.20.2 hadoop codebase to 0.23.1 we encountered this issue for jobs run in local mode of execution:    We are using cloudera distribution CDH4b2 for testing; however the underlying code is 0.23.1 and I could see no difference in this implementation.,Closed,Fixed,,Devaraj K,Rahul Jain,Tue; 22 May 2012 20:43:28 +0000,Thu; 12 May 2016 18:23:04 +0000,Thu; 3 Jan 2013 17:25:03 +0000,,0.23.1;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4279
MAPREDUCE-4280,Bug,Major,,LocalJobRunner doesn't honor custom OutputCommiter cleanupJob,I have an implementation SampleFileOutputCommiter which extends org.apache.hadoop.mapred.FileOutputCommitter . The implementation has specific code to be executed during cleanupJob() execution. When the framework(LocalJobRunner) makes a call to commitJob(); the framework never takes care of calling the cleanupJob() instead it calls org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitJob() which internally calls its own cleanupJob(). Though the method cleanupJob is deprecated but; still I feel the framework should take care of executing it as it is being executed from org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter. Currently the framework is not letting the Jobs written with MRV1 to run properly.,Open,Unresolved,MAPREDUCE-3563,Unassigned,Subroto Sanyal,Wed; 23 May 2012 11:35:55 +0000,Tue; 14 May 2013 05:14:40 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4280
MAPREDUCE-4281,Bug,Major,,LocalJobRunner doesn't handle Jobs using o.a.h.mapreduce.OutputCommitter,Backport MAPREDUCE-3563 for 1.0 version,Open,Unresolved,,Unassigned,Subroto Sanyal,Wed; 23 May 2012 12:12:28 +0000,Wed; 23 May 2012 12:13:31 +0000,,,1.0.0,,,MAPREDUCE-3563,https://issues.apache.org/jira/browse/MAPREDUCE-4281
MAPREDUCE-4282,Task,Major,documentation,Convert Forrest docs to APT,MR side of HADOOP-8427. Not all of the old forrest docs in src xdocs have been converted over to APT yet; let's do that and remove the forrest docs.,Closed,Fixed,,Akira Ajisaka,Eli Collins,Wed; 23 May 2012 17:33:22 +0000,Wed; 3 Sep 2014 20:33:54 +0000,Tue; 6 May 2014 16:22:36 +0000,,2.0.0-alpha,newbie,,HADOOP-8427,https://issues.apache.org/jira/browse/MAPREDUCE-4282
MAPREDUCE-4283,Improvement,Major,jobhistoryserver;mrv2,Display tail of aggregated logs by default,Similar to the manner in which the nodemanager webUI displays container logs; it would be very useful if the historyserver showed the trailing 4K or so of the aggregated logs with a link to see the full log.  When debugging issues the relevant errors are usually at the end of the log; so showing just the last few K can enable quick diagnosis without waiting for what can be many megabytes of log data to download.,Closed,Fixed,MAPREDUCE-3111,Jason Lowe,Jason Lowe,Wed; 23 May 2012 21:34:02 +0000,Mon; 21 Apr 2014 18:17:59 +0000,Tue; 17 Jul 2012 19:10:31 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4283
MAPREDUCE-4284,Bug,Major,mrv2,Allow setting yarn.nodemanager.delete.debug-delay-sec on a per-job basis,The yarn.nodemanager.delete.debug-delay-sec property is helpful in debugging jobs (inspecting container logs local dirs after the job finishes). Currently it is a nodemanager property and changing it requires restarting the nodemanager. In a production cluster this can be a real problem. It is better to have this property set on a per-job basis and not requiring the restart of nodemanagers.,Reopened,Unresolved,,Ahmed Radwan,Ahmed Radwan,Wed; 23 May 2012 22:50:15 +0000,Fri; 25 May 2012 23:40:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4284
MAPREDUCE-4285,Bug,Minor,mrv1,Code sample in Tool javadocs is broken,The  ocs are online: http: Tool.html,Patch Available,Unresolved,,Gergely Nov  k,Steve Loughran,Sat; 26 May 2012 21:54:47 +0000,Tue; 10 May 2016 15:27:07 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4285
MAPREDUCE-4286,Bug,Major,,TestClientProtocolProviderImpls passes on failure conditions,nan,Closed,Fixed,,Devaraj K,Devaraj K,Mon; 28 May 2012 05:55:01 +0000,Fri; 10 Apr 2015 20:19:38 +0000,Wed; 18 Feb 2015 06:47:21 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4286
MAPREDUCE-4287,Bug,Major,mrv2,jobClient.getQueues () API is giving empty by default,"getQueues () API is returning empty instead of giving default queue info. By default ""default"" queue will be there so the API should return default queue info.",Open,Unresolved,,Devaraj K,Nishan Shetty,Mon; 28 May 2012 14:50:01 +0000,Thu; 12 May 2016 18:23:00 +0000,,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4287
MAPREDUCE-4288,Bug,Major,mrv2,ClusterStatus.getMapTasks() and ClusterStatus.getReduceTasks() is giving one when no job is running,When no job is running in the cluster invoke the ClusterStatus.getMapTasks() and ClusterStatus.getReduceTasks() API's Observed that these API's are returning one instead of zero(as no job is running),Open,Unresolved,,Unassigned,Nishan Shetty,Mon; 28 May 2012 15:10:51 +0000,Tue; 12 May 2015 09:35:05 +0000,,,2.0.0-alpha,,,MAPREDUCE-4289,https://issues.apache.org/jira/browse/MAPREDUCE-4288
MAPREDUCE-4289,Bug,Major,mrv2,JobStatus.getReduceProgress() and JobStatus.getMapProgress() API's not giving any values,1.Run a simple job 2.Invoke JobStatus.getReduceProgress() and JobStatus.getMapProgress() API's  Observe that these API's are giving zeros instead of showing map reduce progress,Open,Unresolved,,Unassigned,Nishan Shetty,Mon; 28 May 2012 15:53:04 +0000,Tue; 12 May 2015 09:35:33 +0000,,,2.0.0-alpha,,,MAPREDUCE-4288,https://issues.apache.org/jira/browse/MAPREDUCE-4289
MAPREDUCE-4290,Bug,Major,mrv2,JobStatus.getState() API is giving ambiguous values,For failed job getState() API is giving status as SUCCEEDED if we use JobClient.getAllJobs() for retrieving all jobs info from RM.,Closed,Fixed,,Devaraj K,Nishan Shetty,Tue; 29 May 2012 04:17:14 +0000,Thu; 12 May 2016 18:22:49 +0000,Mon; 25 Jun 2012 17:56:38 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4290
MAPREDUCE-4291,Bug,Major,mrv2,RpcServerFactoryPBImpl force yarn users to define a protocol in a entailed namespace,We defined a wire protocol use protobuf with its  that issues in the bug.,Open,Unresolved,,Unassigned,Min Zhou,Tue; 29 May 2012 08:26:44 +0000,Tue; 10 Mar 2015 04:31:48 +0000,,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4291
MAPREDUCE-4292,Bug,Critical,mrv2,Job is hanging forever when some maps are failing always,"Set property ""mapred.reduce.tasks"" to some value greater than zero  I have a job in which some maps are failing always.  Observations: 1.Map phase is completing with 100%(with succeeded and failed maps).  2.Reduce phase is not progressing further after 32%. 3.After map phase is completed job is hanging forever.  Expected that job should be failed after waiting for some time.",Resolved,Duplicate,MAPREDUCE-3927,Unassigned,Nishan Shetty,Wed; 30 May 2012 07:13:37 +0000,Wed; 13 Jun 2012 06:20:37 +0000,Wed; 13 Jun 2012 06:20:36 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4292
MAPREDUCE-4293,Bug,Major,tools/rumen,Rumen TraceBuilder gets NPE some times,Rumen TraceBuilder's JobBuilder.processTaskFailedEvent throws NPE if failedDueToAttempt is not available in history.,Patch Available,Unresolved,,Ravi Gummadi,Ravi Gummadi,Wed; 30 May 2012 08:34:24 +0000,Wed; 6 May 2015 03:31:01 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4293
MAPREDUCE-4294,Bug,Major,mrv2,Submitting job by enabling task profiling gives IOException,nan,Resolved,Fixed,,Devaraj K,Nishan Shetty,Wed; 30 May 2012 12:05:00 +0000,Thu; 12 May 2016 18:22:31 +0000,Thu; 12 Feb 2015 14:03:08 +0000,,2.0.0-alpha;3.0.0-alpha1,,,MAPREDUCE-3889;MAPREDUCE-4218,https://issues.apache.org/jira/browse/MAPREDUCE-4294
MAPREDUCE-4295,Bug,Critical,mrv2;resourcemanager,RM crashes due to DNS issue,we had a DNS outage and the RM crashed with the following backtrace:  2012-05-29 19:17:34;492 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler  1213),Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 30 May 2012 14:41:56 +0000,Sat; 8 Jun 2013 01:46:34 +0000,Thu; 21 Jun 2012 18:16:29 +0000,,,,,YARN-713,https://issues.apache.org/jira/browse/MAPREDUCE-4295
YARN-25,Bug,Major,,remove old aggregated logs,Currently the aggregated user logs under NM_REMOTE_APP_LOG_DIR are never removed.  We should have mechanism to remove them after certain period.  It might make sense for job history server to remove them.,Closed,Fixed,,Robert Joseph Evans,Thomas Graves,Wed; 30 May 2012 15:47:16 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Fri; 17 Aug 2012 20:33:41 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/YARN-25
MAPREDUCE-4297,Bug,Major,contrib/gridmix,Usersmap file in gridmix should not fail on empty lines,An empty line (e.g. at the end of the file) in the usersmap file will cause gridmix to fail. Empty lines should be silently ignored.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 30 May 2012 17:23:16 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Thu; 31 May 2012 15:19:29 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4297
MAPREDUCE-4298,Bug,Critical,mrv2;nodemanager,NodeManager crashed after running out of file descriptors,A node on one of our clusters fell over because it ran out of open file descriptors.  Log details with stack traceback to follow.,Resolved,Duplicate,HADOOP-8495,Jason Lowe,Jason Lowe,Thu; 31 May 2012 19:18:56 +0000,Thu; 12 May 2016 18:23:45 +0000,Mon; 18 Jun 2012 14:29:34 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4298
MAPREDUCE-4299,Bug,Major,mrv2,Terasort hangs with MR2 FifoScheduler,What happens is that the number of reducers ramp up until they occupy all of the job's containers; at which point the maps no longer make any progress and the job hangs.  When the same job is run with the CapacityScheduler it succeeds; so this looks like a FifoScheduler bug.,Closed,Fixed,MAPREDUCE-4358;MAPREDUCE-4613,Tom White,Tom White,Thu; 31 May 2012 20:41:50 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Fri; 13 Jul 2012 20:56:31 +0000,,2.0.0-alpha,,,MAPREDUCE-4560,https://issues.apache.org/jira/browse/MAPREDUCE-4299
MAPREDUCE-4300,Bug,Major,applicationmaster,OOM in AM can turn it into a zombie.,It looks like 4 threads in the AM died with OOM but not the one pinging the RM.  stderr for this AM,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 31 May 2012 20:44:00 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Mon; 9 Jul 2012 21:12:30 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4300
MAPREDUCE-4301,Improvement,Major,applicationmaster,Dedupe some strings in MRAM for memory savings,Recently an OutOfMemoryError caused one of our jobs to become a zombie (MAPREDUCE-4300).  It was a rather large job with 78000+ map tasks and only 750MB of heap configured.  I took a heap dump to see if there were any obvious memory leaks; and I could not find any; but yourkit and some digging found some potential memory optimizations that we could do.  In this particular case we could save about 20MB if SplitMetaInfoReader.readSplitMetaInfo only computed the JobSplitFile once instead of for each split. (a 2 line change)  I will look into some others and see if there are more savings I can come up with.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 1 Jun 2012 16:26:42 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Mon; 4 Jun 2012 15:17:01 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4301
MAPREDUCE-4302,Bug,Critical,nodemanager,NM goes down if error encountered during log aggregation,When a container launch request is sent to the NM; if any exception occurs during the init of log aggregation then the NM goes down.  The problem can be induced by situations including; but certainly not limited to: transient rpc connection issues; missing tokens; expired tokens; permissions; full quota exceeded dfs; etc.  The problem may occur with and without security enabled.  The ramification is an entire cluster can be rather easily brought down either maliciously; accidentally; or via a submission bug.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Fri; 1 Jun 2012 16:48:13 +0000,Tue; 10 Mar 2015 04:30:25 +0000,Fri; 1 Jun 2012 22:01:46 +0000,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4302
MAPREDUCE-4303,Improvement,Major,applicationmaster,Look at using String.intern to dedupe some Strings,MAPREDUCE-4301 fixes one issue with too many duplicate strings; but there are other places where it is not as simple to remove the duplicates.  In these cases the source of the strings is an incoming RPC call or from parsing and reading in a file.  The only real way to dedupe these is to either use String.intern() which if not used properly could result in the permgen space being filled up; or by playing games with our own cache; and trying to do the same sort of thing as String.intern; but in the heap.  The following are some that I saw lots of duplicate strings that we should look at doing something about.  TaskAttemptStatusUpdateEvent$TaskAttemptState.stateString MapTaskAttemptImpl.diagnostics The keys to Counters.groups GenericGroup.displayName The keys to GenericGroup.counters and GenericCounter.displayName,Resolved,Duplicate,MAPREDUCE-4229,Unassigned,Robert Joseph Evans,Fri; 1 Jun 2012 19:19:12 +0000,Wed; 24 Oct 2012 14:03:07 +0000,Wed; 24 Oct 2012 14:03:07 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4303
MAPREDUCE-4304,Improvement,Major,mrv2;resourcemanager,Deadlock where all containers are held by ApplicationMasters should be prevented,In my test cluster with 4 NodeManagers; each with only ~1.6G container memory; when a burst of jobs; e.g. 10; are concurrently submitted; it is likely that 4 jobs are accepted; with 4 ApplicationMasters allocated; but then the jobs block each other indefinitely because they're all waiting to allocate more containers.  Note that the problem is not limited to tiny cluster like this.  As long as the number of jobs being submitted is greater than the rate jobs finish; it may run into a vicious cycle where more and more containers are locked up by ApplicationMasters.,Open,Unresolved,,Unassigned,Herman Chen,Fri; 1 Jun 2012 21:32:01 +0000,Fri; 12 Oct 2012 21:24:47 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4304
MAPREDUCE-4305,New Feature,Major,,Implement delay scheduling in capacity scheduler for improving data locality,Capacity Scheduler data local tasks are about 40%-50% which is not good. While my test with 70 node cluster i consistently get data locality around 40-50% on a free cluster.  I think we need to implement something like delay scheduling in the capacity scheduler for improving the data locality. http: 308  After implementing the delay scheduling on Hadoop 22 I am getting 100 % data locality in free cluster and around 90% data locality in busy cluster.  Thanks; Mayank,Open,Unresolved,,Mayank Bansal,Mayank Bansal,Fri; 1 Jun 2012 22:14:20 +0000,Tue; 8 Oct 2013 03:00:17 +0000,,,,,,YARN-80,https://issues.apache.org/jira/browse/MAPREDUCE-4305
MAPREDUCE-4306,Bug,Major,mrv2,Problem running Distributed Shell applications as a user other than the one started the daemons,Using the tarball; if you start the yarn daemons using one user and then switch to a different user. You can successfully run MR jobs; but DS jobs fail to run. Only able to run DS jobs using the user who started the daemons.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Sat; 2 Jun 2012 06:33:07 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Tue; 19 Jun 2012 22:03:22 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4306
MAPREDUCE-4307,Bug,Major,mrv2,TeraInputFormat calls FileSystem.getDefaultBlockSize() without a Path - Failure when using ViewFileSystem,ViewFileSystem.getDefaultBlockSize() throws NotInMountpointException (see HADOOP-8014). I'll upload a patch momentarily.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Sat; 2 Jun 2012 11:03:31 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Sat; 2 Jun 2012 18:51:25 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4307
MAPREDUCE-4308,Improvement,Major,jobtracker,Remove excessive split log messages,Job tracker currently prints out information on every split.     I looked at one cluster and these messages were taking up more than 30% of the JT log. If jobs have large number of maps; it can be worse. I think it is reasonable to lower the log level of the statement from INFO to DEBUG.,Patch Available,Unresolved,,Unassigned,Kihwal Lee,Mon; 4 Jun 2012 16:48:04 +0000,Wed; 6 May 2015 03:31:13 +0000,,,1.0.3,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4308
YARN-18,New Feature,Major,,Configurable Hierarchical Topology for YARN,Per discussion in the design lounge of Hadoop Summit 2013; we agreed to change the design of  Pluggable topologies with NodeGroup for YARN  to support a configurable hierarchical topology that makes adding additional locality layers simple. Please refer attached doc HierachicalTopologyForYARNr1.pdf for details.,Open,Unresolved,,Junping Du,Junping Du,Mon; 4 Jun 2012 06:06:02 +0000,Fri; 22 Aug 2014 01:07:43 +0000,,,2.0.3-alpha,features,HADOOP-10512,,https://issues.apache.org/jira/browse/YARN-18
YARN-19,New Feature,Major,,4-layer topology (with NodeGroup layer) implementation of Container Assignment and Task Scheduling (for YARN),There are several classes in YARN s container assignment and task scheduling algorithms that related to data locality which were updated to give preference to running a container on the same nodegroup. This section summarized the changes in the patch that provides a new implementation to support a four-layer hierarchy. When the ApplicationMaster makes a resource allocation request to the scheduler of ResourceManager; it will add the node group to the list of attributes in the ResourceRequest. The parameters of the resource request will change from priority; (host; rack; *); memory; #containers to priority; (host; nodegroup; rack; *); memory; #containers. After receiving the ResoureRequest the RM scheduler will assign containers for requests in the sequence of data-local; nodegroup-local; rack-local and off-switch.Then; ApplicationMaster schedules tasks on allocated containers in sequence of data- local; nodegroup-local; rack-local and off-switch. In terms of code changes made to YARN task scheduling; we updated the class ContainerRequestEvent so that applications can requests for containers can include anodegroup. In RM schedulers; FifoScheduler and CapacityScheduler were updated. For the FifoScheduler; the changes were in the method assignContainers. For the Capacity Scheduler the method assignContainersOnNode in the class of LeafQueue was updated. In both changes a new method; assignNodeGroupLocalContainers() was added in between the assignment data-local and rack-local.,Open,Unresolved,,Junping Du,Junping Du,Mon; 4 Jun 2012 06:21:35 +0000,Thu; 4 Jun 2015 05:56:24 +0000,,,,,HADOOP-10512,,https://issues.apache.org/jira/browse/YARN-19
MAPREDUCE-4311,Bug,Major,capacity-sched;mrv2,Capacity scheduler.xml does not accept decimal values for capacity and maximum-capacity settings,"if capacity scheduler capacity or max capacity set with decimal it errors:   	Error starting ResourceManager     lang.NumberFormatException: For input string: ""10.5""           0.20 used to take decimal and this could be an issue on large clusters that would have queues with small allocations.",Closed,Fixed,,Karthik Kambatla,Thomas Graves,Mon; 4 Jun 2012 18:08:51 +0000,Mon; 3 Nov 2014 18:05:51 +0000,Tue; 19 Jun 2012 13:10:10 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4311
MAPREDUCE-4312,Improvement,Minor,mrv2;resourcemanager,Add metrics to RM for NM heartbeats,It would be nice to have a metric in the ResourceManager to track the number of NodeManager heartbeats processed.  The JobTracker in 1.0 has a tasktracker heartbeat metric; and it would be nice if the RM had the equivalent metric.,Resolved,Not A Problem,,Jason Lowe,Jason Lowe,Mon; 4 Jun 2012 22:12:43 +0000,Tue; 5 Jun 2012 21:20:21 +0000,Tue; 5 Jun 2012 21:20:21 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4312
MAPREDUCE-4313,Bug,Blocker,build;test,TestTokenCache doesn't compile due TokenCache.getDelegationToken compilation error,Saw this on the trunk Jenkins job:,Closed,Fixed,,Robert Joseph Evans,Eli Collins,Tue; 5 Jun 2012 01:24:38 +0000,Thu; 4 Sep 2014 01:00:32 +0000,Tue; 5 Jun 2012 15:10:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4313
MAPREDUCE-4314,Bug,Major,tasktracker,Synchronization in JvmManager for 0.22 branch,Changes to JvmManager due to MR-2178 for branch 0.22.,Resolved,Fixed,,Benoy Antony,Konstantin Shvachko,Tue; 5 Jun 2012 07:24:11 +0000,Tue; 5 Jun 2012 13:53:45 +0000,Tue; 5 Jun 2012 07:34:21 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4314
MAPREDUCE-4315,Bug,Major,jobhistoryserver,jobhistory.jsp throws 500 when a .txt file is found in /done,if a .txt file located in  done touch test.txt reload jobhistory,Closed,Fixed,,Sandy Ryza,Alexander Alten-Lorenz,Tue; 5 Jun 2012 08:02:28 +0000,Wed; 15 May 2013 05:15:56 +0000,Wed; 16 Jan 2013 23:56:32 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4315
YARN-138,Bug,Major,resourcemanager;scheduler,Improve default config values for YARN,Currently some of our configs are way off e.g. min-alloc is 128M while max-alloc is 10240.  This leads to poor out-of-box performance as noticed by some users: http: avd,Closed,Fixed,,Harsh J,Arun C Murthy,Tue; 5 Jun 2012 12:15:00 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Sun; 30 Sep 2012 03:48:44 +0000,,2.0.0-alpha,performance,,,https://issues.apache.org/jira/browse/YARN-138
MAPREDUCE-4317,Bug,Major,mrv1,Job view ACL checks are too permissive,The class that does view-based checks; JSPUtil.JobWithViewAccessCheck; has the following internal member:     Note that its true.  Now; in the method that sets proper view-allowed rights; has:     In the above snippet; you can notice that if user==null; which can happen if user is not http-authenticated (as its got via request.getRemoteUser()); can lead to the view being visible since the default is true and we didn't toggle the view to false for user == null case.  Ideally the default of the view job ACL must be false; or we need an else clause that sets the view rights to false in case of a failure to find the user ID.,Closed,Fixed,,Karthik Kambatla,Harsh J,Tue; 5 Jun 2012 13:51:29 +0000,Mon; 3 Nov 2014 18:06:07 +0000,Thu; 5 Jul 2012 16:51:42 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4317
MAPREDUCE-4318,Bug,Major,test,TestRecoveryManager should not use raw and deprecated configuration parameters.,TestRecoveryManager should not use deprecated config keys; and should use constants for the keys where possible.,Resolved,Fixed,,Benoy Antony,Konstantin Shvachko,Tue; 5 Jun 2012 17:51:16 +0000,Fri; 8 Jun 2012 05:02:05 +0000,Fri; 8 Jun 2012 01:18:21 +0000,,0.22.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4318
MAPREDUCE-4319,Bug,Major,mrv2,MRClientProtocolPBClientImpl creates proxy for AM ignoring custom SocketFactory,Use a Customized socket factory and set in the configuration. The constructor of MRClientProtocolPBClientImpl creates proxy with DefaultSocketFactory    It should use NetUtils.getSocketFactory(Configuration conf;Class? clazz),Open,Unresolved,,Unassigned,Subroto Sanyal,Wed; 6 Jun 2012 14:45:22 +0000,Wed; 6 Jun 2012 14:47:09 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4319
MAPREDUCE-4320,Bug,Major,contrib/gridmix,gridmix mainClass wrong in pom.xml,when trying to run gridmix its actually trying to run org.apache.hadoop.tools.HadoopArchives.  the pom.xml needs to be fixed to have correct mainClass: org.apache.hadoop.mapred.gridmix.Gridmix,Closed,Fixed,,Thomas Graves,Thomas Graves,Wed; 6 Jun 2012 20:59:59 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Thu; 21 Jun 2012 15:03:38 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4320
MAPREDUCE-4321,Bug,Major,,DefaultTaskController fails to launch tasks on Windows,DefaultTaskController#launchTask tries to run the child JVM task with the following command line:   And this fails because the given path is prefixed with a forward slash. This also causes a number of tests to fail:  org.apache.hadoop.conf.TestNoDefaultsJobConf org.apache.hadoop.fs.TestCopyFiles org.apache.hadoop.mapred.TestBadRecords org.apache.hadoop.mapred.TestClusterMRNotification org.apache.hadoop.mapred.TestCompressedEmptyMapOutputs org.apache.hadoop.mapred.TestControlledMapReduceJob org.apache.hadoop.mapred.TestCustomOutputCommitter org.apache.hadoop.mapred.TestEmptyJob org.apache.hadoop.mapred.TestFileOutputFormat org.apache.hadoop.mapred.TestIsolationRunner org.apache.hadoop.mapred.TestJavaSerialization org.apache.hadoop.mapred.TestJobCleanup org.apache.hadoop.mapred.TestJobCounters org.apache.hadoop.mapred.TestJobHistoryServer org.apache.hadoop.mapred.TestJobInProgressListener org.apache.hadoop.mapred.TestJobKillAndFail org.apache.hadoop.mapred.TestJobName ...,Resolved,Fixed,,Ivan Mitic,Ivan Mitic,Wed; 6 Jun 2012 21:15:07 +0000,Mon; 11 Jun 2012 19:04:35 +0000,Mon; 11 Jun 2012 19:04:21 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4321
MAPREDUCE-4322,Bug,Major,tasktracker,Fix command-line length abort issues on Windows,When a task is started on the tasktracker; it creates a small batch file to invoke  and runs that batch.  Within the batch file; the invocation of Java currently has -classpath ${CLASSPATH} inline to the command.  That line often exceeds 8000 characters.  This is ok for most linux distributions because the line limit env variable is often set much higher than this.  However; for Windows this cause cmd to abort execution.  This surfaces in Hadoop as an unknown failure mode for the task.  I think the easiest and most natural way to fix this is to push the -classpath option into a config file to take the longest variable part of the line and put it somewhere that scales better.,Resolved,Fixed,,Ivan Mitic,John Gordon,Wed; 6 Jun 2012 21:42:01 +0000,Thu; 5 Jul 2012 07:03:49 +0000,Thu; 5 Jul 2012 07:03:49 +0000,,,,,HADOOP-8079,https://issues.apache.org/jira/browse/MAPREDUCE-4322
YARN-58,Bug,Critical,nodemanager,NM leaks filesystems,The NM is exhausting its fds because it's not closing fs instances when the app is finished.,Closed,Fixed,MAPREDUCE-4340,Jason Lowe,Daryn Sharp,Thu; 7 Jun 2012 15:28:12 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Mon; 20 Aug 2012 18:33:27 +0000,,,,HADOOP-8490,,https://issues.apache.org/jira/browse/YARN-58
MAPREDUCE-4324,Bug,Major,mrv1;mrv2;security,JobClient can perhaps set mapreduce.job.credentials.binary rather than expect its presence?,"HDFS-1007 added in this requirement property ""mapreduce.job.credentials.binary""; that has lead Oozie to add the following duplicate snippet to all its Job-launching main classes such as the Pig; Hive; MR and Sqoop actions:     Same is required for any client program that launches a job from within a task.  Why can't this simply be set by the JobClient initialization bits itself? If no one imagines it causing issues; I'd like to add this snippet somewhere in JobSubmitter before it requests NN JT; as otherwise we'd get        or similar errors when a user submits a job from a task running in a secured cluster.  Let me know your thoughts on this!",Resolved,Won't Fix,,Harsh J,Harsh J,Thu; 7 Jun 2012 16:25:54 +0000,Sun; 2 Dec 2012 04:55:00 +0000,Sun; 2 Dec 2012 04:55:00 +0000,,0.22.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4324
YARN-240,Improvement,Major,,Rename ProcessTree.isSetsidAvailable,The logical use of this member is to find out if processes can be grouped into a unit for process manipulation. eg. killing process groups etc. setsid is the Linux implementation and it leaks into the name. I suggest renaming it to isProcessGroupAvailable.,Resolved,Won't Fix,,Bikas Saha,Bikas Saha,Thu; 7 Jun 2012 19:05:27 +0000,Fri; 1 May 2015 21:22:14 +0000,Fri; 1 May 2015 21:22:14 +0000,,trunk-win,,,HADOOP-8079,https://issues.apache.org/jira/browse/YARN-240
YARN-128,New Feature,Major,resourcemanager,[Umbrella] RM Restart Phase 1: State storage and non-work-preserving recovery,This umbrella jira tracks the work needed to preserve critical state information and reload them upon RM restart.,Resolved,Fixed,,Unassigned,Arun C Murthy,Fri; 8 Jun 2012 04:05:32 +0000,Fri; 8 May 2015 18:07:37 +0000,Sun; 3 May 2015 02:29:20 +0000,,2.0.0-alpha,,MAPREDUCE-5505;YARN-1082;YARN-495,MAPREDUCE-5471;MAPREDUCE-5127;MAPREDUCE-5466;YARN-1305;MAPREDUCE-5472;MAPREDUCE-5567;YARN-209;YARN-479;YARN-149;YARN-218;YARN-556;YARN-1139;MAPREDUCE-5476,https://issues.apache.org/jira/browse/YARN-128
YARN-2,New Feature,Major,capacityscheduler;scheduler,Enhance CS to schedule accounting for both memory and cpu cores,With YARN being a general purpose system; it would be useful for several applications (MPI et al) to specify not just memory but also CPU (cores) for their resource requirements. Thus; it would be useful to the CapacityScheduler to account for both.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 8 Jun 2012 05:15:06 +0000,Thu; 2 May 2013 02:29:59 +0000,Wed; 9 Jan 2013 05:17:15 +0000,,,,MAPREDUCE-4520;YARN-326;YARN-8;MAPREDUCE-4256,YARN-3;MAPREDUCE-4257;YARN-160,https://issues.apache.org/jira/browse/YARN-2
MAPREDUCE-4328,Improvement,Major,mrv1,Add the option to quiesce the JobTracker,In several failure scenarios it would be very handy to have an option to quiesce the JobTracker.  Recently; we saw a case where the NameNode had to be rebooted at a customer due to a random hardware failure - in such a case it would have been nice to not lose jobs by quiescing the JobTracker.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 8 Jun 2012 07:19:52 +0000,Wed; 17 Oct 2012 18:27:25 +0000,Mon; 27 Aug 2012 15:35:09 +0000,,1.0.3,,,HDFS-3518,https://issues.apache.org/jira/browse/MAPREDUCE-4328
MAPREDUCE-4329,Bug,Major,security,security.task.umbilical.protocol.acl should not be configurable,On running MapReduce job; username is changed to jobid and the job fails. Exception is as follows:     This issue can be reproduced by following steps:  1. set hadoop.security.authorization = true in core-site.xml     2. set any value except for '*' to security.task.umbilical.protocol.acl in hadoop-policy.xml     3. run any mapreduce job.   Code Analysis  . Child.  the task authenticates to the TaskTracker using the jobtoken. The username in the jobtoken is jobId. The doAs block done using taskOwner is required so that the username mentioned in the token and the one doing the operation matches.  We can't change security.task.umbilical.protocol.acl and should always be '*' . TaskUmbilicalProtocol should be removed from MapReducePolicyProvider to disable security.task.umbilical.protocol.acl.,Open,Unresolved,,Sho Shimauchi,Sho Shimauchi,Fri; 8 Jun 2012 10:56:27 +0000,Tue; 15 Sep 2015 18:29:17 +0000,,,1.0.3,,,MAPREDUCE-4566;HADOOP-12413,https://issues.apache.org/jira/browse/MAPREDUCE-4329
MAPREDUCE-4330,Bug,Major,,TaskAttemptCompletedEventTransition invalidates previously successful attempt without checking if the newly completed attempt is successful,The previously completed attempt is removed from successAttemptCompletionEventNoMap and marked OBSOLETE. After that; if the newly completed attempt is successful then it is added to the successAttemptCompletionEventNoMap.   This seems wrong because the newly completed attempt could be failed and thus there is no need to invalidate the successful attempt. One error case would be when a speculative attempt completes with killed failed after the successful version has completed.,Patch Available,Unresolved,,Omkar Vinit Joshi,Bikas Saha,Fri; 8 Jun 2012 18:05:48 +0000,Wed; 6 May 2015 03:31:50 +0000,,,0.23.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4330
MAPREDUCE-4331,Bug,Major,,TaskAttemptListenerImpl.statusUpdate and TaskAttemptListenerImpl.ping never return false,If a task has been abandoned by the AM but not terminated at the NM; then it will continue to contact the AM. The AM needs to send it a false value in the response to status ping and that will make the task attempt abort.  However; these responses currently always return true so such aborts dont get triggered.,Open,Unresolved,,Bikas Saha,Bikas Saha,Fri; 8 Jun 2012 18:08:18 +0000,Fri; 8 Jun 2012 18:08:18 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4331
YARN-29,Sub-task,Major,client,Add a yarn-client module,I see that we are duplicating (some) code for talking to RM via client API. In this light; a yarn-client module will be useful so that clients of all frameworks can use extend it.  And that same module can be the destination for all the YARN's command line tools.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 8 Jun 2012 22:58:35 +0000,Thu; 24 Aug 2017 21:20:17 +0000,Mon; 27 Aug 2012 18:35:28 +0000,,,,MAPREDUCE-4580;YARN-40,HADOOP-14771;YARN-103,https://issues.apache.org/jira/browse/YARN-29
MAPREDUCE-4333,Wish,Minor,,ZipKin support,Zipkin; introduced by Twitter; is an open source project inspired by Google Dapper. https: zipkin  Existing  profilers (hprof; btrace; and so on) are insufficient to analyse the bottle neck of hadoop; bacause they are not distributed profiler.  I think that Zipkip may solve the problem.,Open,Unresolved,,Unassigned,Tsuyoshi Ozawa,Mon; 11 Jun 2012 01:51:47 +0000,Mon; 11 Jun 2012 07:46:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4333
YARN-3,Sub-task,Major,,Add support for CPU isolation/monitoring of containers,nan,Closed,Fixed,YARN-147,Andrew Ferguson,Arun C Murthy,Mon; 11 Jun 2012 16:58:15 +0000,Fri; 15 Feb 2013 13:12:40 +0000,Tue; 18 Dec 2012 23:02:11 +0000,,,,,YARN-4;YARN-2;MAPREDUCE-4256,https://issues.apache.org/jira/browse/YARN-3
YARN-137,Improvement,Major,scheduler,Change the default scheduler to the CapacityScheduler,There's some bugs in the FifoScheduler atm - doesn't distribute tasks across nodes and some headroom (available resource) issues. That's not the best experience for users trying out the 2.0 branch. The CS with the default configuration of a single queue behaves the same as the FifoScheduler and doesn't have these issues.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Mon; 11 Jun 2012 17:50:37 +0000,Thu; 11 Oct 2012 17:48:02 +0000,Sun; 30 Sep 2012 00:46:12 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-137
MAPREDUCE-4336,Bug,Major,mrv2,Distributed Shell fails when used with the CapacityScheduler,DistributedShell attempts to get queue info without providing a queue name - which ends up in an NPE.,Closed,Fixed,,Ahmed Radwan,Siddharth Seth,Tue; 12 Jun 2012 00:49:55 +0000,Thu; 11 Oct 2012 17:48:50 +0000,Mon; 25 Jun 2012 16:03:41 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4336
MAPREDUCE-4337,Improvement,Major,mrv2,Support multiple reducers in 'uber' jobs,This is MAPREDUCE-434 for 'uber' jobs (jobs that run in the same container as the AM).,Open,Unresolved,,Unassigned,Tom White,Tue; 12 Jun 2012 02:23:51 +0000,Tue; 12 Jun 2012 02:24:40 +0000,,,,,,MAPREDUCE-434,https://issues.apache.org/jira/browse/MAPREDUCE-4337
MAPREDUCE-4338,Bug,Major,nodemanager,NodeManager daemon is failing to start.,Node manager daemons is not getting started on the slave machines. and giving an error like stated below. 2012-06-12 19:05:56;172 FATAL nodemanager.NodeManager (NodeManager. run(605)) - SHUTDOWN_MSG:,Resolved,Not A Problem,,Unassigned,srikanth ayalasomayajulu,Tue; 12 Jun 2012 05:25:58 +0000,Tue; 11 Sep 2012 03:25:13 +0000,Tue; 11 Sep 2012 03:24:58 +0000,,0.23.0,features;hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4338
MAPREDUCE-4339,Bug,Major,examples;job submission;mrv2;scheduler,pi example job hangs on when run on hadoop 0.23.0 when capacity scheduler is included in the setting environment.,Tried to include default capacity scheduler in hadoop and tried to run an example pi program. The job hangs and no more output is getting displayed. Starting Job 2012-06-12 22:10:02;524 INFO  ipc.YarnRPC (YarnRPC. monitorAndPrintJob(1227)) -  map 0% reduce 0%,Resolved,Cannot Reproduce,,Unassigned,srikanth ayalasomayajulu,Tue; 12 Jun 2012 06:45:53 +0000,Mon; 21 Apr 2014 15:39:30 +0000,Mon; 21 Apr 2014 15:39:29 +0000,,0.23.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4339
MAPREDUCE-4340,Bug,Critical,mrv2;nodemanager,Node Manager leaks socket connections connected to Data Node,I am running simple wordcount example with default configurations; for every job run it increases one datanode socket connection and it will be there in CLOSE_WAIT state forever.,Resolved,Duplicate,YARN-58,Devaraj K,Devaraj K,Thu; 14 Jun 2012 09:35:19 +0000,Thu; 12 May 2016 18:22:34 +0000,Tue; 24 Jul 2012 21:27:04 +0000,,2.0.0-alpha;3.0.0-alpha1,,,HDFS-3545,https://issues.apache.org/jira/browse/MAPREDUCE-4340
MAPREDUCE-4341,Bug,Major,capacity-sched;mrv2,add types to capacity scheduler properties documentation,MAPREDUCE-4311 is changing capacity CapacityScheduler.html#Configuration).,Closed,Fixed,,Karthik Kambatla,Thomas Graves,Thu; 14 Jun 2012 14:28:31 +0000,Mon; 3 Nov 2014 18:05:48 +0000,Tue; 19 Jun 2012 16:19:28 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4341
MAPREDUCE-4342,Bug,Major,,Distributed Cache gives inconsistent result if cache files get deleted from task tracker ,nan,Closed,Fixed,,Mayank Bansal,Mayank Bansal,Fri; 15 Jun 2012 22:32:03 +0000,Tue; 10 Mar 2015 04:30:30 +0000,Mon; 30 Jul 2012 22:58:15 +0000,,0.22.0;1.0.3,,,MAPREDUCE-4349,https://issues.apache.org/jira/browse/MAPREDUCE-4342
MAPREDUCE-4343,Improvement,Major,,ZK recovery support for ResourceManager,MAPREDUCE-279 included bits and pieces of possible ZK integration for YARN's RM; but looks like it failed to complete it (for scalability reasons? etc?) and there seems to be no JIRA tracking this feature that has been already claimed publicly as a good part about YARN.  If it did complete it; we should document how to use it. Setting the following only yields:        This JIRA is hence filed to track the addition completion of recovery via ZK.,Resolved,Duplicate,MAPREDUCE-4326;MAPREDUCE-2713,Unassigned,Harsh J,Sun; 17 Jun 2012 06:42:18 +0000,Tue; 19 Jun 2012 08:59:06 +0000,Mon; 18 Jun 2012 17:56:07 +0000,,,,,MAPREDUCE-4344,https://issues.apache.org/jira/browse/MAPREDUCE-4343
MAPREDUCE-4344,Improvement,Minor,,ZKClient does not support auth,ZKClient class in YARN; currently unused (but still induces a dependency; but thats another discussion) has the following comment:     We ought to have auth support in it if its to be kept around and used.  This may also be related to MAPREDUCE-4343 in some ways.,Open,Unresolved,,Unassigned,Harsh J,Sun; 17 Jun 2012 06:45:14 +0000,Mon; 18 Jun 2012 19:48:56 +0000,,,,,,MAPREDUCE-4343,https://issues.apache.org/jira/browse/MAPREDUCE-4344
YARN-149,New Feature,Major,resourcemanager,[Umbrella] ResourceManager (RM) Fail-over,This jira tracks work needed to be done to support one RM instance failing over to another RM instance so that we can have RM HA. Work includes leader election; transfer of control to leader and client re-direction to new leader.,Resolved,Fixed,MAPREDUCE-225,Unassigned,Harsh J,Sun; 17 Jun 2012 07:07:34 +0000,Sun; 3 May 2015 01:50:15 +0000,Sun; 3 May 2015 01:49:16 +0000,,,patch,YARN-1318,YARN-1305;YARN-1139;YARN-1543;YARN-1460;HADOOP-9905;MAPREDUCE-2288;YARN-128;YARN-556,https://issues.apache.org/jira/browse/YARN-149
MAPREDUCE-4346,Improvement,Major,mrv1,Adding a refined version of JobTracker.getAllJobs() and exposing through the JobClient,The current implementation for JobTracker.getAllJobs() returns all submitted jobs in any state; in addition to retired jobs. This list can be long and represents an unneeded overhead especially in the case of clients only interested in jobs in specific state(s).   It is beneficial to include a refined version where only jobs having specific statuses are returned and retired jobs are optional to include.   I'll be uploading an initial patch momentarily.,Patch Available,Unresolved,,Ahmed Radwan,Ahmed Radwan,Mon; 18 Jun 2012 08:27:41 +0000,Wed; 6 May 2015 03:32:09 +0000,,,,BB2015-05-TBR,,YARN-563,https://issues.apache.org/jira/browse/MAPREDUCE-4346
MAPREDUCE-4347,Wish,Major,,joined PhD. Intrested to do research in cloud especially in Hadoop. need suggession for problems to work.,nan,Resolved,Invalid,,Unassigned,Suresh S,Mon; 18 Jun 2012 11:16:33 +0000,Mon; 18 Jun 2012 12:16:59 +0000,Mon; 18 Jun 2012 12:16:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4347
MAPREDUCE-4348,Improvement,Minor,mrv1,JobSubmissionProtocol should be made public; not package private,The JobSubmissionProtocol interface is package private; yet it is the only way to remotely query the status of the JT or the cluster.   Even if Job Submission is considered private; probing JT state shouldn't be.,Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Mon; 18 Jun 2012 13:04:54 +0000,Mon; 26 Jan 2015 22:35:56 +0000,Mon; 26 Jan 2015 22:35:56 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4348
MAPREDUCE-4349,Improvement,Minor,,Distributed Cache gives inconsistent result if cache Archive files get deleted from task tracker ,Add test to verify Distributed Cache consistency when cached archives are deleted.,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Mon; 18 Jun 2012 18:08:41 +0000,Tue; 10 Mar 2015 04:30:31 +0000,Mon; 29 Apr 2013 21:31:39 +0000,,0.22.0;1.0.3,,,MAPREDUCE-4342,https://issues.apache.org/jira/browse/MAPREDUCE-4349
MAPREDUCE-4350,Bug,Major,distributed-cache,Distributed Cache should put files read only on Task tracker,nan,Open,Unresolved,,Mayank Bansal,Mayank Bansal,Mon; 18 Jun 2012 18:10:47 +0000,Tue; 10 Mar 2015 04:30:29 +0000,,,0.22.0;1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4350
YARN-4,Sub-task,Major,,Make ContainersMonitor pluggable,nan,Resolved,Won't Fix,,Unassigned,Andrew Ferguson,Mon; 18 Jun 2012 21:23:37 +0000,Fri; 8 May 2015 17:31:45 +0000,Fri; 8 May 2015 17:31:45 +0000,,,,,YARN-3;MAPREDUCE-4256,https://issues.apache.org/jira/browse/YARN-4
YARN-99,Sub-task,Major,nodemanager,Jobs fail during resource localization when private distributed-cache hits unix directory limits,If we have multiple jobs which uses distributed cache with small size of files; the directory limit reaches before reaching the cache size and fails to create any directories in file cache. The jobs start failing with the below exception.      We should have a mechanism to clean the cache files if it crosses specified number of directories like cache size.,Closed,Fixed,,Omkar Vinit Joshi,Devaraj K,Tue; 19 Jun 2012 13:48:41 +0000,Thu; 12 May 2016 18:30:26 +0000,Tue; 9 Apr 2013 01:35:32 +0000,,2.0.0-alpha;3.0.0-alpha1,,YARN-112;YARN-467,,https://issues.apache.org/jira/browse/YARN-99
MAPREDUCE-4353,Bug,Minor,mrv2;pipes,fix TestPipes,MAPREDUCE-4267 mavenized pipes.  The TestPipes  but has the @Ignore in it.   We should make that test work now.,Open,Unresolved,,Unassigned,Thomas Graves,Tue; 19 Jun 2012 19:49:06 +0000,Tue; 19 Jun 2012 19:50:21 +0000,,,0.23.3,,,MAPREDUCE-4267,https://issues.apache.org/jira/browse/MAPREDUCE-4353
MAPREDUCE-4354,Improvement,Minor,performance,Performance improvement with compressor object reinit restriction,HADOOP-5879 patch aimed at picking the conf (instead of default) settings for GzipCodec. It also involved re-initializing the recycled compressor object.  On our performance tests; this re-initialization led to performance degradation of 15% for LzoCodec because re-initialization for Lzo involves reallocation of buffers. LzoCodec takes the initial settings from config so it is not necessary to re-initialize it. This patch checks for the codec class and calls reinit only if the codec class is Gzip. This led to significant performance improvement of 15% for LzoCodec.,Resolved,Invalid,,Unassigned,Ankit Kamboj,Tue; 19 Jun 2012 22:43:50 +0000,Thu; 21 Mar 2013 20:11:01 +0000,Thu; 21 Mar 2013 20:11:01 +0000,,0.20.205.0,performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-4354
MAPREDUCE-4355,New Feature,Major,mrv1;mrv2,Add RunningJob.getJobStatus(),Usecase: Read the start end-time of a particular job.  Currently; one has to iterate through JobClient.getAllJobStatuses() and iterate through them. JobClient.getJob(JobID) returns RunningJob; which doesn't hold the job's start time.  Adding RunningJob.getJobStatus() solves the issue.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 19 Jun 2012 22:53:05 +0000,Mon; 3 Nov 2014 18:34:04 +0000,Thu; 5 Jul 2012 16:34:38 +0000,,1.0.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4355
MAPREDUCE-4356,Bug,Major,tools/rumen,Provide access to ParsedTask.obtainTaskAttempts(),Change the access modifier of obtainTaskAttempts() in ParsedTask. from default to public sothat it is accessible for everyone.,Closed,Fixed,,Ravi Gummadi,Ravi Gummadi,Wed; 20 Jun 2012 05:20:40 +0000,Wed; 3 Sep 2014 22:45:04 +0000,Thu; 21 Jun 2012 05:45:32 +0000,,,,,MAPREDUCE-3597,https://issues.apache.org/jira/browse/MAPREDUCE-4356
MAPREDUCE-4357,Bug,Major,,"Snappy Codec does not load properly when m/r job is run in ""uber"" mode",sudo -u hdfs hadoop jar  hadoop-mapreduce-client-jobclient-2.0.0-cdh4.0.0-tests.jar TestDFSIO -Dmapreduce.job.ubertask.enable=false -write,Open,Unresolved,,Unassigned,Jeff Lord,Wed; 20 Jun 2012 18:48:52 +0000,Sat; 14 Oct 2017 01:56:09 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4357
MAPREDUCE-4358,Bug,Major,mrv2,Reducers are assigned containers before all maps are assigned containers,Reducers start to get containers before all maps are. We have seen this issue and it is problematic since if there is no avaialable resources for the remaining maps; the job will just stall where reducers are waiting for mappers which are unable to start because there is no containers available.,Resolved,Duplicate,MAPREDUCE-4299,Unassigned,Ahmed Radwan,Wed; 20 Jun 2012 19:39:45 +0000,Tue; 17 Jul 2012 22:48:55 +0000,Tue; 17 Jul 2012 22:48:55 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4358
MAPREDUCE-4359,Bug,Major,,Potential deadlock in Counters,"jcarder identified this deadlock in branch-1 (though it may also be present in trunk):  	Counters.size() is synchronized and locks Counters before Group 	Counters.Group.getCounterForName() is synchronized and calls through to Counters.size()    This creates a potential cycle which could cause a deadlock (though probably quite rare in practice)",Closed,Fixed,,Tom White,Todd Lipcon,Thu; 21 Jun 2012 17:27:38 +0000,Wed; 15 May 2013 05:16:05 +0000,Thu; 5 Jul 2012 19:46:18 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4359
MAPREDUCE-4360,Bug,Major,,Capacity Scheduler Hierarchical leaf queue does not honor the max capacity of container queue,nan,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Thu; 21 Jun 2012 21:43:33 +0000,Sat; 30 Jun 2012 01:51:20 +0000,Fri; 29 Jun 2012 19:09:11 +0000,,0.22.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4360
MAPREDUCE-4361,Bug,Major,mrv2,Fix detailed metrics for protobuf-based RPC on 0.23,RPC detailed metrics for any protobuf-based RPC ports are always zero.  ProtoOverHadoopRpcEngine needs the same detailed metric logic as in WritableRpcEngine.  This is effectively the same change as in HADOOP-8085 except tailored for branch-0.23 which didn't take the full protobuf branch changes that went into branch-2 and trunk.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 21 Jun 2012 22:48:32 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Mon; 25 Jun 2012 14:39:43 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4361
MAPREDUCE-4362,Bug,Major,client;mrv2,If possible; we should get back the feature of propagating task logs back to JobClient,MAPREDUCE-3889 removed the code which was trying to pull from  tasklog. We should see if it is possible to get back the feature.,Open,Unresolved,,Wei Yan,Vinod Kumar Vavilapalli,Fri; 22 Jun 2012 00:20:02 +0000,Wed; 11 Dec 2013 20:18:41 +0000,,,2.0.0-alpha,,,YARN-499;YARN-522,https://issues.apache.org/jira/browse/MAPREDUCE-4362
MAPREDUCE-4363,Bug,Major,build;pipes,Hadoop 1.X; 2.X and trunk do not build on Fedora 17,I upgraded my machine to the latest Fedora 17 and now Apache Hadoop is failing to build. This seems related to the bump in version of gcc to 4.7.0,Resolved,Duplicate,MAPREDUCE-4383,Bruno Mah  ,Bruno Mah  ,Fri; 22 Jun 2012 05:04:07 +0000,Wed; 11 Mar 2015 20:27:51 +0000,Wed; 11 Mar 2015 20:27:51 +0000,,1.0.3,bigtop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4363
YARN-517,Task,Major,documentation,Document Yarn/MR2 performance related configurations and how to tune them.,Various new configuration properties have been introduced in Yarn MR2. It will be nice to create a document highlighting what configurations are crucial for optimal performance and how such properties can be tuned; and also contrast that with MR1.,Open,Unresolved,,Unassigned,Ahmed Radwan,Sat; 23 Jun 2012 00:13:16 +0000,Fri; 29 Mar 2013 07:38:14 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-517
MAPREDUCE-4365,New Feature,Major,,Shipping Profiler Libraries by DistributedCache,Hadoop profiling is great for performance tuning and debugging; but currently we can only use Java built-in profilers such as HProf; and for other profilers we need to install them on all slave nodes first; which is inconvenient for large clusters and sometimes impossible for production clusters.   Supporting shipping profiler libraries using DistributedCache will solve this problem. For example; in mapred.task.profile.params; we specify a profiler library from the DistributedCache using special place holders such as foo.jar; and Hadoop can look at the DistributedCache to replace foo.jar with the localized path before launching the child jvm.,Resolved,Fixed,,Unassigned,Jie Li,Mon; 25 Jun 2012 07:20:33 +0000,Thu; 28 Jun 2012 16:14:29 +0000,Thu; 28 Jun 2012 01:11:39 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4365
MAPREDUCE-4366,Bug,Major,jobtracker,mapred metrics shows negative count of waiting maps and reduces,Negative waiting_maps and waiting_reduces count is observed in the mapred metrics.  MAPREDUCE-1238 partially fixed this but it appears there is still issues as we are seeing it; but not as bad.,Resolved,Fixed,,Sandy Ryza,Thomas Graves,Mon; 25 Jun 2012 15:33:32 +0000,Sat; 27 Jul 2013 03:44:37 +0000,Sat; 27 Jul 2013 03:44:37 +0000,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4366
MAPREDUCE-4367,Improvement,Minor,client;mrv2,mapred job -kill tries to connect to history server,The mapred job -kill command attempts to connect to the history server; even though it is unrelated to the process of killing a job.,Open,Unresolved,,Mayank Bansal,Jason Lowe,Mon; 25 Jun 2012 16:38:37 +0000,Thu; 13 Sep 2012 05:09:20 +0000,,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4367
MAPREDUCE-4368,Bug,Major,tasktracker,TaskRunner fails to start jars when the java.library.path contains a quoted path with embedded spaces,"TaskRunner splits arguments by space before it adds them back to the vargs list; so it loses all context of quote escaped strings with embedded spaces.  This gets fixed up later by wrapping all arguments with ""  so you get something like  libarary.path contains paths and the tests often use %PATH% to seed this; so the fix is to remove embedded quotes in listed path elements because we know the aggregate will be quoted when the JVM is started.",Resolved,Fixed,,John Gordon,John Gordon,Mon; 25 Jun 2012 23:53:45 +0000,Thu; 5 Jul 2012 07:15:42 +0000,Thu; 5 Jul 2012 07:15:42 +0000,,1-win,newbie;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4368
MAPREDUCE-4369,Bug,Major,,Fix streaming job failures with WindowsResourceCalculatorPlugin,Some streaming jobs use local mode job runs that do not start tasks trackers. In these cases; the jvm context is not setup and hence local mode execution causes the code to crash. Fix is to not not use ResourceCalculatorPlugin in such cases or make the local job run creating dummy jvm contexts. Choosing the first option because thats the current implicit behavior in Linux. The ProcfsBasedProcessTree (used inside the LinuxResourceCalculatorPlugin) does no real work when the process pid is not setup correctly. This is what happens when local job mode runs.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Tue; 26 Jun 2012 00:49:17 +0000,Thu; 5 Jul 2012 07:05:55 +0000,Thu; 5 Jul 2012 07:05:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4369
MAPREDUCE-4370,Bug,Major,build,eclipse plugin for 1.0.3 hadoop version - impossible to generate it,"I need to generate the eclipse plugin for hadoop 1.0.3.  I had lot of error while   247)      exec 	... 38 more",Open,Unresolved,,Unassigned,Matteo,Tue; 26 Jun 2012 06:56:39 +0000,Tue; 26 Jun 2012 06:56:39 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4370
MAPREDUCE-4371,Improvement,Major,mrv1,Check for cyclic dependencies in Jobcontrol job DAG,In current implementation of JobControl; whenever there is a cyclic dependency between the jobs it throws a Stack overflow exception. This jira adds a cyclic check to jobcontrol.,Resolved,Fixed,,madhukara phatak,madhukara phatak,Tue; 26 Jun 2012 09:48:13 +0000,Thu; 12 May 2016 18:22:43 +0000,Mon; 2 Jul 2012 19:32:17 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4371
MAPREDUCE-4372,Bug,Major,mrv2;resourcemanager,Deadlock in Resource Manager between SchedulerEventDispatcher.EventProcessor and Shutdown hook manager,Please find the attached resource manager thread dump for the issue.,Closed,Fixed,,Devaraj K,Devaraj K,Tue; 26 Jun 2012 11:00:04 +0000,Thu; 12 May 2016 18:22:45 +0000,Wed; 27 Jun 2012 14:29:39 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4372
MAPREDUCE-4373,Bug,Major,,Fix Javadoc warnings in JobClient.,It looks like MAPREDUCE-4355 added in two new  oc warnings.,Resolved,Won't Fix,,Karthik Kambatla,Robert Joseph Evans,Tue; 26 Jun 2012 14:03:50 +0000,Thu; 12 May 2016 18:22:16 +0000,Wed; 27 Jun 2012 22:33:07 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4373
MAPREDUCE-4374,Bug,Minor,mrv2,Fix child task environment variable config and add support for Windows,In HADOOP-2838; a new feature was introduced to set environment variables via the Hadoop config 'mapred.child.env' for child tasks. There are some further fixes and improvements around this feature; e.g. HADOOP-5981 were a bug fix; MAPREDUCE-478 broke the config into 'mapred.map.child.env' and 'mapred.reduce.child.env'.  However the current implementation is still not complete. It does not match its documentation or original intend as I believe. Also; by using  :  (colon) and  ;  (semicolon) in the configuration syntax; we will have problems using them on Windows because  :  appears very often in Windows path as in  C:  ; and environment variables are used very often to hold path names. The Jira is created to fix the problem and provide support on Windows.,Closed,Fixed,,Chuan Liu,Chuan Liu,Tue; 26 Jun 2012 18:53:11 +0000,Thu; 12 May 2016 18:22:27 +0000,Wed; 10 Jul 2013 23:21:22 +0000,,1-win;2.1.0-beta;3.0.0-alpha1,,,HADOOP-9790,https://issues.apache.org/jira/browse/MAPREDUCE-4374
MAPREDUCE-4375,Improvement,Major,applicationmaster,Show Configuration Tracability in MR UI,Once HADOOP-8525 goes in we should provide a way for the Configuration UI to display the traceability information.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 26 Jun 2012 21:07:40 +0000,Thu; 2 May 2013 02:29:54 +0000,Tue; 31 Jul 2012 13:45:18 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4375
MAPREDUCE-4376,Bug,Major,mrv2;test,TestClusterMRNotification times out,The TestClusterMRNotification test is often timing out.  git bisect tests narrowed it down to MAPREDUCE-3921; as the test consistently passes before that change and times out most of the time after picking up that change.,Closed,Fixed,MAPREDUCE-5690,Kihwal Lee,Jason Lowe,Tue; 26 Jun 2012 21:46:43 +0000,Mon; 18 May 2015 17:42:53 +0000,Thu; 28 Jun 2012 19:30:49 +0000,,2.0.0-alpha,,,MAPREDUCE-3921,https://issues.apache.org/jira/browse/MAPREDUCE-4376
MAPREDUCE-4377,Bug,Major,task-controller,TaskRunner javaopts parsing doesn't handle embedded spaces,TaskRunner::GetVMArgs reads getChildJavaOpts as one space-delimited string; then split is on ' ' and tries to reason on individual options from there.  The problem with this approach is that  options may contain embedded spaces in many legitimate cases  this means it is reasoning on incomplete option strings and cannot do appropriate preprocessing to do things like handle escape characters or matched quotation marks.,Open,Unresolved,,Unassigned,John Gordon,Wed; 27 Jun 2012 02:41:26 +0000,Tue; 10 Mar 2015 04:30:41 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4377
MAPREDUCE-4378,Bug,Major,mrv2,hadoop-validate-setup.sh fails to execute kinit command in secure mode,hadoop-validate-setup.sh is refering to the invalid kinit location.,Resolved,Cannot Reproduce,,Unassigned,Nishan Shetty,Wed; 27 Jun 2012 12:42:59 +0000,Thu; 12 May 2016 18:24:22 +0000,Mon; 11 May 2015 11:27:56 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4378
MAPREDUCE-4379,Bug,Blocker,mrv2;nodemanager,Node Manager throws java.lang.OutOfMemoryError: Java heap space due to org.apache.hadoop.fs.LocalDirAllocator.contexts,nan,Closed,Fixed,,Devaraj K,Devaraj K,Wed; 27 Jun 2012 13:54:42 +0000,Thu; 12 May 2016 18:24:27 +0000,Sat; 7 Jul 2012 14:23:56 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4379
MAPREDUCE-4380,Bug,Minor,mrv2;nodemanager,Empty Userlogs directory is getting created under logs directory,Empty Userlogs directory is getting created under logs directory.,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 28 Jun 2012 04:16:54 +0000,Thu; 12 May 2016 18:23:37 +0000,Tue; 17 Jul 2012 19:16:01 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4380
MAPREDUCE-4381,Improvement,Minor,task;tasktracker,Make PROGRESS_INTERVAL of org.apache.hadoop.mapred.Task a tunable,Currently PROGRESS_INTERVAL is a hard-coded value and is set to 3000 msec. We tried making it a tunable and experimented with different values. In some cases setting it to a smaller value like 1000 msec helps significantly improve performance of short running jobs such as piEstimator. This is because the task threads do not end up blocking for as many as 3 seconds for their last progress update event. We also noticed close to 14% improvement on Mahout KMeans iteration jobs which take more than 5 minutes on the test cluster that we are using. Please let me know if this seems to be a good idea. I have an initial patch that I have attached here. This is based on branch-1 tree. It may need some rework on MRv2 based branches I think. Also note that I have not changed the variable naming style for PROGRESS_INTERVAL even though it is not a public static final anymore. I can revise the patch if there are no objections to this idea.  Thanks.,Open,Unresolved,,Unassigned,Shrinivas Joshi,Thu; 28 Jun 2012 19:01:25 +0000,Sat; 7 Jul 2012 00:34:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4381
MAPREDUCE-4382,Bug,Major,mrv2;resourcemanager,RMContainerImpl State Machine Doesn't Handle RELEASED State from AM Properly,Encountered this error with an RMContainerImpl unable to go from the RUNNING state to the RELEASED state.  Upon further inspection; the state machine has no means of dealing with this and since the RELEASED state can be sent from the AM at any time; it should be able to handle this in both the RUNNING state and the ALLOCATED state.,Open,Unresolved,,Unassigned,Jack Dintruff,Thu; 28 Jun 2012 16:50:38 +0000,Fri; 24 Aug 2012 15:33:48 +0000,,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4382
MAPREDUCE-4383,Bug,Minor,pipes,HadoopPipes.cc needs to include unistd.h,"Since MAPREDUCE-4267 I've seen ""mvn -Pnative compile"" failing with:       exec  HadoopPipes.cc.o Error 1  I believe the failure is new simply because I wasn't compiling pipes before.  The fix is pretty simple; just include unistd.h in HadoopPipes.cc.  My environment is debian unstable; amd64; g++ 4.7.0-6; openjdk-6-jdk 6b24-1.11.1-6.",Closed,Fixed,MAPREDUCE-4363,Andy Isaacson,Andy Isaacson,Thu; 28 Jun 2012 19:33:34 +0000,Wed; 11 Mar 2015 20:27:51 +0000,Fri; 29 Jun 2012 21:02:50 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4383
MAPREDUCE-4384,Bug,Major,nodemanager,Race conditions in IndexCache,TestIndexCache is intermittently failing due to a race condition. Up on inspection of IndexCache implementation; more potential issues have been discovered.,Closed,Fixed,,Kihwal Lee,Kihwal Lee,Thu; 28 Jun 2012 20:01:12 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Thu; 5 Jul 2012 21:39:13 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4384
MAPREDUCE-4385,Bug,Major,,FairScheduler.maxTasksToAssign() should check for fairscheduler.assignmultiple.maps < TaskTracker.availableSlots,FairScheduler.maxTasksToAssign() can potentially return a value greater than the available slots. Currently; we rely on canAssignMaps() canAssignReduces() to reject such requests.  These additional calls can be avoided by check against the available slots in maxTasksToAssign().,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Thu; 28 Jun 2012 20:36:00 +0000,Mon; 3 Nov 2014 18:33:50 +0000,Thu; 5 Jul 2012 16:55:56 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4385
MAPREDUCE-4386,Bug,Major,,"Investigate possible abstractions for shell commands ""bash -c"" and ""cmd /c""","Currently; we have multiple files within the codebase that have if (WINDOWS) ""cmd  c  "" else ""bash  c  "". Instead; we should try to scope this down to only Shell. and expose the needed functionality to other places. We might not be able to remove all such occurrences; but it looks like there is room for improvement (check the discussion on MAPREDUCE-4322).",Open,Unresolved,,Unassigned,Ivan Mitic,Fri; 29 Jun 2012 02:50:17 +0000,Fri; 3 Aug 2012 05:34:39 +0000,,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4386
MAPREDUCE-4387,Bug,Major,resourcemanager,RM gets fatal error and exits during TestRM,It doesn't happen on my desktop; but it happens frequently during the builds with clover enabled. Surefire will report it as fork failure.,Closed,Fixed,,Kihwal Lee,Kihwal Lee,Fri; 29 Jun 2012 16:03:40 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Fri; 6 Jul 2012 13:40:45 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4387
MAPREDUCE-4388,Bug,Major,jobtracker,Cleanup of restart count in job tracker as it is no longer needed,Jobtracker restart count is no longer required after MAPREDUCE-3837. As suggested by Tom; need to cleanup that.  Working on that.  Thanks; Mayank,Open,Unresolved,,Mayank Bansal,Mayank Bansal,Mon; 2 Jul 2012 17:58:07 +0000,Tue; 10 Jul 2012 19:20:45 +0000,,,0.22.0;1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4388
MAPREDUCE-4389,Bug,Major,job submission;mrv2,Map only jobs should work even for MapOutput(Key|Value)Class configuration,I have written a Map only job and have set MapOutput(Key|Value)Class. Job was passing when I set TextOutputFormat; however; when I changed the OF to SequenceFileOutputFormat; job started failing.  Later; I have set them to Output(Key|Value)Class; and job was passing.  I think; for Map only jobs; jobs should pass even for MapOutput(Key|Value)Class.,Open,Unresolved,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Mon; 2 Jul 2012 18:39:51 +0000,Tue; 10 Mar 2015 04:30:22 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4389
MAPREDUCE-4390,Bug,Major,examples;job submission;mrv2,java.io.IOException: File /user/XXXX/QuasiMonteCarlo_TMP_3_141592654/in/part0 could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.,Tried to run an example program on hadoop0.23.0 and getting the following error. error:  1484),Resolved,Invalid,,Unassigned,srikanth ayalasomayajulu,Tue; 3 Jul 2012 23:45:43 +0000,Wed; 4 Jul 2012 01:15:48 +0000,Wed; 4 Jul 2012 01:15:48 +0000,,0.23.0,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4390
MAPREDUCE-4391,Bug,Major,mrv2,datanode.DataNode (DataNode.java:handshake(820)) - Problem connecting to server: master/192.168.100.140:9000,datanode cannot able to connect to namenode; and in turn resulting in future errors during running examples. 2012-07-04 15:25:09;636 WARN  datanode.DataNode (DataNode. handleConnectionFailure(671)) - Retrying connect to server: master 192.168.100.140:9000. Already tried 3 time(s).,Resolved,Invalid,,Unassigned,srikanth ayalasomayajulu,Tue; 3 Jul 2012 23:56:14 +0000,Wed; 4 Jul 2012 02:29:19 +0000,Wed; 4 Jul 2012 02:29:19 +0000,,0.23.0,datanode;hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4391
MAPREDUCE-4392,Bug,Major,mrv2,Counters.makeCompactString() changed behavior from 0.20,In 0.20; makeCompactString() returned a comma-separated list; but MAPREDUCE-3697 changed it to be equivalent to makeEscapedCompactString().  Users moving from 0.20 to 0.23 are expecting the original behavior from makeCompactString().,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 4 Jul 2012 00:19:18 +0000,Thu; 11 Oct 2012 17:48:47 +0000,Thu; 5 Jul 2012 18:12:27 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4392
YARN-153,New Feature,Major,,PaaS on YARN: an YARN application to demonstrate that YARN can be used as a PaaS,This application is to demonstrate that YARN can be used for non-mapreduce applications. As Hadoop has already been adopted and deployed widely and its deployment in future will be highly increased; we thought that it's a good potential to be used as PaaS.   I have implemented a proof of concept to demonstrate that YARN can be used as a PaaS (Platform as a Service). I have done a gap analysis against VMware's Cloud Foundry and tried to achieve as many PaaS functionalities as possible on YARN.  I'd like to check in this POC as a YARN example application.,Open,Unresolved,,Jacob Jaigak Song,Jacob Jaigak Song,Wed; 4 Jul 2012 00:59:47 +0000,Tue; 10 Mar 2015 04:17:45 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-153
MAPREDUCE-4394,Bug,Minor,mrv1,ReduceTask.MapOutputCopier.copyOutput() signature doesn't match the corresponding Javadoc,nan,Resolved,Won't Fix,,Unassigned,Karthik Kambatla,Wed; 4 Jul 2012 01:50:55 +0000,Mon; 28 Mar 2016 06:05:01 +0000,Mon; 28 Mar 2016 06:05:01 +0000,,1.0.3,docs;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4394
MAPREDUCE-4395,Bug,Critical,distributed-cache;job submission;mrv2,Possible NPE at ClientDistributedCacheManager#determineTimestamps,It may be possible that tfiles array contains null as it's entry; and subsequently leads to NPE.,Closed,Fixed,,Bhallamudi Venkata Siva Kamesh,Bhallamudi Venkata Siva Kamesh,Wed; 4 Jul 2012 12:16:22 +0000,Tue; 10 Mar 2015 04:30:49 +0000,Mon; 16 Jul 2012 14:21:38 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4395
MAPREDUCE-4396,Bug,Minor,client,Make LocalJobRunner work with private distributed cache,Some LocalJobRunner related unit tests fails if user directory permission and or umask is too restrictive.,Closed,Fixed,,Yu Gao,Luke Lu,Thu; 5 Jul 2012 09:36:39 +0000,Wed; 6 Mar 2013 09:55:56 +0000,Fri; 14 Dec 2012 23:33:58 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4396
MAPREDUCE-4397,Improvement,Major,task-controller,Introduce HADOOP_SECURITY_CONF_DIR for task-controller,The linux task controller currently hard codes the directory in which to look for its config file at compile time (via the HADOOP_CONF_DIR macro). Adding a new environment variable to look for task-controller's conf dir (with strict permission checks) would make installation much more flexible.,Closed,Fixed,,Yu Gao,Luke Lu,Thu; 5 Jul 2012 09:59:05 +0000,Fri; 3 May 2013 23:20:34 +0000,Fri; 21 Dec 2012 23:32:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4397
MAPREDUCE-4398,Bug,Major,contrib/fair-share,Fix mapred.system.dir permission error with FairScheduler,Incorrect job initialization logic in FairScheduler causes mysterious intermittent mapred.system.dir permission errors.,Resolved,Duplicate,MAPREDUCE-4451,Yu Gao,Luke Lu,Thu; 5 Jul 2012 10:13:59 +0000,Mon; 6 May 2013 02:51:04 +0000,Sat; 20 Oct 2012 07:46:11 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4398
MAPREDUCE-4399,Bug,Major,performance;tasktracker,Fix performance regression in shuffle ,There is a significant (up to 3x) performance regression in shuffle (vs 0.20.2) in the Hadoop 1.x series. Most noticeable with high-end switches.,Closed,Fixed,,Luke Lu,Luke Lu,Thu; 5 Jul 2012 10:20:53 +0000,Wed; 17 Oct 2012 18:25:31 +0000,Fri; 20 Jul 2012 18:13:46 +0000,,0.20.203.0;1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4399
MAPREDUCE-4400,Bug,Major,performance;task,Fix performance regression for small jobs/workflows,There is a significant performance regression for small jobs workflows (vs 0.20.2) in the Hadoop 1.x series. Most noticeable with Hive and Pig jobs. PigMix has an average 40% regression against 0.20.2.,Closed,Fixed,,Luke Lu,Luke Lu,Thu; 5 Jul 2012 10:25:13 +0000,Wed; 17 Oct 2012 18:27:24 +0000,Thu; 26 Jul 2012 00:17:07 +0000,,0.20.203.0;1.0.3,,,MAPREDUCE-4477,https://issues.apache.org/jira/browse/MAPREDUCE-4400
MAPREDUCE-4401,Improvement,Major,build;mrv2,Enhancements to MapReduce for Windows Server and Windows Azure development and runtime environments,This JIRA tracks the work that needs to be done on trunk to enable Hadoop to run on Windows Server and Azure environments. This incorporates porting relevant work from the similar effort on branch 1 tracked via HADOOP-8079.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Thu; 5 Jul 2012 17:59:47 +0000,Thu; 12 May 2016 18:24:24 +0000,Tue; 11 Feb 2014 17:54:23 +0000,,3.0.0-alpha1,,,MAPREDUCE-5056;MAPREDUCE-5191;MAPREDUCE-5391;MAPREDUCE-5075;MAPREDUCE-5177,https://issues.apache.org/jira/browse/MAPREDUCE-4401
MAPREDUCE-4402,Bug,Major,test,TestFileInputFormat fails intermittently,TestFileInputFormat#testLocality is failing intermittently when verifying each file split has two block locations.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 6 Jul 2012 16:22:17 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Mon; 9 Jul 2012 16:17:16 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4402
MAPREDUCE-4403,Improvement,Minor,jobtracker,Adding test case for resubmission of jobs in TestRecoveryManager,In Hadoop 22 Test recovery Manager does not have resubmission test case which checks after the resubmission jobs get succeeded.  There is some refactoring is also needed.   Thanks; Mayank,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Fri; 6 Jul 2012 18:39:36 +0000,Fri; 13 Jul 2012 17:58:48 +0000,Fri; 13 Jul 2012 17:58:48 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4403
MAPREDUCE-4404,Bug,Minor,client,Adding Test case for TestMRJobClient to verify the user name,Adding Test case for TestMRJobClient to verify the user name,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Fri; 6 Jul 2012 20:40:48 +0000,Fri; 31 May 2013 21:19:14 +0000,Fri; 31 May 2013 21:19:14 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4404
MAPREDUCE-4405,Improvement,Minor,client,Adding test case for HierarchicalQueue in TestJobQueueClient,Adding test case for HierarchicalQueue in TestJobQueueClient,Resolved,Fixed,,Mayank Bansal,Mayank Bansal,Fri; 6 Jul 2012 20:55:49 +0000,Mon; 29 Apr 2013 21:30:26 +0000,Mon; 29 Apr 2013 21:30:26 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4405
MAPREDUCE-4406,Bug,Major,mrv2;test,Users should be able to specify the MiniCluster ResourceManager and JobHistoryServer ports,There is use-cases where users may need to specify the ports used for the resource manager and history server for the minicluster.  In the current implementation; the MiniCluster sets these addresses regardless of them being already set by the user in the conf.  Users should be able to add these properties to the conf and in such case the MiniCluster will use the specified addresses. If not specified then the current behavior of the MiniCluster for explicitly setting the addresses will be used.  I'll be uploading a patch momentarily.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Fri; 6 Jul 2012 23:10:48 +0000,Wed; 14 Nov 2012 00:07:45 +0000,Wed; 18 Jul 2012 03:37:57 +0000,,,,MAPREDUCE-987,YARN-144,https://issues.apache.org/jira/browse/MAPREDUCE-4406
MAPREDUCE-4407,Bug,Major,build;mrv2,Add hadoop-yarn-server-tests-<version>-tests.jar to hadoop dist package,This change basically adds hadoop-yarn-server-tests-version-tests.jar to the package.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Fri; 6 Jul 2012 23:17:37 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Wed; 18 Jul 2012 22:44:36 +0000,,,,MAPREDUCE-987,,https://issues.apache.org/jira/browse/MAPREDUCE-4407
MAPREDUCE-4408,Improvement,Major,mrv1;mrv2,allow jobs to set a JAR that is in the distributed cached,Setting a job JAR with JobConf.setJar(String) and Job.setJar(String) assumes that the JAR is local to the client submitting the job; thus it triggers copying the JAR to HDFS and injecting it to the distributed cached.  AFAIK; this is the only way to use uber JARs (JARs with JARs inside) in MR jobs.  For jobs launched by Oozie; all JARs are already in HDFS. In order for Oozie to suport uber JARs (OOZIE-654) there should be a way for specifying as JAR a JAR that is already in HDFS.,Closed,Fixed,,Robert Kanter,Alejandro Abdelnur,Fri; 6 Jul 2012 23:53:56 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Fri; 24 Aug 2012 23:44:00 +0000,,1.0.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4408
YARN-5,New Feature,Major,,Add support for FifoScheduler to schedule CPU along with memory.,nan,Resolved,Won't Fix,,Arun C Murthy,Arun C Murthy,Sat; 7 Jul 2012 00:42:56 +0000,Fri; 8 May 2015 17:21:05 +0000,Fri; 8 May 2015 17:17:16 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-5
YARN-7,Sub-task,Major,,Add support for DistributedShell to ask for CPUs along with memory,nan,Closed,Fixed,,Junping Du,Arun C Murthy,Sat; 7 Jul 2012 00:44:27 +0000,Mon; 24 Feb 2014 20:58:33 +0000,Fri; 11 Oct 2013 08:35:19 +0000,,2.1.1-beta,patch,,,https://issues.apache.org/jira/browse/YARN-7
MAPREDUCE-4412,Bug,Minor,mrv2,No mapred-site.xml present in the configuration directory. This is very trivial but thought would be less confusing for a new user if it came packaged.,The binary Distribution of the hadoop-0.23.3 has no mapred-site.xml file in the  hadoop directory.  And for the setting up the cluster we need to configure mapred-site.xml. Though this is trivial issue but new users might get confused while configuring.,Open,Unresolved,,Unassigned,Pavan Kulkarni,Fri; 6 Jul 2012 16:54:29 +0000,Mon; 9 Jul 2012 19:22:58 +0000,,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4412
MAPREDUCE-4413,Bug,Critical,build,MR lib dir contains jdiff (which is gpl),A tarball built from trunk contains the following:  . jdiff-1.0.9.jar  jdiff is gplv2; we need to exclude it from the build artifact.,Resolved,Fixed,,Nemon Lou,Eli Collins,Mon; 9 Jul 2012 18:34:12 +0000,Fri; 20 May 2016 03:22:45 +0000,Mon; 9 Feb 2015 22:03:19 +0000,,2.0.0-alpha,,,HADOOP-11519;HADOOP-12893,https://issues.apache.org/jira/browse/MAPREDUCE-4413
MAPREDUCE-4414,Improvement,Major,client,Add main methods to JobConf and YarnConfiguration; for debug purposes,Just like Configuration has a main() func that dumps XML out for debug purposes; we should have a similar function under the JobConf and YarnConfiguration classes that do the same. This is useful in testing out app classpath setups at times.,Resolved,Fixed,,Plamen Jeliazkov,Harsh J,Mon; 9 Jul 2012 19:18:48 +0000,Tue; 30 Aug 2016 01:20:49 +0000,Mon; 16 Mar 2015 19:34:01 +0000,,2.0.0-alpha,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4414
MAPREDUCE-4415,Improvement,Major,mrv1,Backport the Job.getInstance methods from MAPREDUCE-1505 to branch-1,In 2.x MR; the Job constructors have all been deprecated in favor of Job.getInstance() calls to get a Job object.  However; these getInstance methods do not appear to be present in the 1.x MR API; and thereby may cause additional pain to users moving from 1.x to 2.x going forward.  This patch proposes to add in the getInstance style of methods with suitable test coverage for both style of constructors; while not pulling in anything else from MAPREDUCE-1505 (as we lack 'Cluster' in 1.x). As we're not going to be deprecating the regular ctors in a 1.x release; this is not an incompatible change in any way.,Closed,Fixed,,Harsh J,Harsh J,Mon; 9 Jul 2012 20:37:10 +0000,Wed; 15 May 2013 05:16:00 +0000,Tue; 24 Jul 2012 17:56:48 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4415
MAPREDUCE-4416,Bug,Critical,client;mrv2,Some tests fail if Clover is enabled,There are number of tests running under hadoop-mapreduce-client-jobclient that fail if Clover is enabled. Whenever a job is launched; AM doesn't start because it can't locate the clover jar file.  I thought MAPREDUCE-4253 had something to do with this; but I can reproduce the issue on an older revision. Although unrelated; MAPREDUCE-4253 does have a problem and it has been reported to the jira.,Closed,Fixed,,Kihwal Lee,Kihwal Lee,Mon; 9 Jul 2012 21:52:59 +0000,Thu; 12 May 2016 18:24:15 +0000,Thu; 12 Jul 2012 15:54:13 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4416
MAPREDUCE-4417,New Feature,Major,mrv2;security,add support for encrypted shuffle,Currently Shuffle fetches go on the clear. While Kerberos provides comprehensive authentication for the cluster; it does not provide confidentiality.   When processing sensitive data confidentiality may be desired (at the expense of job performance and resources utilization for doing encryption).,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 10 Jul 2012 00:15:57 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Thu; 26 Jul 2012 13:26:43 +0000,,2.0.0-alpha,,,HDFS-3637,https://issues.apache.org/jira/browse/MAPREDUCE-4417
MAPREDUCE-4418,Bug,Major,contrib/gridmix,Gridmix should emulate hdfs_bytes_read when compression emulation is ON,When compression emulation is ON and if map-input-compression-ratio is 0.5; then Gridmix is emulating mapInputBytes and the value of hdfs_bytes_read is becoming half of original task. This needs to be fixed.,Open,Unresolved,,Unassigned,Ravi Gummadi,Tue; 10 Jul 2012 09:42:36 +0000,Tue; 10 Jul 2012 09:42:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4418
MAPREDUCE-4419,Bug,Major,mrv2,./mapred queue -info <queuename> -showJobs displays all the jobs irrespective of <queuename> ,. mapred queue -info queuename -showJobs shows all the jobs irrespective of queuename  In Queue name field all the jobs are showing as default queue but they are submitted to the configured queue(see screenshots attached).,Closed,Fixed,,Devaraj K,Nishan Shetty,Tue; 10 Jul 2012 10:02:32 +0000,Thu; 12 May 2016 18:23:49 +0000,Fri; 13 Jul 2012 20:47:20 +0000,,2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4419
MAPREDUCE-4420,Bug,Major,mrv2,./mapred queue -info <queuename> -showJobs displays containers and memory as zero always,. mapred queue -info queuename -showJobs displays containers and memory as zero always.,Resolved,Fixed,,Devaraj K,Nishan Shetty,Tue; 10 Jul 2012 10:27:26 +0000,Mon; 23 Jul 2012 09:01:43 +0000,Mon; 23 Jul 2012 09:01:43 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4420
MAPREDUCE-4421,Sub-task,Major,,Run MapReduce framework via the distributed cache,Currently MR AM depends on MR jars being deployed on all nodes via implicit dependency on YARN_APPLICATION_CLASSPATH.   We should stop adding mapreduce jars to YARN_APPLICATION_CLASSPATH and; probably; just rely on adding a shaded MR jar along with job.jar to the dist-cache.,Closed,Fixed,,Jason Lowe,Arun C Murthy,Tue; 10 Jul 2012 13:12:57 +0000,Tue; 25 Nov 2014 16:37:31 +0000,Tue; 1 Oct 2013 22:40:11 +0000,,2.0.0-alpha,,,YARN-2464;MAPREDUCE-5534;MAPREDUCE-6173;YARN-666,https://issues.apache.org/jira/browse/MAPREDUCE-4421
MAPREDUCE-4422,Improvement,Major,nodemanager,YARN_APPLICATION_CLASSPATH needs a documented default value in YarnConfiguration,MAPREDUCE-3505 allowed YARN_APPLICATION_CLASSPATH to be configurable.  However; we didn't add a default value to YarnConfiguration; as-is the norm.  Ran into it while investigating MAPREDUCE-4421.,Closed,Fixed,,Ahmed Radwan,Arun C Murthy,Tue; 10 Jul 2012 13:18:26 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Tue; 17 Jul 2012 23:35:27 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4422
MAPREDUCE-4423,Bug,Critical,mrv2,Potential infinite fetching of map output,Inside Fetcher. there are a few cases where an error can happen and the corresponding map task is not marked as a fetch failure.  One of these is if the Shuffle server returns a malformed result.  MAPREDUCE-3992 makes this case a lot less common; but it is still possible.  IF the shuffle handler always returns a malformed result; but a OK response the Fetcher will never stop trying to fetch those results.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 10 Jul 2012 15:26:49 +0000,Thu; 12 May 2016 18:24:10 +0000,Fri; 27 Jul 2012 01:51:15 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4423
MAPREDUCE-4424,Improvement,Minor,mrv2,'mapred job -list' command should show the job name as well,Currently the mapred job -list command does not show the Job Name; just the Job ID. It would be good to display the Job name too. Idea originally from HADOOP-5555.,Resolved,Fixed,,Avinash Kujur,Harsh J,Tue; 10 Jul 2012 16:29:14 +0000,Thu; 12 May 2016 18:23:19 +0000,Fri; 20 Mar 2015 09:50:13 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4424
MAPREDUCE-4425,Bug,Critical,mrv2,Speculation + Fetch failures can lead to a hung job,After a task goes to SUCCEEDED; FAILED KILLED tempt isn't started.,Closed,Fixed,,Jason Lowe,Siddharth Seth,Tue; 10 Jul 2012 19:08:28 +0000,Wed; 3 Sep 2014 23:17:17 +0000,Mon; 12 Nov 2012 19:03:08 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4425
MAPREDUCE-4426,Improvement,Major,test,Hook daemon process exit for testing,HDFS-3582 introduced a mechanism for testing daemon exit; this allows us to (1) verify that the daemons don't exit unexpectedly and (2) test the particular cause of exit when we do expect it. I've never seen the same MR jenkins failures that prompted HDFS-3582 but it would be worth updating the various raw calls to System#exit or Runtime#exit in MR to use ExitUtil#terminate for consistency (and eg aid hooking exit for other reasons like HADOOP-8096).,Open,Unresolved,,Unassigned,Eli Collins,Tue; 10 Jul 2012 20:22:43 +0000,Tue; 10 Jul 2012 20:22:58 +0000,,,2.0.0-alpha,,,HDFS-3582,https://issues.apache.org/jira/browse/MAPREDUCE-4426
YARN-420,Improvement,Major,applications/unmanaged-AM-launcher,Enable the RM to work with AM's that are not managed by it,Currently; the RM itself manages the AM by allocating a container for it and negotiating the launch on the NodeManager and manages the AM lifecycle. Thereafter; the AM negotiates resources with the RM and launches tasks to do the real work. It would be a useful improvement to enhance this model by allowing the AM to be launched independently by the client without requiring the RM. These AM's would be launched on a gateway machine that can talk to the cluster. This would open up new use cases such as the following 1) Easy debugging of AM; specially during initial development. Having the AM launched on an arbitrary cluster node makes it hard to looks at logs or attach a debugger to the AM. If it can be launched locally then these tasks would be easier. 2) Running AM's that need special privileges that may not be available on machines managed by the NodeManager,Closed,Fixed,,Bikas Saha,Bikas Saha,Tue; 10 Jul 2012 20:37:24 +0000,Thu; 12 May 2016 18:30:20 +0000,Sun; 15 Jul 2012 21:48:21 +0000,,3.0.0-alpha1,incom;mrv2,YARN-419,YARN-255,https://issues.apache.org/jira/browse/YARN-420
MAPREDUCE-4428,Bug,Major,jobhistoryserver;jobtracker,A failed job is not available under job history if the job is killed right around the time job is notified as failed ,We have observed this issue consistently running hadoop CDH4 version (based upon 2.0 alpha release):  In case our hadoop client code gets a notification for a completed job ( using RunningJob object job; with (job.isComplete() &amp; job.isSuccessful()==false) the hadoop client code does an unconditional job.killJob() to terminate the job.  With earlier hadoop versions (verified on hadoop 0.20.2 version); we still  have full access to job logs afterwards through hadoop console. However; when using MapReduceV2; the failed hadoop job no longer shows up under jobhistory server. Also; the tracking URL of the job still points to the non-existent Application master http port.  Once we removed the call to job.killJob() for failed jobs from our hadoop client code; we were able to access the job in job history with mapreduce V2 as well. Therefore this appears to be a race condition in the job management wrt. job history for failed jobs.  We do have the application master and node manager logs collected for this scenario if that'll help isolate the problem and the fix better.,Open,Unresolved,,Robert Joseph Evans,Rahul Jain,Wed; 11 Jul 2012 18:26:23 +0000,Thu; 12 Sep 2013 04:41:38 +0000,,,2.0.0-alpha,,,MAPREDUCE-5418;MAPREDUCE-4559,https://issues.apache.org/jira/browse/MAPREDUCE-4428
MAPREDUCE-4429,Bug,Major,,Upgrade Guava for critical performance bug fix,The bug is http: LoadingCache fixed!',Open,Unresolved,,Unassigned,Ted Yu,Wed; 11 Jul 2012 21:12:17 +0000,Wed; 11 Jul 2012 21:12:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4429
MAPREDUCE-4430,Bug,Major,mrv2,"Adding child queues to any queue need the process restart ""./yarn rmadmin -refreshQueues"" throws IO exception",1.Configure different queues for capacity scheduler say a;b under root. 2.Start the process 3.Now add the child queue b1;b2 under b 4.Now do refresh queues with command . yarn rmadmin -refreshQueues Observed that it throws the following IO exception,Resolved,Duplicate,YARN-952,Unassigned,Nishan Shetty,Thu; 12 Jul 2012 03:22:21 +0000,Fri; 13 Jul 2012 14:06:16 +0000,Fri; 13 Jul 2012 14:06:16 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4430
MAPREDUCE-4431,Improvement,Minor,mrv2,mapred command should print the reason on killing already completed jobs,"If we try to kill the already completed job by the following command it gives ambiguous message as ""Killed job job id""  . mapred job -kill already completed job id",Closed,Fixed,,Devaraj K,Nishan Shetty,Thu; 12 Jul 2012 09:22:11 +0000,Fri; 10 Apr 2015 20:19:38 +0000,Thu; 12 Feb 2015 11:39:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4431
MAPREDUCE-4432,Bug,Trivial,,Confusing warning message when GenericOptionsParser is not used,"The warning that is issued in JobSubmitter  ""Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.""  is confusing and (probably) grammatically incorrect.  This can be improved by having an updated warning message which gives clearer directions on what can be improved in the application to avoid the warning in the future.",Closed,Fixed,,Unassigned,Gabriel Reid,Thu; 12 Jul 2012 13:24:35 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Fri; 13 Jul 2012 15:24:14 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4432
MAPREDUCE-4433,Improvement,Minor,,Use Time#now and Time#monotonicNow instead of System#currentTimeMillis,hadoop-auth should be updated per HDFS-3641; I didn't do so in that patch as hadoop-common depends on hadoop-auth so we can't introduce a dependency on a common method. Given it's two one-line methods that we won't update let's just create a small Util (or Time) class in hadoop-auth and copy the methods into there.,Open,Unresolved,,Unassigned,Eli Collins,Thu; 12 Jul 2012 19:33:53 +0000,Thu; 12 Jul 2012 19:33:53 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4433
MAPREDUCE-4434,Bug,Major,mrv1,Backport MR-2779 (JobSplitWriter.java can't handle large job.split file) to branch-1,nan,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Thu; 12 Jul 2012 20:15:43 +0000,Mon; 3 Nov 2014 18:33:44 +0000,Wed; 6 Feb 2013 01:43:19 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4434
MAPREDUCE-4435,Improvement,Major,jobtracker;tasktracker,Expose JobTracker metrics for number of reducers in shuffle vs. sort vs. reduce phase,We'd like to be able to show our Cloudera Manager users some more detailed metrics about the number of reducers running at any given time--specifically; how many reducers are running in each of the three possible phases (shuffle; sort; and reduce). This would require the addition of some new overridable methods to the JobTrackerInstrumentation API; plus a little bit of code to actually call them from the JobTracker class. The necessary information seems to already be available in the TaskStatus object. The attached patch (which I've tested on hadoop-common branch-1.0) shows one way to do it.,Open,Unresolved,,Unassigned,Eirik Bakke,Thu; 12 Jul 2012 22:51:18 +0000,Wed; 22 Aug 2012 07:14:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4435
YARN-150,Bug,Major,,AppRejectedTransition does not unregister app from master service and scheduler,AttemptStartedTransition() adds the app to the ApplicationMasterService and scheduler. when the scheduler rejects the app then AppRejectedTransition() forgets to unregister it from the ApplicationMasterService.,Closed,Fixed,,Bikas Saha,Bikas Saha,Fri; 13 Jul 2012 06:39:45 +0000,Thu; 12 May 2016 18:30:22 +0000,Wed; 10 Oct 2012 00:10:10 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-150
MAPREDUCE-4437,Bug,Critical,applicationmaster;mrv2,Race in MR ApplicationMaster can cause reducers to never be scheduled,If the MR AM is notified of container completion by the RM before the AM receives notification of the container cleanup from the NM then it can fail to schedule reducers indefinitely.  Logs showing the issue to follow.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 13 Jul 2012 14:25:20 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Mon; 16 Jul 2012 19:14:37 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4437
YARN-419,Improvement,Major,applications/unmanaged-AM-launcher,Add client side for Unmanaged-AMs,MAPREDUCE-4427 added server side support for umanaged AM's. This tracks creating client side supporting pieces. The basic flow of the client is as follows 1) accepts a cmd line for the AM. Optional queue information etc. 2) negotiates an application id with the RM and submits the unmanaged AM. 3) waits for the AM to reach YarnApplicationState ACCEPTED 4) then launches the AM in a separate process via the cmd provided. It communicated application attempt id to the AM via env variable. Stdout and stderr is redirected to the clients streams respectively. 5) waits for the AM process to exit and RM app to complete.,Closed,Fixed,,Bikas Saha,Bikas Saha,Fri; 13 Jul 2012 17:10:46 +0000,Thu; 12 May 2016 18:30:29 +0000,Tue; 24 Jul 2012 18:07:06 +0000,,3.0.0-alpha1,,YARN-420,YARN-255,https://issues.apache.org/jira/browse/YARN-419
MAPREDUCE-4439,Bug,Major,,MAPREDUCE-3451 introduced a bunch of findbugs warnings,Committed findbugs exclusions (hadoop-mapreduce-project findbugs-exclude.xml) as an amendment of MAPREDUCE-3451.   Lower priority to major as warnings are excluded.  Reassigning to Patrick to verifydisregard or fix the warning issues. If the warnings are invalid please close this JIRA as won't fix.,Resolved,Duplicate,MAPREDUCE-4452,NO NAME,Arun C Murthy,Fri; 13 Jul 2012 17:13:02 +0000,Thu; 2 May 2013 02:30:52 +0000,Thu; 19 Jul 2012 01:42:28 +0000,,,,MAPREDUCE-4441,YARN-12;MAPREDUCE-3451,https://issues.apache.org/jira/browse/MAPREDUCE-4439
MAPREDUCE-4440,Bug,Major,,Change SchedulerApp & SchedulerNode to be a minimal interface ,Schedulers should manage their own implementations of SchedulerApp and SchedulerNode.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 13 Jul 2012 17:15:45 +0000,Thu; 2 May 2013 02:30:52 +0000,Tue; 17 Jul 2012 01:51:22 +0000,,2.0.0-alpha,,,MAPREDUCE-3451,https://issues.apache.org/jira/browse/MAPREDUCE-4440
MAPREDUCE-4441,Bug,Blocker,,Fix build issue caused by MR-3451,TestFSSchedulerApp is in the wrong package and missing some imports.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 13 Jul 2012 20:02:25 +0000,Mon; 3 Nov 2014 18:33:38 +0000,Fri; 13 Jul 2012 20:43:05 +0000,,2.0.0-alpha,,MAPREDUCE-4439,MAPREDUCE-3451,https://issues.apache.org/jira/browse/MAPREDUCE-4441
MAPREDUCE-4442,Bug,Major,,Accessing hadoop counters from a job is unreliable in yarn during AM process cleanup  window,We found this issue during our tests moving from MapReduceV1 to MapReduceV2. A few of our applications access job counters multiple times:  a) After submission of job; while job is execution (works fine)  b) Right after job complete notification is received (works fine)  c) Few seconds after job complete notification (fails most of the time).  The error snippet is as follows:     The connection to 10.202.50.187:47944 is actually the connection to AM; appears that we are connecting to AM to get the counters for the successful job and not yet to the history server.  I'll attach the logs for AM and resource mgr separately; however no unusual activity is seen in those.  This makes me suspect that we have a race condition in the code trying to access job counters when AM is finishing up and the job hasn't moved to history server yet.,Open,Unresolved,,Unassigned,Rahul Jain,Fri; 13 Jul 2012 20:22:51 +0000,Thu; 2 May 2013 02:30:54 +0000,,,2.0.0-alpha,usability,,MAPREDUCE-3755,https://issues.apache.org/jira/browse/MAPREDUCE-4442
MAPREDUCE-4443,Bug,Major,,MR AM and job history server should be resilient to jobs that exceed counter limits ,We saw this problem migrating applications to MapReduceV2:  Our applications use hadoop counters extensively (1000+ counters for certain jobs). While this may not be one of recommended best practices in hadoop; the real issue here is reliability of the framework when applications exceed counter limits.  The hadoop servers (yarn; history server) were originally brought up with mapreduce.job.counters.max=1000 under core-site.xml  We then ran map-reduce job under an application using its own job specific overrides; with  mapreduce.job.counters.max=10000  All the tasks for the job finished successfully; however the overall job still failed due to AM encountering exceptions as:     The overall job failed; and the job history wasn't accessible either at the end of the job (didn't show up in job history server).  We were able to workaround the issue by changing to higher limits in core-site.xml and restarting yarn servers. However that forced us to increase the counters global limit to be as high as possible use by any individual application; which is hard to predict.  The original job then succeeded with new global limits.   However; since we didn't restart the job history server; it was unable to display job history page for the successful job altogether as it still hit counter exceeded exception. Restart of job history server finally got the application available under job history.  I'll also attach AM logs to help debug the issue,Patch Available,Unresolved,,Mayank Bansal,Rahul Jain,Fri; 13 Jul 2012 20:51:44 +0000,Wed; 6 May 2015 03:28:11 +0000,,,2.0.0-alpha,BB2015-05-TBR;usability,,MAPREDUCE-5875,https://issues.apache.org/jira/browse/MAPREDUCE-4443
MAPREDUCE-4444,Bug,Blocker,nodemanager,nodemanager fails to start when one of the local-dirs is bad,nan,Closed,Fixed,,Jason Lowe,Nathan Roberts,Fri; 13 Jul 2012 21:44:48 +0000,Thu; 12 May 2016 18:23:34 +0000,Tue; 31 Jul 2012 21:11:20 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4444
MAPREDUCE-4445,Bug,Major,,TestFSSchedulerApp should be in scheduler.fair package,MAPREDUCE-3451 added Fair Scheduler to MRv2  TestFSSchedulerApp was added under src fair but its package was declared to be org.apache.hadoop.yarn.server.resourcemanager.scheduler,Resolved,Duplicate,MAPREDUCE-4441,Unassigned,Ted Yu,Sat; 14 Jul 2012 00:05:39 +0000,Sat; 14 Jul 2012 03:09:47 +0000,Sat; 14 Jul 2012 00:34:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4445
YARN-54,Sub-task,Trivial,,AggregatedLogFormat should be marked Private / Unstable,AggregatedLogFormat is still in a state of flux; so we should mark it as Private   Unstable for clarity.,Resolved,Duplicate,YARN-825,Siddharth Seth,Jason Lowe,Mon; 16 Jul 2012 15:05:25 +0000,Sun; 16 Jun 2013 20:28:07 +0000,Sun; 16 Jun 2013 20:28:07 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-54
MAPREDUCE-4447,Bug,Major,build,Remove aop from cruft from the ant build ,The nop aop build dirs and remaining reference (MR ant build) should be removed.,Closed,Fixed,,Eli Collins,Eli Collins,Mon; 16 Jul 2012 17:04:37 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Mon; 16 Jul 2012 19:11:09 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4447
MAPREDUCE-4448,Bug,Critical,mrv2;nodemanager,Nodemanager crashes upon application cleanup if aggregation failed to start,When log aggregation is enabled; the nodemanager can crash if log aggregation for an application failed to start.,Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 16 Jul 2012 19:12:08 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Tue; 17 Jul 2012 19:52:51 +0000,,0.23.3;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4448
MAPREDUCE-4449,Bug,Major,mrv2,Incorrect MR_HISTORY_STORAGE property name in JHAdminConfig,Just noticed that MR_HISTORY_STORAGE has an extra period in the its name (i.e. the name is mapreduce.jobhistory..store.class).,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 17 Jul 2012 00:33:13 +0000,Thu; 11 Oct 2012 17:48:45 +0000,Tue; 17 Jul 2012 13:52:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4449
MAPREDUCE-4450,Bug,Minor,contrib/gridmix,Hadoop jar names don't match the GridMix(2) scripts.,"Now; in Hadoop 1.0.3; the jar names are changed  as ""hadoop-examples-1.0.3.jar; hadoop-core-1.0.3.jar"". The version number is placed after ""examples""; ""cores""; and so on; which is different from the old version (e.g. in 0.20.2; the name is like hadoop-0.20.2-examples.jar.). However; in Gridmix (2) scripts (like gridmix-env); they still comply with the old naming pattern. So; there will be some problems when use gridmix benchmarks.",Open,Unresolved,,Unassigned,Xiaoyi Lu,Tue; 17 Jul 2012 02:52:53 +0000,Tue; 17 Jul 2012 02:52:53 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4450
MAPREDUCE-4451,Bug,Major,contrib/fair-share,fairscheduler fail to init job with kerberos authentication configured,Using FairScheduler in Hadoop 1.0.3 with kerberos authentication configured. Job initialization fails:     When a job is submitted; fairscheduler calls JobTracker.initJob; which calls JobInProgress.generateAndStoreTokens to write security keys to hdfs. However; the operation is involved in the server side rpc call path; using UGI created by UserGroupInformation.createRemoteUser in rpc server; which have no tgt. This should be done with UGI used by JobTracker.,Closed,Fixed,MAPREDUCE-4398;MAPREDUCE-3470,Erik.fang,Erik.fang,Tue; 17 Jul 2012 10:34:13 +0000,Wed; 15 May 2013 05:16:14 +0000,Thu; 11 Oct 2012 21:56:02 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4451
YARN-12,Bug,Major,scheduler,Several Findbugs issues with new FairScheduler in YARN,The good feature of FairScheduler is added recently to YARN. As recently PreCommit test from MAPREDUCE-4309; there are several bugs found by Findbugs related to FairScheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerEventLog.shutdown() might ignore  lang.Exception Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerEventLog.logDisabled; locked 50% of time Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueueManager.queueMaxAppsDefault; locked 50% of time Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueueManager.userMaxAppsDefault; locked 50% of time The details are in:https: newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html#DE_MIGHT_IGNORE,Closed,Fixed,,Junping Du,Junping Du,Wed; 18 Jul 2012 03:26:21 +0000,Thu; 11 Oct 2012 17:48:00 +0000,Wed; 8 Aug 2012 18:56:14 +0000,,2.0.0-alpha,,,MAPREDUCE-4439,https://issues.apache.org/jira/browse/YARN-12
MAPREDUCE-4453,Bug,Major,mrv2,Jobs should be executed as same user in hadoop-validate-setup.sh,'su -c' command should be removed in hadoop-validate-setup.sh as TeraGen; Terasort and teravalidate jobs should be executed as same user.,Resolved,Cannot Reproduce,,Unassigned,Nishan Shetty,Wed; 18 Jul 2012 10:56:45 +0000,Mon; 11 May 2015 11:23:54 +0000,Mon; 11 May 2015 11:23:54 +0000,,2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4453
MAPREDUCE-4454,Improvement,Major,applicationmaster;jobtracker;mrv1;mrv2,MR does not audit-log the job kill operations,Currently the JobTracker MR AM's AuditLogger logs only job successes and failures.  We should also log other things such as KILL; etc. (All under the Operations enum) such that MR has a proper audit log trace to use if one needs it.,Open,Unresolved,,Unassigned,Harsh J,Wed; 18 Jul 2012 16:22:14 +0000,Wed; 8 Mar 2017 12:29:11 +0000,,,1.0.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4454
YARN-37,Bug,Minor,resourcemanager,TestRMAppTransitions.testAppSubmittedKilled passes for the wrong reason,TestRMAppTransitions#testAppSubmittedKilled causes an invalid event exception but the test doesn't catch the error since the final app state is still killed.  Killed for the wrong reason; but the final state is the same.,Closed,Fixed,,Mayank Bansal,Jason Lowe,Wed; 18 Jul 2012 19:58:19 +0000,Thu; 11 Oct 2012 17:48:01 +0000,Mon; 27 Aug 2012 19:40:17 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/YARN-37
MAPREDUCE-4456,Bug,Major,mrv2,LocalDistributedCacheManager can get an ArrayIndexOutOfBounds when creating symlinks,nan,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 18 Jul 2012 21:08:13 +0000,Thu; 12 May 2016 18:23:15 +0000,Tue; 31 Jul 2012 14:51:08 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4456
MAPREDUCE-4457,Bug,Critical,mrv2,mr job invalid transition TA_TOO_MANY_FETCH_FAILURE at FAILED,we saw a job go into the ERROR state from an invalid state transition.  3;600 INFO AsyncDispatcher event handler org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: tempt_1342238829791_2501_r_000461_1000   It looks like we possibly got 2 TA_TOO_MANY_FETCH_FAILURE events. The first one moved it to FAILED and then the second one failed because no valid transition.,Closed,Fixed,,Robert Joseph Evans,Thomas Graves,Wed; 18 Jul 2012 21:38:17 +0000,Sun; 20 Oct 2013 21:21:32 +0000,Tue; 31 Jul 2012 20:58:13 +0000,,0.23.3,,,MAPREDUCE-5409,https://issues.apache.org/jira/browse/MAPREDUCE-4457
MAPREDUCE-4458,Improvement,Major,mrv2,Warn if java.library.path is used for AM or Task,If  library.path is used on the command line for launching an MRAppMaster or an MR Task; it could conflict with how standard Hadoop HDFS JNI libraries and dependencies are found.  At a minimum the client should output a warning and ask the user to switch to LD_LIBRARY_PATH.  It would be nice to automatically do this for them but parsing the command line is scary so just a warning is probably good enough for now.,Closed,Fixed,,Robert Parker,Robert Joseph Evans,Wed; 18 Jul 2012 21:49:26 +0000,Thu; 12 May 2016 18:23:18 +0000,Fri; 18 Jan 2013 23:05:09 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4458
MAPREDUCE-4459,Improvement,Minor,mr-am,Allow ad-placement on the JobTracker /RM UI,"A lot of Hadoop map-reduce users spend a lot of time staring at the jobtracker webUI to check if their job has been scheduled; and checking the progress. An easy way to monetize these eyeballs is to allow ad-placement on this page. This will attract public-cloud IaaS companies such as AWS; Google Compute Engine; Microsoft Azure etc to place ads on that page; such as ""Waiting for your job to be scheduled on your company's Hadoop cluster ? You can create your own cluster and run your jobs fast; without waiting"".  This will allow major Hadoop installations to offload some of their load to public IaaS clouds; and in addition; create an ad-revenue source for themselves.  And not only that; based on the demographic (mostly male; mostly starved of all the real-world fun) of users of these Hadoop clusters; there could be very targeted ads to be placed on this page.  (Please consider this as an extension to HADOOP-8607).",Open,Unresolved,,Unassigned,Milind Bhandarkar,Thu; 19 Jul 2012 04:04:00 +0000,Fri; 20 Jul 2012 18:14:26 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4459
YARN-26,Bug,Critical,,Refresh queue throws IO exception after configuring wrong queue capacity,Scenario: 1.My setup has a;b queues(each with capacity say 50%) under root queue 2.Start the process 3.Add one more queue 'c' under root 4.Configure some capacity for 'c' such that total capacity of a;b;c is not equal to 100 5.Now do refresh queues; it will throw exception as wrong capacity(This is expected as capacity was not equal to 100). 6.Now reconfigure queue capacities of a;b;c such that total capacity is 100 5.Now do refresh queues again  Observed that it throws IO exception,Resolved,Duplicate,MAPREDUCE-3763,Arun C Murthy,Nishan Shetty,Thu; 19 Jul 2012 05:26:30 +0000,Fri; 7 Sep 2012 21:12:24 +0000,Sun; 19 Aug 2012 20:03:34 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-26
MAPREDUCE-4461,Bug,Major,,Resourcemanager UI does not show the queue details in IE,Resourcemanager UI does not show the queue details in IE,Resolved,Cannot Reproduce,,Unassigned,Nishan Shetty,Thu; 19 Jul 2012 06:17:33 +0000,Mon; 11 May 2015 11:46:21 +0000,Mon; 11 May 2015 11:46:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4461
MAPREDUCE-4462,Bug,Minor,scheduler;test,Enhance readability of TestFairScheduler.java,While reading over the unit tests for the Fair Scheduler introduced by MAPREDUCE-3451; I added comments to make the logic of the test easier to grok quickly.,Open,Unresolved,,Unassigned,Ryan Hennig,Thu; 19 Jul 2012 14:12:21 +0000,Mon; 28 Sep 2015 18:56:18 +0000,,,,comments;test,,MAPREDUCE-3451,https://issues.apache.org/jira/browse/MAPREDUCE-4462
MAPREDUCE-4463,Bug,Blocker,mrv1,JobTracker recovery fails with HDFS permission issue,Recovery fails when the job user is different to the JT owner (i.e. on anything bigger than a pseudo-distributed cluster).,Closed,Fixed,,Tom White,Tom White,Thu; 19 Jul 2012 16:15:14 +0000,Wed; 15 May 2013 05:15:45 +0000,Thu; 4 Apr 2013 13:10:29 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4463
MAPREDUCE-4464,Improvement,Minor,task,Reduce tasks failing with NullPointerException in ConcurrentHashMap.get(),If DNS does not resolve hostnames properly; reduce tasks can fail with a very misleading exception.  as per my peer Ahmed's diagnosis:  In ReduceTask; it seems that event.getTaskTrackerHttp() returns a malformed URI; and so host from:   is evaluated to null and the NullPointerException is thrown afterwards in the ConcurrentHashMap.  I have written a patch to check for a null hostname condition when getHost is called in the getMapCompletionEvents method and print an intelligible warning message rather than suppressing it until later when it becomes confusing and misleading.,Closed,Fixed,,Clint Heath,Clint Heath,Thu; 19 Jul 2012 18:14:37 +0000,Wed; 15 May 2013 05:15:51 +0000,Thu; 27 Sep 2012 16:35:15 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4464
MAPREDUCE-4465,Bug,Trivial,,Update description of yarn.nodemanager.address property,The description for the property 'yarn.nodemanager.address' says 'address of node manager IPC.'; which is not clear enough. It should be changed to something as 'The address of the container manager in the NM'.,Closed,Fixed,,Bo Wang,Bo Wang,Fri; 20 Jul 2012 01:20:36 +0000,Thu; 11 Oct 2012 17:48:49 +0000,Tue; 24 Jul 2012 22:09:49 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4465
YARN-22,Bug,Minor,,Using URI for yarn.nodemanager log dirs fails,"If I use URIs (eg file: dirs) for yarn.nodemanager.log-dirs or yarn.nodemanager.remote-app-log-dir the container log servlet fails with an NPE (works if I remove the ""file"" scheme). Using a URI for yarn.nodemanager.local-dirs works.",Closed,Fixed,,Mayank Bansal,Eli Collins,Fri; 20 Jul 2012 07:34:30 +0000,Thu; 11 Oct 2012 17:48:00 +0000,Tue; 21 Aug 2012 22:37:52 +0000,,0.23.3,,,YARN-33,https://issues.apache.org/jira/browse/YARN-22
MAPREDUCE-4467,Bug,Critical,nodemanager,IndexCache failures due to missing synchronization,"TestMRJobs.testSleepJob fails randomly due to synchronization error in IndexCache:     A related issue is MAPREDUCE-4384. The change introduced there removed ""synchronized"" keyword and hence ""info.wait()"" call fails. Tbis needs to be wrapped into a ""synchronized"" block.",Closed,Fixed,,Kihwal Lee,Andrey Klochkov,Fri; 20 Jul 2012 18:20:20 +0000,Thu; 11 Oct 2012 17:48:47 +0000,Tue; 24 Jul 2012 19:30:56 +0000,,0.23.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4467
MAPREDUCE-4468,Improvement,Minor,scheduler,Encapsulate FairScheduler preemption logic into helper class,I've extracted the preemption logic from the Fair Scheduler into a helper class so that FairScheduler is closer to following the Single Responsibility Principle.  This may eventually evolve into a generalized preemption module which could be leveraged by other schedulers.,Open,Unresolved,,Unassigned,Ryan Hennig,Fri; 20 Jul 2012 19:05:14 +0000,Mon; 28 Sep 2015 18:55:44 +0000,,,,refactoring;scheduler,,MAPREDUCE-533;MAPREDUCE-3451,https://issues.apache.org/jira/browse/MAPREDUCE-4468
YARN-3612,Bug,Major,,Resource calculation in child tasks is CPU-heavy,In doing some benchmarking on a hadoop-1 derived codebase; I noticed that each of the child tasks was doing a ton of syscalls. Upon stracing; I noticed that it's spending a lot of time looping through all the files in  proc to calculate resource usage.  As a test; I added a flag to disable use of the ResourceCalculatorPlugin within the tasks. On a CPU-bound 500G-sort workload; this improved total job runtime by about 10% (map slot-seconds by 14%; reduce slot seconds by 8%),Open,Unresolved,,Unassigned,Todd Lipcon,Mon; 23 Jul 2012 20:42:21 +0000,Sat; 7 Jan 2017 01:52:36 +0000,,,2.7.0,BB2015-05-RFC;performance,,,https://issues.apache.org/jira/browse/YARN-3612
MAPREDUCE-4470,Bug,Major,test,Fix TestCombineFileInputFormat.testForEmptyFile,TestCombineFileInputFormat.testForEmptyFile started failing after HADOOP-8599.   It expects one split on an empty input file; but with HADOOP-8599 it gets zero. The new behavior seems correct; but is it breaking anything else?,Closed,Fixed,MAPREDUCE-4475,Ilya Katsov,Kihwal Lee,Mon; 23 Jul 2012 21:55:59 +0000,Sat; 2 Feb 2013 12:40:29 +0000,Thu; 23 Aug 2012 00:26:05 +0000,,2.0.0-alpha,,MAPREDUCE-4479;MAPREDUCE-4577,,https://issues.apache.org/jira/browse/MAPREDUCE-4470
MAPREDUCE-4471,Bug,Major,mrv2,TestClientRMService.testGetQueueInfo failing after MR-4427,TestClientRMService.testGetQueueInfo has been consistently failing since MAPREDUCE-4427.,Closed,Invalid,,Unassigned,Kihwal Lee,Mon; 23 Jul 2012 22:13:56 +0000,Tue; 10 Mar 2015 04:31:03 +0000,Mon; 23 Jul 2012 22:21:43 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4471
YARN-255,Improvement,Major,applications/unmanaged-AM-launcher,Support secure AM launch for unmanaged AM's,Currently unmanaged AM launch does not get security tokens because tokens are passed by the RM to the AM via the NM during AM container launch. For unmanaged AM's the RM can send tokens in the SubmitApplicationResponse to the secure client. The client can then pass these onto the AM in a manner similar to the NM.,Resolved,Duplicate,YARN-937,Unassigned,Bikas Saha,Tue; 24 Jul 2012 06:23:12 +0000,Thu; 12 May 2016 18:29:10 +0000,Wed; 6 May 2015 19:50:43 +0000,,3.0.0-alpha1,,,YARN-419;YARN-420,https://issues.apache.org/jira/browse/YARN-255
MAPREDUCE-4473,Improvement,Minor,tasktracker,tasktracker rank on machines.jsp?type=active,sometimes we need to simple judge which tasktracker is down from the page of machines.jsp?type=active,Resolved,Won't Fix,,Unassigned,jian fan,Tue; 24 Jul 2012 06:58:42 +0000,Sat; 9 May 2015 00:16:51 +0000,Sat; 9 May 2015 00:16:51 +0000,,0.20.2;0.21.0;0.22.0;0.23.0;0.23.1;1.0.0;1.0.1;1.0.2;1.0.3,BB2015-05-TBR;tasktracker,,,https://issues.apache.org/jira/browse/MAPREDUCE-4473
MAPREDUCE-4474,Bug,Major,test,TestDistributedShell.testDSShell fails on CentOS 6 because of high virtual memory usage,TestDistributedShell.testDSShell fails on CentOS 6 because of high virtual memory usage:,Open,Unresolved,,Ilya Katsov,Ilya Katsov,Tue; 24 Jul 2012 08:37:12 +0000,Thu; 9 Aug 2012 22:07:17 +0000,,,0.23.3,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-4474
MAPREDUCE-4475,Bug,Major,test,testForEmptyFile failed,This test failed in a recent test run:  testForEmptyFile(org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat): expected:0 but was:1  https: ,Resolved,Duplicate,MAPREDUCE-4470,Unassigned,Eli Collins,Tue; 24 Jul 2012 15:51:06 +0000,Thu; 12 May 2016 18:22:20 +0000,Sat; 29 Sep 2012 00:25:21 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4475
YARN-8,Improvement,Major,,Add more unit tests for CPU scheduling in CS,Companion to YARN-2.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Tue; 24 Jul 2012 19:55:04 +0000,Mon; 8 Jul 2013 18:31:03 +0000,,,,,YARN-2,,https://issues.apache.org/jira/browse/YARN-8
MAPREDUCE-4477,Improvement,Minor,performance;task,Improve task finish synchronization,Tom suggested on MAPREDUCE-4400 that we keep the task finish synchronization logic the same as much as possible.,Open,Unresolved,,Unassigned,Luke Lu,Tue; 24 Jul 2012 22:16:39 +0000,Tue; 24 Jul 2012 22:17:02 +0000,,,2.0.0-alpha,,,MAPREDUCE-4400,https://issues.apache.org/jira/browse/MAPREDUCE-4477
MAPREDUCE-4478,Bug,Major,,TaskTracker's heartbeat is out of control,nan,Closed,Fixed,,Liyin Liang,Liyin Liang,Wed; 25 Jul 2012 05:30:38 +0000,Wed; 6 Mar 2013 09:55:59 +0000,Fri; 30 Nov 2012 20:49:56 +0000,,1.0.0;1.0.1;1.0.2;1.0.3,,,MAPREDUCE-2355,https://issues.apache.org/jira/browse/MAPREDUCE-4478
MAPREDUCE-4479,Bug,Major,test,Fix parameter order in assertEquals() in TestCombineInputFileFormat.java,nan,Closed,Fixed,,Mariappan Asokan,Mariappan Asokan,Wed; 25 Jul 2012 15:30:45 +0000,Thu; 12 May 2016 18:24:23 +0000,Fri; 19 Oct 2012 17:59:33 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,MAPREDUCE-4470,,https://issues.apache.org/jira/browse/MAPREDUCE-4479
MAPREDUCE-4480,Bug,Critical,,T_ATTEMPT_KILLED after SUCCEEDED can happen for reduces too ,This does not seem to impact 0.23.  If speculative execution is enabled then a T_ATTEMPT_KILLED event can come in after the task has transitioned to SUCCEEDED.  This causes the MapRetroactiveKilledTransition to kill the Job; because it expects to only handle map tasks.,Resolved,Not A Problem,,Unassigned,Robert Joseph Evans,Wed; 25 Jul 2012 17:59:21 +0000,Thu; 12 May 2016 18:23:47 +0000,Thu; 15 Nov 2012 16:05:24 +0000,,2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4480
MAPREDUCE-4481,Improvement,Minor,tasktracker,User Log Retention across TT restarts,The tasktrackers cleanup the userlog directory when they restart. This happens independent of value of mapred.userlog.retain.hours.  The feature is to add a configurable feature to respect mapred.userlog.retain.hours across TT restarts,Reopened,Unresolved,,Unassigned,Benoy Antony,Wed; 25 Jul 2012 18:02:17 +0000,Thu; 2 May 2013 02:30:53 +0000,,,0.22.0,,,MAPREDUCE-2415,https://issues.apache.org/jira/browse/MAPREDUCE-4481
MAPREDUCE-4482,New Feature,Major,mrv1,Backport MR sort plugin(MAPREDUCE-2454) to Hadoop 1.2,nan,Patch Available,Unresolved,,Mariappan Asokan,Mariappan Asokan,Wed; 25 Jul 2012 19:31:47 +0000,Wed; 6 May 2015 03:31:22 +0000,,,1.2.0,BB2015-05-TBR,,MAPREDUCE-2454,https://issues.apache.org/jira/browse/MAPREDUCE-4482
MAPREDUCE-4483,Bug,Major,,2.0 build does not work ,Seems like hadoop-yarn-applications-unmanaged-am-launcher pom.xml is pointing to the wrong parent,Closed,Fixed,,John George,John George,Wed; 25 Jul 2012 19:54:54 +0000,Thu; 4 Sep 2014 01:00:32 +0000,Tue; 31 Jul 2012 19:50:58 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4483
MAPREDUCE-4484,Bug,Major,mrv2,Incorrect IS_MINI_YARN_CLUSTER property name in YarnConfiguration,"Noticed that the IS_MINI_YARN_CLUSTER property name in YarnConfiguration ended up having an extra ""."" after appending to YARN_PREFIX.",Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Wed; 25 Jul 2012 23:15:39 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Tue; 7 Aug 2012 05:17:03 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4484
YARN-100,Improvement,Minor,nodemanager,container-executor should deal with stdout; stderr better,"container-executor.c contains the following code:     Whenever you open a new file descriptor; its number is the lowest available number.  So if stdout (fd number 1) has been closed; and you do open("" null.  dup2 can be used for this purpose.  It looks like LOGFILE and ERRORFILE are always set to stdout and stderr at the moment.  However; this is a latent bug that should be fixed in case these are ever made configurable (which seems to have been the intent).",Resolved,Later,,Unassigned,Colin P. McCabe,Thu; 26 Jul 2012 01:03:25 +0000,Sun; 3 May 2015 01:33:44 +0000,Sun; 3 May 2015 01:33:44 +0000,,2.0.1-alpha,,,,https://issues.apache.org/jira/browse/YARN-100
MAPREDUCE-4486,Bug,Major,build,issues in POM of hadoop-yarn-applications-unmanaged-am-launcher,Incorrectly the dependency for distributed shell has a version; this should be in the dependencies management section of hadoop-project POM  backport to branch-2 didn't set the right Hadoop version in the POM and parent.,Closed,Duplicate,MAPREDUCE-4483,Bikas Saha,Alejandro Abdelnur,Thu; 26 Jul 2012 13:30:36 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Thu; 26 Jul 2012 15:36:21 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4486
MAPREDUCE-4487,Improvement,Major,mrv1;mrv2;performance,Reduce job latency by removing hardcoded sleep statements,There are a few places in MapReduce where there are hardcoded sleep statements. By replacing them with wait notify or similar it's possible to reduce latency for short running jobs.,Patch Available,Unresolved,,Tom White,Tom White,Thu; 26 Jul 2012 16:22:04 +0000,Wed; 6 May 2015 03:34:34 +0000,,,1.0.3;2.0.0-alpha,BB2015-05-TBR,,MAPREDUCE-4488,https://issues.apache.org/jira/browse/MAPREDUCE-4487
MAPREDUCE-4488,New Feature,Major,mrv1;performance,Port MAPREDUCE-463 (The job setup and cleanup tasks should be optional) to branch-1,nan,Reopened,Unresolved,,Tom White,Tom White,Thu; 26 Jul 2012 18:05:20 +0000,Tue; 14 May 2013 05:14:42 +0000,,,1.0.3,,,MAPREDUCE-4487;MAPREDUCE-463,https://issues.apache.org/jira/browse/MAPREDUCE-4488
HDFS-3732,Bug,Minor,fuse-dfs,fuse_dfs: incorrect configuration value checked for connection expiry timer period,In fuse_dfs; we check an incorrect hdfs configuration value checked for the connection expiry timer period.     We should be checking HADOOP_FUSE_TIMER_PERIOD.,Closed,Fixed,,Colin P. McCabe,Colin P. McCabe,Thu; 26 Jul 2012 22:13:31 +0000,Thu; 11 Oct 2012 17:46:20 +0000,Mon; 30 Jul 2012 18:08:42 +0000,,2.0.1-alpha,,,,https://issues.apache.org/jira/browse/HDFS-3732
MAPREDUCE-4490,Bug,Critical,task-controller;tasktracker,JVM reuse is incompatible with LinuxTaskController (and therefore incompatible with Security),When using LinuxTaskController; JVM reuse (mapred.job.reuse.jvm.num.tasks  1) with more map tasks in a job than there are map slots in the cluster will result in immediate task failures for the second task in each JVM (and then the JVM exits). We have investigated this bug and the root cause is as follows. When using LinuxTaskController; the userlog directory for a task tempt directories.  Call that command; with ShellCommandExecutor; in the LinuxTaskController#createLogDir method,Resolved,Fixed,,sam liu,George Datskos,Fri; 27 Jul 2012 01:22:21 +0000,Fri; 13 Jun 2014 21:38:12 +0000,Fri; 13 Jun 2014 21:38:12 +0000,,0.20.205.0;1.0.3;1.2.1,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4490
MAPREDUCE-4491,New Feature,Major,documentation;security;task-controller;tasktracker,Encryption and Key Protection,When dealing with sensitive data; it is required to keep the data encrypted wherever it is stored. Common use case is to pull encrypted data out of a datasource and store in HDFS for analysis. The keys are stored in an external keystore.   The feature adds a customizable framework to integrate different types of keystores; support for Java KeyStore; read keys from keystores; and transport keys from JobClient to Tasks. The feature adds PGP encryption as a codec and additional utilities to perform encryption related steps.   The design document is attached. It explains the requirement; design and use cases. Kindly review and comment. Collaboration is very much welcome.  I have a tested patch for this for 1.1 and will upload it soon as an initial work for further refinement.  Update: The patches are uploaded to subtasks.,Resolved,Won't Do,,Benoy Antony,Benoy Antony,Fri; 27 Jul 2012 01:24:45 +0000,Mon; 16 Oct 2017 19:44:18 +0000,Mon; 16 Oct 2017 19:44:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4491
MAPREDUCE-4492,Bug,Minor,mrv2,Configuring total queue capacity between 100.5 and 99.5 at perticular level is sucessfull,Scenario: 1.Configure a;b queues with capacities 40.0 and 60.5 respectively under root queue 2.Start process Observe that process is started sucessfully with configured queue capacity though the total capacity is 100.5(40.0+60.5),Closed,Fixed,,Mayank Bansal,Nishan Shetty,Fri; 27 Jul 2012 14:24:23 +0000,Thu; 11 Oct 2012 17:48:45 +0000,Tue; 31 Jul 2012 19:38:54 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4492
MAPREDUCE-4493,Bug,Critical,mrv2,Distibuted Cache Compatability Issues,The distributed cache does not work like it does in 1.0.  mapreduce.job.cache.symlink.create is completely ignored and symlinks are always created no matter what.  Files and archives without a fragment will also have symlinks created.  If two cache archives or cache files happen to have the same name; or same symlink fragment only the last one in the list is localized.  The localCacheArchives and LocalCacheFiles are not set correctly when these duplicates happen causing off by one or more errors for anyone trying to use them.  The reality is that use of symlinking is so common currently that these incompatibilities are not that likely to show up; but we still need to fix them.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Fri; 27 Jul 2012 20:56:45 +0000,Thu; 12 May 2016 18:22:16 +0000,Tue; 31 Jul 2012 19:22:53 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4493
MAPREDUCE-4494,Bug,Major,mrv2;test,TestFifoScheduler failing with Metrics source QueueMetrics;q0=default already exists!,TestFifoScheduler is failing:,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Sat; 28 Jul 2012 21:06:32 +0000,Thu; 11 Oct 2012 17:48:52 +0000,Tue; 7 Aug 2012 05:13:03 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4494
OOZIE-1178,New Feature,Major,,Workflow Application Master in YARN,"It is useful to have a workflow application master; which will be capable of running a DAG of jobs. The workflow client submits a DAG request to the AM and then the AM will manage the life cycle of this application in terms of requesting the needed resources from the RM; and starting; monitoring and retrying the application's individual tasks.  Compared to running Oozie with the current MapReduce Application Master; these are some of the advantages:  	Less number of consumed resources; since only one application master will be spawned for the whole workflow. 	Reuse of resources; since the same resources can be used by multiple consecutive jobs in the workflow (no need to request extended by higher systems like Pig and hive to provide an optimized way of running their workflows.",Open,Unresolved,,Unassigned,Bo Wang,Mon; 30 Jul 2012 20:57:49 +0000,Mon; 27 Jun 2016 14:53:10 +0000,,,,,,OOZIE-1770;PIG-1734;OOZIE-593;HIVE-1107,https://issues.apache.org/jira/browse/OOZIE-1178
MAPREDUCE-4496,Bug,Major,applicationmaster;mrv2,AM logs link is missing user name,The link to the ApplicationMaster's logs on the MRAppMaster's web page is missing the user name.,Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 30 Jul 2012 21:40:29 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Tue; 31 Jul 2012 15:11:22 +0000,,0.23.3;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4496
MAPREDUCE-4497,Bug,Minor,jobtracker,"JobTracker webUI ""Kill Selected Jobs"" button has no effect",When enabling the webinterface.private.actions property to true; the JobTracker displays additional buttons allowing the user to (1) kill jobs or (2) change the priority of a job.  However; an erroneous interaction between the HTML (produced by mapred JSPUtil.  the form element is placed inside the table and spans multiple tr and td which is incorrect. Placing the form around the table fixes this bug (see patch),Open,Unresolved,,Unassigned,George Datskos,Tue; 31 Jul 2012 00:19:31 +0000,Tue; 31 Jul 2012 00:21:24 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4497
MAPREDUCE-4498,Bug,Critical,build;examples,Remove hsqldb jar from Hadoop runtime classpath,The hsqldb jar is included in hadoop for the DBCountPageView example only.  Currently the example is using hsqldb version 2.x; however; 2.x is incompatible with 1.8.x  having this jar in the hadoop class path conflicts with dependent projects like Oozie; Hive; and Pig which still use 1.8.x.  As there are no features hsqldb 2.x that are used by the example; we should remove it from Hadoop's runtime classpath.,Closed,Fixed,,Robert Kanter,Robert Kanter,Tue; 31 Jul 2012 16:27:00 +0000,Thu; 11 Oct 2012 17:48:46 +0000,Mon; 6 Aug 2012 18:16:20 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4498
MAPREDUCE-4499,Improvement,Major,mrv1;performance,Looking for speculative tasks is very expensive in 1.x,"When there are lots of jobs and tasks active in a cluster; the process of figuring out whether or not to launch a speculative task becomes very expensive.   I could be missing something but it certainly looks like on every heartbeat we could be scanning 10's of thousands of tasks looking for something which might need to be speculatively executed. In most cases; nothing gets chosen so we completely trashed our data cache and didn't even find a task to schedule; just to do it all over again on the next heartbeat.  On busy jobtrackers; the following backtrace is very common:  ""IPC Server handler 32 on 50300"" daemon prio=10 tid=0x00002ab36c74f800 nid=0xb50 runnable 0x0000000045adb000    3398) 	locked 0x00002aab6e191278 (a org.apache.hadoop.mapred.JobTracker) ...)",Closed,Fixed,,Koji Noguchi,Nathan Roberts,Tue; 31 Jul 2012 21:50:47 +0000,Wed; 15 May 2013 05:15:57 +0000,Wed; 29 Aug 2012 15:48:27 +0000,,1.0.3,,,MAPREDUCE-1684,https://issues.apache.org/jira/browse/MAPREDUCE-4499
MAPREDUCE-4500,Bug,Major,mrv1,TestUlimit is failing locally,ant clean test -Dtestcase=TestUlimit -Dtest.output=yes fails locally  Attaching the dump,Resolved,Duplicate,NULL,Unassigned,Karthik Kambatla,Wed; 1 Aug 2012 00:05:01 +0000,Mon; 3 Nov 2014 18:33:55 +0000,Wed; 1 Aug 2012 00:22:00 +0000,,1.0.3,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-4500
MAPREDUCE-4501,Bug,Major,,couldn't compile hadoop-2.0 successfully because of errors in build files,hadoop-yarn-applications relies on is 2.0.1-SNAPSHOT; however; the commit makes it 3.0.0-SNAPSHOT. This makes the compile fail.,Open,Unresolved,,Unassigned,Yan Liu,Wed; 1 Aug 2012 03:12:19 +0000,Fri; 3 Aug 2012 08:28:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4501
MAPREDUCE-4502,Improvement,Major,applicationmaster;mrv2,Node-level aggregation with combining the result of maps,The shuffle costs is expensive in Hadoop in spite of the existence of combiner; because the scope of combining is limited within only one MapTask. To solve this problem; it's a good way to aggregate the result of maps per node rack by launch combiner.  This JIRA is to implement the multi-level aggregation infrastructure; including combining per container(MAPREDUCE-3902 is related); coordinating containers by application master without breaking fault tolerance of jobs.,Patch Available,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Wed; 1 Aug 2012 06:46:27 +0000,Thu; 12 May 2016 18:23:00 +0000,,,3.0.0-alpha1,BB2015-05-TBR,,TAJO-374,https://issues.apache.org/jira/browse/MAPREDUCE-4502
MAPREDUCE-4503,Bug,Major,mrv2,Should throw InvalidJobConfException if duplicates found in cacheArchives or cacheFiles,in 1.0 if a file was both in a jobs cache archives and cache files; and InvalidJobConfException was thrown.  We should replicate this behavior on mrv2.  We should also extend it so that if a cache archive or cache file is not going to be downloaded at all because of conflicts in the names of the symlinks a similar exception is thrown.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 1 Aug 2012 13:07:46 +0000,Thu; 12 May 2016 18:22:23 +0000,Fri; 3 Aug 2012 20:31:03 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4503
MAPREDUCE-4504,Bug,Major,mrv2,SortValidator writes to wrong directory,"SortValidator tries to write to jobConf.get(""hadoop.tmp.dir""; "" tmp.",Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 1 Aug 2012 14:31:42 +0000,Thu; 12 May 2016 18:22:25 +0000,Wed; 1 Aug 2012 22:23:11 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4504
MAPREDUCE-4505,Bug,Major,performance;task,Create a combiner bypass path for keys with a single value,It would help optimize a lot of cases where there aren't a lot of replicated keys if the framework would bypass the deserialize serialize step for keys that only have a single value.,Open,Unresolved,,Arun C Murthy,Owen O'Malley,Wed; 1 Aug 2012 18:56:19 +0000,Wed; 1 Aug 2012 19:07:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4505
MAPREDUCE-4506,Bug,Minor,,EofException / 'connection reset by peer' while copying map output ,When running complex mapreduce jobs with many mappers and reducers (e.g. 8 mappers; 8 reducers on a 8 core machine); sometimes the following exceptions pop up in the logs during the shuffle phase:     The problem looks like some network problems at first; however it turns out that hadoop shuffleInMemory sometimes deliberately closes map-output-copy connections just to reopen them a few milliseconds later; because of temporary unavailability of free memory. Because the sending side does not expect this; an exception is thrown. Additionally this leads to wasting resources on the sender side; which does more work than required serving additional requests.,Patch Available,Unresolved,,Unassigned,Piotr Ko  aczkowski,Thu; 2 Aug 2012 09:29:38 +0000,Wed; 6 May 2015 03:31:09 +0000,,,1.0.3,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4506
MAPREDUCE-4507,Bug,Major,mrv1,IdentityMapper is being triggered when the type of the Input Key at class level and method level has a conflict,If we use the default InputFormat (TextInputFormat) but specify the Key type in mapper as IntWritable instead of Long Writable. The framework is supposed throw a class cast exception.Such an exception is thrown only if the key types at class level and method level are the same (IntWritable). But if we provide the Input key type as IntWritable on the class level but LongWritable on the method level (map method); instead of throwing a compile time error; the code compliles fine . In addition to it on execution the framework triggers Identity Mapper instead of the custom mapper provided with the configuration. In this case the 'mapreduce.map.class' in job.xml shows mapper as Custom Mapper itself ; it should show IdentityMapper in cases where IdentityMapper is triggered to avoid confusion and easy debugging.,Open,Unresolved,,Unassigned,Bejoy KS,Thu; 2 Aug 2012 22:39:46 +0000,Fri; 3 Aug 2012 11:07:12 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4507
YARN-55,Bug,Major,resourcemanager,YARN needs to properly check the NM;AM memory properties in yarn-site.xml and mapred.xml and report errors accordingly.,Please refer to this discussion on the Hadoop Mailing list: http: HBase cluster. My datanodes were only having 3.2GB of memory. So; i configured the yarn.nodemanager.resource.memory-mb property in yarn-site.xml to 1200. After setting the property if i run any Yarn Job then the NodemManager wont be able to start any Map task since by default the yarn.app.mapreduce.am.resource.mb property is set to 1500 MB in mapred-site.xml.  Expected Behavior: NodeManager should give an error if yarn.app.mapreduce.am.resource.mb = yarn.nodemanager.resource.memory-mb.  Please let me know if more information is required.,Resolved,Invalid,,Unassigned,Anil Gupta,Thu; 2 Aug 2012 23:22:16 +0000,Sun; 14 Apr 2013 20:56:15 +0000,Sun; 14 Apr 2013 20:56:15 +0000,,2.0.2-alpha;0.23.3,Map;Reduce;YARN,,,https://issues.apache.org/jira/browse/YARN-55
YARN-239,Improvement,Trivial,nodemanager,"Make link in ""Aggregation is not enabled. Try the nodemanager at""",if log aggregation is disabled message is displayed   Aggregation is not enabled. Try the nodemanager at reavers.com:9006  It would be helpfull to make link to nodemanager clickable.  This message is located in   but i could not figure out how to make link in hamlet framework.,Resolved,Duplicate,YARN-2275,Unassigned,Radim Kolar,Fri; 3 Aug 2012 00:32:06 +0000,Mon; 14 Jul 2014 17:44:17 +0000,Mon; 14 Jul 2014 17:44:17 +0000,,2.0.0-alpha,usability,,,https://issues.apache.org/jira/browse/YARN-239
MAPREDUCE-4510,Bug,Major,,"Avoid logging ""Cannot run program getconf"" on Windows",ProcfsbasesProcessTree logs error messages when it cannot run getconf to determine system attributes on linux. this causes a lot of log spew on windows. need to fix this code because linux is not longer the only OS supported for hadoop.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Fri; 3 Aug 2012 05:27:32 +0000,Thu; 30 Aug 2012 02:28:26 +0000,Thu; 30 Aug 2012 02:28:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4510
MAPREDUCE-4511,Improvement,Major,mrv1;mrv2;performance,Add IFile readahead,This ticket is to add IFile readahead as part of HADOOP-7714.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Fri; 3 Aug 2012 10:18:29 +0000,Wed; 17 Jul 2013 19:46:39 +0000,Wed; 15 Aug 2012 23:16:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4511
HADOOP-8654,Bug,Major,util,TextInputFormat delimiter  bug:- Input Text portion ends with & Delimiter starts with same char/char sequence,"TextInputFormat delimiter  bug scenario ; a character sequence of the input text;  in which the first character matches with the first character of delimiter; and the remaining input text character sequence  matches with the entire delimiter character sequence from the  starting position of the delimiter.  eg   delimiter =""record""; and Text ="" record 1:- name = Gelesh e mail = gelesh.hadoop@gmail.com Location Bangalore record 2: name = sdf  ..  location =Bangalorrecord 3: name .... ""   Here string ""=Bangalorrecord 3: "" satisfy two conditions  1) contains the delimiter ""record"" 2) The character  char sequence 'r' );  Here the delimiter is not encountered by the program resulting in improper value text in map that contains the delimiter",Closed,Fixed,,Unassigned,Gelesh,Fri; 3 Aug 2012 15:56:08 +0000,Thu; 4 Sep 2014 00:59:39 +0000,Thu; 16 Aug 2012 14:25:43 +0000,,0.20.204.0;1.0.3;0.21.0;2.0.0-alpha,patch,,,https://issues.apache.org/jira/browse/HADOOP-8654
MAPREDUCE-4513,Improvement,Major,,Make MR AM thread-safe,Currently MR-AM has a bunch of statics making it thread unsafe. We should fix that.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Fri; 3 Aug 2012 17:44:44 +0000,Fri; 3 Aug 2012 17:44:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4513
YARN-14,Bug,Major,nodemanager,Symlinks to peer distributed cache files no longer work,"Trying to create a symlink to another file that is specified for the distributed cache will fail to create the link.  For example:  hadoop jar ... -files ""x;y;x#z""  will localize the files x and y as x and y; but the z symlink for x will not be created.  This is a regression from 1.x behavior.",Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 3 Aug 2012 21:59:02 +0000,Thu; 11 Oct 2012 17:48:00 +0000,Thu; 9 Aug 2012 19:23:43 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-14
MAPREDUCE-4515,Test,Minor,jobtracker;tasktracker,Add test to check if userlogs are retained across TaskTracker restarts,nan,Resolved,Later,,Karthik Kambatla,Karthik Kambatla,Fri; 3 Aug 2012 23:50:08 +0000,Mon; 3 Nov 2014 18:33:31 +0000,Wed; 15 Aug 2012 18:45:32 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4515
MAPREDUCE-4516,Bug,Major,,Error reading task output Server returned HTTP response code: 400 for URL: http://hadoop03:8080/tasklog?plaintext=true&attemptid=attempt_1344047400780_0002_m_000000_0&filter=stdout,bin in_test   INFO mapreduce.Job: Counters: 28         File System Counters                 FILE: Number of bytes read=240                 FILE: Number of bytes written=118412                 FILE: Number of read operations=0                 FILE: Number of large read operations=0                 FILE: Number of write operations=0                 HDFS: Number of bytes read=167                 HDFS: Number of bytes written=100000000                 HDFS: Number of read operations=8                 HDFS: Number of large read operations=0                 HDFS: Number of write operations=4         Job Counters                  Failed map tasks=1                 Launched map tasks=3                 Other local map tasks=3                 Total time spent by all maps in occupied slots (ms)=193607         Map-Reduce Framework                 Map input records=1000000                 Map output records=1000000                 Input split bytes=167                 Spilled Records=0                 Failed Shuffles=0                 Merged Map outputs=0                 GC time elapsed (ms)=34470                 CPU time spent (ms)=9510                 Physical memory (bytes) snapshot=224739328                 Virtual memory (bytes) snapshot=3888279552                 Total committed heap usage (bytes)=63832064         org.apache.hadoop.examples.terasort.TeraGen$Counters                 CHECKSUM=2148987642402270         File Input Format Counters                  Bytes Read=0         File Output Format Counters                  Bytes Written=100000000,Open,Unresolved,,Unassigned,jiafeng.zhang,Sat; 4 Aug 2012 03:37:55 +0000,Sat; 4 Aug 2012 03:37:55 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4516
MAPREDUCE-4517,Improvement,Minor,applicationmaster,Too many INFO messages written out during AM to RM heartbeat,"Too many INFO log messages written out during AM to RM heartbeat. Based on default frequency of 1000ms (scheduler.heartbeat.interval-ms) either 2 or 4 INFO messages are written out per second:  LOG.info(""Before Scheduling: "" + getStat()); ListContainer allocatedContainers = getResources(); LOG.info(""After Scheduling: "" + getStat()); if (allocatedContainers.size()  0) {   LOG.info(""Before Assign: "" + getStat());   scheduledRequests.assign(allocatedContainers);   LOG.info(""After Assign: "" + getStat()); }  These should probably be changed to DEBUG message to save the log growing too quickly.",Closed,Fixed,,Jason Lowe,James Kinley,Sun; 5 Aug 2012 19:40:19 +0000,Wed; 3 Sep 2014 23:17:19 +0000,Tue; 13 Nov 2012 23:50:43 +0000,,0.23.1;2.0.1-alpha,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4517
YARN-23,Improvement,Major,scheduler,FairScheduler: FSQueueSchedulable#updateDemand() - potential redundant aggregation,In FS; FSQueueSchedulable#updateDemand() limits the demand to maxTasks only after iterating though all the pools and computing the final demand.   By checking if the demand has reached maxTasks in every iteration; we can avoid redundant work; at the expense of one condition check every iteration.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Mon; 6 Aug 2012 09:03:52 +0000,Mon; 3 Nov 2014 18:33:34 +0000,Thu; 4 Oct 2012 23:03:24 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/YARN-23
HADOOP-8655,Bug,Major,util,In TextInputFormat; while specifying textinputformat.record.delimiter the character/character sequences in data file similar to starting character/starting character sequence in delimiter were found missing in certain cases in the Map Output,"Set textinputformat.record.delimiter as "" name  The pattern shown above need not occur for value 1;2;3 necessarily. The bug occurs at some random positions in the map input.",Closed,Fixed,,Unassigned,Arun A K,Mon; 6 Aug 2012 11:01:33 +0000,Thu; 4 Sep 2014 00:59:38 +0000,Thu; 23 Aug 2012 17:00:34 +0000,,0.20.2,hadoop;mapreduce;textinputformat;textinputformat.record.delimiter,,,https://issues.apache.org/jira/browse/HADOOP-8655
MAPREDUCE-4520,New Feature,Major,,Add experimental support for MR AM to schedule CPUs along-with memory,nan,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sat; 7 Jul 2012 00:43:48 +0000,Fri; 15 Feb 2013 13:10:04 +0000,Wed; 9 Jan 2013 05:32:00 +0000,,,,YARN-2,,https://issues.apache.org/jira/browse/MAPREDUCE-4520
MAPREDUCE-4521,Bug,Major,mrv2,mapreduce.user.classpath.first incompatibility with 0.20/1.x,In Hadoop 0.20 or 1.x; jobs can specify the user's classpath should appear first by setting the property mapreduce.user.classpath.first to true in the job configuration.  However in Hadoop 0.23 or 2.x; this has no effect; as the corresponding property there is mapreduce.job.user.classpath.first.,Closed,Fixed,,Ravi Prakash,Jason Lowe,Mon; 6 Aug 2012 22:39:02 +0000,Wed; 3 Sep 2014 23:17:19 +0000,Tue; 16 Oct 2012 22:02:24 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4521
MAPREDUCE-4522,Bug,Major,task-controller,DBOutputFormat Times out on large batch inserts,In DBRecordWriter#close(); progress is never updated. In large batch inserts; this can cause the reduce task to time out due to the amount of time it takes the SQL engine to process that insert.   Potential solutions I can see: Don't batch inserts; do the insert when DBRecordWriter#write() is called (awful) Spin up a thread in DBRecordWriter#close() and update progress in that. (gross)  I can provide code for either if you're interested.,Patch Available,Unresolved,,Shyam Gavulla,Nathan Jarus,Tue; 7 Aug 2012 01:48:32 +0000,Mon; 25 Jul 2016 04:58:10 +0000,,,0.20.205.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4522
MAPREDUCE-4523,Improvement,Minor,,DBOutputFormat cannot be easily subclassed,In DBOutputFormat#setOutput(); job.setOutputFormat(DBOutputFormat.class) is called. When subclassing DBOutputFormat; this function must be overridden to call job.setOutputFormat(SubclassedDBOutputFormat.class); otherwise the custom subclass is never called. This is pretty unobvious at first glance; especially since most examples tell you to explicitly call job.setOutputFormat() in your setup function.   I'm not sure this call is necessary in DBOutputFormat#setOutput() at all; given that it's unnecessary if people follow the examples and that it makes subclassing DBOutputFormat trickier than it should be.,Open,Unresolved,,Unassigned,Nathan Jarus,Tue; 7 Aug 2012 01:53:48 +0000,Tue; 7 Aug 2012 01:53:48 +0000,,,0.20.205.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4523
YARN-11,Improvement,Major,,Capacity Scheduler does not support adding sub-queues to the existing queues.,"In-line to the issue; MAPREDUCE-3410; there should be a note stating that - ""Capacity Scheduler does not support adding sub-queues to the existing queue""",Open,Unresolved,,Kiran BC,Kiran BC,Wed; 8 Aug 2012 04:31:53 +0000,Wed; 3 Jul 2013 23:07:07 +0000,,,,,,YARN-952,https://issues.apache.org/jira/browse/YARN-11
MAPREDUCE-4525,Sub-task,Major,applicationmaster;mrv2,Combiner per node,This JIRA is to implement the combining per container(MAPREDUCE-3902 is related); coordinating containers by application master without breaking fault tolerance of jobs.,Open,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Wed; 8 Aug 2012 07:25:01 +0000,Tue; 11 Sep 2012 01:41:28 +0000,,,,,,MAPREDUCE-3902,https://issues.apache.org/jira/browse/MAPREDUCE-4525
MAPREDUCE-4526,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be changed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:18:11 +0000,Tue; 14 Aug 2012 17:42:27 +0000,Tue; 14 Aug 2012 17:42:27 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4526
MAPREDUCE-4527,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:18:32 +0000,Tue; 14 Aug 2012 17:42:45 +0000,Tue; 14 Aug 2012 17:42:45 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4527
MAPREDUCE-4528,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:18:34 +0000,Tue; 14 Aug 2012 17:43:01 +0000,Tue; 14 Aug 2012 17:43:01 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4528
MAPREDUCE-4529,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:18:44 +0000,Tue; 14 Aug 2012 17:43:18 +0000,Tue; 14 Aug 2012 17:43:18 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4529
MAPREDUCE-4530,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:19:54 +0000,Tue; 14 Aug 2012 17:43:31 +0000,Tue; 14 Aug 2012 17:43:31 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4530
MAPREDUCE-4531,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:22:18 +0000,Tue; 14 Aug 2012 17:43:42 +0000,Tue; 14 Aug 2012 17:43:42 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4531
MAPREDUCE-4532,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 06:22:50 +0000,Tue; 14 Aug 2012 17:43:56 +0000,Tue; 14 Aug 2012 17:43:56 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4532
MAPREDUCE-4533,Bug,Major,test,"Test failures with ""Container .. is running beyond virtual memory limits""",Tests org.apache.hadoop.tools.TestHadoopArchives. {testRelativePath;testPathWithSpaces}  fail with the following message:     This is not a stably reproducible problem; but adding MALLOC_ARENA_MAX resolves the problem.,Resolved,Duplicate,MAPREDUCE-4533,Unassigned,Ilya Katsov,Thu; 9 Aug 2012 06:33:17 +0000,Wed; 15 Aug 2012 23:24:39 +0000,Wed; 15 Aug 2012 23:24:38 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4533
MAPREDUCE-4534,Bug,Major,test,"Test failures with ""Container .. is running beyond virtual memory limits""",Tests org.apache.hadoop.tools.TestHadoopArchives. {testRelativePath;testPathWithSpaces}  fail with the following message:     This is not a stably reproducible problem; but adding MALLOC_ARENA_MAX resolves the problem.,Resolved,Duplicate,MAPREDUCE-4533,Unassigned,Ilya Katsov,Thu; 9 Aug 2012 06:33:34 +0000,Fri; 5 Apr 2013 16:13:49 +0000,Fri; 5 Apr 2013 16:13:49 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4534
MAPREDUCE-4535,Bug,Major,test,"Test failures with ""Container .. is running beyond virtual memory limits""",Tests org.apache.hadoop.tools.TestHadoopArchives. {testRelativePath;testPathWithSpaces}  fail with the following message:     This is not a stably reproducible problem; but adding MALLOC_ARENA_MAX resolves the problem.,Resolved,Not A Problem,,Ilya Katsov,Ilya Katsov,Thu; 9 Aug 2012 06:34:29 +0000,Mon; 8 Apr 2013 10:40:28 +0000,Mon; 8 Apr 2013 10:40:28 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4535
MAPREDUCE-4536,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Unassigned,Benoy Antony,Thu; 9 Aug 2012 07:43:23 +0000,Tue; 14 Aug 2012 17:45:26 +0000,Tue; 14 Aug 2012 17:45:25 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4536
MAPREDUCE-4537,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 07:43:40 +0000,Tue; 14 Aug 2012 17:45:37 +0000,Tue; 14 Aug 2012 17:45:37 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4537
MAPREDUCE-4538,Bug,Trivial,,Please delete me,I am in a bad state will someone please delete me.,Resolved,Duplicate,MAPREDUCE-4053,Robert Joseph Evans,Robert Joseph Evans,Thu; 9 Aug 2012 15:20:18 +0000,Tue; 14 Aug 2012 18:00:01 +0000,Tue; 14 Aug 2012 18:00:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4538
MAPREDUCE-4539,Bug,Trivial,,Please delete me,I am in a bad state will someone please delete me?,Resolved,Duplicate,MAPREDUCE-4053,Robert Joseph Evans,Robert Joseph Evans,Thu; 9 Aug 2012 16:00:56 +0000,Tue; 14 Aug 2012 17:59:34 +0000,Tue; 14 Aug 2012 17:59:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4539
MAPREDUCE-4540,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed as part of a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2; these credentials are transmitted only when security is turned on.  This should be changed in HADOOP 2 for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off.,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 16:38:16 +0000,Tue; 14 Aug 2012 17:46:02 +0000,Tue; 14 Aug 2012 17:46:02 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4540
MAPREDUCE-4541,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 16:43:26 +0000,Tue; 14 Aug 2012 17:46:12 +0000,Tue; 14 Aug 2012 17:46:12 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4541
MAPREDUCE-4542,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed as part of a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2; these credentials are transmitted only when security is turned on.  This should be changed in HADOOP 2 for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off.,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 16:58:08 +0000,Tue; 14 Aug 2012 17:46:22 +0000,Tue; 14 Aug 2012 17:46:22 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4542
MAPREDUCE-4543,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 20:02:51 +0000,Tue; 14 Aug 2012 17:46:32 +0000,Tue; 14 Aug 2012 17:46:32 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4543
MAPREDUCE-4544,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 20:04:49 +0000,Tue; 14 Aug 2012 17:46:52 +0000,Tue; 14 Aug 2012 17:46:52 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4544
MAPREDUCE-4545,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Fixed,,Unassigned,Benoy Antony,Thu; 9 Aug 2012 20:07:51 +0000,Tue; 14 Aug 2012 17:47:02 +0000,Tue; 14 Aug 2012 17:47:02 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4545
MAPREDUCE-4546,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.,Resolved,Duplicate,MAPREDUCE-4554,Unassigned,Benoy Antony,Thu; 9 Aug 2012 20:09:41 +0000,Tue; 14 Aug 2012 17:47:12 +0000,Tue; 14 Aug 2012 17:47:12 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4546
MAPREDUCE-4547,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.   In HADOOP 1; these credentials get submitted and routed to task processes even if security was off.  In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be fixed for two reasons:  1) It is not backward compatible. 2) Credentials should be passed even if security is turned off .,Resolved,Duplicate,MAPREDUCE-4554,Benoy Antony,Benoy Antony,Thu; 9 Aug 2012 22:32:27 +0000,Tue; 14 Aug 2012 17:47:25 +0000,Tue; 14 Aug 2012 17:47:25 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4547
HADOOP-10326,Bug,Major,security,M/R jobs can not access S3 if Kerberos is enabled,With Kerberos enabled; any job that is taking as input or output s3 files fails.  It can be easily reproduced with wordcount shipped in hadoop-examples.jar and a public S3 file:    returns:,Closed,Fixed,,bc Wong,Manuel DE FERRAN,Fri; 10 Aug 2012 13:49:57 +0000,Thu; 10 Apr 2014 13:11:59 +0000,Tue; 11 Feb 2014 02:49:34 +0000,,2.2.0,s3,,,https://issues.apache.org/jira/browse/HADOOP-10326
MAPREDUCE-4549,Bug,Blocker,mrv2,Distributed cache conflicts breaks backwards compatability,I recently put in MAPREDUCE-4503 which went a bit too far; and broke backwards compatibility with 1.0 in distribtued cache entries.  instead of changing the behavior of the distributed cache to more closely match 1.0 behavior I want to just change the exception to a warning message informing the users that it will become an error in 2.0,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 13 Aug 2012 14:28:56 +0000,Fri; 26 Apr 2013 02:14:43 +0000,Thu; 28 Mar 2013 21:34:57 +0000,,0.23.3;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4549
MAPREDUCE-4550,Sub-task,Major,security,Key Protection : Define Encryption and Key Protection interfaces and default implementations,A secret key is read from a Key Store and then encrypted during transport between JobClient and Task. The tasktrackers dummy implementations will also be added. This includes a KeyProvider implementation to read keys from a Java KeyStore.,Resolved,Won't Do,,Benoy Antony,Benoy Antony,Mon; 13 Aug 2012 16:36:21 +0000,Mon; 16 Oct 2017 19:41:56 +0000,Mon; 16 Oct 2017 19:41:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4550
MAPREDUCE-4551,Sub-task,Major,job submission;security,Key Protection :  Add ability to read keys and protect keys  in  JobClient and TTS/NodeManagers,"Based on Cluster configuration; NodeManager TaskTrackers set up Decrypters  to decrypt the job's secrets. Based on Job configuration; JobClient reads secrets from a KeyStore using a Keyprovider implementation and encrypts them using the cluster's public key.  The encrypted secrets are stored in Job Credentials.  The task addresses the following requirements:    	Plug in different key store mechanisms.  	Retrieve specified keys from a configured keystore as part of job submission  	Protect keys during its transport through the cluster.  	Make sure that keys are handed over only to the tasks of the correct job.",Resolved,Won't Do,,Benoy Antony,Benoy Antony,Mon; 13 Aug 2012 16:44:23 +0000,Mon; 16 Oct 2017 19:42:13 +0000,Mon; 16 Oct 2017 19:42:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4551
MAPREDUCE-4552,Sub-task,Major,security,Encryption:  Add support for PGP Encryption,"Provide support for PGP encryption by implementing Encrypter and Decrypter interfaces defined in MAPREDUCE-4450.  This can be used by the cluster to protect the job secrets. This also be used map reduce jobs to encrypt decrypt files in local file system  1.	Genkey - Generate an asymmetric key pair (public and private keys) of a specified strength 2.	Encrypt - Encrypt a file  3.	Decrypt   Decrypt a file  Added as a contrib project -  hadoop-crypto.",Resolved,Won't Do,,Benoy Antony,Benoy Antony,Mon; 13 Aug 2012 16:51:12 +0000,Mon; 16 Oct 2017 19:44:07 +0000,Mon; 16 Oct 2017 19:44:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4552
MAPREDUCE-4553,Sub-task,Major,job submission;security,Key Protection :  Implement KeyProvider to read key from a WebService Based KeyStore,Normally keys have to be stored in a central location using custom key management system.  organizations can implement KeyProvider to integrate their custom key management system to Hadoop. This interface is specified in MAPREDUCE-4550  Optionally ; developers can use Safe to integrate custom key management system with Hadoop.  Safe is an open source web service based keystore to securely store secret keys and passwords.  Safe authenticates the user using SPNego; checks whether the user is authorized to read the secret and returns the secret.  It is easy to plug in different mechanisms for authentication;authorization and Key storage.  Safe is kept as a separate open source project at (http: )  The hadoop proxy to safe is added as a contrib project -  hadoop-safe.,Resolved,Won't Do,,Benoy Antony,Benoy Antony,Mon; 13 Aug 2012 16:54:23 +0000,Mon; 16 Oct 2017 19:42:35 +0000,Mon; 16 Oct 2017 19:42:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4553
MAPREDUCE-4554,Bug,Major,job submission;security,Job Credentials are not transmitted if security is turned off,Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or mapreduce.job.credentials.binary .  These credentials get submitted during job submission and are made available to the task processes.  In HADOOP 1; these credentials get submitted and routed to task processes even if security was off. In HADOOP 2 ; these credentials are transmitted only when the security is turned on.  This should be changed for two reasons: 1) It is not backward compatible.  2) Credentials should be passed even if security is turned off .,Closed,Fixed,,Benoy Antony,Benoy Antony,Mon; 13 Aug 2012 17:00:36 +0000,Wed; 3 Sep 2014 23:17:18 +0000,Mon; 8 Oct 2012 21:00:05 +0000,,2.0.0-alpha,,HADOOP-8726,,https://issues.apache.org/jira/browse/MAPREDUCE-4554
MAPREDUCE-4555,Improvement,Major,client;job submission,make user's mapred .staging area permissions configurable,The directories are created in JobTracker and LocalRunner; but they are currently forced to be 0700. There is even a segment of the source code that will check the permissions are 0700; and if not it will change the permissions to match 0700. For monitoring purposes the permissions should be configurable.  Please note: 1. We can make the hard-coded 700 configurable at clients (its the client who creates it) but there's two issues here:  1.1. It violates security principals (as its client sided and overridable)  1.2. It can't be consistent; since some user may ignore configs provided to them and create it with 0700.,Resolved,Not A Problem,,Unassigned,Alexander Alten-Lorenz,Mon; 13 Aug 2012 22:03:19 +0000,Wed; 3 Oct 2012 05:09:40 +0000,Wed; 3 Oct 2012 05:09:40 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4555
MAPREDUCE-4556,Improvement,Minor,contrib/fair-share,FairScheduler: PoolSchedulable#updateDemand() has potential redundant computation,nan,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 14 Aug 2012 18:44:46 +0000,Mon; 3 Nov 2014 18:33:51 +0000,Thu; 4 Oct 2012 23:56:30 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4556
MAPREDUCE-4557,Bug,Minor,nodemanager,With default settings; log aggregation service creates aggregated log dirs with ownership not matching JH server run-as user and group,In order to read aggregated logs; JH server; running as mapred:hadoop by default; tries to access hdfs: logs rather than leave the group unchanged.  On the other hand; the user and app dirs should better be created with the group unchanged (i.e.; hadoop).,Open,Unresolved,,Unassigned,Martin Gerlach,Wed; 15 Aug 2012 15:42:32 +0000,Wed; 15 Aug 2012 15:43:11 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4557
MAPREDUCE-4558,Bug,Major,,TestJobTrackerSafeMode is failing,MAPREDUCE-1906 exposed an issue with this unit test. It has 3 TTs running; but has a check for the TT count to reach exactly 2 (which would be reached with a higher heartbeat interval).  The test ends up getting stuck; with the following message repeated multiple times.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 15 Aug 2012 18:38:30 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Thu; 16 Aug 2012 22:50:12 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4558
MAPREDUCE-4559,Bug,Major,,Job logs not accessible through job history server for AM killed due to am.liveness-monitor expiry,nan,Open,Unresolved,,Unassigned,Rahul Jain,Wed; 15 Aug 2012 22:59:51 +0000,Thu; 12 Sep 2013 04:41:38 +0000,,,2.0.0-alpha,,,MAPREDUCE-4428;MAPREDUCE-5418,https://issues.apache.org/jira/browse/MAPREDUCE-4559
MAPREDUCE-4560,Bug,Major,,Job can get stuck in a deadlock between mappers and reducers for low values of mapreduce.job.reduce.slowstart.completedmaps (<<1),This issue has been seen with MapReduceV2; never with MapReduceV1 in our lab systems.  The parameter mapreduce.job.reduce.slowstart.completedmaps=0.05 (the default value).  We found Application master stuck in a deadlock between mappers and reducers with no progress in the job; the sequence appears to be:  1. Initial available map reduce slots were allocated to mappers 2. Once mappers made progress and few of them completed; reducers started occupying few of the slots due to low values of above config param. 3. The scheduler appears to not give priority to mappers over reducers; after a while in our system we saw all slots occupied by reducers. 4. Since there were still mapper tasks not yet assigned any slot; the map phase never completed. 5. The system entered a deadlock state where reducers occupy all available slots; but are waiting for mappers to be complete; mappers cannot move forward because of no slot available.  The workaround in our system was to set  mapreduce.job.reduce.slowstart.completedmaps=1 and the issue was no longer seen.,Resolved,Duplicate,MAPREDUCE-4299,Unassigned,Rahul Jain,Wed; 15 Aug 2012 23:32:44 +0000,Tue; 3 Sep 2013 06:41:08 +0000,Tue; 3 Sep 2013 06:41:08 +0000,,,,,MAPREDUCE-4299,https://issues.apache.org/jira/browse/MAPREDUCE-4560
MAPREDUCE-4561,Bug,Major,,Support for node health scripts on Windows ,TestNodeHealthService fails because NodeHealthServiceChecker tries to run a shell script directly. That wont work on Windows. Need to launch it via cmd or winutils.,Resolved,Duplicate,MAPREDUCE-4598,Unassigned,Bikas Saha,Wed; 15 Aug 2012 23:40:52 +0000,Thu; 6 Sep 2012 01:21:42 +0000,Thu; 6 Sep 2012 01:21:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4561
MAPREDUCE-4562,Bug,Major,,"Support for ""FileSystemCounter"" legacy counter group name for compatibility reasons is creating incorrect counter name",Hi Guys; I was investigating issue in Sqoop project(http: users might also be affected and therefore it would be better to fix it in upstream.,Closed,Fixed,,Jarek Jarcec Cecho,Jarek Jarcec Cecho,Thu; 16 Aug 2012 06:46:56 +0000,Thu; 11 Oct 2012 17:48:52 +0000,Thu; 16 Aug 2012 13:35:35 +0000,,0.23.0;0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4562
MAPREDUCE-4563,Bug,Major,,TestJobTrackerSafeMode creates cyclic symlinks,When enabled; TestJobTrackerSafeMode ends up creating cyclic symlinks.  build ......,Open,Unresolved,,Mayank Bansal,Siddharth Seth,Thu; 16 Aug 2012 22:47:29 +0000,Thu; 16 Aug 2012 23:30:28 +0000,,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4563
MAPREDUCE-4564,Bug,Major,,Shell timeout mechanism does not work for processes spawned using winutils,Upon timeout; Shell calls Java process.destroy() to terminate the spawned process. This would destroy the winutils process but not the real process spawned by winutils.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Thu; 16 Aug 2012 23:22:03 +0000,Mon; 10 Sep 2012 14:33:13 +0000,Mon; 10 Sep 2012 14:33:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4564
MAPREDUCE-4565,Improvement,Major,,Backport MR-2855 to branch-1: ResourceBundle lookup during counter name resolution takes a lot of time,Loading a job status page in trunk takes a lot of time; and it seems like most of the time is spent resolving counter names. Looking through the JDK source; ResourceBundle.getBundle(String) ends up calling getClassContext() which is not very efficient. I think if we pass our own classloader manually it will be faster. In Counters.incrAllCounters; we may also be able to avoid setting the counter name if one is already set.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Sat; 18 Aug 2012 19:22:33 +0000,Mon; 3 Nov 2014 18:33:44 +0000,Tue; 21 Aug 2012 22:46:42 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4565
MAPREDUCE-4566,Bug,Major,security,security.job.task.protocol.acl should not be used,In MAPREDUCE-4329; we removed security.task.umbilical.protocol.acl from branch-1 hadoop-policy.xml because we can neither change the value from default nor remove the property from code. The property name is changed to security.job.task.protocol.acl in trunk. The new property security.job.task.protocol.acl should be removed from hadoop-policy.xml in trunk too.,Open,Unresolved,,Sho Shimauchi,Sho Shimauchi,Sun; 19 Aug 2012 08:37:28 +0000,Tue; 10 Mar 2015 04:30:18 +0000,,,,,,MAPREDUCE-4329,https://issues.apache.org/jira/browse/MAPREDUCE-4566
MAPREDUCE-4567,Bug,Major,mrv1,Fix failing TestJobKillAndFail in branch-1,This was introduced in MAPREDUCE-4488.,Reopened,Unresolved,,Tom White,Tom White,Mon; 20 Aug 2012 15:18:08 +0000,Sun; 14 Jul 2013 23:57:32 +0000,,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4567
MAPREDUCE-4568,Bug,Major,,"Throw ""early"" exception when duplicate files or archives are found in distributed cache",According to #MAPREDUCE-4549; Hadoop 2.x throws exception if duplicates found in cacheFiles or cacheArchives. The exception  throws during job submission.  This JIRA is to throw the exception ==early== when it is first added to the Distributed Cache through addCacheFile or addFileToClassPath.  It will help the client to decide whether to fail-fast or continue w o the duplicated entries.  Alternatively; Hadoop could provide a knob where user will choose whether to throw error( coming behavior) or silently ignore (old behavior).,Open,Unresolved,,Arun C Murthy,Mohammad Kamrul Islam,Mon; 20 Aug 2012 19:35:22 +0000,Mon; 15 Oct 2012 06:27:39 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4568
MAPREDUCE-4569,Bug,Major,,TestHsWebServicesJobsQuery fails on jdk7,"TestHsWebServicesJobsQuery fails on jdk7 due to the test order no longer being constant.   testJobsQueryStateNone(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery)  Time elapsed: 0.279 sec  &lt; FAILURE!  lang.AssertionError: jobs is not null expected:null but was:{""job"":[ {""startTime"":1345559717819;""finishTime"":1345560891194;""id"":""job_1345560632472_0002"";""name"":""RandomWriter"";""queue"":""mockqueue"";""user"":""mock"";""state"":""KILL_WAIT"";""mapsTotal"":0;""mapsCompleted"":0;""reducesTotal"":1;""reducesCompleted"":1} ]}          we don't expect any jobs to be in.",Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 21 Aug 2012 15:23:41 +0000,Thu; 12 May 2016 18:24:14 +0000,Thu; 30 Aug 2012 21:08:14 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-4569
MAPREDUCE-4570,Bug,Minor,mrv2,ProcfsBasedProcessTree#constructProcessInfo() prints a warning if procfsDir/<pid>/stat is not found.,I think a warning is misleading in this case. What is happening here is that the list of all processes in the system is found; and then later the procfsDir stat file for each is opened. This warning is thrown when the process finishes before the stat file is opened; and hence the file is no longer there. This could normally happen; and shouldn't signify a waring. An info message is sufficient. I'll be uploading a patch momentarily.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Tue; 21 Aug 2012 16:47:25 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Tue; 21 Aug 2012 17:50:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4570
MAPREDUCE-4571,Bug,Major,webapps,TestHsWebServicesJobs fails on jdk7,TestHsWebServicesJobs fails on jdk7.   Tests run: 22; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 7.561 sec &lt; FAILURE!testJobIdSlash(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs)  Time elapsed: 0.334 sec  &lt; FAILURE!  lang.AssertionError: mapsTotal incorrect expected:0 but was:1,Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 21 Aug 2012 22:03:37 +0000,Thu; 12 May 2016 18:23:46 +0000,Fri; 15 Mar 2013 18:54:10 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-4571
MAPREDUCE-4572,Bug,Major,tasktracker;webapps,Can not access user logs - Jetty is not configured by default to serve aliases/symlinks,The task log servlet can no longer access user logs because MAPREDUCE-2415 introduce symlinks to the logs and jetty is not configured by default to serve symlinks.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Wed; 22 Aug 2012 01:07:19 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Thu; 6 Sep 2012 19:47:39 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4572
MAPREDUCE-4573,Bug,Major,,Hadoop benckmarking for NutchIndexing,Hi; i have downloaded nutch indexing program ffom GitHub and trying to run. For that the input file is of size 16 GB which am nt able to download. Ccn anyone help me on if there is any other alternative to run this program or if anyone having scledown version of the input jar.  Is it possible to give a text file of some URL as the input for the NutchIndexing  Thanks; Prashanthi,Open,Unresolved,,Unassigned,prashanthi,Wed; 22 Aug 2012 12:42:41 +0000,Wed; 22 Aug 2012 12:42:41 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4573
MAPREDUCE-4574,Bug,Trivial,client,Fix TotalOrderParitioner to work with non-WritableComparable key types,The current TotalOrderPartitioner class will not work with an alternative serialization library such as Avro.  To make it work; we may edit the readPartitions bits in it to support non-WritableComparable keys and also remove the WritableComparable check in the class types definition.  That is; since we do not use the values at all (NullWritable); we may as well do:,Resolved,Fixed,,Harsh J,Harsh J,Wed; 22 Aug 2012 13:45:11 +0000,Thu; 12 May 2016 18:23:06 +0000,Tue; 9 Oct 2012 09:59:03 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4574
MAPREDUCE-4575,Improvement,Major,,Add an option to drain the JobTracker jobs for upgrades,Following on from MAPREDUCE-4328 it will be useful to allow an option to drain the JobTracker so that it will finish up existing jobs and not accept new ones.  This is particularly useful during upgrades.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Wed; 22 Aug 2012 19:51:11 +0000,Thu; 2 May 2013 02:30:53 +0000,,,,,,YARN-38,https://issues.apache.org/jira/browse/MAPREDUCE-4575
MAPREDUCE-4576,Bug,Major,,Large dist cache can block tasktracker heartbeat,nan,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Wed; 22 Aug 2012 21:24:37 +0000,Wed; 15 May 2013 05:16:07 +0000,Tue; 11 Sep 2012 14:35:08 +0000,,0.20.205.0;1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4576
MAPREDUCE-4577,Bug,Minor,test,HDFS-3672 broke TestCombineFileInputFormat.testMissingBlocks() test,Before HDFS-3672; locally applying MAPREDUCE-4470 made TestCombineFileInputFormat to pass all it tests.  After HDFS-3672; TestCombineFileInputFormat.testMissingBlocks() fails:,Closed,Fixed,,Aaron T. Myers,Alejandro Abdelnur,Wed; 22 Aug 2012 20:49:10 +0000,Thu; 11 Oct 2012 17:48:47 +0000,Wed; 22 Aug 2012 22:46:19 +0000,,2.0.2-alpha,,MAPREDUCE-4470,HDFS-3672,https://issues.apache.org/jira/browse/MAPREDUCE-4577
YARN-56,Improvement,Major,resourcemanager,Handle container requests that request more resources than currently available in the cluster,In heterogenous clusters; a simple check at the scheduler to check if the allocation request is within the max allocatable range is not enough.   If there are large nodes in the cluster which are not available; there may be situations where some allocation requests will never be fulfilled. Need an approach to decide when to invalidate such requests. For application submissions; there will need to be a feedback loop for applications that could not be launched. For running AMs; AllocationResponse may need to augmented with information for invalidated cancelled container requests.,Open,Unresolved,MAPREDUCE-3946;YARN-2555;YARN-2604,Unassigned,Hitesh Shah,Wed; 22 Aug 2012 23:35:24 +0000,Tue; 25 Jul 2017 15:27:04 +0000,,,2.0.2-alpha;0.23.3,,,YARN-394;YARN-389;YARN-6867,https://issues.apache.org/jira/browse/YARN-56
MAPREDUCE-4579,Bug,Major,,TestTaskAttempt fails jdk7,------------------------------------------------------------------------------- Test set: org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt ------------------------------------------------------------------------------- Tests run: 10; Failures: ,Closed,Fixed,,Thomas Graves,Thomas Graves,Thu; 23 Aug 2012 17:44:02 +0000,Thu; 12 May 2016 18:22:24 +0000,Tue; 28 Aug 2012 02:22:44 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-4579
MAPREDUCE-4580,Bug,Major,,Change MapReduce to use the yarn-client module,Mapreduce needs to be changed to use the yarn-client module added via YARN-29.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Thu; 23 Aug 2012 19:38:25 +0000,Thu; 11 Oct 2012 17:48:48 +0000,Tue; 28 Aug 2012 00:42:06 +0000,,,,YARN-29,,https://issues.apache.org/jira/browse/MAPREDUCE-4580
MAPREDUCE-4581,Sub-task,Minor,applicationmaster,[MAPREDUCE-3902] TaskHeartbeatHandler should extends HeartbeatHandlerBase,TaskHeartbeatHandler extends AbstractService currently; however; this causes code duplication between TaskHeartbeatHandler and HeartbeatHandlerBase. TaskHeartbeatHandler should extends HeartbeatHandlerBase to solve the problem.,Resolved,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Fri; 24 Aug 2012 03:58:19 +0000,Sat; 25 Aug 2012 20:27:54 +0000,Fri; 24 Aug 2012 18:57:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4581
MAPREDUCE-4582,Sub-task,Minor,,[MAPREDUCE-3902] ScheduledRequests#remove should remove the elements from mapsHostMapping and mapsRackMapping,"ScheduledRequests#remove only remove the specified TaskAttemptId from ""maps"".  It's inefficient; and the method should remove the elements from mapsHostMapping and mapsRackMapping.",Open,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Fri; 24 Aug 2012 15:08:44 +0000,Tue; 4 Sep 2012 18:17:29 +0000,,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4582
MAPREDUCE-4583,Bug,Major,documentation,Wrong paths for CapacityScheduler/FairScheduler jar in documentation,Both documentations http: *scheduler directory.  But that's not the case ; both jars are actually in the lib folder,Resolved,Fixed,,Unassigned,Bertrand Dechoux,Fri; 24 Aug 2012 16:08:51 +0000,Thu; 11 Feb 2016 22:51:54 +0000,Mon; 28 Sep 2015 00:04:24 +0000,,1.0.3,documentation,,,https://issues.apache.org/jira/browse/MAPREDUCE-4583
MAPREDUCE-4584,New Feature,Major,applicationmaster;mrv2;performance;resourcemanager;task,Umbrella: Preemption and restart of MapReduce tasks,This JIRA will track the implementation of improvements to the handling of intermediate data (e.g.; map output). Specifically; it tracks changes in support of preempting running tasks; checkpointing completed work; and spawning one or more tasks to complete the original split sailfish,Open,Unresolved,,Chris Douglas,Sriram Rao,Sat; 25 Aug 2012 00:14:56 +0000,Wed; 5 Jun 2013 04:35:13 +0000,,,,,,YARN-291,https://issues.apache.org/jira/browse/MAPREDUCE-4584
MAPREDUCE-4585,New Feature,Major,task,Checkpoint shuffle aggregation as map output,Map output collected during the shuffle can be spilled and written as a composite of map outputs. Particularly if the job employs a combiner; this checkpoint can provide fault tolerance and improve job throughput by aggregating intermediate output. The latter is especially helpful for jobs with multiple waves of reduces.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:17:11 +0000,Mon; 27 Aug 2012 19:19:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4585
MAPREDUCE-4586,New Feature,Major,task,Reduce large output segments directly from remote host,For some jobs; copying large output segments to the local host is inefficient. The reduce can construct iterators on remote hosts; provided the stream is restartable. This should reduce task latency by amortizing the cost of the data transfer over the entire reduce; rather than paying it upfront.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:17:18 +0000,Tue; 11 Dec 2012 18:54:41 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4586
MAPREDUCE-4587,Improvement,Major,nodemanager;task,Support fetch by key boundaries for memcmp types,Intermediate data addressable by key support not only restartable streams; but partitioning after the map output are written. With sampling of map output; a job can implement a total-order and tune the number of reduces around skew. It is possible to implement something similar for non-memcmp types; but it is significantly more complex.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:17:24 +0000,Sat; 25 Aug 2012 00:20:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4587
MAPREDUCE-4588,Improvement,Major,task,Map local segments as on-disk segments,Local map segments should never be handled as though they were remote (i.e.; copied through a servlet to local disk). This optimization is uniformally more efficient for the fetch; though it increases the number of on-disk segments. Each segment has its own overhead; which can exceed the cost of pulling it into memory (e.g.; the decompressor overhead for an active segment exceeds the cost of decompression into memory). Some logic is required to handle a large number of such segments.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:17:30 +0000,Sat; 25 Aug 2012 00:20:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4588
MAPREDUCE-4589,Improvement,Major,task,MapTask preemption,For many input types; it is possible to restore the state of a RecordReader by writing a new split for the remaining data (e.g.; storing the inflater state with a file offset for gzip text). Similarly; an InputFormat may be capable of further subdividing an InputSplit into smaller tasks to be completed in parallel.  Since some splits are semantically significant; whether a MapTask can be preempted in this way is not necessarily a property of the InputFormat; only. Minimally; we should allow the user to disable this capability.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:17:46 +0000,Sat; 25 Aug 2012 00:20:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4589
MAPREDUCE-4590,Improvement,Major,task,ReduceTask preemption,With a facility for addressing subsequences of the reduce input keygroups (such as MAPREDUCE-4587); a ReduceTask can efficiently checkpoint and restart itself. In some cases; a memento (i.e.; a key in the stream) may be a sufficient checkpoint of the ReduceTask state.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:18:25 +0000,Sat; 25 Aug 2012 00:21:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4590
MAPREDUCE-4591,Improvement,Major,nodemanager;task,Extend IFile format to include optional metadata,By including sections for per-segment and per-spill metadata; one can embed information useful to consumers (e.g.; information on key ranges; sampling; etc.). These changes make IFiles ideal candidates for implementing checkpointing for tasks (MAPREDUCE-4589; MAPREDUCE-4590).,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:18:37 +0000,Sat; 25 Aug 2012 00:21:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4591
MAPREDUCE-4592,Improvement,Major,task,Collect statistics on key distributions/samples in intermediate data,Some jobs would benefit from statistics about the key distribution of intermediate data; including sampling for jobs implementing a total-order in the job. These data can inform a policy for handling skew.,Open,Unresolved,,Unassigned,Chris Douglas,Sat; 25 Aug 2012 00:18:50 +0000,Sat; 25 Aug 2012 00:21:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4592
MAPREDUCE-4593,Bug,Minor,client,CombineFileInputFormat must ensure it doesn't dupe locations in its InputSplit objects,Currently it seems possible for CombineFileInputFormat's InputSplit objects to grow to very large sizes due to its non-de-duplication of the locations field. We should probably use a set structure to prevent dupe locations from rising the block locations size of InputSplits sent over by CombineFileInputFormat; as that will help performance and help fix unnecessary warnings MR AM.,Resolved,Duplicate,MAPREDUCE-2021,Unassigned,Harsh J,Sat; 25 Aug 2012 10:52:18 +0000,Sun; 26 Aug 2012 14:39:28 +0000,Sun; 26 Aug 2012 14:39:28 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4593
MAPREDUCE-4594,Improvement,Major,client,Add init/shutdown methods to mapreduce Partitioner,The Partitioner supports only the Configurable API; which can be used for basic init in setConf(). Problem is that there is no shutdown function.  I propose to use standard setup() cleanup() functions like in mapper   reducer.  Use case is that I need to start and stop spring context and datagrid client.,Patch Available,Unresolved,,Radim Kolar,Radim Kolar,Sat; 25 Aug 2012 21:40:07 +0000,Wed; 6 May 2015 03:27:32 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4594
MAPREDUCE-4595,Bug,Critical,,TestLostTracker failing - possibly due to a race in JobHistory.JobHistoryFilesManager#run(),The source for occasional failure of TestLostTracker seems like the following:  On job completion; JobHistoryFilesManager#run() spawns another thread to move history files to done folder. TestLostTracker waits for job completion; before checking the file format of the history file. However; the history files move might be in the process or might not have started in the first place.  The attachment (force-TestLostTracker-failure.patch) helps reproducing the error locally; by increasing the chance of hitting this race.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Sat; 25 Aug 2012 22:16:06 +0000,Mon; 3 Nov 2014 18:33:35 +0000,Mon; 27 Aug 2012 22:39:18 +0000,,1.0.3,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-4595
MAPREDUCE-4596,Task,Major,applicationmaster;mrv2,Split StateMachine state from states seen by MRClientProtocol (for Job; Task; TaskAttempt),State machine states are currently exposed via MRClienProtocol. This makes it tough to modify the AM state machines; or have an alternate AM with different state machines (MR-3902) without the changes being visible in MRClientProtocol (MRv2 equivalent of ClientProtocol).,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Mon; 27 Aug 2012 21:42:15 +0000,Wed; 6 Feb 2013 17:05:35 +0000,Fri; 19 Oct 2012 06:02:53 +0000,,0.23.0,,,MAPREDUCE-3902,https://issues.apache.org/jira/browse/MAPREDUCE-4596
MAPREDUCE-4597,Bug,Major,,TestKillSubProcesses intermittently fails,The test starts a mapper that spawns subprocesses. The test then checks if sufficient number of subprocesses have been spawned. The check can happen before all the processes have been spawned and can sometimes fail.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Mon; 27 Aug 2012 21:44:35 +0000,Thu; 30 Aug 2012 02:26:10 +0000,Thu; 30 Aug 2012 02:26:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4597
MAPREDUCE-4598,Bug,Major,,Support for node health scripts on Windows,Currently; it is not possible to have node health scripts on Windows; as NodeHealthCheckerService tries to directly launch (CreateProcess()) .sh scripts. TestNodeHealthService test fails because of this issue also leading to a subsequent TestNodeRefresh test failure.,Resolved,Fixed,,Bikas Saha,Bikas Saha,Mon; 27 Aug 2012 21:51:57 +0000,Thu; 30 Aug 2012 02:23:59 +0000,Thu; 30 Aug 2012 02:23:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4598
MAPREDUCE-4599,Sub-task,Major,applicationmaster,[MAPREDUCE-3902] Ensure not to launch container on blacklisted hosts,The current implementation of RMContainerAllocator doesn't ensure not to launch containers on blacklisted nodes. This may cause some skews by tasks on bad nodes.,Resolved,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Tue; 28 Aug 2012 07:29:11 +0000,Wed; 29 Aug 2012 18:32:53 +0000,Wed; 29 Aug 2012 18:32:53 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4599
MAPREDUCE-4600,Bug,Critical,,TestTokenCache.java from MRV1 no longer compiles,nan,Closed,Fixed,,Daryn Sharp,Robert Joseph Evans,Tue; 28 Aug 2012 16:36:59 +0000,Thu; 12 May 2016 18:24:12 +0000,Tue; 28 Aug 2012 18:58:05 +0000,,0.23.3;2.0.0-alpha;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4600
MAPREDUCE-4601,Bug,Major,,Windows CMD processor doesn't use double quotes,"Currently; the task launch script under windows matches Linux and double quotes all of the values. Unfortunately; the Windows' CMD processor doesn't need and doesn't ignore the double quotes. The main symptom of this is that the CLASSPATH loses the first and last entries.     results in having '""c: bar' is valid.",Open,Unresolved,,Owen O'Malley,Owen O'Malley,Tue; 28 Aug 2012 20:58:16 +0000,Tue; 28 Aug 2012 22:07:58 +0000,,,1-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4601
MAPREDUCE-4602,Sub-task,Minor,applicationmaster,[MAPREDUCE-3902] Re-create ask list correctly in case of a temporary error in the AM-RM allocate call,This isn't applicable to trunk - since modification of the table happens in one of two RMCommunicator specific threads; which allows for the methods to be synchronized.,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 29 Aug 2012 01:43:00 +0000,Wed; 29 Aug 2012 01:53:41 +0000,Wed; 29 Aug 2012 01:47:40 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4602
MAPREDUCE-4603,Improvement,Major,,Allow JobClient to retry job-submission when JT is in safemode,Similar to HDFS-3504; it would be useful to allow JobClient to retry job-submission when JT is in safemode (via MAPREDUCE-4328).  This way applications like Pig JT are not operational.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 29 Aug 2012 16:30:13 +0000,Wed; 17 Oct 2012 18:27:25 +0000,Tue; 25 Sep 2012 18:27:10 +0000,,,,HADOOP-8748;HDFS-3871,,https://issues.apache.org/jira/browse/MAPREDUCE-4603
MAPREDUCE-4604,Bug,Critical,mrv2,In mapred-default; mapreduce.map.maxattempts & mapreduce.reduce.maxattempts defaults are set to 4 as well as mapreduce.job.maxtaskfailures.per.tracker. ,This causes the AM to fail the job at the same time as it blacklists a node; thus never actually trying another node.  Marking as critical because we need this in 0.23.3 before it releases.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 29 Aug 2012 16:49:34 +0000,Tue; 10 Mar 2015 04:30:46 +0000,Fri; 31 Aug 2012 21:29:06 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4604
YARN-59,Bug,Major,,Text File Busy errors launching MR tasks,"Some very small percentage of tasks fail with a ""Text file busy"" error.  The following was the original diagnosis:  Our use of PrintWriter in TaskController.writeCommand is unsafe; since that class swallows all IO exceptions. We're not currently checking for errors; which I'm seeing result in occasional task failures with the message ""Text file busy"" - assumedly because the close() call is failing silently for some reason. .. but turned out to be another issue as well (see below)",Resolved,Duplicate,YARN-1271,Andy Isaacson,Todd Lipcon,Wed; 29 Aug 2012 16:57:42 +0000,Sun; 3 May 2015 01:08:14 +0000,Sun; 3 May 2015 01:08:14 +0000,,2.0.2-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/YARN-59
MAPREDUCE-4606,Bug,Major,,TestMRJobs and TestUberAM fail if /mapred/history are not present,This might be related to the test framework rather than those tests themselves. To make them pass; I had to create  history.,Open,Unresolved,,Unassigned,Ravi Prakash,Wed; 29 Aug 2012 19:40:13 +0000,Wed; 29 Aug 2012 19:40:13 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4606
MAPREDUCE-4607,Bug,Major,,Race condition in ReduceTask completion can result in Task being incorrectly failed,Problem reported by chackaravarthy in MAPREDUCE-4252  This problem has been handled when speculative task launched for map task and other tempt to override a previous             succeeded state           return TaskState.SUCCEEDED;         }       } please check whether this is a valid case and give your suggestion.,Closed,Fixed,,Bikas Saha,Bikas Saha,Wed; 29 Aug 2012 20:27:40 +0000,Fri; 15 Feb 2013 13:09:57 +0000,Tue; 11 Sep 2012 14:15:01 +0000,,2.0.0-alpha,,,MAPREDUCE-4252,https://issues.apache.org/jira/browse/MAPREDUCE-4607
MAPREDUCE-4608,Bug,Major,build,hadoop-mapreduce-client is missing some dependencies,commons-logging guava should be defined with provided scope as they are used directly by mapreduce.  While Maven gets them transitively from hadoop-common (also provided); not being there makes IntelliJ to break (it seems intellij does not do a transitive closure with provided dependencies),Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 30 Aug 2012 06:53:51 +0000,Thu; 11 Oct 2012 17:48:51 +0000,Thu; 30 Aug 2012 10:04:15 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4608
MAPREDUCE-4609,Sub-task,Minor,applicationmaster,[MAPREDUCE-3902] RMContainerAllocator#scheduleInterval should be configurable,Currently; RMContainerAllocator#scheduleInterval is fixed. It should be configurable.,Resolved,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Thu; 30 Aug 2012 10:39:01 +0000,Fri; 31 Aug 2012 20:20:41 +0000,Fri; 31 Aug 2012 20:20:41 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4609
MAPREDUCE-4610,Bug,Major,mrv2,Support deprecated mapreduce.job.counters.limit property in MR2,The property mapreduce.job.counters.limit was introduced in MAPREDUCE-1943; but the mechanism was changed in MAPREDUCE-901 where the property name was changed to mapreduce.job.counters.max without supporting the old name. We should deprecate but honour the old name to make it easier for folks to move from Hadoop 1 to Hadoop 2.,Closed,Fixed,,Tom White,Tom White,Thu; 30 Aug 2012 12:28:28 +0000,Thu; 11 Oct 2012 17:48:44 +0000,Thu; 30 Aug 2012 17:16:37 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4610
MAPREDUCE-4611,Bug,Critical,,MR AM dies badly when Node is decomissioned,The MR AM always thinks th the .staging directory will be leaked and the job will not show up in the history server on an kill from the RM in some cases.  At least until the full set of AM cleanup issues can be addressed; probably as part of MAPREDUCE-4428,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Thu; 30 Aug 2012 14:39:03 +0000,Thu; 12 May 2016 18:22:51 +0000,Fri; 31 Aug 2012 20:49:06 +0000,,0.23.3;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4611
MAPREDUCE-4612,Bug,Critical,,job summary file permissions not set when its created,The job summary file permissions are not set when its written out by to the done intermediate directory. The conf and jhist files are both set properly but the summary file doesn't follow the same path.    This can cause the summary file to not be copied to the done directory if the default umask is set to be restrictive (like 600) and the mapred user can't read it.,Closed,Fixed,,Thomas Graves,Thomas Graves,Thu; 30 Aug 2012 21:22:52 +0000,Thu; 12 May 2016 18:22:36 +0000,Fri; 31 Aug 2012 20:29:25 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,MAPREDUCE-4636,https://issues.apache.org/jira/browse/MAPREDUCE-4612
MAPREDUCE-4613,Bug,Major,scheduler,Scheduling of reduce tasks results in starvation,"If a job has more reduce tasks than there are containers available; then the reduce tasks can occupy all containers causing starvation. The attached graph illustrates the behaviour. Scheduler used is fifo.  I understand that the correct behaviour when all containers are taken by reducers while mappers are still pending; is for the running reducers to be ""pre-empted"". However; pre-emption does not occur.  A work-around is to set the number of reducers  available containers.",Resolved,Duplicate,MAPREDUCE-4299,Unassigned,Vasco,Thu; 30 Aug 2012 21:29:19 +0000,Fri; 31 Aug 2012 16:15:15 +0000,Fri; 31 Aug 2012 15:58:05 +0000,,0.23.1;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4613
MAPREDUCE-4614,Improvement,Major,client;task,Simplify debugging a job's tokens,It's exceedingly difficult to debug token issues with a job.  Sometimes tokens appear to be missing; or have the wrong service; etc.  It would be much easier if job submission logged the tokens submitted; and if tasks logged the tokens they received.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Thu; 30 Aug 2012 23:12:41 +0000,Thu; 12 May 2016 18:22:44 +0000,Fri; 31 Aug 2012 20:42:23 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,HDFS-3873,https://issues.apache.org/jira/browse/MAPREDUCE-4614
MAPREDUCE-4615,Sub-task,Minor,applicationmaster,[MAPREDUCE-3902] RMContainerAllocator#assign should be split into functions,Currently; the RMContainerAllocator#assign functions does a lot of works inside the one function. This is a bit confusing and make the changes difficult; so this ticket is for refactoring the function and split it into some functions.,Open,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Fri; 31 Aug 2012 08:42:23 +0000,Fri; 31 Aug 2012 22:02:42 +0000,,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4615
MAPREDUCE-4616,Improvement,Minor,documentation,Improvement to MultipleOutputs javadocs,In the new API; and using MultipleOutputs it is possible to segment output into directories by using MultipleOutputs.write(KEYOUT key; VALUEOUT value; String baseOutputPath) in the Reducer to determine the output directory; and by using LazyOutputFormat at the job-level config to suppress normal output eg use LazyOutputFormat.setOutputFormatClass(job; TextOutputFormat.class); instead of job.setOutputFormatClass(TextOutputFormat.class);  This recreates the functionality previously provided in the old API by using MultipleTextOutputFormat (etc),Closed,Fixed,,Tony Burton,Tony Burton,Fri; 31 Aug 2012 10:15:29 +0000,Fri; 15 Feb 2013 13:09:52 +0000,Thu; 11 Oct 2012 17:24:06 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4616
MAPREDUCE-4617,Sub-task,Major,,[MAPREDUCE-3902] Re-wire AM Recovery,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 20:49:55 +0000,Fri; 14 Sep 2012 00:41:49 +0000,Fri; 14 Sep 2012 00:41:49 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4617
MAPREDUCE-4618,Sub-task,Major,,[MAPREDUCE-3902] Re-wire LocalContainerAllocator / UberAM,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 20:50:51 +0000,Fri; 21 Sep 2012 18:13:02 +0000,Fri; 21 Sep 2012 18:13:02 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4618
MAPREDUCE-4619,Sub-task,Major,,[MAPREDUCE-3902] Change AMContainerMap to extend AbstractService,nan,Resolved,Fixed,,Tsuyoshi Ozawa,Siddharth Seth,Fri; 31 Aug 2012 20:51:40 +0000,Tue; 4 Sep 2012 18:24:07 +0000,Tue; 4 Sep 2012 18:24:07 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4619
MAPREDUCE-4620,Sub-task,Major,,[MAPREDUCE-3902] RMContainerAllocator should factor in nodes being blacklisted,Needs to modify the request table to remove these nodes.,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 20:53:09 +0000,Thu; 6 Sep 2012 06:40:22 +0000,Thu; 6 Sep 2012 06:40:22 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4620
MAPREDUCE-4621,Sub-task,Major,,[MAPREDUCE-3902] Disable AM blacklisting if #blacklistedNodes crosses the configured threshold,nan,Resolved,Duplicate,MAPREDUCE-4626,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 20:54:10 +0000,Fri; 14 Sep 2012 00:44:39 +0000,Fri; 14 Sep 2012 00:44:39 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4621
MAPREDUCE-4622,Sub-task,Major,,[MAPREDUCE-3902] Unit tests for AMContainer,nan,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 31 Aug 2012 20:55:09 +0000,Fri; 31 Aug 2012 20:55:09 +0000,,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4622
MAPREDUCE-4623,Sub-task,Major,,[MAPREDUCE-3902] Unit tests for AMNode,nan,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 31 Aug 2012 20:55:43 +0000,Fri; 31 Aug 2012 20:55:43 +0000,,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4623
MAPREDUCE-4624,Sub-task,Major,,[MAPREDUCE-3902] Reduce scheduling fixes; factor in MR-4437,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 20:58:27 +0000,Fri; 31 Aug 2012 22:44:28 +0000,Fri; 31 Aug 2012 22:44:28 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4624
MAPREDUCE-4625,Sub-task,Minor,,[MAPREDUCE-3902] Statistics logging in the AM scheduler,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 20:59:26 +0000,Fri; 31 Aug 2012 22:39:44 +0000,Fri; 31 Aug 2012 22:39:44 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4625
MAPREDUCE-4626,Sub-task,Major,,[MAPREDUCE-3902] Fix and re-enable RMContaienrAllocator unit tests,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 21:01:04 +0000,Fri; 14 Sep 2012 00:39:08 +0000,Fri; 14 Sep 2012 00:39:08 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4626
MAPREDUCE-4627,Sub-task,Major,,[MAPREDUCE-3902] Handle the JobFinishedEvent correctly,A job can succeed before a TaskAttempt's internal state changes to a final state; or before a container transitions to it's final state. The AM should wait for TAs and Containers to transition - so that cleanup happens correctly. A partial implementation of this handler is already in place. Needs to be finished.,Open,Unresolved,,Siddharth Seth,Siddharth Seth,Fri; 31 Aug 2012 21:13:38 +0000,Fri; 31 Aug 2012 21:13:38 +0000,,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4627
YARN-84,Improvement,Minor,,Use Builder to get RPC server in YARN,In HADOOP-8736; a Builder is introduced to replace all the getServer() variants. This JIRA is the change in YARN.,Closed,Fixed,,Brandon Li,Brandon Li,Fri; 31 Aug 2012 22:50:10 +0000,Tue; 27 Aug 2013 22:15:19 +0000,Thu; 20 Sep 2012 04:12:30 +0000,,,,,HADOOP-8736,https://issues.apache.org/jira/browse/YARN-84
MAPREDUCE-4629,Bug,Major,,Remove JobHistory.DEBUG_MODE,Remove JobHistory.DEBUG_MODE for the following reasons:  1. No one seems to be using it - the config parameter corresponding to enabling it does not even exist in mapred-default.xml 2. The logging being done in DEBUG_MODE needs to move to LOG.debug() and LOG.trace() 3. Buggy handling of helper methods in DEBUG_MODE; e.g. directoryTime() and timestampDirectoryComponent().,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Sat; 1 Sep 2012 02:35:33 +0000,Mon; 3 Nov 2014 18:34:05 +0000,Fri; 7 Sep 2012 16:48:50 +0000,,1.0.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4629
MAPREDUCE-4630,Improvement,Minor,,API for setting dfs.block.size,Add API for setting block size in Tool while creating MR job.  I propose  FileOutputFormat.setBlockSize(Job job; int blocksize);  which sets dfs.block.size,Resolved,Not A Problem,,Unassigned,Radim Kolar,Mon; 3 Sep 2012 09:16:54 +0000,Thu; 22 Nov 2012 16:22:15 +0000,Thu; 22 Nov 2012 16:22:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4630
MAPREDUCE-4631,Bug,Major,contrib/streaming,Duplicate Mapper input when using StreamXmlRecordReader,This is the same defect as https: MAPREDUCE-577; which was fixed in v0.22.0.  So I'm wondering whether there is a plan to fix it in v1.0.3 as well? Or shall I move to v2.0.x?,Open,Unresolved,,Unassigned,Ming Jin,Tue; 4 Sep 2012 09:00:34 +0000,Tue; 4 Sep 2012 09:01:27 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4631
MAPREDUCE-4632,Improvement,Major,build,Make sure MapReduce declares correct set of dependencies,This is the equivalent of HADOOP-8278 for MapReduce.,Open,Unresolved,,Unassigned,Tom White,Tue; 4 Sep 2012 15:15:20 +0000,Tue; 4 Sep 2012 15:16:41 +0000,,,2.0.0-alpha,,,HADOOP-8278,https://issues.apache.org/jira/browse/MAPREDUCE-4632
MAPREDUCE-4633,Bug,Critical,jobhistoryserver,history server doesn't set permissions on all subdirs ,"The job history server creates a bunch of subdirectories under the ""done"" directory.  They are like 2012 03 aren't explicitly set so if the umask is more restrictive; they won't be set as it expects.",Closed,Fixed,,oss.wakayama,Thomas Graves,Tue; 4 Sep 2012 21:33:17 +0000,Thu; 12 May 2016 18:22:18 +0000,Thu; 6 Sep 2012 14:24:48 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,HDFS-3890,MAPREDUCE-4636,https://issues.apache.org/jira/browse/MAPREDUCE-4633
MAPREDUCE-4634,Bug,Minor,,Change TestUmbilicalProtocolWithJobToken to use RPC builder,In HADOOP-8736; a Builder is introduced to replace all the getServer() variants. This JIRA is the change in MapReduce.,Resolved,Duplicate,YARN-84,Brandon Li,Vinod Kumar Vavilapalli,Tue; 4 Sep 2012 23:07:00 +0000,Wed; 5 Sep 2012 00:19:36 +0000,Wed; 5 Sep 2012 00:19:36 +0000,,,,,HADOOP-8736,https://issues.apache.org/jira/browse/MAPREDUCE-4634
MAPREDUCE-4635,Bug,Major,,MR side of YARN-83. Changing package of YarnClient,nan,Closed,Fixed,,Bikas Saha,Bikas Saha,Wed; 5 Sep 2012 01:43:45 +0000,Thu; 2 May 2013 02:29:55 +0000,Wed; 5 Sep 2012 20:19:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4635
MAPREDUCE-4636,Bug,Major,jobhistoryserver,job history server needs more unit tests,The job history server doesn't have very many unit tests.    For instance we should have unit tests to validate permissions; job history events; etc..,Open,Unresolved,,Unassigned,Thomas Graves,Wed; 5 Sep 2012 14:16:49 +0000,Thu; 12 May 2016 18:24:44 +0000,,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,MAPREDUCE-4612;MAPREDUCE-4633,https://issues.apache.org/jira/browse/MAPREDUCE-4636
MAPREDUCE-4637,Bug,Major,mrv2,Killing an unassigned task attempt causes the job to fail,Attempting to kill a task attempt that has been scheduled but is not running causes an invalid state transition and the AM to stop with an error.,Closed,Fixed,,Mayank Bansal,Tom White,Wed; 5 Sep 2012 15:56:18 +0000,Fri; 15 Feb 2013 13:10:01 +0000,Tue; 23 Oct 2012 21:04:05 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4637
MAPREDUCE-4638,Improvement,Major,,MR AppMaster shouldn't rely on YARN_APPLICATION_CLASSPATH providing MR jars,Currently YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH provides $YARN_HOME *. It should not depend on this post YARN-86.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 5 Sep 2012 21:56:08 +0000,Wed; 17 Apr 2013 23:01:41 +0000,Fri; 7 Sep 2012 04:59:58 +0000,,,,YARN-15,,https://issues.apache.org/jira/browse/MAPREDUCE-4638
MAPREDUCE-4639,Bug,Minor,client,CombineFileInputFormat#getSplits should throw IOException when input paths contain a directory,FileInputFormat#getSplits throws an IOException when the input paths contain a directory. CombineFileInputFormat should do the same; otherwise the jo will not fail until the record reader is initialized when FileSystem#open will say that the directory does not exist.,Patch Available,Unresolved,,Unassigned,Jim Donofrio,Thu; 6 Sep 2012 06:52:27 +0000,Wed; 6 May 2015 03:31:13 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4639
MAPREDUCE-4640,Bug,Major,jobhistoryserver,jobHistoryEventHandler doesn't fix done_intermediate parent directory permissions,The JobHistoryEventHandler will create the done intermediate directory and its parents if it doesn't exist; but it doesn't properly set the parent directory permissions when the default umask is restrictive - 077.  Normally if you start the history server; it properly creates the directories with the right permissions  but if you don't start it before you run a job the parent directories get wrong permissions..,Open,Unresolved,,Unassigned,Thomas Graves,Thu; 6 Sep 2012 16:58:59 +0000,Sat; 7 Jan 2017 01:59:52 +0000,,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4640
MAPREDUCE-4641,Bug,Major,mrv2,Exception in commitJob marks job as successful in job history,If the job committer throws an IOException from commitJob then the job will be marked as FINISHED FAILED on the RM apps page; but the history server will show the job as SUCCEEDED.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 6 Sep 2012 20:11:51 +0000,Thu; 11 Oct 2012 17:48:42 +0000,Thu; 6 Sep 2012 22:24:34 +0000,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4641
MAPREDUCE-4642,Bug,Major,test,MiniMRClientClusterFactory should not use job.setJar(),Currently; MiniMRClientClusterFactory does job.setJar(callerJar) so that the callerJar is added to the cache in MR2.  However; this makes the resulting configuration inconsistent between MR1 and MR2 as in MR1 the job jar is not set and in MR2 its set to the callerJar.  This difference can also cause some tests to fail in Oozie.  We should instead use the job.addCacheFile() method.,Closed,Fixed,,Robert Kanter,Robert Kanter,Thu; 6 Sep 2012 22:00:11 +0000,Thu; 11 Oct 2012 17:48:43 +0000,Fri; 7 Sep 2012 17:07:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4642
MAPREDUCE-4643,Bug,Major,jobhistoryserver,Make job-history cleanup-period configurable,Job history cleanup should be made configurable. Currently; it is set to 1 month by default. The DEBUG_MODE (to be removed; see MAPREDUCE-4629) sets it to 20 minutes; but it should be configurable.,Closed,Fixed,MAPREDUCE-4676;MAPREDUCE-4973,Sandy Ryza,Karthik Kambatla,Thu; 6 Sep 2012 23:41:12 +0000,Mon; 3 Nov 2014 18:33:58 +0000,Thu; 14 Feb 2013 21:55:49 +0000,,1.0.3,,MAPREDUCE-4676,,https://issues.apache.org/jira/browse/MAPREDUCE-4643
MAPREDUCE-4644,Bug,Blocker,build;test,mapreduce-client-jobclient-tests do not run from dist tarball,The mapreduce jobclient tests rely on junit which is missing from the dist tarball.  This prevents running often-used tests like sleep jobs.,Resolved,Not A Problem,MAPREDUCE-4656,Unassigned,Jason Lowe,Fri; 7 Sep 2012 15:24:18 +0000,Mon; 1 Oct 2012 22:45:59 +0000,Mon; 1 Oct 2012 22:45:59 +0000,,2.0.2-alpha,,,MAPREDUCE-4658,https://issues.apache.org/jira/browse/MAPREDUCE-4644
MAPREDUCE-4645,Improvement,Major,performance;test,Providing a random seed to Slive should make the sequence of filenames completely deterministic,Using the -random seed option still doesn't produce a deterministic sequence of filenames. Hence there's no way to replicate the performance test. If I'm providing a seed; its obvious that I want the test to be reproducible.,Resolved,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 7 Sep 2012 19:28:45 +0000,Tue; 25 Sep 2012 15:08:30 +0000,Mon; 24 Sep 2012 21:30:09 +0000,,0.23.1;2.0.0-alpha,performance;test,,,https://issues.apache.org/jira/browse/MAPREDUCE-4645
MAPREDUCE-4646,Bug,Major,mrv2,client does not receive job diagnostics for failed jobs,When a job fails the client is not showing any diagnostics.  For example; running a fail job results in this not-so-helpful message from the client:     ...and nothing else to go with it indicating what went wrong.  The job diagnostics are apparently not making it back to the client.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 7 Sep 2012 21:29:50 +0000,Thu; 11 Oct 2012 17:48:52 +0000,Wed; 12 Sep 2012 01:01:17 +0000,,0.23.0;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4646
MAPREDUCE-4647,Bug,Major,mrv2,We should only unjar jobjar if there is a lib directory in it.,For backwards compatibility we recently added made is so we would unjar the job.jar and add anything to the classpath in the lib directory of that jar.  But this also slows job startup down a lot if the jar is large.  We should only unjar it if actually doing so would add something new to the classpath.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 10 Sep 2012 14:05:05 +0000,Thu; 4 Sep 2014 00:57:45 +0000,Wed; 26 Sep 2012 15:25:38 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4647
MAPREDUCE-4648,Bug,Major,mrv2,Diagnostics from AM are missing from job history,When a job fails during setup or commit; any diagnostics from the MapReduce ApplicationMaster are not available in the job history.  Currently the diagnostics for the job are collected from the diagnostics of tasks run for the job; but the AM has no corresponding task record in the job history.,Open,Unresolved,,Unassigned,Jason Lowe,Mon; 10 Sep 2012 21:31:44 +0000,Tue; 12 Feb 2013 20:59:21 +0000,,,0.23.0;2.0.0-alpha,usability,,,https://issues.apache.org/jira/browse/MAPREDUCE-4648
MAPREDUCE-4649,Bug,Major,jobhistoryserver,mr-jobhistory-daemon.sh needs to be updated post YARN-1,Even today; JHS is assuming that YARN_HOME will be same as HADOOP_MAPRED_HOME besides other such assumptions. We need to fix it.,Closed,Fixed,MAPREDUCE-3900,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 11 Sep 2012 00:54:51 +0000,Thu; 29 Aug 2013 16:47:28 +0000,Tue; 25 Sep 2012 23:51:03 +0000,,0.23.3;2.0.2-alpha,,YARN-9,HADOOP-8794;MAPREDUCE-4712;HADOOP-9902,https://issues.apache.org/jira/browse/MAPREDUCE-4649
MAPREDUCE-4650,Improvement,Minor,webapps,Provide an ability to show task counters for a given task type in Web UI,In the Web UI for Hadoop (post YARN); there is a view that lists counter values per task for a given counter (singlejobcounter page). I found this very useful to get a consolidated view of a specific counter across all tasks; for e.g. in debugging slow tasks. We can navigate to this view by selecting the specific counter from the Job Counters page.  This JIRA is to allow for the singlejobcounter page to be prepopulated only with map task values or reduce task values (if one were interested in only a particular type of task).  I understand there is a 'search' option on the singlejobcounter page that can be used to accomplish the same purpose. However; seems a little more usable to provide a direct filter before getting on to the page.,Open,Unresolved,,Hemanth Yamijala,Hemanth Yamijala,Tue; 11 Sep 2012 09:57:14 +0000,Tue; 11 Sep 2012 11:39:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4650
MAPREDUCE-4651,New Feature,Major,benchmarks;test,Benchmarking random reads with DFSIO,TestDFSIO measures throughput of HDFS write; read; and append operations. It will be useful to have an option to use it for benchmarking random reads.,Resolved,Fixed,,Konstantin Shvachko,Konstantin Shvachko,Wed; 12 Sep 2012 07:48:45 +0000,Thu; 8 Jun 2017 12:10:16 +0000,Tue; 25 Sep 2012 21:40:35 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4651
MAPREDUCE-4652,Bug,Major,examples;mrv1,ValueAggregatorJob sets the wrong job jar,Using branch-1 tarball; if the user tries to submit an example aggregatewordcount; the job fails with the following error:,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Thu; 13 Sep 2012 00:12:15 +0000,Wed; 15 May 2013 05:15:52 +0000,Tue; 25 Sep 2012 11:51:57 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4652
MAPREDUCE-4653,Improvement,Trivial,contrib/gridmix,"TestRandomAlgorithm has an unused ""import"" statement ",need to remove the import statement usinf below patch. will attach a patch shortly .  Index: TestRandomAlgorithm. .code.Attribute.Array; -  public class TestRandomAlgorithm {    private static final int[][] parameters = new int[][] {       {5; 1; 1} ;,Resolved,Fixed,,Amir Sanjar,Amir Sanjar,Thu; 13 Sep 2012 13:30:11 +0000,Tue; 30 Aug 2016 01:20:48 +0000,Tue; 17 Mar 2015 08:45:23 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4653
MAPREDUCE-4654,Bug,Critical,test,TestDistCp is @ignored,We should fix TestDistCp so that it actually runs; rather than being ignored.,Closed,Fixed,,Sandy Ryza,Colin P. McCabe,Tue; 28 Aug 2012 22:03:58 +0000,Fri; 15 Feb 2013 13:09:57 +0000,Tue; 9 Oct 2012 14:50:52 +0000,,2.0.2-alpha,,,HDFS-3054;MAPREDUCE-2765,https://issues.apache.org/jira/browse/MAPREDUCE-4654
MAPREDUCE-4655,Bug,Major,nodemanager,MergeManager.reserve can OutOfMemoryError if more than 10% of max memory is used on non-MapOutputs,The MergeManager does a memory check; using a limit that defaults to 90% of Runtime.getRuntime().maxMemory(). Allocations that would bring the total memory allocated by the MergeManager over this limit are asked to wait until memory frees up. Disk is used for single allocations that would be over 25% of the memory limit.  If some other part of the reducer were to be using more than 10% of the memory. the current check wouldn't stop an OutOfMemoryError.  Before creating an in-memory MapOutput; a check can be done using Runtime.getRuntime().freeMemory(); waiting until memory is freed up if it fails.    INFO mapreduce.Job: Task Id :  org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 153),Resolved,Invalid,,Unassigned,Sandy Ryza,Thu; 13 Sep 2012 18:50:09 +0000,Thu; 3 Jan 2013 19:47:44 +0000,Thu; 3 Jan 2013 19:47:44 +0000,,2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4655
MAPREDUCE-4656,Bug,Major,,Can't run TestDFSIO due to junit dependency,TestDFSIO can't be run from the tarball any more.  The tarball does not bundle junit; and TestDFSIO makes use of that library.,Resolved,Duplicate,MAPREDUCE-4644,Unassigned,Colin P. McCabe,Thu; 13 Sep 2012 21:02:37 +0000,Thu; 13 Sep 2012 21:21:43 +0000,Thu; 13 Sep 2012 21:21:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4656
MAPREDUCE-4657,Bug,Minor,,WindowsResourceCalculatorPlugin has NPE,When Shell command execution is interrupted then WindowsResourceCalculatorPlugin has NPE. code} 2012-08-31 13:01:00;140 ERROR Thread-771 util.WindowsResourceCalculatorPlugin(69):  662)^M,Resolved,Fixed,,Bikas Saha,Bikas Saha,Thu; 13 Sep 2012 22:30:29 +0000,Thu; 4 Oct 2012 02:48:25 +0000,Thu; 4 Oct 2012 02:48:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4657
MAPREDUCE-4658,Improvement,Major,,Move tools JARs into separate lib directories and have common bootstrap script.,This is a follow up of the discussion going on on MAPREDUCE-4644   Moving each tools JARs into separate lib  dirs it is quite easy (modifying a single assembly). What we should think is a common bootstrap script for that so each tool does not have to duplicate (and get wrong) such script. I'll open a JIRA for that.,Resolved,Won't Fix,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 14 Sep 2012 16:19:43 +0000,Wed; 14 May 2014 21:13:08 +0000,Wed; 14 May 2014 21:13:08 +0000,,2.0.2-alpha,,,MAPREDUCE-4644,https://issues.apache.org/jira/browse/MAPREDUCE-4658
HADOOP-9349,Bug,Major,tools,Confusing output when running hadoop version from one hadoop installation when HADOOP_HOME points to another,"Hadoop version X is downloaded to ~ hadoop might expect to be running the hadoop-y jars; but; because of HADOOP_HOME; will actually be running hadoop-x jars.  ""hadoop version"" could help clear this up a little by reporting the current HADOOP_HOME.",Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 14 Sep 2012 17:47:43 +0000,Wed; 15 May 2013 05:16:13 +0000,Fri; 1 Mar 2013 01:24:26 +0000,,0.20.2;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/HADOOP-9349
MAPREDUCE-4660,New Feature,Major,jobtracker;mrv1;scheduler,Update task placement policy for NetworkTopology with 'NodeGroup' layer,nan,Closed,Fixed,,Junping Du,Junping Du,Sun; 16 Sep 2012 19:14:49 +0000,Wed; 15 May 2013 05:16:04 +0000,Fri; 21 Dec 2012 22:51:30 +0000,,,,HADOOP-8820,,https://issues.apache.org/jira/browse/MAPREDUCE-4660
MAPREDUCE-4661,Improvement,Major,security;webapps,Add HTTPS for WebUIs on Branch-1,"After investigating the methodology used to add HTTPS support in branch-2; I feel that this same approach should be back-ported to branch-1. I have taken many of the patches used for branch-2 and merged them in.  I was working on top of HDP 1 at the time - I will provide a patch for trunk soon once I can confirm I am adding only the necessities for supporting HTTPS on the webUIs.  As an added benefit  this patch actually provides HTTPS webUI to HBase by extension. If you take a hadoop-core jar compiled with this patch and put it into the hbase conf.  ========= OLD IDEA(s) BEHIND ADDING HTTPS (look @ Sept 17th patch) ==========  In order to provide full security around the cluster; the webUI should also be secure if desired to prevent cookie theft and user masquerading.   Here is my proposed work. Currently I can only add HTTPS support. I do not know how to switch reliance of the HttpServer from HTTP to HTTPS fully.  In order to facilitate this change I propose the following configuration additions: CONFIG PROPERTY - DEFAULT VALUE mapred.https.enable - false mapred.https.need.client.auth - false mapred.https.server.keystore.resource - ""ssl-server.xml"" mapred.job.tracker.https.port - 50035 mapred.job.tracker.https.address - ""IP_ADDR:50035"" mapred.task.tracker.https.port - 50065 mapred.task.tracker.https.address - ""IP_ADDR:50065""  I tested this on my local box after using keytool to generate a SSL certficate. You will need to change ssl-server.xml to point to the .keystore file after. Truststore may not be necessary; you can just point it to the keystore.",In Progress,Unresolved,HADOOP-8581,Michael Weng,Plamen Jeliazkov,Mon; 17 Sep 2012 22:39:12 +0000,Wed; 7 Aug 2013 01:13:48 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4661
MAPREDUCE-4662,Bug,Major,jobhistoryserver,JobHistoryFilesManager thread pool never expands,The job history file manager creates a threadpool with core size 1 thread; max pool size 3.   It never goes beyond 1 thread though because its using a LinkedBlockingQueue which doesn't have a max size.       void start()  {       executor = new ThreadPoolExecutor(1; 3; 1;           TimeUnit.HOURS; new LinkedBlockingQueueRunnable());     }  According to the ThreadPoolExecutor  doc page it only increases the number of threads when the queue is full. Since the queue we are using has no max size it never fills up and we never get more then 1 thread.,Closed,Fixed,,Kihwal Lee,Thomas Graves,Tue; 18 Sep 2012 16:04:20 +0000,Tue; 16 Dec 2014 20:15:53 +0000,Tue; 25 Sep 2012 14:39:22 +0000,,1.0.2,,,YARN-2972,https://issues.apache.org/jira/browse/MAPREDUCE-4662
MAPREDUCE-4663,Sub-task,Major,,[MAPREDUCE-3902] Container Launch should be independent of o.a.h.m.Task,Since a container JVM can be used across TaskAttempts - launching the jvm should not depend on an individual task.,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 18 Sep 2012 18:52:05 +0000,Fri; 21 Sep 2012 18:14:02 +0000,Fri; 21 Sep 2012 18:14:02 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4663
MAPREDUCE-4664,Sub-task,Minor,,[MAPREDUCE-3902] ContainerHeartbeatHandler should be pinged on a getTask call,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 18 Sep 2012 19:10:19 +0000,Fri; 21 Sep 2012 18:13:37 +0000,Fri; 21 Sep 2012 18:13:37 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4664
MAPREDUCE-4665,Sub-task,Major,,[MAPREDUCE-3902] Use the configured shuffle port and application ACLs,nan,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 18 Sep 2012 20:25:30 +0000,Fri; 21 Sep 2012 18:13:16 +0000,Fri; 21 Sep 2012 18:13:16 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4665
MAPREDUCE-4666,Improvement,Minor,jobhistoryserver,JVM metrics for history server,It would be nice if the job history server provided the same JVM metrics via metrics2 that other Hadoop daemons are already providing.,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 18 Sep 2012 21:51:41 +0000,Wed; 3 Sep 2014 23:17:17 +0000,Fri; 9 Nov 2012 22:21:33 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4666
MAPREDUCE-4667,Improvement,Major,jobhistoryserver,Add job history server metrics,The job history server should provide metrics; via metrics2; that allow tracking of metrics specific to the history server; such as jobs discovered processed; requests served; etc.,Open,Unresolved,,Unassigned,Jason Lowe,Tue; 18 Sep 2012 21:54:26 +0000,Tue; 18 Sep 2012 21:54:26 +0000,,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4667
MAPREDUCE-4668,Bug,Major,,JettyBugMonitor thread should kill TT if can't find jetty selector thread,We ran into a case where a tasktracker started but for some reason the jetty thread didn't start or died shortly after start.  I couldn't find anything useful as to why.    Since Jetty wasn't running the TT couldn't serve up any map output.  The JettyBugMonitor thread saw this but just spit out the warning. We should have it just kill the TT since its basically unusable without it.   2012-07-23 05:42:04;072 WARN org.apache.hadoop.mapred.JettyBugMonitor: Could not locate Jetty selector threads,Open,Unresolved,,Unassigned,Thomas Graves,Wed; 19 Sep 2012 15:30:14 +0000,Tue; 14 May 2013 05:14:45 +0000,,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4668
MAPREDUCE-4669,Bug,Major,mr-am,MRAM web UI does not work with HTTPS,With Kerberos enable; the MRAM runs as the user that submitted the job; thus the MRAM process cannot read the cluster keystore files to get the certificates to start its HttpServer using HTTPS.  We need to decouple the keystore used by RM DN (which are cluster provided) from the keystore used by AMs (which ought to be user provided).,Open,Unresolved,,Haibo Chen,Alejandro Abdelnur,Wed; 19 Sep 2012 18:26:01 +0000,Mon; 15 May 2017 04:34:12 +0000,,,2.0.3-alpha,,,YARN-4562,https://issues.apache.org/jira/browse/MAPREDUCE-4669
MAPREDUCE-4670,Bug,Minor,,HadoopServiceTestDFSIOBenchmark could switch to hadoop version of TestDFSIO,Assuming I've got my versions right; that 1.0.3 is after 0.20.2; then MAPREDUCE-1832 is fixed; so after WHIRR-661 is in the local copy of TestDFSIO can be pulled.,Resolved,Invalid,,Unassigned,Steve Loughran,Thu; 20 Sep 2012 10:41:53 +0000,Thu; 20 Sep 2012 10:42:30 +0000,Thu; 20 Sep 2012 10:42:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4670
MAPREDUCE-4671,Bug,Major,,AM does not tell the RM about container requests that are no longer needed,Say the AM wanted a container at hosts h1; h2; h3. After getting a container at h1 it should tell RM that it no longer needs containers at h2; h3. Otherwise on the RM h2; h3 remain valid allocation locations. The AM RMContainerAllocator does remove these resource requests internally. When the resource request container count drops to 0 then it drops the resource request from its tables but forgets to send the 0 sized request to the RM.,Closed,Fixed,MAPREDUCE-4984,Bikas Saha,Bikas Saha,Thu; 20 Sep 2012 22:59:54 +0000,Tue; 27 Aug 2013 22:22:00 +0000,Thu; 7 Feb 2013 07:09:01 +0000,,0.23.3;2.0.0-alpha,,,YARN-110,https://issues.apache.org/jira/browse/MAPREDUCE-4671
MAPREDUCE-4672,Bug,Major,resourcemanager,RM with lost NMs results in massive log of AppAttemptId doesnt exist in cache,Hey Guys;  I'm running a 9 node cluster with 8 NMs and a single RM node. If I run an app master and have that app master start a container; then shut down all NMs; but leave the RM up (to simulate a failure); the containers timeout and fail; as expected.  What's unexpected is that my log then starts filling with:   2012-09-21 18:02:02;614 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService. allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001  Is there any way to shut this off fix it? It just keeps going forever; until I bounce the RM node.  Thanks! Chris,Resolved,Duplicate,YARN-72,Vinod Kumar Vavilapalli,Chris Riccomini,Fri; 21 Sep 2012 18:05:02 +0000,Fri; 8 May 2015 18:36:49 +0000,Fri; 8 May 2015 18:36:49 +0000,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4672
MAPREDUCE-4673,Bug,Major,test,make TestRawHistoryFile and TestJobHistoryServer more robust,these unit tests fail if 2 different users run them on the same host as they are using  input path  following is the info from the test log,Closed,Fixed,,Arpit Gupta,Arpit Gupta,Fri; 21 Sep 2012 18:06:11 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Mon; 24 Sep 2012 19:45:53 +0000,,1.1.0;1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4673
MAPREDUCE-4674,Bug,Minor,,"Hadoop examples secondarysort has a typo ""secondarysrot"" in the usage",$ hadoop jar  hadoop-mapreduce-examples.jar secondarysort Usage: secondarysrot in out,Closed,Fixed,,Robert Justice,Robert Justice,Fri; 21 Sep 2012 14:44:48 +0000,Wed; 6 Feb 2013 17:05:39 +0000,Fri; 21 Sep 2012 20:17:05 +0000,,0.23.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4674
MAPREDUCE-4675,Bug,Major,test,TestKillSubProcesses fails as the process is still alive after the job is done,I ran this test in branch 1 and branch 1.1 and they both failed with the following,Closed,Fixed,,Bikas Saha,Arpit Gupta,Fri; 21 Sep 2012 22:15:50 +0000,Wed; 17 Oct 2012 18:27:23 +0000,Mon; 24 Sep 2012 22:40:55 +0000,,1.1.0;1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4675
MAPREDUCE-4676,Bug,Major,jobhistoryserver,Add test for job history cleaner,Add a test to TestJobHistory that verifies that the HistoryCleaner cleans up the job history,Reopened,Unresolved,MAPREDUCE-4643,Unassigned,Sandy Ryza,Fri; 21 Sep 2012 22:44:17 +0000,Tue; 11 Jun 2013 23:54:39 +0000,,,2.0.3-alpha,,MAPREDUCE-4643,,https://issues.apache.org/jira/browse/MAPREDUCE-4676
MAPREDUCE-4677,Improvement,Minor,client,Text IF/OF separator character configuration should support passing non-XML-serializable characters,Since HADOOP-7542 can't be done to easily enable special characters; we need a base64 way of emitting set characters for both input delimiters and output delimiters (for TextInputFormat and TextOutputFormat) similar to HBASE-3623.,Open,Unresolved,,Unassigned,Harsh J,Sun; 23 Sep 2012 10:53:28 +0000,Sun; 23 Sep 2012 10:57:29 +0000,,,2.0.0-alpha,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4677
MAPREDUCE-4678,Bug,Minor,examples,Running the Pentomino example with defaults throws java.lang.NegativeArraySizeException,HADOOP_HOME hadoop-examples.jar pentomino output_dir will fail with the following error message:,Closed,Fixed,,Chris McConnell,Chris McConnell,Mon; 24 Sep 2012 12:26:21 +0000,Thu; 2 May 2013 02:29:59 +0000,Tue; 15 Jan 2013 13:49:04 +0000,,2.0.0-alpha,,MAPREDUCE-4930,,https://issues.apache.org/jira/browse/MAPREDUCE-4678
MAPREDUCE-4679,Improvement,Major,,Backport MAPREDUCE-1881 (Improve TaskTrackerInstrumentation) to branch-1,nan,Open,Unresolved,,Unassigned,Karthik Kambatla,Mon; 24 Sep 2012 18:36:39 +0000,Mon; 3 Nov 2014 18:33:31 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4679
MAPREDUCE-4680,Bug,Major,jobhistoryserver,Job history cleaner should only check timestamps of files in old enough directories,Job history files are stored in yyyy dd folders.  Currently; the job history cleaner checks the modification date of each file in every one of these folders to see whether it's past the maximum age.  The load on HDFS could be reduced by only checking the ages of files in directories that are old enough; as determined by their name.,Closed,Fixed,,Robert Kanter,Sandy Ryza,Mon; 24 Sep 2012 22:17:40 +0000,Mon; 24 Feb 2014 20:57:22 +0000,Mon; 28 Oct 2013 23:56:02 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4680
MAPREDUCE-4681,Bug,Major,,HDFS-3910 broke MR tests,HDFS-3910 changed signatures of DFSTestUtil functions and didn't change MR tests.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Wed; 26 Sep 2012 01:55:41 +0000,Fri; 15 Feb 2013 13:09:52 +0000,Sun; 30 Sep 2012 17:03:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4681
MAPREDUCE-4682,Bug,Blocker,,TestKillSubProcess & TestTaskTrackerMemoryManager fail to compile on trunk due to MAPREDUCE-4253,Fail with:    TestKillSubProcesses.        TestProcfsBasedProcessTree.setupProcfsRootDir(procfsRootDir);,Resolved,Not A Problem,,Arun C Murthy,Arun C Murthy,Wed; 26 Sep 2012 02:01:42 +0000,Tue; 13 Nov 2012 22:25:42 +0000,Tue; 13 Nov 2012 22:25:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4682
MAPREDUCE-4683,Bug,Critical,build,Create and distribute hadoop-mapreduce-client-core-tests.jar,We need to fix our build to create distribute hadoop-mapreduce-client-core-tests.jar; need this before MAPREDUCE-4253,Resolved,Fixed,,Akira Ajisaka,Arun C Murthy,Wed; 26 Sep 2012 02:37:20 +0000,Thu; 8 Dec 2016 02:40:54 +0000,Thu; 8 Dec 2016 02:29:23 +0000,,,,MAPREDUCE-4253,,https://issues.apache.org/jira/browse/MAPREDUCE-4683
MAPREDUCE-4684,Bug,Critical,,Mavenize all remaining MR tests ,Mavenize all remaining MR tests - else we run into situations like MAPREDUCE-3681; MAPREDUCE-3682 etc.,Open,Unresolved,,Unassigned,Arun C Murthy,Wed; 26 Sep 2012 02:50:37 +0000,Wed; 26 Sep 2012 02:50:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4684
MAPREDUCE-4685,Bug,Major,examples,DBCount should not use ACCESS ,DBCount uses ACCESS as table name which is not supported for Oracle DBs since it is a keyword in Oracle as per http: apb.htm  Also; BIGINT isn't supported.  I will shortly post a patch to address this.,Resolved,Fixed,,Viji,Viji,Wed; 26 Sep 2012 07:12:07 +0000,Thu; 12 May 2016 18:22:39 +0000,Wed; 26 Sep 2012 10:23:29 +0000,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4685
MAPREDUCE-4686,Improvement,Major,build,hadoop-mapreduce-client-core fails compilation in Eclipse due to missing Avro-generated classes,After importing all of hadoop-common trunk into Eclipse with the m2e plugin; the Avro-generated classes in hadoop-mapreduce-client-core don't show up on Eclipse's classpath.  This causes compilation errors for anything that depends on those classes.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Wed; 26 Sep 2012 06:58:48 +0000,Wed; 22 Mar 2017 21:49:26 +0000,Wed; 26 Sep 2012 12:53:33 +0000,,3.0.0-alpha1,,,HADOOP-9304,https://issues.apache.org/jira/browse/MAPREDUCE-4686
MAPREDUCE-4687,Bug,Major,,Add compilation of 'classic' MR1 (ant based) to jenkins builds,nan,Resolved,Won't Fix,,Unassigned,Arun C Murthy,Wed; 26 Sep 2012 14:39:09 +0000,Mon; 19 Jun 2017 04:22:52 +0000,Mon; 19 Jun 2017 04:22:52 +0000,,,,,MAPREDUCE-4266,https://issues.apache.org/jira/browse/MAPREDUCE-4687
MAPREDUCE-4688,Bug,Minor,,setJarByClass does not work under JBoss AS 7,Hello;  I m using Hadoop as a client from a J2EE web application. One of the lib within my EAR is a jar containing several Map Reduce cluster. With the VFS protocol the resource name may be or may not be the actual system file name of the resource. I mean; the class file is within the jar file which may be within an ear file in case of a non-exploded deployment; so there are not system File corresponding to the resource. Though; I guess similar issues may happen with jar: protocol.  In order to make the job working with JBoss AS-7; I did the following implementation of the Job class. This override the setJarByClass mechanism; by creating a temporary jar file from the actual jar file read from vfs.     So; after the call; I must not forget deleting the temporary jar file.,Open,Unresolved,,Unassigned,Philippe,Wed; 26 Sep 2012 14:53:36 +0000,Mon; 14 Apr 2014 21:00:59 +0000,,,0.20.2;1.0.3,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4688
MAPREDUCE-4689,Bug,Major,client,JobClient.getMapTaskReports on failed job results in NPE,When calling JobClient.getMapTaskReports for a job that has failed results in an NPE.  For example:,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 26 Sep 2012 23:06:18 +0000,Thu; 4 Sep 2014 00:57:37 +0000,Fri; 28 Sep 2012 22:32:22 +0000,,0.23.3,,,MAPREDUCE-4693,https://issues.apache.org/jira/browse/MAPREDUCE-4689
MAPREDUCE-4690,Improvement,Major,client,remove deprecated properties in the default configurations,We need to remove the deprecated properties included in the default configurations; such as core-default.xml and core-site.xml.,Resolved,Duplicate,MAPREDUCE-3223,Unassigned,Jianbin Wei,Thu; 27 Sep 2012 17:16:56 +0000,Thu; 12 May 2016 18:23:49 +0000,Thu; 27 Sep 2012 17:44:06 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4690
MAPREDUCE-4691,Bug,Critical,jobhistoryserver;mrv2,"Historyserver can report ""Unknown job"" after RM says job has completed",Example traceback from the client:,Closed,Fixed,,Robert Joseph Evans,Jason Lowe,Thu; 27 Sep 2012 22:45:41 +0000,Thu; 4 Sep 2014 00:57:30 +0000,Fri; 28 Sep 2012 22:06:40 +0000,,0.23.3;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4691
MAPREDUCE-4692,Bug,Minor,client,Investigate and remove MR1 JTConfig and its constants use in the MR project on trunk,Filed on behalf of Robert from MAPREDUCE-3223   Are there any JIRAs to deprecate the configs from where they reside in the code? .  for example. I know we cannot delete them out just yet; because MRV1 code still exists and may be using it; but it would be good to mark all of those configs as deprecated. So that we can delete them in trunk once the MRV1 code is completely removed.,Open,Unresolved,,Unassigned,Harsh J,Fri; 28 Sep 2012 13:49:21 +0000,Thu; 2 May 2013 02:30:58 +0000,,,,usability,,MAPREDUCE-4997,https://issues.apache.org/jira/browse/MAPREDUCE-4692
MAPREDUCE-4693,Bug,Major,jobhistoryserver;mrv2,Historyserver should provide counters for failed tasks,Currently the historyserver is not providing counters for failed tasks; even though they are available via the AM as long as the job is still running.  Those counters are lost when the client needs to redirect to the historyserver after the job completes.,Closed,Fixed,,Xuan Gong,Jason Lowe,Fri; 28 Sep 2012 22:14:56 +0000,Tue; 27 Aug 2013 22:22:20 +0000,Wed; 27 Feb 2013 21:04:57 +0000,,2.0.3-alpha;0.23.6,usability,,MAPREDUCE-4689;MAPREDUCE-5309,https://issues.apache.org/jira/browse/MAPREDUCE-4693
MAPREDUCE-4694,Bug,Major,client,Inconsistency in reduce input record counters between the stable and evolving APIs,"In the stable (mapred) API execution; if the values iterator is skipped by a user; the records underneath it aren't counted in the ""Reduce input records"" counter as the key progresses to the next unique one. In the evolving API (mapreduce) API execution; if the values iterator is skipped by a user; the records underneath it is still counted as the key progresses to the next unique one.  This behavior comes to me as a faulty one in the old API. A ""Reduce input records"" counter must always define all the records that have been passed into a reducer (cause they are read regardless of skipping); and both API's record counting despite user applications must be consistent.  I'll post a test case illustrating this shortly.",Resolved,Won't Fix,,Unassigned,Harsh J,Mon; 1 Oct 2012 08:36:23 +0000,Wed; 8 Mar 2017 12:15:02 +0000,Wed; 8 Mar 2017 12:15:02 +0000,,2.0.0-alpha,inconsistency;regression;test,,,https://issues.apache.org/jira/browse/MAPREDUCE-4694
MAPREDUCE-4695,Bug,Blocker,test,Fix LocalRunner on trunk after MAPREDUCE-3223 broke it,MAPREDUCE-3223 removed mapreduce.cluster.local.dir property from mapred-default.xml (since NM local dirs are now used) but failed to counter that LocalJobRunner; etc. still use it.     All local job tests have been failing since then.  This JIRA is to reintroduce it or provide an equivalent new config for fixing it.,Resolved,Fixed,,Harsh J,Harsh J,Mon; 1 Oct 2012 15:43:05 +0000,Fri; 13 May 2016 05:19:53 +0000,Mon; 1 Oct 2012 17:11:00 +0000,,3.0.0-alpha1,,,MAPREDUCE-5762,https://issues.apache.org/jira/browse/MAPREDUCE-4695
MAPREDUCE-4696,Bug,Minor,,TestMRServerPorts throws NullReferenceException,TestMRServerPorts throws      Use the JobTracker.startTracker(string; string; boolean initialize) factory method to get a pre-initialized JobTracker for the test.,Closed,Fixed,,Gopal V,Gopal V,Mon; 1 Oct 2012 22:31:32 +0000,Wed; 6 Mar 2013 09:56:01 +0000,Wed; 5 Dec 2012 22:31:47 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4696
MAPREDUCE-4697,Bug,Minor,,TestMapredHeartbeat fails assertion on HeartbeatInterval,TestMapredHeartbeat fails test on heart beat interval     Replicate math for getNextHeartbeatInterval() in the test-case to ensure MRConstants changes do not break test-case.,Closed,Fixed,,Gopal V,Gopal V,Mon; 1 Oct 2012 22:43:00 +0000,Wed; 6 Mar 2013 09:55:59 +0000,Wed; 5 Dec 2012 22:32:07 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4697
MAPREDUCE-4698,Bug,Minor,,TestJobHistoryConfig throws Exception in testJobHistoryLogging,TestJobHistoryConfig cannot find the LOG_DIR and throws,Closed,Fixed,,Gopal V,Gopal V,Mon; 1 Oct 2012 22:57:50 +0000,Wed; 17 Oct 2012 18:27:25 +0000,Wed; 3 Oct 2012 02:37:11 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4698
MAPREDUCE-4699,Bug,Minor,,TestFairScheduler & TestCapacityScheduler fails due to JobHistory exception,TestFairScheduler fails due to exception from mapred.JobHistory     TestCapacityScheduler fails due to     Update UtilsForTest::getJobTracker to call initialize() initializeFileSystem() to match behaviour in pre-safe mode constructor.,Closed,Fixed,,Gopal V,Gopal V,Mon; 1 Oct 2012 23:08:58 +0000,Wed; 6 Mar 2013 09:56:00 +0000,Wed; 5 Dec 2012 22:32:36 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4699
MAPREDUCE-4700,Bug,Minor,,ACL Failure in TestWebUIAuthorization causes Timeout,TestWebUIAuthorization test fails     This is repeated until a timeout is triggered,Open,Unresolved,,Unassigned,Gopal V,Tue; 2 Oct 2012 03:27:59 +0000,Tue; 2 Oct 2012 23:47:48 +0000,,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4700
HDFS-3997,Bug,Trivial,namenode,OfflineImageViewer incorrectly passes value of imageVersion when visiting IS_COMPRESSED element,"Rumen's processing of FSImage logs reports the value of ""IS_COMPRESSED"" incorrectly as ""-39"" (or whatever the image-version is).  The problem is in ImageLoaderCurrent; where the FSIMAGE_COMPRESSION node is visited using the imageVersion value instead of the value of isCompressed.) A fix is forthcoming.",Closed,Fixed,,Mithun Radhakrishnan,Mithun Radhakrishnan,Tue; 2 Oct 2012 20:12:20 +0000,Fri; 15 Feb 2013 13:12:03 +0000,Wed; 17 Oct 2012 01:12:57 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/HDFS-3997
HADOOP-8877,Wish,Trivial,,Rename o.a.h.security.token.Token.TrivialRenewer to UnmanagedRenewer for clarity,While browsing through the code; I came across the TrivialRenewer. It would definitely be easy to comprehend if we rename it to UnmanagedRenewer.,Resolved,Won't Fix,,Karthik Kambatla,Karthik Kambatla,Wed; 3 Oct 2012 22:05:10 +0000,Mon; 3 Nov 2014 18:34:06 +0000,Thu; 11 Oct 2012 20:44:05 +0000,,2.0.1-alpha,,,,https://issues.apache.org/jira/browse/HADOOP-8877
MAPREDUCE-4703,Improvement,Major,mrv1;mrv2;test,Add the ability to start the MiniMRClientCluster using the configurations used before it is being stopped.,The objective here is to enable starting back the cluster; after being stopped; using the same configurations port numbers used before stopping.,Closed,Fixed,,Ahmed Radwan,Ahmed Radwan,Thu; 4 Oct 2012 01:57:04 +0000,Fri; 15 Feb 2013 13:09:54 +0000,Tue; 18 Dec 2012 13:25:52 +0000,,1.2.0;2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4703
MAPREDUCE-4704,Bug,Minor,mr-am;mrv2,TaskHeartbeatHandler misreports a ping timeout as a task timeout,When a task fails to ping within the hardcoded ping timeout of 5 minutes; TaskHeartbeatHandler logs a message reporting the wrong timeout value.  It reports a timeout of mapreduce.task.timeout seconds rather than the 5 minute ping timeout.  This can lead to user confusion if they try increasing mapreduce.task.timeout and see the log message showing the larger value but the task continues to timeout after only 5 minutes.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 4 Oct 2012 14:33:04 +0000,Tue; 12 Feb 2013 20:58:28 +0000,,,0.23.3,usability,,,https://issues.apache.org/jira/browse/MAPREDUCE-4704
MAPREDUCE-4705,Bug,Critical,jobhistoryserver;mrv2,Historyserver links expire before the history data does,The historyserver can serve up links to jobs that become useless well before the job history files are purged.  For example on a large; heavily used cluster we can end up rotating through the maximum number of jobs the historyserver can track fairly quickly.  If a user was investigating an issue with a job using a saved historyserver URL; that URL can become useless because the historyserver has forgotten about the job even though the history files are still sitting in HDFS.  We can tell the historyserver to keep track of more jobs by increasing mapreduce.jobhistory.joblist.cache.size; but this has a direct impact on the responsiveness of the main historyserver page since it serves up all the entries to the client at once.  It looks like Hadoop 1.x avoided this issue by encoding the history file location into the URLs served up by the historyserver; so it didn't have to track a mapping between job ID and history file location.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 4 Oct 2012 21:32:48 +0000,Wed; 6 Feb 2013 17:05:26 +0000,Tue; 9 Oct 2012 03:26:07 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4705
MAPREDUCE-4706,Bug,Critical,contrib/fair-share,FairScheduler#dump(): Computing of # running maps and reduces is commented out,In FairScheduler#dump(); we conveniently comment the updating of number of running maps and reduces. It needs to be fixed for the dump to throw out meaningful information.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Thu; 4 Oct 2012 21:56:03 +0000,Mon; 3 Nov 2014 18:33:53 +0000,Mon; 8 Oct 2012 11:46:42 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4706
MAPREDUCE-4707,Improvement,Trivial,contrib/fair-share,Add a comment to explain why FairScheduler#dump()'s body is synchronized on eventLog,FairScheduler#dump() is a synchronized method. In addition to that; the entire method body is in a synchronized block on eventLog. However; there is no other portion of the code that tries to acquire a lock on eventLog. So; it seems like the second synchronized block is redundant; and can be removed.,Resolved,Won't Fix,,Karthik Kambatla,Karthik Kambatla,Fri; 5 Oct 2012 07:58:17 +0000,Mon; 3 Nov 2014 18:33:29 +0000,Fri; 7 Jun 2013 03:49:26 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4707
MAPREDUCE-4708,Test,Major,contrib/fair-share,TestFairScheduler is failing,TestFairScheduler#testJobsWithPriorities() and TestFairScheduler#testFifoPool() are failing. Attached is a failure instance.,Open,Unresolved,,Unassigned,Karthik Kambatla,Fri; 5 Oct 2012 08:28:35 +0000,Mon; 3 Nov 2014 18:33:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4708
MAPREDUCE-4709,New Feature,Minor,,Counters that track max values,"A nice feature to help monitor MR jobs would be mapreduce counters that track the maximum of some metric across all workers. These trackers would work just like regular counters except it would track the max value of all arguments passed to the ""increment"" function as opposed to summing them.",Open,Unresolved,,Unassigned,Jeremy Lewi,Fri; 5 Oct 2012 17:39:39 +0000,Fri; 25 Jan 2013 13:50:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4709
MAPREDUCE-4710,New Feature,Minor,task,Add peak memory usage counter for each task,Each task has counters PHYSICAL_MEMORY_BYTES and VIRTUAL_MEMORY_BYTES; which are snapshots of memory usage of that task. They are not sufficient for users to understand peak memory usage by that task; e.g. in order to diagnose task failures; tune job parameters or change application design. This new feature will add two more counters for each task: PHYSICAL_MEMORY_BYTES_MAX and VIRTUAL_MEMORY_BYTES_MAX.,Patch Available,Unresolved,,Cindy Li,Cindy Li,Fri; 5 Oct 2012 18:47:59 +0000,Fri; 29 Apr 2016 23:25:00 +0000,,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4710
MAPREDUCE-4711,Bug,Major,jobhistoryserver,Append time elapsed since job-start-time for finished tasks,In 0.20.x 10 20:23:10 (1hrs; 27mins; 54sec)  The time it took for the last task to finish needs to be calculated mentally in 0.23. I believe we should print it next to the finish time.,Resolved,Won't Fix,,Unassigned,Ravi Prakash,Fri; 5 Oct 2012 20:29:07 +0000,Mon; 18 May 2015 16:53:30 +0000,Mon; 18 May 2015 16:53:30 +0000,,0.23.3,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4711
MAPREDUCE-4712,Bug,Major,jobhistoryserver,mr-jobhistory-daemon.sh doesn't accept --config,It says,Closed,Fixed,MAPREDUCE-4814;MAPREDUCE-4713,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 5 Oct 2012 21:54:22 +0000,Fri; 15 Feb 2013 13:10:08 +0000,Mon; 8 Oct 2012 19:05:40 +0000,,2.0.2-alpha,,BIGTOP-713,MAPREDUCE-4649,https://issues.apache.org/jira/browse/MAPREDUCE-4712
MAPREDUCE-4713,Bug,Major,jobhistoryserver,mr-jobhistory-daemon.sh --config option doesn't work,I was trying to start the job history server with --config option (mr-jobhistory-daemon.sh --config  conf start historyserver)  but it fails and simply prints the usage:   Usage: mr-jobhistory-daemon.sh --config conf-dir&#93; (start|stop) mapred-command   The only way I could get it to start is remove the --config option.,Resolved,Duplicate,MAPREDUCE-4712,Unassigned,Thomas Graves,Mon; 8 Oct 2012 16:29:30 +0000,Mon; 8 Oct 2012 16:43:31 +0000,Mon; 8 Oct 2012 16:43:31 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4713
MAPREDUCE-4714,Bug,Minor,jobhistoryserver;mrv2,Historyserver retrieves job from jobID more often than necessary,When serving up a web page for job history; AppController.requireJob() is converting from a jobID to a job twice when it only needs to do it once.  The resulting job is stored into the app object; which we could; in turn; use in historyserver web page render() methods to simply retrieve the job rather than performing yet another jobID-job lookup.  That would cut the job lookups down from 3 to 1.  jobID-job lookups aren't necessarily cheap.  If the job isn't in the historyserver joblist cache then the historyserver needs to scan directories looking for it; adding an unnecessary extra load onto the namenode.,Open,Unresolved,,Unassigned,Jason Lowe,Mon; 8 Oct 2012 20:18:10 +0000,Mon; 8 Oct 2012 20:18:10 +0000,,,0.23.3;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4714
MAPREDUCE-4715,Bug,Minor,job submission,Heap memory growing when JVM reuse option enabled,"When mapred.job.reuse.jvm.num.tasks option is set to 100 or more tasks; JVM fails with "" lang.OutOfMemoryError: Java heap space"" error message. Jobs itself are small and job heap size is set to -Xmx200m . It looks like the reason of the issue is a FileSystem$Cache object which collects JobConf objects from all jobs which were executed in current JVM. GC root for the FileSystem$Cache is ApplicationShutdownHooks class (cannot attach screenshot from visualvm) In my case each of JobConf objects allocates ~500K (50M total in case of 100 jobs).",Open,Unresolved,,Unassigned,Boris Ryakhovskiy,Tue; 9 Oct 2012 14:11:05 +0000,Tue; 9 Oct 2012 14:42:33 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4715
MAPREDUCE-4716,Bug,Major,jobhistoryserver,TestHsWebServicesJobsQuery.testJobsQueryStateInvalid fails with jdk7,"Using jdk7 TestHsWebServicesJobsQuery.testJobsQueryStateInvalid  fails.  It looks like the string changed from ""const class"" to ""constant"" in jdk7.   Tests run: 25; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 9.713 sec &lt; FAILURE! testJobsQueryStateInvalid(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery)  Time elapsed: 0.371 sec  &lt; FAILURE!  286)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",Closed,Fixed,,Thomas Graves,Thomas Graves,Tue; 9 Oct 2012 17:03:22 +0000,Thu; 12 May 2016 18:23:22 +0000,Fri; 15 Mar 2013 19:00:59 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,java7,YARN-30,,https://issues.apache.org/jira/browse/MAPREDUCE-4716
MAPREDUCE-4717,Bug,Major,mrv1,Mapreduce job fails to run after configuring multiple namespaces [HDFS Federation],I am having setup of 4 nodes with following details -  Standalone Desktop-1 - NameNode1;Tasktracker;Zookeeper;Jobtracker;datanode;HMaster  Standalone Desktop-2 - NameNode2;Tasktracker;datanode.RegionServer  Virtual Machine-1 - Namenode3;Datanode;Tasktracker  Virtual Machine-2 - Namenode4;Datanode;Tasktracker   I have configured HDFS Federation with following name service - a) nameservice1 b) oss-hadoop-nameservice  While executing Mapreduce job I am getting following error -  ================================================================ -bash-4.1$ id uid=496(hdfs) gid=496(hdfs) groups=496(hdfs);497(hadoop) -bash-4.1$ hadoop jar  testing   ERROR security.UserGroupInformation: PriviledgedActionException as:hdfs (auth:SIMPLE) cause: 208) -bash-4.1$ ================================================================,Resolved,Not A Problem,,Unassigned,Sagar Shimpi,Wed; 10 Oct 2012 06:57:13 +0000,Fri; 12 Oct 2012 04:39:02 +0000,Wed; 10 Oct 2012 17:00:42 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4717
HADOOP-10533,Bug,Minor,fs/s3,S3 input stream NPEs in MapReduce job,I'm running a wordcount MR as follows  hadoop jar WordCount.jar wordcount.WordCountDriver s3n:   (both input path are directories),Closed,Fixed,,Steve Loughran,Benjamin Kim,Wed; 10 Oct 2012 11:30:51 +0000,Thu; 12 May 2016 18:27:04 +0000,Thu; 3 Jul 2014 13:04:02 +0000,,1.0.0;1.0.3;2.4.0;3.0.0-alpha1,,,HADOOP-10589,https://issues.apache.org/jira/browse/HADOOP-10533
MAPREDUCE-4719,Improvement,Minor,,mapred.TaskInProgress should be public,In Cloudera's CDH3 distributions; mapred.TaskInProgress has been made public along with its generateSingleReport() and getDiagnosticInfo() methods.  Should this change be brought back into the main source tree?,Resolved,Invalid,,Unassigned,Dave Beech,Wed; 10 Oct 2012 13:03:35 +0000,Thu; 11 Oct 2012 17:17:08 +0000,Thu; 11 Oct 2012 17:17:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4719
MAPREDUCE-4720,Bug,Major,,Browser thinks History Server main page JS is taking too long,The main History Server page with the default settings of 20;000 jobs can cause browsers to think that the JS on the page is stuck and ask you if you want to kill it. This is a big usability problem.,Closed,Fixed,,Ravi Prakash,Robert Joseph Evans,Wed; 10 Oct 2012 14:09:50 +0000,Mon; 5 Sep 2016 12:03:21 +0000,Thu; 15 Nov 2012 00:23:15 +0000,,0.23.3,,,YARN-151;MAPREDUCE-4802,https://issues.apache.org/jira/browse/MAPREDUCE-4720
MAPREDUCE-4721,Bug,Major,jobhistoryserver,Task startup time in JHS is same as job startup time.,As Bobby pointed out in https: MAPREDUCE-4711?focusedCommentId=13471696page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13471696  In the Map and Reduce tasks page; it should print the earliest task attempt launch time as TaskImpl:getLaunchTime() does.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Wed; 10 Oct 2012 20:33:53 +0000,Thu; 12 May 2016 18:22:41 +0000,Wed; 17 Oct 2012 15:04:57 +0000,,0.23.3;2.0.2-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4721
MAPREDUCE-4722,Bug,Major,job submission,LocalJobRunner random ID should not be chosen with Math.abs(rand.nextInt()),According to findbugs 2; this can cause problems if the randomly generated int is Integer.MIN_VALUE because Math.abs(Integer.MIN_VALUE) == Integer.MIN_VALUE.,Resolved,Invalid,,Sandy Ryza,Sandy Ryza,Thu; 11 Oct 2012 18:01:12 +0000,Thu; 11 Oct 2012 18:42:15 +0000,Thu; 11 Oct 2012 18:41:39 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4722
MAPREDUCE-4723,Improvement,Major,,Fix warnings found by findbugs 2,The MAPREDUCE side of HADOOP-8594. Umbrella jira for fixing the warnings found by findbugs 2.,Closed,Fixed,MAPREDUCE-4725;MAPREDUCE-4726,Sandy Ryza,Sandy Ryza,Thu; 11 Oct 2012 18:19:41 +0000,Fri; 15 Feb 2013 13:10:05 +0000,Thu; 15 Nov 2012 00:17:24 +0000,,2.0.0-alpha,,,HADOOP-8594,https://issues.apache.org/jira/browse/MAPREDUCE-4723
MAPREDUCE-4724,Bug,Major,jobhistoryserver,job history web ui applications page should be sorted to display last app first,The job history server jobs web page defaults the sort order to ascending; which has oldest jobs first (smallest job id).   I think its more useful to sort descending so that the newest jobs show first since those are more likely what people are going to look at.  YARN-159 changed this for RM apps page.,Closed,Fixed,,Thomas Graves,Thomas Graves,Mon; 15 Oct 2012 15:40:40 +0000,Wed; 3 Sep 2014 23:17:18 +0000,Wed; 31 Oct 2012 19:16:06 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4724
MAPREDUCE-4725,Sub-task,Major,,Setting local variables to null causes findbugs 2 warnings,In a couple places; local variables are set to null when they are no longer used.  This is unnecessary as the compiler is able to figure this out; and causes findbugs warnings.,Resolved,Duplicate,MAPREDUCE-4723,Sandy Ryza,Sandy Ryza,Mon; 15 Oct 2012 19:50:31 +0000,Wed; 24 Oct 2012 00:39:59 +0000,Mon; 15 Oct 2012 21:36:57 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4725
MAPREDUCE-4726,Sub-task,Major,,Empty catch blocks cause findbugs 2 warnings,Debug messages can be logged.,Resolved,Duplicate,MAPREDUCE-4723,Sandy Ryza,Sandy Ryza,Mon; 15 Oct 2012 20:04:21 +0000,Wed; 24 Oct 2012 00:39:35 +0000,Mon; 15 Oct 2012 21:37:16 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4726
MAPREDUCE-4727,Sub-task,Major,applicationmaster,[MAPREDUCE-3902] Handle a successful NM stop request,The branch currently ignores successful container stop requests to the NodeManager; and waits instead for a ContainerFinished message from the RM. These stop requests should be handled.,Resolved,Fixed,,Siddharth Seth,Siddharth Seth,Mon; 15 Oct 2012 21:05:50 +0000,Mon; 15 Oct 2012 21:10:43 +0000,Mon; 15 Oct 2012 21:10:43 +0000,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4727
MAPREDUCE-4728,Bug,Major,,Interaction between oob heartbeats and damper can cause TT to heartbeat with zero delay,When mapreduce.tasktracker.outofband.heartbeat is true and mapreduce.tasktracker.outofband.heartbeat.damper is something largish (like the default of 1000000); the TT doesn't wait for tasks to finish before heartbeating back to the JT. This causes excessive load on the JT which in-turn reduces overall cluster performance.  I believe the problem is that in the following block of code; when getHeartbeatInterval() returns 0; we heartbeat back immediately BUT finishedCount does not get reset. It looks like nothing ever gets us out of this situation so we basically heartbeat without ever sleeping.,Open,Unresolved,,Unassigned,Nathan Roberts,Wed; 17 Oct 2012 16:14:01 +0000,Wed; 20 Feb 2013 22:00:47 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4728
MAPREDUCE-4729,Bug,Major,jobhistoryserver,job history UI not showing all job attempts,We are seeing a case where a job runs but the AM is running out of memory in the first 3 tempts.,Closed,Fixed,,Vinod Kumar Vavilapalli,Thomas Graves,Wed; 17 Oct 2012 16:21:57 +0000,Wed; 6 Feb 2013 17:05:40 +0000,Thu; 1 Nov 2012 23:09:20 +0000,,0.23.3,,,MAPREDUCE-4767,https://issues.apache.org/jira/browse/MAPREDUCE-4729
MAPREDUCE-4730,Bug,Blocker,applicationmaster;mrv2,AM crashes due to OOM while serving up map task completion events,We're seeing a repeatable OOM crash in the AM for a task with around 30000 maps and 3000 reducers.  Details to follow.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 17 Oct 2012 23:36:50 +0000,Thu; 2 May 2013 02:29:56 +0000,Thu; 25 Oct 2012 01:28:37 +0000,,0.23.3,,,HADOOP-8942,https://issues.apache.org/jira/browse/MAPREDUCE-4730
HADOOP-8941,Bug,Major,,FSShell double encodes qualified Paths,nan,Open,Unresolved,,Unassigned,Robert Joseph Evans,Thu; 18 Oct 2012 17:49:33 +0000,Thu; 18 Oct 2012 17:51:36 +0000,,,0.23.3;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/HADOOP-8941
MAPREDUCE-4732,Bug,Major,test,testcase testJobRetire fails using IBM JAVA ,"Testcase: testJobRetire took 53.352 sec Testcase: testJobRetireWithUnreportedTasks took 41.173 sec 	FAILED Job did not retire junit.framework.AssertionFailedError: Job did not retire 	at org.apache.hadoop.mapred.TestJobRetire.waitTillRetire(TestJobRetire. 229)  Testcase: testJobRemoval took 1.073 sec",Open,Unresolved,,Unassigned,Amir Sanjar,Thu; 18 Oct 2012 21:29:11 +0000,Wed; 5 Dec 2012 14:07:08 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4732
MAPREDUCE-4733,Bug,Major,applicationmaster;mrv2,Reducer can fail to make progress during shuffle if too many reducers complete consecutively,"TaskAttemptListenerImpl implements getMapCompletionEvents by calling Job.getTaskAttemptCompletionEvents with the same fromEvent and maxEvents passed in from the reducer and then filtering the result for just map events. We can't filter the task completion event list and expect the caller's ""window"" into the list to match up.  As soon as a reducer event appears in the list it means we are redundantly sending map completion events that were already seen by the reducer.  Worst case the reducer will hang if all of the events in the requested window are reducer events.  In that case zero events will be reported back to the caller and it won't bump up fromEvent on the next call.  Reducer then never sees the final map completion events needed to complete the shuffle. This could happen in a case where all maps complete; more than MAX_EVENTS reducers complete consecutively; but some straggling reducers get fetch failures and cause a map to be restarted.",Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 18 Oct 2012 22:30:49 +0000,Thu; 2 May 2013 02:29:56 +0000,Fri; 19 Oct 2012 20:22:46 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4733
MAPREDUCE-4734,Improvement,Major,jobhistoryserver;mrv2,The history server should link back to NM logs if aggregation is incomplete / disabled,nan,Open,Unresolved,,Siddharth Seth,Siddharth Seth,Fri; 19 Oct 2012 00:06:15 +0000,Tue; 22 Apr 2014 19:15:23 +0000,,,0.23.4,,YARN-171,,https://issues.apache.org/jira/browse/MAPREDUCE-4734
MAPREDUCE-4735,Improvement,Trivial,test,Make arguments in TestDFSIO case insensitive,"It would be convenient if the arguments in TestDFSIO were case insensitive.  For example; it should allow ""-read""; ""-Read""; etc.",Resolved,Fixed,,Brandon Li,Robert Kanter,Mon; 8 Oct 2012 20:33:39 +0000,Thu; 12 May 2016 18:24:45 +0000,Fri; 19 Oct 2012 02:38:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4735
MAPREDUCE-4736,Improvement,Trivial,test,Remove obsolete option [-rootDir] from TestDFSIO,Looks like this option is obsolete. Remove it to avoid confusion.,Closed,Fixed,,Brandon Li,Brandon Li,Fri; 19 Oct 2012 04:48:26 +0000,Thu; 12 May 2016 18:24:09 +0000,Fri; 19 Oct 2012 22:05:30 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4736
MAPREDUCE-4737,Bug,Major,, Hadoop does not close output file / does not call Mapper.cleanup if exception in map,Find this in Pig unit test TestStore under Windows. There are dangling files because map does not close the file when exception happens in map(). In Windows; Hadoop will not remove a file if it is not closed. This happens in reduce() as well.,Closed,Fixed,,Arun C Murthy,Daniel Dai,Tue; 9 Oct 2012 07:45:36 +0000,Wed; 15 May 2013 05:16:14 +0000,Wed; 24 Apr 2013 17:44:11 +0000,,1-win;2.0.3-alpha;1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4737
MAPREDUCE-4738,Sub-task,Major,applicationmaster,[MAPREDUCE-3902] re-enable disabled unit tests in mr-client-app2 module,nan,Open,Unresolved,,Siddharth Seth,Siddharth Seth,Fri; 19 Oct 2012 18:36:46 +0000,Fri; 19 Oct 2012 18:43:01 +0000,,,MR-3902,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4738
MAPREDUCE-4739,Bug,Major,build;test,Some MapReduce tests fail to find winutils.,All modules inherit a setting in the Surefire configuration for HADOOP_HOME via the hadoop-project pom.xml.  This setting is a relative path used in Shell. to find winutils when running on Windows.  The MapReduce modules have a deeper directory structure; which makes the inherited value of HADOOP_HOME invalid and causes some tests to fail while calling winutils.,Resolved,Fixed,,Unassigned,Chris Nauroth,Sun; 21 Oct 2012 07:31:45 +0000,Mon; 22 Oct 2012 20:53:43 +0000,Mon; 22 Oct 2012 20:51:35 +0000,,trunk-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4739
MAPREDUCE-4740,Bug,Blocker,mrv2,only .jars can be added to the Distributed Cache classpath,Koji tracked down this one.      So; cachearchive like class.zip or class.tar.gz were never set as part of the classpath even though they were properly set by DistributedCache.addArchiveToClassPath.  It looks like we are parsing the classpath out of the configs; but then throwing that away.  It looks simple enough to add them in the correct place.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 22 Oct 2012 14:57:47 +0000,Wed; 19 Aug 2015 00:16:16 +0000,Mon; 22 Oct 2012 20:00:38 +0000,,0.23.3;2.0.2-alpha,,,MAPREDUCE-6454,https://issues.apache.org/jira/browse/MAPREDUCE-4740
MAPREDUCE-4741,Bug,Minor,applicationmaster;mrv2,WARN and ERROR messages logged during normal AM shutdown,The ApplicationMaster is logging WARN and ERROR messages during normal shutdown; and some users are misinterpreting these as serious problems.  For example:     Warnings or errors should not be logged if everything is working as intended.,Closed,Fixed,,Vinod Kumar Vavilapalli,Jason Lowe,Mon; 22 Oct 2012 15:04:50 +0000,Wed; 6 Feb 2013 17:05:36 +0000,Wed; 24 Oct 2012 15:51:33 +0000,,0.23.3;2.0.1-alpha,,,MAPREDUCE-4794;YARN-139,https://issues.apache.org/jira/browse/MAPREDUCE-4741
MAPREDUCE-4742,Bug,Trivial,test,Fix typo in nnbench#displayUsage,nan,Closed,Fixed,,Liang Xie,Liang Xie,Tue; 23 Oct 2012 07:43:33 +0000,Fri; 24 Apr 2015 23:15:16 +0000,Tue; 10 Mar 2015 15:43:37 +0000,,2.0.2-alpha;0.23.4;2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4742
MAPREDUCE-4743,Bug,Major,mrv2,Job is marking as FAILED and also throwing the Transition exception instead of KILLED when issues a KILL command,nan,Resolved,Fixed,,Devaraj K,Devaraj K,Tue; 23 Oct 2012 13:23:46 +0000,Fri; 7 Jun 2013 12:06:26 +0000,Fri; 7 Jun 2013 12:06:26 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4743
MAPREDUCE-4744,Bug,Major,mrv2,Application Master is running forever when the TaskAttempt gets TA_KILL event at the state SUCCESS_CONTAINER_CLEANUP,When the Task issues KILL event to TaskAttempt; It is expecting to get event back to the Task from TaskAttempt. If the Task Attempt state SUCCESS_CONTAINER_CLEANUP state then it is ignoring and Task is waiting.,Resolved,Duplicate,MAPREDUCE-4751,Devaraj K,Devaraj K,Tue; 23 Oct 2012 13:27:32 +0000,Fri; 26 Oct 2012 00:56:15 +0000,Fri; 26 Oct 2012 00:55:50 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4744
MAPREDUCE-4745,Bug,Major,,Application Master is hanging when the TaskImpl gets T_KILL event and completes attempts by the time  ,nan,Resolved,Duplicate,MAPREDUCE-4751,Devaraj K,Devaraj K,Tue; 23 Oct 2012 13:36:11 +0000,Fri; 26 Oct 2012 00:56:55 +0000,Fri; 26 Oct 2012 00:56:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4745
MAPREDUCE-4746,Bug,Major,applicationmaster,The MR Application Master does not have a config to set environment variables,There is no mechanism for defining environment variables (i.e. LD_LIBRARY_PATH) for the MRAppMaster.,Closed,Fixed,,Robert Parker,Robert Parker,Tue; 23 Oct 2012 21:47:27 +0000,Wed; 3 Sep 2014 23:17:17 +0000,Thu; 1 Nov 2012 17:12:57 +0000,,0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4746
MAPREDUCE-4747,Improvement,Major,mrv2,Fancy graphs for visualizing task progress,We should think about what kind of map   completion information we have.,Open,Unresolved,,Unassigned,Ravi Prakash,Wed; 24 Oct 2012 20:17:06 +0000,Wed; 27 Aug 2014 18:52:56 +0000,,,0.23.4,,,HADOOP-1894,https://issues.apache.org/jira/browse/MAPREDUCE-4747
MAPREDUCE-4748,Bug,Blocker,mrv2,Invalid event: T_ATTEMPT_SUCCEEDED at SUCCEEDED,We saw this happen when running a large pig script.     Speculative execution was enabled; and that task did speculate so it looks like this is an error in the state machine either between the task attempts or just within that single task.,Closed,Fixed,,Jason Lowe,Robert Joseph Evans,Wed; 24 Oct 2012 21:53:19 +0000,Wed; 6 Feb 2013 17:05:33 +0000,Fri; 26 Oct 2012 21:08:15 +0000,,0.23.3,,MAPREDUCE-4751,,https://issues.apache.org/jira/browse/MAPREDUCE-4748
MAPREDUCE-4749,Bug,Major,,Killing multiple attempts of a task taker longer as more attempts are killed,The following was noticed on a mr job running on hadoop 1.1.0  1. Start an mr job with 1 mapper  2. Wait for a min  3. Kill the first tempt was actually killed was as stated above.,Closed,Fixed,,Arpit Gupta,Arpit Gupta,Thu; 25 Oct 2012 00:41:44 +0000,Mon; 3 Dec 2012 07:33:57 +0000,Sat; 10 Nov 2012 02:37:05 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4749
MAPREDUCE-4750,Bug,Major,client;test,Enable NNBenchWithoutMR in MapredTestDriver,Right now; we could run nnbench from MapredTestDriver only; there's no entry for NNBenchWithoutMR; it would be better enable it explicitly; such that we can do namenode benchmark with less influence factors,Resolved,Fixed,,Liang Xie,Liang Xie,Thu; 25 Oct 2012 11:07:23 +0000,Thu; 12 May 2016 18:24:19 +0000,Fri; 8 May 2015 22:59:01 +0000,,3.0.0-alpha1,,,MAPREDUCE-5248,https://issues.apache.org/jira/browse/MAPREDUCE-4750
MAPREDUCE-4751,Bug,Major,,AM stuck in KILL_WAIT for days,We found some jobs were stuck in KILL_WAIT for days on end. The RM shows them as RUNNING. When you go to the AM; it shows it in the KILL_WAIT state; and a few maps running. All these maps were scheduled on nodes which are now in the RM's Lost nodes list. The running maps are in the FAIL_CONTAINER_CLEANUP state,Closed,Fixed,MAPREDUCE-4744;MAPREDUCE-4745,Vinod Kumar Vavilapalli,Ravi Prakash,Wed; 17 Oct 2012 20:28:04 +0000,Wed; 3 Sep 2014 23:17:17 +0000,Mon; 12 Nov 2012 16:57:21 +0000,,0.23.3;2.0.2-alpha,,MAPREDUCE-4748,,https://issues.apache.org/jira/browse/MAPREDUCE-4751
MAPREDUCE-4752,Improvement,Major,mrv2,Reduce MR AM memory usage through String Interning,"There are a lot of strings that are duplicates of one another in the AM.  This comes from all of the PB events the come across the wire and also tasks heart-beating in through the umbilical.  There are even several duplicates from Configuration.  By ""interning"" all of these strings on the Heap I have been able to reduce the resting memory usage of the AM to be about 5KB per task attempt.  With about half of this coming from counters.  This results in a 5MB heap for a typical 1000 task job; or a 500MB heap for a 100;000 task attempt job.  I think I could cut the size of the counters in half by completely rewriting how counters work in the AM and History Server; but I don't think it is worth it at this point.  I am still investigating what the memory usage of the AM is like when running very large jobs; and I will probably have a follow-up JIRA for reducing that memory usage as well.",Closed,Fixed,HADOOP-9003,Robert Joseph Evans,Robert Joseph Evans,Fri; 26 Oct 2012 14:47:52 +0000,Wed; 3 Sep 2014 23:17:17 +0000,Wed; 31 Oct 2012 15:03:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4752
MAPREDUCE-4753,Bug,Major,test,TestLocalMRNotification.testMR failed in Hudson,TestLocalMRNotification.testMR failed in Hudson; from build #3911 to the latest; build #3917.,Open,Unresolved,,Unassigned,Robert Parker,Fri; 26 Oct 2012 23:47:05 +0000,Tue; 10 Dec 2013 09:28:19 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4753
MAPREDUCE-4754,Sub-task,Major,mrv2,Job is marked as FAILED and also throwing the TransitonException instead of KILLED when issues a KILL command,nan,Resolved,Cannot Reproduce,,Unassigned,Nishan Shetty,Sat; 27 Oct 2012 04:44:47 +0000,Thu; 11 Feb 2016 18:48:38 +0000,Thu; 11 Feb 2016 18:48:38 +0000,,2.0.1-alpha;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4754
MAPREDUCE-4755,Improvement,Major,,Rewrite MapOutputBuffer to use direct buffers & allow parallel sort+collect,The MapOutputBuffer has been written with a very severe constraint on the amount of memory it can consume. This results in code that has to page-in  page-out (i.e spill) data as it passes through the map buffers.  With the advent of the  nio package; there is a fast and portable MMap alternative to handling your own buffers. This exists outside the GC space of Java and yet provides decently fast memory access to all the data.  The suggestion is that using mmap() direct buffers can be faster when a spill is involved and simpler than the current spill logic when given enough address space  uses the buffer caches to deliver best effort I O.,Resolved,Not A Problem,,Gopal V,Gopal V,Sat; 27 Oct 2012 08:37:37 +0000,Thu; 12 May 2016 18:22:59 +0000,Mon; 6 Oct 2014 19:40:24 +0000,,3.0.0-alpha1,optimization;sort,,HAMA-559;MAPREDUCE-3235,https://issues.apache.org/jira/browse/MAPREDUCE-4755
MAPREDUCE-4756,Bug,Major,jobtracker,Map completion shown is not correct if user kills the running job. ,steps to reproduce  1. submit a job in hadoop. (hadoop-0.20.1-examples.jar) 2. kill the job before its completion.  Actual Result  job status shows completion % as 100 but the total completed map is not equal to total map counts.   Expected Result completion percentage should be proper as per the actual status.,Open,Unresolved,,Unassigned,shashwat dubey,Mon; 29 Oct 2012 12:14:16 +0000,Mon; 29 Oct 2012 12:14:16 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4756
MAPREDUCE-4757,Bug,Major,webapps,Localized Progressbar values lead to broken progressbar,"The width value of the style attribute of the jQuery UI Progressbar HTML elements with class ""ui-progressbar-value"" contains a comma instead of a decimal point.(e.g. width: 11;5%)  The problem seems to be that the value is localized for the title attribute of the parentNode and that same localized value is used in the style attribute.",Open,Unresolved,,Unassigned,Dany Gielow,Tue; 30 Oct 2012 09:57:18 +0000,Tue; 30 Oct 2012 09:57:40 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4757
MAPREDUCE-4758,Bug,Major,jobhistoryserver;webapps,jobhistory web ui not showing correct # failed reducers,we had a job fail due to a reducer failing 4 times.  Unfortunately the job history UI didn't show  this particular failed reducer which lead to confusion as to why the job failed.   This reducer failed to launch all 4 task tempts.,Resolved,Duplicate,MAPREDUCE-5982,Unassigned,Thomas Graves,Tue; 30 Oct 2012 20:55:38 +0000,Thu; 12 May 2016 14:25:20 +0000,Thu; 12 May 2016 14:25:20 +0000,,0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4758
MAPREDUCE-4759,Bug,Critical,task-controller,java.io.IOException: File too large,when running mr job.one of cluster lost tasktracker some times   see the hadoop-root-tasktracker-xxx.out     2972)  see files hs_err_pid20204.log and hadoop-root-tasktracker-t0928.log to get more details,Resolved,Not A Problem,,Unassigned,zhangjianlin,Wed; 31 Oct 2012 08:44:30 +0000,Mon; 5 Nov 2012 06:28:24 +0000,Mon; 5 Nov 2012 06:28:24 +0000,,0.20.2,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-4759
MAPREDUCE-4760,Improvement,Minor,mrv2,Make a version of Counters that is composite for the job and stores the counter values in arrays,String interning reduced the size of counters a lot.  After that and the fix for a memory leak in the IPC server a job with 20000 map tasks and 3000 reducers takes about 200MB to store the state of all of the tasks.  Looking at a memory dump of the AM each task attempt has a pointer to a Counters object that is about 2kb to 3kb in size.  That means Counters account for about 56MB of the 200MB of state.  This job only had about 40 task counters in it.  Each counter stores a long value so if we stored them in a long[] instead we should only be taking up 7MB.  Also assuming that some of the counters only appear in a map task or a reduce task we should be able to have one CompositCounters for map tasks and one for reduce tasks so it would reduce the size even further.   NOTE: without this change I would expect to be able to run a 100;000 task job in the default 1024MB AM heap (875MB 150MB * 2300).,Open,Unresolved,,Unassigned,Robert Joseph Evans,Wed; 31 Oct 2012 15:11:12 +0000,Wed; 31 Oct 2012 17:38:40 +0000,,,2.0.2-alpha;0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4760
MAPREDUCE-4761,Bug,Major,applicationmaster,MR AM doesn't handle exceptions from RM correctly,The MR AM currently ignores exceptions upto a certain count irrespective of the failure type.  Exception handling on the MR AM side is totally broken; it doesn't seem to shutdown the AM on getting critical exceptions or reboot commands from the RM - another bug.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Thu; 1 Nov 2012 00:37:46 +0000,Thu; 1 Nov 2012 00:39:05 +0000,,,,,,YARN-189,https://issues.apache.org/jira/browse/MAPREDUCE-4761
MAPREDUCE-4762,Improvement,Major,,repair test org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal,The test org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal is @Ignor-ed.  Due to that several classes in package org.apache.hadoop.mapreduce.security.token have zero unit-test coverage.  The problem is that the test assumed that class org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.Renewer is used as a custom implementation of the org.apache.hadoop.security.token.TokenRenewer service; but that did not happen; because this custom service implementation was not registered.  We solved this problem by using special classloader that is invoked to find the resource META-INF org.apache.hadoop.security.token.TokenRenewer ; and supplies some custom content for it. This way the custom service implementation gets instantiated.,Resolved,Invalid,,Unassigned,Ivan A. Veselovsky,Thu; 1 Nov 2012 12:44:08 +0000,Fri; 21 Dec 2012 09:10:49 +0000,Fri; 21 Dec 2012 09:10:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4762
MAPREDUCE-4763,Improvement,Minor,,repair test org.apache.hadoop.mapreduce.security.TestUmbilicalProtocolWithJobToken,The test was @Ignor-ed; however; it passes without any additional fixes; just being un-ignored.,Closed,Fixed,,Unassigned,Ivan A. Veselovsky,Thu; 1 Nov 2012 16:24:05 +0000,Wed; 3 Sep 2014 23:17:18 +0000,Fri; 2 Nov 2012 15:07:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4763
MAPREDUCE-4764,Improvement,Major,,repair test org.apache.hadoop.mapreduce.security.TestBinaryTokenFile,the test is @Ignore-ed; and fails being enabled. Suggested to repair it to fill the coverage gap.  Problems fixed in the test:  (1) MRConfig.FRAMEWORK_NAME and YarnConfiguration.RM_PRINCIPAL properties must be correctly set in the configuration to correctly enable the security in the way this test implies.  (2) The property MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY now is not passed into the Job configuration  it is intentionally deleted from there. So; we pass the binary file name in another dedicated property.  (3) The test was using deprecated cluster classes. All them are updated to the modern analogs. (4) The delegation token found in the job context is now correctly compared to the one deserialized from the binary file.,Closed,Fixed,,Unassigned,Ivan A. Veselovsky,Thu; 1 Nov 2012 16:54:34 +0000,Wed; 3 Sep 2014 23:25:07 +0000,Mon; 26 Nov 2012 17:40:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4764
MAPREDUCE-4765,Bug,Minor,jobtracker;mrv1,Restarting the JobTracker programmatically can cause DelegationTokenRenewal to throw an exception,The DelegationTokenRenewal class has a global Timer; when you stop the JobTracker by calling stopTracker() on it (or stopJobTracker() in MiniMRCluster); the JobTracker will call close() on DelegationTokenRenewal; which cancels the Timer.  If you then start up the JobTracker again by calling startTracker() on it (or startJobTracker() in MiniMRCluster); the Timer won't necessarily be re-created; and DelegationTokenRenewal will later throw an exception when it tries to use the Timer again (because you can't reuse a canceled Timer).    DelegationTokenRenewal doesn't seem to be used in trunk; so we only need this for branch-1,Closed,Fixed,,Robert Kanter,Robert Kanter,Thu; 1 Nov 2012 19:43:43 +0000,Wed; 15 May 2013 05:15:54 +0000,Wed; 7 Nov 2012 21:13:32 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4765
MAPREDUCE-4766,Improvement,Major,mrv2,in diagnostics task ids and task attempt ids should become clickable links,It would be great if when we see a task id or a task attempt id in the diagnostics that we change it to be a clickable link.,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Thu; 1 Nov 2012 21:29:52 +0000,Wed; 16 Apr 2014 20:31:02 +0000,,,0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4766
MAPREDUCE-4767,Bug,Major,applicationmaster,AM should flush AMInfos to history file,When the ApplicationMaster starts up and generates (and potentially recovers) AMInfo records for the history file; those events should be flushed to disk in case the AM crashes badly.  Failure to do so means the AMInfos could be lost and the previous AM attempts lost upon recovery.  See discussion in MAPREDUCE-4729.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 1 Nov 2012 22:47:11 +0000,Thu; 1 Nov 2012 22:48:34 +0000,,,2.0.2-alpha;0.23.4,,,MAPREDUCE-4729,https://issues.apache.org/jira/browse/MAPREDUCE-4767
YARN-199,Bug,Major,,yarn cmd line scripts for windows,Jira tracking addition of windows equivalents for yarn; yarn-config and yarn-env shell scripts.,Resolved,Fixed,,Ivan Mitic,Ivan Mitic,Fri; 2 Nov 2012 22:40:26 +0000,Sat; 27 Apr 2013 07:36:01 +0000,Mon; 12 Nov 2012 20:02:38 +0000,,trunk-win,,,MAPREDUCE-5187,https://issues.apache.org/jira/browse/YARN-199
MAPREDUCE-4769,Bug,Major,pipes,Pipes build problem with recent OpenSSL libs,Seems to be a problem with CMake not figuring that the linker needs -lcrypto too with recent OpenSSL. Observed on two CentOS 6 build servers occurring after 'yum update' pulled down an openssl-devel update.     This works around the problem:     Builds with -Pnative won't complete without this.,Resolved,Duplicate,MAPREDUCE-6536,Unassigned,Andrew Purtell,Sat; 3 Nov 2012 02:38:37 +0000,Thu; 12 May 2016 18:23:35 +0000,Fri; 6 Nov 2015 01:24:36 +0000,,2.0.3-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4769
MAPREDUCE-4770,Bug,Major,tasktracker,Hadoop jobs failing with FileNotFound Exception while the job is still running,"We are having a strange issue in our Hadoop cluster. We have noticed that some of our jobs fail with the with a file not found exceptionsee below. Basically the files in the ""attempt_*"" directory and the directory itself are getting deleted while the task is still being run on the host. Looking through some of the hadoop documentation I see that the job directory gets wiped out when it gets a KillJobAction however I am not sure why it gets wiped out while the job is still running.  My question is what could be deleting it while the job is running? Any thoughts or pointers on how to debug this would be helpful.  Thanks!   253)",Open,Unresolved,,Unassigned,Jaikannan Ramamoorthy,Mon; 5 Nov 2012 02:19:23 +0000,Fri; 25 Jan 2013 05:25:14 +0000,,,0.20.203.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4770
MAPREDUCE-4771,Bug,Major,mrv2,KeyFieldBasedPartitioner not partitioning properly when configured,Relative to Hadoop 0.20 1.x; KeyFieldBasedPartitioner is not distributing across partitions properly when configured.  This is related to the double-configure issue as described in HADOOP-7425.  KeyFieldBasedPartitioner is getting configured twice; and that ends up duplicating the keyspecs and causing the keys to be hashed twice.  KeyFieldBasedPartitioner should not duplicate keyspecs when configured twice.,Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 5 Nov 2012 19:13:20 +0000,Wed; 3 Sep 2014 23:17:19 +0000,Mon; 5 Nov 2012 22:32:36 +0000,,0.23.3;2.0.1-alpha,,,HADOOP-7425,https://issues.apache.org/jira/browse/MAPREDUCE-4771
MAPREDUCE-4772,Bug,Critical,mrv2,Fetch failures can take way too long for a map to be restarted,In one particular case we saw a NM go down  we don't ever have the reducer waiting for days to try and fetch map output.,Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Mon; 5 Nov 2012 20:19:26 +0000,Wed; 3 Sep 2014 23:17:18 +0000,Thu; 8 Nov 2012 15:27:38 +0000,,0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4772
MAPREDUCE-4773,Improvement,Major,,MultipleOutput with different output path for each ,"Is it possible to have multiple outputs in a map reduce code where each output is directed to a different path ?  e.g.  FileOutputFormat.setOutputPath(job; new Path(outputPath));  MultipleOutputs.addNamedOutput(job; ""Output 1""; TextOutputFormat.class; Text.class; Text.class);  MultipleOutputs.addNamedOutput(job; ""Output 2""; TextOutputFormat.class; Text.class; Text.class);  Can ""Output 1""  ""Output 2"" be alloted seperate paths ?",Resolved,Not A Problem,,Unassigned,Rohit Dandona,Tue; 6 Nov 2012 06:35:02 +0000,Tue; 6 Nov 2012 15:23:46 +0000,Tue; 6 Nov 2012 15:23:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4773
MAPREDUCE-4774,Bug,Major,applicationmaster;mrv2,JobImpl does not handle asynchronous task events in FAILED state,"The test org.apache.hadoop.mapred.TestClusterMRNotification.testMR frequently  fails in mapred build (e.g. see https: ).  The test aims to check Job status notifications received through HTTP Servlet. It runs 3 jobs: successfull; killed; and failed.  The test expects the servlet to receive some expected notifications in some expected order. It also tries to test the retry-on-failure notification functionality; so on each 1st notification the servlet answers ""400 forcing error""; and on each 2nd notification  FAILED"".  Need an expert advice on how that should be fixed.",Closed,Fixed,MAPREDUCE-4816,Jason Lowe,Ivan A. Veselovsky,Tue; 6 Nov 2012 11:28:43 +0000,Wed; 3 Sep 2014 23:17:19 +0000,Fri; 9 Nov 2012 23:20:38 +0000,,0.23.3;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4774
MAPREDUCE-4775,Bug,Major,mrv2,"Reducer will ""never"" commit suicide",In 1.0 there are a number of conditions that will cause a reducer to commit suicide and exit.  This includes if it is stalled; if the error percentage of total fetches is too high.  In the new code it will only commit suicide when the total number of failures for a single task attempt is = max(30; totalMaps 10).  In the best case with the quadratic back-off to get a single map attempt to reach 30 failure it would take 20.5 hours.  And unless there is only one reducer running the map task would have been restarted before then.  We should go back to include the same reducer suicide checks that are in 1.0,Open,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Tue; 6 Nov 2012 19:12:01 +0000,Wed; 16 Apr 2014 20:36:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4775
MAPREDUCE-4776,New Feature,Major,,Reducer Channels,"A Google paper on LDA from 2009  which can be found at http: values written to the job OutputCollector are part of the reduce phase.""  The proposed change would address this limitation of MultipleOutputs.",Open,Unresolved,,Unassigned,Craig Macdonald,Wed; 7 Nov 2012 12:51:10 +0000,Wed; 7 Nov 2012 12:51:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4776
MAPREDUCE-4777,Improvement,Minor,,In TestIFile; testIFileReaderWithCodec relies on testIFileWriterWithCodec,The file used to test reading is expected to have been created by the file used to test writing,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 23 Oct 2012 23:13:26 +0000,Fri; 15 Feb 2013 13:09:51 +0000,Wed; 7 Nov 2012 14:13:35 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4777
MAPREDUCE-4778,Bug,Major,jobtracker;scheduler,Fair scheduler event log is only written if directory exists on HDFS,The fair scheduler event log is supposed to be written to the local filesystem; at  {hadoop.log.dir}  fairscheduler.  The event log will not be written unless this directory exists on HDFS.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 7 Nov 2012 19:16:28 +0000,Fri; 15 Feb 2013 13:10:08 +0000,Wed; 28 Nov 2012 14:43:57 +0000,,1.1.0;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4778
MAPREDUCE-4779,Bug,Major,test,Unit test TestJobTrackerSafeMode fails with  ant 1.8.3+,Problem:   JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4: Solution:  Migrate the testcase to JUnit4,Resolved,Won't Fix,,Amir Sanjar,Amir Sanjar,Wed; 7 Nov 2012 20:38:23 +0000,Sat; 26 Nov 2016 02:03:26 +0000,Sat; 26 Nov 2016 02:03:26 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4779
MAPREDUCE-4780,Bug,Major,build,MapReduce distribution build fails on Windows,Distribution build relies on sh scripts that do not work on Windows.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Wed; 7 Nov 2012 23:49:13 +0000,Mon; 12 Nov 2012 20:55:10 +0000,Mon; 12 Nov 2012 19:40:19 +0000,,trunk-win,,,HADOOP-9008;HDFS-4163;YARN-207;HADOOP-9008;HDFS-4163;MAPREDUCE-4790;YARN-207,https://issues.apache.org/jira/browse/MAPREDUCE-4780
MAPREDUCE-4781,Bug,Major,,Unit test TestKerberosAuthenticationHandler fails with ant 1.8.3+,"Problem: JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4: Solution: Migrate the testcase to JUnit4 How:  Remove extends TestCase""  SetUp and TearDown methods  @Override protected void setUp() throws Exception { }  replaced by:  @Before public void setUp() throws Exception { }  Same for tearDown():  @Override protected void tearDown() throws Exception { }  replaced by  @After public void tearDown() throws Exception { }  Imports  The imports has to be reorganized:     Remove import junit.framework.TestCase;     Add org.junit.*; or import org.junit.After; import org.junit.Before;   import org.junit.Test;",Open,Unresolved,,Unassigned,Amir Sanjar,Thu; 8 Nov 2012 14:30:21 +0000,Wed; 14 Nov 2012 19:57:54 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4781
MAPREDUCE-4782,Bug,Blocker,client,NLineInputFormat skips first line of last InputSplit,NLineInputFormat creates FileSplits that are then used by LineRecordReader to generate Text values. To deal with an idiosyncrasy of LineRecordReader; the begin and length fields of the FileSplit are constructed differently for the first FileSplit vs. the rest.  After looping through all lines of a file; the final FileSplit is created; but the creation does not respect the difference of how the first vs. the rest of the FileSplits are created.  This results in the first line of the final InputSplit being skipped. I've created a patch to NLineInputFormat; and this fixes the problem.,Closed,Fixed,,Mark Fuhs,Mark Fuhs,Thu; 8 Nov 2012 19:54:57 +0000,Tue; 10 Mar 2015 04:30:13 +0000,Fri; 9 Nov 2012 16:03:41 +0000,,0.22.0;0.23.0;1.0.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4782
MAPREDUCE-4783,Bug,Minor,build,data_join mavenization broke the mr1 build,MR-4238 didn't update build.xml and forgot to nuke the old data_join directory.,Resolved,Duplicate,MAPREDUCE-4266,Eli Collins,Eli Collins,Fri; 9 Nov 2012 02:37:54 +0000,Fri; 9 Nov 2012 21:04:21 +0000,Fri; 9 Nov 2012 21:04:21 +0000,,,,,MAPREDUCE-4238,https://issues.apache.org/jira/browse/MAPREDUCE-4783
MAPREDUCE-4784,Bug,Major,mrv2;test,TestRecovery occasionally fails,TestRecovery is occasionally failing with this error:,Resolved,Fixed,,Haibo Chen,Jason Lowe,Sat; 10 Nov 2012 23:41:47 +0000,Tue; 30 Aug 2016 14:20:47 +0000,Tue; 30 Aug 2016 14:13:21 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4784
MAPREDUCE-4785,Bug,Major,mrv2;test,TestMRApp occasionally fails,TestMRApp is failing occasionally with this error:,Closed,Fixed,,Haibo Chen,Jason Lowe,Sat; 10 Nov 2012 23:58:09 +0000,Fri; 6 Jan 2017 01:00:29 +0000,Fri; 4 Mar 2016 00:42:02 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4785
MAPREDUCE-4786,Bug,Major,mrv2,Job End Notification retry interval is 5 milliseconds by default,"Courtesy Steven Willis and Harsh J  From: Harsh J I believe the configs of the latter of both of the above classifications were meant to be added in as replacement names; but the property names got added in wrong (as the former older named ones) in the XML.  the word ""seconds"" in the description of retries? The code in MR2's JobEndNotifier seems to expect seconds but uses it directly in Thread.sleep( ) without making it milliseconds; which may be a bug we need to fix as well; perhaps in a same issue as the configs ones.  On Fri; Nov 9; 2012 at 11:21 PM; Steven Willis swillis@compete.com wrote:  And I noticed that there are some duplicate properties with different values and different descriptions:",Closed,Fixed,,Ravi Prakash,Ravi Prakash,Mon; 12 Nov 2012 06:25:02 +0000,Thu; 12 May 2016 18:23:02 +0000,Mon; 12 Nov 2012 20:54:44 +0000,,2.0.2-alpha;0.23.4;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4786
MAPREDUCE-4787,Bug,Major,test,TestJobMonitorAndPrint is broken,Tests run: 1; Failures: 0; Errors: 1; Skipped: 0; Time elapsed: 1.169 sec &lt; FAILURE! testJobMonitorAndPrint(org.apache.hadoop.mapreduce.TestJobMonitorAndPrint)  Time elapsed: 1105 sec  &lt; ERROR!  75),Closed,Fixed,,Robert Parker,Ravi Prakash,Mon; 12 Nov 2012 15:04:19 +0000,Thu; 12 May 2016 18:23:17 +0000,Mon; 12 Nov 2012 17:08:29 +0000,,2.0.3-alpha;0.23.5;3.0.0-alpha1,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-4787
MAPREDUCE-4788,Bug,Major,applicationmaster,Job are marking as FAILED even if there are no failed tasks in it,Sometimes Jobs are marking as FAILED and some the tasks are marking as KILLED in it.    In MRAppMaster; JobFinishEvent is triggering and waiting for the 5000 millis. If any tasks final state is unknown by this time those tasks are marking as KILLED and Job state is marking as FAILED.,Open,Unresolved,,Unassigned,Devaraj K,Mon; 12 Nov 2012 16:27:13 +0000,Sat; 7 Jan 2017 01:59:53 +0000,,,2.6.0,,,MAPREDUCE-4951;MAPREDUCE-3629,https://issues.apache.org/jira/browse/MAPREDUCE-4788
MAPREDUCE-4789,Bug,Major,mrv1,Map Reduce Counters are 0 on the Job Tracker job details page,Counters on the jobtracker details page are 0 for map and reduce columns. This is reproduced using a simple wordcount. Of note is that customer counters show properly.,Resolved,Invalid,,Unassigned,Jeff Lord,Mon; 12 Nov 2012 16:38:21 +0000,Mon; 12 Nov 2012 19:38:35 +0000,Mon; 12 Nov 2012 19:38:35 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4789
MAPREDUCE-4790,Bug,Major,build,MapReduce build script would be more readable using abspath,This is a follow-up to MAPREDUCE-4780; which was resolved before addressing some feedback to use abspath instead of normpath for improved readability in the build script.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Mon; 12 Nov 2012 20:53:58 +0000,Tue; 13 Nov 2012 22:20:56 +0000,Tue; 13 Nov 2012 22:20:56 +0000,,trunk-win,,,MAPREDUCE-4780,https://issues.apache.org/jira/browse/MAPREDUCE-4790
MAPREDUCE-4791,Improvement,Minor,documentation,Javadoc for KeyValueTextInputFormat should include default separator and how to change it,"The  oc for KeyValueTextInputFormat says ""Each line is divided into key and value parts by a separator byte"" but it doesn't say what the separator byte is or how to change it.  After some exploration I noticed that the default is the Tab character and that the value can be changed by the JobConf value ""key.value.separator.in.input.line""",Closed,Fixed,,Akira Ajisaka,Matt Lavin,Tue; 13 Nov 2012 02:06:44 +0000,Mon; 1 Dec 2014 03:10:02 +0000,Thu; 14 Aug 2014 15:43:56 +0000,,1.1.0;2.2.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-4791
MAPREDUCE-4792,Bug,Major,test,Unit Test TestJobTrackerRestartWithLostTracker fails with ant-1.8.4,"Problem: JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4: Solution: Migrate the testcase to JUnit4; including:  	Remove extends TestCase"" 	Remove import junit.framework.TestCase; 	Add import org.junit.*; 	Use appropriate annotations such as @After; @Before; @Test.",Closed,Fixed,,Amir Sanjar,Amir Sanjar,Tue; 13 Nov 2012 18:46:22 +0000,Mon; 3 Dec 2012 07:33:57 +0000,Mon; 19 Nov 2012 06:06:37 +0000,,1.0.3;1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4792
MAPREDUCE-4793,Bug,Major,,Problem with adding resources when using both -files and -file to hadoop streaming,"It seems when both -files and -file are present; it will trigger this IAE; and the error message is just misleading.   hadoop jar $HADOOP_PREFIX job_1351804437209_0575 Exception in thread ""main""  288)",Resolved,Fixed,,Jason Lowe,Thomas Graves,Tue; 13 Nov 2012 19:14:47 +0000,Sat; 22 Dec 2012 13:21:32 +0000,Fri; 21 Dec 2012 23:14:27 +0000,,0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4793
MAPREDUCE-4794,Bug,Major,applicationmaster,DefaultSpeculator generates error messages on normal shutdown,DefaultSpeculator can log the following error message on a normal shutdown of the ApplicationMaster:     and in addition for some reason it logs the corresponding backtrace to stdout.  Like the errors fixed in MAPREDUCE-4741; this error message in the syslog and backtrace on stdout can be confusing to users as to whether the job really succeeded.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 14 Nov 2012 01:05:42 +0000,Wed; 3 Sep 2014 22:57:02 +0000,Sat; 2 Mar 2013 03:50:47 +0000,,0.23.3;2.0.1-alpha,usability,,MAPREDUCE-4741,https://issues.apache.org/jira/browse/MAPREDUCE-4794
MAPREDUCE-4795,Improvement,Major,,TestDelegationTokenRenewal should not use static variables in Renewer,TestDelegationTokenRenewal uses static variables to access what's going on inside its Renewer class; making it so problems can occur if the tests are run in parallel.,Resolved,Not A Problem,,Sandy Ryza,Sandy Ryza,Wed; 14 Nov 2012 01:36:16 +0000,Fri; 7 Dec 2012 23:57:17 +0000,Fri; 7 Dec 2012 21:31:41 +0000,,1.0.4,,,MAPREDUCE-4860;YARN-264,https://issues.apache.org/jira/browse/MAPREDUCE-4795
MAPREDUCE-4796,Bug,Major,task;tasktracker,Corrupt map outputs created via native Snappy compression,"I am observing cases where a single host in a cluster of 150 slaves ""goes bad"" w.r.t. Snappy compression  Many; but not all; of its map-phase tasks produce the buggy exception message "" lang.InternalError"" (see HADOOP-8151) during on-disk merging; and then a smattering of reducer tasks across the cluster report the same message on every attempt during the ""reduce  reduce"" phase; leading to job failure with no manual intervention.  If I log into the rogue host and kill its tasktracker process while the job is still running; Hadoop's self-healing (rescheduling the map tasks from the dead tasktracker) seems to fix the next reducer attempt for each of the formerly-doomed reducer tasks; and the job succeeds.  Subsequent jobs on the same cluster show a different message on occasion as well on that same bad host: ""org.apache.hadoop.fs.ChecksumException: Checksum Error"".  This evidence leads me to believe that some of the intermediate map output was corrupted by the file system; but this condition was only caught when those writes occurred during merging (and not caught when the last write was the corrupt one).  The strategy for aggressively detecting shuffle failures via exception regex matching (MAPREDUCE-2529) might be useful as a way to solve this case as well; if a tasktracker process could commit suicide if it detected this issue often enough; we would have no reason to manually intervene.  Unfortunately; I'm only seeing this message show up after the shuffle phase is finished; we would need to scan for this exception during the map phase.  I did not see this issue occur on the previous version of Hadoop we were using on Amazon EMR (0.20) using lzo compression for intermediate map outputs.",Open,Unresolved,,Unassigned,Joshua Caplan,Wed; 14 Nov 2012 01:51:51 +0000,Wed; 14 Nov 2012 01:51:51 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4796
MAPREDUCE-4797,Bug,Major,applicationmaster,LocalContainerAllocator can loop forever trying to contact the RM,If LocalContainerAllocator has trouble communicating with the RM it can end up retrying forever if the nature of the error is not a YarnException.  This can be particulary bad if the connection went down because the cluster was reset such that the RM and NM have lost track of the process and therefore nothing else will eventually kill the process.  In this scenario; the looping AM continues to pelt the RM with connection requests every second using a stale token; and the RM logs the SASL exceptions over and over.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 14 Nov 2012 02:15:10 +0000,Wed; 3 Sep 2014 23:17:19 +0000,Wed; 14 Nov 2012 23:09:56 +0000,,0.23.3;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4797
MAPREDUCE-4798,Bug,Minor,jobhistoryserver;test,TestJobHistoryServer fails some times with 'java.lang.AssertionError: Address already in use',"UT Failure in IHC 1.0.3: org.apache.hadoop.mapred.TestJobHistoryServer. This UT fails sometimes.  The error message is: 'Testcase: testHistoryServerStandalone took 5.376 sec 	Caused an ERROR Address already in use  113)'",Closed,Fixed,MAPREDUCE-3135,sam liu,sam liu,Wed; 14 Nov 2012 03:08:47 +0000,Tue; 28 Jan 2014 05:42:22 +0000,Sun; 2 Dec 2012 00:34:00 +0000,,1.0.3,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4798
MAPREDUCE-4799,Bug,Minor,mrv2,Task Attempts Page has tools open; not job,"When you go the the task attempts page either on the running AM or the history server the ""Tools"" section on the left is open; when it should be the ""Job"" section.",Open,Unresolved,,Unassigned,Robert Joseph Evans,Wed; 14 Nov 2012 15:33:17 +0000,Wed; 14 Nov 2012 15:33:17 +0000,,,0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4799
MAPREDUCE-4800,Bug,Minor,,Cleanup o.a.h.mapred.MapTaskStatus - remove unused code,o.a.h.mapred.MapTaskStatus gets and sets sortFinishTime which is not accessed anywhere.  Also setFinishTime should getter setter instead of accessing fields directly.,Resolved,Fixed,,Karthik Kambatla,Karthik Kambatla,Wed; 14 Nov 2012 18:00:14 +0000,Mon; 3 Nov 2014 18:33:58 +0000,Sat; 17 Nov 2012 06:17:16 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4800
MAPREDUCE-4801,Bug,Critical,,ShuffleHandler can generate large logs due to prematurely closed channels,"We ran into an instance where many nodes on a cluster ran out of disk space because the nodemanager logs were huge.  Examining the logs showed many; many shuffle errors due to either ClosedChannelException or IOException from ""Connection reset by peer"" or ""Broken pipe"".",Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 15 Nov 2012 20:04:50 +0000,Wed; 3 Sep 2014 23:17:18 +0000,Fri; 16 Nov 2012 01:07:14 +0000,,0.23.3;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4801
MAPREDUCE-4802,Improvement,Major,mr-am;mrv2;webapps,Takes a long time to load the task list on the AM for large jobs,We should turn on deferred rendering in DataTables as suggested by Luke here: https: YARN-151?focusedCommentId=13475811page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13475811,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 16 Nov 2012 05:40:12 +0000,Thu; 12 May 2016 18:22:40 +0000,Fri; 16 Nov 2012 17:35:14 +0000,,2.0.2-alpha;0.23.4;3.0.0-alpha1,,,MAPREDUCE-4720,https://issues.apache.org/jira/browse/MAPREDUCE-4802
MAPREDUCE-4803,Test,Minor,test,Duplicate copies of TestIndexCache.java,I am not sure whether it was intentional; but I found two identical copies of TestIndexCache. one in hadoop-mapreduce-client-core and the other in hadoop-mapreduce-client-jobclient.  If someone confirms me it was not intentional; I can submit a small patch on this.,Closed,Fixed,,Mariappan Asokan,Mariappan Asokan,Fri; 16 Nov 2012 17:32:40 +0000,Fri; 15 Feb 2013 13:10:05 +0000,Mon; 28 Jan 2013 19:21:51 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4803
MAPREDUCE-4804,Improvement,Major,applicationmaster,Counters for the applicationmaster,We should provide counters for the AM itself to track interesting items such as time spent garbage collecting; cpu time spent; etc.  Currently there are no counters specifically for the AM; so it's difficult to tell if the AM is running very low on heap space; spending a lot of time thrashing in garbage collecting; and slowing down the job in general.  There are some details to work out on how these counters are tracked within the job.  Should they be top-level job counters; or instead should they be treated like a separate task type and therefore rolled into the corresponding collection of GC and CPU counters for all tasks at the job level?,Open,Unresolved,MAPREDUCE-5469,Unassigned,Jason Lowe,Fri; 16 Nov 2012 21:21:28 +0000,Tue; 20 Aug 2013 13:30:11 +0000,,,0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4804
MAPREDUCE-4805,Bug,Blocker,applicationmaster,History files are not move to where the history server sees them,It looks like MAPREDUCE-4723 added in a default case to the JobHistoryEventHandler that is causing it to have lots of issues for events that should just be ignored.,Resolved,Not A Problem,,Robert Joseph Evans,Robert Joseph Evans,Fri; 16 Nov 2012 21:29:34 +0000,Thu; 12 May 2016 18:24:40 +0000,Mon; 19 Nov 2012 16:55:38 +0000,,2.0.3-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4805
MAPREDUCE-4806,Bug,Major,mrv1,Cleanup: Some (5) private methods in JobTracker.RecoveryManager are not used anymore after MAPREDUCE-3837,"MAPREDUCE-3837 re-organized the job recovery code; moving out the code that was using the methods in RecoveryManager.  Now; the following methods in {{JobTracker.RecoveryManager}}seem to be unused:  	updateJob() 	updateTip() 	createTaskAttempt() 	addSuccessfulAttempt() 	addUnsuccessfulAttempt()",Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 16 Nov 2012 23:32:08 +0000,Mon; 3 Nov 2014 18:33:44 +0000,Thu; 20 Dec 2012 15:55:08 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4806
MAPREDUCE-4807,Sub-task,Major,,Allow MapOutputBuffer to be pluggable,Allow MapOutputBuffer to be pluggable,Closed,Fixed,,Mariappan Asokan,Arun C Murthy,Mon; 19 Nov 2012 19:28:28 +0000,Fri; 15 Feb 2013 13:09:53 +0000,Thu; 29 Nov 2012 18:47:26 +0000,,2.0.2-alpha,,,MAPREDUCE-4977,https://issues.apache.org/jira/browse/MAPREDUCE-4807
MAPREDUCE-4808,New Feature,Major,,Refactor MapOutput and MergeManager to facilitate reuse by Shuffle implementations,Now that Shuffle is pluggable (MAPREDUCE-4049); it would be convenient for alternate implementations to be able to reuse portions of the default implementation.   This would come with the strong caveat that these classes are LimitedPrivate and Unstable.,Closed,Fixed,,Mariappan Asokan,Arun C Murthy,Mon; 19 Nov 2012 19:28:56 +0000,Mon; 27 Apr 2015 23:45:07 +0000,Tue; 22 Jan 2013 14:12:21 +0000,,,,,MAPREDUCE-6332,https://issues.apache.org/jira/browse/MAPREDUCE-4808
MAPREDUCE-4809,Sub-task,Major,,Change visibility of classes for pluggable sort changes,Make classes required for MAPREDUCE-2454 to be  public (with LimitedPrivate),Closed,Fixed,,Mariappan Asokan,Arun C Murthy,Mon; 19 Nov 2012 19:29:49 +0000,Fri; 15 Feb 2013 13:09:54 +0000,Wed; 28 Nov 2012 15:23:38 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4809
MAPREDUCE-4810,Improvement,Minor,applicationmaster,Add admin command options for ApplicationMaster,It would be nice if the MR ApplicationMaster had the notion of admin options in addition to the existing user options much like we have for map and reduce tasks; e.g.: mapreduce.admin.map.child. opts.  This allows site-wide configuration options for MR AMs but still allows a user to easily override the heap size of the AM without worrying about dropping other admin-specified options.,Closed,Fixed,,Jerry Chen,Jason Lowe,Mon; 19 Nov 2012 22:31:21 +0000,Fri; 15 Feb 2013 13:09:54 +0000,Wed; 9 Jan 2013 06:34:00 +0000,,2.0.2-alpha;0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4810
MAPREDUCE-4811,Improvement,Minor,jobhistoryserver;mrv2,JobHistoryServer should show when it was started in WebUI About page,Unlike the RM; the JHS doesn't show when it was started.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Tue; 20 Nov 2012 17:28:40 +0000,Thu; 12 May 2016 18:24:36 +0000,Thu; 22 Nov 2012 00:13:57 +0000,,2.0.2-alpha;0.23.4;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4811
MAPREDUCE-4812,New Feature,Major,,Create reduce input merger plugin in ReduceTask.java and pass it to Shuffle,This is part of MAPREDUCE-2454.  This further breaks down MAPREDUCE-4808,Resolved,Duplicate,MAPREDUCE-4808,Mariappan Asokan,Mariappan Asokan,Tue; 20 Nov 2012 19:51:06 +0000,Mon; 17 Dec 2012 23:15:53 +0000,Sat; 15 Dec 2012 20:50:23 +0000,,2.0.2-alpha,,,MAPREDUCE-4049,https://issues.apache.org/jira/browse/MAPREDUCE-4812
MAPREDUCE-4813,Bug,Critical,applicationmaster,AM timing out during job commit,The AM calls the output committer's commitJob method synchronously during JobImpl state transitions; which means the JobImpl write lock is held the entire time the job is being committed.  Holding the write lock prevents the RM allocator thread from heartbeating to the RM.  Therefore if committing the job takes too long (e.g.: the job has tons of files to commit and or the namenode is bogged down) then the AM appears to be unresponsive to the RM and the RM kills the AM attempt.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 21 Nov 2012 15:31:26 +0000,Wed; 3 Sep 2014 23:25:07 +0000,Fri; 28 Dec 2012 15:10:39 +0000,,0.23.3;2.0.1-alpha,,,MAPREDUCE-4819,https://issues.apache.org/jira/browse/MAPREDUCE-4813
MAPREDUCE-4814,Bug,Major,,mr-jobhistory-daemon.sh does not parse --config options,nan,Resolved,Duplicate,MAPREDUCE-4712,Unassigned,Anatoli Fomenko,Wed; 21 Nov 2012 15:40:51 +0000,Mon; 26 Nov 2012 21:02:52 +0000,Mon; 26 Nov 2012 21:02:52 +0000,,2.0.2-alpha,,BIGTOP-713,,https://issues.apache.org/jira/browse/MAPREDUCE-4814
MAPREDUCE-4815,Improvement,Major,mrv2,Speed up FileOutputCommitter#commitJob for many output files,If a job generates many files to commit then the commitJob method call at the end of the job can take minutes.  This is a performance regression from 1.x; as 1.x had the tasks commit directly to the final output directory as they were completing and commitJob had very little to do.  The commit work was processed in parallel and overlapped the processing of outstanding tasks.  In 0.23 2.x; the commit is single-threaded and waits until all tasks have completed before commencing.,Closed,Fixed,,Siqi Li,Jason Lowe,Wed; 21 Nov 2012 16:47:19 +0000,Tue; 19 Apr 2016 16:48:00 +0000,Tue; 10 Mar 2015 19:01:13 +0000,,0.23.3;2.0.1-alpha;2.4.1,perfomance,,MAPREDUCE-6275;MAPREDUCE-5485,https://issues.apache.org/jira/browse/MAPREDUCE-4815
MAPREDUCE-4816,Bug,Major,applicationmaster,JobImpl Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED,Saw this in an AM log of a task that had failed:,Resolved,Duplicate,MAPREDUCE-4774,Unassigned,Jason Lowe,Thu; 22 Nov 2012 00:26:15 +0000,Wed; 23 Apr 2014 20:04:21 +0000,Wed; 23 Apr 2014 20:04:21 +0000,,0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4816
MAPREDUCE-4817,Bug,Critical,applicationmaster;mr-am,Hardcoded task ping timeout kills tasks localizing large amounts of data,When a task is launched and spends more than 5 minutes localizing files; the AM will kill the task due to ping timeout.  The AM's TaskHeartbeatHandler currently tracks tasks via a progress timeout and a ping timeout.  The progress timeout can be controlled via mapreduce.task.timeout and even disabled by setting the property to 0.  The ping timeout; however; is hardcoded to 5 minutes and cannot be configured.  Therefore if the task takes too long localizing; it never gets running in order to ping back to the AM and the AM kills it due to ping timeout.,Closed,Fixed,,Thomas Graves,Jason Lowe,Thu; 22 Nov 2012 01:55:30 +0000,Wed; 3 Sep 2014 23:25:07 +0000,Wed; 28 Nov 2012 19:25:04 +0000,,0.23.3;2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4817
MAPREDUCE-4818,Improvement,Major,mr-am,Easier identification of tasks that timeout during localization,When a task is taking too long to localize and is killed by the AM due to task timeout; the job UI history is not very helpful.  The attempt simply lists a diagnostic stating it was killed due to timeout; but there are no logs for the attempt since it never actually got started.  There are log messages on the NM that show the container never made it past localization by the time it was killed; but users often do not have access to those logs.,Patch Available,Unresolved,,Siqi Li,Jason Lowe,Thu; 22 Nov 2012 02:04:22 +0000,Wed; 6 May 2015 03:33:54 +0000,,,0.23.3;2.0.3-alpha,BB2015-05-TBR;usability,,,https://issues.apache.org/jira/browse/MAPREDUCE-4818
MAPREDUCE-4819,Bug,Blocker,mr-am,AM can rerun job after reporting final job status to the client,If the AM reports final job status to the client but then crashes before unregistering with the RM then the RM can run another AM attempt.  Currently AM re-attempts assume that the previous attempts did not reach a final job state; and that causes the job to rerun (from scratch; if the output format doesn't support recovery).  Re-running the job when we've already told the client the final status of the job is bad for a number of reasons.  If the job failed; it's confusing at best since the client was already told the job failed but the subsequent attempt could succeed.  If the job succeeded there could be data loss; as a subsequent job launched by the client tries to consume the job's output as input just as the re-attempt starts removing output files in preparation for the output commit.,Closed,Fixed,YARN-243,Bikas Saha,Jason Lowe,Mon; 26 Nov 2012 19:03:22 +0000,Wed; 3 Sep 2014 23:25:06 +0000,Fri; 4 Jan 2013 20:44:44 +0000,,0.23.3;2.0.1-alpha,,,MAPREDUCE-5476;MAPREDUCE-4831;MAPREDUCE-4813;MAPREDUCE-4832;MAPREDUCE-4913,https://issues.apache.org/jira/browse/MAPREDUCE-4819
OOZIE-1290,Bug,Major,core,Need to get rid of OOZIE-1089 workaround,"This seems a combination of issues that are being exposed in 2.0.2-alpha by MAPREDUCE-4549.  MAPREDUCE-4549 introduces a check to to ensure there are not duplicate JARs in the distributed-cache (using the JAR name as identity).  In Hadoop 2 (different from Hadoop 1); all JARs in the distributed-cache are symlink-ed to the current directory of the task.  MRApps; when setting up the DistributedCache (MRApps#setupDistributedCache-parseDistributedCacheArtifacts) assumes that the local resources (this includes files in the CURRENT_DIR . The dup check should be done among distributed-cached entries only.  It seems YARNRunner is symlink-ing all files in the distributed cached in the current directory. In Hadoop 1 this was done only for files added to the distributed-cache using a fragment (ie ""#FOO"") to trigger a symlink creation.   Marking as a blocker because without a fix for this; Oozie cannot submit jobs to Hadoop 2 (i've debugged Oozie in a live cluster being used by BigTop thanks Roman to test their release work; and I've verified that Oozie 3.3 does not create duplicated entries in the distributed-cache)",Open,Unresolved,,Unassigned,Alejandro Abdelnur,Mon; 26 Nov 2012 20:02:15 +0000,Wed; 3 Aug 2016 18:40:20 +0000,,,3.3.1;3.3.2,,,BIGTOP-890,https://issues.apache.org/jira/browse/OOZIE-1290
MAPREDUCE-4821,Bug,Major,test,Unit Test: TestJobTrackerRestart fails when it is run with ant-1.8.4,"Problem: JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4: Solution: Migrate the testcase to JUnit4; including:  	Remove extends TestCase"" 	Remove import junit.framework.TestCase; 	Add import org.junit.*; 	Use appropriate annotations such as @After; @Before; @Test.    uploading a patch shortly",Resolved,Won't Fix,,Unassigned,Amir Sanjar,Mon; 26 Nov 2012 22:44:18 +0000,Sat; 26 Nov 2016 01:58:39 +0000,Sat; 26 Nov 2016 01:58:37 +0000,,1.0.3;1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4821
MAPREDUCE-4822,Improvement,Trivial,jobhistoryserver,Unnecessary conversions in History Events,There are a number of conversions in the Job History Event classes that are totally unnecessary.  It appears that they were originally used to convert from the internal avro format; but now many of them do not pull the values from the avro they store them internally.  For example:      The code currently is taking an enum; converting it to a string and then asking the same enum to convert it back to an enum.  If  work properly this should be a noop and a reference to the original taskType should be returned.  There are several places that a string is having toString called on it; and since strings are immutable it returns a reference to itself.  The various ids are not immutable and probably should not be changed at this point.,Closed,Fixed,,Chu Tong,Robert Joseph Evans,Tue; 27 Nov 2012 15:46:46 +0000,Fri; 15 Feb 2013 13:10:05 +0000,Wed; 6 Feb 2013 23:04:54 +0000,,0.23.4,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4822
MAPREDUCE-4823,Bug,Minor,jobhistoryserver,NPE in jobhistory.jsp,asking for the job history page resulted in a stack trace instead of (an empty) job history,Open,Unresolved,,Unassigned,Steve Loughran,Tue; 27 Nov 2012 15:51:04 +0000,Tue; 27 Nov 2012 15:53:31 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4823
MAPREDUCE-4824,New Feature,Major,mrv1,Provide a mechanism for jobs to indicate they should not be recovered on restart,Some jobs (like Sqoop or HBase jobs) are not idempotent; so should not be recovered on jobtracker restart. MAPREDUCE-2702 solves this problem for MR2; however the approach there is not applicable for MR1; since even if we only use the job-level part of the patch and add a isRecoverySupported method to OutputCommitter; there is no way to use that information from the JT (which initiates recovery); since the JT does not instantiate OutputCommitters - and it shouldn't since they are user-level code. (In MR2 it's OK since the MR AM calls the method.)  Instead; we can add a MR configuration property to say that a job is not recoverable; and the JT could safely read this from the job conf.,Closed,Fixed,,Tom White,Tom White,Tue; 27 Nov 2012 15:51:15 +0000,Wed; 15 May 2013 05:16:01 +0000,Fri; 5 Apr 2013 12:25:51 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4824
MAPREDUCE-4825,Bug,Major,mr-am,JobImpl.finished doesn't expect ERROR as a final job state,TestMRApp.testJobError is causing AsyncDispatcher to exit with System.exit due to an exception being thrown.  From the console output from testJobError:,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 27 Nov 2012 19:01:45 +0000,Wed; 3 Sep 2014 23:25:07 +0000,Wed; 28 Nov 2012 17:57:57 +0000,,2.0.3-alpha;0.23.5,,,MAPREDUCE-4835,https://issues.apache.org/jira/browse/MAPREDUCE-4825
MAPREDUCE-4826,Improvement,Major,task-controller,backport MAPREDUCE-2374 fix to 1.0.x stable,Please consider backporting the fix for MAPREDUCE-2374 to 1.0.x. I am running into it frequently ; and it seems to be the original situation of MAPREDUCE-4003; which was marked fixed for a different item (see the last few comments).,Open,Unresolved,,Unassigned,Marc Reichman,Wed; 28 Nov 2012 15:05:24 +0000,Wed; 28 Nov 2012 15:05:56 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4826
MAPREDUCE-4827,Improvement,Major,,Increase hash quality of HashPartitioner,hash partitioner is using object.hashCode() for splitting keys into partitions. This results in bad distributions because hashCode() quality is poor.   These hashCode() functions are sometimes written by hand (very poor quality) and sometimes generated from by commons lang code (poor quality). Applying some transformation on top of hashCode() provides better distribution.,Resolved,Won't Fix,,Unassigned,Radim Kolar,Wed; 28 Nov 2012 17:01:27 +0000,Mon; 17 Dec 2012 23:18:19 +0000,Mon; 17 Dec 2012 22:48:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4827
MAPREDUCE-4828,Bug,Critical,test,Unit Test: TestTaskTrackerLocalization fails when ran with ant-1.8.4 and not 1.7.x,Problem is caused by JUnit3 based testcases ran in Junit4 environment configured by ant 1.8.4.. in this case @Ignore tag is not getting ignored.  This testcase has been removed from trunk,Resolved,Won't Fix,,Unassigned,Amir Sanjar,Wed; 28 Nov 2012 22:37:49 +0000,Sat; 26 Nov 2016 02:00:53 +0000,Sat; 26 Nov 2016 02:00:53 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4828
MAPREDUCE-4829,Bug,Critical,test,Unit Test: TestMiniMRMapRedDebugScript fails when ran with ant-1.8.4 and not 1.7.x ,Problem is caused by JUnit3 based testcases ran in Junit4 environment configured by ant 1.8.4.. in this case @Ignore tag is not getting ignored.  This testcase has been removed from trunk,Resolved,Won't Fix,,Unassigned,Amir Sanjar,Wed; 28 Nov 2012 22:40:19 +0000,Sat; 26 Nov 2016 02:00:36 +0000,Sat; 26 Nov 2016 02:00:35 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4829
MAPREDUCE-4830,Bug,Major,mrv1,Restore JT DelegationTokenSecretManager state on restart,This is the MR1 equivalent of YARN-248.,Open,Unresolved,,Unassigned,Tom White,Thu; 29 Nov 2012 16:22:58 +0000,Thu; 14 Aug 2014 02:26:18 +0000,,,1.1.0,,,YARN-248,https://issues.apache.org/jira/browse/MAPREDUCE-4830
MAPREDUCE-4831,Bug,Critical,mr-am,Task commit can occur more than once due to AM retries,If a task  the job-level.,Resolved,Not A Problem,,Unassigned,Jason Lowe,Thu; 29 Nov 2012 20:14:52 +0000,Wed; 27 Feb 2013 23:38:02 +0000,Wed; 27 Feb 2013 23:38:02 +0000,,0.23.0;2.0.0-alpha,,,MAPREDUCE-4819;MAPREDUCE-4832,https://issues.apache.org/jira/browse/MAPREDUCE-4831
MAPREDUCE-4832,Bug,Critical,applicationmaster,MR AM can get in a split brain situation,It is possible for a networking issue to happen where the RM thinks an AM has gone down and launches a replacement; but the previous AM is still up and running.  If the previous AM does not need any more resources from the RM it could try to commit either tasks or jobs.  This could cause lots of problems where the second AM finishes and tries to commit too.  This could result in data corruption.,Closed,Fixed,,Jason Lowe,Robert Joseph Evans,Thu; 29 Nov 2012 20:15:09 +0000,Fri; 15 Feb 2013 13:09:53 +0000,Fri; 4 Jan 2013 19:35:00 +0000,,2.0.2-alpha;0.23.5,,,MAPREDUCE-4831;MAPREDUCE-4819,https://issues.apache.org/jira/browse/MAPREDUCE-4832
MAPREDUCE-4833,Bug,Critical,applicationmaster;mrv2,Task can get stuck in FAIL_CONTAINER_CLEANUP,If an NM goes down and the AM still tries to launch a container on it the ContainerLauncherImpl can get stuck in an RPC timeout.  At the same time the RM may notice that the NM has gone away and inform the AM of this; this triggers a TA_FAILMSG.  If the TA_FAILMSG arrives at the TaskAttemptImpl before the TA_CONTAINER_LAUNCH_FAILED message then the task attempt will try to kill the container; but the ContainerLauncherImpl will not send back a TA_CONTAINER_CLEANED event causing the attempt to be stuck.,Closed,Fixed,,Robert Parker,Robert Joseph Evans,Thu; 29 Nov 2012 20:53:39 +0000,Fri; 15 Feb 2013 13:10:07 +0000,Fri; 21 Dec 2012 22:38:25 +0000,,0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4833
MAPREDUCE-4834,Bug,Major,task-controller,LinuxTaskController DELETE_AS_USER should try to delete as many paths as possible,When task-controller.c:delete_path iterates inodes in a directory tree; it may encounter a deletion failure. However; other directories files may well be deletable; and the tree walk should proceed.,Open,Unresolved,YARN-1940,Unassigned,Gera Shegalov,Thu; 29 Nov 2012 22:46:36 +0000,Tue; 15 Apr 2014 18:34:40 +0000,,,1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4834
MAPREDUCE-4835,Bug,Minor,mr-am,AM job metrics can double-count a job if it errors after entering a completion state,If JobImpl enters the SUCCEEDED; FAILED; or KILLED state but then encounters an invalid state transition; it could double-count the job since jobs that encounter an error are considered failed jobs.  Therefore the job could be counted initially as a successful; failed; or killed job; respectively; then counted again as a failed job due to the internal error afterwards.,Open,Unresolved,,Unassigned,Jason Lowe,Fri; 30 Nov 2012 15:13:01 +0000,Tue; 4 Dec 2012 00:47:49 +0000,,,2.0.3-alpha;0.23.6,,,MAPREDUCE-4825,https://issues.apache.org/jira/browse/MAPREDUCE-4835
MAPREDUCE-4836,Bug,Major,,Elapsed time for running tasks on AM web UI tasks page is 0,Yeah! The summary,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Fri; 30 Nov 2012 17:16:07 +0000,Thu; 12 May 2016 18:22:54 +0000,Fri; 30 Nov 2012 21:45:58 +0000,,2.0.2-alpha;0.23.5;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4836
MAPREDUCE-4837,Improvement,Major,,Add webservices for jobtracker,Add MR-AM web-services to branch-1,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Sat; 1 Dec 2012 01:21:49 +0000,Wed; 15 May 2013 05:16:00 +0000,Wed; 30 Jan 2013 01:04:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4837
MAPREDUCE-4838,Improvement,Major,,Add extra info to JH files,It will be useful to add more task-info to JH for analytics.,Closed,Fixed,,Zhijie Shen,Arun C Murthy,Sat; 1 Dec 2012 01:23:39 +0000,Sun; 4 Aug 2013 20:27:14 +0000,Wed; 30 Jan 2013 22:09:07 +0000,,,,,MAPREDUCE-4956,https://issues.apache.org/jira/browse/MAPREDUCE-4838
MAPREDUCE-4839,New Feature,Major,,TextPartioner for hashing Text with good hashing function to get better distribution,partitioner for Text keys using util.Hash framework for hashing function,Resolved,Not A Problem,,Radim Kolar,Radim Kolar,Sat; 1 Dec 2012 20:33:44 +0000,Tue; 1 Jan 2013 10:38:11 +0000,Tue; 1 Jan 2013 10:38:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4839
MAPREDUCE-4840,Bug,Minor,,Delete dead code and deprecate public API related to skipping bad records,It looks like the decision was made in MAPREDUCE-1932 to remove support for skipping bad records rather than fix it (it doesn't work right now in trunk). If that's the case then we should probably delete all the dead code related to it and deprecate the public API's for it right?  Dead code I'm talking about: 1. Task class: skipping; skipRanges; writeSkipRecs 2. MapTask class:  SkippingRecordReader inner class 3. ReduceTask class: SkippingReduceValuesIterator inner class 4. Tests: TestBadRecords  Public API: 1. SkipBadRecords class,Patch Available,Unresolved,,Unassigned,Mostafa Elhemali,Sun; 2 Dec 2012 19:14:11 +0000,Wed; 6 May 2015 03:34:23 +0000,,,2.0.0-alpha,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4840
MAPREDUCE-4841,Bug,Critical,applicationmaster,Application Master Retries fail due to FileNotFoundException,Application attempt1 is deleting the job related files and these are not present in the HDFS for following retries.,Resolved,Duplicate,MAPREDUCE-5476,Jason Lowe,Devaraj K,Mon; 26 Nov 2012 03:20:25 +0000,Tue; 22 Jul 2014 14:40:17 +0000,Tue; 22 Jul 2014 13:49:31 +0000,,2.0.1-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4841
MAPREDUCE-4842,Bug,Blocker,mrv2,Shuffle race can hang reducer,Saw an instance where the shuffle caused multiple reducers in a job to hang.  It looked similar to the problem described in MAPREDUCE-3721; where the fetchers were all being told to WAIT by the MergeManager but no merge was taking place.,Closed,Fixed,MAPREDUCE-5423,Mariappan Asokan,Jason Lowe,Mon; 3 Dec 2012 21:09:10 +0000,Wed; 8 Jun 2016 20:21:02 +0000,Fri; 21 Dec 2012 18:36:16 +0000,,2.0.2-alpha;0.23.5,,,MAPREDUCE-3721;TEZ-3293,https://issues.apache.org/jira/browse/MAPREDUCE-4842
MAPREDUCE-4843,Bug,Critical,tasktracker,When using DefaultTaskController; JobLocalizer not thread safe,In our cluster; some times job will failed due to below exception: 2012-12-03 23:11:54;811 WARN org.apache.hadoop.mapred.TaskTracker: Error initializing  another user's dir.,Closed,Fixed,,Karthik Kambatla,yunjiong zhao,Tue; 4 Dec 2012 13:39:40 +0000,Mon; 3 Nov 2014 18:05:46 +0000,Mon; 4 Feb 2013 22:27:34 +0000,,1.1.1,,,MAPREDUCE-4964,https://issues.apache.org/jira/browse/MAPREDUCE-4843
MAPREDUCE-4844,Bug,Major,,Counters / AbstractCounters have constant references not declared final,Counters have a number of immutable fields that have not been declared 'final'.  For example; the field groups is not final. It is; however; accessed in a couple of methods that are declared 'synchronized'. While there is a happens-before relationship between these methods calls; there is none between the Counters object initialization and these synchronized methods.,Resolved,Fixed,,Brahma Reddy Battula,Gera Shegalov,Tue; 4 Dec 2012 19:23:14 +0000,Tue; 30 Aug 2016 01:20:45 +0000,Fri; 3 Apr 2015 17:46:01 +0000,,2.6.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4844
MAPREDUCE-4845,Improvement,Major,client,ClusterStatus.getMaxMemory() and getUsedMemory() exist in MR1 but not MR2 ,For backwards compatibility; these methods should exist in both MR1 and MR2.  Confusingly; these methods return the max memory and used memory of the jobtracker; not the entire cluster.  I'd propose to add them to MR2 and return -1; and deprecate them in both MR1 and MR2.  Alternatively; I could add plumbing to get the resource manager memory stats.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 5 Dec 2012 00:08:43 +0000,Fri; 15 Feb 2013 13:10:08 +0000,Tue; 18 Dec 2012 15:27:53 +0000,,1.1.1;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4845
MAPREDUCE-4846,Improvement,Major,client,Some JobQueueInfo methods are public in MR1 but protected in MR2,setQueueName; setSchedulingInfo; and setQueueState were public in MR1; but are private int MR2.  They should be made public with InterfaceAudience.Private.  getQueueState was public; but is now package private.  It has been replaced with getState; which returns a QueueState instead of a String.  It should be made public and deprecated; with a documentation reference to getState.  Should the other setter methods in JobQueueInfo that were not in MR1 be changed to public InterfaceAudience.Private for consistency?,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 5 Dec 2012 00:39:00 +0000,Tue; 27 Aug 2013 22:21:58 +0000,Thu; 21 Feb 2013 11:37:02 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4846
MAPREDUCE-4847,Improvement,Major,contrib/streaming,Command Parsing in Hadoop Streaming,"Hadoop streaming parse the mapper and reducer commands by itself; this is not a good choice; when I write a complex mapper reducer script inline; such as 'perl -ne ...'; it don't work. An alternative way is to send the command to the shell; simply create new process(sh -c ""command_and_args""); this not also simplize the streaming code; but also improve its capability!",Open,Unresolved,,Unassigned,Peng Lei,Wed; 5 Dec 2012 02:40:08 +0000,Tue; 11 Dec 2012 08:54:48 +0000,,,,features,,,https://issues.apache.org/jira/browse/MAPREDUCE-4847
MAPREDUCE-4848,Bug,Major,mr-am,TaskAttemptContext cast error during AM recovery,Recently saw an AM that failed and tried to recover; but the subsequent attempt quickly exited with its own failure during recovery:     The RM then launched a third AM attempt which succeeded. The third attempt saw basically no progress after parsing the history file from the second attempt and ran the job again from scratch.,Closed,Fixed,,Jerry Chen,Jason Lowe,Wed; 5 Dec 2012 04:01:47 +0000,Fri; 15 Feb 2013 13:10:04 +0000,Wed; 9 Jan 2013 23:06:26 +0000,,0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4848
MAPREDUCE-4849,Bug,Major,contrib/fair-share,TaskSelector not used in FairScheduler,"The documentation (http: fair_scheduler.html) describes the mapred.fairscheduler.taskselector parameter as an ""extension point""; but while the FairScheduler does instantiate the custom TaskSelector provided this way; it does not call any of its methods (obtainNewMapTask; obtainNewReduceTask; neededSpeculativeMaps or neededSpeculativeReduces).  We should either update the FairScheduler to use the TaskSelector when scheduling a task; or completely remove the TaskSelector and update the documentation.",Open,Unresolved,,Unassigned,Vincent Behar,Wed; 5 Dec 2012 13:43:11 +0000,Wed; 5 Dec 2012 13:43:11 +0000,,,1.0.4;1.1.1,documentation,,,https://issues.apache.org/jira/browse/MAPREDUCE-4849
MAPREDUCE-4850,Bug,Major,mrv1,Job recovery may fail if staging directory has been deleted,The job staging directory is deleted in the job cleanup task; which happens before the job-info file is deleted from the system directory (by the JobInProgress garbageCollect() method). If the JT shuts down between these two operations; then when the JT restarts and tries to recover the job; it fails since the job.xml and splits are no longer available.,Closed,Fixed,,Tom White,Tom White,Wed; 5 Dec 2012 16:15:03 +0000,Wed; 15 May 2013 05:15:46 +0000,Wed; 9 Jan 2013 15:02:17 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4850
MAPREDUCE-4851,Improvement,Major,,add lifecycle to Comparators,current mapreduce api is using RawComparator interface in:  setGroupingComparatorClass setSortComparatorClass  This interface has no lifecycle support. I propose to change that methods to take argument new class implements RawComparator with setup and cleanup methods.   This will leave existing code with RawComparator alone; Providing some backward compatibility.  new class:   class SortComparator implements RawComparator,Resolved,Not A Problem,,Unassigned,Radim Kolar,Thu; 6 Dec 2012 14:56:37 +0000,Tue; 1 Jan 2013 10:53:19 +0000,Tue; 1 Jan 2013 10:53:19 +0000,,,mrv2,,,https://issues.apache.org/jira/browse/MAPREDUCE-4851
MAPREDUCE-4852,Bug,Major,mrv2,Reducer should not signal fetch failures for disk errors on the reducer's side,Ran across a case where a reducer ran on a node where the disks were full; leading to an exception like this during the shuffle fetch:     Even though the error was local to the reducer; it reported the error as a fetch failure to the AM than failing the reducer itself.  It then proceeded to run into the same error for many other maps; causing them to relaunch from reported fetch failures.  In this case it would have been better to fail the reducer and try another node rather than blame the mapper for what is an error on the reducer's side.,Resolved,Duplicate,MAPREDUCE-5251,Unassigned,Jason Lowe,Thu; 6 Dec 2012 17:58:33 +0000,Wed; 23 Apr 2014 19:03:09 +0000,Wed; 23 Apr 2014 19:03:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4852
MAPREDUCE-4853,New Feature,Major,security,Modify Security Conditional that check for KERBEROS,To support PLAIN authentication; checks should disallow certain types (TOKEN for token delegation) instead of allowing only KERBEROS,Open,Unresolved,,Robert Parker,Robert Parker,Thu; 6 Dec 2012 00:15:54 +0000,Fri; 7 Dec 2012 00:28:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4853
MAPREDUCE-4854,Bug,Major,,TestRumenJobTraces is broken in branch-1,TestRumenJobTraces is broken in branch-1; need to fix the 'gold' events it's checking against which is broken.,Resolved,Cannot Reproduce,,Arun C Murthy,Arun C Murthy,Fri; 7 Dec 2012 00:04:32 +0000,Fri; 7 Dec 2012 00:11:21 +0000,Fri; 7 Dec 2012 00:11:21 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4854
YARN-263,New Feature,Major,,Modify Security Conditional that check for KERBEROS,To support PLAIN authentication; checks should disallow certain types (TOKEN for token delegation) instead of allowing only KERBEROS,Open,Unresolved,,Robert Parker,Robert Parker,Fri; 7 Dec 2012 00:28:53 +0000,Fri; 7 Dec 2012 00:29:27 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-263
MAPREDUCE-4856,Bug,Major,test,TestJobOutputCommitter uses same directory as TestJobCleanup,This can cause problems if one of the tests fails to delete.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 7 Dec 2012 00:50:39 +0000,Fri; 15 Feb 2013 13:10:02 +0000,Wed; 12 Dec 2012 12:14:27 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4856
MAPREDUCE-4857,Bug,Major,,Fix 126 error during map/reduce phase,"There is rare happenings during map or reduce phase; but mostly in map phase; the Exception messages:   with 0.22; they use ""bash command"" to start the job scritp; but 1.0.4 use ""bash; ""-c""; command"".  I removed ""-c""; everything is ok; 126 error code never happen again.  I read man document of bash; it indicates when fork a new thread with write command; another thread with ""bash -c"" also has a writable fd. so I think it could return 126 status occasionally.  So; there is only one line fix for this issue.",Resolved,Not A Problem,,Unassigned,Fengdong Yu,Fri; 7 Dec 2012 05:31:25 +0000,Thu; 2 Apr 2015 12:21:16 +0000,Thu; 2 Apr 2015 12:21:15 +0000,,1.0.4,,,MAPREDUCE-2374,https://issues.apache.org/jira/browse/MAPREDUCE-4857
MAPREDUCE-4858,Bug,Major,,TestWebUIAuthorization fails on branch-1,TestWebUIAuthorization fails on branch-1,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 7 Dec 2012 07:14:15 +0000,Wed; 6 Mar 2013 09:55:59 +0000,Fri; 7 Dec 2012 07:41:54 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4858
MAPREDUCE-4859,Bug,Major,,TestRecoveryManager fails on branch-1,Looks like the tests are extremely flaky and just hang.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 7 Dec 2012 18:36:14 +0000,Wed; 6 Mar 2013 09:55:58 +0000,Fri; 7 Dec 2012 19:57:02 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4859
MAPREDUCE-4860,Bug,Major,security,DelegationTokenRenewal attempts to renew token even after a job is removed,mapreduce.security.token.DelegationTokenRenewal synchronizes on removeDelegationToken; but fails to synchronize on addToken; and renewing tokens in run().  This inconsistency is exposed by frequent failures of TestDelegationTokenRenewal:,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 7 Dec 2012 19:36:11 +0000,Mon; 3 Nov 2014 18:33:37 +0000,Thu; 13 Dec 2012 22:32:36 +0000,,1.1.1,,,MAPREDUCE-5384;MAPREDUCE-4861;MAPREDUCE-5364;MAPREDUCE-4795,https://issues.apache.org/jira/browse/MAPREDUCE-4860
MAPREDUCE-4861,Bug,Major,,Cleanup: Remove unused mapreduce.security.token.DelegationTokenRenewal,mapreduce.security.token.DelegationTokenRenewal doesn't seem to be used in branch-2 at all. grep on trunk yields no results; not even ReflectionUtils related suff.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 7 Dec 2012 21:55:03 +0000,Mon; 3 Nov 2014 18:33:43 +0000,Tue; 11 Dec 2012 19:30:43 +0000,,2.0.2-alpha,,,MAPREDUCE-4860;YARN-264,https://issues.apache.org/jira/browse/MAPREDUCE-4861
YARN-264,Bug,Major,,y.s.rm.DelegationTokenRenewer attempts to renew token even after removing an app,yarn.s.rm.security.DelegationTokenRenewer uses TimerTask Timer. When such a timer task is canceled; already scheduled tasks run to completion. The task should check for such cancellation before running. Also; delegationTokens needs to be synchronized on all accesses.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 7 Dec 2012 23:57:16 +0000,Mon; 3 Nov 2014 18:34:00 +0000,Thu; 13 Dec 2012 22:21:52 +0000,,2.0.2-alpha,,,MAPREDUCE-4861;MAPREDUCE-4795,https://issues.apache.org/jira/browse/YARN-264
MAPREDUCE-4863,Sub-task,Major,applicationmaster,Adding aggregationWaitMap for node-level combiner.,To manage node rack-level combining; MRAppMaster needs to have a management information about outputs of completed MapTasks to be aggregated.  AggregationWaitMap is used so that MRAppMaster decides whether or not MapTasks start to combine local MapOutputFiles.  AggregationWaitMap is a abstraction class of ConcurrentHashMapString; ArrayListTaskAttemptCompletionEvent. These Events are candidate files to be aggregated.  When MapTasks are completed; MRAppMaster buffer TaskAttemptCompletionEvent into AggregationWaitMap to delay reducers' fethcing outputs from mappers until node-level aggregation are finished.  After node-level aggreagtion; MRAppMaster write back mapAttemptCompletionEvents; to restart reducers' feching outputs from mappers.,In Progress,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 10 Dec 2012 05:15:28 +0000,Thu; 12 May 2016 18:22:27 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4863
MAPREDUCE-4864,Sub-task,Major,applicationmaster;mrv2;tasktracker,"Adding new umbilical protocol RPC; ""getAggregationTargets()""; for node-level combiner.",MapTasks need to know whether or not they should start node-level combiner agaist outputs of mapper on their node.   The new umbilical RPC; getAggregationTargets(); is used to get outputs to be aggregated on the node. The definition as follows:      AggregationTarget getAggregationTargets(TaskAttemptID aggregator) throws IOException;  AggregationTarget is a abstraction class of array of TaskAttemptID to be aggregated.,In Progress,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 10 Dec 2012 05:23:20 +0000,Thu; 12 May 2016 18:22:28 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4864
MAPREDUCE-4865,Sub-task,Major,tasktracker,Launching node-level combiner at the end stage of MapTask and ignoring aggregated inputs at ReduceTask,MapTask needs to start node-level aggregation against local outputs at the end stage of MapTask after calling getAggregationTargets().  This feature is implemented with Merger and CombinerRunner.,In Progress,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 10 Dec 2012 06:46:04 +0000,Thu; 12 May 2016 18:22:29 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4865
MAPREDUCE-4866,Improvement,Minor,mrv1,ShuffleRamManager is limited to 2Gb of memory - we should increase that,Inside the org.apache.hadoop.mapred.ReduceTask.  the ShuffleRamManager is limited to allocate up to 2Gb of memory during the shuffle phase.  We should be able to allocate more; to take advantage of the full memory we have on servers.,Open,Unresolved,,Unassigned,Varene Olivier,Mon; 10 Dec 2012 10:01:48 +0000,Sun; 5 Jan 2014 03:12:56 +0000,,,0.20.2,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4866
MAPREDUCE-4867,Bug,Major,scheduler,reduces tasks won't start in certain circumstances ,"Reduce tasks start are conditioned by the value of ""mapred.reduce.slowstart.completed.maps"". However; if the number of completed map tasks never reached the configured value (for example because ""mapred.max.map.failures.percent"" has been set to a high value; to permit a job to have a lot of failed tasks); then the reduce tasks won't start. The job is still running; all map tasks are finished (either successful or not); and all reduce tasks are still pending. The only thing one can do is to kill the job.  There are 2 things that could be done :   	document the relation between ""mapred.max.map.failures.percent"" and ""mapred.reduce.slowstart.completed.maps"" : we can say that the rule to follow if you want to be sure that your reduce tasks will start is : ""mapred.reduce.slowstart.completed.maps * 100  100 - mapred.max.map.failures.percent""     	fix JobInProgress.scheduleReduces() to return true if all map tasks are finished",Open,Unresolved,,Unassigned,Vincent Behar,Mon; 10 Dec 2012 11:04:21 +0000,Mon; 10 Dec 2012 15:45:27 +0000,,,1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4867
MAPREDUCE-4868,Improvement,Major,mrv2,Allow multiple iteration for map,"Currently; the Mapper class allows advanced users to override ""public void run(Context context)"" method for more control over the execution of the mapper; while Context interface limit the operations over the data which is the foundation of ""more control"".  One of use cases is that when I am considering a hive optimziation problem; I want to go two passes over the input data instead of using a another job or task ( which may slower the whole process). Each pass do the same thing but with a different parameters.  This is a new paradigm of Map Reduce usage and can be archived easily by extend Context interface a little with the more control over the data such as reset the input.",Open,Unresolved,,Unassigned,Jerry Chen,Tue; 11 Dec 2012 02:26:21 +0000,Thu; 12 May 2016 18:23:29 +0000,,,2.0.3-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4868
MAPREDUCE-4869,Bug,Major,test,TestMapReduceChildJVM fails in branch-trunk-win,The YARN-233 patch for getting YARN working on Windows forgot to include a corresponding change in TestMapReduceChildJVM; so the test is failing now.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Tue; 11 Dec 2012 06:44:56 +0000,Fri; 28 Dec 2012 04:31:05 +0000,Fri; 28 Dec 2012 04:31:05 +0000,,trunk-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4869
MAPREDUCE-4871,Bug,Major,mrv2,AM uses mapreduce.jobtracker.split.metainfo.maxsize but mapred-default has mapreduce.job.split.metainfo.maxsize,When the user needs to configure a larger split metainfo file size; mapred-default.xml points to the mapreduce.job.split.metainfo.maxsize property.  However the ApplicationMaster actually uses the mapreduce.jobtracker.split.metainfo.maxsize property when determining the largest allowed size.  This leads to much confusion on the part of end-users trying to increase the allowed limit.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 12 Dec 2012 00:53:06 +0000,Wed; 3 Sep 2014 22:57:02 +0000,Thu; 28 Feb 2013 20:00:40 +0000,,0.23.3;2.0.2-alpha,,,MAPREDUCE-4926;MAPREDUCE-2760,https://issues.apache.org/jira/browse/MAPREDUCE-4871
MAPREDUCE-4872,Bug,Major,client,MapReduce JVM launch does not use correct working directory on Windows,MapReduceChildJVM#getVMCommand sets  io.tmpdir by using environment variable PWD as the root of the path.  On Windows; %PWD% likely will not be defined.  Instead; we need to use %CD%.  Any part of the codebase that uses Environment#PWD is likely to be impacted by this.,Resolved,Won't Fix,,Chris Nauroth,Chris Nauroth,Wed; 12 Dec 2012 23:47:29 +0000,Fri; 14 Nov 2014 22:43:00 +0000,Fri; 14 Nov 2014 22:43:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4872
MAPREDUCE-4873,Test,Major,mrv1;test,TestQueueManagerForJobKillAndJobPriority is failing on branch-1,nan,Resolved,Won't Fix,,Unassigned,Karthik Kambatla,Thu; 13 Dec 2012 05:34:07 +0000,Sat; 26 Nov 2016 01:47:36 +0000,Sat; 26 Nov 2016 01:47:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4873
MAPREDUCE-4874,Test,Major,mrv1,TestQueueManagerForJobKillAndNonDefaultQueue fails in branch-1,nan,Open,Unresolved,,Unassigned,Karthik Kambatla,Thu; 13 Dec 2012 05:39:49 +0000,Mon; 3 Nov 2014 18:33:57 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4874
MAPREDUCE-4875,Test,Major,test,coverage fixing for org.apache.hadoop.mapred,added  some tests for org.apache.hadoop.mapred MAPREDUCE-4875-trunk.patch for trunk and branch-2 MAPREDUCE-4875-branch-0.23.patch for branch-0.23,Closed,Fixed,,Aleksey Gorshkov,Aleksey Gorshkov,Thu; 13 Dec 2012 12:51:27 +0000,Thu; 12 May 2016 18:24:28 +0000,Fri; 29 Mar 2013 16:28:22 +0000,,2.0.3-alpha;0.23.6;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4875
MAPREDUCE-4876,Wish,Minor,,Adopt a Tuple MapReduce API instead of classic MapReduce one,After using MapReduce for many years; we have noticed th is requested in  https: multipleoutput.  Well; we are open to the discussion and to contribute.,Open,Unresolved,,Unassigned,Iv  n de Prado,Thu; 13 Dec 2012 17:01:45 +0000,Mon; 21 Jan 2013 10:22:19 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4876
MAPREDUCE-4877,Bug,Major,applicationmaster;job submission,AM doesn't properly support multiple NNs,Yarn expected NN.  However the AM uses the user's job conf; which means the user's defined defaultFS can cause the job to use incorrect paths.  Typically the output path's NN is also the yarn cluster's NN.  However problems occur when a yarn cluster is servicing multiple NN's (ex. federated clusters).  The JHS is assuming the AM will write to NN1; whereas the user's job conf may be using a defaultFS of NN2 or NN3 which influences where the AM writes.,Open,Unresolved,,Daryn Sharp,Daryn Sharp,Fri; 14 Dec 2012 00:12:52 +0000,Sat; 7 Jan 2017 02:00:00 +0000,,,0.23.0;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4877
MAPREDUCE-4878,Bug,Major,,JobID.forName() isn't strict enough,If you have a job running as job_201208221603_0003; and then try to kill a job passing id job_201208221603_003; it will kill job_201208221603_0003 because the last part of the JobID is parsed as an integer.  We should make JobID.forName() stricter to prevent this and similar situations as the current behavior isn't so obvious.    More specifically; we shouldn't accept JobIDs if the last part of the JobID is: - less than 4 characters (e.g. _003; _123) - more than 4 characters and has a leading zero (e.g. _00003; _01234),Resolved,Later,,Robert Kanter,Robert Kanter,Mon; 19 Nov 2012 21:08:28 +0000,Fri; 21 Mar 2014 18:29:14 +0000,Fri; 21 Mar 2014 18:29:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4878
MAPREDUCE-4879,Bug,Major,examples,TeraOutputFormat may overwrite an existing output directory,Unlike FileOutputFormat; TeraOutputFormat does not prevent TeraGen Sort jobs from writing into an existing directory; and potentially overwriting previous runs.,Closed,Fixed,MAPREDUCE-5911,Gera Shegalov,Gera Shegalov,Fri; 14 Dec 2012 06:32:21 +0000,Fri; 10 Apr 2015 20:19:38 +0000,Sun; 14 Dec 2014 02:15:51 +0000,,1.2.1;2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4879
MAPREDUCE-4880,Bug,Major,mr-am,TaskImpl interprets death of second attempt as RetroactiveKilledTransition even when first attempt succeeds,"Consider a reduce task with 2 attempts; one running and one unassigned.  Reduce task attempt 1 succeeds.  This causes reduce task attempt 2 to be killed.  This causes reduce task attempt 2 to issue a T_ATTEMPT_KILLED; which the TaskImpl interprets as a RetroactiveKilledTransition.  As RetroactiveKilledTransitions are supposed to only apply to map events; the TaskImpl errors with ""Unexpected event for REDUCE task T_ATTEMPT_KILLED"".",Resolved,Not A Problem,,Unassigned,Sandy Ryza,Sat; 15 Dec 2012 09:48:39 +0000,Mon; 17 Dec 2012 19:58:26 +0000,Mon; 17 Dec 2012 09:49:27 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4880
MAPREDUCE-4881,Bug,Major,task,Task should throw exception and die if its attempt directory already exists,While tracking down HADOOP-9051; I noticed that TaskLog can create circular symlinks when a task's attempt directory exists before task initialization; which usually indicate a restart bug in JobTracker; as attempt id should be unique. Task should throw an exception; log it and die in this case.,Open,Unresolved,,Unassigned,Luke Lu,Sat; 15 Dec 2012 18:22:35 +0000,Sat; 15 Dec 2012 18:22:35 +0000,,,1.0.4;1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4881
MAPREDUCE-4882,Bug,Major,,Error in estimating the length of the output file in Spill Phase,"The sortAndSpill() method in MapTask.   private void sortAndSpill() throws IOException; ClassNotFoundException;                                        InterruptedException {        buffer + header lengths for the partitions       long size = (bufend = bufstart           ? bufend - bufstart           : (bufvoid - bufend) + bufstart) +                   partitions * APPROX_HEADER_LENGTH;       FSDataOutputStream out = null; ------------------------------------------------------------------------------ I had a test on ""TeraSort"". A snippet from mapper's log is as follows:  MapTask: Spilling map output: record full = true MapTask: bufstart = 157286200; bufend = 10485460; bufvoid = 199229440 MapTask: kvstart = 262142; kvend = 131069; length = 655360 MapTask: Finished spill 3  In this occasioin; Spill Bytes should be (199229440 - 157286200) + 10485460 = 52428700 (52 MB) because the number of spilled records is 524287 and each record costs 100B.",Closed,Duplicate,MAPREDUCE-6063,Jerry Chen,Lijie Xu,Mon; 17 Dec 2012 02:52:29 +0000,Tue; 30 Jun 2015 07:18:59 +0000,Fri; 8 May 2015 21:43:54 +0000,,0.20.2;1.0.3,BB2015-05-TBR;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4882
MAPREDUCE-4883,Improvement,Major,,Reducer's Maximum Shuffle Buffer Size should be enlarged for 64bit JVM,"In hadoop-0.20.2; hadoop-1.0.3 or other versions; reducer's shuffle buffer size cannot exceed 2048MB (i.e.; Integer.MAX_VALUE). This is reasonable for 32bit JVM. But for 64bit JVM; although reducer's JVM size can be set more than 2048MB (e.g.; mapred.child. needs modification for 64bit JVM. ---------------------------------------------------------------------------------------       private final long maxSize;       private final long maxSingleShuffleLimit;        private long size = 0;        private Object dataAvailable = new Object();       private long fullSize = 0;       private int numPendingRequests = 0;       private int numRequiredMapOutputs = 0;       private int numClosed = 0;       private boolean closed = false;        public ShuffleRamManager(Configuration conf) throws IOException {         final float maxInMemCopyUse =           conf.getFloat(""mapred.job.shuffle.input.buffer.percent""; 0.70f);         if (maxInMemCopyUse  1.0 || maxInMemCopyUse  0.0)  {           throw new IOException(""mapred.job.shuffle.input.buffer.percent"" +                                 maxInMemCopyUse);         }           Allow unit tests to fix Runtime memory --   maxSize = (int)(conf.getInt(""mapred.job.reduce.total.mem.bytes""; --        (int)Math.min(Runtime.getRuntime().maxMemory(); Integer.MAX_VALUE)) --      * maxInMemCopyUse);         maxSingleShuffleLimit = (long)(maxSize * MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION);         LOG.info(""ShuffleRamManager: MemoryLimit="" + maxSize +                  ""; MaxSingleShuffleLimit="" + maxSingleShuffleLimit);       }",Resolved,Duplicate,MAPREDUCE-5649,Jerry Chen,Lijie Xu,Mon; 17 Dec 2012 03:09:43 +0000,Mon; 4 May 2015 19:41:45 +0000,Mon; 4 May 2015 19:41:45 +0000,,0.20.2;1.0.3,patch,,MAPREDUCE-5649,https://issues.apache.org/jira/browse/MAPREDUCE-4883
MAPREDUCE-4884,Bug,Major,contrib/streaming;test,"streaming tests fail to start MiniMRCluster due to ""Queue configuration missing child queue names for root""","Multiple tests in hadoop-streaming; such as TestFileArgs; fail to initialize MiniMRCluster due to a YarnException with reason ""Queue configuration missing child queue names for root"".",Closed,Fixed,HADOOP-9052,Chris Nauroth,Chris Nauroth,Mon; 17 Dec 2012 06:43:41 +0000,Thu; 12 May 2016 18:24:22 +0000,Wed; 2 Jan 2013 19:31:32 +0000,,trunk-win;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4884
MAPREDUCE-4885,Bug,Major,contrib/streaming;test,Streaming tests have multiple failures on Windows,"There are multiple test failures due to ""Queue configuration missing child queue names for root"".",Closed,Fixed,,Chris Nauroth,Chris Nauroth,Wed; 5 Dec 2012 18:37:57 +0000,Thu; 12 May 2016 18:22:43 +0000,Fri; 12 Apr 2013 03:04:37 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4885
MAPREDUCE-4886,Bug,Major,scheduler,TestCapacityScheduler failed in branch-1,The test failure on my local env is as following:,Closed,Not A Problem,,meng gong,Junping Du,Mon; 17 Dec 2012 11:10:01 +0000,Wed; 15 May 2013 05:15:46 +0000,Thu; 20 Dec 2012 10:16:23 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4886
MAPREDUCE-4887,New Feature,Major,,Rehashing partitioner for better distribution,rehash value returned by Object.hashCode() to get better distribution,Resolved,Fixed,,Radim Kolar,Radim Kolar,Tue; 18 Dec 2012 00:12:47 +0000,Thu; 12 May 2016 18:23:42 +0000,Wed; 19 Dec 2012 21:50:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4887
MAPREDUCE-4888,Bug,Blocker,mrv1,NLineInputFormat drops data in 1.1 and beyond,When trying to root cause why MAPREDUCE-4782 did not cause us issues on 1.0.2; I found out that HADOOP-7823 introduced essentially the exact same error into org.apache.hadoop.mapred.lib.NLineInputFormat.  In 1.X org.apache.hadoop.mapred.lib.NLineInputFormat and org.apache.hadoop.mapreduce.lib.input.NLineInputFormat are separate implementations.  The latter had an off by one error in it until MAPREDUCE-4782 fixed it. The former had no error in it until HADOOP-7823 introduced it in 1.1 and MAPREDUCE-375 combined the implementations together but picked the implementation with the off by one error in 0.21.  I will attach a patch that exposes the error.,Closed,Fixed,,Vinod Kumar Vavilapalli,Robert Joseph Evans,Tue; 18 Dec 2012 16:50:46 +0000,Wed; 6 Mar 2013 09:55:57 +0000,Fri; 21 Dec 2012 07:42:08 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4888
MAPREDUCE-4889,Bug,Major,mr-am,AM should have a diagnostics message for invalid state transitions,When the ApplicationMaster encounters an invalid state transition in one of its many state machines (JobImpl; TaskImpl; TaskAttemptImpl; etc.) the job will fail with the ERROR state but the diagnostics string doesn't have any information about the failure.  The diagnostics string should contain a message indicating the job is failing because of an invalid state transition and; preferably; details on the nature of the internal error.,Open,Unresolved,,Unassigned,Jason Lowe,Wed; 19 Dec 2012 02:25:23 +0000,Wed; 19 Dec 2012 02:25:23 +0000,,,2.0.2-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4889
MAPREDUCE-4890,Bug,Critical,mr-am,Invalid TaskImpl state transitions when task fails while speculating,"There are a couple of issues when a task fails while speculating (i.e.: multiple attempts are active):   	The other active attempts are not killed. 	TaskImpl's FAILED state does not handle the T_ATTEMPT_* set of events which can be sent from the other active attempts.  These all need to be handled since they can be sent asynchronously from the other active task attempts.    Failure to handle this properly means jobs that are configured to normally tolerate failures via mapreduce.map.failures.maxpercent or mapreduce.reduce.failures.maxpercent and also speculate can easily end up failing due to invalid state transitions rather than complete successfully with a few explicitly allowed task failures.",Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 19 Dec 2012 02:52:30 +0000,Fri; 15 Feb 2013 13:09:51 +0000,Sat; 22 Dec 2012 01:52:30 +0000,,2.0.2-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4890
MAPREDUCE-4891,New Feature,Major,,Pluggable merge at reduce side,The current implementation of sort in MapReduce is cooperated by Map side sort and Reduce side merge.  MAPREDUCE-2454 provided pluggable sort at the Map side currently and pluggable shuffle at Reduce side; while no pluggable merger provided.  Considering a general need of hash grouping and join; we may need to replace both the Map Sort and Reduce merge with a more light weight hash grouping alorithm. A general pluggable merge would help support this need.,Resolved,Duplicate,MAPREDUCE-4808,Unassigned,Jerry Chen,Wed; 19 Dec 2012 03:05:40 +0000,Thu; 12 May 2016 18:22:45 +0000,Wed; 19 Dec 2012 06:32:54 +0000,,3.0.0-alpha1,,,MAPREDUCE-2454,https://issues.apache.org/jira/browse/MAPREDUCE-4891
MAPREDUCE-4892,Bug,Major,,CombineFileInputFormat node input split can be skewed on small clusters,The CombineFileInputFormat split generation logic tries to group blocks by node in order to create splits. It iterates through the nodes and creates splits on them until there aren't enough blocks left on a node that can be grouped into a valid split. If the first few nodes have a lot of blocks on them then they can end up getting a disproportionately large share of the total number of splits created. This can result in poor locality of maps. This problem is likely to happen on small clusters where its easier to create a skew in the distribution of blocks on nodes.,Closed,Fixed,,Bikas Saha,Bikas Saha,Wed; 19 Dec 2012 19:57:24 +0000,Tue; 27 Aug 2013 22:21:58 +0000,Wed; 27 Feb 2013 18:55:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4892
MAPREDUCE-4893,Bug,Major,applicationmaster,MR AppMaster can do sub-optimal assignment of containers to map tasks leading to poor node locality,Say the MR AppMaster asks the RM for 3 containers on nodes n1; n2 and n3. There are 10 node n1-n10 in the same rack. The RM can give it allocated containers in the list order n5; n2; n1. The way AM map-container assignment happens; the AM will try to assign node local maps to n5; failing which it will assign rack local maps to n5. These rack local maps could be node local on n2 and n1 and would have been assigned to containers on n1 and n2 if the AM had not made an early rack local match for them on n5. This can lead to poor locality.,Closed,Fixed,MAPREDUCE-4982,Bikas Saha,Bikas Saha,Wed; 19 Dec 2012 20:02:42 +0000,Wed; 13 Nov 2013 15:40:20 +0000,Thu; 31 Jan 2013 00:30:33 +0000,,,,,MAPREDUCE-5622;MAPREDUCE-5002,https://issues.apache.org/jira/browse/MAPREDUCE-4893
MAPREDUCE-4894,Bug,Blocker,jobhistoryserver;mrv2,Renewal / cancellation of JobHistory tokens,Equivalent of YARN-50 for JobHistory tokens.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Thu; 20 Dec 2012 08:27:52 +0000,Wed; 3 Sep 2014 23:25:07 +0000,Fri; 4 Jan 2013 20:32:03 +0000,,0.23.4,,,YARN-50;YARN-279,https://issues.apache.org/jira/browse/MAPREDUCE-4894
MAPREDUCE-4895,Bug,Major,,Fix compilation failure of org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators,Task https: YARN-223 breaks compilation of 'Apache Hadoop Gridmix' on branch-2. There is an import of class org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.ProcResourceValues.  Class ProcResourceValues were removed by YARN-223.  this patch removes this import.  applicable to branch-2,Closed,Fixed,,Dennis Y,Dennis Y,Thu; 20 Dec 2012 11:24:47 +0000,Fri; 15 Feb 2013 13:10:00 +0000,Thu; 20 Dec 2012 14:52:46 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4895
MAPREDUCE-4896,Bug,Major,client;scheduler,mapred queue -info spits out ugly exception when queue does not exist,nan,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 20 Dec 2012 19:41:25 +0000,Tue; 27 Aug 2013 22:21:59 +0000,Fri; 1 Mar 2013 19:43:08 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4896
MAPREDUCE-4897,Bug,Major,,Using both MultipleInputs.addInputPath methods causes mappers to fail,The MultipleInputs class has two methods for adding inputs; one takes a mapper for the provided input path. When using both; both the inputformat gets set to DelegatingInputFormat class and the mapper class gets set to the DelegatingMapperClass.  When running a map task; the delegating input sees theres no mapper for the provided input path; and the next step is to get the mapper from the jobconf (which usually defaults to the identity mapper). However; because I used both methods in the MultipleInputs class; the mapper in the jobconf is set to the DelegatingMapper. Thus the delegating mapper creates a delegating mapper and tries its map method. (this is how the framework gets the delegating mapper to use a provided mapper). And the map method sees no mapper created yet; creates a new delegating mapper; uses it; which see no mapper created yet; creates a delegating mapper; etc.,Open,Unresolved,,Unassigned,gladmon@gmail.com,Thu; 20 Dec 2012 21:00:17 +0000,Thu; 20 Dec 2012 21:28:17 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4897
MAPREDUCE-4898,Bug,Major,mrv2,FileOutputFormat.checkOutputSpecs and FileOutputFormat.setOutputPath incompatible with MR1,In MR1; org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs throws org.apache.hadoop.mapred.FileAlreadyExistsException but now it throws org.apache.hadoop.fs.FileAlreadyExistsException instead; making them incompatible.    In MR1; org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath doesn't throw any exceptions but now it throws an IOException; making them incompatible.,Closed,Fixed,,Robert Kanter,Robert Kanter,Fri; 21 Dec 2012 01:24:07 +0000,Tue; 27 Aug 2013 22:21:57 +0000,Thu; 18 Apr 2013 18:53:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4898
MAPREDUCE-4899,Improvement,Major,,Provide a plugin to the Yarn Web App Proxy to generate tracking links for M/R appllications given the ID,Create a Map Reduce specific plugin for use with the Yarn RM Proxy to produce tracking links to the History server.,Closed,Fixed,,Derek Dagit,Derek Dagit,Fri; 21 Dec 2012 20:22:32 +0000,Thu; 12 May 2016 18:22:36 +0000,Tue; 8 Jan 2013 19:55:05 +0000,,0.23.5;3.0.0-alpha1,,YARN-285,YARN-304,https://issues.apache.org/jira/browse/MAPREDUCE-4899
MAPREDUCE-4900,New Feature,Major,resourcemanager;tasktracker,Dynamic configuration for task slots on TT,The current Hadoop MRV1 resource management logic assumes per node slot number is static during the lifetime of the TT process. Allowing run-time configuration on per node slot will give us finer granularity of resource elasticity. This allows Hadoop workloads to coexist with other workloads on the same hardware efficiently; whether or not the environment is virtualized. For more background or design details of this effort; please refer proposal in HADOOP-9165.,Open,Unresolved,,Binglin Chang,Junping Du,Sun; 23 Dec 2012 08:25:10 +0000,Thu; 10 Oct 2013 23:33:47 +0000,,,1.1.1,,MAPREDUCE-5381,YARN-291;MAPREDUCE-4944,https://issues.apache.org/jira/browse/MAPREDUCE-4900
MAPREDUCE-4901,Bug,Major,mrv2,JobHistoryEventHandler errors should be fatal,To be able to truly fix issues like MAPREDUCE-4819 and MAPREDUCE-4832; we need a 2 phase commit where a subsequent AM can be sure that at a specific point in time it knows exactly if any tasks jobs are committing.  The job history log is already used for similar functionality so we would like to reuse this; but we need to be sure that errors while writing out to the job history log are now fatal.,Patch Available,Unresolved,,Robert Joseph Evans,Robert Joseph Evans,Wed; 26 Dec 2012 15:42:40 +0000,Mon; 11 May 2015 17:30:43 +0000,,,0.23.0;2.0.0-alpha,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4901
MAPREDUCE-4902,Bug,Trivial,,"Fix typo ""receievd"" should be ""received"" in log output","Noticed a typo in the log output; ""receievd"" should be ""received""   org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080 mapOutput?job=job_1356131733318_0002reduce=0map=attempt_1356131733318_0002_m_000001_0;attempt_1356131733318_0002_m_000003_0;attempt_1356131733318_0002_m_000000_0 sent hash and receievd reply",Closed,Fixed,,Albert Chu,Albert Chu,Wed; 26 Dec 2012 18:21:45 +0000,Thu; 12 May 2016 18:24:28 +0000,Wed; 26 Dec 2012 20:52:48 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4902
MAPREDUCE-4903,Bug,Major,jobhistoryserver,Job history server giving incorrect job start time.,nan,Open,Unresolved,,Unassigned,Nishan Shetty,Thu; 27 Dec 2012 15:13:09 +0000,Thu; 27 Dec 2012 15:18:39 +0000,,,2.0.1-alpha;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4903
MAPREDUCE-4904,Bug,Major,test,TestMultipleLevelCaching failed in branch-1,TestMultipleLevelCaching will failed:,Closed,Fixed,,Junping Du,meng gong,Fri; 28 Dec 2012 07:28:44 +0000,Wed; 15 May 2013 05:16:05 +0000,Fri; 4 Jan 2013 19:21:07 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4904
MAPREDUCE-4905,Test,Major,,test org.apache.hadoop.mapred.pipes,tests for  org.apache.hadoop.mapred.pipes patch MAPREDUCE-4905-trunk.patch for trunk; branch-2; branch-0.23,Closed,Fixed,,Aleksey Gorshkov,Aleksey Gorshkov,Fri; 28 Dec 2012 07:37:47 +0000,Thu; 12 May 2016 18:23:42 +0000,Wed; 6 Feb 2013 16:03:22 +0000,,2.0.3-alpha;0.23.6;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4905
MAPREDUCE-4906,Bug,Major,test,testJobTrackerRestartsWithMissingJobFile failed in branch-1,testJobTrackerRestartsWithMissingJobFile failed in branch-1 for timeout,Resolved,Won't Fix,,meng gong,meng gong,Fri; 28 Dec 2012 07:38:33 +0000,Sat; 26 Nov 2016 01:59:16 +0000,Sat; 26 Nov 2016 01:59:15 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4906
MAPREDUCE-4907,Improvement,Major,mrv1;tasktracker,TrackerDistributedCacheManager issues too many getFileStatus calls,TrackerDistributedCacheManager issues a number of redundant getFileStatus calls when determining the timestamps and visibilities of files in the distributed cache.  300 distributed cache files deep in the directory structure can hammer HDFS with a couple thousand requests.  A couple optimizations can reduce this load: 1. determineTimestamps and determineCacheVisibilities both call getFileStatus on every file.  We could cache the results of the former and use them for the latter. 2. determineCacheVisibilities needs to check that all ancestor directories of each file have execute permissions for everyone.  This currently entails a getFileStatus on each ancestor directory for each file.  The results of these getFileStatus calls could be cached as well.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 28 Dec 2012 22:04:33 +0000,Fri; 15 Feb 2013 13:10:05 +0000,Thu; 10 Jan 2013 00:55:36 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4907
MAPREDUCE-4908,Bug,Major,contrib/streaming,the length of key or value  is not equal the actual length,The length of key or value  is not equal the actual length.  In this case; mapper class can't read record correctly.,Open,Unresolved,,Unassigned,rainy Yu,Tue; 1 Jan 2013 08:53:08 +0000,Mon; 28 Jan 2013 03:41:46 +0000,,,0.20.205.0;0.23.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4908
MAPREDUCE-4909,Bug,Major,test,TestKeyValueTextInputFormat fails with Open JDK 7 on Windows,TestKeyValueTextInputFormat.testFormat fails with Open JDK 7. The root cause appears to be a failure to delete in-use files via LocalFileSystem.delete (RawLocalFileSystem.delete).,Closed,Fixed,,Arpit Agarwal,Arpit Agarwal,Wed; 2 Jan 2013 22:03:49 +0000,Wed; 15 May 2013 05:15:59 +0000,Thu; 3 Jan 2013 21:51:12 +0000,,1.2.0,,,MAPREDUCE-4969,https://issues.apache.org/jira/browse/MAPREDUCE-4909
MAPREDUCE-4910,Sub-task,Major,applicationmaster;mrv2;task,Adding AggregationWaitMap to some components(MRAppMaster; TaskAttemptListener; JobImpl; MapTaskImpl).,To implement MR-4502; AggregationWaitMap need to be used by some components(MRAppMaster; TaskAttemptListener; JobImpl; MapTaskImpl).,In Progress,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Thu; 3 Jan 2013 05:59:42 +0000,Fri; 18 Jan 2013 05:57:49 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4910
MAPREDUCE-4911,Sub-task,Major,client,Add node-level aggregation flag feature(setNodeLevelAggregation(boolean)) to JobConf,This JIRA adds node-level aggregation flag feature(setLocalAggregation(boolean)) to JobConf. This task is subtask of MAPREDUCE-4502.,Patch Available,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Thu; 3 Jan 2013 06:22:44 +0000,Wed; 6 May 2015 03:27:26 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4911
MAPREDUCE-4912,Bug,Major,mrv2,Investigate ways to clean up double job commit prevention,"Once MAPREDUCE-4819 goes in it fixes the issue where an OutputCommiter can double commit a job.  So that the output will never be touched after the job informs externally of success or failure.  The code and design could potentially use some cleanup and refactoring.  Issues brought up that should be investigated include:   	reporting KILL for killed jobs if they crash after the kill happens instead of error. 	using the job history log for recording the commit status instead of separate external files in HDFS. 	Placing the recovery retry logic in the commit handler instead of the MRAppMaster; and having the recovery service replay the logs as it normally does for recovery.    This is not meant to be things that must be done; but alternatives that might clean up the code.",Open,Unresolved,,Unassigned,Robert Joseph Evans,Fri; 4 Jan 2013 15:28:26 +0000,Fri; 4 Jan 2013 15:28:26 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4912
MAPREDUCE-4913,Bug,Major,mr-am,TestMRAppMaster#testMRAppMasterMissingStaging occasionally exits,testMRAppMasterMissingStaging will sometimes cause the JVM to exit due to this error from AsyncDispatcher:     This can cause a build to fail since the test process exits without unregistering from surefire which treats it as a build error rather than a test failure.,Closed,Fixed,,Jason Lowe,Jason Lowe,Sat; 5 Jan 2013 02:41:54 +0000,Wed; 3 Sep 2014 23:25:06 +0000,Sat; 5 Jan 2013 20:19:55 +0000,,2.0.3-alpha;0.23.6,,,MAPREDUCE-4819,https://issues.apache.org/jira/browse/MAPREDUCE-4913
MAPREDUCE-4914,Bug,Major,test,TestMiniMRDFSSort fails with openJDK7,nan,Closed,Fixed,,Brandon Li,Brandon Li,Sat; 5 Jan 2013 03:38:36 +0000,Wed; 15 May 2013 05:15:54 +0000,Mon; 7 Jan 2013 01:35:06 +0000,,1-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4914
MAPREDUCE-4915,Bug,Major,test,TestShuffleExceptionCount fails with open JDK7,This is a test order-dependency bug. The static variable abortCalled set by one test may affect the next tests.,Closed,Fixed,,Brandon Li,Brandon Li,Sat; 5 Jan 2013 03:44:08 +0000,Wed; 15 May 2013 05:15:55 +0000,Mon; 7 Jan 2013 01:40:43 +0000,,1-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4915
MAPREDUCE-4916,Bug,Major,,TestTrackerDistributedCacheManager is flaky due to other badly written tests in branch-1,Credit to Xuan figuring this: TestTrackerDistributedCacheManager is flaky due to other badly written tests since it checks for existence of a directory upfront which might have bad perms.,Closed,Fixed,,Xuan Gong,Arun C Murthy,Sat; 5 Jan 2013 07:25:13 +0000,Wed; 15 May 2013 05:16:16 +0000,Sat; 5 Jan 2013 08:16:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4916
MAPREDUCE-4917,Improvement,Major,contrib/raid,multiple BlockFixer should be supported in order to improve scalability and reduce too much work on single BlockFixer,current implementation can only run single BlockFixer since the fsck (in RaidDFSUtil.getCorruptFiles) only check the whole DFS file system. multiple BlockFixer will do the same thing and try to fix same file if multiple BlockFixer launched. the change BlockFixer,Resolved,Won't Fix,,Jun Jin,Jun Jin,Sat; 5 Jan 2013 07:49:54 +0000,Tue; 1 Aug 2017 17:14:47 +0000,Tue; 1 Aug 2017 17:14:47 +0000,,0.22.0,BB2015-05-TBR;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-4917
MAPREDUCE-4918,Bug,Minor,,Better error message in TrackerDistributedCacheManager.ancestorsHaveExecutePermissions,Better logging error message in TrackerDistributedCacheManager.ancestorsHaveExecutePermissions should help debugging (e.g. MAPREDUCE-4916). We should log the offending parent directory with the incorrect permissions.,Open,Unresolved,,Xuan Gong,Arun C Murthy,Sun; 6 Jan 2013 04:05:55 +0000,Wed; 20 Mar 2013 23:10:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4918
MAPREDUCE-4919,Bug,Major,client,All maps hangs when set mapreduce.task.io.sort.factor to 1,In one of my testing that when I set mapreduce.task.io.sort.factor to 1; all the maps hang and will never end. But the CPU usage for each node are very high and until killed by the app master when time out comes; and the job failed.   I traced the problem and found out that all the maps hangs on the final merge phase.  The while loop in computeBytesInMerges will never end with a factor of 1:  int f = 1;  in my case while (n  f || considerFinalMerge) {   ...    n -= (f-1);   f = factor; }  As the f-1 will equals 0 and n will always be 16 and the while runs for ever.,Patch Available,Unresolved,,Jerry Chen,Jerry Chen,Mon; 7 Jan 2013 05:38:05 +0000,Wed; 13 May 2015 14:40:22 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4919
MAPREDUCE-4920,Bug,Major,,Use security token protobuf definition from hadoop common,MR part of HADOOP-9173.,Closed,Fixed,,Suresh Srinivas,Vinod Kumar Vavilapalli,Mon; 7 Jan 2013 09:32:20 +0000,Fri; 15 Feb 2013 13:09:56 +0000,Mon; 7 Jan 2013 11:15:14 +0000,,,,YARN-315,YARN-315,https://issues.apache.org/jira/browse/MAPREDUCE-4920
MAPREDUCE-4921,Bug,Blocker,client,JobClient should acquire HS token with RM principal,The job client may acquire a history server token during job submission.  The renewer is specified in a config value that the user must supply (for new api; a bit different for old api).  If this value is not the RM's principal; then the RM cannot renew the token and long running jobs will fail.  Since the token is implicitly acquired for the job; the HS token's renewer should always be the RM's principal.,Closed,Fixed,,Daryn Sharp,Daryn Sharp,Mon; 7 Jan 2013 20:05:16 +0000,Thu; 12 May 2016 18:23:33 +0000,Tue; 15 Jan 2013 15:47:51 +0000,,2.0.3-alpha;0.23.6;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4921
MAPREDUCE-4922,Bug,Major,applicationmaster;mr-am;mrv2;scheduler,Request with multiple data local nodes can cause NPE in AppSchedulingInfo,With the way that the schedulers work; each request for a container on a node must consist of 3 ResourceRequests - one on the node; one on the rack; and one with *.  AppSchedulingInfo tracks the outstanding requests.  When a node is assigned a node-local container; allocateNodeLocal decrements the outstanding requests at each level - node; rack; and *.  If the rack requests reach 0; it removes the mapping.  A mapreduce task with multiple data local nodes submits multiple container requests; one for each node.  It also submits one for each unique rack; and one for *.  If there are fewer unique racks than data local nodes; this means that fewer rack-local ResourceRequests will be submitted than node-local ResourceRequests; so the rack-local mapping will be deleted before all the node-local requests are allocated and an NPE will come up the next time a node-local request from that rack is allocated.,Resolved,Won't Fix,,Sandy Ryza,Sandy Ryza,Tue; 8 Jan 2013 00:05:35 +0000,Fri; 8 Feb 2013 22:44:04 +0000,Fri; 8 Feb 2013 22:44:04 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4922
MAPREDUCE-4923,Bug,Minor,mrv1;mrv2;task,Add toString method to TaggedInputSplit,Per MAPREDUCE-3678; map task logs now contain information about the input split being processed.  Because TaggedInputSplit has no overridden toString method; nothing useful gets printed out.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 8 Jan 2013 00:13:49 +0000,Fri; 15 Feb 2013 13:10:00 +0000,Fri; 18 Jan 2013 00:44:22 +0000,,1.1.1;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4923
MAPREDUCE-4924,Bug,Trivial,mrv1,flakey test: org.apache.hadoop.mapred.TestClusterMRNotification.testMR,I occasionally get a failure like this on org.apache.hadoop.mapred.TestClusterMRNotification.testMR     It looks like a race condition:   Instead of sleeping for 2 seconds; we should keep checking the counter and fail after a timeout.  There's a couple of similar places in the test that should be fixed too.,Closed,Fixed,,Robert Kanter,Robert Kanter,Tue; 8 Jan 2013 01:37:46 +0000,Fri; 15 Feb 2013 13:10:00 +0000,Wed; 16 Jan 2013 01:08:08 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4924
MAPREDUCE-4925,Bug,Major,examples,The pentomino option parser may be buggy,MAPREDUCE-4678 adds an easier way to specify arguments to Pentomino; although it seems to carry a bug when fetching values.  This JIRA is for fixing that on trunk and backporting it onto branches.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 8 Jan 2013 06:33:24 +0000,Mon; 3 Nov 2014 18:33:40 +0000,Tue; 15 Jan 2013 13:57:15 +0000,,2.0.2-alpha;0.23.5,,MAPREDUCE-4930,,https://issues.apache.org/jira/browse/MAPREDUCE-4925
MAPREDUCE-4926,Bug,Minor,documentation,Change documentation to use mapreduce.jobtracker.split.metainfo.maxsize,Current 2.0 documentation points to mapreduce.job.split.metainfo.maxsize for restricting max size for job splits; while the code refers to mapreduce.jobtracker.split.metainfo.maxsize,Resolved,Duplicate,MAPREDUCE-4871,Unassigned,Lohit Vijayarenu,Tue; 8 Jan 2013 19:37:48 +0000,Tue; 8 Jan 2013 20:34:02 +0000,Tue; 8 Jan 2013 20:34:02 +0000,,2.0.2-alpha,,,MAPREDUCE-4871,https://issues.apache.org/jira/browse/MAPREDUCE-4926
MAPREDUCE-4927,Bug,Major,jobhistoryserver,Historyserver 500 error due to NPE when accessing specific counters page for failed job,Went to the historyserver page for a job that failed and examined the counters page.  When I clicked on a specific counter; the historyserver returned a 500 error.  The historyserver logs showed it encountered an NPE error; full traceback to follow.,Closed,Fixed,,Ashwin Shankar,Jason Lowe,Tue; 8 Jan 2013 20:21:12 +0000,Tue; 27 Aug 2013 22:22:07 +0000,Fri; 17 May 2013 20:27:50 +0000,,2.0.3-alpha;0.23.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4927
MAPREDUCE-4928,Improvement,Major,applicationmaster;security,Use token request messages defined in hadoop common ,MapReduce changes related to HADOOP-9192 to reuse the protobuf messages defined in common.,Closed,Fixed,,Suresh Srinivas,Suresh Srinivas,Wed; 9 Jan 2013 17:47:26 +0000,Thu; 2 May 2013 02:29:59 +0000,Tue; 15 Jan 2013 00:13:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4928
MAPREDUCE-4929,Bug,Major,mrv1,mapreduce.task.timeout is ignored,In MR1; only mapred.task.timeout works.  Both should be made to work.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 9 Jan 2013 19:02:55 +0000,Wed; 15 May 2013 05:15:50 +0000,Wed; 23 Jan 2013 11:07:17 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4929
MAPREDUCE-4930,Bug,Major,examples,Backport MAPREDUCE-4678 and MAPREDUCE-4925 to branch-1,MAPREDUCE-4678 adds convenient arguments to Pentomino; which would be nice to have in other branches as well.  However; MR-4678 introduces a bug - MR-4925 addresses this bug for all branches.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Thu; 10 Jan 2013 18:17:21 +0000,Mon; 3 Nov 2014 18:33:51 +0000,Tue; 15 Jan 2013 14:03:02 +0000,,1.1.1,,MAPREDUCE-4925;MAPREDUCE-4678,,https://issues.apache.org/jira/browse/MAPREDUCE-4930
MAPREDUCE-4931,Improvement,Minor,client,Add user-APIs for classpath precedence control,The feature config from MAPREDUCE-1938 of allowing tasks to start with user-classes-first is fairly popular and can use its own API hooks in Job JobConf:     Both of which; depending on their branch of commit; set the property mapreduce.user.classpath.first (1.x) or mapreduce.job.user.classpath.first (trunk; 2.x and if needed; in 0.23.x).,Resolved,Not A Problem,,Unassigned,Harsh J,Thu; 10 Jan 2013 18:58:05 +0000,Wed; 25 Mar 2015 06:50:29 +0000,Wed; 25 Mar 2015 06:50:28 +0000,,1.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4931
MAPREDUCE-4932,Bug,Major,mrv2,mapreduce.job#getTaskCompletionEvents incompatible with Hadoop 1,In MR1; org.apache.hadoop.mapreduce.Job#getTaskCompletionEvents takes one argument: int startFrom.  In MR2; it now takes an additional argument: int numEvents (which is the max number of events to get).  This makes them incompatible.    I propose we add a second getTaskCompletionEvents method that simply calls the other one with numEvents set to Integer.MAX_VALUE to replicate the behavior of the MR1 version.,Closed,Fixed,,Robert Kanter,Robert Kanter,Thu; 10 Jan 2013 19:03:18 +0000,Tue; 27 Aug 2013 22:21:57 +0000,Thu; 18 Apr 2013 21:44:07 +0000,,2.0.2-alpha,,MAPREDUCE-4942,,https://issues.apache.org/jira/browse/MAPREDUCE-4932
MAPREDUCE-4933,Bug,Major,mrv1;task,MR1 final merge asks for length of file it just wrote before flushing it,createKVIterator in ReduceTask contains the following code:    Merger#writeFile() does not close the file after writing it; so when fs.getFileStatus() is called on it; it may not return the correct length.  This causes bad accounting further down the line; which can lead to map output data being lost.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 10 Jan 2013 21:30:10 +0000,Wed; 15 May 2013 05:15:50 +0000,Thu; 28 Feb 2013 05:29:34 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4933
MAPREDUCE-4934,Bug,Critical,build,Maven RAT plugin is not checking all source files,mapreduce side of HADOOP-9097    Running 'mvn apache-rat:check' passes; but running RAT by hand (by downloading the JAR) produces some warnings for Java files; amongst others.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 11 Jan 2013 03:01:57 +0000,Wed; 3 Sep 2014 23:25:06 +0000,Mon; 14 Jan 2013 15:12:07 +0000,,2.0.2-alpha;0.23.5,,,HADOOP-9097,https://issues.apache.org/jira/browse/MAPREDUCE-4934
MAPREDUCE-4935,Bug,Major,jobtracker;mrv1,Support timeout limitation to MRv1 job end notifications ,Since MAPREDUCE-3028 only added timeout limitation to MRv2 job end notification; please add it to MRv1 job end notification.,Resolved,Fixed,MAPREDUCE-5066,Brad Liu,Olga Shen,Fri; 11 Jan 2013 07:59:37 +0000,Thu; 22 Aug 2013 02:51:20 +0000,Thu; 22 Aug 2013 02:51:20 +0000,,1.0.0,patch,,MAPREDUCE-1688,https://issues.apache.org/jira/browse/MAPREDUCE-4935
MAPREDUCE-4936,Bug,Critical,mrv2,JobImpl uber checks for cpu are wrong,"The cpu checks for uberizing have two issues:  	the defaults are hardcoded instead of using the conf defaults 	the comparison against the sys cpu size is using  instead of =       Everything is defaulting to 1; so uber cpu checks are now disabled causing TestUberAM to fail.",Closed,Fixed,,Arun C Murthy,Daryn Sharp,Fri; 11 Jan 2013 16:57:58 +0000,Fri; 15 Feb 2013 13:09:52 +0000,Tue; 15 Jan 2013 14:49:17 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4936
MAPREDUCE-4937,Bug,Major,mr-am,MR AM handles an oversized split metainfo file poorly,When an job runs with a split metainfo file that's larger than it has been configured to handle then it just crashes.  This leaves the user with a less-than-ideal debug session since there are no useful diagnostic messages sent to the client for this failure.  In addition it crashes before registering unregistering with the RM and crashes without generating history; so the proxy URL is not very useful and there's no archived configuration to check to see what setting the AM was using when it encountered the error.  The AM should handle this error case more gracefully and treat the failure as it does any other failed job; with a proper unregistration from the RM and with history.,Closed,Fixed,,Eric Payne,Jason Lowe,Fri; 11 Jan 2013 21:25:17 +0000,Wed; 3 Sep 2014 20:33:51 +0000,Fri; 18 Apr 2014 20:40:04 +0000,,2.0.2-alpha;0.23.5,,,YARN-522,https://issues.apache.org/jira/browse/MAPREDUCE-4937
MAPREDUCE-4938,Bug,Major,client,Job submission to unknown queue can leave staging directory behind,There is a race where submitting a job to an unknown queue can appear to succeed to the client and then subsequently fail later.  Since there was no AM ever launched; there was nothing left to cleanup the staging directory.  At that point the client is the only thing that can cleanup the staging directory.,Resolved,Duplicate,YARN-3131,Unassigned,Jason Lowe,Fri; 11 Jan 2013 21:56:48 +0000,Thu; 15 Oct 2015 22:50:56 +0000,Thu; 15 Oct 2015 22:50:56 +0000,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4938
MAPREDUCE-4939,Bug,Major,,Faulty getLocations input split passed on blindly to topology script,When users implement a (faulty) InputSplit that returns splits that do not map to hostnames; they get passed on to the topology script.  Call stack on 0.20 equivalent code: o.a.h.net.NetworkTopology.add o.a.h.mapred.JobTracker.addHostToNodeMapping o.a.h.mapred.JobTracker.resolveAndAddToTopology o.a.h.mapred.JobInProgress.createCache o.a.h.mapred.JobInProgress.initTasks o.apache.hadoop.mapred.JobTracker.initJob  The CachedDNSToSwitchMapping wraps RawScriptBasedMapping (if a topology script is configured).  The arguments (input splits) are simply passed to the topology script as arguments without any further checks. The input split could incorrectly return a comma separated list of hosts; or in the worst case something like    In 2.0 something similar happens in ScriptBasedMapping.runResolveCommand. That method should check the input values before executing the command.,Open,Unresolved,,Unassigned,Joep Rottinghuis,Fri; 11 Jan 2013 22:12:02 +0000,Fri; 11 Jan 2013 22:20:37 +0000,,,0.20.205.0;2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4939
MAPREDUCE-4940,Bug,Major,,division by zero in getLocalPathForWrite(),see https:    Here is related code:   My guess is that totalAvailable was 0; meaning dirDF was empty.,Resolved,Duplicate,HADOOP-9079,Unassigned,Ted Yu,Mon; 14 Jan 2013 14:58:52 +0000,Wed; 24 Apr 2013 14:31:09 +0000,Mon; 14 Jan 2013 15:05:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4940
MAPREDUCE-4941,Bug,Minor,,Use of org.apache.hadoop.mapred.lib.CombineFileRecordReader requires casting,Unlike its counterpart in org.apache.hadoop.mapreduce.lib.input; the CombineFileRecordReader in mapred requires a user to cast to a RecordReader since the constructor specification says it must have the RecordReaderK;V class as a parameter.  It should use Class? extends RecordReaderK;V&gt; like its mapreduce counterpart to make it easier to use.,Resolved,Won't Fix,,Jason Lowe,Jason Lowe,Mon; 14 Jan 2013 22:34:25 +0000,Tue; 8 Apr 2014 14:33:55 +0000,Tue; 8 Apr 2014 14:33:55 +0000,,2.0.2-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4941
MAPREDUCE-4942,Sub-task,Major,mrv2,mapreduce.Job has a bunch of methods that throw InterruptedException so its incompatible with MR1,The following methods in MR2's org.apache.hadoop.mapreduce.Job throw an InterruptedException but don't in MR1; which makes them incompatible.  (Their Javadoc comments are also missing that they throw an InterruptedException anyway)  I propose that we wrap the InterruptedException in a RuntimeException.,Closed,Fixed,,Robert Kanter,Robert Kanter,Tue; 15 Jan 2013 01:25:36 +0000,Tue; 27 Aug 2013 22:22:15 +0000,Fri; 14 Jun 2013 23:11:10 +0000,,2.0.2-alpha,,MAPREDUCE-4932,,https://issues.apache.org/jira/browse/MAPREDUCE-4942
MAPREDUCE-4943,Improvement,Major,,JobImpl.makeUberDecision needs cleanup,"JobImpl.makeUberDecision needs cleanup:  	Uses hard-coded default values in lots of places 	Need to fix it to use block-size of input while checking input-data 	Need to stop using JobConf.DISABLED_MEMORY_LIMIT 	Could use a real unit test",Open,Unresolved,,Arun C Murthy,Arun C Murthy,Tue; 15 Jan 2013 12:48:31 +0000,Tue; 15 Jan 2013 12:48:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4943
MAPREDUCE-4944,New Feature,Minor,,Backport YARN-40 to support listClusterNodes and printNodeStatus in command line tool,support listClusterNodes and printNodeStatus in command line tool is useful for admin to create certain automation tools; this can also used by MAPREDUCE-4900 to get TaskTracker name so can set TT's slot dynamically,Open,Unresolved,,Unassigned,Binglin Chang,Wed; 16 Jan 2013 08:06:54 +0000,Tue; 14 May 2013 05:14:44 +0000,,,1.1.1,,,YARN-40;MAPREDUCE-4900,https://issues.apache.org/jira/browse/MAPREDUCE-4944
MAPREDUCE-4945,Bug,Major,tasktracker,FileOutputCommitter.abortTask should check a result of outputFileSystem.delete(workPath; true);,MAPREDUCE-1409 partially fixes a problem with an retained output of aborted tasks - unfortunately; the fix is incomplete; there are cases when a delete() method does neither deletes a file nor throws an exception; but merely returns false. That means that its return value shall be checked  and if it is false and a file still exists an exception should be thrown.,Open,Unresolved,,Unassigned,Oleksandr Alesinskyy,Wed; 16 Jan 2013 08:16:32 +0000,Wed; 16 Jan 2013 08:16:32 +0000,,,0.20.205.0;0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4945
MAPREDUCE-4946,Bug,Critical,mr-am,Type conversion of map completion events leads to performance problems with large jobs,We've seen issues with large jobs (e.g.: 13;000 maps and 3;500 reduces) where reducers fail to connect back to the AM after being launched due to connection timeout.  Looking at stack traces of the AM during this time we see a lot of IPC servers stuck waiting for a lock to get the application ID while type converting the map completion events.  What's odd is that normally getting the application ID should be very cheap; but in this case we're type-converting thousands of map completion events for each reducer connecting.  That means we end up type-converting the map completion events over 45 million times during the lifetime of the example job (13;000 * 3;500).  We either need to make the type conversion much cheaper (i.e.: lockless or at least read-write locked) or; even better; store the completion events in a form that does not require type conversion when serving them up to reducers.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 17 Jan 2013 17:27:17 +0000,Fri; 15 Feb 2013 13:09:58 +0000,Tue; 22 Jan 2013 19:09:33 +0000,,2.0.2-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4946
MAPREDUCE-4947,Bug,Minor,,Random task failures during TeraSort job,During most of my terasort jobs; I see occasional; random map task failures during the reduce phase.  Usually there will be only 1-4 task failures during a job; with the job completing successfully.  On rare occasions; a tasktracker will be blacklisted.  Below are the usual error messages: ======================================== NFO mapred.JobClient: Task Id : attempt_201301151521_0002_m_005954_0; Status : FAILED  258) WARN mapred.JobClient: Error reading task outputhttp: tasklog?plaintext=trueattemptid=attempt_201301151521_0002_m_005954_0filter=stderr ========================================== Tasktracker nodes are considered for 8 map and 7 reduce slots each for a total of 32 map slots and 28 reduce slots for the 4 datanode cluster.  The problem never occurs; during teragen jobs and only occur after reduce copies start.  Cutting the number of slots in half helps to reduce the frequency; but the problem still occurs.   Actions taken without any success: ulimit increases for nproc and nofile to 32768 and then 65536 setting MALLOC_ARENA_MAX=4 in the hadoop-env.sh file per HADOOP-7154. heapsize increases and reductions reduction of map and reduce slots as stated above various modifications of mapreduce and hdfs properties  I've done quite a bit of testing with CDH3 on the same hardware and not encountered this problem; so I suspect there may be a bug fix or patch I'm missing.  Any suggestions for further isolating the problem or application of patches would be much appreciated.  Thanks in advance!,Open,Unresolved,,Unassigned,John Elliott,Fri; 18 Jan 2013 14:35:51 +0000,Fri; 18 Jan 2013 14:35:51 +0000,,,0.20.205.0;1.0.0;1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4947
MAPREDUCE-4948,Bug,Critical,client,TestYARNRunner.testHistoryServerToken failed on trunk,The failed log:,Closed,Fixed,,Junping Du,Junping Du,Fri; 18 Jan 2013 09:22:49 +0000,Fri; 15 Feb 2013 13:09:52 +0000,Fri; 18 Jan 2013 19:31:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4948
MAPREDUCE-4949,Improvement,Minor,examples,Enable multiple pi jobs to run in parallel,Currently the hadoop pi example uses a hardcoded temporary directory to store its inputs and outputs.  This makes it so that only one pi job can run at a time; and that if it is cancelled; the temporary directory must be manually deleted.  I propose using a temporary directory based on a timestamp and random number to avoid these conflicts,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 18 Jan 2013 22:29:38 +0000,Fri; 15 Feb 2013 13:10:03 +0000,Tue; 22 Jan 2013 16:29:12 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4949
MAPREDUCE-4950,Bug,Critical,jobhistoryserver;mr-am,MR App Master fails to write the history due to AvroTypeException,nan,Open,Unresolved,,Unassigned,Devaraj K,Sun; 20 Jan 2013 11:58:26 +0000,Thu; 6 Jul 2017 19:13:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4950
MAPREDUCE-4951,Sub-task,Major,applicationmaster;mr-am;mrv2,Container preemption interpreted as task failure,When YARN reports a completed container to the MR AM; it always interprets it as a failure.  This can lead to a job failing because too many of its tasks failed; when in fact they only failed because the scheduler preempted them.  MR needs to recognize the special exit code value of -100 and interpret it as a container being killed instead of a container failure.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Mon; 21 Jan 2013 03:00:28 +0000,Wed; 21 May 2014 21:30:11 +0000,Thu; 21 Feb 2013 12:05:01 +0000,,2.0.2-alpha,,,YARN-352;MAPREDUCE-4788,https://issues.apache.org/jira/browse/MAPREDUCE-4951
MAPREDUCE-4952,Bug,Major,scheduler,FSSchedulerNode is always instantiated with a 0 virtual core capacity,After YARN-2; FSSchedulerNode was not updated to initialize with the underlying RMNode's CPU capacity; and thus always has 0 virtual cores.,Resolved,Invalid,,Sandy Ryza,Sandy Ryza,Mon; 21 Jan 2013 03:04:21 +0000,Mon; 21 Jan 2013 17:41:34 +0000,Mon; 21 Jan 2013 03:14:22 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4952
MAPREDUCE-4953,Bug,Major,pipes,HadoopPipes misuses fprintf,nan,Closed,Fixed,,Andy Isaacson,Andy Isaacson,Mon; 21 Jan 2013 21:50:54 +0000,Thu; 12 May 2016 18:22:32 +0000,Tue; 5 Feb 2013 04:54:50 +0000,,2.0.3-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4953
MAPREDUCE-4954,Bug,Major,,ShuffleHandler logs excessively when channel closed prematurely by reducer,As initially reported in MAPREDUCE-4801; the shuffle protocol allows a reducer to hangup the connection to a nodemanager after receiving the shuffle header.  This can introduce a connection reset IOException or a ClosedChannelException on the nodemanager.  Logging these is not very interesting; and adds a lot of data to the NM log.  MAPREDUCE-4801 missed some places where these exceptions can occur; will post sample exceptions below for reference.,Resolved,Not A Problem,,Unassigned,Jason Lowe,Tue; 22 Jan 2013 16:16:02 +0000,Tue; 22 Jan 2013 16:22:37 +0000,Tue; 22 Jan 2013 16:22:37 +0000,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4954
MAPREDUCE-4955,Bug,Major,mr-am,NM container diagnostics for excess resource usage can be lost if task fails while being killed ,When a nodemanager kills a container for being over resource budgets; it provides a diagnostics message for the container status explaining why it was killed.  However this message can be lost if the task fails during the shutdown from the SIGTERM (e.g.: lost DFS leases because filesystem closed) and notifies the AM via the task umbilical before the AM receives the NM's container status message via the RM heartbeat.  In that case the task attempt fails with the task's failure diagnostic; and the user is left wondering exactly why the task failed because the NM's diagnostics arrive too late; are not written to the history file; and are lost.  If the AM receives the container status via the RM heartbeat before the task fails during shutdown then the diagnostics are written properly to the history file; and the user can see why the task failed.,Open,Unresolved,,Unassigned,Jason Lowe,Tue; 22 Jan 2013 20:23:24 +0000,Thu; 31 Aug 2017 15:52:24 +0000,,,2.0.3-alpha;0.23.5,,,TEZ-3191;MAPREDUCE-6771,https://issues.apache.org/jira/browse/MAPREDUCE-4955
MAPREDUCE-4956,Improvement,Major,,The Additional JH Info Should Be Exposed,In MAPREDUCE-4838; the addition info has been added to JH. This info is useful to be exposed; at least via UI.,Patch Available,Unresolved,,Zhijie Shen,Zhijie Shen,Wed; 23 Jan 2013 21:43:18 +0000,Wed; 6 May 2015 03:31:38 +0000,,,,BB2015-05-TBR,,MAPREDUCE-4838,https://issues.apache.org/jira/browse/MAPREDUCE-4956
MAPREDUCE-4957,Bug,Minor,,"Throw FileNotFoundException when running in single node and ""mapreduce.framework.name"" is local","Run in single node and ""mapreduce.framework.name"" is local; and get following error:   io.FileNotFoundException(File does not exist:  hive-builtins-0.11.0-SNAPSHOT.jar)'",Patch Available,Unresolved,,Yi Liu,Yi Liu,Thu; 24 Jan 2013 02:18:54 +0000,Wed; 6 May 2015 03:33:07 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4957
MAPREDUCE-4958,Bug,Major,mrv1,close method of RawKeyValueIterator is not called after finish using.,I observed that the close method of the RawKeyValueIterator returned from MergeManager is not called.  Which will cause resource leaks for RawKeyValueIterator implementation which depends on the RawKeyValueIterator.close for doing cleanup when finished.  Some other places in MapTask also not follow the convension to call RawKeyValueIterator.close after use it.,Open,Unresolved,,Jerry Chen,Jerry Chen,Thu; 24 Jan 2013 05:52:14 +0000,Tue; 10 Mar 2015 04:30:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4958
MAPREDUCE-4959,Bug,Major,tasktracker,bundling classpath into jar manifest on Windows does not expand environment variables or wildcards,To support long classpaths on Windows; the class path entries get bundled into a small temporary jar with a manifest that has a Class-Path attribute.  When a classpath is specified in a jar manifest like this; it does not expand environment variables (i.e. %HADOOP_COMMON_HOME%); and it does not expand wildcards (i.e. lib *.jar).,Open,Unresolved,,Unassigned,Chris Nauroth,Thu; 24 Jan 2013 18:58:27 +0000,Mon; 5 Aug 2013 21:09:08 +0000,,,1-win,,,HADOOP-8899;YARN-316,https://issues.apache.org/jira/browse/MAPREDUCE-4959
YARN-362,Bug,Minor,,Unexpected extra results when using webUI table search,"When using the search box on the web UI to search for a specific task number (e.g.: ""0831""); sometimes unexpected extra results are shown.  Using the web browser's built-in search-within-page does not show any hits; so these look like completely spurious results.  It looks like the raw timestamp value for time columns; which is not shown in the table; is also being searched with the search box.",Closed,Fixed,,Ravi Prakash,Jason Lowe,Thu; 24 Jan 2013 20:32:47 +0000,Tue; 27 Aug 2013 22:15:12 +0000,Fri; 8 Feb 2013 16:07:05 +0000,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/YARN-362
MAPREDUCE-4961,Bug,Major,,Map reduce running local should also go through ShuffleConsumerPlugin for enabling different MergeManager implementations,MAPREDUCE-4049 provide the ability for pluggable Shuffle and MAPREDUCE-4080 extends Shuffle to be able to provide different MergeManager implementations.   While using these pluggable features; I find that when a map reduce is running locally; a RawKeyValueIterator was returned directly from a static call of Merge.merge; which break the assumption that the Shuffle may provide different merge methods although there is no copy phase for this situation.  The use case is when I am implementating a hash-based MergeManager; we don't need sort in map side; while when running the map reduce locally; the hash-based MergeManager will have no chance to be used as it goes directly to Merger.merge. This makes the pluggable Shuffle and MergeManager incomplete.  So we need to move the code calling Merger.merge from Reduce Task to ShuffleConsumerPlugin implementation; so that the Suffle implementation can decide how to do the merge and return corresponding iterator.,Patch Available,Unresolved,,Jerry Chen,Jerry Chen,Fri; 25 Jan 2013 07:26:04 +0000,Wed; 6 May 2015 03:27:28 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4961
MAPREDUCE-4962,Bug,Major,jobtracker;mrv1,jobdetails.jsp uses display name instead of real name to get counters,jobdetails.jsp displays details for a job including its counters.  Counters may have different real names and display names; but the display names are used to look the counter values up; so counter values can incorrectly show up as 0.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Sat; 26 Jan 2013 01:21:43 +0000,Wed; 15 May 2013 05:16:04 +0000,Sat; 26 Jan 2013 20:34:05 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4962
MAPREDUCE-4963,Bug,Major,mrv1,"StatisticsCollector improperly keeps track of ""Last Day"" and ""Last Hour"" statistics for new TaskTrackers","The StatisticsCollector keeps track of updates to the ""Total Tasks Last Day""; ""Succeed Tasks Last Day""; ""Total Tasks Last Hour""; and ""Succeeded Tasks Last Hour"" per Task Tracker which is displayed on the JobTracker web UI.  It uses buckets to manage when to shift task counts from ""Last Hour"" to ""Last Day"" and out of ""Last Day"".  After the JT has been running for a while; the connected TTs will have the max number of buckets and will keep shifting them at each update.  If a new TT connects (or an old on rejoins); it won't have the max number of buckets; but the code that drops the buckets uses the same counter for all sets of buckets.  This means that new TTs will prematurely drop their buckets and the stats will be incorrect.    example:  	Max buckets is 5 	TaskTracker A has these values in its buckets 4; 2; 0; 3; 10 (i.e. 19) 	A new TaskTracker; B; connects; it has nothing in its buckets: [ ] (i.e. 0) 	TaskTracker B runs 3 tasks and TaskTracker A runs 5 	An update occurs 	TaskTracker A has 2; 0; 3; 10; 5 (i.e. 20) 	TaskTracker B should have 3 but it will drop that bucket after adding it during the update and instead have [ ] again (i.e. 0) 	TaskTracker B will keep doing that forever and always show 0 in the web UI    We can fix this by not using the same counter for all sets of buckets",Closed,Fixed,MAPREDUCE-4227,Robert Kanter,Robert Kanter,Sat; 26 Jan 2013 03:18:59 +0000,Wed; 15 May 2013 05:15:58 +0000,Sat; 26 Jan 2013 04:30:21 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4963
MAPREDUCE-4964,Bug,Major,mrv1,JobLocalizer#localizeJobFiles can potentially write job.xml to the wrong user's directory,In the following code; if jobs corresponding to different users (X and Y) are localized simultaneously; it is possible that jobconf can be written to the wrong user's directory. (X's job.xml can be written to Y's directory),Resolved,Duplicate,MAPREDUCE-4843,Karthik Kambatla,Karthik Kambatla,Sun; 27 Jan 2013 01:48:23 +0000,Mon; 3 Nov 2014 18:33:46 +0000,Mon; 4 Feb 2013 22:17:03 +0000,,1.1.1,,,MAPREDUCE-4843,https://issues.apache.org/jira/browse/MAPREDUCE-4964
MAPREDUCE-4965,Bug,Major,mrv2,In merge; no ordering defined for CompressAwarePath,MAPREDUCE-2264 replaced Paths used in the merge with CompressAwarePaths. In MergeManagerImpl; onDiskMapOutputs is maintained as a TreeSet of CompressAwarePaths; but CompressAwarePath does not implement Comparable; and no Comparator is passed; so there is no defined ordering.,Resolved,Duplicate,MAPREDUCE-2264,Sandy Ryza,Sandy Ryza,Mon; 28 Jan 2013 09:26:30 +0000,Mon; 28 Jan 2013 18:56:48 +0000,Mon; 28 Jan 2013 18:56:48 +0000,,2.0.3-alpha,,,MAPREDUCE-2264,https://issues.apache.org/jira/browse/MAPREDUCE-4965
MAPREDUCE-4966,Improvement,Minor,jobhistoryserver,Env variable for JobHistory JVM OPTS,There seems to be no option to set JVM OPTS for JobHistoryServer. One of the common setting is having Xmx value passed to it. As of now it can be done only via JVM_OPTS or HADOOP_CLIENT_OPTS. It would be good to have something specific for JobHistoryServer,Resolved,Invalid,,Unassigned,Lohit Vijayarenu,Mon; 28 Jan 2013 21:07:02 +0000,Wed; 30 Jan 2013 04:28:24 +0000,Tue; 29 Jan 2013 20:11:08 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4966
MAPREDUCE-4967,Bug,Major,tasktracker;test,TestJvmReuse fails on assertion,TestJvmReuse on branch-1 consistently fails on an assertion.,Closed,Fixed,,Karthik Kambatla,Chris Nauroth,Wed; 30 Jan 2013 07:19:00 +0000,Mon; 3 Nov 2014 18:05:41 +0000,Wed; 6 Feb 2013 01:38:46 +0000,,1.1.2,,,MAPREDUCE-4979,https://issues.apache.org/jira/browse/MAPREDUCE-4967
MAPREDUCE-4968,Improvement,Major,,Separate MR user apis into a separate module,It will be useful to separate MR user apis into a separate module.,Open,Unresolved,,Arun C Murthy,Arun C Murthy,Wed; 30 Jan 2013 12:42:45 +0000,Wed; 30 Jan 2013 12:42:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4968
MAPREDUCE-4969,Bug,Major,test,TestKeyValueTextInputFormat test fails with Open JDK 7,RawLocalFileSystem.delete fails on Windows even when the files are not expected to be in use. It does not reproduce with Sun JDK 6.,Closed,Fixed,,Arpit Agarwal,Arpit Agarwal,Wed; 2 Jan 2013 22:17:50 +0000,Thu; 12 May 2016 18:24:15 +0000,Thu; 31 Jan 2013 17:27:55 +0000,,1.2.0;1-win;trunk-win;3.0.0-alpha1,,,MAPREDUCE-4909,https://issues.apache.org/jira/browse/MAPREDUCE-4969
MAPREDUCE-4970,Bug,Major,,Child tasks (try to) create security audit log files,After HADOOP-8552; MR child tasks will attempt to create security audit log files with their user names.  On an insecure cluster; this has no effect; but on a secure cluster; log4j will try to create log files for tasks with names like SecurityAuth-joeuser.log.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 31 Jan 2013 22:49:17 +0000,Wed; 15 May 2013 05:16:10 +0000,Wed; 6 Feb 2013 01:48:38 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4970
MAPREDUCE-4971,Improvement,Minor,,Minor extensibility enhancements ,Minor extensibility enhancements to Counters  FileOutputFormat.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 1 Feb 2013 15:32:40 +0000,Fri; 15 Feb 2013 13:09:55 +0000,Sat; 2 Feb 2013 00:49:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4971
MAPREDUCE-4972,Test,Major,,Coverage fixing for org.apache.hadoop.mapreduce.jobhistory ,Coverage fixing for package org.apache.hadoop.mapreduce.jobhistory,Closed,Fixed,,Aleksey Gorshkov,Aleksey Gorshkov,Mon; 26 Nov 2012 12:34:07 +0000,Thu; 12 May 2016 18:24:28 +0000,Wed; 20 Mar 2013 16:18:54 +0000,,0.23.7;2.0.4-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4972
MAPREDUCE-4973,Bug,Major,mrv1,Backport history clean up configurations to branch-1,In trunk-based versions; we can configure the max-age of files after which they will be cleaned up. This JIRA is to backport those configurations to branch-1.,Resolved,Duplicate,MAPREDUCE-4643,Karthik Kambatla,Karthik Kambatla,Fri; 1 Feb 2013 23:21:10 +0000,Mon; 3 Nov 2014 18:33:23 +0000,Tue; 5 Feb 2013 02:05:10 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4973
MAPREDUCE-4974,Improvement,Major,mrv1;mrv2;performance,Optimising the LineRecordReader initialize() method,I found there is a a scope of optimizing the code; over initialize() if we have compressionCodecs  codec instantiated only if its a compressed input. Mean while Gelesh George Omathil; added if we could avoid the null check of key  value. This would time save; since for every next key value generation; null check is done. The intention being to instantiate only once and avoid NPE as well. Hope both could be met if initialize key  value over  initialize() method. We both have worked on it.,Closed,Fixed,,Gelesh,Arun A K,Mon; 4 Feb 2013 12:25:53 +0000,Tue; 10 Mar 2015 04:30:31 +0000,Mon; 15 Apr 2013 21:37:10 +0000,,2.0.2-alpha,patch;performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-4974
MAPREDUCE-4975,Bug,Major,,gridmix docs missing,The docs for hadoop streaming and gridmix weren't moved out of the mrv1 code so don't existing in the 0.23 or 2.x line.   ie the 1.X line are http: gridmix.html  We should also check for others that are missing.,Open,Unresolved,,Unassigned,Thomas Graves,Mon; 4 Feb 2013 14:55:22 +0000,Sat; 7 Jan 2017 01:59:57 +0000,,,0.23.6,,,MAPREDUCE-5637,https://issues.apache.org/jira/browse/MAPREDUCE-4975
MAPREDUCE-4976,Improvement,Minor,,Use the new StringUtils methods added by HADOOP-9252,HADOOP-9252 slightly changed the format of some StringUtils outputs.  Some methods were deprecated by HADOOP-9252.  The use of them should be replaced with the new methods.,Resolved,Not A Problem,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Mon; 4 Feb 2013 21:32:42 +0000,Wed; 26 Mar 2014 00:38:29 +0000,Wed; 26 Mar 2014 00:38:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4976
MAPREDUCE-4977,Improvement,Major,documentation,Documentation for pluggable shuffle and pluggable sort,Add documentation with basic information on pluggable shuffle and sort.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Tue; 5 Feb 2013 20:27:37 +0000,Fri; 15 Feb 2013 13:10:07 +0000,Wed; 6 Feb 2013 19:53:30 +0000,,2.0.3-alpha,,,MAPREDUCE-4049;MAPREDUCE-4807,https://issues.apache.org/jira/browse/MAPREDUCE-4977
MAPREDUCE-4978,Improvement,Major,,Add a updateJobWithSplit() method for new-api job,HADOOP-1230 adds a method updateJobWithSplit(); which only works for old-api job. It's better to add another method for new-api job.,Resolved,Won't Fix,,Liyin Liang,Liyin Liang,Wed; 6 Feb 2013 02:56:46 +0000,Mon; 18 May 2015 17:28:22 +0000,Mon; 18 May 2015 17:28:22 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4978
MAPREDUCE-4979,Bug,Major,test,TestJvmReuse must be fixed or removed from branch-1,TestJvmReuse on branch-1 is currently ignored.  If the test is not marked ignored; then it fails.  It's unclear if the test failure indicates that we need to fix a bug or if the test is irrelevant and needs to be deleted.  This jira tracks either fixing the test or removing it.,Resolved,Won't Fix,,Unassigned,Chris Nauroth,Wed; 6 Feb 2013 04:11:51 +0000,Sat; 26 Nov 2016 01:59:41 +0000,Sat; 26 Nov 2016 01:59:41 +0000,,1.2.0,,,MAPREDUCE-3480;MAPREDUCE-4967,https://issues.apache.org/jira/browse/MAPREDUCE-4979
MAPREDUCE-4980,Test,Major,test,Parallel test execution of hadoop-mapreduce-client-core,The maven surefire plugin supports parallel testing feature. By using it; the tests can be run more faster.,Patch Available,Unresolved,,Andrey Klochkov,Tsuyoshi Ozawa,Wed; 6 Feb 2013 06:58:24 +0000,Fri; 15 Sep 2017 20:06:07 +0000,,,3.0.0-alpha1,,,MAPREDUCE-6674,https://issues.apache.org/jira/browse/MAPREDUCE-4980
MAPREDUCE-4981,Bug,Minor,,WordMean; WordMedian; WordStandardDeviation missing from ExamplesDriver,https: dir path output dir path  Just like they do for running the wordcount example.,Closed,Fixed,,Plamen Jeliazkov,Plamen Jeliazkov,Wed; 6 Feb 2013 19:05:46 +0000,Thu; 12 May 2016 18:22:47 +0000,Thu; 11 Apr 2013 20:34:24 +0000,,2.0.3-alpha;3.0.0-alpha1,,,MAPREDUCE-2669,https://issues.apache.org/jira/browse/MAPREDUCE-4981
MAPREDUCE-4982,Bug,Major,mr-am,AM hung with one pending map task,Saw a job that hung with one pending map task that never ran.  The task was in the SCHEDULED state with a single attempt that was in the UNASSIGNED state.  The AM looked like it was waiting for a container from the RM; but the RM was never granting it the one container it needed.  I suspect the AM botched the container request bookkeeping somehow.  More details to follow.,Resolved,Duplicate,MAPREDUCE-4893,Unassigned,Jason Lowe,Wed; 6 Feb 2013 19:26:04 +0000,Wed; 13 Feb 2013 02:00:33 +0000,Fri; 8 Feb 2013 23:11:32 +0000,,0.23.6,,,MAPREDUCE-5002,https://issues.apache.org/jira/browse/MAPREDUCE-4982
MAPREDUCE-4983,Bug,Major,test,multiple MapReduce tests fail on Windows due to platform-specific assumptions in test code,Multiple MapReduce tests have code that makes platform-specific assumptions which do not hold true on Windows.  This includes assumptions about file path manipulation; the path separator used between classpath elements; environment variable syntax; and order of files returned from a directory listing of the local file system.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Wed; 6 Feb 2013 22:52:18 +0000,Thu; 7 Feb 2013 04:58:50 +0000,Thu; 7 Feb 2013 04:05:56 +0000,,trunk-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4983
MAPREDUCE-4984,Improvement,Major,applicationmaster;mr-am,AM leaves unwanted node/rack requests after container has been assigned,Consider the following situation: node1; node2; and node3 are all on rack1 task1 is submitted with resource requests on node1; node2; rack1; and * task2 is submitted with resource requests on node3; rack1; and *  The RM gives a container to the app on node1; on which the AM assigns task1.  While node1 is removed from the scheduler's bookkeeping; node2 is not; so its delay scheduling will try as hard to assign a container there is it would to node3.  The AM should cancel its request for node2 on its next heartbeat by sending a resource request with # containers = 0.,Resolved,Duplicate,MAPREDUCE-4671,Sandy Ryza,Sandy Ryza,Wed; 6 Feb 2013 23:03:26 +0000,Wed; 6 Feb 2013 23:59:43 +0000,Wed; 6 Feb 2013 23:59:43 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4984
MAPREDUCE-4985,Bug,Trivial,,TestDFSIO supports compression but usages doesn't reflect,https: MAPREDUCE-2786 introduced the ability to use a compression codec during TestDFSIO. However; the -compression parameter was never introduced to the usages printout.  This is a trivial patch to reveal the parameter to end users.,Closed,Fixed,,Plamen Jeliazkov,Plamen Jeliazkov,Thu; 7 Feb 2013 00:04:15 +0000,Tue; 27 Aug 2013 22:22:03 +0000,Thu; 11 Apr 2013 23:51:20 +0000,,2.0.3-alpha,,,MAPREDUCE-2786,https://issues.apache.org/jira/browse/MAPREDUCE-4985
MAPREDUCE-4986,Bug,Major,contrib/fair-share;documentation,Document the locality effect of preemption timeouts in FairScheduler when mapred.fairscheduler.preemption is off,fair_scheduler.xml does not mention the delay scheduling algorithm. Furthermore; it does not explain that in getAllowedLocalityLevel the preemption timeouts are used to disable the locality delay scheduling for the starved pool when mapred.fairscheduler.preemption=false (default).,Open,Unresolved,,Unassigned,Gera Shegalov,Thu; 7 Feb 2013 00:27:38 +0000,Thu; 7 Feb 2013 00:30:18 +0000,,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4986
MAPREDUCE-4987,Bug,Major,distributed-cache;nodemanager,TestMRJobs#testDistributedCache fails on Windows due to classpath problems and unexpected behavior of symlinks,On Windows; TestMRJobs#testDistributedCache fails on an assertion while checking the length of a symlink.  It expects to see the length of the target of the symlink; but Java 6 on Windows always reports that a symlink has length 0.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Thu; 7 Feb 2013 04:49:29 +0000,Thu; 12 May 2016 18:22:39 +0000,Fri; 19 Apr 2013 19:33:41 +0000,,3.0.0-alpha1,,,HADOOP-9061;YARN-593;HADOOP-9488;YARN-488,https://issues.apache.org/jira/browse/MAPREDUCE-4987
MAPREDUCE-4988,Bug,Minor,test,ClusterWithCapacityScheduler and related testcases needs to be ported to JUnit4.,TestJobTrackerRestartWithCS; TestCapacitySchedulerServlet; and TestCapacitySchedulerWithJobTracker testcases potentially could fail when they are build with ant 1.8.4. Solution: port above testcases and ClusterWithCapacityScheduler class from Junit3 to Junit4.,Open,Unresolved,,Unassigned,Amir Sanjar,Thu; 7 Feb 2013 18:31:04 +0000,Wed; 6 Mar 2013 09:50:52 +0000,,,1.1.1;1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4988
MAPREDUCE-4989,Improvement,Major,jobhistoryserver;mr-am,JSONify DataTables input data for Attempts page,Use deferred rendering for the attempts page as was done in MAPREDUCE-4720. I'm sorry I didn't realize earlier that this table could be huge too. Thanks to Jason Lowe for pointing it out.,Closed,Fixed,MAPREDUCE-5024,Ravi Prakash,Ravi Prakash,Fri; 8 Feb 2013 00:01:08 +0000,Tue; 27 Aug 2013 22:22:11 +0000,Wed; 13 Feb 2013 01:22:47 +0000,,0.23.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4989
MAPREDUCE-4990,Improvement,Trivial,,Construct debug strings conditionally in ShuffleHandler.Shuffle#sendMapOutput(),In #sendMapOutput(); the debug statements are not wrapped in the customary #isDebugEnabled() condition. Given this piece of code is critical for performance; it would be nice to fix it.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 8 Feb 2013 06:28:05 +0000,Mon; 3 Nov 2014 18:33:47 +0000,Mon; 18 Mar 2013 18:46:56 +0000,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4990
MAPREDUCE-4991,Test,Major,,coverage for gridmix,fix coverage for GridMix MAPREDUCE-4991-trunk.patch patch for thunk MAPREDUCE-4991-branch-2.patch for branch-2 and  MAPREDUCE-4991-branch-0.23.patch for branch-0.23  known fail -org.apache.hadoop.mapred.gridmix.TestGridmixSummary.testExecutionSummarizer. It is for next issue,Closed,Fixed,MAPREDUCE-4242,Aleksey Gorshkov,Aleksey Gorshkov,Fri; 8 Feb 2013 12:05:14 +0000,Thu; 12 May 2016 18:23:50 +0000,Wed; 3 Apr 2013 01:48:22 +0000,,2.0.3-alpha;0.23.7;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4991
MAPREDUCE-4992,Bug,Critical,mr-am,AM hangs in RecoveryService when recovering tasks with speculative attempts,A job hung in the Recovery Service on an AM restart. There were four map tasks events that were not processed and that prevented the complete task count from reaching zero which exits the recovery service. All four tasks were speculative,Closed,Fixed,,Robert Parker,Robert Parker,Fri; 8 Feb 2013 14:36:21 +0000,Tue; 10 Mar 2015 04:30:47 +0000,Fri; 29 Mar 2013 15:40:13 +0000,,2.0.2-alpha;0.23.6,,,MAPREDUCE-5079;MAPREDUCE-5003,https://issues.apache.org/jira/browse/MAPREDUCE-4992
MAPREDUCE-4993,Bug,Major,mr-am,AM thinks it was killed when an error occurs setting up a task container launch context,If an IOException occurs while setting up a container launch context for a task then the AM exits with a KILLED status and no diagnostics.  The job should be marked as FAILED (or maybe ERROR) with a useful diagnostics message indicating the nature of the error.,Open,Unresolved,,Abhishek Kapoor,Jason Lowe,Fri; 8 Feb 2013 17:44:34 +0000,Thu; 7 Mar 2013 15:30:27 +0000,,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4993
MAPREDUCE-4994,Bug,Major,client,#NAME?,hadoop jar myjar.jar MyDriver -fs file: port  This appears to be because Cluster#initialize; which loads the ClientProtocol; contains no special handling for mapred.job.tracker.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 8 Feb 2013 19:20:03 +0000,Tue; 27 Aug 2013 22:22:20 +0000,Thu; 14 Feb 2013 04:22:59 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4994
MAPREDUCE-4995,Bug,Major,task-controller,task-controller fails compilation on Mac,"The branch-1 task-controller codebase will not compile on Mac.  This also means that Mac users generally can't run ""ant package"" unless they hack the build.xml to skip task-controller.",Open,Unresolved,,Unassigned,Chris Nauroth,Fri; 8 Feb 2013 20:25:17 +0000,Tue; 14 May 2013 05:14:45 +0000,,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4995
MAPREDUCE-4996,Bug,Major,documentation,Unable to start resourcemanager on Hadoop 0.23.5,"starting resourcemanager; logging to  yarn-srikmvm-resourcemanager-mvm4.out Exception in thread ""main""  247) Could not find the main class: org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.  Program will exit",Open,Unresolved,,Unassigned,srikanth ayalasomayajulu,Sun; 10 Feb 2013 01:26:33 +0000,Mon; 11 Feb 2013 15:21:46 +0000,,,0.23.5,docs,,,https://issues.apache.org/jira/browse/MAPREDUCE-4996
MAPREDUCE-4997,Improvement,Major,,Get rid of unused configs in JTConfig,"A number (likely all) of the configs in JTConfig do nothing.  Additionally; the old mapred versions of these configs are deprecated in favor of the new ones; so if someone tries to use ""mapred.job.tracker""; they will get a deprecation warning saying that they should use ""mapreduce.jobtracker.address"" instead; when neither of them have any effect.",Open,Unresolved,,Sandy Ryza,Sandy Ryza,Sun; 10 Feb 2013 21:37:32 +0000,Thu; 2 May 2013 02:30:58 +0000,,,2.0.2-alpha,,,MAPREDUCE-4692,https://issues.apache.org/jira/browse/MAPREDUCE-4997
MAPREDUCE-4998,Bug,Minor,mrv1,backport MAPREDUCE-3376: Old mapred API combiner uses NULL reporter to branch-1,http: eI9  backport MAPREDUCE-3376: Old mapred API combiner uses NULL reporter to branch-1,Patch Available,Unresolved,,Unassigned,Jim Donofrio,Mon; 11 Feb 2013 07:09:36 +0000,Wed; 6 May 2015 03:31:35 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-4998
MAPREDUCE-4999,Bug,Major,mr-am,AM attempt ended up in ERROR state and generated history after node decommissioned,Saw a case where a job recorded history for an app tempt should be the one to generate the definitive history for the job.,Open,Unresolved,,Unassigned,Jason Lowe,Mon; 11 Feb 2013 16:07:54 +0000,Mon; 11 Feb 2013 16:07:54 +0000,,,0.23.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-4999
MAPREDUCE-5000,Bug,Critical,mr-am,TaskImpl.getCounters() can return the counters for the wrong task attempt when task is speculating,"When a task is speculating and one attempt completes then sometimes the counters for the wrong attempt are aggregated into the total counters for the job.  The scenario looks like this:   	Two task attempts are racing; _0 and _1 	_1 finishes first; causing the task to issue a TA_KILL to attempt _0 	_0 receives TA_KILL; sets progress to 1.0f and waits for container cleanup 	if TaskImpl.getCounters() is called now; TaskImpl.selectBestAttempt() can return _0 since it is not quite yet in the KILLED state yet progress is maxed out and no other attempt has more progress.",Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 11 Feb 2013 19:31:01 +0000,Tue; 27 Aug 2013 22:21:55 +0000,Wed; 13 Feb 2013 19:28:17 +0000,,0.23.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5000
MAPREDUCE-5001,Bug,Major,,LocalJobRunner has race condition resulting in job failures ,Hive is hitting a race condition with LocalJobRunner and the Cluster class. The JobClient uses the Cluster class to obtain Job objects. The Cluster class uses the job.xml file to populate the JobConf object (https:  L484).  This results in the following exception:    Here is code which exposes this race fairly quickly:,Closed,Fixed,,Sandy Ryza,Brock Noland,Mon; 11 Feb 2013 20:55:07 +0000,Wed; 3 Sep 2014 23:52:31 +0000,Tue; 20 Aug 2013 17:02:06 +0000,,2.0.2-alpha,,,HIVE-4009,https://issues.apache.org/jira/browse/MAPREDUCE-5001
MAPREDUCE-5002,Bug,Major,mr-am,AM could potentially allocate a reduce container to a map attempt,As discussed in MAPREDUCE-4982; after MAPREDUCE-4893 it is theoretically possible for the AM to accidentally assign a reducer container to a map attempt if the AM doesn't find a reduce attempt actively looking for the container (e.g.: the RM accidentally allocated too many reducer containers).,Resolved,Fixed,MAPREDUCE-5115,Chang Li,Jason Lowe,Wed; 13 Feb 2013 01:59:59 +0000,Tue; 30 Aug 2016 01:20:43 +0000,Thu; 17 Sep 2015 18:19:07 +0000,,2.0.3-alpha;0.23.7;2.7.0,,,MAPREDUCE-4982;MAPREDUCE-4893,https://issues.apache.org/jira/browse/MAPREDUCE-5002
MAPREDUCE-5003,Improvement,Major,mr-am,AM recovery should recreate records for attempts that were incomplete,As discussed in MAPREDUCE-4992; it would be nice if the AM recovered task tempts and potentially access their logs.,Patch Available,Unresolved,,Chang Li,Jason Lowe,Wed; 13 Feb 2013 02:24:29 +0000,Mon; 2 Nov 2015 15:59:46 +0000,,,,,,MAPREDUCE-4992;MAPREDUCE-5079,https://issues.apache.org/jira/browse/MAPREDUCE-5003
MAPREDUCE-5004,Bug,Major,,Somebody working on Genetic Algorithm library on Map Reduce,nan,Resolved,Invalid,,Vaibhav Singh Rajput,Abhishek Bajpai,Wed; 13 Feb 2013 12:52:29 +0000,Thu; 18 Apr 2013 06:06:59 +0000,Wed; 13 Feb 2013 17:30:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5004
YARN-485,Bug,Major,,TestProcfsProcessTree#testProcessTree() doesn't wait long enough for the process to die,TestProcfsProcessTree#testProcessTree fails occasionally with the following stack trace     kill -9 is executed asynchronously; the signal is delivered when the process comes out of the kernel (sys call). Checking if the process died immediately after can fail at times.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Wed; 13 Feb 2013 22:30:29 +0000,Mon; 3 Nov 2014 18:33:49 +0000,Mon; 18 Mar 2013 19:44:46 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/YARN-485
MAPREDUCE-5006,Bug,Major,contrib/streaming,streaming tests failing,"The following 2 tests are failing in trunk   	org.apache.hadoop.streaming.TestStreamReduceNone 	org.apache.hadoop.streaming.TestStreamXmlRecordReader",Closed,Fixed,,Sandy Ryza,Alejandro Abdelnur,Thu; 14 Feb 2013 06:00:23 +0000,Fri; 26 Apr 2013 02:14:45 +0000,Wed; 27 Mar 2013 11:48:52 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5006
MAPREDUCE-5007,Test,Major,,fix coverage org.apache.hadoop.mapreduce.v2.hs,fix coverage org.apache.hadoop.mapreduce.v2.hs  MAPREDUCE-5007-trunk.patch patch for trunk MAPREDUCE-5007-branch-2.patch patch for branch-2 MAPREDUCE-5007-branch-0.23.patch patch for branch-0.23,Closed,Fixed,,Aleksey Gorshkov,Aleksey Gorshkov,Fri; 15 Feb 2013 10:47:05 +0000,Thu; 12 May 2016 18:23:38 +0000,Fri; 5 Apr 2013 15:44:40 +0000,,2.0.3-alpha;0.23.7;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5007
MAPREDUCE-5008,Bug,Major,,Merger progress miscounts with respect to EOF_MARKER,After MAPREDUCE-2264; a segment's raw data length is calculated without the EOF_MARKER bytes.  However; when the merge is counting how many bytes it processed; it includes the marker.  This can cause the merge progress to go above 100%.  Whether these EOF_MARKER bytes should count should be consistent between the two.  This a JIRA instead of an amendment because MAPREDUCE-2264 already went into 2.0.3.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 15 Feb 2013 19:21:37 +0000,Wed; 15 May 2013 05:15:48 +0000,Wed; 27 Feb 2013 10:43:21 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5008
MAPREDUCE-5009,Bug,Critical,mrv1,Killing the Task Attempt slated for commit does not clear the value from the Task commitAttempt member,A reduce task attempt was killed by the RM(pre-emptively); but had already been assigned to the commitAttempt member.  This causes all subsequent attempts to be killed by the AM.,Closed,Fixed,MAPREDUCE-5255,Robert Parker,Robert Parker,Fri; 15 Feb 2013 22:54:47 +0000,Wed; 27 May 2015 18:56:17 +0000,Tue; 19 Feb 2013 23:46:21 +0000,,2.0.3-alpha;0.23.5,,,MAPREDUCE-5255,https://issues.apache.org/jira/browse/MAPREDUCE-5009
MAPREDUCE-5010,Improvement,Major,mrv1,use multithreading to speed up mergeParts  and try MapPartitionsCompleteEvent to schedule fetch in reduce ,"use multithreading to speed up Merger and try MapPartitionsCompleteEvent to schedule fetch in reduce    This is for muticore cpu; the performance will depend on your hardware and config.  In maptask  code for (int parts = 0; parts  partitions; parts++) { 	 code in  reduce task . for example ;  100 reduce wait 2 map complete ;beacase the cluster's map task capacity is 98;but the job have  100 map tasks .        so;I think : During the threads mergering  ; for example if map has 8 partitions ; and use 3 thread  doing merger ;  where one of the thread complete one part we can inform  the Reduce to fetch the partition file  immediately; or we can wait after 3 parts complete then send the event  (conf: mapred.map.parts.inform) to reduce the jt's stress. not to wait all the map task complete. by doing this; it will  prevent all reduce-tasks swamping the same tasktracker more effective and  speed reduce process.    is it  acceptable ? and other good ideas ?",Open,Unresolved,,Unassigned,Li Junjun,Sun; 17 Feb 2013 07:52:12 +0000,Tue; 21 Oct 2014 01:16:55 +0000,,,1.0.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5010
MAPREDUCE-5011,Bug,Major,,While Running Word Count in Hadoop showing following errors ,"We are running Word Count on Hadoop 1.1.1 by creating our own MANIFEST and jar file containing classes.The command which I entered is as following    output      Exception in thread ""main""  149",Resolved,Invalid,,Unassigned,Abhishek Bajpai,Mon; 18 Feb 2013 05:29:11 +0000,Mon; 18 Feb 2013 06:14:43 +0000,Mon; 18 Feb 2013 05:41:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5011
MAPREDUCE-5012,Bug,Trivial,documentation,Typo in javadoc for IdentityMapper class,"IdentityMapper.map() is incorrectly documented as the ""identify"" function.",Resolved,Fixed,,Adam Monsen,Adam Monsen,Thu; 14 Feb 2013 18:36:58 +0000,Thu; 12 May 2016 18:24:23 +0000,Tue; 19 Feb 2013 18:45:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5012
MAPREDUCE-5013,Bug,Major,client,mapred.JobStatus compatibility: MR2 missing constructors from MR1,JobStatus is missing the following constructors in MR2 that were present in MR1      public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID; float; float; float; int);     public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID; float; float; int);     public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID; float; float; float; int; org.apache.hadoop.mapred.JobPriority);     public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID; float; float; float; float; int; org.apache.hadoop.mapred.JobPriority);,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 19 Feb 2013 23:03:39 +0000,Tue; 27 Aug 2013 22:22:05 +0000,Thu; 21 Feb 2013 11:45:42 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5013
MAPREDUCE-5014,Improvement,Major,distcp,Extending DistCp through a custom CopyListing is not possible,"While it is possible to implement a custom CopyListing in DistCp; DistCp driver class doesn't allow for using this custom CopyListing.     	Allow SimpleCopyListing to provide an option to exclude files (For instance it is useful to exclude FileOutputCommiter.SUCCEEDED_FILE_NAME during copy as premature copy can indicate that the entire data is available at the destination)",Closed,Fixed,,Srikanth Sundarrajan,Srikanth Sundarrajan,Wed; 20 Feb 2013 01:34:31 +0000,Tue; 10 Mar 2015 04:30:12 +0000,Fri; 22 Mar 2013 10:41:08 +0000,,0.23.0;0.23.1;0.23.3;0.23.4;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5014
MAPREDUCE-5015,Test,Major,,Coverage fix for org.apache.hadoop.mapreduce.tools.CLI,Coverage fix for org.apache.hadoop.mapreduce.tools.CLI MAPREDUCE-5015-trunk.patch patch for trunk MAPREDUCE-5015-branch-2.patch for branch-2 MAPREDUCE-5015-branch-0.23.patch for branch-0.23,Closed,Fixed,,Aleksey Gorshkov,Aleksey Gorshkov,Wed; 20 Feb 2013 09:51:01 +0000,Thu; 12 May 2016 18:22:47 +0000,Tue; 16 Apr 2013 16:14:06 +0000,,2.0.3-alpha;0.23.5;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5015
MAPREDUCE-5016,Bug,Major,contrib/gridmix,GridMix Error:  Found no satisfactory file in path ,Hello;  Everytime i launch gridmix with the command:  PAPATH= test_gridmix  This happen even if i use a hdfs path.  I have exactly the same problem  org.apache.hadoop.mapred.gridmix.Gridmix.main(Gridmix. 395)   INFO gridmix.Gridmix: Exiting...  Thanks in advance for any responses,Open,Unresolved,,Unassigned,Light,Wed; 20 Feb 2013 13:58:20 +0000,Wed; 21 May 2014 06:34:42 +0000,,,1.1.0;1.1.1;2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5016
MAPREDUCE-5017,Bug,Major,,Provide access to launcher job URL from web console when using Map Reduce action ,there are applications where custom inputformat used in MR action; and log message from the inputformat is written on launcher task log. for debugging purpose; users need to check the launcher task log. but currently in MR action; oozie automatically swaps external ID; and do not expose the launcher ID in web-console. (now only way is to to grep oozie.log). this jira is to show launcher job URL on web console when using Map Reduce action,Resolved,Invalid,,Ryota Egashira,Ryota Egashira,Wed; 20 Feb 2013 23:03:47 +0000,Tue; 10 Mar 2015 04:30:45 +0000,Wed; 20 Feb 2013 23:09:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5017
MAPREDUCE-5018,New Feature,Minor,contrib/streaming,Support raw binary data with Hadoop streaming,"People often have a need to run older programs over many files; and turn to Hadoop streaming as a reliable; performant batch system.  There are good reasons for this:  1. Hadoop is convenient: they may already be using it for mapreduce jobs; and it is easy to spin up a cluster in the cloud. 2. It is reliable: HDFS replicates data and the scheduler retries failed jobs. 3. It is reasonably performant: it moves the code to the data; maintaining locality; and scales with the number of nodes.  Historically Hadoop is of course oriented toward processing key value pairs; and so needs to interpret the data passing through it.  Unfortunately; this makes it difficult to use Hadoop streaming with programs th ""JustBytes"" (as ""RawBytes"" was already taken); and it should be usable with most recent versions of Hadoop.",Patch Available,Unresolved,MAPREDUCE-598,Steven Willis,Jay Hacker,Thu; 21 Feb 2013 14:50:33 +0000,Wed; 6 May 2015 03:27:23 +0000,,,1.1.2,BB2015-05-TBR,,HADOOP-1722,https://issues.apache.org/jira/browse/MAPREDUCE-5018
MAPREDUCE-5019,Improvement,Minor,mrv1;scheduler,Fair scheduler should allow peremption on reducer only,"Fair scheduler is very good. But having a big MR job running lots of mapper and reducer( 10M + 10R ) Then a small MR on the same pool (1M + 1R) having slots for 10 mapper and 10 reducer   	The big job take all the map slots 	The small job wait for a map slot 	1rst big job map task finish 	the small job take the map slot it needs 	meanwhile all the reducer of the big job take all the reducer slot to copy and sort 	the small job end is map and wait for the all maps to end and for 1 reducer to end before accessing for a reducer slot. 	all the reducer stalled after sorting waiting for the mapper to end one  by one...    If I have a big job and a lot of small; I don't want new small arriving  and killing running map tasks of big job to get a slot.  I think it could be useful that the small job can kill a reducer tasks (and only reducer) to end before the big job finish all its map tasks and a reducer.  rules can be : a job having all its map finished and waiting for reducer slot can kill reducer tasks from a job that still have map slot running (assuming they are just waiting for copy and sort)",Resolved,Not A Problem,,Unassigned,Damien Hardy,Thu; 21 Feb 2013 15:10:35 +0000,Fri; 12 Apr 2013 10:34:02 +0000,Fri; 12 Apr 2013 10:34:02 +0000,,2.0.2-alpha,scheduler;scheduling,,,https://issues.apache.org/jira/browse/MAPREDUCE-5019
MAPREDUCE-5020,Bug,Major,client,Compile failure with JDK8,Compiling org InputSampler. fails with the Java 8 preview compiler due to its stricter enforcement of JLS 15.12.2.6 (for Java 5 or Java 7); which demands that methods applicable via unchecked conversion have their return type erased:,Closed,Fixed,,Trevor Robinson,Trevor Robinson,Thu; 21 Feb 2013 21:12:57 +0000,Wed; 3 Sep 2014 23:31:06 +0000,Tue; 10 Sep 2013 19:10:27 +0000,,2.0.3-alpha;2.1.0-beta,build-failure;jdk8,,,https://issues.apache.org/jira/browse/MAPREDUCE-5020
MAPREDUCE-5021,Improvement,Major,client;distributed-cache,Add an addDirectoryToClassPath method DistributedCache,As adding a directory of jars to the class path is a common use for the distributed cache it would be easier on API consumers if they were able to call a method that would add all the the files in a directory for them.,Open,Unresolved,,Unassigned,Sandy Ryza,Thu; 21 Feb 2013 23:37:20 +0000,Fri; 22 Feb 2013 18:51:51 +0000,,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5021
MAPREDUCE-5022,Bug,Major,task,Tasklogs disappear if JVM reuse is enabled,Can't see task logs when mapred.job.reuse.jvm.num.tasks is set to -1; but the logs are visible when the same is set 1.,Open,Unresolved,,Unassigned,Karthik Kambatla,Fri; 22 Feb 2013 01:07:23 +0000,Mon; 3 Nov 2014 18:33:54 +0000,,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5022
MAPREDUCE-5023,Bug,Critical,jobhistoryserver;webapps,History Server Web Services missing Job Counters,"The History Server's Job Counters API is not returning all the counters seen on the Job's Counters webpage.  Specifically; I'm not seeing any of the counters in the ""org.apache.hadoop.mapreduce.JobCounter"" group:  TOTAL_LAUNCHED_MAPS TOTAL_LAUNCHED_REDUCES OTHER_LOCAL_MAPS SLOTS_MILLIS_MAPS SLOTS_MILLIS_REDUCES",Closed,Fixed,,Ravi Prakash,Kendall Thrapp,Fri; 22 Feb 2013 16:43:47 +0000,Thu; 4 Sep 2014 00:53:59 +0000,Thu; 7 Mar 2013 23:03:58 +0000,,0.23.6,,,MAPREDUCE-4102,https://issues.apache.org/jira/browse/MAPREDUCE-5023
MAPREDUCE-5024,Improvement,Trivial,jobhistoryserver;webapps,JobHistory task attempts page sorts elapsed time wrong,"The JobHistory attempts UI sorts the ""Elapsed Time"" column lexicographically instead of numerically.  This means that 9 seconds  12 seconds  1 min in the sort order; which is misleading.",Resolved,Duplicate,MAPREDUCE-5105;MAPREDUCE-4989,Gopal V,Gopal V,Sat; 23 Feb 2013 04:24:48 +0000,Thu; 28 Mar 2013 16:37:14 +0000,Sat; 23 Feb 2013 04:45:20 +0000,,,usability;web-ui,,,https://issues.apache.org/jira/browse/MAPREDUCE-5024
MAPREDUCE-5025,Sub-task,Major,security,Key Distribution and Management for supporting crypto codec in Map Reduce,This task defines the work to enable Map Reduce to utilize the Crypto Codec framework to support encryption and decryption of data during MapReduce Job.  According to the some real use case and discussions from the community; for encryption and decryption files in Map Reduce; we have the following requirements:   1. Different stages (input; output; intermediate output) should have the flexibility to choose whether encrypt or not; as well as which crypto codec to use.   2. Different stages may have different scheme of providing the keys.   3. Different Files (for example; different input files) may have or use different keys.    4. Support a flexible way of retrieving keys for encryption or decryption.  So this task defines and provides the framework for supporting these requirements as well as the implementations for common use and key retrieving scenarios.  The design document of this part is included in the Hadoop Crypto Design attached in HADOOP-9331.,Open,Unresolved,,Jerry Chen,Jerry Chen,Mon; 25 Feb 2013 03:37:51 +0000,Tue; 10 Mar 2015 04:30:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5025
MAPREDUCE-5026,Improvement,Major,performance;tasktracker,For shortening the time of TaskTracker heartbeat; decouple the statics collection operations,"In each heartbeat of TaskTracker; it will calculate some system statics; like the free disk space; available virtual physical memory; cpu usage; etc. However; it's not necessary to calculate all the statics in every heartbeat; and this will consume many system resource and impace the performance of TaskTracker heartbeat. Furthermore; the characteristics of system properties(disk; memory; cpu) are different and it's better to collect their statics in different intervals.  To reduce the latency of TaskTracker heartbeat; one solution is to decouple all the system statics collection operations from it; and issue separate threads to do the statics collection works when the TaskTracker starts. The threads could be three: the first one is to collect cpu related statics in a short interval; the second one is to collect memory related statics in a normal interval; the third one is to collect disk related statics in a long interval. And all the interval could be customized by the parameter ""mapred.stats.collection.interval"" in the mapred-site.xml. At last; the heartbeat could get values of system statics from the memory directly.",Open,Unresolved,,Unassigned,sam liu,Sun; 24 Feb 2013 04:48:41 +0000,Fri; 28 Jun 2013 01:43:35 +0000,,,1.1.1,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-5026
MAPREDUCE-5027,Bug,Major,,Shuffle does not limit number of outstanding connections,The ShuffleHandler does not have any configurable limits to the number of outstanding connections allowed.  Therefore a node with many map outputs and many reducers in the cluster trying to fetch those outputs can exhaust a nodemanager out of file descriptors.,Closed,Fixed,,Robert Parker,Jason Lowe,Mon; 25 Feb 2013 20:47:19 +0000,Wed; 3 Sep 2014 22:57:01 +0000,Wed; 6 Mar 2013 00:12:24 +0000,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5027
MAPREDUCE-5028,Bug,Critical,,Maps fail when io.sort.mb is set to high value,Verified the problem exists on branch-1 with the following configuration:  Pseudo-dist mode: 2 maps  1 reduce; mapred.child. opts=-Xmx2048m; io.sort.mb=1280; dfs.block.size=2147483648  Run teragen to generate 4 GB data Maps fail when you run wordcount on this configuration with the following error:,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 26 Feb 2013 03:54:25 +0000,Mon; 3 Nov 2014 18:34:01 +0000,Tue; 11 Mar 2014 01:31:27 +0000,,1.1.1;2.0.3-alpha;0.23.5,,,MAPREDUCE-5032;MAPREDUCE-5031,https://issues.apache.org/jira/browse/MAPREDUCE-5028
MAPREDUCE-5029,Improvement,Major,,Recursively take all files in the directories of a root directory,Suppose we have a root directories with 1000's of sub directories and in each directory there can be 100's of files.So while specifying the root directory in the input path in map-reduce the program crashes due to sub directories in the root directory.So if this feature is includes in latest version it will be great helpful for programers.,Open,Unresolved,,Unassigned,Abhilash S R,Tue; 26 Feb 2013 04:52:34 +0000,Tue; 26 Feb 2013 10:32:00 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5029
YARN-428,Bug,Trivial,,YARNClientImpl logging too aggressively,Every time we execute bin hadoop job etc; the following two lines show up:,Resolved,Duplicate,YARN-379,Karthik Kambatla,Karthik Kambatla,Tue; 26 Feb 2013 15:08:37 +0000,Mon; 3 Nov 2014 18:34:09 +0000,Tue; 26 Feb 2013 15:40:28 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/YARN-428
MAPREDUCE-5031,Bug,Major,mrv2,Maps hitting IndexOutOfBoundsException for higher values of mapreduce.task.io.sort.mb,While trying to reproduce MAPREDUCE-5028 on trunk; ran into what seems to be a different issue. To reproduce:  Psuedo-dist mode: mapreduce. {map;reduce}.memory.mb=2048; mapreduce.{map;reduce} . opts=-Xmx2048m; mapreduce.task.io.sort.mb=1280  The map tasks fail with the following error:,Resolved,Duplicate,MAPREDUCE-5028,Karthik Kambatla,Karthik Kambatla,Tue; 26 Feb 2013 16:25:18 +0000,Mon; 3 Nov 2014 18:33:32 +0000,Mon; 4 Mar 2013 23:48:17 +0000,,2.0.3-alpha;0.23.5,,,MAPREDUCE-5032;MAPREDUCE-5028,https://issues.apache.org/jira/browse/MAPREDUCE-5031
MAPREDUCE-5032,Bug,Major,task,MapTask.MapOutputBuffer contains arithmetic overflows,There are several places where offsets into the collection buffer can overflow when applied to large buffers. These should be accommodated.,Open,Unresolved,,Chris Douglas,Chris Douglas,Tue; 26 Feb 2013 19:44:21 +0000,Mon; 26 Aug 2013 18:42:13 +0000,,,1.1.1;2.0.3-alpha;0.23.5,,,MAPREDUCE-5031;MAPREDUCE-5028,https://issues.apache.org/jira/browse/MAPREDUCE-5032
MAPREDUCE-5033,Improvement,Minor,,mapred shell script should respect usage flags (--help -help -h),Like in HADOOP-9267; the mapred shell script should respect the normal Unix-y help flags.,Closed,Fixed,,Andrew Wang,Andrew Wang,Tue; 26 Feb 2013 20:50:31 +0000,Tue; 27 Aug 2013 22:22:07 +0000,Wed; 27 Feb 2013 02:43:54 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5033
MAPREDUCE-5034,Bug,Major,,Class cast exception in MergeManagerImpl.java,When reduce side merge spills to disk; the following exception was thrown:  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath cannot be cast to  94)  It looks like a bug introduced by MAPREDUCE-2264,Resolved,Not A Problem,,Unassigned,Mariappan Asokan,Tue; 26 Feb 2013 23:08:00 +0000,Tue; 26 Feb 2013 23:37:43 +0000,Tue; 26 Feb 2013 23:37:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5034
MAPREDUCE-5035,Bug,Major,mrv1,Update MR1 memory configuration docs,The pmem cluster_setup.html#Memory+monitoring) have not been supported for a long time. The docs should be updated to reflect the new settings (mapred.cluster.map.memory.mb etc).,Closed,Fixed,,Tom White,Tom White,Wed; 27 Feb 2013 12:30:48 +0000,Wed; 15 May 2013 05:15:52 +0000,Wed; 27 Feb 2013 16:38:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5035
MAPREDUCE-5036,Improvement,Major,,Default shuffle handler port should not be 8080,The shuffle handler port (mapreduce.shuffle.port) defaults to 8080.  This is a pretty common port for web services; and is likely to cause unnecessary port conflicts.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 27 Feb 2013 20:50:05 +0000,Tue; 21 Apr 2015 20:03:58 +0000,Tue; 21 Apr 2015 19:58:56 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5036
MAPREDUCE-5037,Improvement,Minor,client,JobControl logging when a job completes,JobControl emits logs; via the logging in Job.submit(); whenever a job is launched.  It would be nice if it also logged when active jobs it is tracking complete and their final status (i.e.: success; failed; killed; etc.).,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 28 Feb 2013 16:37:24 +0000,Thu; 28 Feb 2013 17:07:25 +0000,,,0.23.7;2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5037
MAPREDUCE-5038,Bug,Major,,old API CombineFileInputFormat missing fixes that are in new API ,The following changes patched the CombineFileInputFormat in mapreduce; but neglected the one in mapred MAPREDUCE-1597 enabled the CombineFileInputFormat to work on splittable files MAPREDUCE-2021 solved returning duplicate hostnames in split locations MAPREDUCE-1806 CombineFileInputFormat does not work with paths not on default FS  In trunk this is not an issue as the one in mapred extends the one in mapreduce.,Reopened,Unresolved,,Sandy Ryza,Sandy Ryza,Thu; 28 Feb 2013 21:40:24 +0000,Tue; 21 May 2013 18:14:16 +0000,,,1.1.1,,,MAPREDUCE-5256;MAPREDUCE-5046,https://issues.apache.org/jira/browse/MAPREDUCE-5038
MAPREDUCE-5039,Bug,Major,contrib/vaidya,Configuration getInt is called From vaidya; but it actually need a float calculation(The values always be a Floating Poin Number),when we run the vaidya scrpit in hadoop-2.0.0-mr1-cdh4.1.2.  Exception: 254)  In the job conf file the properties are like  property&lt;namemapred.reduce.slowstart.completed.maps property  all the above lines throw the exception.  The important thing is default values for the above properties are 0.05 and 0.8   But the getInt() Function takes only integer values; if not it takes only the integer part. In Hadoop io.sort.spill.percent;io.sort.record.percent;mapred.reduce.slowstart.completed.maps are expressed as Floating Point Numbers.,Open,Unresolved,,Unassigned,shobin joseph,Fri; 1 Mar 2013 11:00:03 +0000,Tue; 5 Mar 2013 05:43:58 +0000,,,0.23.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5039
MAPREDUCE-5040,Bug,Major,,Make JobId; TaskId; TaskAttemptId immutable,These classes don't really need to be mutable. The current implementation synchronizes on pretty much all operations - which should be avoided.,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 1 Mar 2013 19:44:07 +0000,Fri; 1 Mar 2013 19:44:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5040
MAPREDUCE-5041,Improvement,Major,,Counters on the UI should be formatted,Counter values; especially larger ones; are tough to read since they're not formatted.,Open,Unresolved,,Unassigned,Siddharth Seth,Fri; 1 Mar 2013 21:35:32 +0000,Fri; 1 Mar 2013 21:35:32 +0000,,,2.0.3-alpha,usability,,,https://issues.apache.org/jira/browse/MAPREDUCE-5041
MAPREDUCE-5042,Bug,Blocker,mr-am;security,Reducer unable to fetch for a map task that was recovered,"If an application attempt fails and is relaunched the AM will try to recover previously completed tasks.  If a reducer needs to fetch the output of a map task attempt that was recovered then it will fail with a 401 error like this:     Looking at the corresponding NM's logs; we see the shuffle failed due to ""Verification of the hashReply failed"".",Closed,Fixed,YARN-403,Jason Lowe,Jason Lowe,Fri; 1 Mar 2013 23:09:23 +0000,Wed; 3 Sep 2014 22:57:01 +0000,Fri; 15 Mar 2013 21:20:00 +0000,,0.23.7;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5042
MAPREDUCE-5043,Bug,Blocker,mr-am,Fetch failure processing can cause AM event queue to backup and eventually OOM,Saw an MRAppMaster with a 3G heap OOM.  Upon investigating another instance of it running; we saw the UI in a weird state where the task table and task attempt tables in the job overview page weren't consistent.  The AM log showed the AsyncDispatcher had hundreds of thousands of events in the event queue; and jstacks showed it spending a lot of time in fetch failure processing.  It turns out fetch failure processing is currently very expensive; with a triple for loop where the inner loop is calling the quite-expensive TaskAttempt.getReport.  That function ends up type-converting the entire task report; counters and all; and performing locale conversions among other things.  It does this for every reduce task in the job; for every map task that failed.  And when it's done building up the large task report; it pulls out one field; the phase; then throws the report away.  While the AM is busy processing fetch failures; tasks attempts are continuing to send events to the AM including memory-expensive events like status updates which include the counters.  These back up in the AsyncDispatcher event queue and eventually even an AM with a large heap size will run out of memory and crash or expire because it thrashes in garbage collect.,Closed,Fixed,,Jason Lowe,Jason Lowe,Sat; 2 Mar 2013 00:41:07 +0000,Wed; 3 Sep 2014 22:57:02 +0000,Mon; 4 Mar 2013 20:14:00 +0000,,0.23.7;2.1.0-beta,,,MAPREDUCE-5124,https://issues.apache.org/jira/browse/MAPREDUCE-5043
MAPREDUCE-5044,Improvement,Major,mr-am,Have AM trigger jstack on task attempts that timeout before killing them,When an AM expires a task attempt it would be nice if it triggered a jstack output via SIGQUIT before killing the task attempt.  This would be invaluable for helping users debug their hung tasks; especially if they do not have shell access to the nodes.,Resolved,Fixed,,Eric Payne,Jason Lowe,Sat; 2 Mar 2013 18:08:39 +0000,Tue; 30 Aug 2016 01:20:39 +0000,Mon; 6 Jun 2016 21:58:11 +0000,,2.1.0-beta,,YARN-1515,MAPREDUCE-1119;YARN-445,https://issues.apache.org/jira/browse/MAPREDUCE-5044
MAPREDUCE-5045,Test,Trivial,contrib/streaming;test,UtilTest#isCygwin method appears to be unused,Method UtilTest#isCygwin in   appears to be unused.  If so; then we need to remove it.  If anything is calling it; then we need to update the naming to isWindows; or perhaps just change call sites to use Shell#WINDOWS.,Resolved,Fixed,,Neelesh Srinivas Salian,Chris Nauroth,Tue; 5 Mar 2013 17:42:26 +0000,Tue; 30 Aug 2016 01:20:38 +0000,Tue; 22 Sep 2015 16:09:55 +0000,,2.7.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5045
MAPREDUCE-5046,Bug,Major,client,backport MAPREDUCE-1423 to mapred.lib.CombineFileInputFormat,The CombineFileInputFormat class in org.apache.hadoop.mapred.lib (the old API) has a couple of issues. These issues were addressed in the new API (MAPREDUCE-1423); but the old class was not fixed.  The main issue the JIRA refers to is a performance problem. However; IMO there is a more serious problem which is a thread-safety issue (rackToNodes) which was fixed alongside.  What is the policy on addressing issues in the old API? Can we backport this to the old class?,Resolved,Fixed,,Unassigned,Sangjin Lee,Tue; 5 Mar 2013 19:06:16 +0000,Mon; 6 May 2013 02:56:50 +0000,Thu; 7 Mar 2013 22:46:39 +0000,,1.1.1,,,MAPREDUCE-5038,https://issues.apache.org/jira/browse/MAPREDUCE-5046
MAPREDUCE-5047,Bug,Major,task;tasktracker,keep.failed.task.files=true causes job failure on secure clusters,To support IsolationRunner; split info is written to local directories.  This occurs inside MapTask#localizeConfiguration; which is called both tasktracker and by the child JVM.  On a secure cluster; the tasktacker's attempt to write it fails; because the tasktracker does not have permission to write to the user's directory. It is likely that the call to localizeConfiguration in the tasktracker can be removed.,Resolved,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 5 Mar 2013 21:07:59 +0000,Mon; 11 Mar 2013 21:04:53 +0000,Mon; 11 Mar 2013 18:59:22 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5047
MAPREDUCE-5048,Bug,Major,contrib/streaming,streaming combiner feature breaks when input binary; output text,When running hadoop streaming job with binary input and shuffling but text output with combiner on; it fails with error   io.IOException: wrong key class: class org.apache.hadoop.io.Text is not class org.apache.hadoop.typedbytes.TypedBytesWritable   repro:  hadoop jar streaming jar -D  'stream.map.input=typedbytes' -D 'stream.map.output=typedbytes'     -D     'stream.reduce.input=typedbytes'       -input  sequence file containing typedbytes     -output  any valid dir  -mapper    cat     -combiner     cat   -reducer cat -inputformat 'org.apache.hadoop.streaming.AutoInputFormat'    if you remove the -combiner option; it works with only performance implications. If you specify in addition -D     'stream.reduce.output=typedbytes'; it succeeds but outputs raw typedbytes (without the sequence file superstructure)  I asked in the discussion of HADOOP-1722 (where typedbytes was first introduced)  if this is a bug or my misunderstanding of that spec and a committer chipped in saying it seems a bug to him too. Originally reported by a user of the rmr2 package for R and filed by me here https: 16,Open,Unresolved,,Unassigned,Antonio Piccolboni,Tue; 5 Mar 2013 23:22:03 +0000,Tue; 5 Mar 2013 23:22:03 +0000,,,1.0.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5048
MAPREDUCE-5049,Bug,Major,,CombineFileInputFormat counts all compressed files non-splitable,In branch-1; CombineFileInputFormat doesn't take SplittableCompressionCodec into account and thinks that all compressible input files aren't splittable.  This is a regression from when handling for non-splitable compression codecs was originally added in MAPREDUCE-1597; and seems to have somehow gotten in when the code was pulled from 0.22 to branch-1.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 6 Mar 2013 03:52:15 +0000,Wed; 15 May 2013 05:16:04 +0000,Thu; 7 Mar 2013 22:34:17 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5049
MAPREDUCE-5050,Bug,Minor,examples,Cannot find partition.lst in Terasort on Hadoop/Local File System,I'm trying to simulate running Hadoop on Lustre by configuring it to use the local file system using a single cloudera VM (cdh3u4).  I can generate the data just fine; but when running the sorting portion of the program; I get an error about not being able to find the _partition.lst file. It exists in the generated data directory.  Perusing the Terasort code; I see in the main method that has a Path reference to partition.lst; which is created with the parent directory.     But in the configure method; the Path isn't created with the parent directory reference.     I modified the code as follows; and now sorting portion of the Terasort test works using the general file system. I think the above code is a bug.,Open,Unresolved,MAPREDUCE-5528,Unassigned,Matt Parker,Thu; 7 Mar 2013 16:10:25 +0000,Wed; 18 Mar 2015 22:55:48 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5050
MAPREDUCE-5051,Bug,Major,mrv1,Combiner not used when NUM_REDUCES=0,We have a M R job to free a tasktracker slot for reducer cf. MAPREDUCE-5019 )  When we put ```job.setNumReduceTasks(0);``` in our job .run(); mapper are started but combiner are not used.,Resolved,Won't Fix,,Unassigned,Damien Hardy,Thu; 7 Mar 2013 17:18:22 +0000,Fri; 8 Mar 2013 19:03:19 +0000,Thu; 7 Mar 2013 19:18:18 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5051
MAPREDUCE-5052,Bug,Critical,jobhistoryserver;webapps,Job History UI and web services confusing job start time and job submit time,"The ""Start Time"" column shown on Job History server's main webpage (http: jobhistory) is actually showing the submit time for jobs.  However; when you drill down to an individual job's page; there the ""Start Time"" really does refer to when the job actually started.    This also true for the web services REST API; where the Jobs listing returns the submit times as ""startTime""; but the single Job API returns the start time as ""startTime"".  The two different times being referred to by the same name is confusing.  However; it is useful to have both times; as the difference between the submit time and start time can show how long a job was stuck waiting in a queue.  The column on the main job history page should be changed to ""Submit Time"" and the individual job's page should show both the submit time and start time.  The web services REST API should be updated with these changes as well.",Closed,Fixed,,Chen He,Kendall Thrapp,Thu; 7 Mar 2013 17:37:22 +0000,Sat; 30 May 2015 03:53:47 +0000,Tue; 10 Dec 2013 17:32:21 +0000,,0.23.6,,,MAPREDUCE-6377,https://issues.apache.org/jira/browse/MAPREDUCE-5052
MAPREDUCE-5053,Bug,Major,,java.lang.InternalError from decompression codec cause reducer to fail,lz4; snappy; zlib; and lzo Decompressor's only throw  lang.InternalError. This exception will cause the reducer to fail and bypass all of the fetch failure logic.  The decompressing errors should be treated as fetch failures.,Closed,Fixed,,Robert Parker,Robert Parker,Fri; 8 Mar 2013 01:31:20 +0000,Mon; 4 Apr 2016 19:53:32 +0000,Tue; 19 Mar 2013 15:55:09 +0000,,2.0.3-alpha;0.23.5,,,TEZ-3196,https://issues.apache.org/jira/browse/MAPREDUCE-5053
YARN-460,Bug,Blocker,capacityscheduler,CS user left in list of active users for the queue even when application finished,We have seen a user get left in the queues list of active users even though the application was removed. This can cause everyone else in the queue to get less resources if using the minimum user limit percent config.,Closed,Fixed,,Thomas Graves,Thomas Graves,Fri; 8 Mar 2013 15:29:46 +0000,Wed; 3 Sep 2014 22:54:42 +0000,Fri; 29 Mar 2013 15:32:36 +0000,,0.23.7;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/YARN-460
MAPREDUCE-5055,Bug,Major,mrv2,Binary compatibility for the method Reporter.incrCounter(String group; String counter; long amount) between hadoop-1.x and hadoop-2.x,Try to generate a lot of counters that exceed the default max limit so the job errors. To simulate this edit org.apache.hadoop.examples.RandomWriter class and add the following in the mapper:   Attached is the modified code of RandomWriter. from branch-1.  When I run it against branch-1;   it fails with the following error:    Using the jar compiled with branch-1 when running in a hadoop 2 cluster completes without any error and don't see the counter. Interestingly there were two more custom counters in the same job that are incremented and they are visible. The difference is that they use the method  Reporter.incrCounter(Enum? key; long amount).  Compiled this against 2.x trunk and ran it. The job did fail with the expected counter exceeded exception. So it seems to be a case of binary incompatibility between 1.x and 2.x.,Resolved,Not A Problem,,Zhijie Shen,Deepesh Khandelwal,Fri; 8 Mar 2013 18:48:13 +0000,Sat; 9 Mar 2013 00:08:40 +0000,Sat; 9 Mar 2013 00:08:40 +0000,,2.0.3-alpha,,,MAPREDUCE-3697,https://issues.apache.org/jira/browse/MAPREDUCE-5055
MAPREDUCE-5056,Bug,Major,,TestProcfsBasedProcessTree fails on Windows with Process-tree dump doesn't start with a proper header,Test fails on the below assertion:  Running org.apache.hadoop.mapreduce.util.TestProcfsBasedProcessTree Tests run: 5; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 0.266 sec &lt; FAILURE! testProcessTreeDump(org.apache.hadoop.mapreduce.util.TestProcfsBasedProcessTree)  Time elapsed: 0 sec  &lt; FAILURE! junit.framework.AssertionFailedError: Process-tree dump doesn't start with a proper header   org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter. 75),Resolved,Not A Problem,,Ivan Mitic,Ivan Mitic,Mon; 11 Mar 2013 17:31:26 +0000,Thu; 12 May 2016 18:22:27 +0000,Tue; 9 Apr 2013 23:23:57 +0000,,3.0.0-alpha1,,,MAPREDUCE-4401,https://issues.apache.org/jira/browse/MAPREDUCE-5056
MAPREDUCE-5057,Bug,Trivial,contrib/data-join,Datajoin Package for reduce side join (in contrib folder) MRJobCOnfig class not present hadoop 1.0.3,"DataJoin Package contributed to Hadoop has bug  1) MRJobConfig config is not present and will not return input file      name (MRJobConfig.MAP_INPUT_FILE)     2 ) While Writing User program for joinig datasets using datajoin package      In TaggedWritable class you will find readFields method will throw exception      for that matter you will have to  create new Text type object for reading beacause while writing     you are writing Text object         Taxt data;         public void readFields(DataInput in) throws IOException {     		data = new Text();         	        	this.tag.readFields(in);                  	if(this.data != null)           	{        		         		       data.readFields(in);           	}        }",Resolved,Fixed,,Vikas Jadhav,Vikas Jadhav,Mon; 11 Mar 2013 17:55:04 +0000,Tue; 12 Mar 2013 06:30:08 +0000,Mon; 11 Mar 2013 18:05:28 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5057
MAPREDUCE-5058,Bug,Major,jobtracker,Job History files not copied,When a job completes; instead of moving the job history files to the DONE folder; an error is thrown: 2013-03-12 15:03:52;111 ERROR org.apache.hadoop.mapred.JobHistory: Unable to move history file to DONE canonical subfolder.  ,Open,Unresolved,,Unassigned,Aaron Zimmerman,Tue; 12 Mar 2013 17:01:20 +0000,Tue; 12 Mar 2013 17:01:20 +0000,,,1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5058
MAPREDUCE-5059,Bug,Major,jobhistoryserver;webapps,Job overview shows average merge time larger than for any reduce attempt,When looking at a job overview page on the history server; the Average Merge Time is often reported with a value that is far larger than the Elapsed Merge Time shown for any reduce task attempt.  The job overview page calculates the merge time as the time delta between the sort finishing and the job launching while the attempts page calculates it as the time delta between the sort finishing and the shuffle finishing.,Closed,Fixed,,Omkar Vinit Joshi,Jason Lowe,Tue; 12 Mar 2013 19:09:29 +0000,Tue; 27 Aug 2013 22:22:15 +0000,Mon; 29 Jul 2013 05:43:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5059
MAPREDUCE-5060,Bug,Critical,,Fetch failures that time out only count against the first map task,"When a fetch failure happens; if the socket has already ""connected"" it is only counted against the first map task.  But most of the time it is because of an issue with the Node itself; not the individual map task; and as such all failures when trying to initiate the connection should count against all of the tasks.  This caused a particularly unfortunate job to take an hour an a half longer then it needed to.",Closed,Fixed,,Robert Joseph Evans,Robert Joseph Evans,Tue; 12 Mar 2013 19:44:39 +0000,Tue; 27 Aug 2013 22:22:15 +0000,Tue; 12 Mar 2013 23:00:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5060
MAPREDUCE-5061,Bug,Minor,,MultipleInputs can not manage path with glob characters like {a;b},"Hello;  The org.apache.hadoop.mapreduce.lib.input.MultipleInputs expects a configuration with :   	the parameter mapreduce.input.multipleinputs.dir.mappers in the format path 1;mapper class 1;path 2;mapper class 2 	the parameter mapreduce.input.multipleinputs.dir.formats in the format path 1;input format class 1;path 2;input format class 2    The usage of the comma as separator unable the use of the glob characters  {a;b} in the path (like : hdfs: data201{2;3} ).  I suggest to change the separator to another non-problematic one (maybe =).  I patched the MultipleInputs code locally and found an other related issue :  when the path are created; the string representing the path is not unescape (like it's done in the org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getInputPaths method) which makes an invalid path in case of glob characters {a;b}  Thank you",Open,Unresolved,,Unassigned,Thierry Granger,Wed; 13 Mar 2013 04:14:31 +0000,Tue; 6 Oct 2015 06:29:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5061
MAPREDUCE-5062,Bug,Major,,MR AM should read max-retries information from the RM,Change MR AM to use app-retry maximum limit that is made available by RM after YARN-378.,Closed,Fixed,,Zhijie Shen,Vinod Kumar Vavilapalli,Wed; 13 Mar 2013 04:45:06 +0000,Tue; 27 Aug 2013 22:21:55 +0000,Mon; 25 Mar 2013 22:35:07 +0000,,,,YARN-378,YARN-378,https://issues.apache.org/jira/browse/MAPREDUCE-5062
MAPREDUCE-5063,Wish,Minor,,Transfering mapper output  (key;value) pair to multiple reducer ,Currently  in  Hadoop MapReduce mapper output in (key;value) form can be transfered to only one reducer   Our goal is to be able transfer shuffle (key;value) pair to multiple reducer  Note:- we need to shuffle same pair to number of reducers,Open,Unresolved,,Unassigned,Vikas Jadhav,Wed; 13 Mar 2013 08:55:15 +0000,Mon; 25 Mar 2013 15:35:51 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5063
MAPREDUCE-5064,Bug,Minor,,TestRumenJobTraces failing on 1.3.x and 1.2,TestRumenJobTraces.testCurrentJHParser() is failing locally; both in a bulk test and standalone,Resolved,Not A Problem,,Unassigned,Steve Loughran,Wed; 13 Mar 2013 09:48:21 +0000,Mon; 6 May 2013 15:13:41 +0000,Mon; 6 May 2013 15:13:41 +0000,,1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5064
MAPREDUCE-5065,Bug,Major,distcp,DistCp should skip checksum comparisons if block-sizes are different on source/target.,When copying files between 2 clusters with different default block-sizes; one sees that the copy fails with a checksum-mismatch; even though the files have identical contents.  The reason is that on HDFS; a file's checksum is unfortunately a function of the block-size of the file. So you could have 2 different files with identical contents (but different block-sizes) have different checksums. (Thus; it's also possible for DistCp to fail to copy files on the same file-system; if the source-file's block-size differs from HDFS default; and -pb isn't used.)  I propose that we skip checksum comparisons under the following conditions: 1. -skipCrc is specified. 2. File-size is 0 (in which case the call to the checksum-servlet is moot). 3. source.getBlockSize() != target.getBlockSize(); since the checksums are guaranteed to differ in this case.  I have a patch for #3.  Edit: I've modified the fix to warn the user (instead of skipping the checksum-check). Skipping parity-checks is unsafe. The code now fails the copy; and suggests that the user either use -pb to preserve block-size; or consider -skipCrc (and forgo copy validation entirely).,Closed,Fixed,,Mithun Radhakrishnan,Mithun Radhakrishnan,Thu; 14 Mar 2013 01:15:39 +0000,Wed; 3 Sep 2014 22:59:39 +0000,Tue; 16 Apr 2013 22:09:17 +0000,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5065
MAPREDUCE-5066,Bug,Major,,JobTracker should set a timeout when calling into job.end.notification.url,In current code; timeout is not specified when JobTracker (JobEndNotifier) calls into the notification URL. When the given URL points to a server that will not respond for a long time; job notifications are completely stuck (given that we have only a single thread processing all notifications). We've seen this cause noticeable delays in job execution in components that rely on job end notifications (like Oozie workflows).   I propose we introduce a configurable timeout option and set a default to a reasonably small value.  If we want; we can also introduce a configurable number of workers processing the notification queue (not sure if this is needed though at this point).  I will prepare a patch soon. Please comment back.,Closed,Fixed,MAPREDUCE-4935,Ivan Mitic,Ivan Mitic,Thu; 14 Mar 2013 07:39:19 +0000,Thu; 22 Aug 2013 02:50:48 +0000,Sat; 20 Apr 2013 19:25:43 +0000,,1-win;2.0.3-alpha;1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5066
MAPREDUCE-5067,Bug,Minor,build,native taskcontroller won't build on Ubuntu 12.10,Building the native tarball is failing in task-controller.c with,Closed,Cannot Reproduce,,Unassigned,Steve Loughran,Thu; 14 Mar 2013 16:09:34 +0000,Tue; 30 Jun 2015 07:18:57 +0000,Mon; 26 Jan 2015 22:26:40 +0000,,1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5067
YARN-484,Bug,Major,scheduler,Fair Scheduler preemption fails if the other queue has a mapreduce job with some tasks in excess of cluster capacity,"This is reliably reproduced while running CDH4.1.2 or CDH4.2.0 on a single Mac OS X machine.   	Two queues are being configured: cjmQ and slotsQ. Both queues are configured with tiny minResources. The intention is for the task(s) of the job in cjmQ to be able to preempt tasks of the job in slotsQ. 	yarn.nodemanager.resource.memory-mb = 24576 	First; a long-running 6-map-task (0 reducers) mapreduce job is started in slotsQ with mapreduce.map.memory.mb=4096. Because MRAppMaster's container consumes some memory; only 5 of its 6 map tasks are able to start; and the 6th is pending; but will never run. 	Then; a short-running 1-map-task (0 reducers) mapreduce job is submitted via cjmQ with mapreduce.map.memory.mb=2048.    Expected behavior: At this point; because the minimum share of cjmQ has not been met; I expected Fair Scheduler to preempt one of the executing map tasks from the single slotsQ mapreduce job to make room for the single map tasks of the cjmQ mapreduce job. However; Fair Scheduler didn't preempt any of the running map tasks of the slotsQ job. Instead; the cjmQ job was being starved perpetually. Since slotsQ had far more than its minimum share allocated to it and already running; while cjmQ was far below its minimum share (0 actually); Fair Scheduler should have started preempting; regardless of there being one task container from the slotsQ job (the 6th map container) th group with the resolution.    Configuration:  In yarn-site.xml:    fair-scheduler.xml:    My fair-scheduler-allocations.xml:",Resolved,Cannot Reproduce,,Sandy Ryza,Vitaly Kruglikov,Thu; 14 Mar 2013 18:52:43 +0000,Fri; 29 Mar 2013 21:31:30 +0000,Fri; 29 Mar 2013 21:31:30 +0000,,,hadoop,,,https://issues.apache.org/jira/browse/YARN-484
MAPREDUCE-5069,Improvement,Minor,mrv1;mrv2,add concrete common implementations of CombineFileInputFormat,CombineFileInputFormat is abstract; and its specific equivalents to TextInputFormat; SequenceFileInputFormat; etc. are currently not in the hadoop code base.  These sound like very common need wherever CombineFileInputFormat is used; and different folks would write the same code over and over to achieve the same goal. It sounds very natural for hadoop to provide at least the text and sequence file implementations of the CombineFileInputFormat class.,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 14 Mar 2013 21:04:59 +0000,Wed; 3 Sep 2014 22:45:02 +0000,Wed; 24 Apr 2013 14:24:03 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5069
MAPREDUCE-5070,Bug,Major,test,TestClusterStatus.testClusterMetrics fails on JDK7,TestClusterStatus is sensitive to the order that the tests are run in.  If testReservedSlots is called before testClusterMetrics; testClusterMetrics will fail.,Resolved,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 14 Mar 2013 21:50:40 +0000,Fri; 15 Mar 2013 17:50:03 +0000,Fri; 15 Mar 2013 17:44:17 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5070
MAPREDUCE-5071,Bug,Minor,,in case of zero map jobs map completion graph is broken,In case of zero map jobs (normal case in hive MR jobs) jobs completion map is broken on jobDetails.jsp.  This doesn't happen in case of reduce because we have a check saying if job.getTasks(TaskType.REDUCE).length  0 then only show reduce completion graph,Open,Unresolved,,Unassigned,Abhishek Gayakwad,Wed; 13 Mar 2013 18:49:41 +0000,Thu; 14 Mar 2013 22:06:01 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5071
MAPREDUCE-5072,Bug,Major,test,TestDelegationTokenRenewal.testDTRenewal fails in MR1 on jdk7,TestDelegationTokenRenewal.testDTRenewal fails in MR1 for the reasons that TestDelegationTokenRenewer.testDTRenewal fails described in YARN-31.  The fix is the same.,Resolved,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 15 Mar 2013 02:39:01 +0000,Fri; 15 Mar 2013 17:50:40 +0000,Fri; 15 Mar 2013 17:50:40 +0000,,1.1.2,,,YARN-31,https://issues.apache.org/jira/browse/MAPREDUCE-5072
MAPREDUCE-5073,Bug,Major,test,TestJobStatusPersistency.testPersistency fails on JDK7,TestJobStatusPersistency is sensitive to the order that the tests are run in. If testLocalPersistency runs before testPersistency; testPersistency will fail.,Resolved,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 15 Mar 2013 03:33:08 +0000,Fri; 15 Mar 2013 20:15:08 +0000,Fri; 15 Mar 2013 20:15:08 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5073
MAPREDUCE-5074,Improvement,Major,mr-am;mrv2,Remove limits on number of counters and counter groups in MapReduce,Can we please consider removing limits on the number of counters and counter groups now that it is all user code? Thanks to the much better architecture of YARN in which there is no single Job Tracker we have to worry about overloading; I feel we should do away with this (now arbitrary) constraint on users' capabilities. Thoughts?,Resolved,Won't Fix,,Unassigned,Ravi Prakash,Fri; 15 Mar 2013 18:22:58 +0000,Thu; 12 May 2016 18:23:18 +0000,Mon; 18 May 2015 16:52:09 +0000,,2.0.3-alpha;0.23.6;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5074
MAPREDUCE-5075,Bug,Major,distcp,DistCp leaks input file handles,DistCp wraps the InputStream for each input file it reads in an instance of ThrottledInputStream.  This class does not close the wrapped InputStream.  RetriableFileCopyCommand guarantees that the ThrottledInputStream gets closed; but without closing the underlying wrapped stream; it still leaks a file handle.,Closed,Fixed,HDFS-4601,Chris Nauroth,Chris Nauroth,Fri; 15 Mar 2013 21:55:21 +0000,Thu; 12 May 2016 18:22:55 +0000,Wed; 20 Mar 2013 10:45:56 +0000,,3.0.0-alpha1,,,MAPREDUCE-4401,https://issues.apache.org/jira/browse/MAPREDUCE-5075
MAPREDUCE-5076,Bug,Major,,CombineFileInputFormat can create splits that exceed maxSplitSize,I ran a local job with CombineFileInputFormat using an 80 MB file and a max split size of 32 MB (the default local FS block size).  The job ran with two splits of 32 MB; and the last 16 MB were just omitted.  This appears to be caused by a subtle bug in getMoreSplits; in which the code that generates the splits from the blocks expects the 16 MB block to be at the end of the block list. But the code that generates the blocks does not respect this.,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Sat; 16 Mar 2013 00:45:54 +0000,Mon; 18 Mar 2013 21:21:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5076
MAPREDUCE-5077,Bug,Minor,mrv2,Cleanup: mapreduce.util.ResourceCalculatorPlugin and related code should be removed,ResourceCalculatorPlugin and ProcfsBasedProcessTree have moved to yarn.util and the mapreduce.util versions don't seem to be used anymore. Should remove related code.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Mon; 18 Mar 2013 18:29:56 +0000,Mon; 3 Nov 2014 18:33:35 +0000,Tue; 26 Mar 2013 18:23:10 +0000,,2.0.3-alpha,,MAPREDUCE-5098,MAPREDUCE-5098,https://issues.apache.org/jira/browse/MAPREDUCE-5077
MAPREDUCE-5078,Bug,Major,client,TestMRAppMaster fails on Windows due to mismatched path separators,The failing test is TestMRAppMaster#testMRAppMasterForDifferentUser.  There is an assertion about the AM staging directory; but the expected value is constructed with a mix of forward and back slashes.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Mon; 18 Mar 2013 19:00:58 +0000,Thu; 12 May 2016 18:24:07 +0000,Thu; 21 Mar 2013 21:44:20 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5078
MAPREDUCE-5079,Improvement,Critical,mr-am,Recovery should restore task state from job history info directly,We've encountered a lot of hanging issues during MR-AM recovery because the state machines don't always end up in the same states after recovery.  This is especially true when speculative execution is enabled.  It should be straightforward to restore task and task attempt states directly from the TaskInfo and TaskAttemptInfo records in the job history file to avoid relying on the task state machines ending up in the proper states with the proper number of attempts.  This should be a more robust solution that would also give us the option of recovering start time and log locations for tasks that were in-progress when the AM crashed.,Closed,Fixed,MAPREDUCE-5869,Jason Lowe,Jason Lowe,Mon; 18 Mar 2013 19:52:19 +0000,Wed; 18 Mar 2015 11:58:25 +0000,Thu; 11 Apr 2013 05:03:48 +0000,,0.23.7,,,MAPREDUCE-4992;MAPREDUCE-5003,https://issues.apache.org/jira/browse/MAPREDUCE-5079
MAPREDUCE-5080,Bug,Major,,TestContainerLauncher fails on Windows due to assertion failures on event/thread counts,nan,Resolved,Duplicate,MAPREDUCE-3872,Chris Nauroth,Chris Nauroth,Mon; 18 Mar 2013 21:16:41 +0000,Thu; 12 May 2016 18:23:21 +0000,Mon; 18 Mar 2013 22:13:09 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5080
MAPREDUCE-5081,New Feature,Major,distcp,Backport DistCpV2 and the related JIRAs to branch-1,"Here is a list of DistCpV2 JIRAs:  	MAPREDUCE-2765: DistCpV2 main jira 	HADOOP-8703: turn CRC checking off for 0 byte size 	HDFS-3054: distcp -skipcrccheck has no effect. 	HADOOP-8431: Running distcp without args throws IllegalArgumentException 	HADOOP-8775: non-positive value to -bandwidth 	MAPREDUCE-4654: TestDistCp is ignored 	HADOOP-9022: distcp fails to copy file if -m 0 specified 	HADOOP-9025: TestCopyListing failing 	MAPREDUCE-5075: DistCp leaks input file handles 	distcp part of HADOOP-8341: Fix findbugs issues in hadoop-tools 	MAPREDUCE-5014: custom CopyListing",Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 19 Mar 2013 08:18:29 +0000,Tue; 13 May 2014 15:17:39 +0000,Thu; 28 Mar 2013 05:03:26 +0000,,,,,MAPREDUCE-2765,https://issues.apache.org/jira/browse/MAPREDUCE-5081
HADOOP-9419,Improvement,Major,,CodecPool should avoid OOMs with buggy codecs,I recently found a bug in the gpl compression libraries that was causing map tasks for a particular job to OOM.  https: compressor.  If the codec newly created object does not match the value from getType... it should turn off caching for that Codec.,Resolved,Won't Fix,,Unassigned,Robert Joseph Evans,Tue; 19 Mar 2013 18:34:28 +0000,Tue; 19 Mar 2013 21:20:44 +0000,Tue; 19 Mar 2013 21:20:44 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-9419
MAPREDUCE-5083,Bug,Major,mrv2,MiniMRCluster should use a random component when creating an actual cluster,Currently all unit tests end up using the same work dir - which can affect anyone trying to run parallel instances.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 20 Mar 2013 01:10:04 +0000,Tue; 25 Jun 2013 19:57:02 +0000,Thu; 4 Apr 2013 17:05:05 +0000,,2.0.3-alpha,,,MAPREDUCE-5349,https://issues.apache.org/jira/browse/MAPREDUCE-5083
MAPREDUCE-5084,Test,Major,,fix coverage  org.apache.hadoop.mapreduce.v2.app.webapp and org.apache.hadoop.mapreduce.v2.hs.webapp,fix coverage  org.apache.hadoop.mapreduce.v2.app.webapp and org.apache.hadoop.mapreduce.v2.hs.webapp The same patch for trunk; branch-2 and branch-0.23,Closed,Fixed,,Aleksey Gorshkov,Aleksey Gorshkov,Wed; 20 Mar 2013 06:25:04 +0000,Thu; 12 May 2016 18:22:17 +0000,Wed; 19 Jun 2013 16:20:36 +0000,,0.23.7;2.0.4-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5084
MAPREDUCE-5085,Bug,Major,,JobClient reorders splits ,The JobClient hard codes ordering of splits in descending size. While this could be fine for traditional smoothly utilized over time.      It should be straightforward to make the SplitComparator an instance variable of the JobClient and allow it to be set by the consumers if they care about the order in which splits are attempted to run.,Open,Unresolved,,Unassigned,ledion bitincka,Wed; 20 Mar 2013 17:26:39 +0000,Wed; 20 Mar 2013 17:27:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5085
MAPREDUCE-5086,Sub-task,Major,,MR app master deletes staging dir when sent a reboot command from the RM,If the RM is restarted when the MR job is running; then it sends a reboot command to the job. The job ends up deleting the staging dir and that causes the next attempt to fail.,Closed,Fixed,,Jian He,Jian He,Wed; 13 Mar 2013 01:58:28 +0000,Tue; 5 Nov 2013 20:47:22 +0000,Mon; 8 Apr 2013 16:13:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5086
HADOOP-9426,Bug,Major,,Hadoop should expose Jar location utilities on its public API,The facilities behind JobConf#setJarByClass and the JarFinder utility in test are both generally useful. As the core platform; these should be published as part of the public API. In addition to HBase; they are probably useful for Pig and Hive as well. See also HBASE-2588; HBASE-5317; HBASE-8140.,Patch Available,Unresolved,,Unassigned,Nick Dimiduk,Wed; 20 Mar 2013 22:59:01 +0000,Wed; 6 May 2015 03:32:13 +0000,,,1.0.0;1.1.0;2.0.0-alpha,BB2015-05-TBR,,HBASE-8158,https://issues.apache.org/jira/browse/HADOOP-9426
MAPREDUCE-5088,Bug,Blocker,,MR Client gets an renewer token exception while Oozie is submitting a job,After the fix for HADOOP-9299 I'm now getting the following bizzare exception in Oozie while trying to submit a job. This also seems to be KRB related:,Closed,Fixed,,Daryn Sharp,Roman Shaposhnik,Fri; 15 Mar 2013 17:55:08 +0000,Tue; 1 Oct 2013 18:59:43 +0000,Wed; 3 Apr 2013 18:47:16 +0000,,2.0.3-alpha,,,MAPREDUCE-5093,https://issues.apache.org/jira/browse/MAPREDUCE-5088
MAPREDUCE-5089,Task,Minor,,Remove TestProcfsBasedProcessTree from mapreduce-client-jobclient,A similar copy already exists in YARN which is where it should be.,Resolved,Duplicate,MAPREDUCE-5077,Unassigned,Siddharth Seth,Thu; 21 Mar 2013 02:25:01 +0000,Thu; 21 Mar 2013 02:29:47 +0000,Thu; 21 Mar 2013 02:29:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5089
MAPREDUCE-5090,Bug,Major,,TotalOrderPartitioner does not recognize total.order.partitioner.* settings,There is a backwards-compatibility issue where TotalOrderPartitioner no longer recognizes the Hadoop 1.x properties such as total.order.partitioner.natural.order; total.order.partitioner.max.trie.depth; and total.order.partitioner.path.  The  oc for TotalOrderPartitioner.setConf even mentions these properties but does not honor them.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 21 Mar 2013 22:19:55 +0000,Thu; 21 Mar 2013 22:19:55 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5090
YARN-500,Bug,Major,resourcemanager,ResourceManager webapp is using next port if configured port is already in use,nan,Closed,Fixed,,Kenji Kikushima,Nishan Shetty,Fri; 22 Mar 2013 04:48:40 +0000,Mon; 17 Mar 2014 14:58:43 +0000,Wed; 17 Apr 2013 04:24:23 +0000,,2.0.2-alpha;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/YARN-500
MAPREDUCE-5092,Bug,Major,,Parameter 'chunks' of org.apache.hadoop.mapred.lib.db.DBInputFormat.getSplits method is ignored,Class  org.apache.hadoop.mapred.lib.db.DBInputFormat  (hadoop-mapreduce-project     contains method: public InputSplit[] getSplits(JobConf job; int chunks) throws IOException  but 'chunks' parameter is ignored.  Chunks count taken from 'job.getConfiguration().getInt(MRJobConfig.NUM_MAPS; 1);'    affects trunk; branch-2; branch-0.23,Open,Unresolved,,Unassigned,Dennis Y,Fri; 22 Mar 2013 11:44:55 +0000,Thu; 12 May 2016 18:24:42 +0000,,,2.0.3-alpha;0.23.5;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5092
MAPREDUCE-5093,Improvement,Major,job submission,Improve RM and HS token acquisition during job submission,Jobs that intend to submit other jobs (ex. oozie; pig) require a RM token.  Yarn has added the requirement of a HS token.  Currently the submitter is required to explicitly obtain a RM token with the correct renewer and add it to the credentials.  To avoid breaking compatibility; the HS token is implicitly acquired if the submitter acquired a RM token via getDelegationToken.  Viewfs exposed the limitations of assuming only one token per filesystem.  Similarly; the RM + HS token has the same issue.  We should consider changing the api; ex. getDelegationToken(renewer) to addDelegationTokens(renewer; creds) ala the filesystem change.  Further; token acquisition should ideally be considered an internal implementation detail required by security.  Submitters; particularly oozie  pig; would benefit greatly from conf setting to indicate jobs are allowed to submit jobs.  This conf setting would trigger invoking the proposed addDelegationTokens plus ensure the correct renewer is used; further freeing submitters from knowing internal implementation details of security.,Open,Unresolved,,Unassigned,Daryn Sharp,Fri; 22 Mar 2013 14:50:07 +0000,Thu; 12 May 2016 18:24:47 +0000,,,0.23.0;2.0.0-alpha;3.0.0-alpha1,,,MAPREDUCE-5088,https://issues.apache.org/jira/browse/MAPREDUCE-5093
MAPREDUCE-5094,Bug,Major,,Disable mem monitoring by default in MiniMRYarnCluster,YARN-449. Some hbase tests were failing since containers were getting killed.  I believe these checks are disabled by default on the branch-1 MiniMRCluster.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Fri; 22 Mar 2013 19:13:13 +0000,Fri; 26 Apr 2013 02:14:48 +0000,Thu; 11 Apr 2013 22:57:36 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5094
MAPREDUCE-5095,Bug,Major,,TestShuffleExceptionCount#testCheckException fails occasionally with JDK7,The test fails due a test-order dependency that can be violated when running with JDK 7.,Resolved,Fixed,,Arpit Agarwal,Arpit Agarwal,Fri; 22 Mar 2013 21:26:19 +0000,Mon; 20 May 2013 20:14:04 +0000,Mon; 20 May 2013 20:12:57 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5095
MAPREDUCE-5096,Improvement,Major,job submission,Deprecate ability to not cancel tokens when job completes,MR provides a config mapreduce.job.complete.cancel.delegation.tokens and an api Job#setCancelDelegationTokenUponJobCompletion to disable canceling tokens when a job completes.  This functionality appears to only be a workaround for the RM's inability to track tokens are being used by multiple apps.  Hence; w o this setting; oozie  pig jobs will fail after the first sub-job completes and the tokens are cancelled.  YARN-503 properly tracks tokens used by multiple jobs; which likely negates the need to specify not canceling tokens.,Open,Unresolved,,Daryn Sharp,Daryn Sharp,Fri; 22 Mar 2013 21:44:13 +0000,Thu; 12 May 2016 18:23:49 +0000,,,0.23.0;2.0.0-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5096
MAPREDUCE-5097,Bug,Minor,test,Job.addArchiveToClassPath is ignored when running job with LocalJobRunner,Using external dependency jar in mr job. Adding it to the job classpath via Job.addArchiveToClassPath(...) doesn't work when running with LocalJobRunner (i.e. in unit test). This makes it harder to unit-test such jobs (with third-party runtime dependencies).,Patch Available,Unresolved,,Alex Baranau,Alex Baranau,Fri; 22 Mar 2013 21:46:19 +0000,Wed; 6 May 2015 03:31:38 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5097
MAPREDUCE-5098,Bug,Major,contrib/gridmix,Fix findbugs warnings in gridmix,Work on MAPREDUCE-5077 has exposed a bunch of findbugs warnings in gridmix code.   https: newPatchFindbugsWarningshadoop-gridmix.html,Closed,Fixed,MAPREDUCE-4239,Karthik Kambatla,Karthik Kambatla,Sat; 23 Mar 2013 01:17:23 +0000,Mon; 3 Nov 2014 18:33:34 +0000,Thu; 11 Apr 2013 13:09:35 +0000,,2.0.3-alpha,findbugs,MAPREDUCE-5077,MAPREDUCE-5077,https://issues.apache.org/jira/browse/MAPREDUCE-5098
MAPREDUCE-5099,Bug,Major,mrv2,mapreduce.lib.jobcontrol.JobControl API Incompatibility between branch-1 and branch-2,The branch-1 API has the following methods:    and the branch-2 API has the following methods:,Resolved,Not A Problem,,Karthik Kambatla,Karthik Kambatla,Sat; 23 Mar 2013 04:11:07 +0000,Mon; 3 Nov 2014 18:33:31 +0000,Sat; 23 Mar 2013 04:14:28 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5099
MAPREDUCE-5100,Bug,Minor,,jobconf_history.jsp is not showing job configs in case of retired jobs,jobconf_history.jsp is not showing job config for retired jobs; even job id mentioned on this page is wrong. As per mapreduce code all this information is calculated from logFile param passed to these jsp; which flows form jobtracker.jsp - jobdetailshistory.jsp - jobconf_history.jsp as shown below.  http: localhost_1364233603831_job_201303252316_0001_conf.xml,Resolved,Cannot Reproduce,,Unassigned,Abhishek Gayakwad,Mon; 25 Mar 2013 18:29:44 +0000,Sat; 13 Apr 2013 04:16:46 +0000,Sat; 13 Apr 2013 04:16:46 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5100
BIGTOP-884,Bug,Major,tests,hive smoke tests can't be executed as a jar file isn't present anymore,An attempt run run Hive 0.9 fails because of   INFO  gmaven-plugin:1.0:execute (find-versioned-jar) @ hive-smoke-execution  Mar 25; 2013 2:58:20 PM org.apache.commons.logging.Log$error call SEVERE: No slf4j-log4j12-.* .jar has been found under  lib. Check your installation. ...... ERROR Failed to execute goal org.codehaus.groovy.maven:gmaven-plugin:1.0:execute (find-versioned-jar) on project hive-smoke-execution:  lang.NullPointerException - Help 1  A look into Hive's smoke tests pom.xml shows that tries to find the following libs  'hive-hbase-handler.jar'; 'hive-exec.jar'; 'hive-jdbc.jar'; 'hive-metastore.jar'; 'hive-service.jar'; 'slf4j-api.jar'; 'slf4j-log4j12.jar'; 'guava.jar' and slf4j-log4j12.jar doesn't come with Hive.,Closed,Fixed,,Konstantin Boudnik,Konstantin Boudnik,Mon; 25 Mar 2013 21:58:26 +0000,Fri; 21 Jun 2013 23:49:50 +0000,Mon; 25 Mar 2013 23:17:17 +0000,,0.5.0,,,,https://issues.apache.org/jira/browse/BIGTOP-884
MAPREDUCE-5102,Test,Major,,fix coverage  org.apache.hadoop.mapreduce.lib.db and org.apache.hadoop.mapred.lib.db,fix coverage  org.apache.hadoop.mapreduce.lib.db and org.apache.hadoop.mapred.lib.db patch MAPREDUCE-5102-trunk.patch for trunk and branch-2 patch MAPREDUCE-5102-branch-0.23.patch for branch-0.23 only,Closed,Fixed,,Andrey Klochkov,Aleksey Gorshkov,Tue; 26 Mar 2013 10:07:05 +0000,Thu; 12 May 2016 18:24:19 +0000,Wed; 9 Oct 2013 22:45:44 +0000,,0.23.7;2.0.4-alpha;3.0.0-alpha1,,,MAPREDUCE-5569,https://issues.apache.org/jira/browse/MAPREDUCE-5102
MAPREDUCE-5103,Improvement,Major,,Remove dead code QueueManager and JobEndNotifier,There are a few classes that are dead or duplicate code at this point.   org JobEndNotifier.  LocalRunner is currently using the JobEndNotifier; but there is a replacement for in in MRv2 org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.  The two should be combined together and duplicate code removed.  There appears to only be one method called for the QueueManger and it appears to be setting a property that is not used any more; so it can be removed.,Open,Unresolved,,jhanver chand sharma,Robert Joseph Evans,Tue; 26 Mar 2013 14:38:51 +0000,Wed; 30 Apr 2014 12:39:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5103
MAPREDUCE-5104,Improvement,Major,,Deprecate and Remove PathCleanupQueue,CleanupQueue and InlineCleanupQueue appear to be dead code.  However; they are not marked as private and InlineCleanupQueue is part of UtilsForTests; so they could be used by other projects as part of their testing.  We should deprecate these in branch-2 and remove them from trunk. There is no point in continuing to test dead code.,Open,Unresolved,,Unassigned,Robert Joseph Evans,Tue; 26 Mar 2013 14:44:27 +0000,Tue; 26 Mar 2013 14:44:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5104
MAPREDUCE-5105,Bug,Minor,jobhistoryserver;webapps,Job History Webpage Elapsed Time Column Sort Broken,The Job History server's table for listing task attempts includes an 'Elapsed Time' column.  It appears this column is being sorted alphabetically instead of numerically.  For example; a duration of 18 minutes is ordered as shorter than a duration of 1 minute.  Example URL: http: SUCCESSFUL,Resolved,Duplicate,MAPREDUCE-5024,Unassigned,Kendall Thrapp,Tue; 26 Mar 2013 15:39:57 +0000,Thu; 28 Mar 2013 16:37:14 +0000,Thu; 28 Mar 2013 16:37:14 +0000,,0.23.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5105
MAPREDUCE-5106,Bug,Minor,,mapreduce.jobtracker.split.metainfo.maxsize can be set at job level ,mapreduce.jobtracker.split.metainfo.maxsize gives an impression that this property can be set at JT level only and will require JT restart in case of any modification. But actually this can be set at individual job level.  So either this property should be named properly or should be restricted to JT level only.,Resolved,Not A Problem,,Unassigned,Abhishek Gayakwad,Tue; 26 Mar 2013 17:06:33 +0000,Wed; 27 Mar 2013 15:10:52 +0000,Wed; 27 Mar 2013 12:29:40 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5106
MAPREDUCE-5107,Improvement,Major,,MR AM needs to be able to handle unavailable HDFS,Stuff like not starting tasks when HDFS is unavailable. Not terminating tasks that are spinning on HDFS to become available. These features exist in branch-1 JT. Some of this may already be in place in the current app master.,Open,Unresolved,,Unassigned,Bikas Saha,Wed; 27 Mar 2013 18:34:29 +0000,Wed; 27 Mar 2013 18:34:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5107
MAPREDUCE-5108,Improvement,Blocker,,Changes needed for Binary Compatibility for MR applications via YARN,As we get ready to ship out a beta stable version of hadoop-2; it makes sense to spend time reviewing support for existing MR applications (hadoop-1) to migrate seamlessly.  We've done various pieces of work over time; let's track progress and document things clearly. Zhijie Shen has done a bunch of testing and results look very promising so far.  The aim is to support applications using org.apache.hadoop.mapred.* api in a binary compatible manner in hadoop-2 - thus; users can just take existing MR applications jars; point them at YARN clusters and things just work.  Clearly; we might have some corner cases (haven't seen many so far); including semantics (not just apis); however the intent is to; at least; document them throughly if not actually fix them as feasible.  Also; it's clear that we will not be able to support org.apache.hadoop.mapreduce api in a binary compatible manner due to the interface changes we made in hadoop-0.21 (sigh); and hence; users using the new apis will have to re-compile (i.e. source compatible only).   Net; given that vast majority of users use the org.apache.hadoop.mapred api; it's a very reasonable way to ease migration to hadoop-2.,Resolved,Fixed,,Zhijie Shen,Arun C Murthy,Wed; 27 Mar 2013 21:33:51 +0000,Fri; 16 Aug 2013 04:13:59 +0000,Tue; 18 Jun 2013 16:43:57 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5108
MAPREDUCE-5109,Improvement,Major,,Job view-acl should apply to job listing too,Job view-acl should apply to job listing too; currently it only applies to job details pages.,Open,Unresolved,,Vinod Kumar Vavilapalli,Arun C Murthy,Wed; 27 Mar 2013 23:38:22 +0000,Thu; 27 Jun 2013 22:20:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5109
MAPREDUCE-5110,Bug,Major,tasktracker,Kill task early in case of long task launch delays,If a task takes too long to launch; the JT expires the task and schedules another  any point in time.,Resolved,Won't Fix,,Karthik Kambatla,Karthik Kambatla,Thu; 28 Mar 2013 00:58:54 +0000,Mon; 3 Nov 2014 18:34:03 +0000,Wed; 12 Mar 2014 18:44:10 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5110
YARN-538,Improvement,Major,,RM address DNS lookup can cause unnecessary slowness on every JHS page load ,When I run the job history server locally; every page load takes in the 10s of seconds.  I profiled the process and discovered that all the extra time was spent inside YarnConfiguration#getRMWebAppURL; trying to resolve 0.0.0.0 to a hostname.  When I changed my yarn.resourcemanager.address to localhost; the page load times decreased drastically.  There's no that we need to perform this resolution on every page load.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 28 Mar 2013 02:29:29 +0000,Tue; 27 Aug 2013 22:15:01 +0000,Wed; 3 Apr 2013 20:44:39 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/YARN-538
MAPREDUCE-5112,Bug,Major,contrib/fair-share,Hadoop Mapreduce fails when permission management is enabled and scheduler is FairScheduler,I enabled the permission management in my hadoop cluster; but I'm facing a problem sending jobs with pig. This is the scenario:  1 - I have hadoop property  Ps: This works with Capacity Scheduler,Open,Unresolved,,Unassigned,Marcos Sousa,Thu; 28 Mar 2013 12:52:21 +0000,Thu; 29 Aug 2013 00:24:52 +0000,,,1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5112
MAPREDUCE-5113,Bug,Major,,Streaming input/output types are ignored with java mapper/reducer,After MAPREDUCE-1888; with a  mapper or reducer; StreamJob doesn't respect stream.map.output value classes; even if these configs are explicitly set by the user.   As MAPREDUCE-1888 is not in branch-1; this change is only needed in hadoop 2.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 12 Feb 2013 22:14:17 +0000,Tue; 27 Aug 2013 22:22:07 +0000,Thu; 11 Apr 2013 13:05:24 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5113
MAPREDUCE-5114,Bug,Major,mr-am,Subsequent AM attempt can crash trying to read prior AM attempt information,Saw the second AM attempt of a job fail early during startup because it tried to read the AMInfos from the previous attempt's history file and hit an error that wasn't an IOException.  Stack trace to follow.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 28 Mar 2013 20:47:58 +0000,Fri; 14 Nov 2014 16:09:00 +0000,,,2.0.3-alpha;0.23.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5114
MAPREDUCE-5115,Bug,Major,,MR app master may try to assign a reduce priority container to a map,ScheduledRequests.assign() checks reduces.isEmpty() and releases REDUCE priority containers. But it could have received more REDUCE priority containers than reduces.size() in which case it will not release excess REDUCE priority containers. Later on in ScheduledRequests.assignToReduce() it will not be able to assign them to reduces. These containers will fall through to ScheduledRequests.assignMapsWithLocality() where they will get assigned to maps or crash depending on the behavior of Java assert.,Resolved,Duplicate,MAPREDUCE-5002,Unassigned,Bikas Saha,Thu; 28 Mar 2013 21:33:51 +0000,Thu; 28 Mar 2013 21:43:27 +0000,Thu; 28 Mar 2013 21:43:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5115
MAPREDUCE-5116,New Feature,Major,benchmarks,PUMA Benchmark Suite,"A benchmark suite which represents a broad range of ""real-world"" MapReduce applications exhibiting application characteristics with high j.jpdc.2012.12.012) project in JPDC '12.",Resolved,Later,,Faraz Ahmad,Faraz Ahmad,Thu; 28 Mar 2013 21:50:54 +0000,Fri; 25 Apr 2014 14:30:34 +0000,Fri; 25 Apr 2014 14:30:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5116
MAPREDUCE-5117,Bug,Blocker,security,With security enabled HS delegation token renewer fails,It seems that the HSClientProtocolPBClientImpl should implement Closeable as per the attached stack trace. The problem can be observed on a cluster running the latest branch-2.0.4-alpha with MAPREDUCE-5088 applied on top. The easiest way to reproduce it is to run an oozie pig job:     Please also note that I can successfully submit simple jobs (Pi Sleep) from a command line using hadoop jar command. Thus it seems related to MAPREDUCE-5088 change.,Closed,Fixed,,Siddharth Seth,Roman Shaposhnik,Thu; 28 Mar 2013 23:43:08 +0000,Fri; 26 Apr 2013 02:14:46 +0000,Wed; 3 Apr 2013 05:45:22 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5117
MAPREDUCE-5118,Sub-task,Major,benchmarks,Inverted Index,Inverted-Index takes a list of documents as input and generates word-to-document indexing. Map emits word; docId tuples with each word emitted once per docId. Reduce combines all tuples on key word and emits word;docId tuples after removing duplicates.,Resolved,Later,,Faraz Ahmad,Faraz Ahmad,Fri; 29 Mar 2013 10:23:40 +0000,Fri; 25 Apr 2014 14:30:56 +0000,Fri; 25 Apr 2014 14:30:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5118
MAPREDUCE-5119,Bug,Minor,,Splitting issue when using NLineInputFormat with compression,#make a long text line. It seems only long line text causing issue. $ c          mapper wc  I am expecting the same results as above; 'coz decompressing should occur before processing one-line text (i.e. wc); however; I am getting:  Num task: 397 (or other large numbers depend on environments); and output has 397 lines: Line1-396: 0 0 0 Line 397: 1 2 202699  Any idea why so many mapred.map.tasks &gt;1? Is it incorrect splitting? I purposely choose gzip because I believe it is NOT split-able. I got similar results when using bzip2 and lzop codecs.,Reopened,Unresolved,,Unassigned,Qiming He,Thu; 28 Mar 2013 12:47:15 +0000,Fri; 29 Mar 2013 14:33:35 +0000,,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5119
MAPREDUCE-5120,Improvement,Major,applicationmaster,Allow app master to use tracing async dispatcher,YARN-366 proposes an option to add traces to events so that exceptions could report an events lineage.  This JIRA would add a mapreduce config option that would allow the MR app master to use the tracing async dispatcher as well.,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Sun; 31 Mar 2013 05:49:36 +0000,Thu; 2 May 2013 02:30:03 +0000,,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5120
MAPREDUCE-5121,Bug,Trivial,,Problem with field separator in FieldSelectionHelper,I found that org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper and the corresponding old api org.apache.hadoop.mapred.lib.FieldSelectionMapReduce take user specified separator string as a regular expression in String.split(); but also use it as a normal string in StringBuffer.append(). It will be a problem if the separator string contains meta character. I suggest take separator literally by calling Pattern.quote(separator). Or just use another property to specify the separator which should be added in the output.,Open,Unresolved,,Unassigned,Kai Wei,Mon; 1 Apr 2013 03:01:00 +0000,Thu; 19 Mar 2015 06:50:32 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5121
MAPREDUCE-5122,Bug,Major,,JH web UI: clicking on data/rack local counters always list all maps/reducers with value 0,In the job history UI when you are looking at job counters it lets you click on the data-local map tasks; rack-local map tasks; etc; but it always shows you all maps and reduces with the value of 0 even though some maps were data local and some were rack local.,Open,Unresolved,,Unassigned,Thomas Graves,Mon; 1 Apr 2013 16:05:41 +0000,Mon; 1 Apr 2013 16:05:41 +0000,,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5122
HADOOP-9448,Bug,Blocker,,Reimplement things,We've got to the point we need to reimplement things from scratch.,Resolved,Won't Fix,,Alejandro Abdelnur,Alejandro Abdelnur,Mon; 1 Apr 2013 21:10:40 +0000,Wed; 3 Apr 2013 05:27:02 +0000,Wed; 3 Apr 2013 05:27:02 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/HADOOP-9448
MAPREDUCE-5124,Bug,Major,mr-am,AM lacks flow control for task events,The AM does not have any flow control to limit the incoming rate of events from tasks.  If the AM is unable to keep pace with the rate of incoming events for a sufficient period of time then it will eventually exhaust the heap and crash.  MAPREDUCE-5043 addressed a major bottleneck for event processing; but the AM could still get behind if it's starved for CPU and or handling a very large job with tens of thousands of active tasks.,Resolved,Fixed,,Peter Bacsko,Jason Lowe,Tue; 2 Apr 2013 14:30:05 +0000,Thu; 11 Jan 2018 16:58:31 +0000,Fri; 1 Dec 2017 20:36:13 +0000,,2.0.3-alpha;0.23.5,,,YARN-270;MAPREDUCE-5043;YARN-3630;MAPREDUCE-6242,https://issues.apache.org/jira/browse/MAPREDUCE-5124
MAPREDUCE-5125,Bug,Minor,test,TestDFSIO should write less compressible data,Currently; TestDFSIO writes a short repeating string of sequential (byte)0 through (byte)50. This makes its output very compressible (I measured 250:1 by LZOing the resulting file). This makes the results of TestDFSIO very hard to compare when running on HDFS vs other file systems which may include some compression on the network; disk; or both  what is ostensibly a benchmark of IO throughput yields completely skewed results towards the system with compression.,Open,Unresolved,,Unassigned,Todd Lipcon,Wed; 3 Apr 2013 17:38:23 +0000,Mon; 9 Sep 2013 05:28:57 +0000,,,2.0.3-alpha;1.1.2,,,MAPREDUCE-5491,https://issues.apache.org/jira/browse/MAPREDUCE-5125
MAPREDUCE-5126,New Feature,Minor,,Add possibility to set a custom system classloader for mapred child processes; separate from mapred.child.java.opts,Some third party frameworks   systems based on Hadoop might want to set a custom classloader for loading classes of their jobs to better resolve conflicts with their libraries.   While it is possible to set a custom classloader using the mapred.child. class.loader that allows to set the classloader separately. This gives custom frameworks built on top of Hadoop more flexibility to supply their own classloader; without need to force users to adjust any settings.,Open,Unresolved,,Unassigned,Piotr Ko  aczkowski,Thu; 4 Apr 2013 10:16:36 +0000,Thu; 4 Apr 2013 10:20:23 +0000,,,1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5126
MAPREDUCE-5127,Sub-task,Major,applicationmaster;resourcemanager,MR job succeeds and exits even when unregister with RM fails,MR app master will clean staging dir; if the job is already succeeded and asked to reboot. If the finishApplicationMaster call fails; RM will consider this job unfinished and launch further attempts; further attempts will fail because staging dir is cleaned,Resolved,Duplicate,MAPREDUCE-5471,Jian He,Jian He,Tue; 2 Apr 2013 17:23:23 +0000,Sat; 5 Oct 2013 22:40:49 +0000,Wed; 4 Sep 2013 00:29:13 +0000,,,,,YARN-128,https://issues.apache.org/jira/browse/MAPREDUCE-5127
MAPREDUCE-5128,Improvement,Major,documentation;jobhistoryserver,mapred-default.xml is missing a bunch of history server configs,mapred-default.xml is missing many configs that work for the job history server.  mapreduce.jobhistory.cleaner.enable; mapreduce.jobhistory.done-dir; and mapreduce.jobhistory.datestring.cache.size are a few examples.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 4 Apr 2013 21:05:33 +0000,Tue; 27 Aug 2013 22:22:07 +0000,Wed; 17 Apr 2013 23:15:26 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5128
MAPREDUCE-5129,New Feature,Minor,,Add tag info to JH files,It will be useful to add tags to the existing workflow info logged by JH.  This will allow jobs to be filtered grouped for analysis more easily.,Closed,Fixed,,Billie Rinaldi,Billie Rinaldi,Thu; 4 Apr 2013 22:11:37 +0000,Wed; 15 May 2013 05:15:49 +0000,Sat; 6 Apr 2013 05:36:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5129
MAPREDUCE-5130,Improvement,Major,documentation,Add missing job config options to mapred-default.xml,I came across that mapreduce.map. opts mapreduce.map reduce.env,Closed,Fixed,MAPREDUCE-5236,Ray Chiang,Sandy Ryza,Thu; 4 Apr 2013 22:41:24 +0000,Thu; 25 Dec 2014 17:17:21 +0000,Mon; 25 Aug 2014 16:58:20 +0000,,2.0.4-alpha,,,MAPREDUCE-5236;MAPREDUCE-6205,https://issues.apache.org/jira/browse/MAPREDUCE-5130
MAPREDUCE-5131,Bug,Major,,Provide better handling of job status related apis during JT restart,I've seen pig hive applications bork during JT restart since they get NPEs - this is due to fact that jobs are not really inited; but are submitted.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 5 Apr 2013 12:36:13 +0000,Wed; 15 May 2013 05:15:48 +0000,Sat; 6 Apr 2013 03:11:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5131
MAPREDUCE-5132,Improvement,Minor,,Enhance FairScheduler queue selection with Unix-SubGroups,I have clients that use the primary group for other reasons and would like to select the fairScheduler queue by subgroup.  Currently the fairscheduler can only link a job config property to a fairscheduler queue and subgroups are not in the job config.    Now thankfully we can get this data from UserGroupInformation.createProxyUser which is cool because this is how TT currently see if it can copy data when kerberos is enabled.  Once we have the sub-groups we just connect the first sub-group that matches a queue.  I'll put up some code that I used to solve the problem in the short term.    Note that there is an issue with this code.  It doesn't populate the TT Web UI drop down menu correctly.  I think I have a solution for that; but before I implement that I was wondering if the community has any feedback first.,Open,Unresolved,,Unassigned,Theodore michael Malaska,Fri; 5 Apr 2013 15:24:48 +0000,Fri; 19 Apr 2013 20:54:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5132
MAPREDUCE-5133,Bug,Major,test,TestSubmitJob.testSecureJobExecution is flaky due to job dir deletion race,At the end of TestSubmitJob.testSecureJobExecution; the test waits for the job to be done and then asserts that the job submission directory has been deleted.  The directory is deleted by an asynchronous cleanup thread; so the test can hit the assert before the deletion is run.,Resolved,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 5 Apr 2013 23:09:44 +0000,Wed; 17 Apr 2013 23:18:27 +0000,Wed; 17 Apr 2013 23:18:27 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5133
MAPREDUCE-5134,Bug,Major,,Default settings cause LocalJobRunner to OOME,If I run a job using the local job runner with vanilla settings; I get an out of memory error.  This seems to be because the default client memory maximum is 128 MB; and the default io.sort.mb is 100 MB.,Resolved,Not A Problem,,Sandy Ryza,Sandy Ryza,Sat; 6 Apr 2013 02:52:27 +0000,Tue; 30 Apr 2013 00:22:54 +0000,Tue; 30 Apr 2013 00:22:54 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5134
MAPREDUCE-5135,New Feature,Minor,jobhistoryserver,Allow for a plugin to process JH files as they are transferred from MR AM to JHS,Allow for a plugin to process JH files as they are transferred from MR AM to JHS. This will allow; for e.g.; Ambari to add a plugin to intercept JH data.,Open,Unresolved,,Unassigned,Arun C Murthy,Sat; 6 Apr 2013 06:34:46 +0000,Sat; 6 Apr 2013 06:34:46 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5135
MAPREDUCE-5136,Bug,Major,,TestJobImpl->testJobNoTasks fails with IBM JAVA,"I am not sure if this is a testcase or a design issue. During execution of TestJobImpl-testJobNoTasks() there is an assertion made based on the order of key value pairs stored in adjacency list. However adjacency list was created by Configuration-getValByRegex() as a HashMap (order is not guaranteed):  Testcase:     JobSubmittedEventHandler jseHandler = new JobSubmittedEventHandler(""testId"";         ""testName""; ""testNodeName""; "" "" "");    ....    ....     try {       Assert.assertTrue(jseHandler.getAssertValue()); ===  Configuration-getValByRegex(): public MapString;String getValByRegex(String regex) {     Pattern p = Pattern.compile(regex);     MapString;String result = new HashMapString;String(); =======   as we all know; HashMap makes absolutely no guarantees about the iteration order. It can (and will) even change completely when new elements are added.  Changing HashMap to LinkedHashMap fixes the ordering inconsistency; however with a small performance side effect.",Closed,Fixed,,Amir Sanjar,Amir Sanjar,Sun; 7 Apr 2013 05:23:42 +0000,Tue; 27 Aug 2013 22:22:16 +0000,Thu; 11 Apr 2013 19:19:12 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5136
MAPREDUCE-5137,Bug,Major,applicationmaster,AM web UI: clicking on Map Task results in 500 error,Go to a running mapreduce app master web UI. Click on the job; then click on the MAP task type to bring up the list of maps; then try to click on a particular map task.  It fails with a 500 error.  Note this doesn't exist in 0.23.6.   Exception in the log looks like:  2013-04-09 13:53:01;587 DEBUG 1088374@qtp-13877033-2 -  task_1365457322543_0004_m_000000   org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler. 1212) ... ... ...,Closed,Fixed,MAPREDUCE-5500,Thomas Graves,Thomas Graves,Tue; 9 Apr 2013 15:14:34 +0000,Thu; 12 Sep 2013 00:05:09 +0000,Thu; 11 Apr 2013 16:37:09 +0000,,0.23.7;2.1.0-beta,,,MAPREDUCE-5144,https://issues.apache.org/jira/browse/MAPREDUCE-5137
MAPREDUCE-5138,Bug,Major,,Fix LocalDistributedCacheManager after YARN-112,LocalDistributedCacheManager uses FSDownload which is changing in YARN-112. Need to fix it.,Closed,Fixed,,Omkar Vinit Joshi,Vinod Kumar Vavilapalli,Tue; 9 Apr 2013 19:47:29 +0000,Tue; 27 Aug 2013 22:21:59 +0000,Tue; 9 Apr 2013 19:58:19 +0000,,,,,YARN-112,https://issues.apache.org/jira/browse/MAPREDUCE-5138
MAPREDUCE-5139,Bug,Major,,Update MR App after YARN-486,MR App needs to be updated after YARN-486 API Changes.  Will try committing this and YARN-486 almost together to not break builds.,Closed,Fixed,,Xuan Gong,Vinod Kumar Vavilapalli,Wed; 10 Apr 2013 04:12:31 +0000,Tue; 27 Aug 2013 22:22:15 +0000,Thu; 11 Apr 2013 23:06:45 +0000,,,,,YARN-486,https://issues.apache.org/jira/browse/MAPREDUCE-5139
MAPREDUCE-5140,Bug,Major,,MR part of YARN-514,In YARN-514; application store needs to be delayed to unblock application submission; such that a new state of MRApp needs to be created. On mapreduce side; there's some function to map yarn states to mapreduce ones. This mapping needs to be updated due to the newly added state.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Wed; 10 Apr 2013 04:55:15 +0000,Tue; 27 Aug 2013 22:22:06 +0000,Wed; 17 Apr 2013 20:35:23 +0000,,,,YARN-514,,https://issues.apache.org/jira/browse/MAPREDUCE-5140
YARN-570,Bug,Major,webapp,Time strings are formated in different timezone,"Time strings on different page are displayed in different timezone. If it is rendered by renderHadoopDate() in yarn.dt.plugins.js; it appears as ""Wed; 10 Apr 2013 08:29:56 GMT"" If it is formatted by format() in yarn.util.Times; it appears as ""10-Apr-2013 16:29:56""  Same value; but different timezone.",Closed,Fixed,YARN-1973;YARN-1998,Akira Ajisaka,Peng Zhang,Wed; 10 Apr 2013 12:40:09 +0000,Wed; 4 Nov 2015 22:41:00 +0000,Tue; 11 Nov 2014 21:26:10 +0000,,2.2.0,,,HDFS-8388,https://issues.apache.org/jira/browse/YARN-570
MAPREDUCE-5142,Bug,Major,,MR AM unregisters with state KILLED when an error causes dispatcher to shutdown,RMCommunicator sets final state to KILLED if the job is in a running state and isSignalled is set to true.      This happens when any uncaught exception in any event handler ends up causing the AsyncDispatcher to trigger a shutdown. In such a scenario; even though the AM actually failed due to some error; its actual state ends up as KILLED.,Open,Unresolved,,Unassigned,Hitesh Shah,Wed; 10 Apr 2013 19:42:32 +0000,Wed; 10 Apr 2013 20:04:47 +0000,,,2.0.3-alpha;0.23.5,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5142
MAPREDUCE-5143,Bug,Minor,,TestLineRecordReader has no test case for compressed files,TestLineRecordReader was no test case for compressed files,Resolved,Duplicate,MAPREDUCE-5656,Tsuyoshi Ozawa,Sonu Prathap,Thu; 11 Apr 2013 11:26:15 +0000,Thu; 12 May 2016 18:22:21 +0000,Thu; 27 Feb 2014 14:40:23 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5143
MAPREDUCE-5144,Bug,Minor,test,TestAMWebApp.testConfView has poor test coverage,"testConfView is supposed to test the rendering of a job's configuration page; but the rendering code exits early with; ""Sorry; can't do anything without a JobID.""  Therefore it's not really testing much of the ConfBlock code at all.",Open,Unresolved,,Unassigned,Jason Lowe,Thu; 11 Apr 2013 15:31:27 +0000,Thu; 11 Apr 2013 15:32:29 +0000,,,0.23.7;2.1.0-beta,,,MAPREDUCE-5137,https://issues.apache.org/jira/browse/MAPREDUCE-5144
MAPREDUCE-5145,Bug,Major,,Change default max-attempts to be more than one for MR jobs as well,We need to give the AM of MR jobs the chance to retry.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 11 Apr 2013 19:38:22 +0000,Tue; 27 Aug 2013 22:22:03 +0000,Wed; 1 May 2013 00:44:31 +0000,,,,,YARN-542,https://issues.apache.org/jira/browse/MAPREDUCE-5145
MAPREDUCE-5146,Bug,Minor,task,application classloader may be used too early to load classes,At least in the case of YarnChild; the application classloader is set fairly early (both in Configuration and as a TCCL). This has an effect of using the application classloader unexpectedly early.  There is a fair amount of code that gets invoked between setting the classloader and executing mapper reducer classes and their dependencies.,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 11 Apr 2013 20:38:28 +0000,Tue; 27 Aug 2013 22:22:14 +0000,Mon; 22 Apr 2013 20:10:38 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5146
MAPREDUCE-5147,Bug,Major,mrv2,Maven build should create hadoop-mapreduce-client-app-VERSION.jar directly,Currently the build creates mr-app.jar and links it to the proper name.  All hard links to mr-app.jar appear to have been removed.  The maven build should be simplified to directly build the jar. Related,Closed,Fixed,,Robert Parker,Robert Parker,Fri; 12 Apr 2013 15:59:36 +0000,Tue; 10 Mar 2015 04:30:44 +0000,Fri; 19 Apr 2013 20:55:09 +0000,,,,HADOOP-9469,MAPREDUCE-3370,https://issues.apache.org/jira/browse/MAPREDUCE-5147
MAPREDUCE-5148,Bug,Major,tasktracker,Syslog missing from Map/Reduce tasks,MAPREDUCE-4970 introduced incompatible change and causes syslog to be missing from tasktracker on old clusters which just have log4j.properties configured,Closed,Fixed,,Arun C Murthy,Yesha Vora,Fri; 12 Apr 2013 23:35:35 +0000,Sun; 4 Aug 2013 08:23:27 +0000,Wed; 8 May 2013 20:45:23 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5148
MAPREDUCE-5149,Bug,Major,,If job has more counters Job History server is not able to show them. ,We saw this problem migrating applications to MapReduceV2:  Our applications use hadoop counters extensively (1000+ counters for certain jobs). While this may not be one of recommended best practices in hadoop; the real issue here is reliability of the framework when applications exceed counter limits.  The hadoop servers (yarn; history server) were originally brought up with mapreduce.job.counters.max=1000 under core-site.xml  We then ran map-reduce job under an application using its own job specific overrides; with  mapreduce.job.counters.max=10000  All the tasks for the job finished successfully; however the overall job still failed due to AM encountering exceptions as:     The overall job failed; and the job history wasn't accessible either at the end of the job (didn't show up in job history server).  We were able to workaround the issue by changing to higher limits in core-site.xml and restarting yarn servers. However that forced us to increase the counters global limit to be as high as possible use by any individual application; which is hard to predict.  The original job then succeeded with new global limits.   However; since we didn't restart the job history server; it was unable to display job history page for the successful job altogether as it still hit counter exceeded exception. Restart of job history server finally got the application available under job history.  I'll also attach AM logs to help debug the issue,Open,Unresolved,,Mayank Bansal,Mayank Bansal,Fri; 12 Apr 2013 23:47:33 +0000,Wed; 25 Mar 2015 05:11:14 +0000,,,2.0.0-alpha,usability,,MAPREDUCE-5875,https://issues.apache.org/jira/browse/MAPREDUCE-5149
MAPREDUCE-5150,Improvement,Minor,examples,Backport 2009 terasort (MAPREDUCE-639) to branch-1,Users evaluate performance of Hadoop clusters using different benchmarks such as TeraSort. However; terasort version in branch-1 is outdated. It works on teragen dataset that cannot exceed 4 billion unique keys and it does not have the fast non-sampling partitioner SimplePartitioner either.,Resolved,Won't Fix,,Gera Shegalov,Gera Shegalov,Sat; 13 Apr 2013 23:26:11 +0000,Sat; 9 May 2015 00:06:03 +0000,Sat; 9 May 2015 00:04:57 +0000,,1.2.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5150
MAPREDUCE-5151,Bug,Major,,Update MR App after YARN-444,YARN-444 is moving standard exit codes from YarnConfiguration into a separate record; creating a tracking ticket for MR only changes.,Closed,Fixed,,Sandy Ryza,Vinod Kumar Vavilapalli,Mon; 15 Apr 2013 20:27:45 +0000,Tue; 27 Aug 2013 22:22:18 +0000,Mon; 15 Apr 2013 23:57:34 +0000,,,,,YARN-444,https://issues.apache.org/jira/browse/MAPREDUCE-5151
MAPREDUCE-5152,Bug,Major,,MR App is not using Container from RM,The goal of YARN-486 was to make AMs just pass information encapsulated in Container along to NM instead of doing it themselves by duplicating information. We still do not do this pass-through as intended as YARN-486 avoided the individual field duplication but failed to avoid the duplication of container itself.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 16 Apr 2013 01:46:09 +0000,Tue; 27 Aug 2013 22:22:15 +0000,Thu; 18 Apr 2013 20:14:47 +0000,,2.1.0-beta,,YARN-571,YARN-486,https://issues.apache.org/jira/browse/MAPREDUCE-5152
MAPREDUCE-5153,New Feature,Major,,Support for running combiners without reducers,scenario: Workflow mapper - sort - combiner - hdfs  No api change is need; if user set combiner class and reducers = 0 then run combiner and sent output to HDFS.  Popular libraries such as scalding and cascading are offering this functionality; but they use caching entire mapper output in memory.,Open,Unresolved,,Unassigned,Radim Kolar,Tue; 16 Apr 2013 15:41:10 +0000,Fri; 26 Jul 2013 12:35:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5153
MAPREDUCE-5154,Bug,Major,jobtracker,staging directory deletion fails because delegation tokens have been cancelled,In a secure setup; the jobtracker needs the job's delegation tokens to delete the staging directory.  MAPREDUCE-4850 made it so that job cleanup staging directory deletion occurs asynchronously; so that it could order it with system directory deletion.  This introduced the issue that a job's delegation tokens could be cancelled before the cleanup thread got around to deleting it; causing the deletion to fail.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 17 Apr 2013 01:00:49 +0000,Wed; 15 May 2013 05:16:16 +0000,Wed; 1 May 2013 02:55:11 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5154
MAPREDUCE-5155,Bug,Minor,test,Race condition in test case TestFetchFailure cause it to fail,I run into this once: testFetchFailureWithRecovery(org.apache.hadoop.mapreduce.v2.app.TestFetchFailure): Num completion events not correct expected:1 but was:0  There is a race condition between job.getTaskAttemptCompletionEvents and dealing with JOB_TASK_ATTEMPT_COMPLETED event. If job.getTaskAttemptCompletionEvents invoked because of task in SUCCEEDED state ;but before JOB_TASK_ATTEMPT_COMPLETED event scheduled;the test case will fail.,Resolved,Fixed,,Haibo Chen,Nemon Lou,Wed; 17 Apr 2013 04:16:12 +0000,Thu; 29 Dec 2016 19:35:07 +0000,Thu; 29 Dec 2016 19:00:35 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5155
MAPREDUCE-5156,Sub-task,Blocker,,Hadoop-examples-1.x.x.jar cannot run on Yarn,M R examples are run through ProgramDriver.driver. ProgramDriver.driver returns void in hadoop-1; while it returns int in hadoop-2. Therefore; the function signatures in the example jar and yarn are incompatible.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Wed; 17 Apr 2013 07:21:14 +0000,Tue; 27 Aug 2013 22:22:14 +0000,Wed; 22 May 2013 06:37:46 +0000,,,,MAPREDUCE-5157,,https://issues.apache.org/jira/browse/MAPREDUCE-5156
MAPREDUCE-5157,Sub-task,Major,,Sort in hadoop-1 examples is not binary compatible with hadoop-2 mapred.lib,In SORT example; org.apache.hadoop.mapred.lib.InputSampler.Sampler is used in hadoop-1. However; after upgrading to hadoop-2; org.apache.hadoop.mapred.lib.InputSampler is modified to extend org.apache.hadoop.mapreduce.lib.partition.InputSampler; and the inner class; Sampler; has been moved to the superclass. Therefore; hadoop-1 SORT can not find Sampler when it runs with hadoop-2 framework.,Closed,Fixed,MAPREDUCE-4251,Zhijie Shen,Zhijie Shen,Wed; 17 Apr 2013 16:43:22 +0000,Tue; 27 Aug 2013 22:22:14 +0000,Wed; 8 May 2013 21:43:34 +0000,,,,MAPREDUCE-5156,MAPREDUCE-5225,https://issues.apache.org/jira/browse/MAPREDUCE-5157
MAPREDUCE-5158,Bug,Major,jobtracker,Cleanup required when mapreduce.job.restart.recover is set to false,When mapred.jobtracker.restart.recover is set as true and mapreduce.job.restart.recover is set to false for a MR job; Job clean up never happens for that job if JT restarts while job is running.  .staging and job-info file for that job remains on HDFS forever.,Closed,Fixed,,Mayank Bansal,Yesha Vora,Wed; 17 Apr 2013 17:10:21 +0000,Wed; 15 May 2013 05:16:12 +0000,Sat; 27 Apr 2013 01:44:23 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5158
MAPREDUCE-5159,Sub-task,Major,,Aggregatewordcount and aggregatewordhist in hadoop-1 examples are not binary compatible with hadoop-2 mapred.lib.aggregate,Both examples in hadoop-1 use org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String args[]; Class? caller); which no longer exists after upgrading to hadoop-2. Therefore; they cannot not find the accordant function with their function signature in the binary.,Closed,Fixed,MAPREDUCE-5160,Zhijie Shen,Zhijie Shen,Wed; 17 Apr 2013 17:14:44 +0000,Tue; 27 Aug 2013 22:22:00 +0000,Wed; 8 May 2013 18:29:29 +0000,,,,MAPREDUCE-5160,MAPREDUCE-5160,https://issues.apache.org/jira/browse/MAPREDUCE-5159
MAPREDUCE-5160,Sub-task,Major,,Aggregatewordcount and aggregatewordhist in hadoop-1 examples can not find their inner classes when running on Yarn,Aggregatewordcount and Aggregatewordhist of hadoop-1 cannot run on hadoop-2 due to org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String args[]; Class? caller) is not available on hadoop-2 (see MAPREDUCE-5159).  After I changed Aggregatewordcount and Aggregatewordhist to use createValueAggregatorJob(String args[]; Class? extends ValueAggregatorDescriptor[] descriptors); which is available on hadoop-2; the two examples could be accepted and run on Yarn.  However; the two examples still failed; because their inner classes; WordCountPlugInClass and AggregateWordHistogramPlugin; cannot be found in runtime; respectively. Both the plugin classes extend org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.,Closed,Duplicate,MAPREDUCE-5159,Zhijie Shen,Zhijie Shen,Wed; 17 Apr 2013 18:17:32 +0000,Tue; 27 Aug 2013 22:22:01 +0000,Wed; 8 May 2013 19:05:14 +0000,,,,MAPREDUCE-5159,MAPREDUCE-5159,https://issues.apache.org/jira/browse/MAPREDUCE-5160
MAPREDUCE-5161,Improvement,Major,mrv1,Merge MAPREDUCE-1806 from branch-1 to branch-1-win. CombineFileInputFormat fix for paths not on default FS,MAPREDUCE-1806 fixed a bug related to use of CombineFileInputFormat with paths that are not on the default file system.  This jira will merge the branch-1 fix to branch-1-win.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Wed; 17 Apr 2013 21:22:50 +0000,Fri; 19 Apr 2013 20:41:10 +0000,Fri; 19 Apr 2013 20:41:10 +0000,,1-win,,,MAPREDUCE-1806,https://issues.apache.org/jira/browse/MAPREDUCE-5161
MAPREDUCE-5162,Improvement,Major,client,Add ability to change the queue a job has been assigned to with JobClient,Currently the job client does not provide a facility to change the particular queue a job is assigned to. It would be nice to be able to do something like this: mapred job jobid -setqueue newqueue,Open,Unresolved,,Unassigned,Jeff Lord,Wed; 17 Apr 2013 23:48:06 +0000,Wed; 17 Apr 2013 23:48:06 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5162
MAPREDUCE-5163,Bug,Major,,Update MR App after YARN-441,YARN-441 is removing some collection APIs that are utility methods on top the base APIs. MR App needs to be updated to not use those anymore.,Closed,Fixed,,Xuan Gong,Vinod Kumar Vavilapalli,Thu; 18 Apr 2013 03:54:21 +0000,Tue; 27 Aug 2013 22:22:01 +0000,Fri; 19 Apr 2013 01:35:25 +0000,,,,,YARN-441,https://issues.apache.org/jira/browse/MAPREDUCE-5163
MAPREDUCE-5164,Bug,Major,,"command  ""mapred job"" and ""mapred queue"" omit HADOOP_CLIENT_OPTS ","HADOOP_CLIENT_OPTS does not take effect when type ""mapred job -list"" and ""mapred queue -list"". The mapred script omit it",Closed,Fixed,,Nemon Lou,Nemon Lou,Thu; 18 Apr 2013 13:47:24 +0000,Tue; 24 Sep 2013 23:33:24 +0000,Thu; 12 Sep 2013 14:36:46 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5164
MAPREDUCE-5165,Bug,Minor,,Create MiniMRCluster version which uses the mapreduce package.,The MiniMapRedCluster class references some older mapred.* classes (as per comments below however; there is the MiniMRYarnCluster; which may aim to replace it).   It could be recreated in the mapreduce package to use the Configuration class instead of JobConf; which would make it simpler to use and integrate with new FS implementations and test harnesses that use new Configuration (not JobConf) objects to drive tests.  This could be done many ways:  1) using inheritance or else  2) by copying the code directly  The appropriate implementation depends on wether or not   1) Is it okay for mapreduce.* classes to depend on mapred.* classes ? 2) Is the mapred MiniMRCluster implementation going to be deprecated or eliminated anytime?  3) What is the future of the JobConf class - which has been deprecated and then undeprecated ?  Note that This is all intimately linked to the role that MiniMRYarnCluster will play.  Relevant classes:  . MiniMRYarnCluster.java,Open,Unresolved,,Unassigned,jay vyas,Thu; 18 Apr 2013 16:32:38 +0000,Thu; 18 Apr 2013 20:18:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5165
MAPREDUCE-5166,Bug,Blocker,,ConcurrentModificationException in LocalJobRunner,With the latest version hive unit tests fail in various places with the following stack trace. The problem seems related to: MAPREDUCE-2931,Closed,Fixed,,Sandy Ryza,Gunther Hagleitner,Thu; 18 Apr 2013 18:29:39 +0000,Tue; 10 May 2016 07:39:41 +0000,Thu; 25 Apr 2013 00:56:39 +0000,,1.2.0;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5166
MAPREDUCE-5167,Bug,Major,,Update MR App after YARN-562,Tracking JIRA for MR changes at YARN-562.,Closed,Fixed,,Jian He,Vinod Kumar Vavilapalli,Fri; 19 Apr 2013 01:38:21 +0000,Tue; 27 Aug 2013 22:22:04 +0000,Fri; 26 Apr 2013 19:05:09 +0000,,,,,YARN-562,https://issues.apache.org/jira/browse/MAPREDUCE-5167
MAPREDUCE-5168,Bug,Critical,mrv2,Reducer can OOM during shuffle because on-disk output stream not released,If a reducer needs to shuffle a map output to disk; it opens an output stream and writes the data to disk.  However it does not release the reference to the output stream within the MapOutput; and the output stream can have a 128K buffer attached to it.  If enough of these on-disk outputs are queued up waiting to be merged; it can cause the reducer to OOM during the shuffle phase.  In one case I saw there were 1200 on-disk outputs queued up to be merged; leading to an extra 150MB of pressure on the heap due to the output stream buffers that were no longer necessary.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Fri; 19 Apr 2013 04:01:45 +0000,Tue; 14 May 2013 17:04:02 +0000,Tue; 14 May 2013 17:04:02 +0000,,0.23.7,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5168
MAPREDUCE-5169,Bug,Major,,Job recovery fails if job tracker is restarted after the job is submitted but before its initialized,This was noticed when within 5 seconds of submitting a word count job; the job tracker was restarted. Upon restart the job failed to recover,Closed,Fixed,,Arun C Murthy,Arpit Gupta,Fri; 19 Apr 2013 16:26:18 +0000,Wed; 15 May 2013 05:15:46 +0000,Wed; 24 Apr 2013 17:50:14 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5169
MAPREDUCE-5170,Bug,Trivial,mrv2,incorrect exception message if min node size > min rack size,"The exception message for CombineFileInputFormat if min node size  min rack size is worded backwards.  Currently it reads ""Minimum split size per node... cannot be smaller than the minimum split size per rack...""  It should be ""Minimum split size per node... cannot be LARGER than the minimum split size per rack...""",Closed,Fixed,,Sangjin Lee,Sangjin Lee,Fri; 19 Apr 2013 21:04:36 +0000,Tue; 30 Jun 2015 07:18:58 +0000,Thu; 26 Sep 2013 04:32:07 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5170
MAPREDUCE-5171,Improvement,Major,applicationmaster,Expose blacklisted nodes from the MR AM REST API ,It would be useful to expose some the list of nodes that an MR AM has blacklisted.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Mon; 22 Apr 2013 18:49:20 +0000,Tue; 27 Aug 2013 22:22:02 +0000,Sun; 16 Jun 2013 22:20:59 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5171
MAPREDUCE-5172,Improvement,Major,applicationmaster,Expose number of non-local maps in MR app metrics,nan,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Mon; 22 Apr 2013 19:38:06 +0000,Mon; 22 Apr 2013 19:38:06 +0000,,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5172
MAPREDUCE-5173,Bug,Major,client;security,Need to specify master principal run local job in a secure setup,When security is turned on; running a job involves asking the filesystems it uses for delegation tokens.  Currently; this fails if the kerberos master principal is not set; even if the job is run against a filesystem that doesn't use delegation tokens,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Mon; 22 Apr 2013 22:59:36 +0000,Mon; 22 Apr 2013 22:59:36 +0000,,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5173
MAPREDUCE-5174,Bug,Major,jobhistoryserver,Job History server gives wrong no of total maps and reducers,History server displays wrong no of total maps and total reducers in JHS UI Job listing for non-succeeded jobs and also REST API (i.e http: ) gives wrong data for total maps and reducers,Open,Unresolved,MAPREDUCE-5447,Unassigned,Devaraj K,Tue; 23 Apr 2013 09:53:38 +0000,Mon; 5 Aug 2013 07:05:49 +0000,,,2.0.3-alpha;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5174
MAPREDUCE-5175,Bug,Major,,Update MR App to not set envs that will be set by NMs anyways after YARN-561,After YARN-561; apps don't need to set specific env variables like container-id etc. This JIRA is to track the MR part of YARN-561.,Closed,Fixed,,Xuan Gong,Vinod Kumar Vavilapalli,Tue; 23 Apr 2013 21:30:47 +0000,Tue; 27 Aug 2013 22:22:17 +0000,Wed; 24 Apr 2013 00:03:23 +0000,,,,,YARN-561,https://issues.apache.org/jira/browse/MAPREDUCE-5175
MAPREDUCE-5176,Sub-task,Major,mrv2,Preemptable annotations (to support preemption in MR),Proposing a patch that introduces a new annotation @Checkpointable that represents to the framework property of user-supplied classes (e.g.; Reducer; OutputCommiter). The intended semantics is that a tagged class is safe to be preempted between invocations.   (this is in spirit similar to the Output Contracts of Nephele PACT ),Closed,Fixed,,Carlo Curino,Carlo Curino,Wed; 24 Apr 2013 00:02:47 +0000,Wed; 15 Jul 2015 23:32:18 +0000,Fri; 31 May 2013 06:08:37 +0000,,,,,MAPREDUCE-5189;MAPREDUCE-5196;MAPREDUCE-6434;YARN-567;YARN-568;YARN-569,https://issues.apache.org/jira/browse/MAPREDUCE-5176
MAPREDUCE-5177,Bug,Major,,Move to common utils FileUtil#setReadable/Writable/Executable and FileUtil#canRead/Write/Execute,Move to using common utils described in HADOOP-9413 that work well cross-platform.,Closed,Fixed,,Ivan Mitic,Ivan Mitic,Wed; 24 Apr 2013 05:33:29 +0000,Thu; 12 May 2016 18:24:12 +0000,Mon; 29 Apr 2013 23:01:05 +0000,,3.0.0-alpha1,,,MAPREDUCE-4401,https://issues.apache.org/jira/browse/MAPREDUCE-5177
MAPREDUCE-5178,Bug,Major,,Fix use of BuilderUtils#newApplicationReport as a result of YARN-577.,nan,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Wed; 24 Apr 2013 14:50:39 +0000,Tue; 27 Aug 2013 22:22:15 +0000,Thu; 25 Apr 2013 05:47:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5178
MAPREDUCE-5179,Bug,Major,,Change TestHSWebServices to do string equal check on hadoop build version similar to YARN-605,nan,Closed,Fixed,,Hitesh Shah,Hitesh Shah,Wed; 24 Apr 2013 17:21:52 +0000,Tue; 27 Aug 2013 22:22:19 +0000,Sun; 28 Apr 2013 21:03:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5179
MAPREDUCE-5180,Bug,Major,,"Running wordcount with ""-Ddfs.client.read.shortcircuit=true/false"" fails to get proper message on syslogs",Running wordcount job with -Ddfs.client.read.shortcircuit=true 2621440 2013-04-18 13:07:10;920 WARN org.apache.hadoop.io.compress.snappy.LoadSnappy: Snappy native library is available 2013-04-18 13:07:10;920 INFO org.apache.hadoop.io.compress.snappy.LoadSnappy: Snappy native library loaded 2013-04-18 13:07:10;934 INFO com.hadoop.compression.lzo.GPLNativeCodeLoader: Loaded native gpl library 2013-04-18 13:07:10;947 INFO com.hadoop.compression.lzo.LzoCodec: Successfully loaded  initialized native-lzo library hadoop-lzo rev cf4e7cbf8ed0f0622504d008101c2729dc0c9ff3 2013-04-18 13:07:11;414 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output 2013-04-18 13:07:11;586 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor 2013-04-18 13:07:11;962 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0 2013-04-18 13:07:12;034 INFO org.apache.hadoop.mapred.Task: Task:attempt_201304181305_0001_m_000000_0 is done. And is in the process of commiting 2013-04-18 13:07:12;106 INFO org.apache.hadoop.mapred.Task: Task attempt_201304181305_0001_m_000000_0 done. 2013-04-18 13:07:12;152 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs truncater with mapRetainSize=-1 and reduceRetainSize=-1 2013-04-18 13:07:12;637 INFO org.apache.hadoop.io.nativeio.NativeIO: Initialized cache for UID to User mapping with a cache timeout of 14400 seconds. 2013-04-18 13:07:12;637 INFO org.apache.hadoop.io.nativeio.NativeIO: Got UserName mapred for UID 2002 from the native implementation,Resolved,Invalid,,Unassigned,Yesha Vora,Wed; 24 Apr 2013 20:09:12 +0000,Fri; 26 Apr 2013 19:11:12 +0000,Fri; 26 Apr 2013 19:11:12 +0000,,1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5180
MAPREDUCE-5181,Bug,Major,applicationmaster,RMCommunicator should not use AMToken from the env,nan,Closed,Fixed,,Vinod Kumar Vavilapalli,Siddharth Seth,Thu; 25 Apr 2013 00:49:27 +0000,Tue; 27 Aug 2013 22:21:55 +0000,Thu; 25 Apr 2013 02:53:04 +0000,,2.0.4-alpha,,YARN-579,,https://issues.apache.org/jira/browse/MAPREDUCE-5181
MAPREDUCE-5182,Bug,Major,,LineRecordReader#getProgress throwing IOException breaks compatibility,This has been in trunk for a while (since MAPREDUCE-773); but was only introduced into branch-1 in July.,Resolved,Won't Fix,,Sandy Ryza,Sandy Ryza,Thu; 25 Apr 2013 08:31:04 +0000,Fri; 7 Jun 2013 19:59:04 +0000,Fri; 7 Jun 2013 19:59:04 +0000,,1.1.2;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5182
MAPREDUCE-5183,Bug,Minor,mrv1;tasktracker,In; TaskTracker#reportProgress logging of 0.0-1.0 progress is followed by percent sign,This makes looking at progress in the logs unnecessarily confusing.  It would probably look prettiest to keep the percentage sign and have the numbers between 0 and 100.,Resolved,Fixed,,Niranjan Singh,Sandy Ryza,Thu; 25 Apr 2013 21:15:14 +0000,Sun; 22 Mar 2015 08:13:16 +0000,Sat; 21 Mar 2015 21:33:35 +0000,,1.1.2,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5183
MAPREDUCE-5184,Sub-task,Major,documentation,Document MR Binary Compatibility vis-a-vis hadoop-1 and hadoop-2,nan,Closed,Fixed,,Zhijie Shen,Arun C Murthy,Fri; 26 Apr 2013 02:10:11 +0000,Tue; 27 Aug 2013 22:22:11 +0000,Sun; 16 Jun 2013 19:10:53 +0000,,,,,MAPREDUCE-5459,https://issues.apache.org/jira/browse/MAPREDUCE-5184
YARN-2275,Bug,Major,log-aggregation,When log aggregation not enabled; message should point to NM HTTP port; not IPC port ,"When I try to get a container's logs in the JHS without log aggregation enabled; I get a message that looks like this: ""Aggregation is not enabled. Try the nodemanager at sandy-ThinkPad-T530:33224""  This could be a lot more helpful by actually pointing the URL that would show the container logs on the NM.",Resolved,Won't Fix,YARN-239,Ray Chiang,Sandy Ryza,Fri; 26 Apr 2013 23:56:16 +0000,Thu; 17 Jul 2014 23:39:20 +0000,Thu; 17 Jul 2014 23:39:20 +0000,,2.0.4-alpha,usability,,,https://issues.apache.org/jira/browse/YARN-2275
MAPREDUCE-5186,Bug,Critical,job submission,mapreduce.job.max.split.locations causes some splits created by CombineFileInputFormat to fail,"CombineFileInputFormat can easily create splits that can come from many different locations (during the last pass of creating ""global"" splits). However; we observe that this often runs afoul of the mapreduce.job.max.split.locations check that's done by JobSplitWriter.  The default value for mapreduce.job.max.split.locations is 10; and with any decent size cluster; CombineFileInputFormat creates splits that are well above this limit.",Closed,Fixed,,Robert Parker,Sangjin Lee,Sat; 27 Apr 2013 00:28:13 +0000,Wed; 3 Sep 2014 23:35:25 +0000,Mon; 11 Nov 2013 19:30:30 +0000,,2.0.4-alpha;2.2.0,,,MAPREDUCE-1943;MAPREDUCE-4146,https://issues.apache.org/jira/browse/MAPREDUCE-5186
MAPREDUCE-5187,Bug,Major,mrv2,Create mapreduce command scripts on Windows,We don't have mapreduce command scripts; e.g. mapred.cmd; on Windows in trunk code base right now. As a result; some import functionality like Job history server is not available. This JIRA is created to track this issue.,Closed,Fixed,,Chuan Liu,Chuan Liu,Sat; 27 Apr 2013 01:27:30 +0000,Thu; 12 May 2016 18:23:01 +0000,Mon; 8 Jul 2013 20:32:54 +0000,,2.1.0-beta;3.0.0-alpha1,,,YARN-199,https://issues.apache.org/jira/browse/MAPREDUCE-5187
MAPREDUCE-5188,Bug,Critical,contrib/raid,error when verify FileType of RS_SOURCE in getCompanionBlocks  in BlockPlacementPolicyRaid.java,error when verify FileType of RS_SOURCE in getCompanionBlocks  in BlockPlacementPolicyRaid. need change xorParityLength in line #379 to rsParityLength since it's for verifying RS_SOURCE  type,Resolved,Won't Fix,,junjin,junjin,Sat; 27 Apr 2013 02:35:27 +0000,Tue; 1 Aug 2017 17:14:47 +0000,Tue; 1 Aug 2017 17:14:47 +0000,,2.0.2-alpha,BB2015-05-TBR;contrib/raid,,,https://issues.apache.org/jira/browse/MAPREDUCE-5188
MAPREDUCE-5189,Sub-task,Major,mr-am;mrv2,Basic AM changes to support preemption requests (per YARN-45),This JIRA tracks the minimum amount of changes necessary in the mapreduce AM to receive preemption requests (per YARN-45) and invoke a local policy that manages preemption. (advanced policies and mechanisms will be tracked separately),Resolved,Fixed,,Carlo Curino,Carlo Curino,Sat; 27 Apr 2013 02:57:22 +0000,Thu; 12 May 2016 18:22:30 +0000,Tue; 17 Dec 2013 22:53:58 +0000,,,,,MAPREDUCE-5176;YARN-567;YARN-568;YARN-569,https://issues.apache.org/jira/browse/MAPREDUCE-5189
MAPREDUCE-5190,Improvement,Minor,mrv2,Unnecessary condition test in RandomSampler,"In getSampe method; there is a condition test after ""int ind = r.nextInt(numSamples);"". The test is ""(ind != numSamples)"". This test is unneeded since nextInt(numSamples) will not return numSamples.",Resolved,Fixed,,Jingguo Yao,Jingguo Yao,Sat; 27 Apr 2013 14:06:55 +0000,Tue; 30 Aug 2016 01:20:36 +0000,Sun; 22 Mar 2015 04:35:39 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5190
MAPREDUCE-5191,Bug,Major,,TestQueue#testQueue fails with timeout on Windows,Test times out on my machine after 5 seconds always on the below stack:,Closed,Fixed,,Ivan Mitic,Ivan Mitic,Mon; 29 Apr 2013 04:43:37 +0000,Thu; 12 May 2016 18:24:31 +0000,Mon; 20 May 2013 20:02:33 +0000,,3.0.0-alpha1,,,MAPREDUCE-4401,https://issues.apache.org/jira/browse/MAPREDUCE-5191
MAPREDUCE-5192,Task,Minor,task,Separate TCE resolution from fetch,The EventFetcher thread grounds task completion events as URIs before passing them to the ShuffleScheduler. If the former deferred this to the scheduler; one could interpret the TCE metadata differently,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 30 Apr 2013 00:01:51 +0000,Tue; 27 Aug 2013 22:22:13 +0000,Sun; 16 Jun 2013 03:08:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5192
MAPREDUCE-5193,Bug,Major,test,A few MR tests use block sizes which are smaller than the default minimum block size,HDFS-4305 introduced a new configurable minimum block size of 1MB. A few MR tests deliberately set much smaller block sizes. This JIRA is to update those tests to fix these failing tests.,Closed,Fixed,,Andrew Wang,Aaron T. Myers,Tue; 30 Apr 2013 05:18:56 +0000,Tue; 27 Aug 2013 22:21:56 +0000,Thu; 2 May 2013 02:00:56 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5193
MAPREDUCE-5194,Task,Minor,task,Heed interrupts during Fetcher shutdown,In the current implementation; Fetcher instances usually exit gracefully when the shuffle succeeds. When it fails; threads are interrupted; but may continue running harmlessly until the JVM shuts down.  However; to generate consistent checkpoints; these threads should exit cleanly to quiesce the state of the shuffle.,Closed,Fixed,,Chris Douglas,Chris Douglas,Tue; 30 Apr 2013 11:05:55 +0000,Tue; 27 Aug 2013 22:21:59 +0000,Wed; 19 Jun 2013 02:14:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5194
MAPREDUCE-5195,Bug,Major,job submission,Job doesn't utilize all the available cluster resources with CombineFileInputFormat,If we enable delay scheduling in capacity scheduler and the submitted job is using CombineFileInputFormat then this job is not able to use the all the available resources in the cluster; running most of the maps in only some nodes and other nodes resources are idle.,Open,Unresolved,,Unassigned,Devaraj K,Tue; 30 Apr 2013 13:21:02 +0000,Tue; 30 Apr 2013 13:24:22 +0000,,,0.23.7;2.1.0-beta;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5195
MAPREDUCE-5196,Improvement,Major,mr-am;mrv2,CheckpointAMPreemptionPolicy implements preemption in MR AM via checkpointing ,This JIRA tracks a checkpoint-based AM preemption policy. The policy handles propagation of the preemption requests received from the RM to the appropriate tasks; and bookeeping of checkpoints. Actual checkpointing of the task state is handled in upcoming JIRAs.,Resolved,Fixed,,Carlo Curino,Carlo Curino,Tue; 30 Apr 2013 17:50:47 +0000,Fri; 13 Oct 2017 18:07:41 +0000,Sat; 28 Dec 2013 21:59:30 +0000,,,,,MAPREDUCE-5176;MAPREDUCE-5197,https://issues.apache.org/jira/browse/MAPREDUCE-5196
MAPREDUCE-5197,Improvement,Major,mrv2,Checkpoint Service: a library component to facilitate checkpoint of task state,A small library that abstract file API for the purpose of checkpointing.,Resolved,Fixed,,Carlo Curino,Carlo Curino,Tue; 30 Apr 2013 18:51:51 +0000,Thu; 12 May 2016 18:22:55 +0000,Tue; 17 Dec 2013 21:38:26 +0000,,,,,MAPREDUCE-5196,https://issues.apache.org/jira/browse/MAPREDUCE-5197
MAPREDUCE-5198,Bug,Major,tasktracker,Race condition in cleanup during task tracker renint with LinuxTaskController,This was noticed when job tracker would be restarted while jobs were running and would ask the task tracker to reinitialize.   Tasktracker would fail with an error like,Closed,Fixed,,Arpit Gupta,Arpit Gupta,Tue; 30 Apr 2013 22:22:33 +0000,Wed; 15 May 2013 05:15:55 +0000,Wed; 1 May 2013 01:52:17 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5198
MAPREDUCE-5199,Sub-task,Blocker,security,AppTokens file can/should be removed,All the required tokens are propagated to AMs and containers via startContainer(); no need for explicitly creating the app-token file that we have today..,Closed,Fixed,MAPREDUCE-4069,Daryn Sharp,Vinod Kumar Vavilapalli,Tue; 30 Apr 2013 22:38:46 +0000,Thu; 12 May 2016 18:22:38 +0000,Thu; 13 Jun 2013 20:22:01 +0000,,2.1.0-beta;3.0.0-alpha1,,,YARN-579;MAPREDUCE-5205,https://issues.apache.org/jira/browse/MAPREDUCE-5199
YARN-637,Bug,Major,scheduler,FS: maxAssign is not honored,maxAssign limits the number of containers that can be assigned in a single heartbeat. Currently; FS doesn't keep track of number of assigned containers to check this.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 30 Apr 2013 23:10:18 +0000,Mon; 3 Nov 2014 18:33:37 +0000,Thu; 9 May 2013 21:52:59 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/YARN-637
TEZ-95,Bug,Major,,MRPartitioner should get num partitions from TezTaskContext,Instead of relying on the MR configuration property. Currently; partitioning is broken since the MR API is used - which after key deprecation will end up returning the default value of 1.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Wed; 1 May 2013 06:52:37 +0000,Sun; 1 Dec 2013 20:21:26 +0000,Wed; 1 May 2013 07:03:49 +0000,,,TEZ-0.2.0;TEZ-1,,,https://issues.apache.org/jira/browse/TEZ-95
MAPREDUCE-5202,Bug,Major,,Revert MAPREDUCE-4397 to avoid using incorrect config files,MAPREDUCE-4397 added the capability to switch the location of the taskcontroller.cfg file; which weakens security.,Closed,Fixed,,Owen O'Malley,Owen O'Malley,Wed; 1 May 2013 16:33:48 +0000,Wed; 15 May 2013 05:16:01 +0000,Wed; 1 May 2013 17:50:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5202
MAPREDUCE-5203,Bug,Major,,Make AM of M/R Use NMClient,YARN-422 adds NMClient. AM of mapreduce should use it instead of using the raw ContainerManager proxy directly. ContainerLauncherImpl needs to be changed.,Patch Available,Unresolved,,Zhijie Shen,Zhijie Shen,Thu; 2 May 2013 00:13:52 +0000,Wed; 6 May 2015 03:34:27 +0000,,,,BB2015-05-TBR,,YARN-422,https://issues.apache.org/jira/browse/MAPREDUCE-5203
MAPREDUCE-5204,Bug,Major,,Handle YarnRemoteException separately from IOException in MR api ,YarnRemoteException is not rooted as IOException; so in MR api; we need to handle them separately from IOException,Closed,Fixed,,Xuan Gong,Xuan Gong,Thu; 2 May 2013 02:41:57 +0000,Tue; 27 Aug 2013 22:21:59 +0000,Mon; 6 May 2013 19:20:45 +0000,,,,,YARN-629,https://issues.apache.org/jira/browse/MAPREDUCE-5204
MAPREDUCE-5205,Bug,Blocker,,Apps fail in secure cluster setup,Found at YARN-579 by Daryn Sharp. Need to investigate if it was caused by YARN-579 itself or something else.  Secure setup on trunk passes though.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Tue; 30 Apr 2013 18:09:13 +0000,Tue; 27 Aug 2013 22:21:56 +0000,Sat; 4 May 2013 00:29:51 +0000,,,,,MAPREDUCE-5199,https://issues.apache.org/jira/browse/MAPREDUCE-5205
MAPREDUCE-5206,Bug,Minor,,JT can show the same job multiple times in Retired Jobs section,JT can show the same job multiple times in Retired Jobs section since the RetireJobs thread has a bug which adds the same job multiple times to collection of retired jobs.,Closed,Fixed,,Arun C Murthy,Arun C Murthy,Fri; 3 May 2013 07:22:35 +0000,Sun; 4 Aug 2013 08:23:28 +0000,Mon; 6 May 2013 14:46:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5206
MAPREDUCE-5207,Bug,Minor,,Add mapreduce.{map|reduce}.memory.mb defaults to mapred-default.xml,mapred-default.xml is missing defaults for mapredue. {map|reduce} .memory.mb,Resolved,Duplicate,NULL,Karthik Kambatla,Karthik Kambatla,Fri; 3 May 2013 16:07:09 +0000,Mon; 3 Nov 2014 18:33:56 +0000,Fri; 3 May 2013 17:01:36 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5207
MAPREDUCE-5208,Bug,Major,,SpillRecord and ShuffleHandler should use SecureIOUtils for reading index file and map output,ShuffleHandler (map output file) and SpillRecord (index file) are reading file using unsecured input stream. There exists a possibility for symlink attack. related to YARN-578 . Creating this issue to track map reduce changes.,Closed,Fixed,,Omkar Vinit Joshi,Omkar Vinit Joshi,Fri; 3 May 2013 18:16:27 +0000,Tue; 27 Aug 2013 22:22:21 +0000,Sun; 12 May 2013 22:00:10 +0000,,,,HADOOP-9511,YARN-578,https://issues.apache.org/jira/browse/MAPREDUCE-5208
MAPREDUCE-5209,Bug,Minor,mrv2,ShuffleScheduler log message incorrect,"In ShuffleScheduler. line 361 log message is incorrect; there should be ""ms"" instead of ""s"".      LOG.info(host + "" freed by "" + Thread.currentThread().getName() + "" in "" +               (System.currentTimeMillis()-shuffleStart.get()) + ""ms"");",Closed,Fixed,,Tsuyoshi Ozawa,Radim Kolar,Mon; 6 May 2013 02:57:22 +0000,Wed; 19 Mar 2014 18:35:27 +0000,Wed; 8 May 2013 21:13:13 +0000,,2.0.4-alpha,,,TEZ-952,https://issues.apache.org/jira/browse/MAPREDUCE-5209
MAPREDUCE-5210,Bug,Major,,Job submission has strict permission validation,The following code in JobSubmissionFiles. mandates strict permission on job submission :     For file systems such as S3; which do not have permission concept; user can never submit a job with staging area in S3.,Open,Unresolved,,samar,Amareshwari Sriramadasu,Mon; 6 May 2013 08:24:24 +0000,Thu; 9 May 2013 20:23:35 +0000,,,,,HADOOP-9554,,https://issues.apache.org/jira/browse/MAPREDUCE-5210
MAPREDUCE-5211,Bug,Blocker,mrv2,Reducer intermediate files can collide during merge,"The OnDiskMerger.merge method constructs an output path that is not unique to a reduce attempt; and as a result can result in a file collision with other reducers from the same app that are running on the same node.  In addition the name of the output file is based on MapOutput.toString which may not be unique in light of multi-pass merges on disk since the mapId will be null and the basename ends up as ""MapOutput(null; DISK)""",Resolved,Fixed,,Jason Lowe,Jason Lowe,Mon; 6 May 2013 18:32:19 +0000,Sun; 16 Jun 2013 12:25:54 +0000,Sun; 16 Jun 2013 12:25:54 +0000,,0.23.7,2.0.4.2,,,https://issues.apache.org/jira/browse/MAPREDUCE-5211
MAPREDUCE-5212,Bug,Major,,Handle exception related changes in YARN's ClientRMProtocol api after YARN-631,nan,Closed,Fixed,,Xuan Gong,Xuan Gong,Mon; 6 May 2013 21:43:37 +0000,Tue; 27 Aug 2013 22:22:14 +0000,Wed; 8 May 2013 22:56:02 +0000,,,,,YARN-631,https://issues.apache.org/jira/browse/MAPREDUCE-5212
MAPREDUCE-5213,Bug,Minor,,Re-assess TokenCache methods marked @Private,While looking at the source; noticed that TokenCache#loadTokens methods are marked @Private but not used anywhere.   We should either remove those methods or mark them Public or LimitedPrivate.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 7 May 2013 01:50:19 +0000,Mon; 3 Nov 2014 18:33:44 +0000,Wed; 24 Jul 2013 22:40:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5213
MAPREDUCE-5214,Sub-task,Major,,Compatibility: Add a deprecated MRAdmin that wraps around RMAdmin,MRAdmin doesn't apply to MR2. However; to maintain compatibility against 1.x releases; it might be a good idea to add a deprecated version of MRAdmin that wraps around RMAdmin; prints out a deprecated message and calls the relevant RMAdmin methods.,Resolved,Won't Fix,MAPREDUCE-5243,Karthik Kambatla,Karthik Kambatla,Tue; 7 May 2013 02:38:02 +0000,Mon; 3 Nov 2014 18:33:38 +0000,Mon; 13 May 2013 22:27:01 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5214
MAPREDUCE-5215,Sub-task,Blocker,mrv2,mapreduce.Job is missing getJobClient() so its incompatible with MR1,The method org.apache.hadoop.mapred.JobClient getJobClient() is in MR1's mapreduce.Job but doesn't exist in MR2's; which makes them incompatible.  MR2's implementation of Job doesn't use a JobClient object; but we can create one and return it.,Resolved,Won't Fix,,Robert Kanter,Robert Kanter,Tue; 7 May 2013 05:17:59 +0000,Wed; 27 Nov 2013 20:19:40 +0000,Wed; 27 Nov 2013 20:19:40 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5215
MAPREDUCE-5216,Bug,Major,,While using TextSplitter in DataDrivenDBInputformat; the lower limit (split start) always remains the same; for all splits.,While using TextSplitter in DataDrivenDBInputformat; the lower limit (split start) always remains the same; for all splits. ie;  Split 1 Start =A; End = M; Split 2 Start =A; End = P; Split 3 Start =A; End = S;  instead of Split 1 Start =A; End = M; Split 2 Start =M; End = P; Split 3 Start =P; End = S;,Patch Available,Unresolved,,Unassigned,Gelesh,Tue; 7 May 2013 13:40:17 +0000,Wed; 6 May 2015 03:35:05 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5216
MAPREDUCE-5217,Bug,Major,distcp;security,DistCp fails when launched by Oozie in a secure cluster,"As mentioned in MAPREDUCE-4324; Oozie has the following boilerplate code in in the main launcher for Pig; Hive; MR and Sqoop actions.  if (System.getenv(""HADOOP_TOKEN_FILE_LOCATION"") != null) {             jobConf.set(""mapreduce.job.credentials.binary""; System.getenv(""HADOOP_TOKEN_FILE_LOCATION"")); }  For Java action; which does not have a main launcher in oozie; the above codecan be added by the user as the user purportedly has the code that is launched.  But for DistCp action; the user has no such luxury.  The solution attempted in MAPREDUCE-4324 would have helped DistCp; but it was not implemented as it would break MAPREDUCE-3727.  So; we have to fix DistCp and add the same boilerplate code so that DistCp action can be launched by Oozie in a secure cluster.  The code added checks for an System env. variable to be set which is not typically set in normal command line execution of DistCp;  DistCp runs fine with commnad  line usage both in secure and non-secure cluster.",Resolved,Fixed,,Venkat Ranganathan,Venkat Ranganathan,Tue; 7 May 2013 14:10:05 +0000,Fri; 10 May 2013 22:02:55 +0000,Fri; 10 May 2013 22:02:55 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5217
MAPREDUCE-5218,Bug,Minor,,Annotate (comment) internal classes as Private,"The following classes are intended for internal use and it would be nice to explicitly state that in comments annotation.   	TaskUmbilicalProtocol 	TaskInProgress 	MapReducePolicyProvider 	MRAdmin?",Resolved,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 7 May 2013 18:52:13 +0000,Mon; 3 Nov 2014 18:33:33 +0000,Thu; 9 May 2013 21:23:11 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5218
MAPREDUCE-5219,Sub-task,Major,,JobStatus#getJobPriority changed to JobStatus#getPriority in MR2,We should change it back for compatibility,Resolved,Invalid,,Sandy Ryza,Sandy Ryza,Tue; 7 May 2013 19:04:54 +0000,Wed; 8 May 2013 22:55:57 +0000,Wed; 8 May 2013 22:55:57 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5219
MAPREDUCE-5220,Sub-task,Major,client,Mapred API: TaskCompletionEvent incompatibility issues with MR1,1. Setter methods in TaskCompletionEvent are public in MR1 and protected in MR2.  2. void setTaskID(TaskAttemptID) is missing.,Closed,Fixed,,Zhijie Shen,Sandy Ryza,Tue; 7 May 2013 21:06:14 +0000,Tue; 27 Aug 2013 22:22:05 +0000,Mon; 3 Jun 2013 21:35:56 +0000,,2.0.4-alpha,,,MAPREDUCE-5299,https://issues.apache.org/jira/browse/MAPREDUCE-5220
MAPREDUCE-5221,Bug,Major,,Reduce side Combiner is not used when using the new API,If a combiner is specified using o.a.h.mapreduce.Job.setCombinerClass - this will silently ignored on the reduce side since the reduce side usage is only aware of the old api combiner. This doesn't fail the job - since the new combiner key does not deprecate the old key.,In Progress,Unresolved,,Tsuyoshi Ozawa,Siddharth Seth,Tue; 7 May 2013 22:58:27 +0000,Tue; 28 Jun 2016 06:26:49 +0000,,,2.0.4-alpha,BB2015-05-TBR,MAPREDUCE-5294;MAPREDUCE-5295,,https://issues.apache.org/jira/browse/MAPREDUCE-5221
MAPREDUCE-5222,Sub-task,Major,,Fix JobClient incompatibilities with MR1,"JobClient is missing the following two public methods we need to add for binary compatibility:   	static isJobDirValid(Path; FileSystem) 	Path getStagingAreaDir()",Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Wed; 8 May 2013 00:13:40 +0000,Mon; 3 Nov 2014 18:34:08 +0000,Tue; 14 May 2013 05:53:07 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5222
MAPREDUCE-5223,Bug,Major,,ant package shouldn't build task-controller by default,ant package shouldn't build task-controller by default; not sure when we broke this. task-controller should have to be explicitly built via '-Dtask-controller' option.  This breaks tar creation on all non-Linux platforms. Sigh.,Open,Unresolved,,Unassigned,Arun C Murthy,Wed; 8 May 2013 08:26:47 +0000,Wed; 8 May 2013 16:49:03 +0000,,,,,,HADOOP-8921,https://issues.apache.org/jira/browse/MAPREDUCE-5223
MAPREDUCE-5224,Bug,Minor,jobtracker,JobTracker should allow the system directory to be in non-default FS,"JobTracker today expects the system directory to be in the default file system         if (fs == null) {           fs = mrOwner.doAs(new PrivilegedExceptionActionFileSystem() {             public FileSystem run() throws IOException {               return FileSystem.get(conf);           }});         }   ...    public String getSystemDir()  {     Path sysDir = new Path(conf.get(""mapred.system.dir""; "" system""));       return fs.makeQualified(sysDir).toString();   } In Cloud like Azure the default file system is set as ASV (Windows Azure Blob Storage); but we would still like the system directory to be in DFS. We should change JobTracker to allow that.",Resolved,Fixed,,Xi Fang,Xi Fang,Wed; 8 May 2013 18:42:18 +0000,Sun; 16 Jun 2013 04:18:02 +0000,Sun; 16 Jun 2013 04:17:45 +0000,,1-win,,,MAPREDUCE-5277,https://issues.apache.org/jira/browse/MAPREDUCE-5224
MAPREDUCE-5225,Bug,Major,,SplitSampler in mapreduce.lib should use a SPLIT_STEP to jump around splits,Now; SplitSampler only samples the first maxSplitsSampled splits; caused by MAPREDUCE-1820. However; jumping around all splits is in general preferable than the first N splits.,Patch Available,Unresolved,,Zhijie Shen,Zhijie Shen,Wed; 8 May 2013 21:12:52 +0000,Wed; 6 May 2015 03:34:34 +0000,,,,BB2015-05-TBR,,MAPREDUCE-5157;MAPREDUCE-1820,https://issues.apache.org/jira/browse/MAPREDUCE-5225
MAPREDUCE-5226,Bug,Major,,Handle exception related changes in YARN's AMRMProtocol api after YARN-630,nan,Closed,Fixed,,Xuan Gong,Xuan Gong,Wed; 8 May 2013 23:42:07 +0000,Tue; 27 Aug 2013 22:22:02 +0000,Thu; 9 May 2013 05:34:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5226
MAPREDUCE-5227,Improvement,Minor,mrv1,JobTrackerMetricsSource and QueueMetrics should standardize naming rules,"JobTrackerMetricsSource and QueueMetrics provides users with some metrics; but its naming rules( ""jobs_running""; ""running_maps""; ""running_reduces"") sometimes confuses users. It should be standardized.  One concern is backward compatibility; so one idea is to share MetricMutableGaugeInt object from old and new property name. e.g. to share runningMaps from ""running_maps"" and ""maps_running"".",Patch Available,Unresolved,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Thu; 9 May 2013 01:46:08 +0000,Wed; 6 May 2015 03:34:35 +0000,,,1.1.3;1.2.1,BB2015-05-TBR,,HADOOP-10045,https://issues.apache.org/jira/browse/MAPREDUCE-5227
MAPREDUCE-5228,Sub-task,Major,,Enum Counter is removed from FileInputFormat and FileOutputFormat of both mapred and mapreduce,The enum was used by findCounter(Enum key) to find a specific counter object. Now it seems to be replaced by FileInputFormatCounter and FileOutputFormatCounter. Now the enum seems to be only used internally; but not sure whether it will be used externally when users extend FileXXXXFormat.,Closed,Fixed,,Mayank Bansal,Zhijie Shen,Thu; 9 May 2013 20:03:00 +0000,Tue; 27 Aug 2013 22:22:21 +0000,Thu; 30 May 2013 23:59:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5228
MAPREDUCE-5229,Sub-task,Major,,TEMP_DIR_NAME is removed from of FileOutputCommitter of mapreduce,TEMP_DIR_NAME is removed from of FileOutputCommitter of mapreduce. As FileOutputFormat and FileOutputCommitter may be extend by users; and the extended user classes can configured to use. Therefore; this missing public static variable may cause compatibility problem when the extended classes refer it.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 9 May 2013 20:31:09 +0000,Tue; 27 Aug 2013 22:22:17 +0000,Sat; 1 Jun 2013 22:12:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5229
MAPREDUCE-5230,Sub-task,Major,,createFileSplit is removed from NLineInputFormat of mapred,createFileSplit is removed from NLineInputFormat of mapred; because it's no longer used in the new getSplit implementation. However; since function is protected before; there is still the potential risk that the user defined format class which extends old NLineInputFormat uses the protected function.,Closed,Fixed,,Mayank Bansal,Zhijie Shen,Thu; 9 May 2013 20:42:04 +0000,Tue; 27 Aug 2013 22:22:16 +0000,Fri; 24 May 2013 00:43:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5230
MAPREDUCE-5231,Sub-task,Major,,Constructor of DBInputFormat.DBRecordReader in mapred is changed,The constructor of DBInputFormat.DBRecordReader in mapred is changed from MR1 to RM2. Though MAPREDUCE-716 tried to deal with the API difference. However; if DBInputFormat.DBRecordReader is extended; the incompatibility around the constructor is still there.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 9 May 2013 20:55:03 +0000,Tue; 27 Aug 2013 22:22:04 +0000,Fri; 31 May 2013 23:58:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5231
MAPREDUCE-5232,Improvement,Major,mrv1;mrv2,log classpath and other key properties on child JVM start,It would be great if we log vital information such as classpath; etc. upon a mapreduce child JVM start. This would help a great deal in terms of troubleshooting classpath issues; etc. Today it is pretty difficult to debug this unless you preserve the container script.  Maybe it can log things like classpath; os name version;  version; etc. at the beginning of the child JVM start.,Resolved,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 9 May 2013 21:14:56 +0000,Tue; 30 Aug 2016 01:20:34 +0000,Tue; 14 May 2013 23:44:21 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5232
MAPREDUCE-5233,Sub-task,Major,,Functions are changed or removed from Job in jobcontrol,The functions are removed from Job in jobcontrol:  1. setMapredJobID(String) 2. setState(int)  The function signatures are changed:  1. addDependingJob(ControlledJob) 2. getMapredJobID(),Closed,Fixed,,Mayank Bansal,Zhijie Shen,Thu; 9 May 2013 21:40:06 +0000,Tue; 27 Aug 2013 22:22:09 +0000,Wed; 22 May 2013 23:13:58 +0000,,,,,MAPREDUCE-5372,https://issues.apache.org/jira/browse/MAPREDUCE-5233
MAPREDUCE-5234,Sub-task,Major,,Signature changes for getTaskId of TaskReport in mapred,TaskReport in mapred of MR2 extends TaskReport in mapreduce; and inherits getTaskId; which return TaskID object. in MR1; this function returns String.,Closed,Fixed,,Mayank Bansal,Zhijie Shen,Thu; 9 May 2013 21:59:37 +0000,Tue; 27 Aug 2013 22:22:00 +0000,Fri; 17 May 2013 18:18:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5234
MAPREDUCE-5235,Sub-task,Major,,mapred.Counters incompatiblity issues with MR1,MAX_GROUP_LIMIT is removed from Counters in mapred in MR2. Though it seems not to be the variable that will be referred by the user code. It was actually configurable value MR1. We should investigate why the upper bound doesn't need to be checked in MR2.,Closed,Fixed,,Mayank Bansal,Zhijie Shen,Thu; 9 May 2013 22:34:50 +0000,Tue; 27 Aug 2013 22:22:19 +0000,Tue; 21 May 2013 22:01:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5235
MAPREDUCE-5236,Bug,Major,,references to JobConf.DISABLE_MEMORY_LIMIT don't make sense in the context of MR2,In MR1; a special value of -1 could be given for mapreduce.job.map|reduce.memory.mb when memory limits were disabled.  In MR2; this makes no sense; as with slots gone; this value is used for requesting resources and scheduling.,Resolved,Duplicate,MAPREDUCE-5130,Sandy Ryza,Sandy Ryza,Thu; 9 May 2013 22:44:38 +0000,Thu; 16 May 2013 19:51:18 +0000,Thu; 16 May 2013 19:51:18 +0000,,2.0.4-alpha,,,MAPREDUCE-5130,https://issues.apache.org/jira/browse/MAPREDUCE-5236
MAPREDUCE-5237,Sub-task,Major,,ClusterStatus incompatiblity issues with MR1,The three functions are:  CollectionString getGraylistedTrackerNames() int getGraylistedTrackers() State getJobTrackerState()  The're tracker related; such that they are no longer used in MR2. Maybe we should add them and throw UnsupportedOperationException?  In addition; UNINITIALIZED_MEMORY_VALUE changes from long to int,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 9 May 2013 23:49:12 +0000,Tue; 27 Aug 2013 22:21:57 +0000,Wed; 29 May 2013 00:44:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5237
MAPREDUCE-5238,Bug,Major,test,TestDistCacheEmulation.testGenerateDistCacheData is failing in trunk,nan,Open,Unresolved,,Unassigned,Sandy Ryza,Fri; 10 May 2013 16:55:03 +0000,Fri; 10 May 2013 16:55:26 +0000,,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5238
MAPREDUCE-5239,Bug,Major,,Update MR App to reflect YarnRemoteException changes after YARN-634,YARN-634 is making YarnRemoteException to be not backed by PB anymore. Need some MR changes because of that. Tracking MR changes from the patch at YARN-634.,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Fri; 10 May 2013 17:54:12 +0000,Tue; 27 Aug 2013 22:22:20 +0000,Fri; 10 May 2013 21:52:48 +0000,,,,,YARN-634,https://issues.apache.org/jira/browse/MAPREDUCE-5239
MAPREDUCE-5240,Bug,Blocker,mrv2,inside of FileOutputCommitter the initialized Credentials cache appears to be empty,I am attaching a modified wordcount job that clearly demonstrates the problem we've encountered in running Sqoop2 on YARN (BIGTOP-949).  Here's what running it produces:     As you can see; even though we've clearly initialized the creds via:     It doesn't seem to appear later in the job.  This is a pretty critical issue for Sqoop 2 since it appears to be DOA for YARN in Hadoop 2.0.4-alpha,Closed,Fixed,,Vinod Kumar Vavilapalli,Roman Shaposhnik,Sun; 12 May 2013 03:15:16 +0000,Tue; 27 Aug 2013 22:22:09 +0000,Mon; 20 May 2013 20:53:43 +0000,,2.0.4-alpha,2.0.4.1,BIGTOP-949,,https://issues.apache.org/jira/browse/MAPREDUCE-5240
MAPREDUCE-5241,Bug,Major,contrib/fair-share,FairScheduler preeempts tasks from the pool whose fair share is below the mininum quota ,The code snippet below is from class FairScheduler.UpdateThread:     Suppose a pool A with the minimum shares of map slots set to 10. And a user submits a job with 5 maps to pool A and the 5 maps starts to run immediately. After update() in UpdateThread.run() is executed; pool A gets map shares of 5; and pool A has 5 running map tasks. Before preemptTasksIfNecessary() is called; a speculative map task could be started; and pool A has 6 running map tasks now; but still gets map shares of 5; so the new speculative map task could be preempted. For the number of running map tasks(6)is still less than the pool A's minimun shares(10); probably it is wrong to preempt any tasks from pool A. A possible fix is to make the call to update() and preemptTasksIfNecessary() atomic to eliminate the race condition; and the following is the first try:     Another possible fix is to call FairScheduler.update() in FairScheduler.assignTasks() to re-calculate the fairs share.  Any comments?,Open,Unresolved,,Unassigned,Angus He,Sun; 12 May 2013 03:47:12 +0000,Sun; 12 May 2013 03:47:12 +0000,,,0.20.2;0.21.0;0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5241
MAPREDUCE-5242,Improvement,Major,,Remove mapred-default.xml,Similar to YARN-673. (details there),Open,Unresolved,,Unassigned,Siddharth Seth,Mon; 13 May 2013 20:38:42 +0000,Mon; 13 May 2013 20:38:42 +0000,,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5242
MAPREDUCE-5243,Sub-task,Major,,MRAdmin is removed from M/R while RMAdmin is added to Yarn,Though in the 2.x mapred script; MRAdmin will not be called; MRAdmin class is better to be there in case users call it programmatically.,Closed,Duplicate,MAPREDUCE-5214,Zhijie Shen,Zhijie Shen,Mon; 13 May 2013 21:33:51 +0000,Tue; 27 Aug 2013 22:22:00 +0000,Mon; 13 May 2013 21:40:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5243
MAPREDUCE-5244,Sub-task,Major,,Two functions changed their visibility in JobStatus,Two functions change their visibility in JobStatus from public to protected:  void setRunState(int) void setSchedulingInfo(String),Closed,Fixed,,Zhijie Shen,Zhijie Shen,Mon; 13 May 2013 21:53:41 +0000,Tue; 27 Aug 2013 22:22:19 +0000,Tue; 14 May 2013 22:14:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5244
MAPREDUCE-5245,Sub-task,Major,,A number of public static variables are removed from JobConf,"A number of public static variables are removed from JobConf:  boolean DEFAULT_MAPREDUCE_RECOVER_JOB	  String MAPREDUCE_RECOVER_JOB	 	  String WORKFLOW_ADJACENCY_PREFIX_PATTERN	  String WORKFLOW_ADJACENCY_PREFIX_STRING	  String WORKFLOW_ID	  String WORKFLOW_NAME	  String WORKFLOW_NODE_NAME	  String WORKFLOW_TAGS  The workflow related variables are moved to MRJobConfig.  The follwing public static variables becomes default:  String MAPRED_JOB_MAP_MEMORY_MB_PROPERTY	  String MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY  The variables there are no longer referred internally in 2.x; but they might be used by users as they were public.",Closed,Fixed,,Zhijie Shen,Zhijie Shen,Mon; 13 May 2013 22:15:38 +0000,Tue; 27 Aug 2013 22:22:02 +0000,Mon; 3 Jun 2013 23:57:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5245
MAPREDUCE-5246,Improvement,Major,,Adding application type to submission context,Adding application type to submission context of map reduce YARN-563,Closed,Fixed,,Mayank Bansal,Mayank Bansal,Tue; 14 May 2013 09:01:18 +0000,Tue; 27 Aug 2013 22:22:04 +0000,Thu; 23 May 2013 18:03:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5246
MAPREDUCE-5247,Bug,Major,,FileInputFormat should filter files with '._COPYING_' sufix,"FsShell copy put completes staging files are moved).  As a workaround; we've defined a custom input path filter and loaded it with ""mapred.input.pathFilter.class"".",Resolved,Won't Fix,,Unassigned,Stan Rosenberg,Tue; 14 May 2013 15:36:14 +0000,Fri; 19 Jul 2013 16:59:58 +0000,Fri; 19 Jul 2013 15:02:57 +0000,,,,,HADOOP-9750,https://issues.apache.org/jira/browse/MAPREDUCE-5247
MAPREDUCE-5248,Improvement,Minor,client;test,Let NNBenchWithoutMR specify the replication factor for its test,The NNBenchWithoutMR test creates files with a replicationFactorPerFile hard-coded to 1. It'd be nice to be able to specify that on the commandline.  Also; it'd be great if MAPREDUCE-4750 was merged along with this fix.,Resolved,Fixed,,Erik Paulson,Erik Paulson,Tue; 14 May 2013 16:15:19 +0000,Tue; 30 Aug 2016 01:20:32 +0000,Fri; 8 May 2015 22:31:31 +0000,,3.0.0-alpha1,,,MAPREDUCE-4750,https://issues.apache.org/jira/browse/MAPREDUCE-5248
MAPREDUCE-5249,Bug,Major,jobtracker;security,Oozie delegation token renewal fails for MR tokens in branch-1,When Oozie  462)  Setting the renewer to Kerberos Local name does not help because AbstractDelegationTokenIdentifier sets the renewer to Kerberos shortname but JobTracker.renewDelegationToken uses the fullName. This essentially causes the renewal to fail,Resolved,Duplicate,MAPREDUCE-5375,Venkat Ranganathan,Venkat Ranganathan,Wed; 15 May 2013 05:36:17 +0000,Thu; 4 Jul 2013 22:58:51 +0000,Thu; 4 Jul 2013 22:55:26 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5249
MAPREDUCE-5250,Bug,Minor,,Searching for ';' in JobTracker History throws ArrayOutOfBoundException ,Searching for ';' in JobTracker History throws ArrayOutOfBoundException,Resolved,Fixed,,Karthik Kambatla,Karthik Kambatla,Wed; 15 May 2013 07:25:47 +0000,Mon; 3 Nov 2014 18:33:33 +0000,Mon; 3 Jun 2013 18:02:42 +0000,,1.2.0,history,,,https://issues.apache.org/jira/browse/MAPREDUCE-5250
MAPREDUCE-5251,Bug,Major,mrv2,Reducer should not implicate map attempt if it has insufficient space to fetch map output,A job can fail if a reducer happens to run on a node with insufficient space to hold a map attempt's output.  The reducer keeps reporting the map attempt as bad; and if the map attempt ends up being re-launched too many times before the reducer decides maybe it is the real problem the job can fail.  In that scenario it would be better to re-launch the reduce attempt and hopefully it will run on another node that has sufficient space to complete the shuffle.  Reporting the map attempt is bad and relaunching the map task doesn't change the fact that the reducer can't hold the output.,Closed,Fixed,MAPREDUCE-4852,Ashwin Shankar,Jason Lowe,Wed; 15 May 2013 13:50:49 +0000,Wed; 3 Sep 2014 23:52:31 +0000,Fri; 26 Jul 2013 17:59:13 +0000,,0.23.7;2.0.4-alpha,,,TEZ-952,https://issues.apache.org/jira/browse/MAPREDUCE-5251
MAPREDUCE-5252,Improvement,Minor,scheduler,Fair scheduler should use SchedulerUtils.normalizeRequest,The capacity scheduler and the fifo scheduler use the same normalizeRequest in SchedulerUtils.  The fair scheduler has its own version of this method that does exactly the same thing.  It should use the common one.,Resolved,Not A Problem,,Sandy Ryza,Sandy Ryza,Thu; 16 May 2013 00:09:10 +0000,Fri; 7 Jun 2013 17:52:41 +0000,Fri; 7 Jun 2013 17:52:41 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5252
MAPREDUCE-5253,Bug,Major,task,Whitespace value entry in mapred-site.xml for name=mapred.reduce.child.java.opts causes child tasks to fail at launch,Hi;  Below is a patch for Hadoop v1.1.2.  I'm new to this list; so if I need to write up a JIRA ticket for this; please let me know.  The defect scenario is that if you enter any white space within values in this file:      mapred-site.xml  e.g.: (a white space prior to the -X...)    property     namemapred.reduce.child. ptsSplit[i]); +      }      }         Path childTmpDir = createChildTmpDir(workDir; conf; false);,Open,Unresolved,,Unassigned,Karl D. Gierach,Thu; 16 May 2013 00:45:39 +0000,Thu; 16 May 2013 22:39:43 +0000,,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5253
MAPREDUCE-5254,Bug,Major,,Fix exception unwrapping and unit tests using UndeclaredThrowable,Follow up to YARN-628. Exception unwrapping for MRClientProtocol needs some work. Also; there's a bunch of MR tests still relying on UndeclaredThrowableException which should no longer be thrown.,Open,Unresolved,,Unassigned,Siddharth Seth,Thu; 16 May 2013 17:07:48 +0000,Thu; 1 Aug 2013 02:07:44 +0000,,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5254
MAPREDUCE-5255,Bug,Major,mrv2,Reduce task preemption  results in task never completing ; incomplete fix to MAPREDUCE-3858 ?,The problem was seen with symptoms very similar to MAPREDUCE-3858: the job is hung with continuous reduce task attempts; each attempt getting killed around commit phase.  After a while the single reduce task was the only one remaining in the job; with 50K 'kills' done for the task.  Relevant logs from application master:  (the problem task is: attempt_1368653326922_0080_r_001278_0    Afterwards; we see tasks repeatedly scheduled and killed with the following message:     another one...,Open,Unresolved,MAPREDUCE-5009,Unassigned,Rahul Jain,Fri; 17 May 2013 20:57:58 +0000,Wed; 27 May 2015 18:56:17 +0000,,,2.0.3-alpha,,,MAPREDUCE-3858;MAPREDUCE-5009,https://issues.apache.org/jira/browse/MAPREDUCE-5255
MAPREDUCE-5256,Bug,Major,,CombineInputFormat isn't thread safe affecting HiveServer,This was originally fixed as part of MAPREDUCE-5038; but that got reverted now. Which uncovers this issue; breaking HiveServer. Originally reported by Thejas M Nair.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 17 May 2013 22:08:18 +0000,Sun; 4 Aug 2013 08:23:27 +0000,Sat; 6 Jul 2013 23:21:48 +0000,,1.2.0,,,MAPREDUCE-5038,https://issues.apache.org/jira/browse/MAPREDUCE-5256
MAPREDUCE-5257,Bug,Major,mr-am;mrv2,TestContainerLauncherImpl fails,TestContainerLauncherImpl is hanging and eventually being killed by the surefire timeout which fails a maven test build.,Closed,Fixed,,Omkar Vinit Joshi,Jason Lowe,Fri; 17 May 2013 22:29:50 +0000,Tue; 27 Aug 2013 22:22:11 +0000,Sun; 19 May 2013 21:16:16 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5257
MAPREDUCE-5258,Bug,Major,,Memory Leak while using LocalJobRunner,Every-time a LocalJobRunner is launched it creates JobTrackerInstrumentation and QueueMetrics.  While creating this MetricsSystem ; it registers and adds a Callback to ArrayList which keeps on growing as the DefaultMetricsSystem is Singleton.,Patch Available,Unresolved,,skrho,Subroto Sanyal,Sun; 19 May 2013 01:02:46 +0000,Wed; 6 May 2015 03:26:17 +0000,,,1.1.2,BB2015-05-TBR;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-5258
MAPREDUCE-5259,Bug,Major,test,TestTaskLog fails on Windows because of path separators missmatch,Test failure:,Closed,Fixed,,Ivan Mitic,Ivan Mitic,Sun; 19 May 2013 20:08:33 +0000,Thu; 12 May 2016 18:24:07 +0000,Wed; 12 Jun 2013 19:07:19 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5259
MAPREDUCE-5260,Bug,Major,tasktracker,Job failed because of JvmManager running into inconsistent state,In our cluster; jobs failed due to randomly task initialization failed because of JvmManager running into inconsistent state and TaskTracker failed to exit:   251),Closed,Fixed,,yunjiong zhao,yunjiong zhao,Mon; 20 May 2013 05:43:32 +0000,Sun; 4 Aug 2013 08:23:26 +0000,Fri; 28 Jun 2013 20:55:49 +0000,,1.1.2,,,MAPREDUCE-1397,https://issues.apache.org/jira/browse/MAPREDUCE-5260
MAPREDUCE-5261,Bug,Major,mrv2,TestRMContainerAllocator is exiting and failing the build,Recent builds are failing because TestRMContainerAllocator is exiting rather than succeeding or failing.,Closed,Invalid,,Omkar Vinit Joshi,Jason Lowe,Mon; 20 May 2013 14:39:48 +0000,Tue; 27 Aug 2013 22:21:59 +0000,Thu; 30 May 2013 21:55:30 +0000,,2.1.0-beta,,,YARN-713,https://issues.apache.org/jira/browse/MAPREDUCE-5261
MAPREDUCE-5262,Bug,Major,applicationmaster,AM generates NPEs when RM connection fails,If the AM fails to connect to the RM; it causes a cascade of NPEs as the AM attempts to shutdown and exit.,Open,Unresolved,,Unassigned,Daryn Sharp,Tue; 21 May 2013 16:28:45 +0000,Thu; 12 May 2016 18:22:18 +0000,,,2.0.4-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5262
MAPREDUCE-5263,Sub-task,Major,,filecache.DistributedCache incompatiblity issues with MR1,A couple of methods and variables have been removed:  void addLocalArchives(Configuration; String) void addLocalFiles(Configuration; String) void createAllSymlink(Configuration; File; File) FileStatus getFileStatus(Configuration; URI) long getTimestamp(Configuration; URI) void setArchiveTimestamps(Configuration; String) void setFileTimestamps(Configuration; String) void setLocalArchives(Configuration; String) void setLocalFiles(Configuration; String)  String CACHE_ARCHIVES String CACHE_ARCHIVES_SIZES String CACHE_ARCHIVES_TIMESTAMPS String CACHE_FILES String CACHE_FILES_SIZES String CACHE_FILES_TIMESTAMPS String CACHE_LOCALARCHIVES String CACHE_LOCALFILES String CACHE_SYMLINK,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Tue; 21 May 2013 18:58:08 +0000,Tue; 27 Aug 2013 22:21:58 +0000,Mon; 3 Jun 2013 23:03:34 +0000,,,,,MAPREDUCE-5300;MAPREDUCE-5272,https://issues.apache.org/jira/browse/MAPREDUCE-5263
MAPREDUCE-5264,Bug,Major,,FileAlreadyExistsException is assumed to be thrown by FileSystem#mkdirs or FileContext#mkdir in the codebase,"According to https: HADOOP-9438; FileSystem#mkdirs and FileContext#mkdir do not throw FileAlreadyExistsException if the directory already exist.  Some places in the mapreduce codebase assumes FileSystem#mkdirs or FileContext#mkdir throw FileAlreadyExistsException. At least the following files are concerned:  	YarnChild.    It would be good to re-review and patch this if needed.",Patch Available,Unresolved,,Unassigned,R  my Saissy,Wed; 22 May 2013 09:46:15 +0000,Thu; 12 May 2016 18:24:04 +0000,,,2.1.0-beta;3.0.0-alpha1,BB2015-05-TBR,,HADOOP-9361,https://issues.apache.org/jira/browse/MAPREDUCE-5264
MAPREDUCE-5265,New Feature,Major,jobhistoryserver,History server admin service to refresh user and superuser group mappings,The history server needs an admin interface with the ability to 1. refresh the super user groups configurations; 2. refresh user to group mappings; 3. refresh its admin acls; 4. get groups given a username  without requiring a restart of the history server.  This is analogous to the  -refreshSuperUserGroupsConfiguration capabilities provided by hdfs dfsadmin and yarn rmadmin.,Closed,Fixed,,Ashwin Shankar,Jason Lowe,Wed; 22 May 2013 16:10:30 +0000,Wed; 3 Sep 2014 23:35:27 +0000,Thu; 18 Jul 2013 20:48:07 +0000,,2.1.0-beta,,,MAPREDUCE-5404,https://issues.apache.org/jira/browse/MAPREDUCE-5265
MAPREDUCE-5266,New Feature,Major,jobhistoryserver,Ability to refresh retention settings on history server,"It would be very useful if the job and log retention settings of the history server could be refreshed without restarting the history server.  This would include such things as:   	how many to jobs to keep for browsing 	how many jobs to cache 	how long to retain jobs 	how long to retain logs 	how often to check for retention",Closed,Fixed,,Ashwin Shankar,Jason Lowe,Wed; 22 May 2013 16:13:42 +0000,Wed; 3 Sep 2014 23:35:28 +0000,Mon; 29 Jul 2013 22:49:53 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5266
MAPREDUCE-5267,Improvement,Major,jobhistoryserver,History server should be more robust when cleaning old jobs,Ran across a situation where an admin user had accidentally created a directory in one of the date directories under  file being processed and move on to the next entry in the list rather than aborting the entire cleaning process.,Open,Unresolved,,Maysam Yabandeh,Jason Lowe,Wed; 22 May 2013 20:03:54 +0000,Sat; 7 Jan 2017 01:59:58 +0000,,,0.23.7;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5267
MAPREDUCE-5268,Improvement,Major,jobhistoryserver,Improve history server startup performance,The history server can easily take many minutes to startup when there are a significant number of jobs to scan in the done directory.  However the scanning of files is not the bottleneck; rather it's the heavy use of ConcurrentSkipListMap.size in HistoryFileManager.    ConcurrentSkipListMap.size is a very expensive operation; especially on maps with many entries; as it has to scan every entry to compute the size.  We should avoid calling this method or at least minimize its use.,Closed,Fixed,,Karthik Kambatla,Jason Lowe,Wed; 22 May 2013 20:12:12 +0000,Mon; 3 Nov 2014 18:05:37 +0000,Mon; 3 Jun 2013 14:53:18 +0000,,0.23.7;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5268
MAPREDUCE-5269,Improvement,Major,mrv2,Preemption of Reducer (and Shuffle) via checkpointing,This patch tracks the changes in the task runtime (shuffle; reducer context; etc.) that are required to implement checkpoint-based preemption of reducer tasks.,Patch Available,Unresolved,,Carlo Curino,Carlo Curino,Wed; 22 May 2013 21:52:45 +0000,Wed; 22 Feb 2017 23:59:03 +0000,,,,BB2015-05-TBR,,MAPREDUCE-6849,https://issues.apache.org/jira/browse/MAPREDUCE-5269
MAPREDUCE-5270,Bug,Major,,Migrate from using BuilderUtil factory methods to individual record factory method on MapReduce side,Migrate the factory method on map reduce side.,Closed,Fixed,,Jian He,Jian He,Thu; 23 May 2013 21:49:48 +0000,Tue; 27 Aug 2013 22:22:01 +0000,Sat; 25 May 2013 01:49:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5270
MAPREDUCE-5271,Bug,Major,jobtracker,Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in InMemoryMerger - Thread to merge in-memory shuffled map-outputs,(hadoop-2.0.0-cdh4.2.0)I encounter following question when do a simple words-count working.small input data is ok;there is problem when using big datas: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in InMemoryMerger - Thread to merge in-memory shuffled map-outputs          org.apache.hadoop.mapreduce.task.reduce.MergeThread.run(MergeThread. 94),Open,Unresolved,,lijuanhzou,lijuanhzou,Fri; 24 May 2013 06:56:48 +0000,Fri; 24 May 2013 13:30:30 +0000,,,2.0.0-alpha,hadoop,,,https://issues.apache.org/jira/browse/MAPREDUCE-5271
MAPREDUCE-5272,Bug,Trivial,test,A Minor Error in Javadoc of TestMRWithDistributedCache in Branch-1,It should be org.apache.hadoop.filecache.DistributedCache instead. Branch-1 doesn't have org.apache.hadoop.mapreduce.filecache.DistributedCache,Resolved,Fixed,,Zhijie Shen,Zhijie Shen,Fri; 24 May 2013 20:53:26 +0000,Tue; 17 Mar 2015 05:15:18 +0000,Tue; 17 Mar 2015 05:15:18 +0000,,,,,MAPREDUCE-5263,https://issues.apache.org/jira/browse/MAPREDUCE-5272
MAPREDUCE-5273,Sub-task,Major,,Protected variables are removed from CombineFileRecordReader in both mapred and mapreduce,"Two protected variables are removed from CombineFileRecordReader in both mapred and mapreduce:  	FileSystem fs 	ClassRecordReaderK; V&gt; rrClass",Closed,Fixed,,Mayank Bansal,Zhijie Shen,Fri; 24 May 2013 21:31:07 +0000,Tue; 27 Aug 2013 22:21:58 +0000,Sat; 1 Jun 2013 00:34:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5273
MAPREDUCE-5274,Sub-task,Major,,Mapreduce API: String toHex(byte[]) is removed from SecureShuffleUtils,String toHex(byte[]) is removed from SecureShuffleUtils in mapreduce after upgrading to M R 2,Closed,Fixed,,Mayank Bansal,Zhijie Shen,Fri; 24 May 2013 22:19:45 +0000,Tue; 27 Aug 2013 22:22:08 +0000,Sat; 1 Jun 2013 22:22:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5274
MAPREDUCE-5275,Sub-task,Major,,Mapreduce API: TokenCache incompatibility issues with MR1,"There're following incompatibility issues:  	TokenDelegationTokenIdentifier getDelegationToken(Credentials; String) is removed 	Credentials loadTokens(String; Configuration) changes to Credentials loadTokens(String; JobConf)",Closed,Fixed,,Mayank Bansal,Zhijie Shen,Fri; 24 May 2013 22:39:57 +0000,Tue; 27 Aug 2013 22:22:06 +0000,Sat; 15 Jun 2013 00:08:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5275
MAPREDUCE-5276,Bug,Minor,jobhistoryserver,johistory.jsp hangs when a directory under ./done is empty,WARN from jobtracker.log  013-05-22 17:07:36;240 WARN org.apache.hadoop.mapred.JobHistory: JobHistory: existingDoneSubdirs doesn't contain file: 000623; but should.  the jobhistory page stops; which causes a empty page. The jobhistory.jsp should go over this WARN and proceed.,Open,Unresolved,,Unassigned,Alexander Alten-Lorenz,Mon; 27 May 2013 07:10:03 +0000,Mon; 27 May 2013 07:10:03 +0000,,,0.23.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5276
MAPREDUCE-5277,Bug,Major,jobhistoryserver,Job history completed location cannot be on a file system other than default,mapred.job.tracker.history.completed.location should be configurable to a location on any available file system. This can come handy for cases where HDFS is not the only file system in use.,Resolved,Duplicate,MAPREDUCE-2351,Ivan Mitic,Ivan Mitic,Mon; 27 May 2013 22:30:32 +0000,Tue; 4 Jun 2013 02:33:08 +0000,Tue; 4 Jun 2013 02:33:08 +0000,,1-win,,,MAPREDUCE-5224,https://issues.apache.org/jira/browse/MAPREDUCE-5277
MAPREDUCE-5278,Bug,Major,distributed-cache,Distributed cache is broken when JT staging dir is not on the default FS,"Today; the JobTracker staging dir (""mapreduce.jobtracker.staging.root.dir) is set to point to HDFS; even though other file systems (e.g. Amazon S3 file system and Windows ASV file system) are the default file systems.  For ASV; this config was chosen and there are a few reasons why:  1. To prevent leak of the storage account credentials to the user's storage account;  2. It uses HDFS for the transient job files what is good for two reasons   a) it does not flood the user's storage account with irrelevant data Pig jars throughout the cluster.",Resolved,Fixed,,Xi Fang,Xi Fang,Tue; 28 May 2013 06:15:27 +0000,Tue; 9 Jul 2013 19:40:20 +0000,Tue; 9 Jul 2013 18:56:39 +0000,,1-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5278
MAPREDUCE-5279,Bug,Critical,mrv2;scheduler,Jobs can deadlock if headroom is limited by cpu instead of memory,YARN-2 imported cpu dimension scheduling; but MR RMContainerAllocator doesn't take into account virtual cores while scheduling reduce tasks. This may cause more reduce tasks to be scheduled because memory is enough. And on a small cluster; this will end with deadlock; all running containers are reduce tasks but map phase is not finished.,Closed,Fixed,,Peng Zhang,Peng Zhang,Tue; 28 May 2013 08:13:25 +0000,Mon; 1 Dec 2014 03:09:30 +0000,Mon; 22 Sep 2014 17:47:26 +0000,,2.0.3-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5279
MAPREDUCE-5280,Sub-task,Major,,Mapreduce API: ClusterMetrics incompatibility issues with MR1,1. Constructor has one fewer parameters: numGraylistedTrackers 2. getGrayListedTaskTrackerCount() is removed,Closed,Fixed,,Mayank Bansal,Zhijie Shen,Wed; 29 May 2013 17:55:09 +0000,Tue; 27 Aug 2013 22:22:08 +0000,Sat; 1 Jun 2013 03:59:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5280
MAPREDUCE-5281,Sub-task,Major,,Mapreduce API: Counter changes from non-abstract class to interface,"Therefore; significant changes in Counter:  1. Two Constructors are removed; 2. Following methods are removed:  	boolean equals(Object) 	int hashCode() 	void readFields(DataInput) 	void write(DataOutput)    Fix of this issue may break 0.23.",Resolved,Won't Fix,,Zhijie Shen,Zhijie Shen,Wed; 29 May 2013 18:30:40 +0000,Mon; 3 Jun 2013 22:44:48 +0000,Mon; 3 Jun 2013 22:44:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5281
MAPREDUCE-5282,Bug,Major,,Update MR App to use immutable ApplicationID after YARN-716,nan,Closed,Fixed,,Siddharth Seth,Vinod Kumar Vavilapalli,Wed; 29 May 2013 23:23:24 +0000,Tue; 27 Aug 2013 22:22:12 +0000,Thu; 30 May 2013 20:20:52 +0000,,,,,YARN-716,https://issues.apache.org/jira/browse/MAPREDUCE-5282
MAPREDUCE-5283,Improvement,Major,applicationmaster;test,Over 10 different tests have near identical implementations of AppContext,I'm trying to add a method to AppContext for MAPREDUCE-5171; and I have to go into nearly every test file for MR web services to make sure their TestAppContext implements it.  I propose having a common implementation of AppContext that all these tests can use.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 29 May 2013 23:33:57 +0000,Tue; 27 Aug 2013 22:22:05 +0000,Tue; 4 Jun 2013 01:55:49 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5283
MAPREDUCE-5284,Sub-task,Major,,Mapreduce API: CounterGroup changes from non-abstract class to interface,Therefore; constructors and implemented methods are removed.,Resolved,Won't Fix,,Zhijie Shen,Zhijie Shen,Thu; 30 May 2013 05:02:11 +0000,Mon; 3 Jun 2013 22:45:48 +0000,Mon; 3 Jun 2013 22:45:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5284
MAPREDUCE-5285,Bug,Major,,Update MR App to use immutable ApplicationAttemptID; ContainerID; NodeID after YARN-735,nan,Closed,Fixed,,Unassigned,Jian He,Fri; 31 May 2013 00:27:53 +0000,Tue; 27 Aug 2013 22:22:08 +0000,Sat; 1 Jun 2013 00:17:26 +0000,,,,,YARN-735,https://issues.apache.org/jira/browse/MAPREDUCE-5285
MAPREDUCE-5286,Task,Major,,startContainer call should use the ContainerToken instead of Container [YARN-684],MapReduce counterpart of YARN-684.,Closed,Fixed,,Vinod Kumar Vavilapalli,Siddharth Seth,Fri; 31 May 2013 04:04:12 +0000,Tue; 27 Aug 2013 22:22:21 +0000,Fri; 31 May 2013 04:20:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5286
MAPREDUCE-5287,Improvement,Minor,mrv1;performance,Create a generic InputFormat wrapping any other InputFormat; to control the number of map tasks,I wrote a generic InputFormat that wraps any other InputFormat; and creates CompositeInputSplits to reduce the number of map tasks in a controllable manner while preserving data locality. A correspondent CompositeRecordReader is written to iterate through underlying RecordReaders as created by the underlying InputFormat for each underlying raw split.  An application to this is to group TableSplits when the raw splits are coming from multiple regions and are filtered with key ranges. We use this to shard distribute a time based incremental access to an hbase table.,In Progress,Unresolved,,nicu marasoiu,nicu marasoiu,Fri; 31 May 2013 12:11:27 +0000,Thu; 13 Jun 2013 11:50:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5287
MAPREDUCE-5288,Bug,Major,mrv1,ResourceEstimator#getEstimatedTotalMapOutputSize suffers from divide by zero issues,The computation in the above mentioned class-method is below:     Given http: Math.html#round(double); its possible that the returned estimate could be Long.MAX_VALUE if completedMapsInputSize is determined to be zero.  This can be proven with a simple code snippet:     The above conveniently prints out: 9223372036854775807; which is Long.MAX_VALUE (or 8 Exbibytes per MapReduce).,Resolved,Fixed,,Karthik Kambatla,Harsh J,Sat; 1 Jun 2013 15:40:59 +0000,Mon; 3 Nov 2014 18:05:40 +0000,Wed; 24 Jul 2013 22:26:45 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5288
MAPREDUCE-5289,Bug,Major,,Update MR App to use Token directly after YARN-717,Ticket for tracking MR changes after YARN-717.,Closed,Fixed,,Jian He,Vinod Kumar Vavilapalli,Sat; 1 Jun 2013 21:03:48 +0000,Tue; 27 Aug 2013 22:22:14 +0000,Sat; 1 Jun 2013 21:46:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5289
YARN-751,Bug,Major,capacityscheduler,CLONE - CapacityScheduler incorrectly utilizes extra-resources of queue for high-memory jobs,Imagine; we have a queue A with capacity 10 slots and 20 as extra-capacity; jobs which use 3 map slots will never consume more than 9 slots; regardless how many free slots on a cluster.,Closed,Invalid,,Arun C Murthy,Sergey Tryuber,Mon; 3 Jun 2013 01:05:07 +0000,Tue; 27 Aug 2013 22:15:34 +0000,Mon; 3 Jun 2013 03:28:36 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/YARN-751
MAPREDUCE-5291,Bug,Major,,Change MR App to use update property names in container-log4j.properties,nan,Closed,Fixed,,Zhijie Shen,Siddharth Seth,Mon; 3 Jun 2013 02:31:17 +0000,Tue; 27 Aug 2013 22:22:13 +0000,Mon; 3 Jun 2013 02:37:50 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5291
MAPREDUCE-5292,Bug,Blocker,mrv2,ShuffleConsumerPlugin.Context should support org.apache.hadoop.mapreduce.Reducer,ShuffleConsumerPlugin.Context only supports org.apache.hadoop.mapred.Reducer currently. Because of this; Reduce side Combiner is not used when using the new API; and just ignored. Please see MAPREDUCE-5221 for more detail.,Resolved,Duplicate,MAPREDUCE-5294,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 3 Jun 2013 08:47:19 +0000,Tue; 10 Mar 2015 04:30:11 +0000,Mon; 3 Jun 2013 09:01:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5292
MAPREDUCE-5293,Bug,Blocker,mrv2,Shuffle#MergeManager should support org.apache.hadoop.mapreduce.Reducer,Shuffle#MergeManager only accepts org.apache.hadoop.mapred.Reducer currently. Because of this; Reduce-side Combiner is not used when using the new API; and just ignored. By supporting it and using the feature from ReduceTask; Reduce-side combiner can be enabled with new API. Please see MAPREDUCE-5221 for more detail.,Resolved,Duplicate,MAPREDUCE-5294,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 3 Jun 2013 08:52:52 +0000,Tue; 10 Mar 2015 04:30:11 +0000,Mon; 3 Jun 2013 09:04:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5293
MAPREDUCE-5294,Sub-task,Major,mrv2,Shuffle#MergeManager should support org.apache.hadoop.mapreduce.Reducer,Shuffle#MergeManager only accepts org.apache.hadoop.mapred.Reducer currently. Because of this; Reduce-side Combiner is not used when using the new API; and just ignored. By supporting it and using the feature from ReduceTask; Reduce-side combiner can be enabled with new API. Please see MAPREDUCE-5221 for more detail.,Resolved,Duplicate,MAPREDUCE-5221,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 3 Jun 2013 08:56:29 +0000,Tue; 10 Mar 2015 04:30:12 +0000,Tue; 9 Jul 2013 05:51:42 +0000,,2.1.0-beta;2.0.5-alpha,,MAPREDUCE-5295;MAPREDUCE-5221,,https://issues.apache.org/jira/browse/MAPREDUCE-5294
MAPREDUCE-5295,Sub-task,Major,,ShuffleConsumerPlugin.Context should remove unused combiner-related methods and fields,ShuffleConsumerPlugin.Context only supports org.apache.hadoop.mapred.Reducer currently. Because of this; Reduce side Combiner is not used when using the new API; and just ignored. Please see MAPREDUCE-5221 for more detail.  (Update Jun. 7th;  2013)  The latest version of MergeManagerImpl in MAPREDUCE-5294 never calls ShuffleConsumerPlugin.Context#getCombinerClass() as Mariappan Asokan pointed out. Because of this; combinerClass field and getCombinerClass() method should be removed from ShuffleConsumerPlugin.Context.,Resolved,Duplicate,MAPREDUCE-5221,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Mon; 3 Jun 2013 08:57:37 +0000,Tue; 10 Mar 2015 04:30:13 +0000,Tue; 9 Jul 2013 05:51:58 +0000,,2.1.0-beta;2.0.5-alpha,,MAPREDUCE-5221;MAPREDUCE-5294,,https://issues.apache.org/jira/browse/MAPREDUCE-5295
MAPREDUCE-5296,Sub-task,Major,,Mapred API: Function signature change in JobControl,String addJob(Job) - String addJob(ControlledJob),Closed,Fixed,,Zhijie Shen,Zhijie Shen,Mon; 3 Jun 2013 17:30:59 +0000,Tue; 27 Aug 2013 22:22:10 +0000,Mon; 3 Jun 2013 22:55:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5296
MAPREDUCE-5297,Bug,Major,,Update MR App  since BuilderUtils is moved to yarn-server-common after YARN-748,nan,Closed,Fixed,,Jian He,Jian He,Mon; 3 Jun 2013 19:01:45 +0000,Tue; 27 Aug 2013 22:21:58 +0000,Tue; 4 Jun 2013 00:58:20 +0000,,,,,YARN-748,https://issues.apache.org/jira/browse/MAPREDUCE-5297
MAPREDUCE-5298,New Feature,Major,applicationmaster,Move MapReduce services to YARN-117 stricter lifecycle,The MR services need to be in sync with the YARN-117 lifecycle enhancements,Closed,Fixed,,Steve Loughran,Steve Loughran,Mon; 3 Jun 2013 21:00:24 +0000,Tue; 27 Aug 2013 22:22:05 +0000,Thu; 13 Jun 2013 16:01:10 +0000,,2.0.4-alpha,,,YARN-117,https://issues.apache.org/jira/browse/MAPREDUCE-5298
MAPREDUCE-5299,Sub-task,Major,,Mapred API: void setTaskID(TaskAttemptID) is missing in TaskCompletionEvent ,Move the add-on patch of MAPREDUCE-5220 here.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Mon; 3 Jun 2013 22:59:07 +0000,Tue; 27 Aug 2013 22:22:20 +0000,Mon; 3 Jun 2013 23:46:07 +0000,,,,,MAPREDUCE-5220,https://issues.apache.org/jira/browse/MAPREDUCE-5299
MAPREDUCE-5300,Sub-task,Major,,Two function signature changes in filecache.DistributedCache,"Two more incompatibility issues:   	long[] getArchiveTimestamps(Configuration) - String[] getArchiveTimestamps(Configuration) 	long[] getFileTimestamps(Configuration) - String[] getFileTimestamps(Configuration)    Changes will break 0.23  Move the add-on patch of MAPREDUCE-5263 here.",Closed,Fixed,,Zhijie Shen,Zhijie Shen,Mon; 3 Jun 2013 23:07:19 +0000,Tue; 27 Aug 2013 22:22:06 +0000,Mon; 3 Jun 2013 23:48:28 +0000,,,,,MAPREDUCE-5263,https://issues.apache.org/jira/browse/MAPREDUCE-5300
MAPREDUCE-5301,Bug,Major,,Update MR code to work with YARN-635 changes,nan,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 4 Jun 2013 02:47:34 +0000,Tue; 27 Aug 2013 22:22:19 +0000,Tue; 4 Jun 2013 04:52:25 +0000,,,,YARN-635,,https://issues.apache.org/jira/browse/MAPREDUCE-5301
YARN-760,Bug,Major,nodemanager,NodeManager throws AvroRuntimeException on failed start,NodeManager wraps exceptions that occur in its start method in AvroRuntimeExceptions; even though it doesn't use Avro anywhere else.,Closed,Fixed,,Niranjan Singh,Sandy Ryza,Tue; 4 Jun 2013 04:43:44 +0000,Tue; 27 Aug 2013 22:15:16 +0000,Fri; 7 Jun 2013 16:27:06 +0000,,2.0.4-alpha,newbie,,,https://issues.apache.org/jira/browse/YARN-760
MAPREDUCE-5303,Bug,Major,,Changes on MR after moving ProtoBase to package impl.pb on YARN-724,nan,Closed,Fixed,,Jian He,Jian He,Tue; 4 Jun 2013 22:00:11 +0000,Tue; 27 Aug 2013 22:22:19 +0000,Tue; 4 Jun 2013 22:50:05 +0000,,,,,YARN-724,https://issues.apache.org/jira/browse/MAPREDUCE-5303
MAPREDUCE-5304,Sub-task,Blocker,,mapreduce.Job killTask/failTask/getTaskCompletionEvents methods have incompatible signature changes,Pointed out by Zhijie Shen in MAPREDUCE-4942.  In o.a.h.mapreduce.Job class; the following changed from Hadoop 1 to Hadoop 2.  boolean failTask(TaskAttemptID): Change in return type from void to boolean. boolean killTask(TaskAttemptID): Change in return type from void to boolean. TaskCompletionEvent[] getTaskCompletionEvents(int): Change in return type from org.apache.hadoop.mapred.TaskCompletionEvent[] to org.apache.hadoop.mapreduce.TaskCompletionEvent[].   Using same rational as in other JIRAs; we should fix this to ensure Hadoop 1 to Hadoop 2 source compatibility (taking 0.23.x releases as a casualty as there is not right way for everybody because we screwed up  ). Flagging it as incompatible change because of 0.23.,Closed,Fixed,,Karthik Kambatla,Alejandro Abdelnur,Wed; 5 Jun 2013 18:23:06 +0000,Mon; 3 Nov 2014 18:05:39 +0000,Wed; 12 Jun 2013 18:52:47 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5304
YARN-765,Bug,Minor,api,AggregatedLogDeletionService may delete recent stuff if its clock is out of sync,The AggregatedLogDeletionService compares file time with current time before deciding whether to delete things. If the clock on the system is sufficiently wrong; it may overreact.  If this is felt to be an issue; the fix would be for it to create a file on the DFS; stat it; and work out out the offset.,Open,Unresolved,,Unassigned,Steve Loughran,Wed; 5 Jun 2013 21:02:36 +0000,Thu; 12 May 2016 18:29:01 +0000,,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-765
MAPREDUCE-5306,Bug,Minor,,HistoryFileManager.mkdir() doesn't handle case where dest path exists -and is a file,The HistoryFileManager.mkdir() code handles the path existing simply by logging that the dir exists; and returning for everything else to work.  There's a big assumption there: that the path resolves to a directory. A check needs to be made that this assumption is valid -throwing some IOE subclass if it's just a file,Patch Available,Unresolved,,Gergely Nov  k,Steve Loughran,Wed; 5 Jun 2013 22:00:29 +0000,Tue; 10 May 2016 16:28:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5306
MAPREDUCE-5307,Bug,Major,mr-am;mrv2,Failure to launch a task attempt leads to missing failed attempt,When the AM tries to connect to a node to launch a task tempt_1368637921738_2222198_m_000396_2.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 6 Jun 2013 16:19:33 +0000,Thu; 6 Jun 2013 16:20:05 +0000,,,0.23.7;2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5307
MAPREDUCE-5308,Bug,Major,,Shuffling to memory can get out-of-sync when fetching multiple compressed map outputs,"When a reducer is fetching multiple compressed map outputs from a host; the fetcher can get out-of-sync with the IFileInputStream; causing several of the maps to fail to fetch.  This occurs because decompressors can return all the decompressed bytes before actually processing all the bytes in the compressed stream (due to checksums or other trailing data that we ignore). In the unfortunate case where these extra bytes cross an io.file.buffer.size boundary; some extra bytes will be left over and the next map_output will not fetch correctly (usually due to an invalid map_id).  This scenario is not typically fatal to a job because the failure is charged to the map_output immediately following the ""bad"" one and the subsequent retry will normally work.",Closed,Fixed,,Nathan Roberts,Nathan Roberts,Thu; 6 Jun 2013 21:46:55 +0000,Tue; 10 Mar 2015 04:30:36 +0000,Mon; 10 Jun 2013 21:48:23 +0000,,2.0.3-alpha;0.23.8,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5308
MAPREDUCE-5309,Bug,Major,jobhistoryserver;mrv2,2.0.4 JobHistoryParser can't parse certain failed job history files generated by 2.0.3 history server,"When the 2.0.4 JobHistoryParser tries to parse a job history file generated by hadoop 2.0.3; the jobhistoryparser throws as an error as   io.IOException; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FileSystem; import org.apache.hadoop.fs.Path; import org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser; import org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo; import org.junit.Test; import org.apache.hadoop.yarn.YarnException;  public class Test20JobHistoryParsing {    @Test   public void testFileAvro() throws IOException   {       Path local_path2 = new Path("" MAPREDUCE-4693 that added counters to the historyserver  for failed tasks.  This breaks backward compatibility with JobHistoryServer.",Closed,Fixed,,Rushabh S Shah,Vrushali C,Fri; 7 Jun 2013 17:44:16 +0000,Wed; 3 Sep 2014 20:33:51 +0000,Tue; 20 May 2014 15:52:30 +0000,,2.0.4-alpha,,,MAPREDUCE-4693,https://issues.apache.org/jira/browse/MAPREDUCE-5309
MAPREDUCE-5310,Bug,Major,applicationmaster,MRAM should not normalize allocation request capabilities,The MRAM is assuming knowledge of the scheduler internals to normalize allocation request capabilities.  Per discussions in YARN-689 and YARN-769 it should not do that.,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 7 Jun 2013 19:41:05 +0000,Tue; 27 Aug 2013 22:22:08 +0000,Fri; 14 Jun 2013 19:12:27 +0000,,2.0.4-alpha,,YARN-787,YARN-689;YARN-787;YARN-788;MAPREDUCE-5311;YARN-789,https://issues.apache.org/jira/browse/MAPREDUCE-5310
MAPREDUCE-5311,Bug,Blocker,applicationmaster,Remove SLOTS_MILLIS counters,Per discussion in MAPREDUCE-5310 and comments in the code we should remove all the related logic and just leave the counter constant for backwards compatibility and deprecate the counter constants.,Closed,Won't Fix,,Sandy Ryza,Alejandro Abdelnur,Fri; 7 Jun 2013 22:55:25 +0000,Tue; 27 Aug 2013 22:22:02 +0000,Thu; 15 Aug 2013 22:06:59 +0000,,2.0.4-alpha,,,TEZ-244;YARN-787;MAPREDUCE-5310,https://issues.apache.org/jira/browse/MAPREDUCE-5311
MAPREDUCE-5312,Bug,Major,,TestRMNMInfo is failing,2 test methods are failing:,Closed,Fixed,,Sandy Ryza,Alejandro Abdelnur,Sat; 8 Jun 2013 02:44:00 +0000,Thu; 12 May 2016 18:24:13 +0000,Sat; 8 Jun 2013 19:47:18 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5312
MAPREDUCE-5313,Bug,Major,jobtracker,JobTracker Creates Empty Mapper Task; and a Mapper Task with 2 FileSplits.,"When reading an input text file; the Job Tracker seems to assign the first two FileSplits to a single Mapper Task; then assigns an EMPTY FileSplit (end of file) to a Mapper Task; which finishes instantaneously. This can affect job balance; since one map job is now twice as big as the others.  In ""src LineRecordReader. ; line 110; there is a comment about skipping the first line of the input file by default; since ""next()"" reads two lines anyway. This was not the behavior in 0.20.2; which did not have this problem.  Seems perhaps related to :  ""HADOOP-4010. Change semantics for LineRecordReader to read an additional     line per split- rather than moving back one character in the stream- to     work with splittable compression codecs. (Abdul Qadeer via cdouglas)""  It seems this was not implemented properly and is leading to the issue described above in the situation that the input file is text.",Open,Unresolved,,Unassigned,Noel C. F. Codella; Ph.D.,Sun; 9 Jun 2013 07:07:16 +0000,Sun; 9 Jun 2013 07:13:08 +0000,,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5313
TEZ-197,Bug,Major,,Fix build break by YARN-686 (flatten node report),nan,Closed,Fixed,,Bikas Saha,Bikas Saha,Mon; 10 Jun 2013 00:32:35 +0000,Sun; 1 Dec 2013 20:21:50 +0000,Mon; 10 Jun 2013 00:36:01 +0000,,,TEZ-0.2.0,,,https://issues.apache.org/jira/browse/TEZ-197
MAPREDUCE-5315,Bug,Critical,distcp,DistCp reports success even on failure.,DistCp doesn't check the job-status when run in blocking-mode; before returning its exit-code. (The Yahoo-internal version did this correctly.)  In blocking-mode; DistCp must check that the launched job runs to completion; and return an appropriate exit-code.  Pretty serious bug; since it affects data integrity; in Oozie-launched-DistCp actions.  (I could've sworn I had another JIRA with this patch attached.),Closed,Fixed,,Mithun Radhakrishnan,Mithun Radhakrishnan,Mon; 10 Jun 2013 21:19:56 +0000,Tue; 27 Aug 2013 22:22:20 +0000,Tue; 11 Jun 2013 19:36:45 +0000,,0.23.1;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5315
MAPREDUCE-5316,Bug,Major,client,job -list-attempt-ids command does not handle illegal task-state,Courtesy : Phil Suh  job -list-attempt-ids command should handle illegal argument for task-state the same way as task-type.  Right now only illegal task-type is handle by an exception being thrown. Illegal task-state on the other hand does not throw exception. For example is a user mistype 'completed' as 'complete'; they may wrongly think there are no completed tasks; instead of being notified of the illegal task-state that was used.  1) illegal task-type handled.  philips@gwbl2003:4095 ~ mapred job -list-attempt-ids job_1345673924741_0086 map completed   WARN conf.Configuration: mapred.used.genericoptionsparser is deprecated. Instead; use mapreduce.client.genericoptionsparser.used Also;we could make input task-state to be case-insensitive to be consistent with task-type behavior(MAPREDUCE-4019).,Closed,Fixed,,Ashwin Shankar,Ashwin Shankar,Mon; 10 Jun 2013 22:27:39 +0000,Thu; 12 May 2016 18:22:47 +0000,Tue; 18 Jun 2013 20:40:31 +0000,,2.0.4-alpha;0.23.8;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5316
MAPREDUCE-5317,Bug,Major,mrv2,Stale files left behind for failed jobs,Courtesy Amar Kamat!  We are seeing _temporary files left behind in the output folder if the job fails. The job were failed due to hitting quota issue. I simply ran the randomwriter (from hadoop examples) with the default setting. That failed and left behind some stray files.,Closed,Fixed,,Ravi Prakash,Ravi Prakash,Mon; 10 Jun 2013 22:54:25 +0000,Thu; 12 May 2016 18:22:49 +0000,Tue; 23 Jul 2013 17:01:58 +0000,,2.0.4-alpha;0.23.8;3.0.0-alpha1,,,TEZ-263;MAPREDUCE-5746,https://issues.apache.org/jira/browse/MAPREDUCE-5317
MAPREDUCE-5318,Bug,Minor,jobtracker,Ampersand in JSPUtil.java is not escaped,"The malformed urls cause hue crash. The malformed urls are caused by the unescaped ampersand """".",Closed,Fixed,,Bohou Li,Bohou Li,Mon; 10 Jun 2013 23:09:20 +0000,Sun; 4 Aug 2013 08:23:28 +0000,Fri; 28 Jun 2013 21:38:00 +0000,,1.1.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5318
MAPREDUCE-5319,Bug,Major,,Job.xml file does not has 'user.name' property for Hadoop2,"Run a sleep job and look for job.xml file generated by sleep job.   It does not contain ""user.name"" property.",Closed,Fixed,,Xuan Gong,Yesha Vora,Thu; 6 Jun 2013 20:44:21 +0000,Tue; 27 Aug 2013 22:22:13 +0000,Fri; 14 Jun 2013 06:28:04 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5319
MAPREDUCE-5320,Bug,Major,,Cluster.close() is not called by mapreduce.Job,For MapReduce jobs run through mapreduce.Job.waitForCompletion(); Cluster.close() never seems to get called.  I noticed this problem in my own customized MapReduce environment; which uses a custom ClientProtocolProvider.  My provider creates ClientProtocol instances that contain resources that need to be cleaned up; such as thread pools.  Cluster.close() calls ClientProtocolProvider.close(ClientProtocol); which should clean up these resources.  Cluster.close() is called by mapred.JobClient code and by the CLI; but it doesn't seem to get called for jobs started through mapred.Job.waitForCompletion().  This leads to resource leaks in my application.  This seems like a bug; since mapreduce.Job creates a resource (the Cluster instance) that it never cleans up.,Open,Unresolved,,Chris Douglas,Josh Rosen,Tue; 11 Jun 2013 04:52:25 +0000,Tue; 11 Jun 2013 04:52:25 +0000,,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5320
YARN-809,Improvement,Major,,Enable better parallelism in the Fair Scheduler,Currently; the Fair Scheduler is locked on pretty much every operation; node updates; application additions and removals; every time the update thread runs; and every time the RM queries it for information.  Most of this locking is unnecessary; especially as only the core scheduling operations like application additions; removals; and node updates need a consistent view of scheduler state.  We can probably increase parallelism by using concurrent data structures when applicable; as well as keeping a slightly stale view to serve via the RM APIs.,Open,Unresolved,,Unassigned,Sandy Ryza,Thu; 13 Jun 2013 19:17:54 +0000,Mon; 9 Jan 2017 23:44:24 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-809
YARN-817,Bug,Minor,resourcemanager,If input path does not exist application/job id is getting assigned.,1.Run job by giving input as some path which does not exist 2.Application app id input path check can be made.,Resolved,Invalid,,Unassigned,Nishan Shetty,Fri; 14 Jun 2013 02:58:53 +0000,Mon; 11 May 2015 11:06:23 +0000,Mon; 11 May 2015 11:06:23 +0000,,2.0.2-alpha;2.0.1-alpha,,,,https://issues.apache.org/jira/browse/YARN-817
MAPREDUCE-5323,Bug,Minor,task,Min Spills For Combine Ignored,We've observed for some time that combiners always run when specified. However there is a config called mapreduce.map.combine.minspills which sort of implies that the developer or administrator ought to be able to control when combiners are invoked.  I spelunked into the code and found this gem in MapTask.   if (combinerRunner == null || numSpills  minSpillsForCombine)  { Merger.writeFile(kvIter; writer; reporter; job); }  else  { combineCollector.setWriter(writer); combinerRunner.combine(kvIter; combineCollector); }  That looks way buggy to me. If ( A || B ) is made false by A then B is never executed. I spelunked around the code some more and it looks like combinerRunner is never null except on reflection failure. So it looks like the intention is for minSpillsForCombine to be respected; but due to this logic error it's totally ignored.,Resolved,Not A Problem,,Unassigned,Jeff Bean,Fri; 14 Jun 2013 21:53:46 +0000,Fri; 14 Jun 2013 23:43:08 +0000,Fri; 14 Jun 2013 23:43:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5323
MAPREDUCE-5324,Bug,Minor,,Admin-provided user environment can be overridden by user provided values for the AM,MRJobConfig.MR_AM_ADMIN_USER_ENV can be overridden by MRJobConfig.MR_AM_ENV.  Either the variable should be renamed to something along the lines of DEFAULT_ENV or the code fixed to have the correct overrides. Current documentation clearly states user env overrides admin env.,Open,Unresolved,,Unassigned,Hitesh Shah,Fri; 14 Jun 2013 22:03:17 +0000,Fri; 14 Jun 2013 22:03:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5324
MAPREDUCE-5325,Bug,Major,,ClientRMProtocol.getAllApplications should accept ApplicationType as a parameter---MR changes,nan,Closed,Fixed,,Xuan Gong,Xuan Gong,Sat; 15 Jun 2013 02:08:47 +0000,Tue; 27 Aug 2013 22:22:21 +0000,Tue; 9 Jul 2013 23:11:36 +0000,,,,,YARN-727,https://issues.apache.org/jira/browse/MAPREDUCE-5325
MAPREDUCE-5326,Bug,Blocker,,Add version to shuffle header,We need to add a version to the shuffle header to allow for forward-compatibility etc.,Closed,Fixed,,Zhijie Shen,Arun C Murthy,Sun; 16 Jun 2013 14:22:12 +0000,Tue; 27 Aug 2013 22:22:18 +0000,Wed; 26 Jun 2013 05:50:53 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5326
MAPREDUCE-5327,Bug,Critical,,TestMRJobs and TestUberAM fail at verifying counters,"See the test report in YARN-829 and YARN-830:  	https:     The failure seems to be related to:     in TestMRJobs.",Resolved,Invalid,,Alejandro Abdelnur,Zhijie Shen,Sun; 16 Jun 2013 18:09:03 +0000,Sun; 16 Jun 2013 22:02:44 +0000,Sun; 16 Jun 2013 22:02:44 +0000,,,,,YARN-829;HADOOP-9649,https://issues.apache.org/jira/browse/MAPREDUCE-5327
MAPREDUCE-5328,Bug,Major,,ClientToken should not be set in the environment,This is to track Map Reduce related changes. related to YARN-610,Closed,Fixed,,Omkar Vinit Joshi,Omkar Vinit Joshi,Mon; 17 Jun 2013 05:37:14 +0000,Tue; 27 Aug 2013 22:22:04 +0000,Sat; 29 Jun 2013 00:59:42 +0000,,,,,YARN-610,https://issues.apache.org/jira/browse/MAPREDUCE-5328
MAPREDUCE-5329,Bug,Major,mr-am,APPLICATION_INIT is never sent to AuxServices other than the builtin ShuffleHandler,"APPLICATION_INIT is never sent to AuxServices other than the built-in ShuffleHandler.  This means that 3rd party ShuffleProvider(s) will not be able to function; because APPLICATION_INIT enables the AuxiliaryService to map jobId-userId. This is needed for properly finding the MOFs of a job per reducers' requests.  NOTE: The built-in ShuffleHandler does get APPLICATION_INIT events due to hard-coded expression in hadoop code. The current TaskAttemptImpl. similar to the fix in: MAPREDUCE-2668  ""APPLICATION_STOP is never sent to AuxServices"".  This means that in case the 'handle' method gets APPLICATION_INIT event it will demultiplex it to all Aux Services regardless of the value in event.getServiceID().  I prefer the 2nd solution.  I am welcoming any ideas.  I can provide the needed patch for any option that people like.  See Pluggable Shuffle in Hadoop documentation",Closed,Fixed,,Avner BenHanoch,Avner BenHanoch,Thu; 13 Jun 2013 14:37:38 +0000,Tue; 10 Mar 2015 04:30:39 +0000,Sun; 13 Oct 2013 20:20:47 +0000,,2.1.0-beta;2.0.6-alpha,,,MAPREDUCE-4049;YARN-841;YARN-886;MAPREDUCE-2668,https://issues.apache.org/jira/browse/MAPREDUCE-5329
MAPREDUCE-5330,Bug,Major,,JVM manager should not forcefully kill the process on Signal.TERM on Windows,In MapReduce; we sometimes kill a task's JVM before it naturally shuts down if we want to launch other tasks (look in JvmManager$JvmManagerForType.reapJvm). This behavior means that if the map task process is in the middle of doing some cleanup Reduce task is done and during closing file systems in a special shutdown hook; we're typically uploading storage (ASV in our context) usage metrics to Microsoft Azure Tables. So if this kill happens these metrics get lost. The impact is that for many MR jobs we don't see accurate metrics reported most of the time.,Resolved,Fixed,,Xi Fang,Xi Fang,Tue; 18 Jun 2013 22:48:45 +0000,Sun; 14 Jul 2013 17:21:04 +0000,Tue; 2 Jul 2013 20:36:59 +0000,,1-win,,,HADOOP-9677,https://issues.apache.org/jira/browse/MAPREDUCE-5330
MAPREDUCE-5331,Bug,Major,,hadoop pipes not working on Windows,Hadoop pipes does not work Windows right now. I debugged this a little when investigating the unit test TestPipeApplication failure on Windows.  Hadoop pipes use TaskLog.buildCommandLine() to construct a command line for running the task JVM. The command line from this method does not work on Windows.  After changing this method to get a working command line; the next error I got was an EOF IO exception in Application.waitForAuthentication(). I haven't got the chance to root cause the exception.  This JIRA is created to track the issue.,Open,Unresolved,,Unassigned,Chuan Liu,Wed; 19 Jun 2013 01:43:35 +0000,Wed; 19 Jun 2013 01:44:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5331
MAPREDUCE-5332,New Feature,Major,jobhistoryserver,Support token-preserving restart of history server,To better support rolling upgrades through a cluster; the history server needs the ability to restart without losing track of delegation tokens.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 19 Jun 2013 13:15:53 +0000,Wed; 3 Sep 2014 23:35:27 +0000,Fri; 27 Sep 2013 18:26:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5332
MAPREDUCE-5333,Test,Major,mr-am,Add test that verifies MRAM works correctly when sending requests with non-normalized capabilities,This is a follow on MAPREDUCE-5310 to ensure nothing broke after we removed normalization on the MRAM side.,Closed,Fixed,,Wei Yan,Alejandro Abdelnur,Wed; 19 Jun 2013 18:03:39 +0000,Tue; 27 Aug 2013 22:22:02 +0000,Fri; 28 Jun 2013 19:03:49 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5333
MAPREDUCE-5334,Bug,Blocker,,TestContainerLauncherImpl is failing,Broken by YARN-694; but Jenkins didn't report it.,Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Wed; 19 Jun 2013 19:16:22 +0000,Tue; 27 Aug 2013 22:22:05 +0000,Thu; 20 Jun 2013 00:37:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5334
MAPREDUCE-5335,Improvement,Major,applicationmaster,Rename Job Tracker terminology in ShuffleSchedulerImpl,nan,Closed,Fixed,,Devaraj K,Devaraj K,Thu; 20 Jun 2013 10:40:15 +0000,Fri; 10 Apr 2015 20:19:40 +0000,Thu; 12 Feb 2015 11:11:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5335
MAPREDUCE-5336,Bug,Major,,JobHistory UI shows -ve times for reducer,Attached screenshot,Open,Unresolved,,Xuan Gong,Bikas Saha,Thu; 20 Jun 2013 07:47:42 +0000,Thu; 20 Jun 2013 21:39:32 +0000,,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5336
YARN-865,Improvement,Major,,RM webservices can't query based on application Types,The resource manager web service api to get the list of apps doesn't have a query parameter for appTypes.,Closed,Fixed,YARN-990,Xuan Gong,Xuan Gong,Thu; 20 Jun 2013 17:59:18 +0000,Wed; 28 Aug 2013 21:42:10 +0000,Wed; 17 Jul 2013 21:45:53 +0000,,,,,YARN-727,https://issues.apache.org/jira/browse/YARN-865
MAPREDUCE-5338,Improvement,Major,,Bring back mapred.child.ulimit,In MR1; a ulimit could be set for MapReduce child processes.  For parity; this would be good to have in MR2 as well.,Open,Unresolved,,Naren Koneru,Sandy Ryza,Fri; 21 Jun 2013 23:46:58 +0000,Wed; 12 Mar 2014 18:31:49 +0000,,,2.0.5-alpha,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5338
MAPREDUCE-5339,Bug,Major,documentation,There are methods and capabilities in Job and other Classes for which no information is provided in Javadoc.,http: Job.html  The uber capability is not defined. isUber does not indicate wh important?  Does getAllQeues return root queues + child queues? This question is not well answered.    Cluster also keeps blacklisted Task Trackers. There is no info or reference in the  oc for JobACL or security.authorize.AccessControlList.,Open,Unresolved,MAPREDUCE-5340,Unassigned,Pranay Varma,Sat; 22 Jun 2013 21:56:36 +0000,Sun; 23 Jun 2013 04:35:35 +0000,,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5339
MAPREDUCE-5340,Bug,Major,documentation,isRetired is not well defined. javadoc does not indicate how a job is retired and waht does retired mean.,http: Job.html#isRetired%28%29  There is no description of what is retired and how a job is retired.,Resolved,Duplicate,MAPREDUCE-5339,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:01:31 +0000,Sun; 23 Jun 2013 00:39:45 +0000,Sun; 23 Jun 2013 00:39:29 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5340
MAPREDUCE-5341,Bug,Major,documentation,All constructors for Job are deprecated. There is no indication of what the alternative is.,http: fields to indicate whether an alternative exists or not and if the alternative exists; what is the alternative.,Resolved,Duplicate,MAPREDUCE-5597,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:09:21 +0000,Tue; 18 Mar 2014 19:26:39 +0000,Tue; 18 Mar 2014 19:26:39 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5341
MAPREDUCE-5342,Bug,Major,jobtracker,There are methods that should be deprecated and new methods should be added with names matching purposes,"ClusterStatus class has the following methods that need to be deprecated and new methods added: getMapTasks does not return map tasks; it returns the number of map tasks.   	getBlacklistedTrackers - getNumBlacklistedTrackers 	getMapTasks - getNumMapTasks 	getReduceTasks - getNumReduceTasks 	getTaskTrackers - getNumTaskTrackers    Cluster class needs the following change: There is a ClusterStatus class. When getClusterStatus is called; one would expect ClusterStatus to be returned. Instead; one gets ClusterMetrics.    	getClusterStatus - getClusterMetrics    Job class has the following methods that need to be deprecated and new methods added to match the purposes:  mapProgress suggests that the method is going to map progress and is misleading because; in fact; the method provides progress information about map tasks. It should be deprecated and a method should be added with a name that matches the purpose: getMapTasksProgress or getMapProgress.   	mapProgress - getMapProgress 	reduceProgress - getReduceProgress 	cleanupProgress - getCleanupProgress    JobStatus:   	getQueue - getQueueName    JobClient:  	getAllJobs - getJobStatuses",Open,Unresolved,MAPREDUCE-5343;MAPREDUCE-5344;MAPREDUCE-5345;MAPREDUCE-5347,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:18:46 +0000,Sun; 23 Jun 2013 06:00:20 +0000,,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5342
MAPREDUCE-5343,Bug,Major,jobtracker,reduceProgress is misleading. It should be renamed getReduceTasksProgress,reduceProgress suggests that the method is going to reduce progress and is misleading because; in fact; the method provides progress information about reduce tasks. It should be renamed to match what it does: getReduceTasksProgress.,Resolved,Duplicate,MAPREDUCE-5342,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:21:12 +0000,Sun; 23 Jun 2013 00:35:33 +0000,Sun; 23 Jun 2013 00:35:03 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5343
MAPREDUCE-5344,Bug,Major,mrv2,getClusterStatus method in Cluster returns ClusterMetrics. It should be called getClusterMetrics or it should return ClusterStatus.,There is a ClusterStatus class. When getClusterStatus is called; one would expect ClusterStatus to be returned. Instead; one gets ClusterMetrics.,Resolved,Duplicate,MAPREDUCE-5342,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:34:15 +0000,Sun; 23 Jun 2013 05:45:43 +0000,Sun; 23 Jun 2013 00:55:51 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5344
MAPREDUCE-5345,Bug,Major,documentation,cleanupProgress is misleading. It should be renamed getCleanupTasksProgress ,cleanupProgress suggests that Progress should be cleaned up. In reality; the user is getting the progress of the cleanup tasks. It should be renamed getCleanupTasksProgress.,Resolved,Duplicate,MAPREDUCE-5342,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:41:39 +0000,Sun; 23 Jun 2013 00:36:05 +0000,Sun; 23 Jun 2013 00:34:05 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5345
MAPREDUCE-5346,Bug,Minor,documentation,The example provided in the javadoc for Job is outdated.,This is a portion of the job example:  Here is an example on how to submit a job:             Create a new Job          Job job = new Job(new Configuration());  This way of creating a job is deprecated. The user is supposed to use Job.getInstance. The example should be changed to reflect the new paradigm.,Resolved,Duplicate,MAPREDUCE-5597,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:44:32 +0000,Thu; 27 Mar 2014 02:14:51 +0000,Thu; 27 Mar 2014 02:14:34 +0000,,2.1.0-beta;2.0.5-alpha,newbie,,MAPREDUCE-5800,https://issues.apache.org/jira/browse/MAPREDUCE-5346
MAPREDUCE-5347,Bug,Major,contrib/streaming;documentation,getBlacklistedTrackers() should be deprecated and a new method called  getNumBlacklistedTrackers should be added. ,"If the method returns a number; then that is what the method name should reflect. It should be called getNumBlacklistedTrackers(). The method does not return trackers; it returns number of trackers.  The same applies to the following:  	getMapTasks; getReduceTasks; getTaskTrackers    These should be deprecated and a new method should be added: getNumxxx.",Resolved,Duplicate,MAPREDUCE-5342,Unassigned,Pranay Varma,Sat; 22 Jun 2013 22:48:25 +0000,Sun; 23 Jun 2013 00:54:37 +0000,Sun; 23 Jun 2013 00:54:12 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5347
MAPREDUCE-5348,Bug,Major,,There are innconsistencies and duplication in the design of Cluster and other classes.,Cluster seems to keep TaskTracker information using class TaskTrackerInfo[]. getTaskTrackers returns TaskTrackerInfo[]. Ideally; I would like it to simply return TaskTracker[] or else have the method be called getTaskTrackerInfos.  A user would expect JobTracker information as well. For consistency; I would expect a getJobTracker method to return JobTrackerInfo or JobTracker. This method is not available; instead I see getJobTrackerStatus which returns JobTrackerStatus.  Although Cluster has TaskTracker and JobTracker; it uses QueueInfo instead of JobQueueInfo; which leaves one wondering what other kinds of queues are there. There is no documentation.  Not clear why Scheduling info is a totally unstructured string. Perhaps some information should be structured and the class should contain some String member to keep the unstructured information for extensibility.  JobStatus has information that is duplicated by calls in Job. This will lead to a wrapping function every time a method is added to JobStatus. I think it should be clearly decided as to what belongs in Job and what belongs in JobStatus. Let the users then get the information from JobStatus that is unique to JobStatus.  In some cases Job History is obtained as getHistoryFile while; in other cases; it is obtained as getHistoryUrl. There is consistency required in naming.,Open,Unresolved,,Unassigned,Pranay Varma,Sun; 23 Jun 2013 02:17:39 +0000,Sun; 23 Jun 2013 03:24:39 +0000,,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5348
MAPREDUCE-5349,Bug,Minor,,TestClusterMapReduceTestCase and TestJobName fail on Windows in branch-2,The two unit tests fails due to MiniMRCluster use test class fullname in branch-2; instead of simple name as in trunk; to construct the MiniMRCluster identifier. Full name in the identifier almost always leads to a command script path with length larger than 260 characters which will generate an exception DefaultContainerExecutor.launchContainer() when launching the container script.  The exception looks like the follows:,Closed,Fixed,,Chuan Liu,Chuan Liu,Mon; 24 Jun 2013 17:29:30 +0000,Tue; 27 Aug 2013 22:22:18 +0000,Sun; 30 Jun 2013 17:34:46 +0000,,2.1.0-beta,,,MAPREDUCE-5083,https://issues.apache.org/jira/browse/MAPREDUCE-5349
YARN-883,Improvement,Major,scheduler,Expose Fair Scheduler-specific queue metrics,When the Fair Scheduler is enabled; QueueMetrics should include fair share; minimum share; and maximum share.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Mon; 24 Jun 2013 21:58:11 +0000,Tue; 27 Aug 2013 22:15:17 +0000,Fri; 28 Jun 2013 19:02:12 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/YARN-883
MAPREDUCE-5351,Bug,Critical,jobtracker,JobTracker memory leak caused by CleanupQueue reopening FileSystem,When a job is completed; closeAllForUGI is called to close all the cached FileSystems in the FileSystem cache.  However; the CleanupQueue may run after this occurs and call FileSystem.get() to delete the staging directory; adding a FileSystem to the cache that will never be closed.  People on the user-list have reported this causing their JobTrackers to OOME every two weeks.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 25 Jun 2013 00:11:47 +0000,Tue; 8 Apr 2014 07:15:18 +0000,Sun; 7 Jul 2013 05:19:06 +0000,,1.1.2,,,MAPREDUCE-5508,https://issues.apache.org/jira/browse/MAPREDUCE-5351
MAPREDUCE-5352,Improvement,Major,,Optimize node local splits generated by CombineFileInputFormat ,CombineFileInputFormat currently walks through all available nodes and generates multiple (maxSplitsPerNode) splits on a single node before attempting to generate splits on subsequent nodes. This ends up reducing the possibility of generating splits for subsequent nodes - since these blocks will no longer be available for subsequent nodes. Allowing splits to go 1 block above the max-split-size makes this worse. Allocating a single split per node in one iteration; should help increase the distribution of splits across nodes - so the subsequent nodes will have more blocks to choose from.,Closed,Fixed,,Siddharth Seth,Siddharth Seth,Tue; 25 Jun 2013 04:46:49 +0000,Tue; 27 Aug 2013 22:22:03 +0000,Thu; 1 Aug 2013 17:48:37 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5352
MAPREDUCE-5353,Bug,Major,,Job end notification callback not sent on Application Master initialization failure,Job notification callback is not sent if the initialization of AM fails. This makes sense as the the AM is responsible for callbacks; and in case of AM init failure there is no way to send that callback. This would also be the case when AM fails for reasons such as OOM etc.  A few possible solutions have been discussed. Here is a link to the discussion on the mailing list http: f8suV1M6SFN,Open,Unresolved,,Unassigned,Prashant Kommireddi,Tue; 25 Jun 2013 06:10:01 +0000,Tue; 25 Jun 2013 06:10:01 +0000,,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5353
MAPREDUCE-5354,Bug,Major,,some job submission fail when one of the configured local disks on jt is read only,Following exception is seen in the jt,Open,Unresolved,,Unassigned,Arpit Gupta,Tue; 25 Jun 2013 23:47:28 +0000,Tue; 25 Jun 2013 23:49:31 +0000,,,1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5354
MAPREDUCE-5355,Bug,Minor,,MiniMRYarnCluster with localFs does not work on Windows,"When MiniMRYarnCluster configured to run on localFs instead of remoteFs; i.e. MiniDFSCluster; the job will fail on Windows. The error message looks like the following.     In my testing; the following unit tests hit this exception.   	TestMRJobsWithHistoryService 	TestClusterMRNotification 	TestJobCleanup 	TestJobCounters 	TestMiniMRClientCluster 	TestJobOutputCommitter 	TestMRAppWithCombiner 	TestMROldApiJobs 	TestSpeculativeExecution",Closed,Fixed,,Chuan Liu,Chuan Liu,Thu; 27 Jun 2013 16:48:10 +0000,Thu; 12 May 2016 18:22:48 +0000,Tue; 2 Jul 2013 23:40:23 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5355
MAPREDUCE-5356,Sub-task,Major,jobhistoryserver,Ability to refresh aggregated log retention period and check interval ,We want to be able to refresh log aggregation retention time and 'check interval' time on the fly by changing configs so that we dont have to bounce history server.,Closed,Fixed,,Ashwin Shankar,Ashwin Shankar,Thu; 27 Jun 2013 18:04:27 +0000,Wed; 3 Sep 2014 23:35:28 +0000,Tue; 23 Jul 2013 19:26:09 +0000,,2.1.0-beta,features,,,https://issues.apache.org/jira/browse/MAPREDUCE-5356
MAPREDUCE-5357,Bug,Minor,,Job staging directory owner checking could fail on Windows,"In JobSubmissionFiles.getStagingDir(); we have following code that will throw exception if the directory owner is not the current user.     This check will fail on Windows when the underlying file system is LocalFileSystem. Because on Windows; the default file or directory owner could be ""Administrators"" group if the user belongs to ""Administrators"" group.  Quite a few MR unit tests that runs MR mini cluster with localFs as underlying file system fail because of this.",Closed,Fixed,,Chuan Liu,Chuan Liu,Fri; 28 Jun 2013 01:30:10 +0000,Thu; 12 May 2016 18:22:33 +0000,Wed; 3 Jul 2013 05:49:00 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5357
MAPREDUCE-5358,Bug,Major,mr-am,MRAppMaster throws invalid transitions for JobImpl,nan,Closed,Fixed,,Devaraj K,Devaraj K,Fri; 28 Jun 2013 05:40:45 +0000,Wed; 3 Sep 2014 23:48:12 +0000,Wed; 3 Jul 2013 14:47:29 +0000,,2.0.1-alpha;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5358
MAPREDUCE-5359,Bug,Minor,,JobHistory should not use File.separator to match timestamp in path,In HistoryFileManager.getTimestampPartFromPath() method; we use the following regular expression to match the timestamp in a Path object.      This is incorrect because Path uses backslash even for Windows path while File.separator is platform dependent; and is a forward slash on Windows.  This leads to failure matching the timestamp on Windows. One consequence is that addDirectoryToSerialNumberIndex() also failed. Later; getFileInfo() will fail if the job info is not in cache or intermediate directory.  The test case TestJobHistoryParsing.testScanningOldDirs() tests exactly the above scenario and fails on Windows.,Closed,Fixed,,Chuan Liu,Chuan Liu,Fri; 28 Jun 2013 06:08:18 +0000,Thu; 12 May 2016 18:22:42 +0000,Wed; 3 Jul 2013 00:08:27 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5359
MAPREDUCE-5360,Bug,Minor,test,TestMRJobClient fails on Windows due to path format,"This unit test has following two failed test cases on Windows due to path name format.   	testJobHistory 	testSubmit    When passing local path to the command line; the test cases use ""file: "" + a string derived from Java API File.getAbsolutePath(). The mixed use of forward and back slashes in the path leads to the failure.",Closed,Fixed,,Chuan Liu,Chuan Liu,Fri; 28 Jun 2013 16:53:44 +0000,Thu; 12 May 2016 18:24:37 +0000,Sat; 6 Jul 2013 04:09:13 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5360
MAPREDUCE-5361,Bug,Major,,Reducer getting fewer records than expected,"Hi All;  We have a scenario of generating unique key for every single row in a file. we have a timestamp column but the are multiple rows available for a same timestamp in few scenarios. We decided unique values to be timestamp appended with their respective count as mentioned in the below program. Mapper will just emit the timestamp as key and the entire row as its value; and in reducer the key is generated. Problem is Map outputs about 236 rows; of which only 230 records are fed as an input for reducer which outputs the same 230 records. public class UniqueKeyGenerator extends Configured implements Tool {      private static final String SEPERATOR = "" t"";     private static final int TIME_INDEX = 10;     private static final String COUNT_FORMAT_DIGITS = ""%010d"";     public static class Map extends MapperLongWritable; Text; Text; Text {          @Override         protected void map(LongWritable key; Text row; Context context)                 throws IOException; InterruptedException {             String input = row.toString();             String[] vals = input.split(SEPERATOR);             if (vals != null &amp; vals.length = TIME_INDEX)  {                 context.write(new Text(vals[TIME_INDEX - 1]); row);             }         }     }      public static class Reduce extends ReducerText; Text; NullWritable; Text {          @Override         protected void reduce(Text eventTimeKey;                 IterableText timeGroupedRows; Context context)                 throws IOException; InterruptedException {             int cnt = 1;             final String eventTime = eventTimeKey.toString();             for (Text val : timeGroupedRows)  {                 final String res = SEPERATOR.concat(getDate(                         Long.valueOf(eventTime)).concat(                         String.format(COUNT_FORMAT_DIGITS; cnt)));                 val.append(res.getBytes(); 0; res.length());                 cnt++;                 context.write(NullWritable.get(); val);             }         }     }      public static String getDate(long time)  {         SimpleDateFormat utcSdf = new SimpleDateFormat(""yyyyMMddhhmmss"");         utcSdf.setTimeZone(TimeZone.getTimeZone(""America  job.setNumReduceTasks(400);          FileInputFormat.addInputPath(job; new Path(args[0]));         FileOutputFormat.setOutputPath(job; new Path(args[1]));          job.waitForCompletion(true);     }  }  It is consistent for higher no of lines and the difference is as huge as 208969 records for an input of 20855982 lines. what might be the reason for reduced inputs to reducer?  Many Thanks; Sathish.",Open,Unresolved,,Unassigned,Sathish,Fri; 28 Jun 2013 17:14:34 +0000,Fri; 28 Jun 2013 17:14:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5361
HADOOP-11943,Sub-task,Major,build,clean up POM dependencies,Intermediate 'pom' modules define dependencies inherited by leaf modules.  This is causing issues in intellij IDE.  We should normalize the leaf modules like in common; hdfs and tools where all dependencies are defined in each leaf module and the intermediate 'pom' module do not define any dependency.,Open,Unresolved,,Alejandro Abdelnur,Alejandro Abdelnur,Fri; 28 Jun 2013 18:38:05 +0000,Tue; 23 Feb 2016 12:45:12 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/HADOOP-11943
MAPREDUCE-5363,Bug,Minor,mrv1;mrv2,Fix doc and spelling for TaskCompletionEvent#getTaskStatus and getStatus,The doc for TaskCompletionEvent#get(Task)Status in both MR1 and MR2 is    The actual values that the Status enum can take are FAILED; KILLED; SUCCEEDED; OBSOLETE; TIPFAILED,Closed,Fixed,,Akira Ajisaka,Sandy Ryza,Mon; 1 Jul 2013 18:52:56 +0000,Mon; 1 Dec 2014 03:10:24 +0000,Thu; 14 Aug 2014 15:48:07 +0000,,1.1.2;2.1.0-beta,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5363
MAPREDUCE-5364,Bug,Major,,Deadlock between RenewalTimerTask methods cancel() and run(),MAPREDUCE-4860 introduced a local variable cancelled in RenewalTimerTask to fix the race where DelegationTokenRenewal attempts to renew a token even after the job is removed. However; the patch also makes run() and cancel() synchronized methods leading to a potential deadlock against run()'s catch-block (error-path).  The deadlock stacks below:,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Mon; 1 Jul 2013 20:11:46 +0000,Mon; 3 Nov 2014 18:33:35 +0000,Thu; 11 Jul 2013 20:29:28 +0000,,1.2.0,,,MAPREDUCE-5384;MAPREDUCE-4860,https://issues.apache.org/jira/browse/MAPREDUCE-5364
MAPREDUCE-5365,Improvement,Major,,Set mapreduce.job.classloader to true by default,MAPREDUCE-1700 introduced the mapreduce.job.classpath option; which uses a custom classloader to separate system classes from user classes.  It seems like there are only rare cases when a user would not want this on; and that it should enabled by default.,Patch Available,Unresolved,,Sandy Ryza,Sandy Ryza,Mon; 1 Jul 2013 21:08:26 +0000,Wed; 6 May 2015 03:32:10 +0000,,,2.0.5-alpha,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5365
MAPREDUCE-5366,Bug,Minor,test,TestMRAsyncDiskService fails on Windows,The unit test fails on Windows because mismatching of File.seperator and  Path object name. In general; we should only use Path.SEPARATOR when dealing with Path objects.,Closed,Fixed,,Chuan Liu,Chuan Liu,Mon; 1 Jul 2013 21:48:42 +0000,Thu; 12 May 2016 18:23:14 +0000,Mon; 8 Jul 2013 17:27:21 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5366
MAPREDUCE-5367,Improvement,Major,,Local jobs all use same local working directory,This means that local jobs; even in different JVMs; can't run concurrently because they might delete each other's files during work directory setup.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Mon; 1 Jul 2013 22:34:02 +0000,Tue; 24 Sep 2013 23:33:34 +0000,Mon; 5 Aug 2013 17:22:43 +0000,,1.2.0,,,MAPREDUCE-4278,https://issues.apache.org/jira/browse/MAPREDUCE-5367
MAPREDUCE-5368,Improvement,Major,mrv1,Save memory by  set capacity; load factor and concurrency level for ConcurrentHashMap in TaskInProgress,Below is histo from our JobTracker:   num     #instances         #bytes  class name ----------------------------------------------    1:     136048824    11347237456  [C    2:     124156992     5959535616      MapTaskAttemptID; Locality taskLocality =        new ConcurrentHashMapTaskAttemptID; Locality();   MapTaskAttemptID; Avataar taskAvataar =        new ConcurrentHashMapTaskAttemptID; Avataar();,Closed,Fixed,,yunjiong zhao,yunjiong zhao,Tue; 2 Jul 2013 07:08:12 +0000,Sun; 4 Aug 2013 08:23:27 +0000,Fri; 5 Jul 2013 03:24:35 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5368
MAPREDUCE-5369,Bug,Major,,Progress for jobs with multiple splits in local mode is wrong,In case a job with multiple splits is executed in local mode (LocalJobRunner) its progress calculation is wrong. After the first split is processed it jumps to 100%; then back to 50% and so on.   The reason lies in the progress calculation in LocalJobRunner:    The problem is that mapIds is filled lazily in run(). There is an loop over all splits. In the loop; the splits task id is added to mapIds; then the split is processed. That means numTasks is 1 while the first split is processed; it is 2 while the second task is processed and so on...  I tried Hadoop 0.20.2; 1.0.3; 1.1.2 and cdh-4.1. All the same behaviour!,Open,Unresolved,,Unassigned,Johannes Zillmann,Tue; 2 Jul 2013 08:49:01 +0000,Tue; 17 Sep 2013 16:52:12 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5369
MAPREDUCE-5370,Task,Minor,,Rolling Restart Tasktrackers from JobTracker,For near real-time jobs running on hadoop; we want to minimize impact on them when rolling restarting tasktrackers. The idea here is to restart tasktrackers from jobtracker and selectively choose task trackers according to tasks' status on them to do rolling restart; such that the impact on total job running time is minimum.,Open,Unresolved,,Unassigned,Cindy Li,Tue; 2 Jul 2013 21:02:13 +0000,Tue; 20 Aug 2013 22:30:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5370
MAPREDUCE-5371,Bug,Minor,test,TestProxyUserFromEnv#testProxyUserFromEnvironment failed caused by domains of windows users,The error message was: Error Message expected:sijenkins-vm2jenkins but was:[]jenkins Stacktrace at org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment(TestProxyUserFromEnv. 45)  The root cause of this failure is the domain used on Windows.,Resolved,Fixed,,Xi Fang,Xi Fang,Tue; 2 Jul 2013 21:13:26 +0000,Mon; 8 Jul 2013 17:53:25 +0000,Mon; 8 Jul 2013 17:51:33 +0000,,1-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5371
MAPREDUCE-5372,Bug,Major,,ControlledJob#getMapredJobID capitalization is inconsistent between MR1 and MR2,In MR2; the 'd' in Id is lowercase; but in MR1; it is capitalized.  While ControlledJob is marked as Evolving; there is no reason to be inconsistent here.,Resolved,Won't Fix,,Akira Ajisaka,Sandy Ryza,Tue; 2 Jul 2013 23:22:33 +0000,Fri; 23 Aug 2013 18:51:34 +0000,Fri; 23 Aug 2013 18:51:34 +0000,,2.1.0-beta,newbie,,MAPREDUCE-5233,https://issues.apache.org/jira/browse/MAPREDUCE-5372
MAPREDUCE-5373,Bug,Major,,TestFetchFailure.testFetchFailureMultipleReduces could fail intermittently,The unit test case could fail intermittently on both Linux and Windows in my testing. The error message seems suggesting the task status was wrong during testing.  An example Linux failure:    An example Windows failure:,Closed,Fixed,,Jonathan Eagles,Chuan Liu,Wed; 3 Jul 2013 22:48:39 +0000,Thu; 12 May 2016 18:23:44 +0000,Sat; 16 Nov 2013 03:39:43 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5373
MAPREDUCE-5374,Bug,Major,,"CombineFileRecordReader does not set ""map.input.*"" configuration parameters for first file read","The CombineFileRecordReader operates on splits consisting of multiple files. Each time a new record reader is initialised for a ""chunk""; certain parameters are supposed to be set on the configuration object (map.input.file; map.input.start and map.input.length)  However; the first reader is initialised in a different way to subsequent ones (i.e. initialize is called by the MapTask directly rather than from inside the record reader class). Because of this; these config parameters are not set properly and are returned as null when you access them from inside a mapper.",Patch Available,Unresolved,,Dave Beech,Dave Beech,Thu; 4 Jul 2013 13:02:12 +0000,Wed; 6 May 2015 03:34:29 +0000,,,1.2.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5374
MAPREDUCE-5375,Bug,Critical,,Delegation Token renewal exception in jobtracker logs,Filing on behalf of Venkat Ranganathan who found this originally and provided a patch.  Saw this in the JT logs while oozie tests were running with Hadoop.  When Oozie  action is executed; the following shows up in the job tracker log.     Setting the renewer to Kerberos Local name does not help because AbstractDelegationTokenIdentifier sets the renewer to Kerberos shortname but JobTracker.renewDelegationToken uses the fullName.  This essentially causes the renewal to fail.,Closed,Fixed,MAPREDUCE-5249,Venkat Ranganathan,Venkat Ranganathan,Thu; 4 Jul 2013 17:55:20 +0000,Sun; 4 Aug 2013 08:23:27 +0000,Fri; 5 Jul 2013 03:18:53 +0000,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5375
MAPREDUCE-5376,Bug,Major,jobtracker;mrv1,"The value of the Counters at Map/Reduce column shows wrong values as ""0"" in jobdetails.jsp and jobdetailshistory.jsp",In jobdetails.jsp; the The acquisition of the counter of M R column uses displayName in Counters.Group.getCounter(). Therefore; the counter where is different in realname and displayname cannot get a value. It uses displayName to get a value by Map column and Reduce column.,Open,Unresolved,,Shinichi Yamashita,Shinichi Yamashita,Thu; 4 Jul 2013 22:31:17 +0000,Tue; 18 Feb 2014 05:59:52 +0000,,,1.2.0;1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5376
MAPREDUCE-5377,Bug,Minor,mrv1,"JobID is not displayed truly by ""hadoop job -history"" command","JobID output by ""hadoop job -history"" command is wrong string.   hadoop@hadoop hadoop$ hadoop job -history terasort  Hadoop job: 0001_1374260789919_hadoop ===================================== Job tracker host name: job job tracker start time: Tue May 18 15:39:51 PDT 1976 User: hadoop JobName: TeraSort JobConf: hdfs: job.xml Submitted At: 19-7-2013 12:06:29 Launched At: 19-7-2013 12:06:30 (0sec) Finished At: 19-7-2013 12:06:44 (14sec) Status: SUCCESS  In this example; it should show ""job_201307191206_0001"" at ""Hadoop job:""; but shows ""0001_1374260789919_hadoop"". In addition; ""Job tracker host name"" and ""job tracker start time"" is invalid. This problem can solve by fixing setting of jobId in HistoryViewer(). In addition; it should fix the information of JobTracker at HistoryViewr.",Patch Available,Unresolved,,Shinichi Yamashita,Shinichi Yamashita,Fri; 5 Jul 2013 23:42:09 +0000,Wed; 6 May 2015 03:32:14 +0000,,,1.2.0,BB2015-05-TBR;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5377
MAPREDUCE-5378,Improvement,Major,,Enable ApplicationMaster to support different QOP for client and server communications,Currently ApplicationMaster's QOP(quality of protection) is derived from the client's config. If the client uses privacy; all the communication done by the application master will be set to privacy.   As part of the feature to support multiple QOP (HADOOP -9709); the application master is modified so that application master can support a different QOPs  for its communication with client vs its communication with other hadoop components.,Resolved,Duplicate,HADOOP-10221;HDFS-5910,Benoy Antony,Benoy Antony,Mon; 8 Jul 2013 23:07:32 +0000,Mon; 31 Mar 2014 23:38:10 +0000,Mon; 31 Mar 2014 23:31:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5378
MAPREDUCE-5379,Improvement,Major,job submission;security,Include token tracking ids in jobconf,HDFS-4680 enables audit logging delegation tokens. By storing the tracking ids in the job conf; we can enable tracking what files each job touches.,Closed,Fixed,,Karthik Kambatla,Sandy Ryza,Tue; 9 Jul 2013 22:58:23 +0000,Mon; 3 Nov 2014 18:05:38 +0000,Mon; 16 Sep 2013 12:21:28 +0000,,2.1.0-beta,,,HDFS-4680;HADOOP-9775,https://issues.apache.org/jira/browse/MAPREDUCE-5379
MAPREDUCE-5380,Bug,Major,,Invalid mapred command should return non-zero exit code,Running the mapred bin script with an invalid command returns exit code 0; but it should return a non-zero exit code.,Closed,Fixed,,Stephen Chu,Stephen Chu,Wed; 10 Jul 2013 22:25:04 +0000,Thu; 12 May 2016 18:23:03 +0000,Wed; 17 Jul 2013 00:33:02 +0000,,2.0.4-alpha;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5380
MAPREDUCE-5381,Improvement,Major,mrv1,Support graceful decommission of tasktracker,When TTs are decommissioned for non-fault reasons (capacity change etc.); it's desirable to minimize the impact to running jobs.  Currently if a TT is decommissioned; all running tasks on the TT need to be rescheduled on other TTs. Further more; for finished map tasks; if their map output are not fetched by the reducers of the job; these map tasks will need to be rerun as well.  We propose to introduce a mechanism to optionally gracefully decommission a tasktracker.,Resolved,Won't Fix,,Binglin Chang,Luke Lu,Wed; 10 Jul 2013 23:17:42 +0000,Mon; 9 Feb 2015 18:48:01 +0000,Mon; 9 Feb 2015 18:48:01 +0000,,1.2.0,,MAPREDUCE-4900;HADOOP-9160,YARN-914,https://issues.apache.org/jira/browse/MAPREDUCE-5381
MAPREDUCE-5382,Bug,Major,,LocalJobRunner should use default FS for system and staging dirs by default,For local jobs; staging dirs and system dirs are currently required to be placed on the local FS. I am continually bitten by permissions errors when I set mapreduce.jobtracker.staging.root.dir to  user; even when the default FS is still HDFS.  I think using a different FS for staging than the default FS is confusing.,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Thu; 11 Jul 2013 18:45:05 +0000,Thu; 11 Jul 2013 18:45:05 +0000,,,1.1.2;2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5382
MAPREDUCE-5383,Improvement,Major,,Deprecate to mapreduce.jobtracker.staging.root.dir to yarn.app.mapreduce.am.staging-dir,This will allow configurations that had previously set mapreduce.jobtracker.staging.root.dir should be able to more easily transition to MR2; as well as make it clear that these properties refer to the same thing.,Open,Unresolved,,Anthony Rojas,Sandy Ryza,Thu; 11 Jul 2013 20:04:47 +0000,Mon; 30 Nov 2015 17:07:29 +0000,,,2.1.0-beta,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5383
MAPREDUCE-5384,Bug,Major,,Races in DelegationTokenRenewal,"There are a couple of races in DelegationTokenRenewal.   One of them was addressed by MAPREDUCE-4860; which introduced a deadlock while fixing this race. Opening a new JIRA per discussion in MAPREDUCE-5364; since MAPREDUCE-4860 is already shipped in a release.  Races to fix:  	TimerTask#cancel() disallows future invocations of run(); but doesn't abort an already scheduled started run(). 	In the context of DelegationTokenRenewal; RenewalTimerTask#cancel() only cancels that TimerTask instance. However; it has no effect on any other TimerTasks created for that token.",Open,Unresolved,,Unassigned,Karthik Kambatla,Thu; 11 Jul 2013 20:26:24 +0000,Sun; 28 Dec 2014 18:34:52 +0000,,,1.2.0;1.1.2;1.2.1,,,MAPREDUCE-5364;MAPREDUCE-4860,https://issues.apache.org/jira/browse/MAPREDUCE-5384
MAPREDUCE-5385,Bug,Blocker,,JobContext cache files api are broken,"I just checked there are issues with latest distributed cache api.   	JobContext.getCacheFiles is broken returns null.",Closed,Fixed,,Omkar Vinit Joshi,Omkar Vinit Joshi,Thu; 11 Jul 2013 21:51:30 +0000,Mon; 16 Dec 2013 18:45:31 +0000,Tue; 30 Jul 2013 20:06:06 +0000,,2.1.0-beta,,,MAPREDUCE-5685,https://issues.apache.org/jira/browse/MAPREDUCE-5385
MAPREDUCE-5386,Sub-task,Major,jobhistoryserver,Ability to refresh history server job retention and job cleaner settings,We want to be able to refresh following job retention parameters without having to bounce the history server : 1. Job retention time - mapreduce.jobhistory.max-age-ms 2. Cleaner interval - mapreduce.jobhistory.cleaner.interval-ms 3. Enable disable cleaner -mapreduce.jobhistory.cleaner.enable,Closed,Fixed,,Ashwin Shankar,Ashwin Shankar,Fri; 12 Jul 2013 22:11:36 +0000,Wed; 3 Sep 2014 23:35:26 +0000,Fri; 26 Jul 2013 17:32:52 +0000,,2.1.0-beta,features,,,https://issues.apache.org/jira/browse/MAPREDUCE-5386
MAPREDUCE-5387,Improvement,Major,,Implement Signal.TERM on Windows,"Signal.TERM is currently not supported by Hadoop on the Windows platform. Tracking Jira for the problem.   A couple of things to keep in mind:  	Support for process groups (JobObjects on Windows) 	Solution should work for both  and other streaming Hadoop apps",Open,Unresolved,,Ivan Mitic,Ivan Mitic,Sun; 14 Jul 2013 17:14:36 +0000,Thu; 12 May 2016 18:23:34 +0000,,,1-win;2.1.0-beta;3.0.0-alpha1,,,YARN-445,https://issues.apache.org/jira/browse/MAPREDUCE-5387
MAPREDUCE-5388,Bug,Major,tasktracker,There are two TaskLaunchers for map after the TaskTracker reinit,The TaskTracker was asked to reinit as the full gc;then the process contained of two TaskLauncher instance for map:,Open,Unresolved,,Unassigned,Hua xu,Mon; 15 Jul 2013 06:33:19 +0000,Mon; 15 Jul 2013 06:49:17 +0000,,,0.21.0;0.22.0;1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5388
MAPREDUCE-5390,Bug,Major,,JOB_FAIL and JOB_KILL have different behaviors when they should ideally be same / similar.,After MAPREDUCE-5317; both JOB_KILL and JOB_FAIL wait for all the tasks to die   be killed; and then move to their final states. We can make these two code paths the same. Ideally KILL_WAIT should also have a timeout like the one MAPREDUCE-5317 introduces.,Open,Unresolved,,Unassigned,Ravi Prakash,Mon; 15 Jul 2013 18:15:01 +0000,Thu; 12 May 2016 18:22:30 +0000,,,0.23.9;2.3.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5390
MAPREDUCE-5391,Bug,Major,test,TestNonLocalJobJarSubmission fails on Windows due to missing classpath entries,This test works by having the mapper check all classpath entries loaded by the classloader.  On Windows; the classpath is packed into an intermediate jar file with a manifest containing the classpath to work around command line length limitation.  The test needs to be updated to unpack the intermediate jar file and read the manifest when running on Windows.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Mon; 15 Jul 2013 20:43:33 +0000,Wed; 17 Jul 2013 22:15:23 +0000,Wed; 17 Jul 2013 22:15:23 +0000,,1-win,,,MAPREDUCE-4401,https://issues.apache.org/jira/browse/MAPREDUCE-5391
MAPREDUCE-5392,Bug,Major,mrv2,mapred job -history all command throws IndexOutOfBoundsException,"When I use an ""all"" option by ""mapred job -history"" comamnd; the following exceptions are displayed and do not work.     This is because a node name recorded in History file is not given ""tracker_"". Therefore it makes modifications to be able to read History file even if a node name is not given by ""tracker_"". In addition; it fixes the URL of displayed task log.",Patch Available,Unresolved,,Shinichi Yamashita,Shinichi Yamashita,Mon; 15 Jul 2013 23:40:39 +0000,Mon; 11 Sep 2017 05:22:48 +0000,,,2.0.5-alpha;2.2.0;3.0.0-alpha1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5392
MAPREDUCE-5393,Bug,Major,,Physical memory and Virtual Memory counters in Job Counters display incorrect values,The counters Physical memory (bytes) snapshot - represented by PHYSICAL_MEMORY_BYTES ) and Virtual memory (bytes) snapshot - represented by VIRTUAL_MEMORY_BYTES have multiple issues  1. It calculates it as MemTotal from  meminfo if you manually check it. E.g. on a host having 48G memory the tasks show the value of physical memory (byte) snapshot as 214;142;976 and the number varies every time the job is run.  What was the intention of these counters? Why would we need to get the metric for every job (as they should be more or less static for given host).,Open,Unresolved,,Unassigned,Sheetal Dolas,Tue; 16 Jul 2013 01:50:24 +0000,Tue; 27 Jan 2015 18:05:54 +0000,,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5393
MAPREDUCE-5394,New Feature,Major,,Job Counters - ability to perform calculations other than sum,Many a times the applications need to report values as more than sums across tasks. Such as min racks.  Having this kind of ability in counters will greatly enhance the utility of counters.,Open,Unresolved,,jhanver chand sharma,Sheetal Dolas,Tue; 16 Jul 2013 01:55:00 +0000,Mon; 2 Jun 2014 05:32:48 +0000,,,1.2.0;2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5394
MAPREDUCE-5395,Improvement,Major,examples,Update Teragen algorithm,The Teragen algorithm is no longer up to date with the sortbenchmark.org gensort tool used for the official sort benchmark.  The new algorithm is supposed to generate data that isn't very compressible.   Also the new version of gensort can generate skewed data so we should add that option to teragen also.,Open,Unresolved,,Unassigned,Thomas Graves,Tue; 16 Jul 2013 13:12:05 +0000,Wed; 31 Jul 2013 15:21:07 +0000,,,0.23.7,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5395
MAPREDUCE-5396,Bug,Major,mr-am,"Application is ""FAILED"" when multiple appmaster attempts are spawned",1.Run job with 142 maps 2.After some map tasks executed kill NM where appmaster running(Using kill -9 cmd) 3.Now obeserve that till NM expiry interval that appmaster will be running after NM expiry interval that appmaster will be killed and new appmaster will be launched  Observations: ------------------- 1.First appmaster while going down deletes the staging dir of job 2.While new appmaster is running it will kill all the tasks running in it and fails the application saying files in staging dir not present,Open,Unresolved,YARN-929,Devaraj K,Nishan Shetty,Mon; 15 Jul 2013 04:22:04 +0000,Tue; 16 Jul 2013 14:05:52 +0000,,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5396
MAPREDUCE-5397,Bug,Major,,AM crashes because Webapp failed to start on multi node cluster,I set up a 12 nodes cluster and tried submitting jobs but get this exception. But job is able to succeed after AM crashes and retry a few times(2 or 3),Reopened,Unresolved,,Unassigned,Jian He,Tue; 16 Jul 2013 21:59:48 +0000,Mon; 18 Apr 2016 17:11:29 +0000,,,,,,MAPREDUCE-3021,https://issues.apache.org/jira/browse/MAPREDUCE-5397
MAPREDUCE-5398,Improvement,Major,,MR changes for YARN-513,nan,Closed,Fixed,,Jian He,Bikas Saha,Tue; 16 Jul 2013 22:43:45 +0000,Tue; 27 Aug 2013 22:22:01 +0000,Tue; 16 Jul 2013 23:06:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5398
MAPREDUCE-5399,Bug,Blocker,mrv1;mrv2,Unnecessary Configuration instantiation in IFileInputStream slows down merge,We are using hadoop-2.0.0+1357-1.cdh4.3.0.p0.21 with MRv1. After upgrade from 4.1.2 to 4.3.0; I have noticed some performance deterioration in our MR job in the Reduce phase. The MR job has usually 10 000 map tasks (10 000 files on input each about 100MB) and 6 000 reducers (one reducer per table region). I was trying to figure out wh least 1.6 hours longer than it should be.,Closed,Fixed,,Stanislav Barton,Stanislav Barton,Wed; 17 Jul 2013 08:15:57 +0000,Tue; 27 Aug 2013 22:21:58 +0000,Tue; 6 Aug 2013 02:09:38 +0000,,1.1.0;2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5399
MAPREDUCE-5400,Sub-task,Minor,applicationmaster,MRAppMaster throws InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SUCCEEDED for JobImpl,Step 1: Install cluster with HDFS ; MR Step 2: Execute a job Step 3: Issue a kill task   662),Resolved,Cannot Reproduce,,Devaraj K,J.Andreina,Mon; 15 Jul 2013 13:44:39 +0000,Fri; 23 Dec 2016 20:26:29 +0000,Thu; 11 Feb 2016 18:49:51 +0000,,2.0.5-alpha,,,MAPREDUCE-6826,https://issues.apache.org/jira/browse/MAPREDUCE-5400
MAPREDUCE-5401,Bug,Major,,Succeeded Job details displayed as Error  In JobHistoryServer UI when RM issues Reboot to 1st app master.,RM issues Reboot to 1st tempt summary remain as summary_tmp,Resolved,Duplicate,MAPREDUCE-5466,Unassigned,Rohith Sharma K S,Thu; 18 Jul 2013 10:44:03 +0000,Thu; 22 Aug 2013 03:13:57 +0000,Thu; 22 Aug 2013 03:13:57 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5401
MAPREDUCE-5402,Improvement,Major,distcp;mrv2,DynamicInputFormat should allow overriding of MAX_CHUNKS_TOLERABLE,In MAPREDUCE-2765; which provided the design spec for DistCpV2; the author describes the implementation of DynamicInputFormat; with one of the main motivations cited being to reduce the chance of long-tails where a few leftover mappers run much longer than the rest.  However; I today ran into a situation where I experienced exactly such a long tail using DistCpV2 and DynamicInputFormat.  And when I tried to alleviate the problem by overriding the number of mappers and the split ratio used by the DynamicInputFormat; I was prevented from doing so by the hard-coded limit set in the code by the MAX_CHUNKS_TOLERABLE constant.  (Currently set to 400.)  This constant is actually set quite low for production use.  (See a description of my use case below.)  And although MAPREDUCE-2765 states th prevents proper parallelization when dealing with large files and or large numbers of mappers.,Closed,Fixed,,Tsuyoshi Ozawa,David Rosenstrauch,Thu; 18 Jul 2013 21:00:37 +0000,Fri; 15 Aug 2014 05:47:59 +0000,Tue; 6 May 2014 10:25:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5402
MAPREDUCE-5403,Improvement,Major,client,MR changes to accommodate yarn.application.classpath being moved to the server-side,yarn.application.classpath is a confusing property because it is used by MapReduce and not YARN; and MapReduce already has mapreduce.application.classpath; which provides the same functionality.,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Thu; 18 Jul 2013 22:28:19 +0000,Fri; 8 May 2015 23:29:57 +0000,,,2.0.5-alpha,,,YARN-973,https://issues.apache.org/jira/browse/MAPREDUCE-5403
MAPREDUCE-5404,Bug,Major,jobhistoryserver,HSAdminServer does not use ephemeral ports in minicluster mode,I ran HBase trunk tests against 2.2.0-SNAPSHOT and many mapreduce jobs failed. Here is one example:,Closed,Fixed,,Ted Yu,Ted Yu,Fri; 19 Jul 2013 01:06:06 +0000,Thu; 12 May 2016 18:23:39 +0000,Mon; 22 Jul 2013 19:06:11 +0000,,2.3.0;3.0.0-alpha1,,,MAPREDUCE-5265,https://issues.apache.org/jira/browse/MAPREDUCE-5404
MAPREDUCE-5405,Bug,Major,mrv1,Job recovery can fail if task log directory symlink from prior run still exists,During recovery; the task attempt log dir symlink from the prior run might still exist.  If it does; then the recovered attempt will fail while trying to create a symlink at that path.,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Fri; 19 Jul 2013 18:56:45 +0000,Mon; 22 Jul 2013 18:32:17 +0000,Mon; 22 Jul 2013 18:32:17 +0000,,1-win;1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5405
MAPREDUCE-5406,Improvement,Major,tasktracker,Improve logging around Task Tracker exiting with JVM manager inconsistent state,Looks like we are reaching JVM manager inconsistent state which cases TT to crash:    Although this causes TT to crash; the frequency of the error is rare and the error itself is recoverable so the priority of the issue is not high.  However; this does look like a bug in the JVM manager state machine. I'm guessing there is some race condition that we're hitting.  (Logs attached),Resolved,Fixed,,Chelsey Chang,Chelsey Chang,Fri; 19 Jul 2013 21:06:10 +0000,Sat; 20 Jul 2013 06:08:38 +0000,Sat; 20 Jul 2013 06:08:38 +0000,,1-win;1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5406
MAPREDUCE-5407,Bug,Minor,,How to process 1 lack records to show a graph with 12 points,I started HDFS on which hbase is running.Table created in hbase. I am using Hive (hive Query) to process the data from HBase Table.  I have to show a graph with some points ( thsese may include 7 days in a week; 12 months in a year etc.).To show an average value of a day i have to process many records (some times 1000 to lacks). Is there any built in mechanism (in hadoop) ?  so that i can do it using that.  I need to run a job or hive query (when a hive query is running ; actually a job is running) in every 1 hour.Is there any scheduler in hadoop by which can we do this easly.  Also,Resolved,Invalid,,Balamurali,Balamurali,Mon; 22 Jul 2013 13:37:34 +0000,Mon; 22 Jul 2013 15:55:44 +0000,Mon; 22 Jul 2013 15:55:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5407
MAPREDUCE-5408,Improvement,Major,,CLONE - The logging level of the tasks should be configurable by the job,It would be nice to be able to configure the logging level of the Task JVM's separately from the server JVM's. Reducing logging substantially increases performance and reduces the consumption of local disk on the task trackers.,Resolved,Fixed,,Arun C Murthy,Owen O'Malley,Tue; 23 Jul 2013 06:46:55 +0000,Tue; 23 Jul 2013 15:57:16 +0000,Tue; 23 Jul 2013 15:32:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5408
MAPREDUCE-5409,Sub-task,Major,,MRAppMaster throws InvalidStateTransitonException: Invalid event: TA_TOO_MANY_FETCH_FAILURE at KILLED for TaskAttemptImpl,nan,Closed,Fixed,MAPREDUCE-6933,Gera Shegalov,Devaraj K,Tue; 23 Jul 2013 07:34:15 +0000,Fri; 4 Aug 2017 13:36:12 +0000,Thu; 5 Dec 2013 16:34:22 +0000,,2.0.5-alpha,,,MAPREDUCE-4457,https://issues.apache.org/jira/browse/MAPREDUCE-5409
MAPREDUCE-5410,Bug,Major,examples;job submission,MapReduce output issue,"Hi;  I am new to Hadoop concepts.  While practicing with one custom MapReduce program; I found the result is not as expected after executing the code on HDFS based file. Please note that when I execute the same program using Unix based file;getting expected result. Below are the details of my code.  MapReduce in  util.*;  import org.apache.hadoop.fs.Path; import org.apache.hadoop.conf.*; import org.apache.hadoop.io.*; import org.apache.hadoop.mapred.*; import org.apache.hadoop.mapreduce.Job; import org.apache.hadoop.util.*;  public class WordCount1 {      public static class Map extends MapReduceBase implements Mapper {       private final static IntWritable one = new IntWritable(1);       private Text word = new Text();        public void map(LongWritable key; Text value; OutputCollector output; Reporter reporter) throws IOException {         String line = value.toString();         String tokenedZone=null;         StringTokenizer tokenizer = new StringTokenizer(line);         while (tokenizer.hasMoreTokens())  {           tokenedZone=tokenizer.nextToken();           word.set(tokenedZone);           output.collect(word; one);         }       }     }      public static class Reduce extends MapReduceBase implements Reducer {       public void reduce(Text key; Iterator values; OutputCollector output; Reporter reporter) throws IOException {         int sum = 0;         int val = 0;         while (values.hasNext())  {         	val = values.next().get();         	sum += val;         }         if(sum1)         	output.collect(key; new IntWritable(sum));       }     }      public static void main(String[] args) throws Exception  {       JobConf conf = new JobConf();       conf.setJarByClass(WordCount1.class);       conf.setJobName(""wordcount1"");              conf.setOutputKeyClass(Text.class);       conf.setOutputValueClass(IntWritable.class);        conf.setMapperClass(Map.class);       conf.setCombinerClass(Reduce.class);       conf.setReducerClass(Reduce.class);        conf.setInputFormat(TextInputFormat.class);       conf.setOutputFormat(TextOutputFormat.class);              Path inPath = new Path(args[0]);       Path outPath = new Path(args[0]);        FileInputFormat.setInputPaths(conf;inPath );       FileOutputFormat.setOutputPath(conf; outPath);        JobClient.runJob(conf);     }  }   input File =========== test my program during test and my hadoop  your during get program   hadoop generated output file on HDFS file system ======================================= during	2 my	2 test	2  hadoop generated output file on local file system ======================================= during	2 my	2 program	2 test	2  Please help me on this issue",Open,Unresolved,,Unassigned,Mullangi,Tue; 23 Jul 2013 08:29:18 +0000,Tue; 23 Jul 2013 08:29:18 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5410
MAPREDUCE-5411,Sub-task,Major,jobhistoryserver,Refresh size of loaded job cache on history server,We want to be able to refresh size of the loaded job cache(mapreduce.jobhistory.loadedjobs.cache.size) of history server through history server's admin interface.,Closed,Fixed,,Ashwin Shankar,Ashwin Shankar,Tue; 23 Jul 2013 16:00:27 +0000,Wed; 3 Sep 2014 23:35:25 +0000,Mon; 29 Jul 2013 22:48:49 +0000,,2.1.0-beta,features,,,https://issues.apache.org/jira/browse/MAPREDUCE-5411
MAPREDUCE-5412,Bug,Major,,Change MR to use multiple containers API of ContainerManager after YARN-926,nan,Closed,Fixed,,Jian He,Jian He,Tue; 23 Jul 2013 19:51:18 +0000,Tue; 27 Aug 2013 22:21:55 +0000,Wed; 24 Jul 2013 03:49:59 +0000,,,,,YARN-926,https://issues.apache.org/jira/browse/MAPREDUCE-5412
MAPREDUCE-5413,Bug,Major,,Killing mapred job in Initial stage leads to java.lang.NullPointerException,Run a MR job and kill it as soon as jobId is known. After killing the job; try to kill its  org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager. 54),Open,Unresolved,,Omkar Vinit Joshi,Yesha Vora,Tue; 23 Jul 2013 23:46:11 +0000,Tue; 12 Dec 2017 15:34:54 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5413
MAPREDUCE-5414,Bug,Major,test,TestTaskAttempt fails jdk7 with NullPointerException,Test case org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt fails once in a while when i run all of them together.   But if i run a single test case;taking testContainerCleanedWhileRunning for example;it will fail without doubt.,Closed,Fixed,,Nemon Lou,Nemon Lou,Wed; 24 Jul 2013 07:55:53 +0000,Fri; 11 Oct 2013 11:34:10 +0000,Mon; 9 Sep 2013 06:51:23 +0000,,2.0.5-alpha,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-5414
HDFS-5028,Bug,Major,,LeaseRenewer throw java.util.ConcurrentModificationException when timeout,"In LeaseRenewer; when renew() throw SocketTimeoutException; c.abort() will remove one dfsclient from dfsclients. Here will throw a ConcurrentModificationException because dfsclients changed after the iterator created by ""for(DFSClient c : dfsclients)"":  Exception in thread ""org.apache.hadoop.hdfs.LeaseRenewer$1@75fa1077""  662)",Closed,Fixed,,yunjiong zhao,yunjiong zhao,Wed; 24 Jul 2013 08:20:24 +0000,Tue; 24 Sep 2013 23:33:39 +0000,Fri; 2 Aug 2013 07:19:13 +0000,,1.1.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/HDFS-5028
MAPREDUCE-5416,Bug,Major,,hadoop-mapreduce-client-common depends on hadoop-yarn-server-common,mapreduce-client-app and mapreduce-client-jobclient modules also depend on yarn-server-common but only in test scope.,Open,Unresolved,,Unassigned,Hitesh Shah,Wed; 24 Jul 2013 21:39:47 +0000,Wed; 24 Jul 2013 21:39:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5416
MAPREDUCE-5417,Improvement,Major,mrv2,Propagate task settings to AM when job runs in uber mode,When a job runs in Uber-AM mode the JVM settings (e.g.: heap sizing); container sizing; and environment variables are not propagated to the AM.  This means running in uber-AM mode is not as simple as enabling mapreduce.job.ubertask.enable since lack of proper heap container settings can doom the AM to crash or lack of proper environment variables can prevent the task code from properly running.,Open,Unresolved,,Unassigned,Jason Lowe,Wed; 24 Jul 2013 21:44:42 +0000,Mon; 29 Jul 2013 05:10:55 +0000,,,2.0.4-alpha,,,OOZIE-1372,https://issues.apache.org/jira/browse/MAPREDUCE-5417
MAPREDUCE-5418,Bug,Critical,jobhistoryserver;mr-am,JobHistoryServer has no information about applications if the MR-AM crashes,Currently; the AM writes the job-specific information to HDFS only after it finishes; the JHS needs this info to display anything. If the AM fails; this info is not written and the JHS fails to display anything for that job.  While JHS on top of AHS might address this issue; it would be nice to have a solution in the interim.,Resolved,Duplicate,MAPREDUCE-5641,Robert Kanter,Karthik Kambatla,Wed; 24 Jul 2013 23:31:00 +0000,Mon; 3 Nov 2014 18:33:48 +0000,Mon; 7 Jul 2014 18:07:09 +0000,,2.0.5-alpha,,,MAPREDUCE-4428;MAPREDUCE-4559,https://issues.apache.org/jira/browse/MAPREDUCE-5418
MAPREDUCE-5419,Bug,Major,mrv2,TestSlive is getting FileNotFound Exception,"The write directory ""slive"" is not getting created on the FS.",Closed,Fixed,,Robert Parker,Robert Parker,Thu; 25 Jul 2013 19:17:42 +0000,Tue; 10 Mar 2015 04:30:49 +0000,Fri; 26 Jul 2013 22:06:35 +0000,,2.1.0-beta;0.23.9,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5419
MAPREDUCE-5420,Task,Major,,Remove mapreduce.task.tmp.dir from mapred-default.xml,mapreduce.task.tmp.dir no longer has any effect; so it should no longer be documented in mapred-default.  (There is no YARN equivalent for the property.  It now is just always . tmp).,Closed,Fixed,,James Carman,Sandy Ryza,Thu; 25 Jul 2013 23:30:34 +0000,Tue; 26 Sep 2017 02:10:59 +0000,Thu; 11 Dec 2014 04:18:25 +0000,,2.1.0-beta,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5420
MAPREDUCE-5421,Bug,Blocker,test,TestNonExistentJob is failed due to recent changes in YARN,After YARN-873; try to get an application report with unknown appID will get a exception instead of null. This cause test failure in TestNonExistentJob which affects other irrelevant jenkins jobs like: https: . We need to fix test failure here.,Closed,Fixed,MAPREDUCE-5424,Junping Du,Junping Du,Fri; 26 Jul 2013 10:56:23 +0000,Tue; 27 Aug 2013 22:21:59 +0000,Fri; 26 Jul 2013 19:16:51 +0000,,,,,YARN-873;HADOOP-9756,https://issues.apache.org/jira/browse/MAPREDUCE-5421
MAPREDUCE-5422,Task,Major,mr-am,[Umbrella] Fix invalid state transitions in MRAppMaster,There are mutiple invalid state transitions for the state machines present in MRAppMaster. All these can be handled as part of this umbrell JIRA.,Resolved,Fixed,,Devaraj K,Devaraj K,Fri; 26 Jul 2013 11:43:45 +0000,Thu; 11 Feb 2016 18:51:49 +0000,Thu; 11 Feb 2016 18:51:48 +0000,,2.0.5-alpha,,,YARN-676,https://issues.apache.org/jira/browse/MAPREDUCE-5422
MAPREDUCE-5423,Bug,Major,mrv2,Rare deadlock situation when reducers try to fetch map output,During our cluster deployment; we found there is a very rare deadlock situation when reducers try to fetch map output. We had 5 fetchers and log snippet illustrates this problem is below (all fetchers went into a wait state after they can't acquire more RAM beyond the memoryLimit and no fetcher is releasing memory):  2013-07-18 04:32:28;135 INFO main org.apache.hadoop.mapreduce.task.reduce.MergeManager: MergerManager: memoryLimit=1503238528; maxSingleShuffleLimit=375809632; mergeThreshold=992137472; ioSortFactor=10; memToMemMergeOutputsThreshold=10 2013-07-18 04:32:28;138 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher: tempt_1373902166027_0622_m_000006_0 2013-07-18 04:32:57;867 INFO fetcher#4 org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile - map-output of size: 280156692; inMemoryMapOutputs.size() - 6; commitMemory - 1462027584; usedMemory -1742184276 2013-07-18 04:32:57;900 INFO fetcher#4 org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergerManager returned Status.WAIT ... 2013-07-18 04:32:57;901 INFO fetcher#4 org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#4 in 999s 2013-07-18 04:32:57;901 INFO fetcher#3 org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 4 to fetcher#3 2013-07-18 04:32:57;901 INFO fetcher#3 org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to 101-09-04.sc1.verticloud.com:8080 to fetcher#3 2013-07-18 04:32:57;903 INFO fetcher#3 org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080 mapOutput?job=job_1373902166027_0622reduce=1map=attempt_1373902166027_0622_m_000000_0;attempt_1373902166027_0622_m_000002_0;attempt_1373902166027_0622_m_000005_0;attempt_1373902166027_0622_m_000003_0 sent hash and receievd reply 2013-07-18 04:32:57;904 INFO fetcher#3 org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergerManager returned Status.WAIT ... ...,Resolved,Duplicate,MAPREDUCE-4842,Unassigned,Chu Tong,Fri; 26 Jul 2013 17:07:57 +0000,Fri; 26 Jul 2013 21:58:14 +0000,Fri; 26 Jul 2013 21:58:14 +0000,,2.0.2-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5423
MAPREDUCE-5424,Bug,Blocker,test,TestNonExistentJob failing after YARN-873,nan,Resolved,Duplicate,MAPREDUCE-5421,Xuan Gong,Vinod Kumar Vavilapalli,Fri; 26 Jul 2013 19:00:31 +0000,Fri; 26 Jul 2013 19:10:42 +0000,Fri; 26 Jul 2013 19:10:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5424
MAPREDUCE-5425,Bug,Major,jobhistoryserver,Junit in TestJobHistoryServer failing in jdk 7,We get the following exception when we run the unit tests of TestJobHistoryServer with jdk 7: Caused by:  163)   This is happening because testMainMethod starts the history server and doesnt stop it. This worked in jdk 6 because tests executed sequentially and this test was last one and didnt affect other tests;but in jdk 7 it fails.,Closed,Fixed,,Robert Parker,Ashwin Shankar,Fri; 26 Jul 2013 21:27:13 +0000,Wed; 3 Sep 2014 23:52:30 +0000,Wed; 7 Aug 2013 20:10:11 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5425
MAPREDUCE-5426,Bug,Blocker,applicationmaster,MRAM fails to register to RM; AMRM token seems missing,trying to run the pi example in an unsecure pseudo cluster the job fails.   It seems the AMRM token is MIA.  The AM syslog have the following:,Closed,Duplicate,YARN-945,Unassigned,Alejandro Abdelnur,Sat; 27 Jul 2013 21:24:03 +0000,Tue; 27 Aug 2013 22:22:22 +0000,Sat; 27 Jul 2013 21:55:00 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5426
MAPREDUCE-5427,Bug,Major,test,TestRMContainerAllocator.testUpdatedNodes fails on jdk7,nan,Resolved,Duplicate,MAPREDUCE-5632,Sandy Ryza,Nemon Lou,Mon; 29 Jul 2013 07:53:36 +0000,Thu; 16 Jan 2014 02:09:28 +0000,Thu; 16 Jan 2014 02:09:28 +0000,,2.1.0-beta;2.0.5-alpha,java7,MAPREDUCE-5593,,https://issues.apache.org/jira/browse/MAPREDUCE-5427
MAPREDUCE-5428,Bug,Major,jobhistoryserver;mrv2,HistoryFileManager doesn't stop threads when service is stopped,HistoryFileManager is a service that starts threads; but it does not override the serviceStop method to stop the threads when the service is stopped.,Closed,Fixed,,Karthik Kambatla,Jason Lowe,Mon; 29 Jul 2013 15:03:26 +0000,Mon; 3 Nov 2014 18:06:04 +0000,Thu; 1 Aug 2013 20:07:42 +0000,,2.0.4-alpha,,HADOOP-9787,,https://issues.apache.org/jira/browse/MAPREDUCE-5428
MAPREDUCE-5429,Bug,Major,,App Master throw OutOfMemoryErrors.,While running job ; got OOM in app master and exitted the app master jvm.,Resolved,Not A Problem,,Unassigned,Rohith Sharma K S,Mon; 29 Jul 2013 16:46:13 +0000,Sat; 22 Nov 2014 10:41:06 +0000,Sat; 22 Nov 2014 10:41:06 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5429
MAPREDUCE-5430,Bug,Major,distributed-cache;mrv2,TestMRApps#testSetClasspathWithArchives is failing,TestMRApps#testSetClasspathWithArchives is failing; stacktrace to follow.,Resolved,Duplicate,HADOOP-9652,Colin P. McCabe,Jason Lowe,Mon; 29 Jul 2013 19:08:09 +0000,Tue; 28 Jan 2014 23:33:39 +0000,Tue; 30 Jul 2013 01:21:43 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5430
MAPREDUCE-5431,Bug,Major,build,Missing pom dependency in MR-client,There is a missing dependencies in the mr-client pom.xml that is exposed when running a mvn-rpmbuild against system dependencies.  Regular mvn build bypasses the issue via its default classpath.  patch provided by pmackinn@redhat.com,Closed,Fixed,HADOOP-10096,Timothy St. Clair,Timothy St. Clair,Thu; 30 May 2013 18:54:44 +0000,Thu; 12 May 2016 18:22:18 +0000,Wed; 13 Nov 2013 19:53:43 +0000,,2.1.0-beta;3.0.0-alpha1,maven,,,https://issues.apache.org/jira/browse/MAPREDUCE-5431
MAPREDUCE-5432,Bug,Major,jobhistoryserver;mrv2,JobHistoryParser does not fetch clockSplits; cpuUsages; vMemKbytes; physMemKbytes from history file,JobHistoryParser's handleMapAttemptFinishedEvent() function does not look at MapAttemptFinishedEvent's      int[] clockSplits;   int[] cpuUsages;   int[] vMemKbytes;   int[] physMemKbytes;  JobHistoryParser's inner class TaskAttemptInfo also needs to be enhanced to have these as members so that handleMapAttemptFinishedEvent() can get them and store them.,Open,Unresolved,,Tsuyoshi Ozawa,Vrushali C,Mon; 29 Jul 2013 19:59:15 +0000,Sat; 5 Oct 2013 21:46:45 +0000,,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5432
MAPREDUCE-5433,Improvement,Minor,examples,use mapreduce to parse hfiles and output keyvalue,nan,Resolved,Fixed,,rulinma,rulinma,Tue; 30 Jul 2013 07:00:07 +0000,Wed; 7 Aug 2013 02:39:57 +0000,Wed; 31 Jul 2013 02:28:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5433
YARN-995,Bug,Major,,WebAppException is thrown in appmaster logs if any task got failed,nan,Open,Unresolved,,Unassigned,Nishan Shetty,Tue; 30 Jul 2013 09:43:01 +0000,Wed; 18 Sep 2013 03:43:06 +0000,,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/YARN-995
MAPREDUCE-5435,Bug,Major,,Nodemanager stops working automatically,Hi Everyone;  I have been trying to setup a 10 node Hadoop Cluster(Hadoop 2.0.5 alpha). I've completed editing all the configuration files and am now trying to run the daemons. All the processes work fine apart from the nodemanager. The nodemanager runs fine on the slave however; on the master; it will only run for 10-15 sec and then stops. Same thing happens if I run the start command again.  Any suggestions?  Thanks in advance!,Resolved,Invalid,,Unassigned,Vishket,Tue; 30 Jul 2013 15:08:21 +0000,Tue; 30 Jul 2013 18:18:52 +0000,Tue; 30 Jul 2013 17:44:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5435
MAPREDUCE-5436,Bug,Major,,Better exception handling for Invalid AMRMToken exception for MapReduce,Nowadays; even though MR gets an InvalidToken Exception from RM; RMCommunicator just ignores it and continues looping and retry. we should explicitly handle such exception.,Open,Unresolved,,Jian He,Jian He,Tue; 30 Jul 2013 23:12:20 +0000,Wed; 31 Jul 2013 21:06:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5436
MAPREDUCE-5437,Bug,Major,,MR2 specific metrics should be collected,We have a usecase to show the below information. We can find job count by calling the  waiting.,Resolved,Won't Fix,,Unassigned,Srimanth Gunturi,Mon; 29 Jul 2013 19:31:47 +0000,Wed; 31 Jul 2013 04:27:03 +0000,Wed; 31 Jul 2013 04:27:03 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5437
MAPREDUCE-5438,Bug,Minor,documentation,JavaDoc generates partially for MultithreadedMapRunner,"The following code in MultithreadedMapRunner. does not get published to the HTML docs correctly.  This is what actually appears in the HTML docs: ""It can be used instead of the default implementation; ""  This is what should appear:  ",Resolved,Duplicate,MAPREDUCE-2815,Ananth Vikram Bommireddipalli,Ananth Vikram Bommireddipalli,Wed; 31 Jul 2013 18:29:03 +0000,Mon; 21 Jul 2014 17:42:40 +0000,Mon; 21 Jul 2014 17:42:30 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5438
MAPREDUCE-5439,Bug,Major,mrv2,mapred-default.xml has missing properties,Properties that need to be added: mapreduce.map.memory.mb mapreduce.map. opts should not be in mapred-default. yarn.app.mapreduce.am.command-opts description needs fixing,Open,Unresolved,,Unassigned,Siddharth Wagle,Wed; 31 Jul 2013 19:46:57 +0000,Sat; 7 Jan 2017 01:59:51 +0000,,,2.1.0-beta,,,AMBARI-2784,https://issues.apache.org/jira/browse/MAPREDUCE-5439
MAPREDUCE-5440,Bug,Major,mrv2,TestCopyCommitter Fails on JDK7,The testNoCommitAction is affected by the testPreserveStatus.  The testPreserveStatus leaves the CONF_LABEL_PRESERVE_STATUS set.,Closed,Fixed,,Robert Parker,Robert Parker,Wed; 31 Jul 2013 22:12:06 +0000,Tue; 10 Mar 2015 04:30:43 +0000,Fri; 2 Aug 2013 22:58:42 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5440
MAPREDUCE-5441,Sub-task,Major,applicationmaster;client,JobClient exit whenever RM issue Reboot command to 1st attempt App Master.,When RM issue Reboot command to app master; app master shutdown gracefully. All the history event are writtent to hdfs with job status set as ERROR. Jobclient get job state as ERROR and exit.   But RM launches 2nd attempt app master where no client are there to get job status.In RM UI; job status is displayed as SUCCESS but for client Job is Failed.,Closed,Fixed,YARN-1097,Jian He,Rohith Sharma K S,Thu; 1 Aug 2013 12:20:23 +0000,Sat; 5 Oct 2013 22:40:35 +0000,Thu; 29 Aug 2013 21:27:26 +0000,,2.1.0-beta;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5441
MAPREDUCE-5442,Bug,Major,client,$HADOOP_MAPRED_HOME/$HADOOP_CONF_DIR setting not working on Windows,"Currently the mapred-default.xml has ""mapreduce.application.classpath"" entry set to $HADOOP_MAPRED_HOME  which is problematic on Windows since the path does not work on Windows OS.  Additionally; the yarn-default.xml has ""yarn.application.classpath"" entry that has similar problem; and is currently being tracked by YARN-1138",Closed,Fixed,,Yingda Chen,Yingda Chen,Thu; 1 Aug 2013 23:14:34 +0000,Thu; 12 May 2016 18:23:09 +0000,Fri; 4 Oct 2013 05:53:09 +0000,,2.1.1-beta;3.0.0-alpha1,,,MAPREDUCE-5451;YARN-1138,https://issues.apache.org/jira/browse/MAPREDUCE-5442
MAPREDUCE-5443,Bug,Minor,,ClientId should have getMsb/getLsb methods,Both ClientId and RetryCache have the same logic to calculate msb and lsb. We should not have same logics in separate classes but have utility methods to do so in one class.,Resolved,Invalid,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Fri; 2 Aug 2013 04:47:16 +0000,Mon; 5 Aug 2013 05:39:00 +0000,Fri; 2 Aug 2013 04:50:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5443
MAPREDUCE-5444,Sub-task,Minor,applicationmaster,MRAppMaster throws InvalidStateTransitonException: Invalid event: JOB_AM_REBOOT at SUCCEEDED,nan,Resolved,Invalid,,Unassigned,Rohith Sharma K S,Fri; 2 Aug 2013 09:45:00 +0000,Fri; 2 Aug 2013 14:53:11 +0000,Fri; 2 Aug 2013 14:53:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5444
MAPREDUCE-5445,Bug,Major,mrv2;test,MRApp tries to stop services from AsyncDispatcher thread,MRApp tries to stop services from within a service thread.  That causes the stop call itself to be interrupted and not all services are stopped.,Open,Unresolved,,Unassigned,Jason Lowe,Fri; 2 Aug 2013 16:16:03 +0000,Fri; 2 Aug 2013 16:17:24 +0000,,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5445
MAPREDUCE-5446,Bug,Major,mrv2;test,TestJobHistoryEvents and TestJobHistoryParsing have race conditions,TestJobHistoryEvents and TestJobHistoryParsing are not properly waiting for MRApp to finish.  Currently they are polling the service state looking for Service.STATE.STOPPED; but the service can appear to be in that state before it is fully stopped.  This causes tests to finish with MRApp threads still in-flight; and those threads can conflict with subsequent tests when they collide in the filesystem.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 2 Aug 2013 18:10:51 +0000,Wed; 3 Sep 2014 23:48:12 +0000,Mon; 5 Aug 2013 16:09:31 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5446
MAPREDUCE-5447,Bug,Minor,jobhistoryserver,When a job state is ERROR ; total map and reduce task are displayed as 0 in JHS home page ; while navigating inside the respective job page displays the correct total. ,When a job state is in error ; total map and reduce task are displayed as 0 in JHS home page ; while navigating inside the respective job page displays the correct total.  JHS Homepage: ============ Total Map and Reduce Task are 0  Job Page: ========= Total Map task    -2 Total Reduce task -1  successful Map Attempts -2,Resolved,Duplicate,MAPREDUCE-5174,Unassigned,J.Andreina,Mon; 5 Aug 2013 05:26:34 +0000,Mon; 5 Aug 2013 07:05:49 +0000,Mon; 5 Aug 2013 07:05:49 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5447
MAPREDUCE-5448,Bug,Minor,mrv2,MapFileOutputFormat#getReaders bug with invisible files/folders,"MapReduce jobs also produce some invisible files such as _SUCCESS; even when the output format is MapFileOutputFormat. MapFileOutputFormat#getReaders however reads the entire content of the job output; assming that they are MapFiles.   It should use a filter to skip the files that start with ""."" or ""_"".",Resolved,Fixed,,Maysam Yabandeh,Maysam Yabandeh,Mon; 5 Aug 2013 08:28:13 +0000,Tue; 30 Aug 2016 01:20:30 +0000,Sun; 22 Mar 2015 04:26:27 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5448
MAPREDUCE-5449,Improvement,Major,jobtracker,Jobtracker WebUI Add acl to control access to views of submitted jobs,Jobtracker WebUI currently displays the job name for every job submitted. Would like the ability to apply ACL's so that users groups can only see the job's they have submitted and not all the jobs submitted to the cluster. Hive queries put the query as the job name in job tracker. This query information can contain sensitive information; currently the only way to limit access is to limit access to the job tracker ui which reduces the job owners ability to troubleshoot issues,Open,Unresolved,,Unassigned,Christopher LaPlante,Mon; 5 Aug 2013 19:50:36 +0000,Tue; 6 Aug 2013 20:22:39 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5449
MAPREDUCE-5450,Bug,Blocker,mrv1,Unnecessary Configuration instantiation in IFileInputStream slows down merge - Port to branch-1,We are using hadoop-2.0.0+1357-1.cdh4.3.0.p0.21 with MRv1. After upgrade from 4.1.2 to 4.3.0; I have noticed some performance deterioration in our MR job in the Reduce phase. The MR job has usually 10 000 map tasks (10 000 files on input each about 100MB) and 6 000 reducers (one reducer per table region). I was trying to figure out wh least 1.6 hours longer than it should be.,Resolved,Fixed,,Stanislav Barton,Stanislav Barton,Tue; 6 Aug 2013 02:10:03 +0000,Sun; 13 Dec 2015 00:32:52 +0000,Wed; 7 Aug 2013 20:01:23 +0000,,1.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5450
MAPREDUCE-5451,Bug,Major,,MR uses LD_LIBRARY_PATH which doesn't mean anything in Windows,In order to set the path for loading native libraries; MR relies on the default value of the mapreduce.admin.user.env configuration setting the LD_LIBRARY_PATH environment entry. There are two problems with this setting in Windows: a) LD_LIBRARY_PATH doesn't mean anything in Windows. b) It sets it using $HADOOP_COMMON_HOME; instead of %HADOOP_COMMON_HOME%.  The default value here should be platform-dependent (use the PATH variable in Windows instead of LD_LIBRARY_PATH); or we should rely on another mechanism. The net effect is that in Windows unless this configuration is over-ridden MR jobs fail with this error:,Closed,Fixed,,Yingda Chen,Mostafa Elhemali,Thu; 30 May 2013 00:08:18 +0000,Thu; 12 May 2016 18:22:48 +0000,Wed; 6 Nov 2013 18:24:26 +0000,,2.1.1-beta;3.0.0-alpha1,,,MAPREDUCE-5442;HADOOP-11285;YARN-1025,https://issues.apache.org/jira/browse/MAPREDUCE-5451
MAPREDUCE-5452,Bug,Minor,,NPE in TaskID toString when default constructor is used,If you call TaskID.toString() after using the default the constructor toString() NPE's because taskType is null.,Open,Unresolved,,Unassigned,Brock Noland,Fri; 9 Aug 2013 14:47:46 +0000,Thu; 19 Dec 2013 14:14:37 +0000,,,2.0.5-alpha,,,HIVE-4216,https://issues.apache.org/jira/browse/MAPREDUCE-5452
MAPREDUCE-5453,Bug,Major,,File System Counters can NOT be updated in streaming application,It seems that FILE_BYTES_READ HADOOP-3001  and that's why it is NOT properly handled by streaming.jar.  The implementation of File System counter is a bit different; and it keeps track of the real information in FileSystem.Statistics object. When the task finished; the framework would read the info from 'FileSystem.Statistics' and set the File System counters accordingly.  Therefore; the regular way to update counters  ' findCounter() and Counter.incrment() ' would NOT work for the File System counters as they would be overwritten by the info in 'FileSystem.Statistics ' eventually. However; it seems that the 'reporter:counter:' scheme in streaming.jar is implemented by the regular way; and maybe that's why it is not working.,Open,Unresolved,,Unassigned,Danica Zhang,Fri; 9 Aug 2013 20:07:21 +0000,Fri; 9 Aug 2013 20:08:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5453
MAPREDUCE-5454,Bug,Major,test,TestDFSIO fails intermittently on JDK7,TestDFSIO occasionally fails on JDK7,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 9 Aug 2013 21:09:01 +0000,Mon; 3 Nov 2014 18:33:41 +0000,Tue; 13 Aug 2013 07:19:20 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5454
MAPREDUCE-5455,Improvement,Major,mrv1;mrv2,Support FixedLengthOutputFormat,This is a complement to MAPREDUCE-1176 to support fixed length records on output.,Open,Unresolved,,Mariappan Asokan,Mariappan Asokan,Mon; 12 Aug 2013 15:27:23 +0000,Mon; 12 Aug 2013 15:41:56 +0000,,,,,,MAPREDUCE-1176,https://issues.apache.org/jira/browse/MAPREDUCE-5455
MAPREDUCE-5456,Bug,Minor,mrv2;test,TestFetcher.testCopyFromHostExtraBytes is missing,I noticed that the test to verify the fix from MAPREDUCE-5308 was deleted by MAPREDUCE-5194.  It looks like an accidental deletion from an upmerge.   We should reinstate this unit test.,Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 12 Aug 2013 19:38:25 +0000,Wed; 3 Sep 2014 20:33:53 +0000,Thu; 13 Mar 2014 20:51:26 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5456
MAPREDUCE-5457,Improvement,Major,,Add a KeyOnlyTextOutputReader to enable streaming to write out text files without separators,MR jobs sometimes want to just output lines of text; not key value pairs.  TextOutputFormat handles this by; if a null value is given; outputting only the key with no separator.  Streaming jobs are unable to take advantage of this; because they can't output null values.  A text output format reader takes each line as a key and outputs NullWritables for values would allow streaming jobs to output lines of text.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 14 Aug 2013 00:21:41 +0000,Mon; 24 Feb 2014 20:58:30 +0000,Fri; 18 Oct 2013 20:46:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5457
MAPREDUCE-5458,Improvement,Major,jobhistoryserver,Jobhistory server (and probably others) throws HTTP 500 error if keytab fails,I had a situation where the job history didn't renew its kerberos credentials (still verifying that problem).  If a user connects to the web UI at a point when the server can't talk to HDFS; it shows the user a 500 error rather than giving something meaningful.,Open,Unresolved,,Unassigned,Allen Wittenauer,Wed; 14 Aug 2013 20:56:53 +0000,Wed; 14 Aug 2013 20:56:53 +0000,,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5458
MAPREDUCE-5459,Bug,Major,,Update the doc of running MRv1 examples jar on YARN,In addition to adding two env vars: HADOOP_USER_CLASSPATH_FIRST and HADOOP_CLASSPATH; we still need to add   in mapred-site.xml to make sure that the MRv1 examples jar runs correctly on YARN. Some examples will use Java reflection to find the classes in the examples jar dynamically when they are running. With this configuration; the MRv1 examples jar will appear before the MRv2 examples jar in CLASSPATH of the processes in YARN containers. Therefore; the classes found via reflection will be picked from MRv1 examples jar instead of MRv2 examples jar as well.  MapReduce_Compatibility_Hadoop1_Hadoop2.apt.vm needs to be updated to document this.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Wed; 14 Aug 2013 21:05:31 +0000,Tue; 30 Jun 2015 07:18:59 +0000,Wed; 2 Oct 2013 21:10:24 +0000,,,,,MAPREDUCE-5184,https://issues.apache.org/jira/browse/MAPREDUCE-5459
YARN-1112,Bug,Major,,MR AppMaster command options does not replace @taskid@ with the current task ID.,The description of yarn.app.mapreduce.am.command-opts in mapred-default.xml states that occurrences of @taskid@ will be replaced by the current task ID.  This substitution is not happening.,Open,Unresolved,,Unassigned,Chris Nauroth,Wed; 14 Aug 2013 22:08:16 +0000,Thu; 12 May 2016 18:30:29 +0000,,,2.1.1-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/YARN-1112
MAPREDUCE-5461,Improvement,Major,task,Let users be able to get latest Key in reduce(),Reducer generates K; List(V) for reduce(). In some cases such as SecondarySort; although current V and next V share the same K; their actual corresponding Ks are different. For example; in SecondarySort; map() outputs Key         Value 1; 3        3 1; 1        1 2; 5        5 1; 8        8  After partition by Key.getFirst(); sort and group by Key.getFirst(); reducer gets: Key         Value -----Group 1----- 1; 1        1 1; 3        3 1; 8        8 -----Group 2----- 2; 5        5  reduce() receives:  Key      ListValue 1; 1   List1; 3; 8 2; 5   List5  When invoking V.next(); we can get next V (e.g; 3). But we do not have API to get its corresponding Key (e.g; 1; 3). We can only get the first Key (e.g.; 1;1).  If we let user be able to get latest key; SecondarySort does not need to emit value in map(). So that the network traffic is better.  Another example is Join. If we can get latest Key; we do not need to put table label in both key and value.,Open,Unresolved,,Unassigned,Lijie Xu,Thu; 15 Aug 2013 15:34:29 +0000,Thu; 15 Aug 2013 15:36:21 +0000,,,1.2.1,features,,,https://issues.apache.org/jira/browse/MAPREDUCE-5461
MAPREDUCE-5462,Sub-task,Major,performance;task,In map-side sort; swap entire meta entries instead of indexes for better cache performance ,nan,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 15 Aug 2013 19:46:42 +0000,Tue; 24 Sep 2013 23:33:41 +0000,Fri; 16 Aug 2013 08:26:07 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5462
MAPREDUCE-5463,Task,Major,,Deprecate SLOTS_MILLIS counters,As discussed in MAPREDUCE-5311; the SLOTS_MILLIS_MAPS and SLOTS_MILLIS_REDUCES counters don't really make sense in MR2; and should be deprecated so that they can eventually be removed.,Closed,Fixed,,Tsuyoshi Ozawa,Sandy Ryza,Thu; 15 Aug 2013 22:09:08 +0000,Mon; 24 Feb 2014 20:57:36 +0000,Mon; 14 Oct 2013 09:13:09 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5463
MAPREDUCE-5464,Task,Major,,Add analogs of the SLOTS_MILLIS counters that jive with the YARN resource model,Per discussion on MAPREDUCE-5311; it would be good to have analogs for SLOTS_MILLIS that better fit the MR2 resource model.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 15 Aug 2013 22:13:22 +0000,Fri; 11 Apr 2014 17:24:27 +0000,Tue; 28 Jan 2014 21:11:16 +0000,,2.1.0-beta,,,MAPREDUCE-5831,https://issues.apache.org/jira/browse/MAPREDUCE-5464
MAPREDUCE-5465,Improvement,Major,mr-am;mrv2,Tasks are often killed before they exit on their own,If there is profiling enabled for mapper or reducer then hprof dumps profile.out at process exit. It is dumped after task signaled to AM that work is finished.  AM kills container with finished work without waiting for hprof to finish dumps. If hprof is dumping larger outputs (such as with depth=4 while depth=3 works) ; it could not finish dump in time before being killed making entire dump unusable because cpu and heap stats are missing.  There needs to be better delay before container is killed if profiling is enabled.,Resolved,Fixed,,Ming Ma,Radim Kolar,Sun; 3 Mar 2013 15:26:02 +0000,Tue; 30 Aug 2016 01:20:27 +0000,Mon; 11 May 2015 22:41:14 +0000,,,,,MAPREDUCE-6735,https://issues.apache.org/jira/browse/MAPREDUCE-5465
MAPREDUCE-5466,Sub-task,Blocker,,Historyserver does not refresh the result of restarted jobs after RM restart,"Restart RM when sort job is running and verify that the job passes successfully after RM restarts.   Once the job finishes successfully; run job status command for sort job. It shows ""Job state =FAILED"". Job history server does not update the result for the job which restarted after RM restart.  hadoop job -status job_1375923346354_0003   INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server  Job: job_1375923346354_0003 Job File: hdfs: job_1375923346354_0003 Uber job : false Number of maps: 80 Number of reduces: 1 map() completion: 0.0 reduce() completion: 0.0 Job state: FAILED retired: false reason for failure: There are no failed tasks for the job. Job is failed due to some other reason and reason can be found in the logs. Counters not available. Job is retired.",Closed,Fixed,MAPREDUCE-5401,Jian He,Yesha Vora,Sun; 18 Aug 2013 02:23:29 +0000,Sat; 5 Oct 2013 22:39:59 +0000,Wed; 21 Aug 2013 18:19:06 +0000,,,,,YARN-128,https://issues.apache.org/jira/browse/MAPREDUCE-5466
MAPREDUCE-5467,Improvement,Major,,Hierarchical pools in the Fair Scheduler in Hadoop 1.0.x,Allow pools to have subpools with preemption.,Open,Unresolved,,Aniket Mokashi,Steven K. Wong,Mon; 19 Aug 2013 19:23:39 +0000,Tue; 27 Aug 2013 05:04:39 +0000,,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5467
MAPREDUCE-5468,Bug,Blocker,,AM recovery does not work for map only jobs,Map only job (randomwriter; randomtextwriter) restarts from scratch 0% map 0% reduce after RM restart. It should resume from the last state when AM restarted.,Closed,Fixed,,Vinod Kumar Vavilapalli,Yesha Vora,Tue; 20 Aug 2013 01:58:22 +0000,Tue; 24 Sep 2013 23:33:27 +0000,Thu; 22 Aug 2013 01:53:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5468
MAPREDUCE-5469,Improvement,Major,,Counters for MRAppMaster,We have counters for map tasks and reduce tasks ;but has no counters for MRAppMaster. Sometimes we need information like GC time;memory usage for AM tuning.,Resolved,Duplicate,MAPREDUCE-4804,Unassigned,Nemon Lou,Tue; 20 Aug 2013 06:46:54 +0000,Tue; 20 Aug 2013 13:30:11 +0000,Tue; 20 Aug 2013 13:30:11 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5469
MAPREDUCE-5470,Bug,Major,,LocalJobRunner does not work on Windows.,"LocalJobRunner#getLocalTaskDir creates a directory that is unique to the task ID.  The logic of this method concatenates the local job dir and a task-specific path; but one of the arguments is a Path with a scheme; so the final result has ""file:"" embedded in it.  This works on Linux; but the ':' is an invalid character in a file name on Windows.",Closed,Fixed,,Sandy Ryza,Chris Nauroth,Tue; 20 Aug 2013 23:48:09 +0000,Thu; 12 May 2016 18:24:06 +0000,Fri; 23 Aug 2013 17:05:39 +0000,,2.1.1-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5470
MAPREDUCE-5471,Sub-task,Blocker,,Succeed job tries to restart after RMrestart,Run a job ; restart RM when job just finished. It should not restart the job once it Succeed.  After RM restart; The AM of restarted job fails with below error.  AM log after Rmrestart:  013-08-19 17:29:21;144 INFO main org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0 2013-08-19 17:29:21;145 INFO main org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop() 2013-08-19 17:29:21;146 INFO main org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs: job_1376933101704_0001 2013-08-19 17:29:21;156 FATAL main org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster org.apache.hadoop.yarn.exceptions.YarnRuntimeException:  54),Resolved,Duplicate,MAPREDUCE-5127;YARN-540,Jian He,Yesha Vora,Tue; 20 Aug 2013 23:34:56 +0000,Sat; 5 Oct 2013 22:39:03 +0000,Mon; 16 Sep 2013 17:38:08 +0000,,,,,YARN-540;YARN-128,https://issues.apache.org/jira/browse/MAPREDUCE-5471
MAPREDUCE-5472,Bug,Critical,,reducer of sort job restarts from scratch in between after RM restart,Steps Followed: 1) Run a sort job. As soon as it finishes all the map tasks. 100% map; restart resource manager.  2) Analyse the progress of the sort job. It starts with 100% map 0% reduce 100% map 32% reduce 100% map 0% reduce Reducer stays  org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.read(RawLocalFileSystem. 171) ... 26 more,Resolved,Cannot Reproduce,,Omkar Vinit Joshi,Yesha Vora,Tue; 20 Aug 2013 23:26:47 +0000,Thu; 29 Aug 2013 18:59:21 +0000,Thu; 29 Aug 2013 18:59:10 +0000,,,,,YARN-128,https://issues.apache.org/jira/browse/MAPREDUCE-5472
MAPREDUCE-5473,Bug,Major,mrv1,JT webservices use a static SimpleDateFormat; SImpleDateFormat is not threadsafe,MAPREDUCE-4837 is doing:     But SimpleDateFormat is not thread safe.,Open,Unresolved,,Unassigned,Alejandro Abdelnur,Wed; 21 Aug 2013 06:18:13 +0000,Wed; 21 Aug 2013 06:18:13 +0000,,,1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5473
MAPREDUCE-5474,Bug,Major,,Add support for mapreduce.reduce.input.limit in MR2,In MR1 we could set mapreduce.reduce.input.limit to control the reduce input limit and it defaults to -1 meaning no limit.  There is no such property in MR2,Open,Unresolved,,Unassigned,Arpit Gupta,Wed; 21 Aug 2013 17:33:22 +0000,Wed; 21 Aug 2013 17:33:22 +0000,,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5474
MAPREDUCE-5475,Bug,Blocker,mr-am;mrv2,MRClientService does not verify ACLs properly,When MRClientService receives requests; it calls verifyAndGetJob which does not actually validate that the current user has the proper access.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 21 Aug 2013 18:29:11 +0000,Tue; 24 Sep 2013 23:33:20 +0000,Wed; 4 Sep 2013 22:39:17 +0000,,2.0.4-alpha;0.23.9,,YARN-707,,https://issues.apache.org/jira/browse/MAPREDUCE-5475
MAPREDUCE-5476,Sub-task,Blocker,,Job can fail when RM restarts after staging dir is cleaned but before MR successfully unregister with RM,nan,Closed,Fixed,MAPREDUCE-4841,Jian He,Jian He,Fri; 12 Jul 2013 17:54:34 +0000,Fri; 1 May 2015 12:48:13 +0000,Thu; 22 Aug 2013 23:18:51 +0000,,,,,YARN-128;YARN-907;MAPREDUCE-4819,https://issues.apache.org/jira/browse/MAPREDUCE-5476
MAPREDUCE-5477,Bug,Major,,"In JHS wrong values coming for following fields ""Average Reduce Time;Average Shuffle Time;Average Merge Time""",If multiple app master attempts are there wrong values are coming for following fields,Open,Unresolved,,Unassigned,Nishan Shetty,Thu; 22 Aug 2013 10:32:30 +0000,Thu; 22 Aug 2013 10:32:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5477
MAPREDUCE-5478,Improvement,Minor,examples,TeraInputFormat unnecessarily defines its own FileSplit subclass,TeraInputFormat defines its own TeraFileSplit subclass of FileSplit that adds a locations field; which is already included in FileSplit.  This is causing MR2 TeraSort to fail on MR1; which; for a System.arraycopy; requires splits to be of the FileSplit class.  While nobody is promising that everything that runs on MR2 should run on MR1; fixing this would be easy and make it possible to compare MR2 TeraSort performance between MR1 and MR2.  We should just get rid of TeraFileSplit and use FileSplit.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Fri; 23 Aug 2013 00:14:29 +0000,Tue; 24 Sep 2013 23:33:29 +0000,Fri; 23 Aug 2013 21:28:57 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5478
YARN-1094,Bug,Blocker,,RM restart throws Null pointer Exception in Secure Env,Enable rmrestart feature And restart Resorce Manager while a job is running.  Resorce Manager fails to start with below error  2013-08-23 17:57:40;705 INFO  resourcemanager.RMAppManager (RMAppManager. terminate(124)) - Exiting with status 1,Closed,Fixed,,Vinod Kumar Vavilapalli,Yesha Vora,Fri; 23 Aug 2013 19:06:17 +0000,Tue; 24 Sep 2013 23:33:30 +0000,Sat; 24 Aug 2013 23:34:10 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-1094
MAPREDUCE-5480,Bug,Blocker,,TestJSHSecurity.testDelegationToken is breaking after YARN-1085,See https: .,Resolved,Duplicate,YARN-1085,Omkar Vinit Joshi,Vinod Kumar Vavilapalli,Sat; 24 Aug 2013 21:28:04 +0000,Tue; 27 Aug 2013 17:32:28 +0000,Tue; 27 Aug 2013 17:32:28 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5480
MAPREDUCE-5481,Bug,Blocker,mrv2;test,Enable uber jobs to have multiple reducers ,TestUberAM has been timing out on trunk for some time now and surefire then fails the build.  I'm not able to reproduce it locally; but the Jenkins builds have been seeing it fairly consistently.  See https: console  This is caused by changes made in MAPREDUCE-434 breaking Uber AMs.  The easiest fix is to make similar changes in Uber AMs to those in MAPREDUCE-434 to allow multiple reducers.,Closed,Fixed,,Sandy Ryza,Jason Lowe,Mon; 26 Aug 2013 14:41:53 +0000,Thu; 12 May 2016 18:22:41 +0000,Thu; 14 Nov 2013 08:07:27 +0000,,2.3.0;3.0.0-alpha1,,,MAPREDUCE-5502,https://issues.apache.org/jira/browse/MAPREDUCE-5481
MAPREDUCE-5482,Bug,Major,task,Release kvoffsets and kvindices before going to merge phase,"In org.apache.hadoop.mapred.MapTask.MapOutputBuffer.flush() method; we only released the kvbuffer before the merge phase (i.e.; mergeParts()). Though kvindices and kvoffsets are small in many cases; we should release them theoretically before mergeParts().  try  {         spillThread.interrupt();         spillThread.join();       }  catch (InterruptedException e)  {         throw (IOException)new IOException(""Spill failed""             ).initCause(e);       }         release sort buffer before the merge       kvbuffer = null;       mergeParts();       Path outputPath = mapOutputFile.getOutputFile();       fileOutputByteCounter.increment(rfs.getFileStatus(outputPath).getLen());     }",Open,Unresolved,,Unassigned,Lijie Xu,Tue; 27 Aug 2013 02:38:35 +0000,Tue; 27 Aug 2013 02:38:35 +0000,,,1.2.0,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-5482
MAPREDUCE-5483,Bug,Major,distcp,revert MAPREDUCE-5357,MAPREDUCE-5357 does a fileystem chown() operation. chown() is not valid unless you are superuser. if you a chown() to yourself is a NOP; that is why has not been detected in Hadoop testcases where user is running as itself. However; in distcp testcases run by Oozie which use test users groups from UGI for minicluster it is failing because of this chown() either because the test user does not exist of because the current use does not have privileges to do a chown().  We should revert MAPREDUCE-5357. Windows should handle this with some conditional logic used only when running in Windows.  Opening a new JIRA and not reverting directly because MAPREDUCE-5357 went in 2.1.0-beta.,Closed,Fixed,,Robert Kanter,Alejandro Abdelnur,Tue; 27 Aug 2013 18:22:03 +0000,Tue; 24 Sep 2013 23:33:19 +0000,Thu; 29 Aug 2013 19:28:44 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5483
MAPREDUCE-5484,Improvement,Major,task,YarnChild unnecessarily loads job conf twice,In MR task processes; a JobConf is instantiated with the same job.xml twice; once at the beginning of main() and once in configureTask.  IIUC; the second instantiation is not necessary.  These take time reading from disk and parsing XML.  Removing the second instantiation shaved a second off the average map task time in a 1;000-map sleep job.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 28 Aug 2013 08:41:44 +0000,Mon; 24 Feb 2014 20:57:44 +0000,Thu; 29 Aug 2013 23:54:49 +0000,,2.1.0-beta,perfomance,,,https://issues.apache.org/jira/browse/MAPREDUCE-5484
MAPREDUCE-5485,Improvement,Critical,,Allow repeating job commit by extending OutputCommitter API,There are chances MRAppMaster crush during job committing;or NodeManager restart cause the committing AM exit due to container expire.In these cases ;the job will fail. However;some jobs can redo commit so failing the job becomes unnecessary. Let clients tell AM to allow redo commit or not is a better choice. This idea comes from Jason Lowe's comments in MAPREDUCE-4819,Closed,Fixed,MAPREDUCE-6437,Junping Du,Nemon Lou,Wed; 28 Aug 2013 13:07:29 +0000,Wed; 22 Feb 2017 23:10:05 +0000,Tue; 17 Nov 2015 01:14:41 +0000,,2.1.0-beta,,,MAPREDUCE-6478;MAPREDUCE-4815;MAPREDUCE-6545,https://issues.apache.org/jira/browse/MAPREDUCE-5485
YARN-1145,Bug,Major,,Potential file handle leak in aggregated logs web ui,Any problem in getting aggregated logs for rendering on web ui; then LogReader is not closed.   Now; it reader is not closed which causing many connections in close_wait state.  hadoopuser@hadoopuser: jps 27909 JobHistoryServer  DataNode port is 50010. When greped with DataNode port; many connections are in CLOSE_WAIT from JHS. hadoopuser@hadoopuser: netstat -tanlp |grep 50010 tcp        0      0 10.18.40.48:50010       0.0.0.0:*               LISTEN      21453 java,Closed,Fixed,,Rohith Sharma K S,Rohith Sharma K S,Thu; 29 Aug 2013 06:02:31 +0000,Mon; 24 Feb 2014 20:56:45 +0000,Mon; 16 Dec 2013 19:29:20 +0000,,2.0.5-alpha;0.23.9;2.1.1-beta,,,,https://issues.apache.org/jira/browse/YARN-1145
MAPREDUCE-5487,Improvement,Major,performance;task,In task processes; JobConf is unnecessarily loaded again in Limits,Limits statically loads a JobConf; which incurs costs of reading files from disk and parsing XML.  The contents of this JobConf are identical to the one loaded by YarnChild (before adding job.xml as a resource).  Allowing Limits to initialize with the JobConf loaded in YarnChild would reduce task startup time.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 29 Aug 2013 19:36:26 +0000,Mon; 24 Feb 2014 20:58:03 +0000,Wed; 18 Sep 2013 13:59:56 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5487
MAPREDUCE-5488,Bug,Major,,Job recovery fails after killing all the running containers for the app,Here is the client stack trace,Closed,Fixed,,Jian He,Arpit Gupta,Fri; 30 Aug 2013 18:54:48 +0000,Tue; 30 Jun 2015 07:18:58 +0000,Thu; 19 Sep 2013 22:43:38 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5488
MAPREDUCE-5489,Bug,Critical,,MR jobs hangs as it does not use the node-blacklisting feature in RM requests,When RM restarted; if during restart one NM went bad (bad disk); NM got blacklisted by AM and RM keeps giving the containers on the same node even though AM doesn't want it there.  Need to change AM to specifically blacklist node in the RM requests.,Closed,Fixed,,Zhijie Shen,Yesha Vora,Fri; 30 Aug 2013 21:02:13 +0000,Tue; 30 Jun 2015 07:14:42 +0000,Thu; 3 Oct 2013 21:15:55 +0000,,,,YARN-1141,YARN-1133;MAPREDUCE-5559,https://issues.apache.org/jira/browse/MAPREDUCE-5489
MAPREDUCE-5490,Bug,Major,,MapReduce doesn't set the environment variable for children processes,Currently; MapReduce uses the command line argument to pass the classpath to the child. This breaks if the process forks a child that needs the same classpath. Such a case happens in Hive when it uses map-side joins. I propose that we make MapReduce in branch-1 use the CLASSPATH environment variable like YARN does.,Patch Available,Unresolved,,Owen O'Malley,Owen O'Malley,Fri; 30 Aug 2013 23:13:46 +0000,Tue; 18 Aug 2015 18:19:52 +0000,,,1.2.1,BB2015-05-TBR,,MAPREDUCE-6454,https://issues.apache.org/jira/browse/MAPREDUCE-5490
MAPREDUCE-5491,Bug,Major,benchmarks;test,DFSIO do not initialize write buffer correctly,In DFSIO test; the IOMapperBase will set bufferSize in configure method; while writeMapper; appendMapper etc use bufferSize to initialize buffer in the constructor. This will lead to buffer not initialized at all. It is ok for non compression route; while compression is used; the output data size will be very small due to all 0 in buffer.  Thus; the overrided configure method should be be the correct place for initial buffer,Patch Available,Unresolved,,Raymond Liu,Raymond Liu,Tue; 3 Sep 2013 02:10:33 +0000,Wed; 6 May 2015 03:27:38 +0000,,,,BB2015-05-TBR,,MAPREDUCE-5125,https://issues.apache.org/jira/browse/MAPREDUCE-5491
MAPREDUCE-5492,Improvement,Trivial,,Suppress expected log output stated on MAPREDUCE-5,Jetty in MR1 may produce an expected EOFException during its operation that we shouldn't log out in ERROR form.  This shouldn't affect MR2; however; as it uses Netty.  See MAPREDUCE-5 (Jothi's comments) for more info.,Resolved,Won't Fix,,bc Wong,Harsh J,Tue; 3 Sep 2013 06:45:06 +0000,Thu; 5 Feb 2015 17:46:38 +0000,Thu; 5 Feb 2015 17:46:38 +0000,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5492
MAPREDUCE-5493,Bug,Blocker,mrv2,In-memory map outputs can be leaked after shuffle completes,MergeManagerImpl#close adds the contents of inMemoryMergedMapOutputs and inMemoryMapOutputs to a list of map outputs that is subsequently processed; but it does not clear those sets.  This prevents some of the map outputs from being garbage collected and significantly reduces the memory available for the subsequent reduce phase.,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 3 Sep 2013 21:51:15 +0000,Wed; 19 Mar 2014 18:42:55 +0000,Mon; 16 Sep 2013 14:20:24 +0000,,2.1.0-beta;0.23.9,,,TEZ-953,https://issues.apache.org/jira/browse/MAPREDUCE-5493
MAPREDUCE-5494,New Feature,Major,mrv2,Hash-based MapReduce,To support parallel processing; the MapReduce computation model essentially implements group data by key; then apply the reduce function to each group. The currently implementation of MapReduce framework uses sort-merge to guarantee the computation model. While  sort-merge  is relatively expensive when only grouping is needed. And this is wh MapReduce users should not depends on the order of different keys. The order of the keys are implied by the sort-merge process but will no longer implied when using hash for grouping keys.   This work is implemented based on the pluggable MapOutputCollector (Map side) and ShuffleConsumerPlugin (Reduce side) provided by MAPREDUCE-2454. There are no modifications to the existing MapReduce code and so keep the affect to the original implementation to minimum. The hash-based MapReduce is not used by default. To enable Hash-based MapReduce; set  mapreduce.job.map.output.collector.class  to HashMapOutputCollector class and  mapreduce.job.reduce.shuffle.consumer.plugin.class  to HashShuffle class.,Open,Unresolved,,Jerry Chen,Jerry Chen,Wed; 4 Sep 2013 03:15:51 +0000,Tue; 10 Mar 2015 04:30:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5494
MAPREDUCE-5495,Bug,Minor,jobtracker,Make url in JobProfile work when set mapred.job.tracker to 0.0.0.0:<port>,When there are multiple NICs and JobTracker need listen on all NICs; for example when set mapred.job.tracker to 0.0.0.0:8021; then getJobTrackerMachine() will return 0.0.0.0; it cause some problems; for example url in JobProfile won't work. Set this to a hostname can make it work.,Open,Unresolved,,yunjiong zhao,yunjiong zhao,Wed; 4 Sep 2013 06:57:42 +0000,Thu; 29 May 2014 21:54:12 +0000,,,1.1.2,,,HDFS-3150,https://issues.apache.org/jira/browse/MAPREDUCE-5495
MAPREDUCE-5496,Improvement,Minor,documentation,Document mapreduce.cluster.administrators in mapred-default.xml,mapreduce.cluster.administrators is not documented anywhere. We should document it in mapred-default.xml.,Open,Unresolved,,Wilfred Spiegelenburg,Srimanth Gunturi,Wed; 4 Sep 2013 21:49:46 +0000,Thu; 4 May 2017 03:58:28 +0000,,,2.1.0-beta,,,MAPREDUCE-5762,https://issues.apache.org/jira/browse/MAPREDUCE-5496
MAPREDUCE-5497,Bug,Major,,'5s sleep'  in MRAppMaster.shutDownJob is only needed before stopping ClientService,Since the '5s sleep' is for the purpose to let clients know the final states; put it after other services are stopped and only before stopping ClientService is enough. This can reduce some race conditions like MAPREDUCE-5471,Closed,Fixed,,Jian He,Jian He,Wed; 4 Sep 2013 23:57:43 +0000,Tue; 24 Sep 2013 23:33:13 +0000,Wed; 11 Sep 2013 00:41:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5497
MAPREDUCE-5498,Bug,Minor,build,maven Junit dependency should be test only,The maven dependencies for the YARN artifacts don't restrict to test time; so it gets picked up by all downstream users.,Resolved,Duplicate,HADOOP-9935,Andr   Kelpe,Steve Loughran,Fri; 6 Sep 2013 15:30:38 +0000,Thu; 12 May 2016 18:23:22 +0000,Sun; 15 Sep 2013 04:53:53 +0000,,2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5498
MAPREDUCE-5499,Bug,Major,,Fix synchronization issues of the setters/getters of *PBImpl which take in/return lists,Similar to YARN-609. There're the following *PBImpls which need to be fixed: 1. GetDiagnosticsResponsePBImpl 2. GetTaskAttemptCompletionEventsResponsePBImpl 3. GetTaskReportsResposnePBImpl 4. CounterGroupPBImpl 5. JobReportPBImpl 6. TaskReportPBImpl,Patch Available,Unresolved,,Xuan Gong,Zhijie Shen,Mon; 9 Sep 2013 00:04:02 +0000,Wed; 6 May 2015 03:34:29 +0000,,,,BB2015-05-TBR,,YARN-609,https://issues.apache.org/jira/browse/MAPREDUCE-5499
MAPREDUCE-5500,Bug,Major,mr-am,Accessing task page for running job throw 500 Error code,For running jobs on Hadoop 2.0; trying to access Task counters page throws Server 500 error. Digging a bit I see this exception in MRAppMaster logs     This looks to be critical bug because unable to access counters will be major setback for users to be able to debug running jobs.  Note that same job counters work fine if we access it from JobHistoryServer,Resolved,Duplicate,MAPREDUCE-5137,Paul Han,Paul Han,Mon; 9 Sep 2013 20:42:33 +0000,Thu; 12 Sep 2013 00:09:40 +0000,Thu; 12 Sep 2013 00:05:09 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5500
MAPREDUCE-5501,Bug,Major,resourcemanager,RMContainer Allocator does not stop when cluster shutdown is performed in tests,After running MR job client tests many MRAppMaster processes stay alive. The reason seems that RMContainer Allocator thread ignores InterruptedException and keeps retrying:     It takes  6 minutes for the processes to die; and this causes various issues with tests which use the same DFS dir.      Will attach a thread dump separately.,Resolved,Won't Fix,,Andrey Klochkov,Andrey Klochkov,Tue; 10 Sep 2013 05:58:54 +0000,Tue; 10 Mar 2015 04:30:43 +0000,Wed; 11 Sep 2013 23:02:56 +0000,,,,,YARN-1183,https://issues.apache.org/jira/browse/MAPREDUCE-5501
MAPREDUCE-5502,Bug,Major,resourcemanager,History link in resource manager is broken for KILLED jobs,"History link in resource manager is broken for KILLED jobs.  Seems to happen with jobs with State 'KILLED' and FinalStatus 'KILLED'. If the State is 'FINISHED' and FinalStatus is 'KILLED'; then the ""History"" link is fine.  It isn't easy to reproduce the problem since the time at which the app is killed determines the state it ends up in; which is hard to guess. these particular jobs seem to get a Diagnostics message of ""Application killed by user."" where as the other killed jobs get "" Kill Job received from client job_1378766187901_0002 Job received Kill while in RUNNING state. """,Open,Unresolved,MAPREDUCE-5581;MAPREDUCE-6135,Vrushali C,Vrushali C,Tue; 10 Sep 2013 22:18:53 +0000,Thu; 23 Oct 2014 21:36:23 +0000,,,2.0.5-alpha,ui,,MAPREDUCE-5481;MAPREDUCE-5503,https://issues.apache.org/jira/browse/MAPREDUCE-5502
MAPREDUCE-5503,Bug,Blocker,mrv2,TestMRJobClient.testJobClient is failing,TestMRJobClient.testJobClient is failing on trunk and causing precommit builds to complain:,Closed,Fixed,MAPREDUCE-5516;MAPREDUCE-5526,Jian He,Jason Lowe,Wed; 11 Sep 2013 21:07:09 +0000,Thu; 12 May 2016 18:22:25 +0000,Thu; 26 Sep 2013 03:04:07 +0000,,2.1.0-beta;3.0.0-alpha1,,,MAPREDUCE-5502,https://issues.apache.org/jira/browse/MAPREDUCE-5503
MAPREDUCE-5504,Bug,Major,client,mapred queue -info inconsistent with types,$ mapred queue -info default ====================== Queue Name : default Queue State : running Scheduling Info : Capacity: 4.0; MaximumCapacity: 0.67; CurrentCapacity: 0.9309831   The capacity is displayed in % as 4; however maximum capacity is displayed as an absolute number 0.67 instead of 67%.  We should make these consistent with the type we are displaying,Closed,Fixed,,Kousuke Saruta,Thomas Graves,Wed; 11 Sep 2013 21:13:59 +0000,Wed; 3 Sep 2014 23:40:09 +0000,Thu; 19 Sep 2013 21:01:42 +0000,,0.23.9,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5504
MAPREDUCE-5505,Sub-task,Critical,,Clients should be notified job finished only after job successfully unregistered ,This is to make sure user is notified job finished after job is really done. This does increase client latency but can reduce some races during unregister like YARN-540,Closed,Fixed,,Zhijie Shen,Jian He,Fri; 13 Sep 2013 04:58:38 +0000,Tue; 30 Jun 2015 07:14:41 +0000,Wed; 25 Sep 2013 00:56:07 +0000,,,,YARN-128,YARN-1195;YARN-540,https://issues.apache.org/jira/browse/MAPREDUCE-5505
MAPREDUCE-5506,Bug,Blocker,mrv1,Hadoop-1.1.1 occurs ArrayIndexOutOfBoundsException with MultithreadedMapRunner,"After I set:  	'jobConf.setMapRunnerClass(MultithreadedMapRunner.class);' in MR app 	'mapred.map.multithreadedrunner.threads = 2' in mapred-site.xml    A simple MR app failed as its Map task encountered ArrayIndexOutOfBoundsException as below(please ignore the line numbers in the exception as I added some log print codes):  MapOutputBuffer#Buffer#write(). When the exception occurs; 'b.length=4' but 'len=9'.   Btw; if I set 'mapred.map.multithreadedrunner.threads = 1'; no exception happened. So it should be an issue caused by multiple threads.",Resolved,Won't Fix,,Unassigned,sam liu,Fri; 13 Sep 2013 07:40:00 +0000,Tue; 18 Oct 2016 00:28:31 +0000,Tue; 18 Oct 2016 00:28:30 +0000,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5506
MAPREDUCE-5507,Bug,Critical,applicationmaster,MapReduce reducer ramp down is suboptimal with potential job-hanging issues,"Today if we are setting ""yarn.app.mapreduce.am.job.reduce.rampup.limit"" and ""mapreduce.job.reduce.slowstart.completedmaps"" then reducers are launched more aggressively. However the calculation to either Ramp up or Ramp down reducer is not done in most optimal way.   	If MR AM at any point sees situation something like 	 		scheduledMaps : 30 		scheduledReducers : 10 		assignedMaps : 0 		assignedReducers : 11 		finishedMaps : 120 		headroom : 756 ( when your map   container because it will reduce its cluster consumption and thereby may become candidate for an allocation.",Open,Unresolved,,Omkar Vinit Joshi,Omkar Vinit Joshi,Fri; 13 Sep 2013 18:56:35 +0000,Tue; 20 Sep 2016 18:45:45 +0000,,,,,,MAPREDUCE-6513,https://issues.apache.org/jira/browse/MAPREDUCE-5507
MAPREDUCE-5508,Bug,Critical,jobtracker,JobTracker memory leak caused by unreleased FileSystem objects in JobInProgress#cleanupJob,"MAPREDUCE-5351 fixed a memory leak problem but introducing another filesystem object (see ""tempDirFs"") that is not properly released.",Resolved,Fixed,,Xi Fang,Xi Fang,Fri; 13 Sep 2013 23:52:35 +0000,Thu; 7 Nov 2013 18:34:06 +0000,Tue; 24 Sep 2013 05:35:27 +0000,,1-win;1.2.1,,,HDFS-5211;MAPREDUCE-5351;HADOOP-9993,https://issues.apache.org/jira/browse/MAPREDUCE-5508
MAPREDUCE-5509,Bug,Major,,the permission deny error will missing with restart jobtracker twice,recently; i import the multiple user feature in my hadoop cluster. but if a job failed with permission deny error(failed with can not create file error; not include the  heapsize error; and the privilege is right; i don't know why occur this error); and i restart the jobtracker.the new job will failed with permission deny error. but if i restart jobtracker again(is mean restart jobtracker twice); the job will running succeed. so; is this a bug with hadoop-1.1.1?,Open,Unresolved,,Unassigned,prophy Yan,Mon; 16 Sep 2013 03:19:51 +0000,Mon; 16 Sep 2013 03:19:51 +0000,,,1.1.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5509
MAPREDUCE-5510,Bug,Major,applicationmaster,Root queue is full;  leads to a job hung; it's reduces started;but some maps is pending,when it hadppen; I notice reduces were not preempt  2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1 2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce 2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1377833725640_158209_01_004100 to attempt_1377833725640_158209_r_000258_0 2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule; headroom=582656 2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.9940104 totalMemLimit:2548736 finalMapMemLimit:70656 finalReduceMemLimit:2478080 netScheduledMapMem:70656 netScheduledReduceMem:2460672 2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping up 1 2013-09-15 10:32:26;608 INFO RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:212 ScheduledMaps:22 ScheduledReds:55 AssignedMaps:1 AssignedReds:213 CompletedMaps:3817 CompletedReds:0 ContAlloc:4031 ContRel:0 HostLocal:0 RackLocal:0,Open,Unresolved,,Unassigned,wanbin,Mon; 16 Sep 2013 14:26:33 +0000,Mon; 23 Sep 2013 03:05:33 +0000,,,2.0.6-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5510
MAPREDUCE-5511,Bug,Minor,examples,Multifilewc and the mapred.* API:  Is the use of getPos() valid?,"The MultiFileWordCount class in the hadoop examples libraries uses a record reader which switches between files.  This behaviour can cause the RawLocalFileSystem to break in a concurrent environment because of the way buffering works (in RawLocalFileSystem; switching between streams results in a temproraily ""null"" inner stream; and that inner stream is called by the getPos() implementation in the custom RecordReader for MultiFileWordCount).   There are basically 2 ways to handle this:  1) Wrap the getPos() implementation in the object returned by open() in the RawLocalFileSystem to cache the value of getPos() everytime it is called; so that calls to getPos() can return a valid long even if underlying stream is null. OR  2) Update the RecordReader in multifilewc to not rely on the inner input stream and cache the position   return 0 if the stream cannot return a valid value.   The final question here is:  Is the RecordReader for MultiFileWordCount doing the right thing ?  Or is it breaking the contract of getPos()... and really... what SHOULD getPos() return if the underlying stream has already been consumed?",Open,Unresolved,,Unassigned,jay vyas,Mon; 16 Sep 2013 15:35:47 +0000,Mon; 16 Sep 2013 16:13:31 +0000,,,1.0.0;1.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5511
MAPREDUCE-5512,Bug,Major,tasktracker,TaskTracker hung after failed reconnect to the JobTracker,TaskTracker hung after failed reconnect to the JobTracker.   This is the problematic piece of code:    In case RPC.waitForProxy() throws; TrackerDistributedCacheManager cleanup thread will never be stopped; and given that it is a non daemon thread it will keep TT up forever.,Resolved,Fixed,,Ivan Mitic,Ivan Mitic,Tue; 17 Sep 2013 01:53:09 +0000,Fri; 11 Oct 2013 05:57:36 +0000,Fri; 11 Oct 2013 05:57:36 +0000,,1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5512
MAPREDUCE-5513,Bug,Major,,ConcurrentModificationException in JobControl,JobControl.toList is locking individual lists to iterate them; but those lists can be modified elsewhere without holding the list lock.  The locking approaches are mismatched; with toList holding the lock on the actual list object while other methods hold the JobControl lock when modifying the lists.,Closed,Fixed,,Robert Parker,Jason Lowe,Wed; 18 Sep 2013 14:24:41 +0000,Tue; 30 Jun 2015 07:18:59 +0000,Thu; 26 Sep 2013 21:25:56 +0000,,2.1.0-beta;0.23.9,,,MAPREDUCE-5757,https://issues.apache.org/jira/browse/MAPREDUCE-5513
MAPREDUCE-5514,Bug,Blocker,,TestRMContainerAllocator fails on trunk,nan,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Wed; 18 Sep 2013 17:34:03 +0000,Mon; 24 Feb 2014 20:57:46 +0000,Thu; 26 Sep 2013 23:03:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5514
MAPREDUCE-5515,Bug,Major,,Application Manager UI does not appear with Https enabled,related issue YARN-1203. We need to disable https for MR-AM by default as they will need access to keystore which can not be granted in the cluster.,Closed,Fixed,,Omkar Vinit Joshi,Omkar Vinit Joshi,Wed; 18 Sep 2013 21:43:52 +0000,Tue; 30 Jun 2015 07:19:00 +0000,Fri; 20 Sep 2013 00:26:45 +0000,,,,,YARN-1203,https://issues.apache.org/jira/browse/MAPREDUCE-5515
MAPREDUCE-5516,Bug,Major,,TestMRJobClient fails on trunk,nan,Resolved,Duplicate,MAPREDUCE-5503,Unassigned,Jian He,Thu; 19 Sep 2013 01:49:18 +0000,Thu; 19 Sep 2013 17:40:39 +0000,Thu; 19 Sep 2013 17:40:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5516
MAPREDUCE-5517,Bug,Minor,,enabling uber mode with 0 reducer still requires mapreduce.reduce.memory.mb to be less than yarn.app.mapreduce.am.resource.mb,Since there is no reducer; the memory allocated to reducer is irrelevant to enable uber mode of a job,Closed,Fixed,,Siqi Li,Siqi Li,Thu; 19 Sep 2013 18:15:34 +0000,Fri; 15 Aug 2014 05:47:53 +0000,Mon; 7 Jul 2014 20:15:15 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5517
MAPREDUCE-5518,Bug,Trivial,examples,"Fix typo ""can't read paritions file""","Noticed a spelling error when I saw this error message     ""paritions"" should be ""partitions""",Closed,Fixed,,Albert Chu,Albert Chu,Fri; 20 Sep 2013 00:54:35 +0000,Thu; 12 May 2016 18:22:36 +0000,Tue; 15 Oct 2013 06:33:27 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5518
YARN-1224,Improvement,Major,,Have YarnClient generate a directly usable AM proxy ,nan,Open,Unresolved,,Unassigned,Jian He,Fri; 20 Sep 2013 06:06:31 +0000,Sun; 22 Sep 2013 21:38:56 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-1224
MAPREDUCE-5520,Bug,Major,,Run a mapreduce program ;th error msg is shown :ERROR hdfs.DFSClients:Failed to close file ......  how to fix it?,run a mapreduce program;the error msg is shown as below: ERROR hdfs.DFSClients:Failed to close file  job.jar org.apache.hadoop.ipc.RemoteException heap space how to fix it?,Open,Unresolved,,Unassigned,hawkswood,Fri; 20 Sep 2013 14:20:09 +0000,Fri; 20 Sep 2013 14:20:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5520
MAPREDUCE-5521,Bug,Blocker,,Map reduce AM UI incorrectly computes running reducers,If the reducer is killed (may be during ramp down) then Map reduce UI increases the killed reducer count but doesn't change the running reducer count.,Reopened,Unresolved,,Omkar Vinit Joshi,Omkar Vinit Joshi,Fri; 20 Sep 2013 20:38:57 +0000,Sat; 21 Sep 2013 01:17:01 +0000,,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5521
MAPREDUCE-5522,Bug,Minor,test,Incorrectly expect the array of JobQueueInfo returned by o.a.h.mapred.QueueManager#getJobQueueInfos to have a specific order.,There is a bug in test o.a.h.mapred.TestQueue. The implementation of getJobQueueInfos in QueueManager uses the keySet of a HashMap to populate the return value and since there is no guarantee in the ordering of the elements in the keySet of a Hashmap; this test would fail if the order returned by getJobQueueInfos is different than what the test is expecting.,Closed,Fixed,,Jinghui Wang,Jinghui Wang,Fri; 20 Sep 2013 21:48:01 +0000,Thu; 12 May 2016 18:24:46 +0000,Mon; 23 Sep 2013 18:41:00 +0000,,0.23.7;2.1.0-beta;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5522
MAPREDUCE-5523,Bug,Major,,Need to add https port related property in Job history server,related ticket YARN-1204,Closed,Fixed,,Omkar Vinit Joshi,Omkar Vinit Joshi,Fri; 20 Sep 2013 21:53:34 +0000,Tue; 30 Jun 2015 07:18:57 +0000,Tue; 24 Sep 2013 17:24:31 +0000,,,,,YARN-1204,https://issues.apache.org/jira/browse/MAPREDUCE-5523
MAPREDUCE-5524,Bug,Major,,java.io.IOException: Task process exit with nonzero status of   255. how to fix it?,Task ......FAILED   258),Resolved,Invalid,,Unassigned,hawkswood,Sat; 21 Sep 2013 11:06:11 +0000,Tue; 1 Oct 2013 00:31:53 +0000,Tue; 1 Oct 2013 00:31:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5524
MAPREDUCE-5525,Test,Minor,mrv2;test,Increase timeout of TestDFSIO.testAppend and TestMRJobsWithHistoryService.testJobHistoryData,The two test cases consistently fail on Windows due to timeout. The running time of TestDFSIO.testAppend on my Linux box was also close. In the case of TestMRJobsWithHistoryService.testJobHistoryData; it also fails on my Linux due to timeout.,Closed,Fixed,,Chuan Liu,Chuan Liu,Sun; 22 Sep 2013 22:55:20 +0000,Fri; 22 Jul 2016 16:33:15 +0000,Thu; 26 Sep 2013 17:52:43 +0000,,3.0.0-alpha1,,,MAPREDUCE-6744,https://issues.apache.org/jira/browse/MAPREDUCE-5525
MAPREDUCE-5526,Test,Minor,,TestMRJobClient fails on Windows and Linux,The unit test fails on both Windows and Linux. I think the failures are due to wrong assertion at several places.,Resolved,Duplicate,MAPREDUCE-5503,Chuan Liu,Chuan Liu,Mon; 23 Sep 2013 00:55:32 +0000,Thu; 12 May 2016 18:23:43 +0000,Mon; 23 Sep 2013 13:14:48 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5526
MAPREDUCE-5527,Improvement,Major,,Add CONTAINERS_MILLIS_MAPS|REDUCES counters,It would be helpful to have counters which report the total wallclock time spent in all map reduce tasks.  This is what SLOTS_MILLIS_MAPS usually did in MR1.,Open,Unresolved,,Unassigned,Sandy Ryza,Mon; 23 Sep 2013 16:25:24 +0000,Mon; 23 Sep 2013 16:25:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5527
MAPREDUCE-5528,Bug,Minor,examples,"TeraSort fails with ""can't read paritions file"" - does not read partition file from distributed cache",I was trying to run TeraSort against a parallel networked file system; setting things up via the 'file: ' scheme; the working directory was the directory I was running my Hadoop binaries out of.  The attached patch fixed things for me.  It grabs the partition file from the distributed cache all of the time; instead of trusting things underneath to work out.  It seems to be the right thing to do???  Apologies; I was unable to get this to reproduce under the TeraSort example tests; such as TestTeraSort.  so no test added.  Not sure what the subtle difference is in the setup.  I tested under both HDFS  'file' scheme and the patch worked under both.,Open,Unresolved,MAPREDUCE-5050,Albert Chu,Albert Chu,Mon; 23 Sep 2013 23:49:55 +0000,Thu; 12 May 2016 18:22:22 +0000,,,0.20.2;2.5.0;2.4.1;2.6.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5528
MAPREDUCE-5529,Sub-task,Blocker,mrv1;mrv2,Binary incompatibilities in mapred.lib.TotalOrderPartitioner between branch-1 and branch-2,mapred.lib.TotalOrderPartitioner in branch-1 has these two methods:    In branch-2; mapred.lib.TotalOrderPartitioner is now a subclass of mapred.lib.TotalOrderPartitioner; from which it inherits the similar methods:    This means that any code that does either of the following:   will not be binary compatible (that is; if compiled against branch-1; it will throw a NoSuchMethodError if run against branch-2).,Closed,Fixed,,Robert Kanter,Robert Kanter,Tue; 24 Sep 2013 00:01:44 +0000,Tue; 30 Jun 2015 07:14:41 +0000,Fri; 27 Sep 2013 20:05:22 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5529
MAPREDUCE-5530,Sub-task,Blocker,mrv1;mrv2,Binary and source incompatibility in mapred.lib.CombineFileInputFormat between branch-1 and branch-2,mapred.lib.CombineFileInputForm is; if compiled against branch-1; it will throw a NoSuchMethodError if run against branch-2; also; it won't even compile against branch-2).,Closed,Fixed,,Robert Kanter,Robert Kanter,Tue; 24 Sep 2013 00:42:39 +0000,Tue; 30 Jun 2015 07:14:43 +0000,Wed; 2 Oct 2013 16:11:22 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5530
MAPREDUCE-5531,Sub-task,Blocker,mrv1;mrv2,Binary and source incompatibility in mapreduce.TaskID and mapreduce.TaskAttemptID between branch-1 and branch-2,mapreduce.TaskID in branch-1 has these two constructors:   In branch-2; mapreduce.TaskID no longer has either of the above two constructors.    Also; mapreduce.TaskAttemptID in branch-1 has this constructor:   In branch-2; mapreduce.TaskAttemptID no longer his this constructor.  It looks like these constructors were probably removed because the boolean isMap was replaced by an enum; TaskType.  This means that any code that tries to use any of those constructors will not be binary or source compatible (in fact; the missing TaskAttemptID constructor calls one of the missing TaskID constructors).,Closed,Fixed,,Robert Kanter,Robert Kanter,Tue; 24 Sep 2013 17:29:52 +0000,Tue; 30 Jun 2015 07:14:43 +0000,Fri; 27 Sep 2013 19:10:56 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5531
YARN-1234,Bug,Major,nodemanager, Container localizer logs are not created in secured cluster,When we are running ContainerLocalizer in secured cluster we potentially are not creating any log file to track log messages. This will be helpful in potentially identifying ContainerLocalization issues in secured cluster.,Open,Unresolved,,Omkar Vinit Joshi,Omkar Vinit Joshi,Wed; 25 Sep 2013 00:36:32 +0000,Fri; 10 Apr 2015 18:49:59 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-1234
MAPREDUCE-5533,Bug,Major,applicationmaster,Speculative execution does not function for reduce,We have sort job where reduce attempt does not send heartbeat in timely manner to application master. The AM should kick off another attempt to let job succeeds. What we find is the job fails and there is no speculation happening.,Closed,Fixed,,Xuan Gong,Tassapol Athiapinya,Wed; 25 Sep 2013 05:15:01 +0000,Tue; 30 Jun 2015 07:14:42 +0000,Fri; 4 Oct 2013 17:30:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5533
MAPREDUCE-5534,Improvement,Major,mrv2,Improve job configuration handling when MapReduce deployed via HDFS,This is a followup JIRA to MAPREDUCE-4421.  Currently the -site.xml files are loaded from files already present on each node; but loading of those site files may not be appropriate when the MapReduce framework is deployed via HDFS rather than using the pre-installed jars on each node.  We need to determine a strategy for handling job configuration and site files when the MapReduce framework is not being picked up from the nodes.,Open,Unresolved,,Unassigned,Jason Lowe,Wed; 25 Sep 2013 21:48:11 +0000,Tue; 28 Jan 2014 23:33:46 +0000,,,2.3.0,,,MAPREDUCE-4421,https://issues.apache.org/jira/browse/MAPREDUCE-5534
MAPREDUCE-5535,Bug,Major,,TestClusterMRNotification.testMR is failing,nan,Resolved,Duplicate,MAPREDUCE-5538,Unassigned,Jian He,Wed; 25 Sep 2013 22:47:23 +0000,Thu; 26 Sep 2013 06:15:25 +0000,Thu; 26 Sep 2013 06:15:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5535
MAPREDUCE-5536,Bug,Blocker,,mapreduce.jobhistory.webapp.https.address property is not respected,The jobhistory server starts on port defined by mapreduce.jobhistory.webapp.address property instead mapreduce.jobhistory.webapp.https.address when hadoop.ssl.enabled=true.,Closed,Fixed,,Omkar Vinit Joshi,Yesha Vora,Wed; 25 Sep 2013 21:38:14 +0000,Tue; 30 Jun 2015 07:14:43 +0000,Wed; 2 Oct 2013 00:25:13 +0000,,2.1.1-beta,,,HADOOP-10004,https://issues.apache.org/jira/browse/MAPREDUCE-5536
MAPREDUCE-5537,Bug,Major,,hive return different results with and without index when hive.hadoop.supports.splittable.combineinputformat =true,"the  environment: hive-0.8.1 hadoop-0.20.2-cdh3u6 the Presentation: i use the hive-0.8.1 to exec the query: select count from table t1;  the table t1 is lzo formatted ;and the follows is :  	Storage Information SerDe Library:                  org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                    InputFormat:                    com.hadoop.mapred.DeprecatedLzoTextInputFormat                                        OutputFormat:                   org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat     and the hive.hadoop.supports.splittable.combineinputformat =true when i index the table t1;the result is  265329 . when i remove the index of the t1;the result is  265325.",Resolved,Fixed,,alex.lv,alex.lv,Thu; 26 Sep 2013 03:48:33 +0000,Thu; 26 Sep 2013 04:29:10 +0000,Thu; 26 Sep 2013 04:29:10 +0000,,0.20.205.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5537
MAPREDUCE-5538,Sub-task,Blocker,,MRAppMaster#shutDownJob shouldn't send job end notification before checking isLastRetry,nan,Closed,Fixed,MAPREDUCE-5535,Zhijie Shen,Zhijie Shen,Thu; 26 Sep 2013 04:16:49 +0000,Tue; 30 Jun 2015 07:14:43 +0000,Sun; 29 Sep 2013 08:58:38 +0000,,2.2.0,,,MAPREDUCE-5547,https://issues.apache.org/jira/browse/MAPREDUCE-5538
YARN-1243,Bug,Major,capacityscheduler,ResourceManager: Error in handling event type NODE_UPDATE to the scheduler - NPE at SchedulerApp.java:411,2013-09-26 03:25:02;262 ResourceManager Event Processor FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler  lang.NullPointerException          this NPE,Closed,Fixed,,Jason Lowe,Sanjay Upadhyay,Thu; 26 Sep 2013 05:31:12 +0000,Tue; 10 Dec 2013 14:55:51 +0000,Thu; 26 Sep 2013 20:29:56 +0000,,0.23.8,,,YARN-845,https://issues.apache.org/jira/browse/YARN-1243
MAPREDUCE-5540,Bug,Major,,Speculative task makes the default JobQueueTaskScheduler scheduling becomes unreasonable,"Speculative task makes the default JobQueueTaskScheduler scheduling becomes unreasonable  Speculative task resulted in a resource is abundant; using the default scheduler; still prone to (map; reduce) task pend. The Cluster configuration : 3 tasktracker; 12 reduce slot per node.    In the job queue has only 2 jobs: job_201309221020_0357's eleven reduce tasks are running; and  job_201309221020_0358 has a reduce in the pending state;  but my cluster; a total of 36 slot; why does job_201309221020_0358 need to be pending ? Job_201309221020_0358 has been waiting for 2 minutes; and finally in the job_201309221020_0357 has completed a reduce task after the operation .  Check the operation log and scheduling algorithm source code; found that may be because ""Speculative task"" lead to scheduling algorithm default becomes less.   The task_201309221020_0357_r_000006 task actual start of two attmept (attempt_201309221020_0357_r_000006_0; attempt_201309221020_0357_r_000006_1); so although the job_201309221020_0357 only eleven reduce tasks; but since the opening Speculative task; causing it to the actual occupation of twelve slot (four slots per node); so the currently running   12 slots.   According to the default scheduling algorithm; completed the reduce tasks running job_201309221020_0358 reduce task must wait for job_201309221020_0357 s a reduce task; otherwise it will always be pending.So the default scheduling algorithm is not suitable for open ""Speculative task""      JobQueueTaskScheduler  :   double reduceLoadFactor = (double)remainingReduceLoad   if job_201309221020_0357's reduce tasks is running ;the availableReduceSlots is always less 1 	exceededReducePadding = exceededPadding(false; clusterStatus; trackerReduceCapacity);         	synchronized (jobQueue) { 		LOG.debug(""try to assign 1 reduce task to TaskTracker&quot;+taskTracker.trackerName+&#93;..""); 		for (JobInProgress job : jobQueue) { 			if (job.getStatus().getRunState() != JobStatus.RUNNING || job.numReduceTasks == 0)  { 			continue; 	} ... ...",Open,Unresolved,,Unassigned,guowp_aily,Thu; 26 Sep 2013 06:31:14 +0000,Thu; 26 Sep 2013 06:31:14 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5540
MAPREDUCE-5541,Improvement,Major,mrv1,Improved algorithm for whether need speculative task,Most of time; tasks won't start running at same time. In this case hasSpeculativeTask in TaskInProgress not working very well. Some times; some tasks just start running; and scheduler already decide it need speculative task to run. And this waste a lot of resource.,Resolved,Won't Fix,,yunjiong zhao,yunjiong zhao,Thu; 26 Sep 2013 12:41:29 +0000,Wed; 9 Nov 2016 18:12:58 +0000,Wed; 9 Nov 2016 18:12:56 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5541
MAPREDUCE-5542,Bug,Major,client;mrv2,Killing a job just as it finishes can generate an NPE in client,If a client tries to kill a job just as the job is finishing then the client can crash with an NPE.,Closed,Fixed,MAPREDUCE-5764,Rohith Sharma K S,Jason Lowe,Thu; 26 Sep 2013 15:15:36 +0000,Mon; 1 Dec 2014 03:10:16 +0000,Fri; 17 Oct 2014 19:58:05 +0000,,2.1.0-beta;0.23.9,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5542
MAPREDUCE-5543,Bug,Blocker,mrv2,In-memory map outputs can be leaked after shuffle completes in 0.23,MergeManagerImpl#close adds the contents of inMemoryMergedMapOutputs and inMemoryMapOutputs to a list of map outputs that is subsequently processed; but it does not clear those sets.  This prevents some of the map outputs from being garbage collected and significantly reduces the memory available for the subsequent reduce phase.  This was fixed for trunk and branch-2 by MAPREDUCE-5493; but that has since been closed after 2.1.1 released.  This JIRA tracks backporting the fix to branch-0.23 as well.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 26 Sep 2013 15:37:53 +0000,Tue; 10 Dec 2013 14:55:50 +0000,Thu; 26 Sep 2013 20:58:23 +0000,,0.23.9,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5543
MAPREDUCE-5544,Bug,Major,,JobClient#getJob loads job conf twice,Calling JobClient#getJob causes the job conf file to be loaded twice; once in the constructor of JobClient.NetworkedJob and once in Cluster#getJob.  We should remove the former.  MAPREDUCE-5001 was meant to fix a race that was causing problems in Hive tests; but the problem persists because it only fixed one of the places where the job conf file is loaded.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 26 Sep 2013 15:47:14 +0000,Tue; 30 Jun 2015 07:18:58 +0000,Tue; 1 Oct 2013 20:09:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5544
MAPREDUCE-5545,Bug,Major,,org.apache.hadoop.mapred.TestTaskAttemptListenerImpl.testCommitWindow times out,We've been seeing org.apache.hadoop.mapred.TestTaskAttemptListenerImpl.testCommitWindow time out. We should increase the timeout.,Closed,Fixed,,Robert Kanter,Robert Kanter,Fri; 27 Sep 2013 17:52:39 +0000,Tue; 30 Jun 2015 07:18:58 +0000,Fri; 27 Sep 2013 19:21:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5545
MAPREDUCE-5546,Bug,Major,,mapred.cmd on Windows set HADOOP_OPTS incorrectly,The mapred command on Windows does not set HADOOP_OPTS correctly. As a result; some options and settings will miss in the final command; and this will lead to some desired behavior missing. One example is the logging file setting will miss; i.e. even if one set HADOOP_ROOT_LOGGER to DRFA; there is no history server log at HADOOP_LOGFILE.,Closed,Fixed,,Chuan Liu,Chuan Liu,Fri; 27 Sep 2013 20:50:35 +0000,Thu; 12 May 2016 18:23:13 +0000,Mon; 14 Oct 2013 18:39:45 +0000,,2.2.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5546
MAPREDUCE-5547,Sub-task,Major,,Job history should not be flushed to JHS until AM gets unregistered,nan,Open,Unresolved,,Zhijie Shen,Zhijie Shen,Sun; 29 Sep 2013 05:45:47 +0000,Sat; 7 Jan 2017 01:59:52 +0000,,,,,,MAPREDUCE-5538;MAPREDUCE-5703,https://issues.apache.org/jira/browse/MAPREDUCE-5547
MAPREDUCE-5548,Sub-task,Major,security,JobHIstoryServer should let queue admins view info of corresponding apps,YARN-899 added the basic support for queue acls. JHS 'somehow' should let queue admins view info about all apps under that queue.  We should also tests to validate that app-acls work at JHS.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Sun; 29 Sep 2013 08:02:55 +0000,Sun; 29 Sep 2013 08:04:18 +0000,,,,,,YARN-899,https://issues.apache.org/jira/browse/MAPREDUCE-5548
MAPREDUCE-5549,Bug,Major,distcp;mrv2,distcp app should fail if m/r job fails,I run distcpv2 in a scripted manner.  The script checks if the distcp step fails and; if so; aborts the rest of the script.  However; I ran into an issue today where the distcp job failed; but my calling script went on its merry way.  Digging into the code a bit more (at https:  ; I think I see the issue:  the distcp app is not returning an error exit code to the shell when the distcp job fails.  This is a big problem; IMO; as it prevents distcp from being successfully used in a scripted environment.  IMO; the code should change like so:  Before:     After:,Open,Unresolved,,Unassigned,David Rosenstrauch,Mon; 30 Sep 2013 16:57:04 +0000,Sat; 7 Jan 2017 02:00:01 +0000,,,3.0.0-alpha1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5549
MAPREDUCE-5550,Bug,Major,,Task Status message (reporter.setStatus) not shown in UI with Hadoop 2.0,Hadoop 1.0 JobTracker UI displays task status message when list of mapper or reduce tasks are listed. This give an idea of how that task is making progress.  Hadoop 2.0 AM JHS UI.,Closed,Fixed,,Gera Shegalov,Vrushali C,Mon; 30 Sep 2013 20:14:28 +0000,Wed; 30 Jul 2014 23:10:55 +0000,Fri; 20 Dec 2013 21:04:40 +0000,,2.0.5-alpha,,,MAPREDUCE-6014,https://issues.apache.org/jira/browse/MAPREDUCE-5550
MAPREDUCE-5551,Sub-task,Blocker,,Binary Incompatibility of O.A.H.U.mapred.SequenceFileAsBinaryOutputFormat.WritableValueBytes,The non-default constructor is moved to the super class; but it cannot be inherited.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Tue; 1 Oct 2013 00:24:52 +0000,Tue; 30 Jun 2015 07:14:43 +0000,Tue; 1 Oct 2013 02:02:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5551
MAPREDUCE-5552,Bug,Blocker,,org.apache.hadoop.mapred.TestJobCleanup failing on trunk,Running org.apache.hadoop.mapred.TestJobCleanup Tests run: 3; Failures: 0; Errors: 3; Skipped: 0; Time elapsed: 138.031 sec &lt; FAILURE! - in org.apache.hadoop.mapred.TestJobCleanup testDefaultCleanupAndAbort(org.apache.hadoop.mapred.TestJobCleanup)  Time elapsed: 25.522 sec  &lt; ERROR!  319),Resolved,Cannot Reproduce,,Unassigned,Omkar Vinit Joshi,Tue; 1 Oct 2013 17:50:00 +0000,Wed; 11 Mar 2015 20:24:58 +0000,Wed; 11 Mar 2015 20:24:58 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5552
MAPREDUCE-5553,Improvement,Minor,applicationmaster,Add task state filters on Application/MRJob page for MR Application master ,On Job page of MR application master; the task attempts have a nice breakdown of different state: running; failed.... But for map Reduce task.,Closed,Fixed,,Paul Han,Paul Han,Tue; 1 Oct 2013 22:31:37 +0000,Thu; 10 Apr 2014 13:11:22 +0000,Wed; 12 Mar 2014 22:06:06 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5553
MAPREDUCE-5554,Bug,Minor,test,hdfs-site.xml included in hadoop-mapreduce-client-jobclient tests jar is breaking tests for downstream components,The hadoop-mapreduce-client-jobclient tests jar has an hdfs-site.xml in it; so if its in the classpath first; then a downstream component's tests can fail if it needs to use a different hdfs-site.xml as the one in the mapreduce jar gets picked up instead.  We should remove it from the jar.,Closed,Fixed,,Robert Kanter,Robert Kanter,Wed; 2 Oct 2013 00:57:40 +0000,Tue; 30 Jun 2015 07:14:41 +0000,Wed; 2 Oct 2013 22:15:32 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5554
MAPREDUCE-5555,New Feature,Major,distcp,distcp should infer optimal number of mappers,Rather than requiring the user to calculate and provide an optimal number of mappers with the -m option; distcp should (if the option is not provided) be able to estimate a reasonable number.,Open,Unresolved,,Unassigned,Rob Weltman,Thu; 3 Oct 2013 02:44:25 +0000,Thu; 3 Oct 2013 02:44:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5555
MAPREDUCE-5556,Bug,Trivial,,mapred docs have incorrect classpath,"http: mapred_tutorial.html  The classpath for   under the ""Usage"" section is incorrect.",Resolved,Fixed,,Harsh J,Allen Wittenauer,Thu; 3 Oct 2013 17:53:31 +0000,Wed; 18 Mar 2015 12:21:46 +0000,Wed; 18 Mar 2015 12:21:46 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5556
YARN-1269,Bug,Major,,QueueACLs doesn't work as root allows *,Even if we specify acl for default queue; say user1; user2 can still submit and kill applications on default queue; because the queue checked user2 don't have the access to it; it then checked whether user2 has the access to it's parent recursively; and finally it found user2 have the access to root.,Open,Unresolved,YARN-1966,Unassigned,Zhijie Shen,Thu; 3 Oct 2013 19:07:20 +0000,Tue; 13 Jan 2015 21:42:31 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-1269
MAPREDUCE-5558,Bug,Blocker,,Scheme for local file is lost when submitting mapreduce job using mapreduce API,"HBase snapshot export adds dependent jars (local files) through ""tmpjars"" config entry.  When debugging HBASE-9687; we found that scheme for local file (file: "" from the uri. In the earlier code we were creating new Path object (new Path (newPath.toUri().getPath()) ) where as part of newPath.toUri().getPath() call we are losing the authority and scheme which are passed in.  Thanks to Omkar and Vinod who helped debug this issue",Resolved,Later,,Ted Yu,Ted Yu,Thu; 3 Oct 2013 20:42:37 +0000,Mon; 15 Dec 2014 16:52:18 +0000,Fri; 4 Oct 2013 21:06:56 +0000,,2.1.0-beta;2.1.1-beta;2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5558
MAPREDUCE-5559,Improvement,Major,,Reconsidering the policy of ignoring the blacklist after reaching the threshold,Nowadays; when MR AM find the number of blacklisted nodes reaches one threshold; the blacklist will be totally ignored. The newly assigned containers on the blacklisted nodes will be allocated. This may be not the best practice. We need to reconsider of it.,Open,Unresolved,,Zhijie Shen,Zhijie Shen,Thu; 3 Oct 2013 20:44:04 +0000,Mon; 28 Sep 2015 18:55:07 +0000,,,2.1.1-beta,,,MAPREDUCE-3339;MAPREDUCE-5489,https://issues.apache.org/jira/browse/MAPREDUCE-5559
MAPREDUCE-5560,Bug,Critical,,org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler failing on trunk,Tests run: 3; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 1.406 sec &lt; FAILURE! - in org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler testBasic(org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler)  Time elapsed: 0.185 sec  &lt; FAILURE!  263),Resolved,Cannot Reproduce,,Unassigned,Cindy Li,Thu; 3 Oct 2013 22:40:38 +0000,Wed; 11 Mar 2015 20:24:05 +0000,Wed; 11 Mar 2015 20:24:05 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5560
MAPREDUCE-5561,Bug,Critical,,org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl testcase failing on trunk,Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl Tests run: 15; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 9.029 sec &lt; FAILURE! - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl testFailAbortDoesntHang(org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl)  Time elapsed: 5.507 sec  &lt; FAILURE!  418),Closed,Fixed,,Karthik Kambatla,Cindy Li,Thu; 3 Oct 2013 22:55:53 +0000,Mon; 3 Nov 2014 18:05:33 +0000,Tue; 22 Oct 2013 22:52:26 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5561
MAPREDUCE-5562,Sub-task,Major,,MR AM should exit when unregister() throws exception,nan,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 3 Oct 2013 23:04:24 +0000,Tue; 30 Jun 2015 07:14:41 +0000,Sun; 6 Oct 2013 20:55:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5562
MAPREDUCE-5563,Bug,Critical,,  TestMiniMRChildTask test cases failing on trunk,Failed tests:   TestMiniMRChildTask.testTaskTempDir:367 Exception in testing temp dir   TestMiniMRChildTask.testTaskEnv:390 Exception in testing child env   TestMiniMRChildTask.testTaskOldEnv:413 Exception in testing child env,Resolved,Invalid,,Unassigned,Cindy Li,Fri; 4 Oct 2013 18:52:34 +0000,Fri; 8 May 2015 22:04:45 +0000,Fri; 8 May 2015 22:04:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5563
MAPREDUCE-5564,Improvement,Major,,TaskImpl should log the host on which a task is running,Log lines like the following should include the host on which the task is running. This will assist archeologists in locating the appropriate logs post-mortem.,Open,Unresolved,,Unassigned,Nick Dimiduk,Fri; 4 Oct 2013 21:42:44 +0000,Fri; 4 Oct 2013 21:42:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5564
MAPREDUCE-5565,Bug,Critical,jobtracker,job clean up fails on secure cluster as the file system is not created in the context of the ugi running the job,On secure clusters we see the following exceptions in the jt log      And after the job finishes the staging dir is not cleaned up. While debugging with Arun C Murthy we determined that file system object needs to be created in the the context of the user who ran the job.  Job however successfully completes,Resolved,Duplicate,MAPREDUCE-5508,Arun C Murthy,Arpit Gupta,Sat; 5 Oct 2013 02:42:30 +0000,Wed; 9 Oct 2013 23:22:24 +0000,Wed; 9 Oct 2013 23:22:24 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5565
MAPREDUCE-5566,Bug,Critical,,On MR application master ui cluster links are broken in https,The links are pointing to http port instead of https port of resource manager.,Resolved,Won't Fix,,Omkar Vinit Joshi,Omkar Vinit Joshi,Sat; 5 Oct 2013 03:13:45 +0000,Tue; 19 Nov 2013 21:56:12 +0000,Tue; 19 Nov 2013 21:56:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5566
MAPREDUCE-5567,Bug,Major,,[Umbrella] Stabilize MR framework w.r.t ResourceManager restart,There are a bunch of tickets tracking MR AM's issues w.r.t RM restart. Consolidating them here so that we don't make contradictory fixes accross JIRAs.,Resolved,Fixed,,Unassigned,Vinod Kumar Vavilapalli,Sat; 5 Oct 2013 22:32:46 +0000,Fri; 8 May 2015 18:08:48 +0000,Fri; 8 May 2015 18:08:48 +0000,,,,,YARN-128;YARN-556,https://issues.apache.org/jira/browse/MAPREDUCE-5567
MAPREDUCE-5568,Bug,Major,,JHS returns invalid string for reducer completion percentage if AM restarts with 0 reducer.,JobCLient shows like:   With mapped job -status command; it shows:,Closed,Fixed,,MinJi Kim,Jian He,Sat; 5 Oct 2013 23:34:19 +0000,Fri; 10 Apr 2015 20:19:42 +0000,Tue; 25 Nov 2014 21:04:30 +0000,,2.4.1;2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5568
MAPREDUCE-5569,Bug,Major,,FloatSplitter is not generating correct splits,The closing split is not calculated correctly:   For the case of min=5.0; max=7.0; 2 splits; the current code returns splits of (column1 =5.0; column1 6.0); (column1 =7.0; column1 =7.0). The second split is obviously not correct.,Closed,Fixed,,Nathan Roberts,Nathan Roberts,Mon; 7 Oct 2013 16:34:37 +0000,Tue; 10 Mar 2015 04:30:16 +0000,Wed; 9 Oct 2013 16:55:24 +0000,,2.1.0-beta;1.3.0;0.23.9,,,MAPREDUCE-5102,https://issues.apache.org/jira/browse/MAPREDUCE-5569
MAPREDUCE-5570,Bug,Major,mr-am;mrv2,Map task attempt with fetch failure has incorrect attempt finish time,If a map task attempt is retroactively failed due to excessive fetch failures reported by reducers then the attempt's finish time is set to the time the task was retroactively failed rather than when the task attempt completed.  This causes the map task attempt to appear to have run for much longer than it actually did.,Closed,Fixed,,Rushabh S Shah,Jason Lowe,Mon; 7 Oct 2013 18:11:16 +0000,Thu; 10 Apr 2014 13:11:55 +0000,Fri; 14 Mar 2014 20:39:48 +0000,,0.23.9;2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5570
MAPREDUCE-5571,Bug,Major,,allow access to the DFS job submission + staging directory by members of the job submitters group,The job submission and staging directories are explicitly given 0700 permissions restricting access of job submission files only to the submitter UID. this prevents hadoop daemon services running under different UIDs from reading the job submitters files.  it is common unix practice to run daemon services under their own UIDs for security purposes.  This bug can be demonstrated by creating a single node configuration; which runs LocalFileSystem and not HDFS.  Create two users and add them to a 'hadoop' group.  Start the hadoop services with one of the users; then submit a map R job doesn't execute.  The fix is simple enough and secure-- change the staging directory permissions to 2750.  i have demonstrated the patch against 2.0.5 (along  with another fix for an incorrect decimal-octal conversion) and will attach the patch.  this bug is present since very early versions.  i would like to fix it at the lowest level as  it's a simple file mode change in all versions; and localized to one file.  is this possible?,Resolved,Won't Fix,,Unassigned,bradley childs,Thu; 26 Sep 2013 17:33:31 +0000,Wed; 23 Jul 2014 14:26:25 +0000,Wed; 23 Jul 2014 14:26:25 +0000,,1.2.1;2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5571
MAPREDUCE-5572,Bug,Minor,examples,Provide alternative logic for getPos() implementation in custom RecordReader of mapred implementation of MultiFileWordCount,The custom RecordReader class in MultiFileWordCount (MultiFileLineRecordReader) has been replaced in newer examples with a better implementation which uses the CombineFileInputFormat; which doesn't feature this bug.  However; this bug nevertheless still exists in 1.x versions of the MultiFileWordCount which rely on the mapred API.   The older MultiFileWordCount implementation defines the getPos() as follows:  long currentOffset = currentStream == null ? 0 : currentStream.getPos(); ...  This is meant to prevent errors when underlying stream is null. But it doesn't gaurantee to work: The RawLocalFileSystem; for example; currectly will close the underlying file stream once it is consumed; and the currentStream will thus throw a NullPointerException when trying to access the null stream.  This is only seen when running this in the context where the MapTask class; which is only relevant in mapred.* API; calls getPos() twice in tandem; before and after reading a record.  This custom record reader should be gaurded; or else eliminated; since it assumes something which is not in the FileSystem contract:  That a getPos will always return a integral value.,Open,Unresolved,,Unassigned,jay vyas,Mon; 7 Oct 2013 22:40:08 +0000,Mon; 7 Oct 2013 22:43:36 +0000,,,1.1.0;1.1.1;1.2.0;1.1.3;1.2.1;1.2.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5572
MAPREDUCE-5573,Bug,Major,,/ws/v1/mapreduce/blacklistednodes MR AM webservice link is broken.,"run a map reduce job (sleep) then Retrieve MR AM tracking url by running yarn applications -list try accessing  trackingurl + "" blacklistednodes""",Open,Unresolved,,Unassigned,Omkar Vinit Joshi,Tue; 8 Oct 2013 00:22:09 +0000,Tue; 8 Oct 2013 00:22:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5573
MAPREDUCE-5574,Bug,Major,jobhistoryserver,History server returns 500 error on job conf page if user lacks permissions,If a user does not have view ACL permissions for a job and tries to view the job configuration URL (i.e.: ... jobid) then the history server returns a 500 error rather than a descriptive error message informing the user that they lack permissions.,Open,Unresolved,,Unassigned,Jason Lowe,Tue; 8 Oct 2013 21:12:06 +0000,Tue; 8 Oct 2013 21:13:48 +0000,,,0.23.9;2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5574
MAPREDUCE-5575,Bug,Major,jobhistoryserver,History files deleted from the intermediate directory never get removed from the JobListCache,The JobHistoryServer periodically scans through the intermediate directory. It adds all files to the JobListCache. It deletes job files that are older than the max age and moves all other files to the done directory.  Later; when files in the done directory become too old; they're deleted from the JobListCache.  Jobs that were deleted in the intermediate directory (and thus never moved to the done directory) end up in the JobListCache but can never be deleted from it.,Open,Unresolved,,Niranjan Singh,Sandy Ryza,Thu; 10 Oct 2013 17:44:15 +0000,Thu; 10 Oct 2013 18:47:10 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5575
MAPREDUCE-5576,Bug,Major,,MR AM unregistration should not be failed due to UnknownHostException on getting history url,Before RMCommunicator sends the request to RM to finish the application; it will try to get the JHS url; which may throw UnknownHostException. The current code path will skip sending the request to RM when the exception is raised; which sounds not a reasonable behavior; because RM's unregistering an AM will not affected by the tracking URL. The URL can be empty or null.   AFAIK; the impact of null URL will be that the URL to redirect users from RM web page to JHS will be unavailable; and the job report will not show the URL as well. However; is it much much better than failing an application because of UnknownHostException here? Anyway; users can go to JHS directly to find the application history info.  Therefore; the reasonable code path here should be catching UnknownHostException and set historyUrl = null,Open,Unresolved,,Zhijie Shen,Zhijie Shen,Thu; 10 Oct 2013 21:01:21 +0000,Tue; 15 Oct 2013 00:58:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5576
MAPREDUCE-5577,Improvement,Major,jobhistoryserver,Allow querying the JobHistoryServer by job arrival time,The JobHistoryServer REST APIs currently allow querying by job submit time and finish time.  However; jobs don't necessarily arrive in order of their finish time; meaning that a client who wants to stay on top of all completed jobs needs to query large time intervals to make sure they're not missing anything.  Exposing functionality to allow querying by the time a job lands at the JobHistoryServer would allow clients to set the start of their query interval to the time of their last query.   The arrival time of a job would be defined as the time that it lands in the done directory and can be picked up using the last modified date on history files.,Patch Available,Unresolved,,Sandy Ryza,Sandy Ryza,Fri; 11 Oct 2013 00:53:39 +0000,Tue; 12 May 2015 23:40:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5577
YARN-1297,Improvement,Major,fairscheduler,FairScheduler: Move some logs to debug and check if debug logging is enabled,"I ran the Fair Scheduler's core scheduling loop through a profiler tool and identified a bunch of minimally invasive changes that can shave off a few milliseconds.  The main one is demoting a couple INFO log messages to DEBUG; which brought my benchmark down from 16000 ms to 6000.  A few others (which had way less of an impact) were  	Most of the time in comparisons was being spent in Math.signum.  I switched this to direct ifs and elses and it halved the percent of time spent in comparisons. 	I removed some unnecessary instantiations of Resource objects 	I made it so that queues' usage wasn't calculated from the applications up each time getResourceUsage was called.",Resolved,Fixed,YARN-4090,Yufei Gu,Sandy Ryza,Fri; 11 Oct 2013 07:38:03 +0000,Tue; 30 Aug 2016 01:32:05 +0000,Tue; 26 Apr 2016 13:19:27 +0000,,,,,YARN-305,https://issues.apache.org/jira/browse/YARN-1297
MAPREDUCE-5579,Improvement,Major,,Improve JobTracker web UI,Users will often need to use the JobTracker web UI to debug or tune their jobs in addition to checking the status of their jobs. The current web UI is cumbersome to navigate. The goal is to make the JobTracker web UI easier to navigate and present the data in a cleaner and more intuitive format.,Open,Unresolved,,Unassigned,David Chen,Wed; 9 Oct 2013 23:49:21 +0000,Sat; 12 Oct 2013 01:50:15 +0000,,,1.2.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5579
MAPREDUCE-5580,Bug,Major,task,OutOfMemoryError in ReduceTask shuffleInMemory,I have had several reduce tasks fail during the shuffle phase with the following error and stack trace (on CHD 4.1.2):  Error:  lang.OutOfMemoryError: Java heap space   the largest possible in-memory map outputs.  There may be other leakage of these byte arrays; but these were all the large byte arrays in my heap dump.  A test that makes many map outputs that are 0.7   4 = 17.5% of the reduce task heap can reliably recreate this problem and perhaps find other unaccounted large byte arrays.,Open,Unresolved,,Unassigned,Kevin Beyer,Sat; 12 Oct 2013 02:02:45 +0000,Sat; 12 Oct 2013 02:02:45 +0000,,,0.20.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5580
MAPREDUCE-5581,Bug,Major,client,killing jobs which have failed causes log missing,In hive code;when a job failed;they invoke the RunningJob.killJob() API immediately. From mapreduce client side;when job is at failed state;the YARNRunner will invoke resMgrDelegate.killApplication to kill that job.And this prevent AM from writing logs to job history server.,Resolved,Duplicate,MAPREDUCE-5502,Unassigned,Nemon Lou,Sat; 12 Oct 2013 08:19:48 +0000,Mon; 14 Oct 2013 14:05:17 +0000,Mon; 14 Oct 2013 14:05:17 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5581
MAPREDUCE-5582,Bug,Critical,capacity-sched,Setting mapred.job.reduce.memory.mb to 0 from a job with CapacityTracker leads to inconsistent state in JVMManager,"If a job sets mapred.job.reduce.memory.mb to 0 the capacity scheduler incorrectly allocates resources eventually causing ""Inconsistent state!!! JVM Manager reached an unstable state while reaping a JVM for task"" errors from the JVMManager killing all TaskTrackers that have been used for the job.",Resolved,Won't Fix,,Unassigned,Mikhail Davidov,Sun; 13 Oct 2013 23:54:32 +0000,Sat; 9 May 2015 00:22:44 +0000,Sat; 9 May 2015 00:22:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5582
MAPREDUCE-5583,Improvement,Major,mr-am;mrv2,Ability to limit running map and reduce tasks,It would be nice if users could specify a limit to the number of map or reduce tasks that are running simultaneously.  Occasionally users are performing operations in tasks that can lead to DDoS scenarios if too many tasks run simultaneously (e.g.: accessing a database; web service; etc.).  Having the ability to throttle the number of tasks simultaneously running would provide users a way to mitigate issues with too many tasks on a large cluster attempting to access a serivce at any one time.  This is similar to the functionality requested by MAPREDUCE-224 and implemented by HADOOP-3412 but was dropped in mrv2.,Closed,Fixed,MAPREDUCE-6176,Jason Lowe,Jason Lowe,Mon; 14 Oct 2013 21:16:49 +0000,Mon; 16 May 2016 19:54:04 +0000,Tue; 3 Mar 2015 10:16:45 +0000,,0.23.9;2.1.1-beta,,,MAPREDUCE-224;HADOOP-5170;YARN-3274;MAPREDUCE-6697,https://issues.apache.org/jira/browse/MAPREDUCE-5583
MAPREDUCE-5584,Bug,Blocker,,ShuffleHandler becomes unresponsive during gridmix runs and can leak file descriptors,While running gridmix on 2.3 we noticed that jobs are running much slower than normal.  We tracked this down to reducers having difficulties shuffling data from maps.  Details to follow.,Resolved,Duplicate,HADOOP-9652,Unassigned,Jason Lowe,Tue; 15 Oct 2013 15:29:36 +0000,Tue; 28 Jan 2014 23:33:43 +0000,Fri; 24 Jan 2014 15:55:22 +0000,,2.3.0,,,HADOOP-10048,https://issues.apache.org/jira/browse/MAPREDUCE-5584
MAPREDUCE-5585,Bug,Major,,TestCopyCommitter#testNoCommitAction Fails on JDK7,TestCopyCommitter#testNoCommitAction fails on JDK7 when run after testAtomicCommitMissingFinal or testAtomicCommitExistingFinal. Config settings are from atomic tests are being accidentally used for testNoCommitAction.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Tue; 15 Oct 2013 19:23:15 +0000,Thu; 12 May 2016 18:24:09 +0000,Wed; 16 Oct 2013 20:12:08 +0000,,0.23.9;2.3.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5585
MAPREDUCE-5586,Bug,Major,,TestCopyMapper#testCopyFailOnBlockSizeDifference fails when run from hadoop-tools/hadoop-distcp directory,nan,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 16 Oct 2013 03:27:27 +0000,Thu; 12 May 2016 18:23:03 +0000,Wed; 16 Oct 2013 20:30:32 +0000,,2.3.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5586
MAPREDUCE-5587,Bug,Major,,TestTextOutputFormat fails on JDK7,the test method run order on JDK7 is not fixed causing test method inter-dependencies to show themselves.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 17 Oct 2013 06:08:43 +0000,Thu; 12 May 2016 18:22:17 +0000,Fri; 18 Oct 2013 21:11:29 +0000,,0.23.10;2.3.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5587
MAPREDUCE-5588,Bug,Major,tasktracker,TaskTrackers get killed by JettyBugMonitor because of incredibly high cpu usage,We are running a little cluster with 10 servers running task trackers. All of them are getting killed randomly with the following message   2013-10-17 11:32:31;037 FATAL org.apache.hadoop.mapred.JettyBugMonitor: ************************************************************ Jetty CPU usage: 120093277.1%. This is greater than the fatal threshold mapred.tasktracker.jetty.cpu.threshold.fatal. Aborting JVM. ************************************************************ 2013-10-17 11:32:31;039 INFO org.apache.hadoop.mapred.TaskTracker: SHUTDOWN_MSG:     Everytime; the message notices a cpu usage above 120M%. Everything has been running for a while now (since 1.1.2 release) without any problems; and it started just like that.  Any idea of what could cause this ?,Resolved,Duplicate,MAPREDUCE-2980,Chris Nauroth,Anthony MOI,Thu; 17 Oct 2013 13:17:28 +0000,Thu; 17 Oct 2013 17:10:07 +0000,Thu; 17 Oct 2013 17:09:50 +0000,,1.1.2,cpu-usage;jetty;tasktracker,,MAPREDUCE-3184,https://issues.apache.org/jira/browse/MAPREDUCE-5588
MAPREDUCE-5589,Bug,Major,mrv1,MapReduce Job setup error leaves no useful info to users  (when LinuxTaskController is used),nan,Resolved,Won't Do,,Benoy Antony,Benoy Antony,Thu; 17 Oct 2013 17:43:00 +0000,Mon; 16 Oct 2017 19:45:06 +0000,Mon; 16 Oct 2017 19:45:06 +0000,,1.2.1,,,MAPREDUCE-4012,https://issues.apache.org/jira/browse/MAPREDUCE-5589
MAPREDUCE-5590,Bug,Major,,MiniMRClientClusterFactory in Hadoop 1.x forces local mode,Noticed the following in the 1.x branches:    The 2.x branches allow you to set what hadoop configuration to use (and which DFS cluster to connect to). For instance; in the Sqoop project we are using the MiniDFSCluster in conjunction with the MiniMRCluster.,Open,Unresolved,,Unassigned,Abraham Elmahrek,Thu; 17 Oct 2013 20:15:15 +0000,Thu; 17 Oct 2013 20:43:40 +0000,,,1.0.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5590
MAPREDUCE-5591,Task,Major,examples,K-ranker ,"Hi;  I recently wrote some code to find the max K integers corresponding a group.   Given one of more input files containing input lines of the following form:  ""key"";value  where key is a string       value is any integer  the program prints the top K elements corresponding to each key.  eg.  ""a"";1 ""b"";1 ""a"";2 ""a"";5 ""b"";17 ""c"";5 ""b"";6  if k = 2; the program prints  ""a"" 2;5 ""b"" 6;17 ""c"" 5  Compile steps: mvn clean mvn package  oc  Run steps:  hadoop jar ranking jar file  main class K input directory output directory eg. hadoop jar target output  Wanted to know if there is a component (examples maybe) where the code can be contributed. Also open to any suggestions for improvements.  Thanks; Arnab",Open,Unresolved,,Unassigned,Arnab,Mon; 21 Oct 2013 23:32:54 +0000,Mon; 21 Oct 2013 23:33:50 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5591
MAPREDUCE-5592,Improvement,Major,task-controller,Backport MAPREDUCE-1119 (stack traces on task timeout) in branch-1,MAPREDUCE-1119 dumps stack traces on a task timeout; making it easier this difficult case easier to debug.  This made it into 0.21; but never into branch-1; and the backport very very dirty.,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Wed; 23 Oct 2013 21:36:08 +0000,Tue; 5 Nov 2013 00:18:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5592
MAPREDUCE-5593,Improvement,Minor,applicationmaster,Cleanup code for AssignMapsWithLocality() in RMContainerAllocator,In RMContainerAllocator; AssignMapsWithLocality() is a very important method to assign map tasks on allocated containers with conforming different level of locality (dataLocal; rackLocal; etc.). However; this method messed with different code logic to handle different type of locality but have lots of similar behaviours. This is hard to maintain as well as do extension with other locality type; so we need some more clear code here.,Open,Unresolved,,Junping Du,Junping Du,Fri; 6 Sep 2013 15:24:41 +0000,Wed; 13 Nov 2013 04:21:07 +0000,,,,,MAPREDUCE-5427,,https://issues.apache.org/jira/browse/MAPREDUCE-5593
MAPREDUCE-5594,Bug,Major,mrv1,Combiner in mapred API gets only a dummy reporter,The OldCombinerRunner gets Reporter.NULL that doesn't really allow users to report progress from the combiner if they want to.,Open,Unresolved,,Naren Koneru,Karthik Kambatla,Thu; 24 Oct 2013 19:32:25 +0000,Mon; 3 Nov 2014 18:34:08 +0000,,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5594
MAPREDUCE-5595,Bug,Trivial,,Typo in MergeManagerImpl.java,"There's a typo (""Invlaid"" which should be ""Invalid"") in line 199 of MergeManagerImpl. currently:     if (this.maxSingleShuffleLimit = this.mergeThreshold)  {       throw new RuntimeException(""Invlaid configuration: ""           + ""maxSingleShuffleLimit should be less than mergeThreshold""           + ""maxSingleShuffleLimit: "" + this.maxSingleShuffleLimit           + ""mergeThreshold: "" + this.mergeThreshold);     }  should be:      if (this.maxSingleShuffleLimit = this.mergeThreshold)  {       throw new RuntimeException(""Invalid configuration: ""           + ""maxSingleShuffleLimit should be less than mergeThreshold""           + ""maxSingleShuffleLimit: "" + this.maxSingleShuffleLimit           + ""mergeThreshold: "" + this.mergeThreshold);     }",Closed,Fixed,,Akira Ajisaka,Efe Gencer,Fri; 25 Oct 2013 18:57:31 +0000,Thu; 12 May 2016 18:24:40 +0000,Thu; 14 Aug 2014 15:52:17 +0000,,2.2.0;3.0.0-alpha1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5595
MAPREDUCE-5596,Improvement,Major,,Allow configuring the number of threads used to serve shuffle connections,MR1 had mapreduce.tasktracker.http.threads.  MR2 always uses the Netty default 2 * Runtime.availableProcessors().  We should make this configurable.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Sat; 26 Oct 2013 01:08:00 +0000,Wed; 3 Sep 2014 23:35:28 +0000,Tue; 29 Oct 2013 13:57:47 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5596
MAPREDUCE-5597,Bug,Minor,client;documentation;job submission,Missing alternatives in javadocs for deprecated constructors in mapreduce.Job,Deprecated API; such as `new Job()` don't have  ocs explaining what the alternatives are. (It'd also help if the new methods had @since tags to help determine if one could safely use that API on older versions at runtime.),Closed,Fixed,MAPREDUCE-5341,Akira Ajisaka,Christopher Tubbs,Mon; 28 Oct 2013 19:17:46 +0000,Mon; 1 Dec 2014 03:09:14 +0000,Thu; 14 Aug 2014 15:57:37 +0000,,2.2.0,newbie,,MAPREDUCE-5800,https://issues.apache.org/jira/browse/MAPREDUCE-5597
MAPREDUCE-5598,Bug,Major,test,TestUserDefinedCounters.testMapReduceJob is flakey,"TestUserDefinedCounters.testMapReduceJob is flakey.    We sometimes see it fail:    Upon investigation; the problem is that the input for the MR job in this test is at System.getProperty(""test.build.data""; "" input"".  If an earlier test wrote some files there; this test will use them as part of its input.  This can cause all sorts of problems with this test because its not expecting the additional input data.",Closed,Fixed,,Robert Kanter,Robert Kanter,Mon; 28 Oct 2013 21:30:03 +0000,Tue; 10 Mar 2015 04:30:40 +0000,Tue; 29 Oct 2013 14:08:28 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5598
MAPREDUCE-5599,Improvement,Major,jobhistoryserver,JobHistoryServer unnecessarily copies all jobs on each query,Instead; in CachedHistoryStorage; we should only copy jobs that will be returned.,Open,Unresolved,,Sandy Ryza,Sandy Ryza,Mon; 28 Oct 2013 23:40:22 +0000,Mon; 28 Oct 2013 23:40:22 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5599
MAPREDUCE-5600,Bug,Major,tasktracker,ConcurrentModificationException on /tasktracker.jsp,If you request  tasktracker.jsp frequently on a TaskTracker that's busy; every once in a while you'll get this:,Open,Unresolved,,Unassigned,Benoit Sigoure,Tue; 29 Oct 2013 21:44:34 +0000,Tue; 12 Nov 2013 22:15:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5600
MAPREDUCE-5601,Improvement,Major,,ShuffleHandler fadvises file regions as DONTNEED even when fetch fails,When a reducer initiates a fetch request; it does not know whether it will be able to fit the fetched data in memory.  The first part of the response tells how much data will be coming.  If space is not currently available; the reduce will abandon its request and try again later.  When this occurs; the ShuffleHandler still fadvises the file region as DONTNEED.  Meaning that the next time it's asked for; it will definitely be read from disk; even if it happened to be in the page cache before the request.  I noticed this when trying to figure out why my job was doing so much more disk IO in MR2 than in MR1.  When I turned the fadvise stuff off; I found that disk reads went to nearly 0 on machines that had enough memory to fit map outputs into the page cache.  I then straced the NodeManager and noticed that there were over four times as many fadvise DONTNEED calls as map-reduce pairs.  Further logging showed the same map outputs being fetched about this many times.  This is a regression from MR1; which only did the fadvise DONTNEED after all the bytes were transferred.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 30 Oct 2013 00:23:17 +0000,Mon; 24 Feb 2014 20:57:19 +0000,Fri; 1 Nov 2013 08:55:46 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5601
MAPREDUCE-5602,Bug,Major,client,cygwin path error,the path for a file is received wrong; due to the fact that code is not taking into consideration cigwyn.  userlogs is not a valid path,Open,Unresolved,,Unassigned,Amit Cahanovich,Wed; 30 Oct 2013 09:22:36 +0000,Wed; 30 Oct 2013 09:22:36 +0000,,,2.0.6-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5602
MAPREDUCE-5603,Improvement,Minor,client;mrv2,Ability to disable FileInputFormat listLocatedStatus optimization to save client memory,It would be nice if users had the option to disable the listLocatedStatus optimization in FileInputFormat to save client memory.,Resolved,Won't Fix,,Jason Lowe,Jason Lowe,Wed; 30 Oct 2013 19:51:26 +0000,Tue; 22 Apr 2014 17:34:48 +0000,Tue; 22 Apr 2014 17:34:48 +0000,,0.23.10;2.2.0,,,MAPREDUCE-1981;MAPREDUCE-2349,https://issues.apache.org/jira/browse/MAPREDUCE-5603
MAPREDUCE-5604,Bug,Minor,test,TestMRAMWithNonNormalizedCapabilities fails on Windows due to exceeding max path length,The test uses the full class name as a component of the yarn.nodemanager.local-dirs setting for a MiniMRYarnCluster.  This causes container launch to fail when trying to access files at a path longer than the maximum of 260 characters.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Thu; 31 Oct 2013 06:02:13 +0000,Thu; 12 May 2016 18:22:38 +0000,Fri; 1 Nov 2013 19:27:13 +0000,,2.2.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5604
MAPREDUCE-5605,Improvement,Major,,Memory-centric MapReduce aiming to solve the I/O bottleneck,Memory is a very important resource to bridge the gap between CPUs and I O bottleneck. We developed a multi-threaded task execution engine; which runs in a single JVM on a node. In the execution engine; we have implemented the algorithm of memory scheduling to realize global memory management; based on which we further developed the techniques such as sequential disk accessing; multi-cache and solved the problem of full garbage collection in the JVM. The benchmark results shows that it can get impressive improvement in typical cases. When the a system is relatively short of memory (eg; HPC; small- and medium-size enterprises); the improvement will be even more impressive.,Patch Available,Unresolved,,Ming Chen,Ming Chen,Sat; 2 Nov 2013 14:18:27 +0000,Wed; 6 May 2015 03:26:09 +0000,,,1.0.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5605
MAPREDUCE-5606,Bug,Critical,jobtracker,JobTracker blocked for DFSClient: Failed recovery attempt,when a  datanode was crash;the server can  ping ok;but can not  call rpc ;and also can not ssh login. and then jobTracker may be request a block on this datanode. it will happened ;the  JobTracker can not work;the webUI is also unwork;hadoop job -list also unwork;the jobTracker logs no other info .  and then we need to restart the datanode. then jobTraker can work too;but the taskTracker num come to zero; we need run : hadoop mradmin -refreshNodes then the JobTracker begin to add taskTraker ;but is very slowly.  this problem occur 5time  in 2weeks.,Resolved,Won't Fix,,Unassigned,firegun,Tue; 5 Nov 2013 02:48:03 +0000,Sat; 9 May 2015 00:27:51 +0000,Sat; 9 May 2015 00:27:51 +0000,,1.0.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5606
MAPREDUCE-5607,Sub-task,Major,,Backport MAPREDUCE-5086 - MR app master deletes staging dir when sent a reboot command from the RM,If the RM is restarted when the MR job is running; then it sends a reboot command to the job. The job ends up deleting the staging dir and that causes the next attempt to fail.,Resolved,Won't Fix,,Jonathan Eagles,Jonathan Eagles,Tue; 5 Nov 2013 20:47:21 +0000,Thu; 27 Mar 2014 20:50:17 +0000,Thu; 27 Mar 2014 20:50:17 +0000,,0.23.9,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5607
MAPREDUCE-5608,Improvement,Major,,Replace and deprecate mapred.tasktracker.indexcache.mb,In MR2 mapred.tasktracker.indexcache.mb still works for configuring the size of the shuffle service index cache.  As the tasktracker no longer exists; we should replace this with something like mapreduce.shuffle.indexcache.mb.,Patch Available,Unresolved,,Akira Ajisaka,Sandy Ryza,Tue; 5 Nov 2013 21:18:43 +0000,Mon; 17 Oct 2016 08:40:59 +0000,,,2.2.0,BB2015-05-TBR;configuration;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5608
MAPREDUCE-5609,Improvement,Major,,Add debug log message when sending job end notification,Currently; it's hard to tell if the job end notification is working and if its backed up because you only see log messages if there was an error making the notification.  It would be helpful to add a debug log message when the job end notification is sent.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Wed; 6 Nov 2013 22:06:41 +0000,Wed; 6 Nov 2013 22:15:55 +0000,Wed; 6 Nov 2013 22:15:55 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5609
MAPREDUCE-5610,Test,Major,,TestSleepJob fails in jdk7,In jdk7 tests methods in a class do not run in file order; but rather in random order. TestSleepJob hosts are not initialized and a NullPointerException is thrown unless testRandomLocation was run first.  This can be easily seen by running tests individually.  org.apache.hadoop.mapred.gridmix.TestSleepJob#testStressSubmit org.apache.hadoop.mapred.gridmix.TestSleepJob#testReplaySubmit org.apache.hadoop.mapred.gridmix.TestSleepJob#testSerialSubmit org.apache.hadoop.mapred.gridmix.TestSleepJob#testMapTasksOnlySleepJobs org.apache.hadoop.mapred.gridmix.TestSleepJob#testRandomLocation,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Wed; 6 Nov 2013 23:31:04 +0000,Wed; 3 Sep 2014 23:40:08 +0000,Wed; 13 Nov 2013 16:26:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5610
MAPREDUCE-5611,Bug,Major,,CombineFileInputFormat only requests a single location per split when more could be optimal,I have come across an issue with CombineFileInputFormat. Actually I ran a hive query on approx 1.2 GB data with CombineHiveInputFormat which internally uses CombineFileInputFormat. My cluster size is 9 datanodes and max.split.size is 256 MB When I ran this query with replication factor 9; hive consistently creates all 6 rack-local tasks and with replication factor 3 it creates 5 rack-local and 1 data local tasks.    When replication factor is 9 (equal to cluster size); all the tasks should be data-local as each datanode contains all the replicas of the input data; but that is not happening i.e all the tasks are rack-local.   When I dug into CombineFileInputFormat. code in getMoreSplits method; I found the issue with the following snippet (specially in case of higher replication factor)      First node in the map nodeToBlocks has all the replicas of input file; so the above code creates 6 splits all with only one location. Now if JT doesn't schedule these tasks on that node; all the tasks will be rack-local; even though all the other datanodes have all the other replicas.,Patch Available,Unresolved,,Chandra Prakash Bhagtani,Chandra Prakash Bhagtani,Thu; 7 Nov 2013 06:57:14 +0000,Wed; 6 May 2015 03:32:50 +0000,,,1.2.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5611
MAPREDUCE-5612,Improvement,Minor,documentation,Add javadoc for TaskCompletionEvent.Status,What's the difference between FAILED and TIPFAILED?  What is OBSOLETE?,Closed,Fixed,,Chris Palmer,Sandy Ryza,Thu; 7 Nov 2013 17:28:14 +0000,Fri; 10 Apr 2015 20:19:43 +0000,Thu; 26 Feb 2015 23:07:47 +0000,,2.2.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5612
MAPREDUCE-5613,Bug,Major,applicationmaster,DefaultSpeculator holds and checks hashmap that is always empty,The only way pendingSpeculations is used:,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Thu; 7 Nov 2013 23:38:02 +0000,Mon; 24 Feb 2014 20:57:16 +0000,Wed; 13 Nov 2013 09:27:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5613
MAPREDUCE-5614,Bug,Major,,job history file name should escape job status,"Our cluster's queue name contains hyphen e.g. cug-taobao. Because hyphen is the delimiter of job history file name; JobHistoryServer shows ""cug"" as the queue name. To fix this problem; we should escape queuename in job history file name.",Resolved,Fixed,,Liyin Liang,Liyin Liang,Fri; 8 Nov 2013 03:50:58 +0000,Wed; 16 Nov 2016 20:11:36 +0000,Wed; 16 Nov 2016 20:11:33 +0000,,2.2.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5614
MAPREDUCE-5615,New Feature,Minor,client,Off-the-shelf funtionality for processing of Image; Video; Audio files,The FileInputFormat;FileOutputFormat; FileRecordReader; FileRecordWriter  are not ideal for processing of media data types. Believe most use SequenceFile and repeat their own set of media transcoding  processing to enable big data processing for them. There might be few non open source implementations to handle image; video; audio processing.Maybe MapR has some impl.  Suggest we have standard off-the-shelf functionality to handle these kind of input datatypes -  ImageInputFormat; ImageOutputFormat; ImageRecordReader; ImageRecordWriter VideoFileInputFormat;VideoFileOutputFormat; VideoRecordReader;VideoRecordWriter AudioFileInputFormat;AudioFileOutputFormat; AudioRecordReader; AudioRecordWriter,Open,Unresolved,,Rekha Joshi,Rekha Joshi,Fri; 8 Nov 2013 08:41:37 +0000,Fri; 22 Nov 2013 07:50:25 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5615
MAPREDUCE-5616,Bug,Major,client,MR Client-AppMaster RPC max retries on socket timeout is too high.,MAPREDUCE-3811 introduced a separate config key for overriding the max retries applied to RPC connections from the MapReduce Client to the MapReduce Application Master.  This was done to make failover from the AM to the MapReduce History Server faster in the event that the AM completes while the client thinks it's still running.  However; the RPC client uses a separate setting for socket timeouts; and this one is not overridden.  The default for this is 45 retries with a 20-second timeout on each retry.  This means that in environments subject to connection timeout instead of connection refused; the client waits 15 minutes for failover.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Fri; 8 Nov 2013 18:15:40 +0000,Thu; 12 May 2016 18:22:31 +0000,Thu; 14 Nov 2013 18:14:21 +0000,,2.2.0;3.0.0-alpha1,,,MAPREDUCE-3811,https://issues.apache.org/jira/browse/MAPREDUCE-5616
MAPREDUCE-5617,Bug,Critical,,map task is not re-launched when the task is failed while reducers are running with full cluster capacity - which will lead to job hang,In a Cluster with 16GB capacity; job has started with 100maps and 10 reducers.   When the reducers has started its execution; one NM has went down and resulted a failure for 2 maps. But at this time; remaining 8Gb was used by 6 reducers and AM. So there was no place to launch the failed maps. NM never came up again; and cluster size became 8GB  If we kill one of reducers; then also the map cannot be launched as the priority of Failed map is lesser than that of reducer. So the remaining reducer only will get allocated from RM side.  This is causing a hang for in reducer side.,Resolved,Invalid,,Unassigned,Sunil G,Mon; 11 Nov 2013 06:28:36 +0000,Sat; 9 May 2015 02:17:29 +0000,Sat; 9 May 2015 02:17:29 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5617
MAPREDUCE-5618,Improvement,Major,mr-am,Allow setting lineage information,"MR AM sets the applicationType to be ""MAPREDUCE"". Downstream projects like Pig; Hive; Oozie might want to set this to a different value for their error-handling; query-tracking etc. Making this pluggable should help this cause.",Resolved,Duplicate,MAPREDUCE-5699,Karthik Kambatla,Karthik Kambatla,Mon; 11 Nov 2013 07:41:00 +0000,Mon; 3 Nov 2014 18:33:35 +0000,Wed; 8 Jan 2014 18:00:54 +0000,,2.2.0,,YARN-1390,,https://issues.apache.org/jira/browse/MAPREDUCE-5618
YARN-1403,Improvement,Major,,Separate out configuration loading from QueueManager in the Fair Scheduler,nan,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 12 Nov 2013 03:34:11 +0000,Mon; 24 Feb 2014 20:58:23 +0000,Thu; 5 Dec 2013 03:30:48 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/YARN-1403
MAPREDUCE-5620,Bug,Major,,distcp1 -delete fails when target directory contains files with percent signs,"Debugging a distcp1 issue; it fails to delete extra files in the target directory when there is a percent sign in the filename. I'm pretty sure this is an issue with how percent encoding is handled in FsShell (reproduced with just ""hadoop fs -rmr""); but we can also fix this in distcp1 by using FileSystem instead of FsShell. This is what distcp2 does.",Resolved,Invalid,,Andrew Wang,Andrew Wang,Tue; 12 Nov 2013 21:59:52 +0000,Wed; 13 Nov 2013 00:12:37 +0000,Wed; 13 Nov 2013 00:12:37 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5620
MAPREDUCE-5621,Bug,Minor,jobhistoryserver,mr-jobhistory-daemon.sh doesn't have to execute mkdir and chown all the time,"mr-jobhistory-daemon.sh executes mkdir and chown command to output the log files. This is always executed with or without a directory. In addition; this is executed not only starting daemon but also stopping daemon. It add ""if"" like hadoop-daemon.sh and yarn-daemon.sh and should control it.",Resolved,Fixed,,Shinichi Yamashita,Shinichi Yamashita,Wed; 13 Nov 2013 00:55:44 +0000,Wed; 12 Jul 2017 19:59:21 +0000,Wed; 12 Jul 2017 19:59:21 +0000,,2.8.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5621
MAPREDUCE-5622,Bug,Major,applicationmaster,MRAppMaster doesn't assign all allocated NODE_LOCAL containers to node-local maps,MRAppMaster will request containers for all the splits to launch map tasks; RM will give Node Local containers for all these if available. When the RM gives all containers as Node Local; MR AM may assign these  NODE-LOCAL containers to non-local maps.       Consider this instance; assume RM has given one NODE LOCAL container on each node to process all the splits as local maps. While assigning; if the AM gives node1-container for split1; node2-container for split3; node3-container for split3 and node4-container can be given to only split2 which is not local.,Open,Unresolved,,Unassigned,Devaraj K,Wed; 13 Nov 2013 06:23:34 +0000,Wed; 13 Nov 2013 15:40:20 +0000,,,2.2.0,,,MAPREDUCE-4893,https://issues.apache.org/jira/browse/MAPREDUCE-5622
MAPREDUCE-5623,Bug,Major,,TestJobCleanup fails because of RejectedExecutionException and NPE.,org.apache.hadoop.mapred.TestJobCleanup can fail because of RejectedExecutionException by NonAggregatingLogHandler. This problem is described in YARN-1409. TestJobCleanup can still fail after fixing RejectedExecutionException; because of NPE by Job#getCounters()'s returning null.,Closed,Fixed,,Jason Lowe,Tsuyoshi Ozawa,Wed; 13 Nov 2013 11:19:20 +0000,Tue; 10 Mar 2015 04:30:14 +0000,Mon; 16 Dec 2013 17:59:35 +0000,,,,,YARN-1409,https://issues.apache.org/jira/browse/MAPREDUCE-5623
MAPREDUCE-5624,Improvement,Major,build,move grizzly-test and junit dependencies to test scope,stop the the grizzly dependences  Junit getting into everything downstream by moving them to test scope,Resolved,Fixed,,Ted Yu,Steve Loughran,Wed; 13 Nov 2013 20:34:10 +0000,Fri; 15 Nov 2013 12:39:17 +0000,Fri; 15 Nov 2013 12:39:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5624
MAPREDUCE-5625,Test,Major,,TestFixedLengthInputFormat fails in jdk7 environment,nan,Closed,Fixed,,Mariappan Asokan,Jonathan Eagles,Wed; 13 Nov 2013 21:30:02 +0000,Thu; 12 May 2016 18:23:20 +0000,Sun; 17 Nov 2013 14:42:06 +0000,,2.3.0;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-5625
MAPREDUCE-5626,Bug,Minor,,TaskLogServlet could not get syslog,"When multiply tasks use one jvm and generated logs. eg. .  thefile doesn't have anything                       throw new IOException(""Index file for the log of "" + taskId                               + ""is empty."");                   }                    String loc = str.substring(str.indexOf(LogFileDetail.LOCATION)                           + LogFileDetail.LOCATION.length());                   File tf = new File(loc; type.toString());                   return tf.exists() &amp; tf.canRead();                 } finally  {                   if (fis != null)                       fis.close();               }            }         }    workaround: url add filter=SYSLOG could print syslog also.",Resolved,Won't Fix,,Unassigned,yangjun,Fri; 15 Nov 2013 01:59:05 +0000,Mon; 18 May 2015 18:12:57 +0000,Mon; 18 May 2015 18:12:57 +0000,,1.2.1,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-5626
MAPREDUCE-5627,Bug,Minor,,TaskLogServlet could not get syslog,"When multiply tasks use one jvm and generated logs. eg. .  thefile doesn't have anything                       throw new IOException(""Index file for the log of "" + taskId                               + ""is empty."");                   }                    String loc = str.substring(str.indexOf(LogFileDetail.LOCATION)                           + LogFileDetail.LOCATION.length());                   File tf = new File(loc; type.toString());                   return tf.exists() &amp; tf.canRead();                 } finally  {                   if (fis != null)                       fis.close();               }            }         }    workaround: url add filter=SYSLOG could print syslog also.",Open,Unresolved,,Unassigned,yangjun,Fri; 15 Nov 2013 01:59:16 +0000,Fri; 15 Nov 2013 01:59:16 +0000,,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5627
MAPREDUCE-5628,Bug,Critical,job submission,Tracking ids only for HDFS tokens should be included in jobconf,MAPREDUCE-5379 adds the ability to track HDFS accesses of an MR job by adding the tracking-ids from all the tokens to the jobconf. However; only HDFS delegation tokens have a tracking-id. Trying to fetch tracking-ids from other tokens can lead to an NPE.,Resolved,Not A Problem,,Karthik Kambatla,Karthik Kambatla,Fri; 15 Nov 2013 03:35:32 +0000,Mon; 3 Nov 2014 18:33:42 +0000,Thu; 16 Jan 2014 01:46:59 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5628
PIG-3579,Bug,Major,,pig.script's deserialized version does not maintain line numbers,If pig.script is decoded with base64; it loses line numbers because the buffered reader that adds the lines; removes ' n's.,Resolved,Fixed,,Jiaji Grace Zhang,Aniket Mokashi,Sat; 16 Nov 2013 01:34:51 +0000,Mon; 18 Nov 2013 20:03:33 +0000,Mon; 18 Nov 2013 20:03:33 +0000,,,,,,https://issues.apache.org/jira/browse/PIG-3579
YARN-1419,Bug,Minor,scheduler,TestFifoScheduler.testAppAttemptMetrics fails intermittently under jdk7 ,QueueMetrics holds its data in a static variable causing metrics to bleed over from test to test. clearQueueMetrics is to be called for tests that need to measure metrics correctly for a single test. jdk7 comes into play since tests are run out of order; and in the case make the metrics unreliable.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Sat; 16 Nov 2013 04:37:13 +0000,Thu; 12 May 2016 18:30:37 +0000,Mon; 18 Nov 2013 19:32:26 +0000,,0.23.10;2.3.0;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/YARN-1419
MAPREDUCE-5631,Bug,Major,,TestJobEndNotifier.testNotifyRetries fails with Should have taken more than 5 seconds in jdk7,Configuration settings are bleeding over from test to test in jdk7 environment since tests are run in random order.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Sun; 17 Nov 2013 15:14:46 +0000,Thu; 12 May 2016 18:23:23 +0000,Thu; 21 Nov 2013 17:56:47 +0000,,0.23.10;2.3.0;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-5631
MAPREDUCE-5632,Test,Major,,TestRMContainerAllocator#testUpdatedNodes fails,From https: console :   This assertion fails:   The List returned by allocator.getJobUpdatedNodeEvents() is: EventType: JOB_UPDATED_NODES,Closed,Fixed,MAPREDUCE-5427,Jonathan Eagles,Ted Yu,Sat; 16 Nov 2013 15:51:30 +0000,Wed; 3 Sep 2014 23:35:25 +0000,Wed; 4 Dec 2013 22:18:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5632
MAPREDUCE-5633,Task,Major,,Can Hadoop use multi-cores of a processor under single machine,nan,Resolved,Invalid,,Unassigned,Asif,Wed; 20 Nov 2013 19:57:59 +0000,Wed; 20 Nov 2013 20:18:38 +0000,Wed; 20 Nov 2013 20:18:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5633
MAPREDUCE-5634,Bug,Major,,Documentation for FileInputFormat->listStatus seems to be wrong,Take a look at http: FileInputFormat.html  Javadoc says: listStatus(JobConf job)            List input directories  whereas it returns FileStatus[].  Java doc should say; it returns an array containing information about the input directories.,Open,Unresolved,,Unassigned,Pranay Varma,Wed; 20 Nov 2013 22:02:33 +0000,Thu; 21 Nov 2013 19:08:57 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5634
MAPREDUCE-5635,Bug,Major,,FileInputFormat does not specify how the file is split,Here is what the TextInputFormat  oc says: TextInputFormat  An InputFormat for plain text files. Files are broken into lines. Either linefeed or carriage-return are used to signal end of line. Keys are the position in the file; and values are the line of text..  FileInputFormat should say the same on FileInputFormat,Resolved,Not A Problem,,Unassigned,Pranay Varma,Wed; 20 Nov 2013 22:59:19 +0000,Thu; 5 Dec 2013 16:59:36 +0000,Thu; 5 Dec 2013 15:24:00 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5635
MAPREDUCE-5636,Sub-task,Major,documentation,Convert MapReduce Tutorial document to APT,Convert MapReduce Tutorial document from forrest to APT.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 21 Nov 2013 08:47:58 +0000,Wed; 3 Sep 2014 20:33:50 +0000,Tue; 6 May 2014 16:19:49 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5636
MAPREDUCE-5637,Sub-task,Major,documentation,Convert Hadoop Streaming document to APT,Convert Hadoop Streaming document from forrest to APT.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 21 Nov 2013 08:49:20 +0000,Wed; 3 Sep 2014 20:33:50 +0000,Tue; 6 May 2014 16:06:37 +0000,,2.2.0,,,MAPREDUCE-4975,https://issues.apache.org/jira/browse/MAPREDUCE-5637
MAPREDUCE-5638,Sub-task,Major,documentation,Port Hadoop Archives document to trunk,Now Hadoop Archive document exists only in branch-1. Let's port Hadoop Archives document to trunk.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 21 Nov 2013 08:52:13 +0000,Wed; 3 Sep 2014 20:33:53 +0000,Tue; 29 Apr 2014 21:24:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5638
MAPREDUCE-5639,Sub-task,Major,documentation,Port DistCp2 document to trunk,Port DistCp2 document (http: distcp2.html)  to trunk.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 21 Nov 2013 08:54:30 +0000,Wed; 3 Sep 2014 20:33:51 +0000,Fri; 25 Apr 2014 20:33:13 +0000,,2.2.0,,,MAPREDUCE-5922;MAPREDUCE-5809,https://issues.apache.org/jira/browse/MAPREDUCE-5639
MAPREDUCE-5640,Improvement,Trivial,test,Rename TestLineRecordReader in jobclient module,HADOOP-9622 proposes to add new unit tests for LineRecordReader in the mapreduce-client-core module alongside the code.  The existing LineRecordReader tests in the mapreduce-client-jobclient module should be renamed to something like TestLineRecordReaderJobs to avoid a name conflict and to better indicate these are integration tests using full jobs rather than unit tests.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 21 Nov 2013 15:04:32 +0000,Wed; 3 Sep 2014 23:40:09 +0000,Mon; 2 Dec 2013 19:17:32 +0000,,0.23.9;2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5640
MAPREDUCE-5641,Improvement,Major,applicationmaster;jobhistoryserver,History for failed Application Masters should be made available to the Job History Server,"Currently; the JHS has no information about jobs whose AMs have failed.  This is because the History is written by the AM to the intermediate folder just before finishing; so when it fails for any reason; this information isn't copied there.  However; it is not lost as its in the AM's staging directory.  To make the History available in the JHS; all we need to do is have another mechanism to move the History from the staging directory to the intermediate directory.  The AM also writes a ""Summary"" file before exiting normally; which is also unavailable when the AM fails.",Open,Unresolved,MAPREDUCE-5418,Unassigned,Robert Kanter,Thu; 21 Nov 2013 22:35:49 +0000,Wed; 23 Aug 2017 09:21:52 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5641
MAPREDUCE-5642,Test,Minor,test,TestMiniMRChildTask fails on Windows,"The test fails on Windows as a regression from MAPREDUCE-5451. In MAPREDUCE-5451; we set default config of ""mapreduce.admin.user.env"" to ""PATH=%PATH%;%HADOOP_COMMON_HOME%bin"" on Windows. In the test; we set ""PATH=%PATH%;tmp"" for ""mapreduce.map.env"" and ""mapreduce.map.env"". Because the the change in MAPREDUCE-5451; PATH will be set twice now and the value we get in the child tasks no longer matches the previous expected value.",Closed,Fixed,MAPREDUCE-5850,Chuan Liu,Chuan Liu,Fri; 22 Nov 2013 02:06:56 +0000,Thu; 12 May 2016 18:23:29 +0000,Sat; 19 Apr 2014 04:21:14 +0000,,2.4.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5642
MAPREDUCE-5643,Improvement,Major,contrib/fair-share,DynamicMR: A Dynamic Slot Utilization Optimization Framework for Hadoop MRv1,Hadoop MRv1 uses the slot-based resource model with the static configuration of map reduce slot configuration.,Patch Available,Unresolved,,tang shanjiang,tang shanjiang,Fri; 22 Nov 2013 09:10:46 +0000,Wed; 6 May 2015 03:26:13 +0000,,,1.2.1,BB2015-05-TBR;performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-5643
MAPREDUCE-5644,Bug,Major,,error while querying the HDFS (hdfs dfs -ls) [local and destination host is not matching],"I have installed the hive on the local machine and hadoop started to gave error. It was not giving error before Hive installation while query hdfs dfs -ls. Below is the error  ""local host is: ""ubuntu 127.0.1.1""; destination host is: ""localhost"":9000""  i am trying to setup the single node on my laptop runnin gubuntu. I tried alot after chaning IP address in the host file but couldn't able to get rid out of this error. My host file entries as below  127.0.0.1 localhost 127.0.1.1 ubuntu",Open,Unresolved,,Manoj Kumar Danthala,Asif,Fri; 22 Nov 2013 19:45:38 +0000,Sun; 14 Sep 2014 13:26:51 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5644
MAPREDUCE-5645,Bug,Major,,TestFixedLengthInputFormat fails with native libs,mvn clean install -Pnative -DskipTests hadoop-mapreduce-project hadoop-mapreduce-client-jobclient mvn clean test -Dtest=TestFixedLengthInputFormat  Running org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat Tests run: 8; Failures: 0; Errors: 2; Skipped: 0; Time elapsed: 39.957 sec &lt; FAILURE! - in org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat testGzipWithTwoInputs(org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat)  Time elapsed: 0.029 sec  &lt; ERROR!  90)   Results :  Tests in error:    TestFixedLengthInputFormat.testGzipWithTwoInputs:229-writeFile:397   NullPointer   TestFixedLengthInputFormat.testFormatCompressedIn:96-runRandomTests:314-createFile:261   NullPointer   TestFixedLengthInputFormat.testPartialRecordCompressedIn:182-runPartialRecordTest:386-writeFile:357   NullPointer   TestFixedLengthInputFormat.testGzipWithTwoInputs:201-writeFile:357   NullPointer   TestFixedLengthInputFormat.testFormatCompressedIn:90-runRandomTests:287-createFile:234   NullPointer  Tests run: 16; Failures: 0; Errors: 5; Skipped: 0,Closed,Fixed,,Mit Desai,Jonathan Eagles,Fri; 22 Nov 2013 21:12:28 +0000,Thu; 12 May 2016 18:22:57 +0000,Tue; 3 Dec 2013 22:55:03 +0000,,2.3.0;3.0.0-alpha1,native,,,https://issues.apache.org/jira/browse/MAPREDUCE-5645
MAPREDUCE-5646,Improvement,Major,,Option to shuffle splits of equal size,Mapreduce split calculation has the following base logic (via JobClient and the major InputFormat implementations ):  enumerate input files in natural (aka linear) order.  create one split for each 'block-size' of each input. Apart from rack-awareness; combining and so on; the input file order remains in its natural order.  sort the splits by size using a stable sort based on splitsize.  When data from multiple storage services are used in a single hadoop job; we get better I then logic is used.,Resolved,Won't Fix,,Mike Liddell,Mike Liddell,Fri; 22 Nov 2013 22:34:10 +0000,Tue; 10 Mar 2015 04:30:40 +0000,Thu; 23 Jan 2014 19:45:51 +0000,,1-win,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5646
MAPREDUCE-5647,Improvement,Major,,no property for changing ShuffleHandler binding host,"org.apache.hadoop.mapred.ShuffleHandler has a property ""mapreduce.shuffle.port"" with the default value ""13562""; though there is no ""mapreduce.shuffle.host"".  Thus ShuffleHandler always binds to 0.0.0.0 and it is thus impossible to make hadoop completely bind to localhost if desired. This setting is in contrast available for all other port bindings.",Open,Unresolved,,Unassigned,subes,Sat; 23 Nov 2013 17:39:13 +0000,Sat; 23 Nov 2013 17:39:13 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5647
MAPREDUCE-5648,Improvement,Major,client;mr-am;mrv2,Allow user-specified diagnostics for killed tasks and jobs,Our users and tools want to be able to supply additional custom diagnostic messages to mapreduce ClientProtocol killTask.,Open,Unresolved,,Gera Shegalov,Gera Shegalov,Sat; 23 Nov 2013 19:07:17 +0000,Sat; 7 Jan 2017 01:59:51 +0000,,,2.2.0,,YARN-1551;MAPREDUCE-5754,,https://issues.apache.org/jira/browse/MAPREDUCE-5648
MAPREDUCE-5649,Bug,Major,mrv2,Reduce cannot use more than 2G memory  for the final merge,In the org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl. file; in the finalMerge method:    int maxInMemReduce = (int)Math.min(         Runtime.getRuntime().maxMemory() * maxRedPer; Integer.MAX_VALUE);  This means no matter how much memory user has; reducer will not retain more than 2G data in memory before the reduce phase starts.,Closed,Fixed,MAPREDUCE-4883,Gera Shegalov,stanley shi,Mon; 25 Nov 2013 05:32:19 +0000,Fri; 6 Jan 2017 01:00:19 +0000,Mon; 4 May 2015 19:05:29 +0000,,,2.6.1-candidate;2.7.2-candidate,,MAPREDUCE-4883,https://issues.apache.org/jira/browse/MAPREDUCE-5649
MAPREDUCE-5650,Bug,Major,mrv2,Job fails when hprof mapreduce.task.profile.map/reduce.params is specified,When one uses dedicated hprof mapreduce.task.profile.map.params or mapreduce.task.profile.reduce.params; the profiled tasks will fail to launch because hprof parameters are supplied to the child jvm twice.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Mon; 25 Nov 2013 07:06:34 +0000,Mon; 24 Feb 2014 20:56:49 +0000,Fri; 17 Jan 2014 17:54:00 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5650
MAPREDUCE-5651,Improvement,Major,scheduler,Backport Fair Scheduler queue placement policies to branch-1,YARN-1392 introduced general policies for assigning applications to queues in the YARN fair scheduler.  This functionality would be useful and minimally invasive in MR1 as well.,Resolved,Fixed,,Ted Malaska,Sandy Ryza,Mon; 25 Nov 2013 16:28:49 +0000,Tue; 7 Jan 2014 23:53:59 +0000,Tue; 7 Jan 2014 23:39:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5651
MAPREDUCE-5652,Bug,Major,,NM Recovery. ShuffleHandler should handle NM restarts,ShuffleHandler should work across NM restarts and not require re-running map-tasks. On NM restart; the map outputs are cleaned up requiring re-execution of map tasks and should be avoided.,Closed,Fixed,,Jason Lowe,Karthik Kambatla,Mon; 25 Nov 2013 21:06:53 +0000,Mon; 3 Nov 2014 18:33:48 +0000,Tue; 13 May 2014 19:16:14 +0000,,2.2.0,shuffle,YARN-1757,YARN-1336,https://issues.apache.org/jira/browse/MAPREDUCE-5652
MAPREDUCE-5653,Bug,Major,distcp,DistCp does not honour config-overrides for mapreduce.[map;reduce].memory.mb,When a DistCp job is run through Oozie (through a Java action that launches DistCp); one sees that mapred.child. opts as set from the caller is honoured by DistCp. But; DistCp doesn't seem to honour any overrides for configs mapreduce.map;reduce.memory.mb.  Problem has been identified. I'll post a patch shortly.,Resolved,Fixed,,Ratandeep Ratti,Mithun Radhakrishnan,Mon; 25 Nov 2013 23:11:05 +0000,Mon; 27 Mar 2017 12:01:22 +0000,Sun; 1 Mar 2015 06:54:06 +0000,,0.23.9;2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5653
MAPREDUCE-5654,Bug,Major,applicationmaster,blacklist is not propagated from AM to RM,I was trying to blacklist some nodes. I added a set of hosts as strings into blacklistAdditions list and propagated into RMContainerRequestor#makeRemoteRequest to the RM.   However the blacklist is received empty at RM. I logged the path for blacklist in AM and I found that in ApplicationMasterProtocolPBClientImpl#allocate; this list is lost.   I print request.getResourceBlacklistRequest().getBlacklistAdditions().toString() at the beginning of ApplicationMasterProtocolPBClientImpl#allocate and the blacklisted additions are there.   After AllocateRequestProto requestProto is created based on this request; and I print again requestProto.getBlacklistRequest().getBlacklistAdditionsList().toString(); the blacklist additions is empty now.  I looked even further and log what happened. At some point in yarn-api; I was lost with my logging as that code was regenerated every time I recompiled yarn-api.   Thanks; robert,Open,Unresolved,,Unassigned,Robert Grandl,Mon; 25 Nov 2013 19:29:00 +0000,Mon; 21 Jul 2014 19:04:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5654
MAPREDUCE-5655,Bug,Major,client;job submission,Remote job submit from windows to a linux hadoop cluster fails due to wrong classpath,I was trying to run a  class on my client; windows 7 developer environment; which submits a job to the remote Hadoop cluster; initiates a mapreduce there; and then downloads the results back to the local machine.  General use case is to use hadoop services from a web application installed on a non-cluster computer; or as part of a developer environment.  The problem was; th the job runner will be a linux:   property   namemapred.remote.os property  without this entry; the patched jar does the same as the unpatched; so it's required to work!,Resolved,Duplicate,MAPREDUCE-4052,JoneZhang,Attila Pados,Tue; 26 Nov 2013 13:16:16 +0000,Thu; 10 Apr 2014 04:16:23 +0000,Mon; 2 Dec 2013 18:35:29 +0000,,2.2.0;2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5655
MAPREDUCE-5656,Bug,Critical,,bzip2 codec can drop records when reading data in splits,Bzip2Codec.BZip2CompressionInputStream can cause records to be dropped when reading them in splits based on where record delimiters occur relative to compression block boundaries.  Thanks to Koji Noguchi for discovering this problem while working on PIG-3251.,Closed,Fixed,MAPREDUCE-5143,Jason Lowe,Jason Lowe,Wed; 5 Jun 2013 20:54:22 +0000,Fri; 12 Jun 2015 19:59:32 +0000,Mon; 9 Dec 2013 23:42:41 +0000,,2.0.4-alpha;0.23.8,,,MAPREDUCE-5948;PIG-3251,https://issues.apache.org/jira/browse/MAPREDUCE-5656
MAPREDUCE-5657,Bug,Minor,documentation,[JDK8] Fix Javadoc errors caused by incorrect or illegal tags in doc comments,Javadoc is more strict by default in JDK8 and will error out on malformed or illegal tags found in doc comments. Although tagged as JDK8 all of the required changes are generic Javadoc cleanups.,Closed,Fixed,,Akira Ajisaka,Andrew Purtell,Wed; 27 Nov 2013 21:17:13 +0000,Fri; 10 Apr 2015 20:19:42 +0000,Mon; 9 Mar 2015 03:06:55 +0000,,2.7.0,,,HADOOP-10134;HADOOP-11090,https://issues.apache.org/jira/browse/MAPREDUCE-5657
MAPREDUCE-5658,Bug,Major,jobhistoryserver,JHS API and other changes to support tags,YARN-1399 introduces support for adding tags to an application. The JHS should use this and support querying MR jobs with particular tags set.,Open,Unresolved,,Unassigned,Karthik Kambatla,Fri; 29 Nov 2013 07:13:14 +0000,Mon; 3 Nov 2014 18:33:35 +0000,,,2.2.0,,YARN-1399,,https://issues.apache.org/jira/browse/MAPREDUCE-5658
HIVE-5910,Bug,Major,,In HiveConf; the name of mapred.min.split.size.per.rack is MAPREDMINSPLITSIZEPERNODE and the name of mapred.min.split.size.per.node is MAPREDMINSPLITSIZEPERRACK,In HiveConf. ...,Resolved,Fixed,HIVE-6572,Sushanth Sowmyan,Yin Huai,Sat; 30 Nov 2013 15:19:16 +0000,Thu; 20 Mar 2014 22:01:38 +0000,Thu; 20 Mar 2014 22:01:38 +0000,,,,,,https://issues.apache.org/jira/browse/HIVE-5910
MAPREDUCE-5660,Bug,Trivial,capacity-sched;mrv1;tasktracker,Log info about possible thrashing (when using memory-based scheduling in Capacity Scheduler) is not printed,There is a tiny; but confusing when troubleshooting; bug in TaskTracker code:   totalMemoryAllottedForTasks is calculated in megabytes; while totalPhysicalMemoryOnTT (and totalVirtualMemoryOnTT) is calculated in bytes. totalMemoryAllottedForTasks should be converted to bytes for a correct comparison.,Resolved,Fixed,,Adam Kawa,Adam Kawa,Sun; 1 Dec 2013 14:09:32 +0000,Sat; 21 Mar 2015 21:08:22 +0000,Sat; 21 Mar 2015 21:08:22 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5660
MAPREDUCE-5661,Bug,Trivial,,ShuffleHandler using yarn.nodemanager.local-dirs instead of mapreduce.cluster.local.dir,While debugging an issue where a MapReduce job is failing due to running out of disk space; I noticed that the ShuffleHandler uses yarn.nodemanager.local-dirs for its LocalDirAllocator whereas all of the other MapReduce classes use mapreduce.cluster.local.dir:     This inconsistency feels like something that is likely to confuse admins.,Resolved,Not A Problem,,Unassigned,Eric Sirianni,Mon; 2 Dec 2013 14:30:20 +0000,Tue; 24 Jun 2014 00:04:45 +0000,Thu; 5 Dec 2013 21:32:08 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5661
MAPREDUCE-5662,New Feature,Major,,implement the support for using the shared cache for the job jar and libjars,nan,Resolved,Invalid,,Sangjin Lee,Sangjin Lee,Mon; 2 Dec 2013 19:35:38 +0000,Thu; 6 Mar 2014 19:21:28 +0000,Thu; 6 Mar 2014 19:21:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5662
MAPREDUCE-5663,Improvement,Major,,Add an interface to Input/Ouput Formats to obtain delegation tokens,Currently; delegation tokens are obtained as part of the getSplits   OutputFormat respectively.  This works as long as the splits are generated on a node with kerberos credentials. For split generation elsewhere (AM for example); an explicit interface is required.,Open,Unresolved,,Michael Weng,Siddharth Seth,Tue; 3 Dec 2013 00:07:18 +0000,Sat; 7 Jan 2017 01:59:54 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5663
MAPREDUCE-5664,Bug,Major,,java.lang.RuntimeException: javax.xml.parsers.ParserConfigurationException:,Hi;  I am using hadoop 0.21 vesrsion and  1.6.  Please help me to fix the issue. What version jar should i put.   The sample code with xml i have attached here.        When processing xml file as input via map reduce; the error occurred is      Please help to fix the issue,Resolved,Duplicate,HADOOP-5254;MAPREDUCE-5667,Unassigned,ranjini,Tue; 3 Dec 2013 10:11:43 +0000,Wed; 4 Dec 2013 09:06:49 +0000,Wed; 4 Dec 2013 09:05:48 +0000,,0.21.0,,,HADOOP-5254,https://issues.apache.org/jira/browse/MAPREDUCE-5664
MAPREDUCE-5665,Bug,Major,test,Add audience annotations to MiniMRYarnCluster and MiniMRCluster,We should make it clear whether these are public interfaces.,Closed,Fixed,,Anubhav Dhoot,Sandy Ryza,Tue; 3 Dec 2013 22:02:05 +0000,Fri; 15 Aug 2014 05:48:00 +0000,Fri; 28 Feb 2014 00:53:50 +0000,,2.2.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5665
MAPREDUCE-5666,Bug,Major,,org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java(org/apache/hadoop/mapreduce/lib/input:FileInputFormat.java):cannot find symbol,hi   I have written the below code ; and facing the issue. i am using hadoop 0.20 vesion and  util.StringTokenizer;    import org.apache.hadoop.conf.Configured;    import org.apache.hadoop.fs.FSDataInputStream;    import org.apache.hadoop.fs.FileSystem;    import org.apache.hadoop.fs.Path;    import org.apache.hadoop.io.IntWritable;    import org.apache.hadoop.io.Text;    import org.apache.hadoop.io.WritableComparable;    import org.apache.hadoop.mapreduce.InputSplit;    import org.apache.hadoop.mapreduce.Job;    import org.apache.hadoop.mapreduce.Mapper;    import org.apache.hadoop.mapreduce.RecordReader;    import org.apache.hadoop.mapreduce.TaskAttemptContext;    import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;    import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;    import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;    import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;    import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;    import org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer;    import org.apache.hadoop.util.LineReader;    import org.apache.hadoop.util.Tool;    import org.apache.hadoop.util.ToolRunner;       use the WordCount Reducer         job.setCombinerClass(IntSumReducer.class);         job.setReducerClass(IntSumReducer.class);          FileInputFormat.addInputPaths(job; args0);         FileOutputFormat.setOutputPath(job; new Path(args1));         return job.waitForCompletion(true) ? 0 : 1;       }       public static void main(String[] args) throws Exception  {         int ret = ToolRunner.run(new MultiFileWordCount(); args);         System.exit(ret);       }      },Resolved,Invalid,,Unassigned,ranjini,Wed; 4 Dec 2013 05:48:54 +0000,Wed; 4 Dec 2013 14:34:51 +0000,Wed; 4 Dec 2013 14:34:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5666
MAPREDUCE-5667,Bug,Major,,Error in runtime in mapreduce code,Hi;  While executing the code taking input xml file in mapreduce.  The error occurred is Error:  1.6  I used jdom-1.0.jar but still error coming.  Please help this issue suggest what version jar should i use.  Thanks in advance.,Resolved,Duplicate,MAPREDUCE-5664,Unassigned,ranjini,Wed; 4 Dec 2013 07:29:07 +0000,Wed; 4 Dec 2013 09:02:03 +0000,Wed; 4 Dec 2013 09:02:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5667
MAPREDUCE-5668,Bug,Major,,"Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.JobContext; but interface was expected",hi  pl help  i have wrote this code ; tached the code.  import  util.StringTokenizer;    import org.apache.hadoop.conf.Configured;    import org.apache.hadoop.fs.FSDataInputStream;    import org.apache.hadoop.fs.FileSystem;    import org.apache.hadoop.fs.Path;    import org.apache.hadoop.io.IntWritable;    import org.apache.hadoop.io.Text;    import org.apache.hadoop.io.WritableComparable;    import org.apache.hadoop.mapreduce.InputSplit;    import org.apache.hadoop.mapreduce.Job;    import org.apache.hadoop.mapreduce.Mapper;    import org.apache.hadoop.mapreduce.RecordReader;    import org.apache.hadoop.mapreduce.TaskAttemptContext;    import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;    import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;    import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;    import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;    import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;    import org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer;    import org.apache.hadoop.util.LineReader;    import org.apache.hadoop.util.Tool;    import org.apache.hadoop.util.ToolRunner;       use the WordCount Reducer         job.setCombinerClass(IntSumReducer.class);         job.setReducerClass(IntSumReducer.class);          FileInputFormat.addInputPaths(job; args0);         FileOutputFormat.setOutputPath(job; new Path(args1));         return job.waitForCompletion(true) ? 0 : 1;       }       public static void main(String[] args) throws Exception  {         int ret = ToolRunner.run(new MultiFileWordCount(); args);         System.exit(ret);       },Resolved,Invalid,,Unassigned,ranjini,Wed; 4 Dec 2013 09:51:02 +0000,Wed; 4 Dec 2013 19:29:52 +0000,Wed; 4 Dec 2013 14:38:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5668
YARN-1477,Bug,Major,,Improve AM web UI to avoid confusion about AM restart,"Improve AM web UI;  Add submitTime field to the AM's web services REST API; improve ""Elapsed: "" row time computation; etc.",Open,Unresolved,,Chen He,Chen He,Thu; 5 Dec 2013 17:29:42 +0000,Fri; 10 Apr 2015 18:49:58 +0000,,,2.2.0,features,,,https://issues.apache.org/jira/browse/YARN-1477
MAPREDUCE-5670,Bug,Minor,mrv2,CombineFileRecordReader should report progress when moving to the next file,"If a combine split consists of many ""empty"" files (i.e.: no record found by the underlying record reader) then theoretically a task can timeout due to lack of reported progress.",Closed,Fixed,,Chen He,Jason Lowe,Thu; 5 Dec 2013 17:38:23 +0000,Thu; 10 Apr 2014 13:11:48 +0000,Thu; 13 Feb 2014 23:23:04 +0000,,0.23.9,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5670
MAPREDUCE-5671,Bug,Major,,NaN can be created by client and assign to Progress,"MapReduce should filter ""illegal"" progress values that do not fall into (0;1) interval when the progress value is given.  If it is Float.NaN; Float.NEGATIVE_INFINITY; or smaller than 0: set progress to be 0; If its is Float.POSITIVE_INFINITY or larger than 1: set progress to be 1;",Closed,Fixed,,Chen He,Chen He,Thu; 5 Dec 2013 17:39:50 +0000,Wed; 3 Sep 2014 20:33:53 +0000,Fri; 21 Feb 2014 16:33:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5671
MAPREDUCE-5672,Improvement,Major,mr-am;mrv2,Provide optional RollingFileAppender for container log4j (syslog),This JIRA is an alternative take on YARN-1130  We propose providing an option of using a RollingFileAppender(RFA)-based implementation of container log appender as means of log size control via mapreduce.task.userlog.limit.kb.   The idea is to use mapreduce.task.userlog.limit.kb as maximumFileSize of RFA. In addition yarn.app.mapreduce.container.log.backups (task attempt containers) and yarn.app.mapreduce.am.log.backups (MR-AM) are passed as maxBackupIndex.  Both current ContainerLogAppender (CLA) and new ContainerRollingLogAppender (CRLA) co-exist. CLA is the default. CRLA is chosen when  mapreduce.task.userlog.limit.kb  0 &amp; *.backups  0.  Pros:  1) CRLA output is visible in UI right away. CLA output with mapreduce.task.userlog.limit.kb  0 is not visible until the task attempt finishes that prevents timely diagnostics.  2) Even with excessive logging and a large mapreduce.task.userlog.limit.kb; no space is taken from the JVM heap. 3) No UI impact; since YARN is already designed to deal with any log name beyond stderr O due to roll. That should be negligible in the grand scheme.  Furthermore; to improve log consistency and completeness in the case of JVM crashes and SIGTERMing by NM; we propose to restore the MRv1 behavior of periodic log syncing (every 5s) and having log sync as part of a shutdown hook.,Closed,Fixed,YARN-1130,Gera Shegalov,Gera Shegalov,Thu; 5 Dec 2013 23:16:25 +0000,Wed; 16 Jul 2014 22:05:09 +0000,Thu; 16 Jan 2014 23:18:33 +0000,,2.2.0,,,YARN-1130,https://issues.apache.org/jira/browse/MAPREDUCE-5672
MAPREDUCE-5673,Improvement,Trivial,jobhistoryserver,It would be great if we can know which host(IP) the client submitted job in jobhistory web UI,Current Hadoop jobhistory web UI cann't list which host(IP) the client submitted the job; and it would be great if we can know which host(IP) the client submitted job in jobhistory web UI.,Open,Unresolved,,Unassigned,wyp,Fri; 6 Dec 2013 09:59:57 +0000,Tue; 17 Mar 2015 05:04:16 +0000,,,2.2.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5673
MAPREDUCE-5674,Bug,Major,client,Missing start and finish time in mapred.JobStatus,The JobStatus obtained from the JobClient or runningJob has no start or finish time for the job  the start and finish time is always 0. This is a regression with respect to 1.0 mapreduce client and JobStatus API. This can also lead to regressions in downstream projects. For example; we discovered the problem in webhcat that the jobstatus for mapreduce job submmited to webhcat always reports start time as 0.,Closed,Fixed,,Chuan Liu,Chuan Liu,Sat; 7 Dec 2013 01:48:09 +0000,Thu; 12 May 2016 18:23:36 +0000,Thu; 12 Dec 2013 18:41:42 +0000,,2.2.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5674
MAPREDUCE-5675,Bug,Major,mrv2,krb5.conf is missing in some of the test resource folders,org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.testPartialJob fail due to some timeout issue:   The same error also exist for the test org.apache.hadoop.mapred.TestJobClient.testIsJobDirValid This is due to the missing of the krb5.conf file in the corresponding test resource folder;  The solution would be copy the krb5.conf file to the corresponding test resource dir:   Not sure if this exists on trunk also;,Open,Unresolved,,Unassigned,stanley shi,Tue; 10 Dec 2013 07:47:55 +0000,Tue; 10 Dec 2013 07:49:26 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5675
MAPREDUCE-5676,Bug,Major,jobhistoryserver,Unable to view MRv1 jobs in the MRv2 job history server after upgrading Apache Hadoop 1.2.0 to Apache Hadoop 2.1.0-beta,Unable to view MRv1 jobs in the MRv2 job history server after upgrading Apache Hadoop 1.2.0 to Apache Hadoop 2.1.0-beta.  After successful upgrade from Apache Hadoop 1.2.0 to Apache Hadoop 2.1.0-beta I can now see the existing files in the HDFS that were used by earlier Map Reduce jobs(input files  generated output files) using Apache Hadoop-1.2.0.  However; I cannot see the history of those Map Reduce jobs (MRv1) on the  JobHistory Server.,Open,Unresolved,,Unassigned,Nirmal Kumar,Tue; 10 Dec 2013 07:54:56 +0000,Tue; 10 Dec 2013 07:55:56 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5676
MAPREDUCE-5677,Bug,Major,jobhistoryserver,Hadoop 2.2 historyviewer report NPE when read 0.23 fail job's history,2013-12-10 12:49:39;394 WARN org.apache.hadoop.yarn.webapp.GenericExceptionHandler: INTERNAL_SERVER_ERROR  582),Open,Unresolved,,Chen He,Chen He,Tue; 10 Dec 2013 20:52:21 +0000,Wed; 8 Jan 2014 23:44:44 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5677
MAPREDUCE-5678,Improvement,Major,,Move junit to test scope in more projects,MAPREDUCE-5624 moved junit to test scope for most projects but missed a few pom.xml  This JIRA moves junit to test scope for the missed projects  Thanks to Jeff Bowles who made the discovery,Resolved,Duplicate,HADOOP-8738,Ted Yu,Ted Yu,Tue; 10 Dec 2013 22:51:02 +0000,Wed; 11 Dec 2013 00:07:23 +0000,Wed; 11 Dec 2013 00:07:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5678
MAPREDUCE-5679,Bug,Major,,TestJobHistoryParsing has race condition,org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing can fail because of race condition.    In the checkHistoryParsing() function; after    a thread named MoveIntermediateToDone will be launched to move history file from done_intermediate to done directory. If the history file is moved;    will throw IOException because the history file is not found.,Closed,Fixed,,Liyin Liang,Liyin Liang,Thu; 12 Dec 2013 03:12:57 +0000,Wed; 3 Sep 2014 23:35:27 +0000,Tue; 17 Dec 2013 16:51:07 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5679
MAPREDUCE-5680,Improvement,Major,applicationmaster,Reconsider limits,Limits were first introduced in 0.20.2xx line with the main goal of protecting  jobtracker from rogue jobs. Now that problem no longer exists in yarn; where each job gets its own MR AM.  So; its good time now to revisit limits and see which of those still make sense.,Open,Unresolved,,Unassigned,Ashutosh Chauhan,Thu; 12 Dec 2013 16:32:54 +0000,Fri; 24 Jan 2014 18:08:19 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5680
MAPREDUCE-5681,Bug,Major,,TestJHSSecurity fails on trunk,Did some preliminary investigation; in HistoryClientService:   MR_WEBAPP_SPNEGO_USER_NAME_KEY seems not to be in the configuration.,Resolved,Duplicate,YARN-1463,Unassigned,Zhijie Shen,Fri; 13 Dec 2013 23:36:51 +0000,Sat; 14 Dec 2013 02:28:58 +0000,Sat; 14 Dec 2013 02:28:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5681
MAPREDUCE-5682,Bug,Major,mrv1,Job Counters are not retrieved properly from web UI,After MAPREDUCE-4962; most job counters are coming back as 0 because the web UI retrieves them using the name instead of displayName; which is what is expected:,Open,Unresolved,,Mark Wagner,Mark Wagner,Sat; 14 Dec 2013 01:22:16 +0000,Sat; 14 Dec 2013 01:25:11 +0000,,,1.2.1;1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5682
MAPREDUCE-5683,Improvement,Minor,documentation;mrv2,Expand documentation for yarn.app.mapreduce.am.resource.mb,Could we please see some more documentation around the yarn.app.mapreduce.am.resource.mb parameter in mapred-site.xml?  Information about when (if ever) it would be appropriate to increase or decrease the value of this would be useful.    Is there a minimum value this needs to be set in order for MapReduce jobs to run under YARN?,Open,Unresolved,,Unassigned,Bart Kersteter,Sat; 14 Dec 2013 18:29:52 +0000,Sat; 7 Jan 2017 01:59:54 +0000,,,2.0.5-alpha;2.1.1-beta,documentation;;mapreduce;yarn,,,https://issues.apache.org/jira/browse/MAPREDUCE-5683
MAPREDUCE-5684,Bug,Major,,TestMRJobs.testFailingMapper occasionally fails,TestMRJobs is occasionally failing with the error:,Open,Unresolved,,Unassigned,Liyin Liang,Mon; 16 Dec 2013 09:55:22 +0000,Fri; 5 Dec 2014 09:36:04 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5684
MAPREDUCE-5685,Bug,Blocker,client,getCacheFiles()  api doesn't work in WrappedReducer.java due to typo,Typo in WrappedReducer.   line 140: Error code:   Should be:,Closed,Fixed,,Yi Song,Yi Song,Mon; 16 Dec 2013 14:24:16 +0000,Mon; 24 Feb 2014 20:57:07 +0000,Mon; 30 Dec 2013 21:15:34 +0000,,2.2.0,,,MAPREDUCE-5385,https://issues.apache.org/jira/browse/MAPREDUCE-5685
MAPREDUCE-5686,Bug,Major,,Found Class org.apache.hadoop.mapreduce.TaskAttemptContext;but interface was excepted,hi;  Iam using the hadoop version 0.20.   Please suggest to fix the bug.  Thanks in advance.  Ranjini,Resolved,Invalid,,Unassigned,ranjini,Tue; 17 Dec 2013 07:30:51 +0000,Tue; 17 Dec 2013 14:15:13 +0000,Tue; 17 Dec 2013 14:15:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5686
MAPREDUCE-5687,Test,Major,,TestYARNRunner#testResourceMgrDelegate fails with NPE after YARN-1446,On trunk; I got:,Closed,Fixed,,Jian He,Ted Yu,Tue; 17 Dec 2013 15:29:08 +0000,Mon; 24 Feb 2014 20:58:05 +0000,Wed; 18 Dec 2013 00:16:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5687
MAPREDUCE-5688,Bug,Major,,TestStagingCleanup fails intermittently with JDK7,Due to random ordering ordering in JDK7; the test TestStagingCleanup#testDeletionofStagingOnKillLastTry is failing,Closed,Fixed,,Mit Desai,Mit Desai,Wed; 18 Dec 2013 16:27:05 +0000,Thu; 12 May 2016 18:22:52 +0000,Fri; 21 Feb 2014 19:29:38 +0000,,2.3.0;3.0.0-alpha1,java7,,,https://issues.apache.org/jira/browse/MAPREDUCE-5688
MAPREDUCE-5689,Bug,Critical,,MRAppMaster does not preempt reducers when scheduled maps cannot be fulfilled,We saw corner case where Jobs running on cluster were hung. Scenario was something like this. Job was running within a pool which was running at its capacity. All available containers were occupied by reducers and last 2 mappers. There were few more reducers waiting to be scheduled in pipeline.  At this point two mappers which were running failed and went back to scheduled state. two available containers were assigned to reducers; now whole pool was full of reducers waiting on two maps to be complete. 2 maps never got scheduled because pool was full.  Ideally reducer preemption should have kicked in to make room for Mappers from this code in RMContaienrAllocator    But in this scenario lastCompletedTasks is always completedTasks because maps were never completed. This would cause job to hang forever. As workaround if we kill few reducers; mappers would get scheduled and caused job to complete.,Closed,Fixed,,Lohit Vijayarenu,Lohit Vijayarenu,Wed; 18 Dec 2013 17:22:14 +0000,Thu; 12 May 2016 18:22:56 +0000,Fri; 3 Jan 2014 17:32:53 +0000,,2.2.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5689
MAPREDUCE-5690,Bug,Major,,TestLocalMRNotification.testMR occasionally fails,TestLocalMRNotificationis occasionally failing with the error:,Resolved,Duplicate,MAPREDUCE-4376,Liyin Liang,Liyin Liang,Thu; 19 Dec 2013 02:25:03 +0000,Mon; 18 May 2015 19:45:13 +0000,Mon; 18 May 2015 17:42:53 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5690
MAPREDUCE-5691,Improvement,Major,,Throttle shuffle's bandwidth utilization,In our hadoop cluster; a reducer of a big job can utilize all the bandwidth during shuffle phase. Then any task reading data from  the machine which running that reducer becomes very very slow. It's better to move DataTransferThrottler from hadoop-hdfs to hadoop-common. And create a throttler for Shuffle to throttle each Fetcher.,Open,Unresolved,,Unassigned,Liyin Liang,Thu; 19 Dec 2013 07:16:01 +0000,Mon; 30 Dec 2013 02:31:45 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5691
MAPREDUCE-5692,Improvement,Major,mrv2,Add explicit diagnostics when a task attempt is killed due to speculative execution,We need to clearly indicate when a task attempt is killed because another task attempt succeeded first when speculative execution is enabled.,Closed,Fixed,MAPREDUCE-3294,Gera Shegalov,Gera Shegalov,Thu; 19 Dec 2013 12:16:01 +0000,Mon; 20 Jun 2016 21:40:19 +0000,Fri; 20 Dec 2013 19:58:07 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5692
MAPREDUCE-5693,Bug,Major,mrv2,Restore MRv1 behavior for log flush,to improve log consistency and completeness for diagnostics in the case of JVM crashes and SIGTERMing by NM this JIRA proposes to restore the MRv1 behavior of periodic log syncing (every 5s) and having log sync as part of a shutdown hook.,Closed,Fixed,YARN-1130,Gera Shegalov,Gera Shegalov,Thu; 19 Dec 2013 21:04:15 +0000,Mon; 24 Feb 2014 20:57:12 +0000,Tue; 21 Jan 2014 19:28:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5693
MAPREDUCE-5694,Bug,Major,,MR AM container syslog is empty  ,"When the property ""mapreduce.task.userlog.limit.kb"" is set non-zero in mapped-site.xml; AM container syslog remains empty. Without the log; it is hard to identify the cause of any MR AM failure. However; if ""mapreduce.task.userlog.limit.kb""  is not set (or defaulted to 0); syslog contents are correct.  Bug details: For  non zero ""mapreduce.task.userlog.limit.kb""; the code caches the log contents into memory; waited to be written to file when close() method is called at the end(Ref: ContainerLogAppender. ",Closed,Fixed,,Mohammad Kamrul Islam,Mohammad Kamrul Islam,Mon; 23 Dec 2013 03:15:56 +0000,Mon; 24 Feb 2014 20:58:01 +0000,Sat; 28 Dec 2013 17:52:05 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5694
MAPREDUCE-5695,Bug,Blocker,client,"Jobclient API getCleanupTaskReports() is returning error ""Unrecognized task type: JOB_CLEANUP"" ","Exception in thread ""main"" org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Unrecognized task type: JOB_CLEANUP  at org.apache.hadoop.mapreduce.TypeConverter.toYarn(TypeConverter. 531)",Open,Unresolved,,Unassigned,Ashutosh Jindal,Mon; 23 Dec 2013 05:07:01 +0000,Mon; 23 Dec 2013 22:38:46 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5695
MAPREDUCE-5696,Improvement,Major,mrv2,Add Localization counters to MR,Users are often unaware of localization cost that their jobs incur. To measure effectiveness of localization caches it is necessary to expose the overhead in the form of user-visible metrics. The purpose of this JIRA is to compliment YARN-1529. While YARN-1529 attempts to provide a cluster-wide view to cluster admins; this JIRA focuses on exposing the localization overhead on per-job basis to the job owner user.,Open,Unresolved,,Gera Shegalov,Gera Shegalov,Tue; 24 Dec 2013 00:34:05 +0000,Thu; 5 Feb 2015 18:31:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5696
MAPREDUCE-5697,Bug,Critical,benchmarks,My MapReduce program read .gz packets from HDFS; but if one of the packets is incorrect; the program will throw exception; then job will stop.,nan,Resolved,Invalid,,Unassigned,zhongquanong,Thu; 26 Dec 2013 03:08:54 +0000,Fri; 8 May 2015 22:14:41 +0000,Fri; 8 May 2015 22:14:41 +0000,,2.1.1-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5697
MAPREDUCE-5698,Bug,Major,,Backport MAPREDUCE-1285 to branch-1,I found that MAPREDUCE-1285 is not in branch-1. File this issue for backporting.,Resolved,Fixed,,Yongjun Zhang,Yongjun Zhang,Thu; 26 Dec 2013 22:38:24 +0000,Tue; 31 Dec 2013 23:04:05 +0000,Tue; 31 Dec 2013 22:59:01 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5698
MAPREDUCE-5699,Bug,Major,applicationmaster,Allow setting tags on MR jobs,YARN-1399   YARN-1461 add support for tagging YARN applications. MR should expose to users; so they can set tags on an MR job.,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Fri; 27 Dec 2013 01:09:39 +0000,Mon; 3 Nov 2014 18:33:25 +0000,Thu; 6 Feb 2014 18:35:38 +0000,,2.3.0,,YARN-1461,,https://issues.apache.org/jira/browse/MAPREDUCE-5699
MAPREDUCE-5700,Improvement,Major,,historyServer can't show container's log when aggregation is not enabled,When yarn.log-aggregation-enable is seted to false; after a MR_App complete; we can't view the container's log from the HistoryServer; it shows message like: Aggregation is not enabled. Try the nodemanager at hd13-vm1:34669  Since we don't want to aggregate the container's log; because it will be a pressure to namenode. but sometimes we also want to take a look at container's log. Should we show the container's log across HistoryServer even if yarn.log-aggregation-enable is seted to false.,Patch Available,Unresolved,,Hong Shen,Hong Shen,Mon; 6 May 2013 13:24:00 +0000,Wed; 6 May 2015 03:34:54 +0000,,,0.23.7;2.0.4-alpha;2.2.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5700
YARN-1550,Bug,Critical,fairscheduler,NPE in FairSchedulerAppsBlock#render,"three Steps : 1 debug at RMAppManager#submitApplication after code if (rmContext.getRMApps().putIfAbsent(applicationId; application) !=         null)  {       String message = ""Application with id "" + applicationId           + "" is already present! Cannot add a duplicate!"";       LOG.warn(message);       throw RPCUtil.getRemoteException(message);     }  2 submit one application:hadoop jar ~ scheduler and find 500 ERROR   the log:",Closed,Fixed,,Anubhav Dhoot,caolong,Mon; 30 Dec 2013 03:58:32 +0000,Sun; 11 Oct 2015 03:07:03 +0000,Mon; 2 Jun 2014 20:30:18 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/YARN-1550
MAPREDUCE-5702,Bug,Trivial,task,TaskLogServlet#printTaskLog has spurious HTML closing tags,TaskLogServlet#printTaskLog closes some HTML tags that it never opens. These should be removed. This isn't a problem while viewing in a browser; but can lead to issues while parsing it.,Resolved,Fixed,,Robert Kanter,Karthik Kambatla,Tue; 31 Dec 2013 01:53:33 +0000,Mon; 3 Nov 2014 18:34:02 +0000,Tue; 31 Dec 2013 19:33:52 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5702
MAPREDUCE-5703,Bug,Critical,client,Job client gets failure though RM side job execution result is FINISHED and SUCCEEDED,1) Run MR job  2) After reduce completed and while JHS file writing; restart DN.  RM side job is shown as successful. JHS doesnt have info about the job. Job client gets NPE and exit code as 255.   835),Resolved,Duplicate,MAPREDUCE-5547,Unassigned,Ashutosh Jindal,Tue; 31 Dec 2013 10:47:46 +0000,Sat; 9 May 2015 00:41:48 +0000,Sat; 9 May 2015 00:41:48 +0000,,,,,MAPREDUCE-5547,https://issues.apache.org/jira/browse/MAPREDUCE-5703
MAPREDUCE-5704,Improvement,Major,jobtracker;mrv1,Optimize nextJobId in JobTracker,"When jobtracker start; nextJobId start with 1;if we have run 3000 jobs  then restart jobtracker and run a new job;we can not see this new job on jobtracker:5030 jobhistory.jsp unless click ""get more results"" button. In jobhistory_jsp.  array SCAN_SIZES controls job numbers displayed on jobhistory.jsp. I make a little chage;when jobtracker start;find the biggest id under history done directory;job will start with maxId+1 or 1 if can not find any job files.",Patch Available,Unresolved,,JamesLi,JamesLi,Thu; 2 Jan 2014 09:37:32 +0000,Wed; 6 May 2015 03:33:00 +0000,,,1.2.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5704
MAPREDUCE-5705,Bug,Major,,mapreduce.task.io.sort.mb hardcoded cap at 2047,mapreduce.task.io.sort.mb is hardcoded to not allow values larger then 2047. If you enter a value larger then this the map tasks will always crash at this line -  https:  source=cc#L746  The nodes at dev site have over 380 GB of Ram each; we are not able to make the best use of large mappers (15GB mappers) because of the hardcoded buffer max. Is there a reason this value has been hardcoded?     Also validated on my dev VM. Indeed setting io.sort.mb to 2047 works but 2048 fails.,Reopened,Unresolved,MAPREDUCE-2308,Unassigned,Joseph Niemiec,Fri; 3 Jan 2014 17:58:44 +0000,Mon; 4 Apr 2016 22:52:12 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5705
MAPREDUCE-5706,Bug,Major,security,toBeDeleted parent directories aren't being cleaned up,"When security is enabled on 0.22; MRASyncDiskService doesn't always delete the parent directories under toBeDeleted.  MRAsyncDiskService goes through toBeDeleted and creates ""tasks"" to delete the directories under there using the LinuxTaskController. It chooses which user to run as by looking at who owns that directory. For example:    It would create a task to use ""test"" user to delete  2013-07-05_05-37-49.052_0).",Resolved,Fixed,,Robert Kanter,Robert Kanter,Fri; 3 Jan 2014 22:32:31 +0000,Mon; 12 May 2014 22:41:50 +0000,Mon; 12 May 2014 06:25:44 +0000,,0.22.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5706
MAPREDUCE-5707,Bug,Major,client,JobClient does not allow setting RPC timeout for communications with JT/RM,The ApplicationClientProtocolPBClientImpl c'tor (and the JobClient 0.20.2 c'tor as well) creates an rpc proxy that eventually uses '0' as the rpcTimeout:     which leads to this call in RPC:    (the '0' above is the rpc timeout).  Clients should be able to specify the rpc timeout.,Open,Unresolved,,Unassigned,Gilad Wolff,Sat; 4 Jan 2014 01:54:27 +0000,Thu; 9 Jan 2014 00:53:24 +0000,,,1.2.1;2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5707
MAPREDUCE-5708,Bug,Minor,,Duplicate String.format in YarnOutputFiles.getSpillFileForWrite,The code responsible for formatting the spill file name (namely getSpillFileForWrite) unnecessarily calls String.format twice. This does not only affect performance; but leads to the weird requirement that task attempt ids cannot contain % characters (because these would be interpreted as format specifiers in the outside String.format call).  I assume this was done by mistake; as it could only be useful if task attempt ids contained %n.,Resolved,Fixed,,Konstantin Weitz,Konstantin Weitz,Sat; 4 Jan 2014 17:38:18 +0000,Tue; 30 Aug 2016 01:20:23 +0000,Thu; 14 May 2015 16:46:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5708
MAPREDUCE-5709,Bug,Major,task,Getting ClassNotFoundException even though jar is included in lib folder,In YARN; we are getting the below exception. The same is running fine in MRv1.The jar containing CSVReader.class in included in the lib folder. Tried also setting the jar in HADOOP_CLASSPATH as well;but still the same exception.   INFO mapreduce.Job: Task Id :   security.AccessController.doPrivileged(Native Method),Open,Unresolved,,Unassigned,Ajesh Kumar,Mon; 6 Jan 2014 05:02:41 +0000,Wed; 15 Jan 2014 09:13:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5709
MAPREDUCE-5710,Bug,Major,,Backport MAPREDUCE-1305 to branch-1,File this bug for backporting MAPREDUCE-1305 to branch-1.,Resolved,Fixed,,Yongjun Zhang,Yongjun Zhang,Tue; 7 Jan 2014 05:04:40 +0000,Tue; 7 Jan 2014 22:27:47 +0000,Tue; 7 Jan 2014 21:52:30 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5710
MAPREDUCE-5711,Bug,Major,,When JobTracker writing JobHistory to HDFS; it may hung for long time due to DataNode error,When writing JobHistory to HDFS; it may takes very long time due to DataNode error; unfortunately; it also hold JobTracker lock; so it makes JobTracker hung for long time. It happens couple of times on our cluster.,Resolved,Duplicate,MAPREDUCE-1144,yunjiong zhao,yunjiong zhao,Tue; 7 Jan 2014 13:17:00 +0000,Fri; 10 Jan 2014 01:44:54 +0000,Fri; 10 Jan 2014 01:44:54 +0000,,1.2.0,,,MAPREDUCE-1144,https://issues.apache.org/jira/browse/MAPREDUCE-5711
MAPREDUCE-5712,Improvement,Major,scheduler,Backport Fair Scheduler pool placement by secondary group,YARN-1423 introduced a quue police that support selecting a queue if a secondary group was found in the defined queues. This functionality would be useful and minimally invasive in MR1 as well.,Resolved,Fixed,,Theodore michael Malaska,Theodore michael Malaska,Wed; 8 Jan 2014 02:07:00 +0000,Mon; 13 Jan 2014 20:51:53 +0000,Mon; 13 Jan 2014 20:51:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5712
MAPREDUCE-5713,Bug,Trivial,documentation,InputFormat and JobConf JavaDoc Fixes,"https: JobConf.html  Instead of ""some parameters interact subtly rest of the framework"" Should be ""some parameters interact subtly with the rest of the framework""",Closed,Fixed,,Chen He,Ben Robie,Tue; 7 Jan 2014 19:17:05 +0000,Wed; 3 Sep 2014 20:33:53 +0000,Thu; 13 Mar 2014 16:51:20 +0000,,1.2.1;2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5713
MAPREDUCE-5714,Bug,Major,test,TestMRAppComponentDependencies causes surefire to exit without saying proper goodbye,"When running test TestMRAppComponentDependencies; surefire exits with the following message:   Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.16:test (default-test) on project hadoop-mapreduce-client-app: ExecutionException; nested exception is  lang.RuntimeException: The forked VM terminated without saying properly goodbye. VM crash or System.exit called ?  The following code is found in o.a.h.mapreduce.v2.app.MRAppMaster#shutDownJob; which the test case inherits. So; before the test testComponentStopOrder completes in TestMRAppComponentDependencies; shutDownJob finishes executing and exits the JVM; thus causing the error. Based on the comment; the System.exit(0) is there as a workaround for before HADOOP-7140. Since the patch for HADOOP-7140 is committed in branch-2; are we safe to remove the System.exit call now.       Not needed after HADOOP-7140     LOG.info(""Exiting MR AppMaster..GoodBye!"");     sysexit();",Closed,Fixed,,Jinghui Wang,Jinghui Wang,Wed; 8 Jan 2014 22:24:44 +0000,Tue; 10 Mar 2015 04:30:14 +0000,Sat; 26 Apr 2014 18:08:23 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5714
MAPREDUCE-5715,Bug,Minor,,ProcfsBasedProcessTree#constructProcessInfo() can still throw NumberFormatException,"For long running jobs I have hit an issue that seems to be to be similar to the bug reported in https: MAPREDUCE-3583  Unfortunately I do not have the OS logs for this issue; but the utime for the application was read by Hadoop as ""184467440737095551615"" which does not fit into a Long. In MAPREDUCE-3583 a change was made to ProcfsBasedProcessTree.   in order to support larger values for stime. Perhaps we need to support larger values for utime (although this could increase the complexity of the math that is being performed on those numbers)",Open,Unresolved,,Unassigned,German Florez-Larrahondo,Thu; 9 Jan 2014 17:16:11 +0000,Tue; 10 Mar 2015 04:30:41 +0000,,,2.2.0,,,MAPREDUCE-3583,https://issues.apache.org/jira/browse/MAPREDUCE-5715
MAPREDUCE-5716,Bug,Critical,applicationmaster,yarn framework occurs Shell$ExitCodeException,"I use hadoop2.2.0 to run map-reduce task;at first I set the  property ""mapreduce.framework.name"" with ""local"" in mapred-site.xml;everything goes fine ;and there is no exception;but when I run the mapreduce task on server cluster;setting the ""mapreduce.framework.name"" property value with ""yarn"";it shows exception belows:      2014-01-10 14:51:03;131 INFO ContainersLauncher #0 org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: launchContainer: [ configuration",Resolved,Invalid,,dimmacro,dimmacro,Fri; 10 Jan 2014 10:36:24 +0000,Fri; 8 May 2015 22:07:26 +0000,Fri; 8 May 2015 22:07:26 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5716
MAPREDUCE-5717,Bug,Major,,Task pings are interpreted as task progress,nan,Resolved,Fixed,,Jason Lowe,Jason Lowe,Fri; 10 Jan 2014 16:42:10 +0000,Thu; 12 May 2016 18:23:52 +0000,Fri; 17 Jan 2014 21:38:48 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5717
MAPREDUCE-5718,Bug,Major,mr-am,MR job will fail after commit fail,"when any of this happens:  	While testing RM HA; if the RM fails over while an MR AM is in the middle of a commit; 	When testing preempting; if the MR AM fails over during the middle of a commit    the subsequent AM gets spawned but dies with a diagnostic message - ""We crashed durring a commit"".",Open,Unresolved,MAPREDUCE-5795,Yang Hao,Karthik Kambatla,Sat; 11 Jan 2014 00:41:13 +0000,Mon; 11 Jan 2016 17:38:42 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5718
MAPREDUCE-5720,Bug,Major,resourcemanager,RM occur exception while unregistering,nan,Resolved,Invalid,,Unassigned,chillon.m,Mon; 13 Jan 2014 01:40:32 +0000,Tue; 14 Jan 2014 09:41:19 +0000,Mon; 13 Jan 2014 14:56:12 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5720
MAPREDUCE-5721,Bug,Major,resourcemanager,RM occur exception while unregistering,when i run WORDCOUNT EXAMPLES;it occur. hadoop@namenode0 ~$ hadoop jar hadoop-2.2.0 job_1389341658181_0001,Resolved,Not A Problem,,Unassigned,chillon.m,Mon; 13 Jan 2014 01:40:54 +0000,Mon; 29 Dec 2014 22:26:20 +0000,Mon; 29 Dec 2014 22:26:20 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5721
MAPREDUCE-5722,Bug,Blocker,build,client-app module failing to compile; missing jersey dependency,This seems a fallout of YARN-888; oddly enough it did not happen while doing a full build with the patch before committing.,Closed,Invalid,,Alejandro Abdelnur,Alejandro Abdelnur,Mon; 13 Jan 2014 19:07:01 +0000,Thu; 12 May 2016 18:22:19 +0000,Mon; 13 Jan 2014 19:17:35 +0000,,2.3.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5722
MAPREDUCE-5723,Bug,Blocker,applicationmaster,MR AM container log can be truncated or empty,"It occurs when the property ""mapreduce.task.userlog.limit.kb"" is set non-zero in mapped-site.xml. AM container syslog remains empty if any exception occurs.   Bug details: In MRAppMaster.  the following code snippets show the bug.    In the catch block; we are exiting the JVM. So finally block (therefore LogManager.shutdown()) is never executed.  Possible fix:  Make sure LogManager.shutdown() is executed in all cases.",Closed,Fixed,,Mohammad Kamrul Islam,Mohammad Kamrul Islam,Tue; 14 Jan 2014 22:43:17 +0000,Mon; 24 Feb 2014 20:56:53 +0000,Thu; 23 Jan 2014 06:09:53 +0000,,2.2.0,,,MAPREDUCE-5730,https://issues.apache.org/jira/browse/MAPREDUCE-5723
MAPREDUCE-5724,Bug,Critical,jobhistoryserver,JobHistoryServer does not start if HDFS is not running,Starting JHS without HDFS running fails with the following error:,Closed,Fixed,,Alejandro Abdelnur,Alejandro Abdelnur,Wed; 15 Jan 2014 00:58:12 +0000,Thu; 12 May 2016 18:23:04 +0000,Thu; 16 Jan 2014 17:13:10 +0000,,2.3.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5724
MAPREDUCE-5725,Bug,Major,,TestNetworkedJob relies on the Capacity Scheduler,We should either make this explicit or make it scheduler-agnostic.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Thu; 16 Jan 2014 00:16:05 +0000,Mon; 24 Feb 2014 20:57:48 +0000,Tue; 21 Jan 2014 01:24:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5725
MAPREDUCE-5726,Test,Major,,TestRMContainerAllocator#testCompletedTasksRecalculateSchedule fails,From https: console :,Resolved,Duplicate,MAPREDUCE-5743;YARN-1610,Unassigned,Akira Ajisaka,Thu; 16 Jan 2014 02:01:26 +0000,Tue; 21 Jan 2014 05:48:01 +0000,Tue; 21 Jan 2014 05:48:01 +0000,,,,,YARN-1474,https://issues.apache.org/jira/browse/MAPREDUCE-5726
MAPREDUCE-5727,Bug,Major,jobhistoryserver;webapps,History server web page can filter without showing filter keyword,I loaded up a job conf page on the history server and used one of the search boxes to narrow the results.  I then navigated to other pages (e.g.: map tasks; logs; etc.) then navigated back to the job conf page using the job configuration link on the left side of the page.  When I arrived it promptly showed me just a few conf entries (the ones I had searched for earlier) but my search term was missing.  At first glance it looked like those were the only entries in the entire job conf; which can be very confusing.  Somehow the search term is being remembered but not replotted when the configuration page is revisited.,Resolved,Duplicate,YARN-2238,Unassigned,Jason Lowe,Thu; 16 Jan 2014 17:04:13 +0000,Wed; 11 Feb 2015 17:10:47 +0000,Wed; 11 Feb 2015 17:10:47 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5727
MAPREDUCE-5728,Improvement,Minor,client,Check NPE for serializer/deserializer in MapTask,Currently we will get NPE if the serializer deserializer in MapTask so that we don't get meaningless NPE.,Patch Available,Unresolved,MAPREDUCE-2584,Jerry He,Jerry He,Sat; 18 Jan 2014 21:53:00 +0000,Thu; 1 Sep 2016 09:28:55 +0000,,,2.2.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5728
MAPREDUCE-5729,Bug,Critical,mrv2,mapred job -list throws NPE,mapred job -list throws the following NPE:,Closed,Fixed,,Karthik Kambatla,Karthik Kambatla,Mon; 20 Jan 2014 18:39:38 +0000,Mon; 3 Nov 2014 18:33:39 +0000,Mon; 20 Jan 2014 19:30:43 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5729
MAPREDUCE-5730,Bug,Critical,mr-am,AM log is truncated,The ApplicationMaster log is being truncated with only the log messages up until around the point where the job is being setup are present.,Resolved,Duplicate,MAPREDUCE-5723,Unassigned,Jason Lowe,Tue; 21 Jan 2014 17:27:57 +0000,Tue; 28 Jan 2014 23:33:41 +0000,Wed; 22 Jan 2014 14:19:25 +0000,,2.3.0,,,MAPREDUCE-5723,https://issues.apache.org/jira/browse/MAPREDUCE-5730
MAPREDUCE-5731,Bug,Major,,testMiniMRChildtask fails on branch-2,nan,Resolved,Cannot Reproduce,,Mit Desai,Mit Desai,Tue; 21 Jan 2014 19:27:39 +0000,Wed; 5 Feb 2014 23:41:09 +0000,Wed; 5 Feb 2014 18:11:47 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5731
MAPREDUCE-5732,Improvement,Major,,Report proper queue when job has been automatically placed,Some schedulers; such as the Fair Scheduler; provide the ability to automatically place an application into a queue based on attributes such as the user and group of the submitter.  In these cases; the JobHistoryServer and AM web UI report the requested queue; not the queue that the app is actually running in.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Wed; 22 Jan 2014 01:27:19 +0000,Thu; 10 Apr 2014 13:11:10 +0000,Thu; 30 Jan 2014 00:23:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5732
MAPREDUCE-5733,Improvement,Trivial,,"Define and use a constant for property ""textinputformat.record.delimiter""","(Configugration) conf.set(""textinputformat.record.delimiter"";""myDelimiter"") ; is bound to typo error. Lets have it as a Static String in some class; to minimise such error. This would also help in IDE like eclipse suggesting the String.",Patch Available,Unresolved,,Gelesh,Gelesh,Thu; 23 Jan 2014 09:58:37 +0000,Wed; 6 May 2015 03:29:36 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5733
YARN-1680,Sub-task,Major,capacityscheduler,availableResources sent to applicationMaster in heartbeat should exclude blacklistedNodes free memory.,There are 4 NodeManagers with 8GB each.Total cluster capacity is 32GB.Cluster slow start is set to 1.  Job is running reducer task occupied 29GB of cluster.One NodeManager(NM-4) is become unstable(3 Map got killed); MRAppMaster blacklisted unstable NodeManager(NM-4). All reducer task are running in cluster now.  MRAppMaster does not preempt the reducers because for Reducer preemption calculation; headRoom is considering blacklisted nodes memory. This makes jobs to hang forever(ResourceManager does not assing any new containers on blacklisted nodes but returns availableResouce considers cluster free memory).,Open,Unresolved,MAPREDUCE-5928,Unassigned,Rohith Sharma K S,Fri; 24 Jan 2014 08:21:29 +0000,Sat; 7 Jan 2017 01:52:23 +0000,,,2.2.0;2.3.0,,,MAPREDUCE-6302,https://issues.apache.org/jira/browse/YARN-1680
MAPREDUCE-5735,Bug,Minor,,MultipleOutputs of hadoop not working properly with s3 filesyatem,I have written a mapreduce job and used MultipleOutputs(org.apache.hadoop.mapreduce.lib.output.MultipleOutputs) calss to put the resultant file in a specific user defined directory path(instead of getting the o p file directory path in s3.,Open,Unresolved,,Unassigned,sunil ranjan khuntia,Fri; 24 Jan 2014 10:05:05 +0000,Fri; 7 Feb 2014 03:21:20 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5735
MAPREDUCE-5736,Bug,Minor,jobtracker,Jobtracker to hang when jobs with lot of tasks running,The jobtracker (in MRv1) is progressing slowly when a job with lot of tasks is running. The reason is that JT.getJobCounters is holding a global lock; and with a big job (like 50+K mappers for instance); it could take while to instanciate the ``Counters`` class. This global lock prevent all other activities to run normally; queuing them and degrading the normal activities of the JT.  I was wondering if job.getCounters(); which is synchronized on a finer granularity (i.e. per job and not global) couldn't be taken out of the synchronized block.  On a more general idea; I was wondering if the usage of the synchronized statement in the JT shouldn't be re-thought. Or maybe all this has already been addressed in YARN.,Open,Unresolved,,Unassigned,Benoit Perroud,Mon; 27 Jan 2014 09:13:03 +0000,Mon; 27 Jan 2014 17:32:35 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5736
YARN-1663,Bug,Minor,scheduler,NPE in FifoScheduler.assignContainers,NPE see in scheduler thread running in a MiniYARNCluster with the fifo scheduler,Resolved,Duplicate,YARN-1572,Unassigned,Steve Loughran,Tue; 28 Jan 2014 16:59:56 +0000,Fri; 1 May 2015 21:37:31 +0000,Fri; 1 May 2015 21:37:31 +0000,,2.3.0,,,YARN-1572,https://issues.apache.org/jira/browse/YARN-1663
YARN-1682,Test,Major,,TestRMRestart#testRMRestartSucceededApp occasionally fails,From https: console :,Resolved,Cannot Reproduce,,Unassigned,Ted Yu,Sat; 1 Feb 2014 15:42:07 +0000,Tue; 11 Feb 2014 21:36:31 +0000,Tue; 11 Feb 2014 21:36:31 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-1682
MAPREDUCE-5739,Bug,Major,,DirectoryCollection#createNonExistentDirs() may use an invalid iterator,"Here is related code:   Call to localDirs.remove() modifies Iterable ""localDirs"" which invalidates the iterator.",Resolved,Fixed,,Unassigned,Ted Yu,Tue; 4 Feb 2014 00:20:43 +0000,Thu; 21 Jul 2016 06:22:22 +0000,Thu; 21 Jul 2016 06:22:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5739
MAPREDUCE-5740,Bug,Minor,,Shuffle error when the MiniMRYARNCluster work path contains special characters,When running tests that leverage MiniMRYARNCluster a failure occurs during the jenkins build; however; the tests are successful on local workstations.  The exception found is as follows:   2014-01-30 10:59:28;649 ERROR ShuffleHandler.     If modifications to SpillRecord are undesirable; allowing testWorkDir to be configurable might be a good workaround.,Open,Unresolved,,Unassigned,Inactive,Wed; 5 Feb 2014 14:43:51 +0000,Wed; 5 Feb 2014 14:43:51 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5740
MAPREDUCE-5741,Improvement,Major,mrv2,JobClient should let querying for jobs that match certain tags,MAPREDUCE-5699 adds tagging support to MR jobs. JobClient should support querying jobs based on the tags.,Open,Unresolved,,Unassigned,Karthik Kambatla,Thu; 6 Feb 2014 00:26:20 +0000,Sat; 7 Jan 2017 01:59:57 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5741
MAPREDUCE-5742,Bug,Minor,,pipes.Application should use SecureRandom for security purposes,org.apache.hadoop.mapred.pipes.Application calls its private method getSecurityChallenge(); which uses  security.SecureRandom.,Resolved,Fixed,,Avinash Kujur,Hiroshi Ikeda,Thu; 6 Feb 2014 02:36:49 +0000,Thu; 15 May 2014 08:53:50 +0000,Thu; 15 May 2014 08:53:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5742
MAPREDUCE-5743,Bug,Major,,TestRMContainerAllocator is failing,From https: console :   In above case getMasterContainer() returned null.  AbstractYarnScheduler#getTransferredContainers() should check such condition.,Closed,Fixed,MAPREDUCE-5726,Ted Yu,Ted Yu,Sat; 11 Jan 2014 14:28:25 +0000,Thu; 12 May 2016 18:23:05 +0000,Thu; 6 Feb 2014 06:41:47 +0000,,2.3.0;3.0.0-alpha1,,,YARN-1041;YARN-1474,https://issues.apache.org/jira/browse/MAPREDUCE-5743
MAPREDUCE-5744,Bug,Blocker,,Job hangs because RMContainerAllocator$AssignedRequests.preemptReduce() violates the comparator contract,We ran into a situation where tasks are not getting assigned because RMContainerAllocator$AssignedRequests.preemptReduce() fails repeatedly with the following exception:     It is because the comparator that's defined in this method does not abide by the contract; specifically if p == 0.  Comparator.compare(): http: Comparator.html#compare(T; T),Closed,Fixed,,Gera Shegalov,Sangjin Lee,Thu; 6 Feb 2014 19:05:01 +0000,Fri; 28 Feb 2014 21:35:29 +0000,Thu; 6 Feb 2014 23:34:47 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5744
MAPREDUCE-5745,Wish,Trivial,,thread may hang forever; even after it receives all the expected data,Please discard this JIRA issue (I should open it under a different project). Tried to cancel this issue; but could not find a way to do so. Sorry about this.,Resolved,Invalid,,Unassigned,Jinfeng Ni,Fri; 7 Feb 2014 05:30:48 +0000,Fri; 7 Feb 2014 07:37:19 +0000,Fri; 7 Feb 2014 07:37:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5745
MAPREDUCE-5746,Bug,Major,jobhistoryserver,Job diagnostics can implicate wrong task for a failed job,"We've seen a number of cases where the history server is showing the wrong task as the reason a job failed.  For example; ""Task task_1383802699973_515536_m_027135 failed 1 times"" when some other task had failed 4 times and was the real reason the job failed.",Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 7 Feb 2014 20:48:37 +0000,Thu; 10 Apr 2014 13:11:05 +0000,Wed; 12 Feb 2014 16:09:31 +0000,,0.23.10;2.1.1-beta,,,MAPREDUCE-5317;MAPREDUCE-5754,https://issues.apache.org/jira/browse/MAPREDUCE-5746
MAPREDUCE-5747,Bug,Minor,,Potential null pointer deference in HsTasksBlock#render(),At line 140:   There is no check for type against null. TaskAttemptInfo ctor deferences type:,Patch Available,Unresolved,,Unassigned,Ted Yu,Sat; 8 Feb 2014 02:34:48 +0000,Thu; 1 Oct 2015 20:03:29 +0000,,,,BB2015-05-TBR;newbie;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-5747
MAPREDUCE-5748,Bug,Minor,,Potential null pointer dereference in ShuffleHandler#Shuffle#messageReceived(),Starting around line 510:   If mapIds is empty; lastMap would remain null; leading to NPE in addListener() call.,Resolved,Not A Problem,,Varun Saxena,Ted Yu,Sat; 8 Feb 2014 16:20:59 +0000,Wed; 1 Jul 2015 09:48:10 +0000,Wed; 1 Jul 2015 09:48:10 +0000,,2.7.0,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-5748
MAPREDUCE-5749,Bug,Major,,TestRMContainerAllocator#testReportedAppProgress Failed,"When execute ""mvn test -Dtest=TestRMContainerAllocator#testReportedAppProgress""; It failed with message:   But in fact; the job.xml exits:   See the following code:   At first; user is ""yuling.sh"";  but the UGI is setted to attemptId at ""start();""; after that; job.xml write to yuling.sh job_1392009213299_0001.",Closed,Fixed,,Jason Lowe,Hong Shen,Mon; 10 Feb 2014 05:31:19 +0000,Tue; 10 Mar 2015 04:30:22 +0000,Fri; 25 Apr 2014 14:57:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5749
MAPREDUCE-5750,Improvement,Major,,Need ability to create ACL for viewing the listing of a job queue,We need a way to restrict the ability to see the list of jobs in a queue.   Currently; the only queue ACLs available are acl_administer_queues; acl_administer_queue and acl_submit_applications; none of which control the ability to the see list of jobs in a queue.  This requirement is necessary because the Job History server provides a lot of potentially sensitive info in the job listing alone; e.g. a Hive map reduce job shows the query itself in the Name column.  The only thing we have currently available is the ability to filter by queue name; but there is no way to enforce a filter.  NOTE: This is a duplicate of YARN-1825; not sure if this should go into MR or YARN.,Open,Unresolved,YARN-1825,Unassigned,Alex Nastetsky,Mon; 10 Feb 2014 20:34:57 +0000,Wed; 12 Mar 2014 14:34:06 +0000,,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5750
MAPREDUCE-5751,Bug,Major,,MR app master fails to start in some cases if mapreduce.job.classloader is true,If mapreduce.job.classloader is set to true; and the MR client includes a jetty jar in its libjars or job jar; the MR app master fails to start. A typical stack trace we get is as follows:     This happens because as part of the MR app master start the jetty classes are loaded normally through the app classloader; but WebAppContext tries to load the specific Configuration class via the thread context classloader (which had been set to the user job classloader).,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Mon; 10 Feb 2014 21:03:11 +0000,Wed; 2 Jul 2014 05:12:28 +0000,Fri; 14 Mar 2014 14:48:58 +0000,,2.2.0,,,MAPREDUCE-5957,https://issues.apache.org/jira/browse/MAPREDUCE-5751
MAPREDUCE-5752,Bug,Minor,,Potential invalid iterator in NMClientImpl#cleanupRunningContainers(),In cleanupRunningContainers() :   Removal of container is done in removeStartedContainer():   This may result in invalid iterator for the loop on startedContainers.values(),Resolved,Invalid,,Unassigned,Ted Yu,Tue; 11 Feb 2014 21:12:38 +0000,Thu; 21 Jul 2016 06:20:24 +0000,Thu; 21 Jul 2016 06:20:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5752
YARN-1716,Bug,Major,,finishedStatus is accessed without proper locking in RMContainerImpl#FinishedTransition#transition(),The access should be guarded by obtaining readLock,Resolved,Not A Problem,,Unassigned,Ted Yu,Tue; 11 Feb 2014 21:40:05 +0000,Wed; 12 Feb 2014 17:16:14 +0000,Wed; 12 Feb 2014 17:16:14 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-1716
MAPREDUCE-5754,Improvement,Major,jobhistoryserver;mr-am,Preserve Job diagnostics in history,History does not store the runtime diagnostics information. JobHistoryParser tries to blame a task. We propose to preserve the original runtime diagnostics that covers all the cases including the job being killed. This is particularly important in the context of user-supplied diagnostic message as in MAPREDUCE-5648.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Wed; 12 Feb 2014 04:46:26 +0000,Thu; 10 Apr 2014 13:11:48 +0000,Wed; 26 Feb 2014 21:46:01 +0000,,2.2.0,,MAPREDUCE-5648,MAPREDUCE-5746,https://issues.apache.org/jira/browse/MAPREDUCE-5754
MAPREDUCE-5755,Improvement,Trivial,,MapTask.MapOutputBuffer#compare/swap should have @Override annotation,MapTask.MapOutputBuffer#compare swap implements IndexedSortable interface; but not have @Override annotation. It should be added.,Resolved,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Wed; 12 Feb 2014 21:13:48 +0000,Tue; 30 Aug 2016 01:20:20 +0000,Tue; 17 Mar 2015 05:56:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5755
MAPREDUCE-5756,Bug,Major,,CombineFileInputFormat.getSplits() including directories in its results,"Trying to track down HIVE-6401; where we see some ""is not a file"" errors because getSplits() is giving us directories.  I believe the culprit is FileInputFormat.listStatus():     Which seems to be allowing directories to be added to the results if recursive is false.  Is this meant to return directories? If not; I think it should look like this:",Closed,Fixed,,Jason Dere,Jason Dere,Wed; 12 Feb 2014 19:55:22 +0000,Tue; 16 Dec 2014 03:02:33 +0000,Mon; 21 Jul 2014 21:30:39 +0000,,,,HIVE-6401,,https://issues.apache.org/jira/browse/MAPREDUCE-5756
MAPREDUCE-5757,Bug,Major,client,ConcurrentModificationException in JobControl.toList,Despite having the fix for MAPREDUCE-5513 we saw another ConcurrencyModificationException in JobControl; so something there still isn't fixed.,Closed,Fixed,,Jason Lowe,Jason Lowe,Thu; 13 Feb 2014 20:35:38 +0000,Thu; 10 Apr 2014 13:11:32 +0000,Mon; 17 Feb 2014 16:26:14 +0000,,0.23.10;2.2.0,,,MAPREDUCE-5513,https://issues.apache.org/jira/browse/MAPREDUCE-5757
MAPREDUCE-5758,Bug,Major,mrv2,Reducer local data is not deleted until job completes,Ran into an instance where a reducer shuffled a large amount of data and subsequently failed; but the local data is not purged when the task fails but only after the entire job completes.  This wastes disk space unnecessarily since the data is no longer relevant after the task-attempt exits.,Open,Unresolved,,Chen He,Jason Lowe,Thu; 13 Feb 2014 22:36:23 +0000,Tue; 20 May 2014 19:19:00 +0000,,,0.23.10;2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5758
MAPREDUCE-5759,Bug,Major,,Remove unnecessary conf load in Limits,This is a continuation if MAPREDUCE-5487.,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 18 Feb 2014 17:44:43 +0000,Fri; 15 Aug 2014 05:47:53 +0000,Tue; 1 Apr 2014 00:18:13 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5759
MAPREDUCE-5760,Bug,Major,,Reduce task percentage is going beyond 100% for a job,1.Run job with some 600 maps and 1 reduce task  Observe that for that Job reduce percentage is going beyond 100% Finally job is succeded.  Client Log -------------- 2014-02-06 14:10:13;647 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 128% 2014-02-06 14:10:19;687 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 135% 2014-02-06 14:10:22;706 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 143% 2014-02-06 14:10:25;724 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 149% 2014-02-06 14:10:28;493 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 153% 2014-02-06 14:10:31;512 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 157% 2014-02-06 14:10:34;553 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 163% 2014-02-06 14:10:37;572 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 171%  AM Log -------------- 2014-02-06 14:13:27;590 INFO IPC Server handler 26 on 65120 org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1391663543178_0003_r_000000_0 is : 1.7558539 2014-02-06 14:13:30;566 INFO IPC Server handler 25 on 65120 org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1391663543178_0003_r_000000_0 2014-02-06 14:13:30;566 INFO IPC Server handler 25 on 65120 org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1391663543178_0003_r_000000_0 is : 1.7558539,Open,Unresolved,,Manoj Kumar Danthala,Nishan Shetty,Thu; 20 Feb 2014 03:30:14 +0000,Fri; 31 Oct 2014 05:11:21 +0000,,,2.3.0,,,MAPREDUCE-5958,https://issues.apache.org/jira/browse/MAPREDUCE-5760
MAPREDUCE-5761,Improvement,Trivial,,"Add a log message like ""encrypted shuffle is ON"" in nodemanager logs","Currently no log message gets printed for encrypted shuffle which can determine if encrypted shuffle is On or Off.  Need to add message at Info level such as ""encrypted shuffle is ON""",Closed,Fixed,,Jian He,Yesha Vora,Thu; 20 Feb 2014 19:01:09 +0000,Thu; 10 Apr 2014 13:11:26 +0000,Tue; 25 Feb 2014 01:36:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5761
MAPREDUCE-5762,Improvement,Minor,documentation,Port MAPREDUCE-3223 and MAPREDUCE-4695 (Remove MRv1 config from mapred-default.xml) to branch-2,MRv1 configs are removed in trunk; but they are not removed in branch-2.,Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Fri; 21 Feb 2014 23:15:16 +0000,Fri; 30 Jun 2017 15:06:22 +0000,Wed; 15 Jul 2015 18:47:06 +0000,,2.3.0,,,MAPREDUCE-3223;MAPREDUCE-5496;MAPREDUCE-4695;MAPREDUCE-6057,https://issues.apache.org/jira/browse/MAPREDUCE-5762
MAPREDUCE-5763,Bug,Major,,Warn message about httpshuffle in NM logs,I'm seeing this in my NodeManager logs;  even though things work fine.  A WARN is being caused by some sort of mismatch between the name of the service (in terms of org.apache.hadoop.service.Service.getName()) and the name of the auxiliary service.,Resolved,Fixed,,Akira Ajisaka,Sandy Ryza,Sun; 23 Feb 2014 04:21:00 +0000,Thu; 12 May 2016 18:22:17 +0000,Mon; 9 Nov 2015 06:34:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5763
MAPREDUCE-5764,Bug,Major,,Potential NullPointerException in YARNRunner.killJob(JobID arg0),I found YARNRunner.killJob(JobID arg0) can throw NullPointerException if job status is null.  clientCache.getClient(arg0).getJobStatus(arg0);  can be null. This can happen when there is history write is failed because of hdfs errors or staging directory is different from history server..  We need to have null check otherwise killJob() is prone to throw NPE which cause joblient to exit.,Resolved,Duplicate,MAPREDUCE-5542,Rohith Sharma K S,Rohith Sharma K S,Mon; 24 Feb 2014 11:53:56 +0000,Fri; 6 Mar 2015 04:42:23 +0000,Mon; 24 Feb 2014 13:59:24 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5764
MAPREDUCE-5765,Bug,Minor,pipes,Update hadoop-pipes examples README,wordcount-simple is in the native examples directory,Closed,Fixed,,Mit Desai,Jonathan Eagles,Mon; 24 Feb 2014 18:57:58 +0000,Thu; 12 May 2016 18:23:55 +0000,Thu; 13 Mar 2014 15:14:03 +0000,,2.5.0;3.0.0-alpha1,documentation,,,https://issues.apache.org/jira/browse/MAPREDUCE-5765
MAPREDUCE-5766,Bug,Minor,applicationmaster,Ping messages from attempts should be moved to DEBUG,"Messages such as ""org.apache.hadoop.mapred.TaskAttemptListenerImpl: Ping from attempt_1391416522080_0015_m_000000_0"" in AM logs should be moved to DEBUG.",Closed,Fixed,,Jian He,Ramya Sunil,Mon; 24 Feb 2014 19:43:10 +0000,Thu; 10 Apr 2014 13:11:04 +0000,Thu; 27 Feb 2014 01:31:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5766
MAPREDUCE-5767,Bug,Major,mrv1,Data corruption when single value exceeds map buffer size (io.sort.mb),There is an issue in org.apache.hadoop.mapred.MapTask in 0.20 th way pretty unlikely.,Open,Unresolved,,Unassigned,Ben Roling,Tue; 25 Feb 2014 16:31:15 +0000,Thu; 17 Aug 2017 00:45:19 +0000,,,0.20.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5767
MAPREDUCE-5768,Bug,Major,,TestMRJobs.testContainerRollingLog fails on trunk,Error Message  Number of sylog* files expected same:4 was not:8 Stacktrace   62),Closed,Fixed,,Gera Shegalov,Zhijie Shen,Wed; 26 Feb 2014 23:10:45 +0000,Thu; 10 Apr 2014 13:12:10 +0000,Fri; 28 Feb 2014 19:22:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5768
MAPREDUCE-5770,Bug,Major,,Redirection from AM-URL is broken with HTTPS_ONLY policy,Steps to reproduce:  1) Run a sleep job 2) Run: yarn application -list command to find AM URL. root@host1:~# yarn application -list Total number of applications (application-types: [] and states: SUBMITTED; ACCEPTED; RUNNING):1 Application-Id Application-Name Application-Type User Queue State Final-State Progress Tracking-URL application_1383251398986_0003 Sleep job MAPREDUCE hdfs default RUNNING UNDEFINED 5% http: info,Closed,Fixed,,Jian He,Yesha Vora,Thu; 20 Feb 2014 19:05:10 +0000,Thu; 10 Apr 2014 13:12:11 +0000,Thu; 27 Feb 2014 19:25:47 +0000,,,,YARN-1280,,https://issues.apache.org/jira/browse/MAPREDUCE-5770
MAPREDUCE-5771,Bug,Major,,Measure bw of a single copy call and display the correct aggregated bw,nan,Open,Unresolved,,Unassigned,Siqi Li,Thu; 27 Feb 2014 19:47:44 +0000,Thu; 27 Feb 2014 19:48:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5771
YARN-1774,Bug,Blocker,fairscheduler,FS: Submitting to non-leaf queue throws NPE,If you create a hierarchy of queues and assign a job to parent queue; FairScheduler quits with a NPE.,Closed,Fixed,YARN-1828,Anubhav Dhoot,Anubhav Dhoot,Sat; 1 Mar 2014 02:00:43 +0000,Mon; 29 Jun 2015 21:41:50 +0000,Fri; 7 Mar 2014 21:37:24 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/YARN-1774
MAPREDUCE-5773,Improvement,Blocker,mr-am,Provide dedicated MRAppMaster syslog length limit,Currently mapreduce.task.userlog.limit.kb controls both the length of task attempt logs and MA-AM attempt logs. Obviously; MR-AM log is not userlog. We are interested in keeping MR-AM log either in its entirety or in much larger size than task logs for debugging.   MAPREDUCE-5672 introduced CRLA. We already use a dedicated setting for how many backups of rolled files we keep for MR-AM. However; for large jobs with tens of megabyte AM log; it means that you have a long series of files. A natural improvement is to have a configuration yarn.app.mapreduce.am.container.log.limit.kb . It allows to either disable rolling the log for altogether while keeping it for the task attempts; or to use much a larger limit to make rolling less frequent.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Sun; 2 Mar 2014 07:43:52 +0000,Thu; 10 Apr 2014 13:11:48 +0000,Mon; 3 Mar 2014 22:20:55 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5773
MAPREDUCE-5774,Improvement,Trivial,jobhistoryserver,Job overview in History UI should list reducer phases in chronological order,"Current order:  Average Map Time	         9sec Average Reduce Time	 0sec Average Shuffle Time	 22sec Average Merge Time	 0sec  Proposed order:  Average Map Time	         9sec Average Shuffle Time	 22sec Average Merge Time	 0sec Average Reduce Time	 0sec",Closed,Fixed,,Gera Shegalov,Gera Shegalov,Sun; 2 Mar 2014 08:45:29 +0000,Fri; 15 Aug 2014 05:47:52 +0000,Mon; 12 May 2014 06:17:14 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5774
MAPREDUCE-5775,Bug,Minor,,Remove unnecessary job.setNumReduceTasks in SleepJob.createJob,The two SleepJob's createJob() call job.setNumReduceTasks(numReducer) twice; which is unnecessary.,Closed,Fixed,,jhanver chand sharma,Liyin Liang,Mon; 3 Mar 2014 03:47:20 +0000,Tue; 10 Mar 2015 04:30:37 +0000,Wed; 16 Apr 2014 08:34:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5775
MAPREDUCE-5776,Bug,Major,,Improve TaskAttempt's handling of TA_KILL event when TA is in SUCCESS_CONTAINER_CLEANUP state,In most states that a TaskAttempt goes through; such as ASSIGNED; RUNNING; SUCCEEDED etc. If a TA receives TA_KILL; the state will transit to KILLED (if the TA is in SUCCEEDED state; it depends on if it is a reducer task).  However; If the TA is in SUCCESS_CONTAINER_CLEANUP state; TA just ignores TA_KILL. Later on; SUCCESS_CONTAINER_CLEANUP will move to SUCCEEDED state after the container is cleaned up. So it is possible after a client issue a kill request; the TA will eventually be in SUCCEEDED state. It isn't a major issue. But from consistency's point of view; it is better if TA_KILL is handled in a similar way as how it is handled when TA is in SUCCEEDED state.,Open,Unresolved,,Unassigned,Ming Ma,Tue; 4 Mar 2014 18:53:51 +0000,Tue; 4 Mar 2014 18:54:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5776
MAPREDUCE-5777,Improvement,Major,,Support utf-8 text with BOM (byte order marker),UTF-8 text may have a BOM. TextInputFormat; KeyValueTextInputFormat and friends should recognize the BOM and not treat it as actual data.,Closed,Fixed,,zhihai xu,bc Wong,Tue; 4 Mar 2014 20:04:25 +0000,Wed; 22 Jul 2015 16:57:23 +0000,Thu; 19 Jun 2014 00:02:03 +0000,,0.22.0;1.2.1;2.2.0,,,MAPREDUCE-5926,https://issues.apache.org/jira/browse/MAPREDUCE-5777
MAPREDUCE-5778,Bug,Major,jobhistoryserver,JobSummary does not escape newlines in the job name,JobSummary is not escaping newlines in the job name.  This can result in a job summary log entry that spans multiple lines when users are expecting one-job-per-line output.,Closed,Fixed,,Akira Ajisaka,Jason Lowe,Tue; 4 Mar 2014 20:28:31 +0000,Thu; 10 Apr 2014 13:11:33 +0000,Wed; 12 Mar 2014 22:01:56 +0000,,0.23.10;2.3.0,,,YARN-1789,https://issues.apache.org/jira/browse/MAPREDUCE-5778
MAPREDUCE-5779,Bug,Major,,Hadoop1.0.2 : JobControl.run() Never stop,"My hadoop version:1.0.2  I wonder why when I call run() on a JobControl object; it loops forever . Namely; this code doesn't work:  JobControl jobControl = new JobControl(""Name"");   some stuff here (add jobs and dependencies) Thread control = new Thread(jobControl); control.start(); while (!jobControl.allFinished()) {     try  {         Thread.sleep(5000);     }     catch (Exception e) {} }",Open,Unresolved,,Unassigned,wxlfight,Wed; 5 Mar 2014 09:19:31 +0000,Wed; 5 Mar 2014 17:11:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5779
MAPREDUCE-5780,Bug,Minor,test,SliveTest always uses default FileSystem,It should use the specified path to get FileSystem.  Otherwise; it won't work if the FileSystem is different.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Wed; 5 Mar 2014 23:48:36 +0000,Thu; 10 Apr 2014 13:11:02 +0000,Thu; 6 Mar 2014 22:06:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5780
MAPREDUCE-5781,Bug,Major,examples,DFSCIOTest fails with libhdfs.so.1 missing,hadoop@localhost bin]$ sudo -u hdfs hadoop jar  libhdfs.so.1 does not exist,Open,Unresolved,HADOOP-10390,Unassigned,Guo Ruijing,Fri; 7 Mar 2014 02:12:14 +0000,Fri; 7 Mar 2014 22:04:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5781
MAPREDUCE-5782,Bug,Minor,,Sort Use TableOrderPartitioner cannot find the path of _partition.lst int the container cwd.,hadoop jar hadoop-mapreduce-examples.jar sort sort             input output It prints cannot find the file  _partition.lst in the container's cwd. Error:  158),Open,Unresolved,,Unassigned,Bing Jiang,Fri; 7 Mar 2014 06:49:36 +0000,Sun; 22 Mar 2015 19:46:54 +0000,,,0.23.10;2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5782
MAPREDUCE-5783,Task,Major,webapps,web UI update to allow people to request thread dump of a running task.,This depends on https: YARN-445.,Open,Unresolved,,Unassigned,Ming Ma,Sat; 8 Mar 2014 07:20:51 +0000,Thu; 3 Apr 2014 08:37:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5783
MAPREDUCE-5784,Task,Major,,CLI update so that people can send signal to a specific task,This depends on https: YARN-445. MR client will first find out the container id for the specified task. Then it will use YARN API to signal the container.,Open,Unresolved,,zhenzhao wang,Ming Ma,Sat; 8 Mar 2014 07:28:06 +0000,Tue; 8 Aug 2017 00:12:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5784
MAPREDUCE-5785,New Feature,Major,mr-am;task,Derive heap size or mapreduce.*.memory.mb automatically,"Currently users have to set 2 memory-related configs per Job   per task type.  One first chooses some container size map reduce..memory.mb and then a corresponding maximum Java heap size Xmx  map reduce..memory.mb. This makes sure that the JVM's C-heap (native memory + Java heap) does not exceed this mapreduce.*.memory.mb. If one forgets to tune Xmx; MR-AM might be   	allocating big containers whereas the JVM will only use the default -Xmx200m. 	allocating small containers that will OOM because Xmx is too high.    With this JIRA; we propose to set Xmx automatically based on an empirical ratio that can be adjusted. Xmx is not changed automatically if provided by the user.",Resolved,Fixed,,Gera Shegalov,Gera Shegalov,Sat; 8 Mar 2014 12:44:27 +0000,Thu; 12 May 2016 18:23:24 +0000,Thu; 22 Jan 2015 02:57:57 +0000,,,,,TEZ-699;MAPREDUCE-6343;MAPREDUCE-5892,https://issues.apache.org/jira/browse/MAPREDUCE-5785
MAPREDUCE-5786,Bug,Major,,Support Keep-Alive connections in ShuffleHandler,Currently ShuffleHandler supports fetching map-outputs in batches from same host.  But there are scenarios wherein; fetchers pull data aggressively (i.e start pulling the data as  when they are available).  In this case; the number of mapIds that are pulled from same host remains at 1. This causes lots of connections to be established.  Number of connections can be reduced a lot if ShuffleHandler supports Keep-Alive.,Resolved,Fixed,,Rajesh Balamohan,Rajesh Balamohan,Sun; 9 Mar 2014 00:19:09 +0000,Fri; 21 Mar 2014 21:46:44 +0000,Fri; 21 Mar 2014 21:46:44 +0000,,2.4.0,shuffle,,,https://issues.apache.org/jira/browse/MAPREDUCE-5786
MAPREDUCE-5787,Sub-task,Critical,nodemanager,Modify ShuffleHandler to support Keep-Alive,nan,Closed,Fixed,,Rajesh Balamohan,Rajesh Balamohan,Sun; 9 Mar 2014 00:20:19 +0000,Thu; 23 Feb 2017 15:25:05 +0000,Fri; 21 Mar 2014 21:45:54 +0000,,2.4.0,,,MAPREDUCE-6850,https://issues.apache.org/jira/browse/MAPREDUCE-5787
MAPREDUCE-5788,Sub-task,Major,,Modify Fetcher to pull data using persistent connection,nan,Resolved,Not A Problem,,Rajesh Balamohan,Rajesh Balamohan,Sun; 9 Mar 2014 00:21:06 +0000,Thu; 20 Mar 2014 19:20:09 +0000,Thu; 20 Mar 2014 19:20:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5788
MAPREDUCE-5789,Bug,Major,jobhistoryserver;webapps,Average Reduce time is incorrect on Job Overview page,The Average Reduce time displayed on the job overview page is incorrect. Previously Reduce time was calculated as difference between finishTime and shuffleFinishTime. It should be difference of finishTime and sortFinishTime,Closed,Fixed,,Rushabh S Shah,Rushabh S Shah,Mon; 10 Mar 2014 20:37:22 +0000,Thu; 10 Apr 2014 13:11:45 +0000,Thu; 13 Mar 2014 15:45:36 +0000,,0.23.10;2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5789
MAPREDUCE-5790,Bug,Blocker,,Default map hprof profile options do not work,I have an MR job doing the following:     When I run this job; some of my map tasks fail with this error message:     It looks like ${mapreduce.task.profile.params} is not getting subbed in correctly.,Closed,Fixed,,Gera Shegalov,Andrew Wang,Mon; 10 Mar 2014 23:24:55 +0000,Fri; 15 Aug 2014 05:47:55 +0000,Tue; 15 Jul 2014 04:53:58 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5790
MAPREDUCE-5791,Bug,Major,client,Shuffle phase is slow in Windows - FadviseFileRegion::transferTo does not read disks efficiently,transferTo method in org.apache.hadoop.mapred.FadvisedFileRegion is using transferTo method from a FileChannel to transfer data from a disk to socket. This is performing slow in Windows; slower than in Linux. The reason is that transferTo method for the  nio is issuing 32K IO requests all the time. In Windows; these 32K transfers are not optimal and we don't get the best performance form the underlying IO subsystem. In order to achieve better performance when reading from the drives; we need to read data in bigger chunks; 512K for example.,Closed,Fixed,,Nikola Vujic,Nikola Vujic,Tue; 11 Mar 2014 14:07:03 +0000,Wed; 2 Aug 2017 21:33:10 +0000,Mon; 24 Mar 2014 19:10:55 +0000,,2.3.0;3.0.0-alpha1,,,MAPREDUCE-6923,https://issues.apache.org/jira/browse/MAPREDUCE-5791
MAPREDUCE-5792,Bug,Major,mr-am;mrv2,When mapreduce.jobhistory.intermediate-done-dir isn't writable; application fails with generic error,When trying to run an application and the permissions are wrong on mapreduce.jobhistory.intermediate-done-dir; the MapReduce AM fails with a non-descriptive error message:     When permissions are corrected on this dir; applications are able to run.  There should probably be some sort of check on this dir before launching the AM so a more meaningful error message can be thrown.,Resolved,Duplicate,YARN-675,Mohammad Kamrul Islam,Travis Thompson,Tue; 11 Mar 2014 01:31:21 +0000,Mon; 17 Mar 2014 19:05:18 +0000,Mon; 17 Mar 2014 19:05:18 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5792
MAPREDUCE-5793,Bug,Major,test,Make TestMRJobsWithProfiler#testProfiler faster,TestMRJobsWithProfiler#testProfiler sometimes took more than 120 seconds and then got timeout. https: ,Resolved,Duplicate,MAPREDUCE-5804,Unassigned,Akira Ajisaka,Tue; 11 Mar 2014 18:03:51 +0000,Wed; 19 Mar 2014 22:56:55 +0000,Wed; 19 Mar 2014 22:56:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5793
MAPREDUCE-5794,Bug,Minor,test,SliveMapper always uses default FileSystem.,Similar to MAPREDUCE-5780; SliveMapper should use the test path to get FileSystem.,Closed,Fixed,,Tsz Wo Nicholas Sze,Tsz Wo Nicholas Sze,Tue; 11 Mar 2014 22:56:10 +0000,Thu; 4 Sep 2014 01:15:58 +0000,Thu; 13 Mar 2014 18:58:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5794
MAPREDUCE-5795,Bug,Major,,Job should be marked as Failed if it is recovered from commit.,If Resource manager is restarted when a job is in commit state; The job is not able to recovered after RM restart and it is marked as Killed. The job status should be Failed instead killed.,Closed,Fixed,MAPREDUCE-5718;YARN-1831,Xuan Gong,Yesha Vora,Thu; 13 Mar 2014 18:43:42 +0000,Thu; 10 Apr 2014 13:12:01 +0000,Tue; 25 Mar 2014 02:01:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5795
MAPREDUCE-5796,Bug,Minor,documentation,Use current version of the archive name in DistributedCacheDeploy document,The archive name is hadoop-mapreduce-2.1.1.tar.gz in DistributedCacheDeploy document but Hadoop 2.1.1 is not released. It should be fixed to hadoop-mapreduce-${project.version}.tar.gz to show the current version.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Fri; 14 Mar 2014 00:08:25 +0000,Mon; 1 Dec 2014 03:08:32 +0000,Fri; 26 Sep 2014 20:00:29 +0000,,2.3.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5796
YARN-1845,Improvement,Major,, Elapsed time for failed tasks that never started is  wrong ,The elapsed time for tasks in a failed job that were never started can be way off.  It looks like we're marking the start time as the beginning of the epoch (i.e.: start time = -1) but the finish time is when the task was marked as failed when the whole job failed.  That causes the calculated elapsed time of the task to be a ridiculous number of hours.  Tasks that fail without any attempts shouldn't have start elapsed times.,Closed,Fixed,,Rushabh S Shah,Rushabh S Shah,Fri; 14 Mar 2014 19:33:19 +0000,Tue; 30 Jun 2015 07:13:14 +0000,Mon; 17 Mar 2014 16:54:12 +0000,,0.23.9,,,,https://issues.apache.org/jira/browse/YARN-1845
TEZ-942,Bug,Trivial,,Mrrsleep job with only maps fails with 'Illegal output to map',Mrr sleep job with only maps is failing with 'Illegal output to map'.,Closed,Fixed,,Hitesh Shah,Yesha Vora,Tue; 18 Mar 2014 00:23:21 +0000,Sun; 30 Mar 2014 08:01:46 +0000,Tue; 18 Mar 2014 00:46:27 +0000,,,,,,https://issues.apache.org/jira/browse/TEZ-942
MAPREDUCE-5799,Improvement,Major,,add default value of MR_AM_ADMIN_USER_ENV,"Submit a 1 map + 1 reduce sleep job with the following config:   And the LinuxContainerExecutor is enable on NodeManager. This job will fail with the following error:    When create a ContainerLaunchContext for task in TaskAttemptImpl.createCommonContainerLaunchContext(); the DEFAULT_MAPRED_ADMIN_USER_ENV which is ""LD_LIBRARY_PATH=$HADOOP_COMMON_HOME native"" is added to the environment. Where when create a ContainerLaunchContext for mrappmaster in YARNRunner.createApplicationSubmissionContext(); there is no default environment. So the ubermode job fails to find native lib.",Resolved,Duplicate,MAPREDUCE-5842;MAPREDUCE-6577,Rajesh Kartha,Liyin Liang,Tue; 18 Mar 2014 13:49:40 +0000,Thu; 17 Dec 2015 06:57:04 +0000,Thu; 17 Dec 2015 06:57:04 +0000,,2.3.0,BB2015-05-TBR,,MAPREDUCE-6021,https://issues.apache.org/jira/browse/MAPREDUCE-5799
MAPREDUCE-5800,Improvement,Minor,,Use Job#getInstance instead of deprecated constructors,There're some methods calling deprecated constructors such as new Job(); which causes   warnings. We should use Job.getInstance() to get an instance.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Tue; 18 Mar 2014 19:34:20 +0000,Fri; 10 Apr 2015 20:19:45 +0000,Tue; 3 Feb 2015 22:40:59 +0000,,2.3.0;2.6.0,newbie,,MAPREDUCE-5346;MAPREDUCE-5597;HADOOP-10380,https://issues.apache.org/jira/browse/MAPREDUCE-5800
MAPREDUCE-5801,Bug,Minor,,Uber mode's log message is missing a vcore reason,If a job cannot be run in uber mode because of insufficient vcores; the resulting log message has an empty reason.,Resolved,Fixed,,Steven K. Wong,Steven K. Wong,Tue; 18 Mar 2014 23:54:20 +0000,Thu; 12 May 2016 18:22:50 +0000,Tue; 21 Jul 2015 17:57:15 +0000,,,BB2015-05-TBR;easyfix,,,https://issues.apache.org/jira/browse/MAPREDUCE-5801
MAPREDUCE-5802,Improvement,Major,,Provide an inclusion list mapreduce.job.classloader.job.classes for the class loading isolation,MAPREDUCE-1700  introduced a way to isolate job-suplied classes in an Application Classloader.  mapreduce.job.classloader.system.classes is a way to provide an exclusion list for this class loader. Sometimes it's much easier to express what to include. For this purpose; we propose an inclusion list. mapreduce.job.classloader.job.classes.  The semantics would be use the exclusion list unless the inclusion list is specified to determine what classes should be loaded in the app class loader.,Resolved,Duplicate,HADOOP-11211,Unassigned,Gera Shegalov,Wed; 19 Mar 2014 00:09:52 +0000,Fri; 9 Dec 2016 03:31:04 +0000,Sun; 21 Dec 2014 05:32:26 +0000,,,,,MAPREDUCE-1700,https://issues.apache.org/jira/browse/MAPREDUCE-5802
MAPREDUCE-5803,Bug,Minor,jobhistoryserver,Counters page display all task neverthless of task type( Map or Reduce),"Accessing JobCouner page in HistoryServer; display all the task info.Clicking on ""Launched map tasks"" display Map Task and Reduce Task.",Resolved,Fixed,,Kai Sasaki,Rohith Sharma K S,Wed; 19 Mar 2014 04:29:13 +0000,Tue; 30 Aug 2016 01:20:18 +0000,Tue; 28 Jun 2016 04:17:31 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5803
MAPREDUCE-5804,Test,Major,,TestMRJobsWithProfiler#testProfiler timesout,nan,Closed,Fixed,MAPREDUCE-5793,Mit Desai,Mit Desai,Wed; 19 Mar 2014 15:25:34 +0000,Tue; 30 Jun 2015 07:18:58 +0000,Fri; 21 Mar 2014 17:59:20 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5804
MAPREDUCE-5805,Bug,Major,jobhistoryserver,Unable to parse launch time from job history file,when job complete; there are WARN complains in the log:    because  there is   in the queue name 'test-queue'; we split the job history file name by ; and get the ninth item as job start time. FileNameIndexUtils.    but there is another potential issue: if I also include '-' in the job name(test_one_world in this case); there are all misunderstand.,Closed,Fixed,,Akira Ajisaka,Fengdong Yu,Wed; 19 Mar 2014 06:04:14 +0000,Wed; 28 May 2014 03:56:40 +0000,Wed; 26 Mar 2014 23:44:56 +0000,,2.3.0,,,MAPREDUCE-5815,https://issues.apache.org/jira/browse/MAPREDUCE-5805
MAPREDUCE-5806,Bug,Major,,Log4j settings in container-log4j.properties cannot be overridden ,setting HADOOP_ROOT_LOGGER; -Dhadoop.root.logger has no effect,Closed,Fixed,,Varun Vasudev,Eugene Koifman,Fri; 11 Oct 2013 00:13:58 +0000,Thu; 10 Apr 2014 13:11:11 +0000,Sat; 22 Mar 2014 00:33:49 +0000,,2.1.0-beta,,,HIVE-5511,https://issues.apache.org/jira/browse/MAPREDUCE-5806
MAPREDUCE-5807,Bug,Trivial,examples,Print usage for TeraSort job.,For new to hadoop; try for getting help mesage for examples jobs provided in mapreduce. These Usage helps them in providing arguements.   terasort job execution does not print Usage message instead throw exception.  . hadoop-mapreduce-examples-*.jar terasort   INFO terasort.TeraSort: starting  212),Resolved,Fixed,MAPREDUCE-1557,Rohith Sharma K S,Rohith Sharma K S,Mon; 24 Mar 2014 10:30:27 +0000,Tue; 30 Aug 2016 01:20:16 +0000,Wed; 18 Mar 2015 12:02:53 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5807
MAPREDUCE-5808,Bug,Minor,examples,Port output replication factor configurable for terasort to Hadoop 1.x,Currently; terasort output is hardcoded to have replication factor of 1 in TeraSort. in Hadoop branch-1 code base and configurable in Hadoop 2.0 and trunk. We would like to back port the changes to make terasort output replication factor configurable in Hadoop 1.0.,Resolved,Fixed,,Chuan Liu,Chuan Liu,Mon; 24 Mar 2014 18:24:06 +0000,Mon; 24 Mar 2014 18:45:09 +0000,Mon; 24 Mar 2014 18:45:09 +0000,,1-win;1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5808
MAPREDUCE-5809,Improvement,Major,distcp,Enhance distcp to support preserving HDFS ACLs.,This issue tracks enhancing distcp to add a new command-line argument for preserving HDFS ACLs from the source at the copy destination.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Tue; 25 Mar 2014 17:50:53 +0000,Wed; 3 Sep 2014 20:33:52 +0000,Fri; 16 May 2014 18:36:02 +0000,,2.4.0,,,MAPREDUCE-5639;HDFS-4685;HADOOP-10557,https://issues.apache.org/jira/browse/MAPREDUCE-5809
MAPREDUCE-5810,Bug,Major,contrib/streaming,TestStreamingTaskLog#testStreamingTaskLogWithHadoopCmd is failing,testStreamingTaskLogWithHadoopCmd(org.apache.hadoop.streaming.TestStreamingTaskLog)  Time elapsed: 44.069 sec  &lt; FAILURE!  107)   Results :  Failed tests:    TestStreamingTaskLog.testStreamingTaskLogWithHadoopCmd:107-runStreamJobAndValidateEnv:157 environment set for child is wrong,Closed,Fixed,HADOOP-10438,Akira Ajisaka,Mit Desai,Mon; 24 Mar 2014 21:22:13 +0000,Thu; 12 May 2016 18:22:50 +0000,Fri; 28 Mar 2014 22:22:49 +0000,,2.4.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5810
MAPREDUCE-5811,Bug,Trivial,,Job history subdirectories under done directory is not set with proper permissions accessible to users,This is regarding the Hadoop log file access. The new directories under   are getting created with 770 permission. So the user could not read logs on HDFS. the permission needs to be set properly.,Open,Unresolved,,chaitali gupta,chaitali gupta,Wed; 26 Mar 2014 17:43:56 +0000,Wed; 18 Mar 2015 10:19:48 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5811
MAPREDUCE-5812,Improvement,Major,mr-am, Make job context available to OutputCommitter.isRecoverySupported(),Background ========== The system like Hive provides its version of  OutputCommitter. The custom implementation of isRecoverySupported() requires task context. From taskContext:getConfiguration(); hive checks if  hive-defined specific property is set or not. Based on the property value; it returns true or false. However; in the current OutputCommitter:isRecoverySupported(); there is no way of getting task config. As a result; user can't  turn on off the MRAM recovery feature.  Proposed resolution: =============== 1. Pass Task Context into  isRecoverySupported() method. Pros: Easy and clean Cons: Possible backward compatibility issue due to aPI changes. (Is it true?)  2. Call outputCommitter.setupTask(taskContext) from MRAM: The new OutputCommitter will store the context in the class level variable and use it from  isRecoverySupported()   Props: No API changes. No backward compatibility issue. This call can be made from MRAppMaster.getOutputCommitter() method for old API case. Cons: Might not be very clean solution due to class level variable.  Please give your comments.,Closed,Fixed,,Mohammad Kamrul Islam,Mohammad Kamrul Islam,Thu; 27 Mar 2014 06:38:45 +0000,Wed; 3 Sep 2014 20:33:51 +0000,Mon; 28 Apr 2014 15:27:20 +0000,,2.3.0,,,HIVE-6638,https://issues.apache.org/jira/browse/MAPREDUCE-5812
MAPREDUCE-5813,Bug,Blocker,mrv2;task,YarnChild does not load job.xml with mapreduce.job.classloader=true ,YarnChild.main uses JobConf.addResource(String) to load job.xml that relies on class loading. When mapreduce.job.classloader=true the job-speicific part of the class path is separated from CLASSPATH into APP_CLASSPATH. Therefore job.xml is inaccessible for the default class loader. Later writeLocalJobFile overwrites the correct localized job.xml on disk as well.  This problem is easily avoided by using  JobConf.addResource(Path) to read the localized job.xml without relying on class loading.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Thu; 27 Mar 2014 11:47:34 +0000,Wed; 2 Jul 2014 10:21:18 +0000,Sat; 29 Mar 2014 19:16:32 +0000,,2.3.0,,,MAPREDUCE-5957,https://issues.apache.org/jira/browse/MAPREDUCE-5813
MAPREDUCE-5814,Bug,Major,mrv2,fat jar with *-default.xml may fail when mapreduce.job.classloader=true.,We faced a failure when a job.jar compiled against 0.20+ hadoop artifacts had to run with mapreduce.job.classloader=true because it needed a more recent guava as a dependency. The job failed because the cluster's *-default.xml files were overshadowed by the ones in the fat jar. We propose to treat these default config files like the system packages org.apache.hadoop. to avoid a counterintuitivie behavior as if we had mapreduce.job.user.classpath.first set.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Thu; 27 Mar 2014 12:45:50 +0000,Wed; 3 Sep 2014 20:33:53 +0000,Tue; 13 May 2014 18:59:59 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5814
MAPREDUCE-5815,Bug,Blocker,client;mrv2,Fix NPE in TestMRAppMaster,Working MAPREDUCE-5813 I stumbled on NPE's in TestMRAppMaster. They seem to be introduced by MAPREDUCE-5805.,Closed,Fixed,,Akira Ajisaka,Gera Shegalov,Fri; 28 Mar 2014 01:26:33 +0000,Mon; 30 Jun 2014 08:18:17 +0000,Fri; 11 Apr 2014 04:03:18 +0000,,2.4.0,,,MAPREDUCE-5805,https://issues.apache.org/jira/browse/MAPREDUCE-5815
MAPREDUCE-5816,Bug,Major,,TestMRAppMaster fails in trunk,As can be seen from https: console:   I got the following locally:,Resolved,Duplicate,MAPREDUCE-5815,Unassigned,Ted Yu,Sun; 30 Mar 2014 13:56:34 +0000,Sun; 30 Mar 2014 23:24:25 +0000,Sun; 30 Mar 2014 23:24:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5816
MAPREDUCE-5817,Bug,Major,applicationmaster,Mappers get rescheduled on node transition even after all reducers are completed,We're seeing a behavior where a job runs long after all reducers were already finished. We found that the job was rescheduling and running a number of mappers beyond the point of reducer completion. In one situation; the job ran for some 9 more hours after all reducers completed!  This happens because whenever a node transition (to an unusable state) comes into the app master; it just reschedules all mappers that already ran on the node in all cases.  Therefore; if any node transition has a potential to extend the job period. Once this window opens; another node transition can prolong it; and this can happen indefinitely in theory.  If there is some instability in the pool (unhealthy; etc.) for a duration; then any big job is severely vulnerable to this problem.  If all reducers have been completed; JobImpl.actOnUnusableNode() should not reschedule mapper tasks. If all reducers are completed; the mapper outputs are no longer needed; and there is no need to reschedule mapper tasks as they would not be consumed anyway.,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Mon; 31 Mar 2014 18:48:21 +0000,Tue; 28 Mar 2017 18:46:04 +0000,Fri; 14 Aug 2015 19:43:41 +0000,,2.3.0,,,YARN-1996;MAPREDUCE-6870,https://issues.apache.org/jira/browse/MAPREDUCE-5817
MAPREDUCE-5818,Bug,Major,,hsadmin cmd is missing in mapred.cmd,nan,Closed,Fixed,,Jian He,Jian He,Wed; 2 Apr 2014 21:56:21 +0000,Mon; 30 Jun 2014 08:18:10 +0000,Thu; 3 Apr 2014 20:29:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5818
MAPREDUCE-5819,Improvement,Minor,security,Binary token merge should be done once in TokenCache#obtainTokensForNamenodesInternal(),Currently mergeBinaryTokens() is called by every invocation of obtainTokensForNamenodesInternal(FileSystem; Credentials; Configuration) in the loop of obtainTokensForNamenodesInternal(Credentials; Path[]; Configuration).  This can be simplified such that mergeBinaryTokens() is called only once in obtainTokensForNamenodesInternal(Credentials; Path[]; Configuration).,Patch Available,Unresolved,,Ted Yu,Ted Yu,Wed; 2 Apr 2014 22:40:25 +0000,Wed; 13 Dec 2017 16:31:09 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5819
MAPREDUCE-5820,Bug,Critical,task,Unable to process mongodb gridfs collection data in Hadoop Mapreduce,"I saved a 2GB pdf file into MongoDB using GridFS. now i want process those GridFS collection data using Java Spark Mapreduce. previously i have succesfully processed mongoDB collections with Hadoop mapreduce using Mongo-Hadoop connector. now i'm unable to handle binary data which is coming from input GridFS collections.   MongoConfigUtil.setInputURI(config; ""mongodb: access that data in readable format. Can i use GridFS Api to do that. if so please suggest me how to convert input BSONObject to GridFS object and other best ways to do...Thank you in Advance!!!",Resolved,Invalid,,Unassigned,sivaram,Fri; 4 Apr 2014 13:20:22 +0000,Wed; 9 Apr 2014 09:48:47 +0000,Wed; 9 Apr 2014 09:48:47 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5820
MAPREDUCE-5821,Bug,Major,performance;task,IFile merge allocates new byte array for every value,I wrote a standalone benchmark of the MapOutputBuffer and found that it did a lot of allocations during the merge phase. After looking at an allocation profile; I found that IFile.Reader.nextRawValue() would always allocate a new byte array for every value; so the allocation rate goes way up during the merge phase of the mapper. I imagine this also affects the reducer input; though I didn't profile that.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 4 Apr 2014 17:49:11 +0000,Tue; 9 Sep 2014 20:13:58 +0000,Wed; 14 May 2014 17:52:51 +0000,,2.4.1,,,HADOOP-5494,https://issues.apache.org/jira/browse/MAPREDUCE-5821
MAPREDUCE-5822,Bug,Major,scheduler,FairScheduler does not preempt due to fairshare-starvation when fairshare is 1,If the fair share returned by the scheduler getFairShare() == 1 the pool will never be marked as being starved because of the following calculation:    getFairShare() returns 1 Math.min calculation will return 0.5 Math.Floor() which will cause the desiredFairShare to be set to 0. the return value to be 'false' (0  0) If you have a small job without a minimum set it will not get scheduled if a large job is hogging the slots.,Resolved,Fixed,,Anubhav Dhoot,Anubhav Dhoot,Mon; 7 Apr 2014 22:42:18 +0000,Fri; 11 Apr 2014 21:53:24 +0000,Fri; 11 Apr 2014 21:53:24 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5822
MAPREDUCE-5823,Bug,Major,,TestTaskAttempt fails in trunk and branch-2 with NPE,Here is the console output I got,Resolved,Duplicate,HADOOP-8751,Yufei Gu,Mit Desai,Wed; 9 Apr 2014 16:09:12 +0000,Tue; 6 Sep 2016 12:13:46 +0000,Sat; 23 Apr 2016 01:06:06 +0000,,2.5.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5823
MAPREDUCE-5824,Bug,Major,,TestPipesNonJavaInputFormat.testFormat fails in windows,nan,Closed,Fixed,,Xuan Gong,Xuan Gong,Wed; 9 Apr 2014 17:03:03 +0000,Mon; 30 Jun 2014 08:18:20 +0000,Thu; 10 Apr 2014 16:45:09 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5824
MAPREDUCE-5825,Improvement,Major,mr-am,Provide diagnostics for reducers killed during ramp down,"Since we operate many queues pretty much at their capacity it some times happens that a failed mapper causes a reducer ramp down. However; the user can only see ""Container killed by the ApplicationMaster"" as a diagnostic message for the task attempt; and have to dig through the AM log in order to piece things together.",Closed,Fixed,,Gera Shegalov,Gera Shegalov,Thu; 10 Apr 2014 07:33:35 +0000,Wed; 3 Sep 2014 20:33:51 +0000,Thu; 10 Apr 2014 22:09:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5825
MAPREDUCE-5826,Bug,Major,,TestHistoryServerFileSystemStateStoreService.testTokenStore fails in windows,The test is failing in windows with the updateToken function failing.,Closed,Fixed,,Varun Vasudev,Varun Vasudev,Thu; 10 Apr 2014 21:26:07 +0000,Mon; 30 Jun 2014 08:18:11 +0000,Fri; 11 Apr 2014 04:30:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5826
MAPREDUCE-5827,Bug,Major,,TestSpeculativeExecutionWithMRApp fails,nan,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 10 Apr 2014 21:38:46 +0000,Thu; 4 Sep 2014 01:12:23 +0000,Tue; 22 Apr 2014 18:36:27 +0000,,,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-5827
MAPREDUCE-5828,Bug,Major,,TestMapReduceJobControl fails on JDK 7 + Windows,"It fails when testControlledJob() runs first on Windows with an exception message saying ""output_2"" directory already exists.",Closed,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 11 Apr 2014 03:44:04 +0000,Mon; 30 Jun 2014 08:18:10 +0000,Sun; 13 Apr 2014 19:56:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5828
MAPREDUCE-5829,Bug,Major,mr-am,MRAppMaster misses writing queue-name/user-name to history when recovering from a previous commit,Found this while reviewing MAPREDUCE-5815.  As commented here; we should try to put out queue user-name etc as part of AM_STARTED event so that they don't disappear away in cases like AM restart during a commit.,Open,Unresolved,,Unassigned,Vinod Kumar Vavilapalli,Fri; 11 Apr 2014 03:58:40 +0000,Fri; 11 Apr 2014 03:58:40 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5829
MAPREDUCE-5830,Bug,Blocker,,HostUtil.getTaskLogUrl is not backwards binary compatible with 2.3,HostUtil.getTaskLogUrl used to have a signature like this in Hadoop 2.3.0 and earlier:  public static String getTaskLogUrl(String taskTrackerHostName; String httpPort; String taskAttemptID)  but now has a signature like this:  public static String getTaskLogUrl(String scheme; String taskTrackerHostName; String httpPort; String taskAttemptID)  This breaks source and binary backwards-compatibility.  MapReduce and Hive both have references to this; so their jars compiled against 2.3 or earlier do not work on 2.4.,Closed,Fixed,,Akira Ajisaka,Jason Lowe,Fri; 11 Apr 2014 14:28:27 +0000,Mon; 30 Jun 2014 08:18:11 +0000,Fri; 20 Jun 2014 18:30:59 +0000,,2.4.0,,,MAPREDUCE-5857;MAPREDUCE-5857,https://issues.apache.org/jira/browse/MAPREDUCE-5830
MAPREDUCE-5831,Bug,Blocker,client;mr-am,Old MR client is not compatible with new MR application,"Recently; we saw the following scenario:  1. The user setup a cluster of hadoop 2.3.; which contains YARN 2.3 and MR  2.3.  2. The user client on a machine that MR 2.2 is installed and in the classpath.  Then; when the user submitted a simple wordcount job; he saw the following message:    The problem is that the wordcount job was running on one or more than one nodes of the YARN cluster; where MR 2.3 libs were installed; and JobCounter.MB_MILLIS_REDUCES is available in the counters. On the other side; due to the classpath setting; the client was likely to run with MR 2.2 libs. After the client retrieved the counters from MR AM; it tried to construct the Counter object with the received counter name. Unfortunately; the enum didn't exist in the client's classpath. Therefore; ""No enum constant"" exception is thrown here.  JobCounter.MB_MILLIS_REDUCES is brought to MR2 via MAPREDUCE-5464 since Hadoop 2.3.",Closed,Fixed,,Junping Du,Zhijie Shen,Fri; 11 Apr 2014 17:23:51 +0000,Mon; 1 Dec 2014 03:08:46 +0000,Fri; 26 Sep 2014 06:48:07 +0000,,2.2.0;2.3.0,,,MAPREDUCE-4150;MAPREDUCE-5464;MAPREDUCE-6168,https://issues.apache.org/jira/browse/MAPREDUCE-5831
MAPREDUCE-5832,Bug,Major,,Few tests in TestJobClient fail on Windows, 74),Closed,Fixed,,Vinod Kumar Vavilapalli,Jian He,Sat; 12 Apr 2014 01:05:56 +0000,Mon; 30 Jun 2014 08:18:08 +0000,Wed; 23 Apr 2014 00:04:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5832
MAPREDUCE-5833,Test,Major,,TestRMContainerAllocator fails ocassionally,testReportedAppProgress and testReportedAppProgressWithOnlyMaps have race conditions.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Sat; 12 Apr 2014 01:51:24 +0000,Thu; 4 Sep 2014 01:12:23 +0000,Tue; 22 Apr 2014 19:40:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5833
MAPREDUCE-5834,Bug,Major,,TestGridMixClasses tests timesout on branch-2,testSleepReducer times out everytime I try to run it.,Closed,Fixed,,Mit Desai,Mit Desai,Mon; 14 Apr 2014 15:15:10 +0000,Thu; 12 May 2016 18:24:11 +0000,Tue; 10 Jun 2014 20:26:49 +0000,,2.4.1;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5834
MAPREDUCE-5835,Bug,Critical,,Killing Task might cause the job to go to ERROR state,There could be a race condition if job is killed right after task attempt receives TA_DONE event. In that case; TaskImpl might receive T_ATTEMPT_SUCCEEDED followed by T_ATTEMPTED_KILLED for the same attempt; thus transition job to ERROR state.  a. The task is in KILL_WAIT. b. TA receives TA_DONE event. c. Before TA transitions to SUCCEEDED state; Task sends TA_KILL event. d. TA transitions to SUCCEEDED state and thus send T_ATTEMPT_SUCCEEDED to the task. The task transitions to KILLED state. e. TA processes TA_KILL event and sends T_ATTEMPT_KILLED to the task. f. When task is in KILLED state; it can't handle T_ATTEMPT_KILLED event; thus transition job to ERROR state.,Closed,Fixed,,Ming Ma,Ming Ma,Mon; 14 Apr 2014 15:38:32 +0000,Thu; 4 Sep 2014 01:12:23 +0000,Fri; 25 Apr 2014 22:35:20 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5835
MAPREDUCE-5836,Bug,Trivial,,Fix typo in RandomTextWriter,In RandomTextWriter.  there is a typo.   The list actually contains 1000 words.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Tue; 15 Apr 2014 13:55:05 +0000,Wed; 3 Sep 2014 20:33:52 +0000,Tue; 15 Apr 2014 20:46:53 +0000,,2.4.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5836
MAPREDUCE-5837,Bug,Critical,,MRAppMaster fails when checking on uber mode,When the MRAppMaster determines whether the job should run in the uber mode; it call Class.forName() to check whether the class is derived from ChainMapper:     The problem here is that Class.forName() can also throw NoClassDefError. It happens when the additional dependent jar is unavailable to the MRAppMaster. For example; the MRAppMaster complains about a MR job on Scala:     The proposed fix is to catch NoClassDefError at the corresponding places.,Closed,Fixed,,Haohui Mai,Haohui Mai,Tue; 15 Apr 2014 20:24:58 +0000,Fri; 15 Aug 2014 05:47:57 +0000,Thu; 24 Apr 2014 22:56:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5837
YARN-1947,Test,Major,,TestRMDelegationTokens#testRMDTMasterKeyStateOnRollingMasterKey is failing intermittently, 117),Closed,Fixed,,Jian He,Jian He,Tue; 15 Apr 2014 21:42:21 +0000,Mon; 30 Jun 2014 08:18:14 +0000,Thu; 17 Apr 2014 20:33:52 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-1947
MAPREDUCE-5839,Improvement,Major,client,Provide a boolean switch to enable LazyOutputFormat,nan,Open,Unresolved,,Gera Shegalov,Gera Shegalov,Tue; 15 Apr 2014 22:55:02 +0000,Sat; 7 Jan 2017 01:59:56 +0000,,,2.4.0,,,PIG-3299,https://issues.apache.org/jira/browse/MAPREDUCE-5839
MAPREDUCE-5840,Bug,Minor,,Update MapReduce calls to ProxyUsers#authorize.,HADOOP-10499 will remove an unnecessary overload of ProxyUsers#authorize. This issue tracks updating call sites in the MapReduce code.,Resolved,Not A Problem,,Benoy Antony,Chris Nauroth,Wed; 16 Apr 2014 17:20:19 +0000,Thu; 12 May 2016 18:23:37 +0000,Wed; 16 Apr 2014 17:49:26 +0000,,2.4.0;3.0.0-alpha1,,,HADOOP-10499;HDFS-6251,https://issues.apache.org/jira/browse/MAPREDUCE-5840
MAPREDUCE-5841,Bug,Major,mrv2,uber job doesn't terminate on getting mapred job kill,"If you issue a ""mapred job -kill"" against a uberized job; the job (and the yarn application) state transitions to KILLED; but the application master process continues to run. The job actually runs to completion despite the killed status.  This can be easily reproduced by running a sleep job:     Issue a kill with ""mapred job -kill [job-id]"". The UI will show the job (app) is in the KILLED state. However; you can see the application master is still running.",Closed,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 17 Apr 2014 03:21:08 +0000,Mon; 30 Jun 2014 08:18:10 +0000,Wed; 23 Apr 2014 22:00:44 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5841
MAPREDUCE-5842,Bug,Major,mrv2,uber job with LinuxContainerExecutor cause exception,enable ubertask with linux container executer cause exception:,Resolved,Duplicate,MAPREDUCE-5799,Unassigned,Atkins,Thu; 17 Apr 2014 16:54:15 +0000,Tue; 10 Feb 2015 22:05:40 +0000,Tue; 10 Feb 2015 22:05:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5842
MAPREDUCE-5843,Test,Major,,TestMRKeyValueTextInputFormat failing on Windows,TestMRKeyValueInputFormat fails intermittently on Windows.,Closed,Fixed,,Varun Vasudev,Varun Vasudev,Thu; 17 Apr 2014 18:55:48 +0000,Mon; 30 Jun 2014 08:18:12 +0000,Wed; 23 Apr 2014 22:55:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5843
MAPREDUCE-5844,Bug,Major,,Add a configurable delay to reducer-preemption,We observed cases where the reducer preemption makes the job finish much later; and the preemption does not seem to be necessary since after preemption both the preempted reducer and the mapper are assigned immediately--meaning that there was already enough space for the mapper.  The logic for triggering preemption is at RMContainerAllocator::preemptReducesIfNeeded The preemption is triggered if the following is true:    where am: number of assigned mappers; |m| is mapper size; pr is number of reducers being preempted; and |r| is the reducer size.  The original idea apparently was that if headroom is not big enough for the new mapper requests; reducers should be preempted. This would work if the job is alone in the cluster. Once we have queues; the headroom calculation becomes more complicated and it would require a separate headroom calculation per queue job.  So; as a result headroom variable is kind of given up currently: headroom is always set to 0 What this implies to the speculation is that speculation becomes very aggressive; not considering whether there is enough space for the mappers or not.,Closed,Fixed,,Maysam Yabandeh,Maysam Yabandeh,Thu; 17 Apr 2014 17:10:33 +0000,Fri; 9 Oct 2015 14:55:44 +0000,Thu; 19 Jun 2014 21:14:11 +0000,,,,,MAPREDUCE-6302,https://issues.apache.org/jira/browse/MAPREDUCE-5844
MAPREDUCE-5845,Test,Major,,TestShuffleHandler failing intermittently on windows,TestShuffleHandler fails intermittently on Windows - specifically; testClientClosesConnection.,Patch Available,Unresolved,,Varun Vasudev,Varun Vasudev,Thu; 17 Apr 2014 21:16:05 +0000,Wed; 6 May 2015 03:34:59 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5845
MAPREDUCE-5846,Bug,Major,tools/rumen,Rumen doesn't understand JobQueueChangedEvent,MAPREDUCE:5732 introduced a JobQueueChangeEvent to jhist files. Rumen fails to parse jhist files containing this event.,Closed,Fixed,,Nathan Roberts,Nathan Roberts,Thu; 17 Apr 2014 21:37:37 +0000,Tue; 10 Mar 2015 04:30:47 +0000,Thu; 24 Apr 2014 06:06:14 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5846
MAPREDUCE-5847,Bug,Major,mrv1;mrv2;task,Remove redundant code for fileOutputByteCounter in MapTask and ReduceTask ,Both MapTask and ReduceTask carry redundant code to update BYTES_WRITTEN counter. However; Task.updateCounters uses file system stats for this.,Resolved,Won't Fix,,Gera Shegalov,Gera Shegalov,Fri; 18 Apr 2014 09:35:02 +0000,Thu; 5 Feb 2015 22:49:17 +0000,Thu; 5 Feb 2015 22:28:11 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5847
MAPREDUCE-5848,Sub-task,Major,,MapReduce counts forcibly preempted containers as FAILED,The MapReduce AM is considering a forcibly preempted container as FAILED; while I think it should be considered as KILLED (i.e.; not count against the maximum number of failures).,Resolved,Duplicate,MAPREDUCE-5900,Subru Krishnan,Carlo Curino,Thu; 17 Apr 2014 21:54:25 +0000,Mon; 22 Sep 2014 21:17:34 +0000,Mon; 22 Sep 2014 21:17:34 +0000,,2.1.0-beta,,,MAPREDUCE-5900,https://issues.apache.org/jira/browse/MAPREDUCE-5848
MAPREDUCE-5849,Bug,Minor,,ReduceContextImpl.ValueIterable can only be iterated once,Since ValueIterable reuses same iterator object it cannot be iterated more than once. This behaviour is counter-intuitive (with regards to Iterable usage) and thus difficult to spot.  Unless there are particular performance concerns; new instance of Iterator should be returned.,Open,Unresolved,,Unassigned,Ivan Balashov,Fri; 18 Apr 2014 14:41:13 +0000,Fri; 24 Oct 2014 04:13:06 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5849
MAPREDUCE-5850,Bug,Minor,client,PATH environment variable contains duplicate values in map and reduce tasks on Windows.,The value of the PATH environment variable gets appended twice before execution of a container for a map or reduce task.  This is ultimately harmless at runtime; but it does cause a failure in TestMiniMRChildTask when running on Windows.,Resolved,Duplicate,MAPREDUCE-5642,Chris Nauroth,Chris Nauroth,Fri; 18 Apr 2014 20:32:40 +0000,Thu; 12 May 2016 18:23:30 +0000,Fri; 18 Apr 2014 21:37:11 +0000,,2.4.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5850
MAPREDUCE-5851,New Feature,Minor,distcp,Enable regular expression in the DistCp input,DistCp doesn't support regular expression as the input. If the files to copy are in the different locations; it is quite verbose to put a long list of inputs in the command.,Open,Unresolved,,Yan Qi,Yan Qi,Mon; 21 Apr 2014 18:09:19 +0000,Tue; 13 May 2014 09:35:02 +0000,,,,distcp;expression;regular,,,https://issues.apache.org/jira/browse/MAPREDUCE-5851
MAPREDUCE-5852,Test,Minor,test,Prepare MapReduce codebase for JUnit 4.11.,HADOOP-10503 upgrades the entire Hadoop repo to use JUnit 4.11. Some of the MapReduce code needs some minor updates to fix deprecation warnings before the upgrade.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Mon; 21 Apr 2014 19:17:04 +0000,Thu; 12 May 2016 18:22:23 +0000,Mon; 21 Apr 2014 23:49:37 +0000,,2.4.0;3.0.0-alpha1,,,HADOOP-10503,https://issues.apache.org/jira/browse/MAPREDUCE-5852
MAPREDUCE-5853,Bug,Major,,ChecksumFileSystem.getContentSummary() including contents for crc files ,Trying to track down some differences in Hive statistics between hadoop-1 hadoop-2.  It looks like although ChecksumFileSystem.listStatus() filters out CRC files; getContentSummary() falls back to using the FilterFileSystem.getContentSummary() implementation; which calls fs.getContentSummary().  The underlying fs may not have the same filters as the ChecksumFileSystem and so the CRC files can get included in the content summary.,Resolved,Duplicate,HADOOP-8014,Unassigned,Jason Dere,Tue; 22 Apr 2014 20:39:38 +0000,Tue; 22 Apr 2014 20:58:15 +0000,Tue; 22 Apr 2014 20:51:08 +0000,,,,,HADOOP-10425,https://issues.apache.org/jira/browse/MAPREDUCE-5853
MAPREDUCE-5854,Improvement,Major,,Move the search box in UI from the right side to the left side,"In the UI for resoure manager; job history; and job configuration (this might not be a complete list); there is a search box at the top-right corner of the listed content. This search box is frequently used but it is usually not visible due to right-alignment. Extra scroll is needed to make it visable and it is not convenient. It would be good to move it to the left-side; next to the ""Show ... Entries"" drop-down box.  In the same spirit; the ""First|Preious|...|Next|Last"" at the bottom-right corner of the listed content can also be moved to the left side.",Patch Available,Unresolved,,Unassigned,Jinhui Liu,Wed; 23 Apr 2014 05:43:58 +0000,Wed; 6 May 2015 03:26:59 +0000,,,0.23.9,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5854
MAPREDUCE-5855,Bug,Major,applicationmaster;job submission;mr-am;mrv2,Oozie jobs able to affect container classpath,A submitted job is able to affect the container classpath and cause failures at the container level.  The jar spec allows a user to specify a service provider via the Service Loader interface for things like XML implementations. These implementations can be provided by including files in META-INF map-reduce?,Open,Unresolved,,Unassigned,Michael Miklavcic,Wed; 23 Apr 2014 21:57:07 +0000,Wed; 23 Apr 2014 22:01:08 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5855
MAPREDUCE-5856,Bug,Major,client,Counter limits always use defaults even if JobClient is given a different Configuration,If you have a job with more than the default number of counters (i.e.  120); and you create a JobClient with a Configuration where the default is increased (e.g. 500); then JobClient will throw this Exception:,Resolved,Duplicate,MAPREDUCE-5875,Robert Kanter,Robert Kanter,Wed; 23 Apr 2014 22:18:38 +0000,Thu; 8 May 2014 17:07:05 +0000,Thu; 8 May 2014 17:07:05 +0000,,2.3.0;2.4.0,,,MAPREDUCE-5875,https://issues.apache.org/jira/browse/MAPREDUCE-5856
MAPREDUCE-5857,Bug,Major,,Need task log URL API for external users,From HIVE-6900; Hive was using HostUtil.getTaskLogUrl() to try to get task logs for error reporting; but this is a private unstable API.  Make a public API for this purpose.,Open,Unresolved,,Unassigned,Jason Dere,Thu; 24 Apr 2014 00:22:42 +0000,Thu; 8 Jun 2017 18:29:47 +0000,,,,,,HIVE-16860;MAPREDUCE-5830;HIVE-6900;MAPREDUCE-5830,https://issues.apache.org/jira/browse/MAPREDUCE-5857
MAPREDUCE-5858,Task,Major,,[Umbrella] MR should make use of the timeline server,Now MR relies on its own JobHistoryServer for MR specific history information. Given the timeline server is ready; we should gradually migrate MR historic data to it as well. relieving MR from maintaining its own history server daemon.,Open,Unresolved,,Unassigned,Zhijie Shen,Thu; 24 Apr 2014 06:56:58 +0000,Wed; 22 Apr 2015 17:54:36 +0000,,,,,,MAPREDUCE-6331,https://issues.apache.org/jira/browse/MAPREDUCE-5858
MAPREDUCE-5859,Improvement,Major,client,org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus should not throw an exception if at least one of input path is not empty,At the time being org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus throws an exception if at least one of input path is empty. This is pretty inconvenient; especially; it there are additional path filters that may exclude some files on the path.  It would be nice if an exception will be thrown if and only if there is no one file to process at all (on all input paths combined).  If backward compatibility is a priority; a configuration setting may be added (with the default value to retain existing behavior).,Open,Unresolved,,Unassigned,Oleksandr Alesinskyy,Fri; 25 Apr 2014 14:46:43 +0000,Fri; 25 Apr 2014 14:46:43 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5859
MAPREDUCE-5860,Bug,Major,pipes,Hadoop pipes Combiner is closed before all of its reduce calls,When a Combiner is specified to runTask() its reduce() method may be called after its close() method has been called due to how the Combiner's containing object; CombineRunner; is closed after the TaskContextImpl's reducer member is closed (see TaskContextImpl::closeAll()).  I believe the fix is to delegate the Combiner's ownership to CombineRunner; making it responsible for calling the Combiner's close() method and deleting the Combiner instance.,Patch Available,Unresolved,,Unassigned,Joe Mudd,Fri; 25 Apr 2014 20:24:56 +0000,Fri; 6 Nov 2015 03:04:23 +0000,,,0.23.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5860
MAPREDUCE-5861,Improvement,Minor,,finishedSubMaps field in LocalContainerLauncher does not need to be volatile,Around line 374:   The increment of finishedSubMaps is not atomic.  See the answer to http: what-is-the-difference-of-atomic-volatile-synchronize .  AtomicInteger can be used to achieve atomicity.,Closed,Fixed,,Tsuyoshi Ozawa,Ted Yu,Fri; 25 Apr 2014 20:40:13 +0000,Fri; 15 Aug 2014 05:47:56 +0000,Thu; 15 May 2014 07:21:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5861
MAPREDUCE-5862,Bug,Critical,,Line records longer than 2x split size aren't handled correctly,Suppose this split (100-200) is in the middle of a record (90-240):     Currently; the first split would read the entire record; up to offset 240; which is good. But the 2nd split has a bug in producing a phantom record of (200; 240).,Closed,Fixed,,bc Wong,bc Wong,Sun; 27 Apr 2014 01:02:23 +0000,Wed; 3 Sep 2014 20:33:52 +0000,Wed; 28 May 2014 19:54:20 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5862
MAPREDUCE-5863,Bug,Major,,Killing task attempts while speculation is enabled can cause the job to fail,There could be a race condition when a T_ADD_SPEC_ATTEMPT is being fired; the task gets succeeded and then killed by the client. In that case; the task state changes from SUCCEEDED to SCHEDULED; and then task gets a T_ADD_SPEC_ATTEMPT event; which is invalid for SCHEDULED state.  1. Task is running. 2. Speculator fires a T_ADD_SPEC_ATTEMPT 3. Before task receives T_ADD_SPEC_ATTEMPT; it succeeds 4. Succeeded TA receives TA_KILL from client. Now the task is at SCHEDULED state. 5. Task receives T_ADD_SPEC_ATTEMPT; since this is an unexpected event; the job fails.,Open,Unresolved,,Unassigned,Mingzhe Hao,Sun; 27 Apr 2014 04:22:52 +0000,Mon; 28 Apr 2014 02:01:33 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5863
MAPREDUCE-5864,Bug,Major,applicationmaster,The part-r-00000 did not generate when I run a sample; wordcount with non-ascii path.,When I run a command; hadoop jar  output.  The file _SUCCESS and part-r-00000 have not generated.,Open,Unresolved,,Binglin Chang,Lizhao.Du,Mon; 28 Apr 2014 08:05:47 +0000,Sun; 14 Sep 2014 13:16:33 +0000,,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5864
MAPREDUCE-5865,Bug,Major,mrv1,RecordReader is not closed in TeraInputFormat#writePartitionFile(),Here is related code:   reader should be closed using finally block.,Patch Available,Unresolved,,Unassigned,Ted Yu,Mon; 28 Apr 2014 17:20:45 +0000,Fri; 10 Mar 2017 02:25:48 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5865
MAPREDUCE-5866,Test,Major,client;test,TestFixedLengthInputFormat fails in windows,org.apache.hadoop.mapred.TextFixedLengthInputFormat and org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat tests fail in Windows,Closed,Fixed,,Varun Vasudev,Varun Vasudev,Mon; 28 Apr 2014 10:38:26 +0000,Thu; 12 May 2016 18:23:35 +0000,Mon; 7 Jul 2014 20:01:03 +0000,,2.4.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5866
MAPREDUCE-5867,Sub-task,Major,resourcemanager,Possible NPE in KillAMPreemptionPolicy related to ProportionalCapacityPreemptionPolicy,I configured KillAMPreemptionPolicy for My Application Master and tried to check preemption of queues. In one scenario I have seen below NPE in my AM  014-04-24 15:11:08;860 ERROR RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM.   662)  I was using 2.2.0 and merged MAPREDUCE-5189 to see how AM preemption works.,Resolved,Fixed,,Sunil G,Sunil G,Thu; 24 Apr 2014 12:45:54 +0000,Thu; 12 May 2016 18:23:58 +0000,Mon; 19 May 2014 06:49:17 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5867
MAPREDUCE-5868,Bug,Major,test,TestPipeApplication causing nightly build to fail,TestPipeApplication appears to be timing out which causes the nightly build to fail.,Closed,Fixed,MAPREDUCE-5923,Akira Ajisaka,Jason Lowe,Tue; 29 Apr 2014 15:24:46 +0000,Tue; 10 Mar 2015 04:30:32 +0000,Mon; 7 Jul 2014 19:48:40 +0000,,,,,HADOOP-10532,https://issues.apache.org/jira/browse/MAPREDUCE-5868
MAPREDUCE-5869,Bug,Trivial,,Wrong date and and time on job tracker page,When an application master restarts during execution of a task; job tracker page displays wrong start date-time for the job.,Resolved,Duplicate,MAPREDUCE-5079,chaitali gupta,chaitali gupta,Tue; 29 Apr 2014 20:33:17 +0000,Wed; 18 Mar 2015 11:58:25 +0000,Wed; 18 Mar 2015 11:58:25 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5869
MAPREDUCE-5870,Improvement,Major,client,Support for passing Job priority through Application Submission Context in Mapreduce Side,"Job Priority support in MapReduce.  1. Job Priority can be set from client side as below (Configuration and api).  	JobConf.getJobPriority() and JobConf.setJobPriority(JobPriority priority) 	We can also use configuration ""mapreduce.job.priority"".    		Now this Job priority can be passed in Application Submission context from Client side. 		Here we can reuse the MRJobConfig.PRIORITY configuration.  2. CLI changes to support --set-priority. Run time change of JobPriority is also to be handled. 3. Change Job to have the support for setPriority and getPriority (getter is handled with JobStatus)",Resolved,Fixed,,Sunil G,Sunil G,Wed; 30 Apr 2014 09:44:08 +0000,Tue; 30 Aug 2016 01:20:13 +0000,Tue; 24 Nov 2015 22:18:03 +0000,,,,,MAPREDUCE-6515;YARN-1963,https://issues.apache.org/jira/browse/MAPREDUCE-5870
MAPREDUCE-5871,Improvement,Major,,Estimate Job Endtime,YARN-1969 adds a new earliest-endtime-first policy to the fair scheduler. As a prerequisite step; the AppMaster should estimate its end time and send it to the RM via the heartbeat. This jira focuses on how the AppMaster performs this estimation.,Resolved,Later,,Maysam Yabandeh,Maysam Yabandeh,Wed; 30 Apr 2014 14:41:01 +0000,Sun; 24 May 2015 23:53:01 +0000,Sun; 24 May 2015 23:53:01 +0000,,,BB2015-05-TBR,YARN-1969,,https://issues.apache.org/jira/browse/MAPREDUCE-5871
MAPREDUCE-5872,New Feature,Minor,performance,Update NativeS3FileSystem to issue copy commands for files with in a directory with a configurable number of threads,In NativeS3FileSystem if you do a copy of a directory it will copy all the files to the new location; but it will do this with one thread.  Code is below.  This jira will allow a configurable number of threads to be used to issue the copy commands to S3.  do {         PartialListing listing = store.list(srcKey; S3_MAX_LISTING_LENGTH; priorLastKey; true);         for (FileMetadata file : listing.getFiles())  {           keysToDelete.add(file.getKey());           store.copy(file.getKey(); dstKey + file.getKey().substring(srcKey.length()));         }         priorLastKey = listing.getPriorLastKey();       } while (priorLastKey != null);,Resolved,Invalid,,Theodore michael Malaska,Theodore michael Malaska,Thu; 1 May 2014 17:31:52 +0000,Thu; 1 May 2014 17:32:59 +0000,Thu; 1 May 2014 17:32:59 +0000,,,performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-5872
MAPREDUCE-5873,Bug,Major,,Shuffle bandwidth computation includes time spent waiting for maps,Currently ShuffleScheduler in ReduceTask JVM status displays bandwidth. Its definition however is confusing because it captures the time where there is no copying because there is a pause between when new wave of map outputs is available. current bw is definded as (bytes copied so far)   (total time in the copy phase so far) It would be more useful  1) to measure bandwidth of a single copy call. 2) display aggregated bw as long as there is at least one fetcher is in the copy call.,Closed,Fixed,,Siqi Li,Siqi Li,Thu; 1 May 2014 20:03:05 +0000,Mon; 1 Dec 2014 03:09:00 +0000,Wed; 15 Oct 2014 16:04:37 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5873
MAPREDUCE-5874,Bug,Major,documentation,Creating MapReduce REST API section,Now that we have the YARN HistoryServer; perhaps we should move HistoryServerRest.apt.vm and MapRedAppMasterRest.apt.vm into the MapReduce section where it really belongs?,Closed,Fixed,YARN-1995,Tsuyoshi Ozawa,Ravi Prakash,Wed; 30 Apr 2014 02:08:26 +0000,Fri; 15 Aug 2014 05:48:00 +0000,Fri; 16 May 2014 17:11:55 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5874
MAPREDUCE-5875,Bug,Major,applicationmaster;client;task,Make Counter limits consistent across JobClient; MRAppMaster; and YarnChild,"Currently; counter limits ""mapreduce.job.counters.*"" handled by org.apache.hadoop.mapreduce.counters.Limits are initialized asymmetrically: on the client side; and on the AM; job.xml is ignored whereas it's taken into account in YarnChild.  It would be good to make the Limits job-configurable; such that max counters groups is only increased when needed. With the current Limits implementation relying on static constants; it's going to be challenging for tools that submit jobs concurrently  without resorting to class loading isolation.  The patch that I am uploading is not perfect but demonstrates the issue.",Closed,Fixed,MAPREDUCE-5856;MAPREDUCE-6129,Gera Shegalov,Gera Shegalov,Sun; 4 May 2014 01:33:32 +0000,Mon; 31 Jul 2017 22:19:02 +0000,Sun; 12 Oct 2014 05:53:52 +0000,,2.4.0,,,MAPREDUCE-5856;MAPREDUCE-6271;MAPREDUCE-5149;MAPREDUCE-6286;MAPREDUCE-4443,https://issues.apache.org/jira/browse/MAPREDUCE-5875
MAPREDUCE-5876,Bug,Major,client,SequenceFileRecordReader NPE if close() is called before initialize(),org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader extends org.apache.hadoop.mapreduce.RecordReader which in turn implements  io Closeable.html) which is not.  An NPE is being thrown if close() method is invoked without previously calling initialize() method. This happens because SequenceFile.Reader in is null.,Patch Available,Unresolved,,Tsuyoshi Ozawa,Reinis Vicups,Mon; 5 May 2014 12:21:51 +0000,Wed; 27 May 2015 09:27:54 +0000,,,2.3.0;2.4.0,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-5876
MAPREDUCE-5877,Bug,Critical,jobtracker;tasktracker,Inconsistency between JT/TT for tasks taking a long time to launch,"For the tasks that take too long to launch (for genuine reasons like large distributed caches); JT expires the task. Depending on whether job recovery is enabled and the JT's restart state; another attempt is launched or not even when the JT is not restarted. The status of the attempt changes to ""Error launching task"". Meanwhile; the TT is not informed of this task expiry and eventually launches the task. Also; the ""new"" attempt might be assigned to the same TT leading to more inconsistent behavior.   To avoid this; one can bump up the mapred.tasktracker.expiry.interval; but leading to long TT failure discovery times.   We should have a per-job timeout for task launches TT should be consistent in what they say.",Resolved,Fixed,,Karthik Kambatla,Karthik Kambatla,Mon; 5 May 2014 20:36:28 +0000,Mon; 3 Nov 2014 18:33:23 +0000,Wed; 7 May 2014 00:50:53 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5877
MAPREDUCE-5878,Bug,Major,mrv2,some standard JDK APIs are not part of system classes defaults,"There are some standard JDK APIs that are not part of the mapreduce.job.classloader.system.classes property value.  Currently the default value covers only "" ."" from the JDK. However; there are other APIs that are as well-established as these; such as org.w3c.dom and org.xml.sax. In other similar systems (e.g. OSGi); it is a standard practice to include both of these packages in the system classes. We should add these to the default values.",Closed,Fixed,,Sangjin Lee,Sangjin Lee,Mon; 5 May 2014 22:11:05 +0000,Mon; 1 Dec 2014 03:07:56 +0000,Thu; 14 Aug 2014 23:19:13 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5878
MAPREDUCE-5879,Bug,Major,client,Hive is broke after YARN-1553,Hive cannot build against branch-2 after YARN-1553,Resolved,Fixed,,Fengdong Yu,Fengdong Yu,Tue; 6 May 2014 09:15:54 +0000,Tue; 6 May 2014 09:25:45 +0000,Tue; 6 May 2014 09:25:45 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5879
PIG-3923,Bug,Trivial,build,Gitignore file should ignore all generated artifacts,"There are several artifacts that get created by build targets which are neither versioned nor .gitignore'd. The attached patch excludes these files:   	.ant-targets-build.xml 	contrib pig_*SNAPSHOT.xml",Closed,Fixed,,Philip (flip) Kromer,Philip (flip) Kromer,Tue; 6 May 2014 09:51:53 +0000,Mon; 7 Jul 2014 18:07:55 +0000,Sat; 10 May 2014 23:11:38 +0000,,,build;git,,,https://issues.apache.org/jira/browse/PIG-3923
MAPREDUCE-5881,New Feature,Minor,mrv2,Create counters that count how many bytes of data were read from a local node and a local rack,"MapReduce provides the counters ""org.apache.hadoop.mapreduce.JobCounter DATA_LOCAL_MAPS"" and ""org.apache.hadoop.mapreduce.JobCounter RACK_LOCAL_MAPS"" that count how many local map tasks were started. This works great; if we have one HDFS block per a input split.  If we have multiple HDFS blocks in an input split (e.g. non-splittable file such as gzip; or use of CombineFileInputFormat); then these counters become inaccurate.  If it has not been proposed yet; I propose adding new counters that count how many bytes of data were read from a local node and a local rack. Thanks to them; a user will see the real data locality ratio.",Open,Unresolved,,Unassigned,Adam Kawa,Wed; 7 May 2014 10:14:50 +0000,Wed; 7 May 2014 10:16:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5881
MAPREDUCE-5882,Bug,Critical,,org.apache.hadoop.mapreduce.tools.CLI doesn't close cluster on job submit.,When job is submitted through CLI class; Job connects to the cluster. However; cluster is never closed in this case and ClientProtocolProvider.close() is never invoked.  In all other cases Cluster is gracefully closed explicitly in finally block.  This can be easily resolved e.g. by wrapping call to job.submit() in try-finally block:  try {     job.submit(); } finally {     Cluster jobCluster = job.getCluster();      if (jobCluster != null)         jobCluster.close(); },Open,Unresolved,,Unassigned,Vladimir Ozerov,Wed; 7 May 2014 11:14:20 +0000,Thu; 27 Oct 2016 10:58:56 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5882
MAPREDUCE-5883,Bug,Minor,,Total megabyte-seconds in job counters is slightly misleading,"The following counters are in milliseconds so ""megabyte-seconds"" might be better stated as ""megabyte-milliseconds"" MB_MILLIS_MAPS.name=               Total megabyte-seconds taken by all map tasks MB_MILLIS_REDUCES.name=            Total megabyte-seconds taken by all reduce tasks VCORES_MILLIS_MAPS.name=           Total vcore-seconds taken by all map tasks VCORES_MILLIS_REDUCES.name=        Total vcore-seconds taken by all reduce tasks",Closed,Fixed,,Nathan Roberts,Nathan Roberts,Wed; 7 May 2014 14:58:57 +0000,Fri; 6 Jan 2017 07:39:58 +0000,Tue; 24 Nov 2015 22:04:27 +0000,,2.4.0;3.0.0-alpha1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5883
MAPREDUCE-5884,Bug,Major,jobhistoryserver;security,History server uses short user name when canceling tokens,When the owner of a token tries to explicitly cancel the token; it gets the following error exception     Details: AbstractDelegationTokenSecretManager.cacelToken() gets the owner as full principal name where as the canceller is the short name. The potential code snippets:    The code shows 'owner' gets the full principal name. Where as the value of 'canceller' depends on who is calling it.  In some cases; it is the short name. REF: HistoryClientService.     Possible resolution: -------------------------- Option 1: in cancelToken() method; compare with both : short name and full principal name. Pros: Easy. Have to change in one place. Cons: Someone can argue that it is hacky!  Option 2: All the caller sends the consistent value as 'canceller' : either short name or full principal name.  Pros: Cleaner. Cons: A lot of code changes and potential bug injections.  I'm open for both options. Please give your opinion.  Btw; how it is working now in most cases?  The short name and the full principal name are usually the same for end-users.,Closed,Fixed,,Mohammad Kamrul Islam,Mohammad Kamrul Islam,Wed; 16 Apr 2014 01:07:22 +0000,Wed; 3 Sep 2014 20:33:52 +0000,Thu; 8 May 2014 21:28:53 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5884
MAPREDUCE-5885,Bug,Major,test,build/test/test.mapred.spill causes release audit warnings,Multiple unit tests are creating files under hadoop-mapreduce-client-jobclient test.mapred.spill which are causing release audit warnings during Jenkins patch precommit builds.  In addition to being in a poor location for test output and not cleaning up after the test; there are multiple tests using this location which will cause conflicts if tests are run in parallel.,Closed,Fixed,,Chen He,Jason Lowe,Fri; 9 May 2014 13:48:59 +0000,Tue; 10 Mar 2015 04:30:42 +0000,Wed; 27 Aug 2014 15:33:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5885
MAPREDUCE-5886,Improvement,Minor,examples,Allow wordcount example job to accept multiple input paths.,It would be convenient if the wordcount example MapReduce job could accept multiple input paths and run the word count on all of them.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Fri; 9 May 2014 20:58:31 +0000,Thu; 12 May 2016 18:24:07 +0000,Tue; 10 Jun 2014 17:52:52 +0000,,2.4.0;3.0.0-alpha1,,,MAPREDUCE-5889,https://issues.apache.org/jira/browse/MAPREDUCE-5886
MAPREDUCE-5887,Improvement,Major,applicationmaster;client,Move split creation from submission client to MRAppMaster,This JIRA is filed to improve scalability of job submission; specifically when there is a significant latency between the submission client and the cluster nodes RM and NN; e.g. in a multi-datacenter environment.,Resolved,Duplicate,MAPREDUCE-207,Gera Shegalov,Gera Shegalov,Mon; 12 May 2014 02:14:26 +0000,Wed; 14 May 2014 09:39:38 +0000,Mon; 12 May 2014 05:11:00 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5887
MAPREDUCE-5888,Bug,Major,mr-am,Failed job leaves hung AM after it unregisters ,When a job fails the AM hangs during shutdown.  A non-daemon thread pool executor thread prevents the JVM teardown from completing; and the AM lingers on the cluster for the AM expiry interval in the FINISHING state until eventually the RM expires it and kills the container.  If application limits on the queue are relatively low (e.g.: small queue or small cluster) this can cause unnecessary delays in resource scheduling on the cluster.,Closed,Fixed,YARN-2283,Jason Lowe,Jason Lowe,Mon; 12 May 2014 22:40:06 +0000,Wed; 3 Sep 2014 20:33:52 +0000,Tue; 13 May 2014 19:18:47 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5888
MAPREDUCE-5889,Improvement,Minor,,Deprecate FileInputFormat.setInputPaths(Job; String) and FileInputFormat.addInputPaths(Job; String),FileInputFormat.setInputPaths(Job job; String commaSeparatedPaths) and FileInputFormat.addInputPaths(Job job; String commaSeparatedPaths) fail to parse commaSeparatedPaths if a comma is included in the file path. (e.g. Path:  file;with;comma) We should deprecate these methods and document to use setInputPaths(Job job; Path... inputPaths) and addInputPaths(Job job; Path... inputPaths) instead.,Patch Available,Unresolved,,Akira Ajisaka,Akira Ajisaka,Tue; 13 May 2014 06:59:24 +0000,Mon; 11 Sep 2017 08:45:00 +0000,,,,,,MAPREDUCE-5886,https://issues.apache.org/jira/browse/MAPREDUCE-5889
MAPREDUCE-5890,New Feature,Major,security,Support for encrypting Intermediate data and spills in local filesystem,For some sensitive data; encryption while in flight (network) is not sufficient; it is required that while at rest it should be encrypted. HADOOP-10150  HDFS-6134 bring encryption at rest for data in filesystem using Hadoop FileSystem API. MapReduce intermediate data and spills should also be encrypted while at rest.,Closed,Fixed,,Arun Suresh,Alejandro Abdelnur,Thu; 15 May 2014 04:05:29 +0000,Tue; 30 Jun 2015 07:18:59 +0000,Fri; 11 Jul 2014 00:48:38 +0000,,2.4.0,encryption,,MAPREDUCE-6257,https://issues.apache.org/jira/browse/MAPREDUCE-5890
MAPREDUCE-5891,Sub-task,Major,,Improved shuffle error handling across NM restarts,To minimize the number of map fetch failures reported by reducers across an NM restart it would be nice if reducers only reported a fetch failure after trying for at specified period of time to retrieve the data.,Closed,Fixed,,Junping Du,Jason Lowe,Thu; 15 May 2014 15:50:39 +0000,Thu; 2 Apr 2015 13:49:13 +0000,Thu; 18 Sep 2014 22:05:33 +0000,,2.5.0,,,YARN-1336;MAPREDUCE-6156;YARN-666,https://issues.apache.org/jira/browse/MAPREDUCE-5891
MAPREDUCE-5892,Improvement,Major,mr-am,Derive MR-AM container size and Xmx based on the job size: number of splits and reduces,https: MAPREDUCE-207?focusedCommentId=13997964page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13997964,Open,Unresolved,,Unassigned,Gera Shegalov,Thu; 15 May 2014 19:28:38 +0000,Mon; 20 Apr 2015 21:05:41 +0000,,,,,,MAPREDUCE-5785,https://issues.apache.org/jira/browse/MAPREDUCE-5892
HADOOP-10614,Improvement,Major,,CBZip2InputStream is not threadsafe,Hadoop uses CBZip2InputStream to decode bzip2 files. However; the implementation is not threadsafe. This is not a really problem for Hadoop MapReduce because Hadoop runs each task in a separate JVM. But for other libraries that utilize multithreading and use Hadoop's InputFormat; e.g.; Spark; it will cause exceptions like the following:,Closed,Fixed,,Xiangrui Meng,Xiangrui Meng,Fri; 16 May 2014 02:32:34 +0000,Fri; 15 Aug 2014 05:39:44 +0000,Sat; 17 May 2014 18:34:44 +0000,,1.2.1;2.2.0,,,,https://issues.apache.org/jira/browse/HADOOP-10614
MAPREDUCE-5894,Improvement,Major,,Make critical YARN properties first class citizens in the build.,"We recently found that when deploy hadoop 2.2 with hadoop 2.0 values     changed to     .    There are likewise many similar examples of parameters which become deprecated over time.   See http: DeprecatedProperties.html  I suggest we:  1) Have a list of all mandatory current parameters stored in the code; and also;   2) a list of deprecated ones.   3) Then; have the build * automatically fail * if a parameter in the ""madatory"" list is NOT accessed during unit tests....   this would (a) make it so that unit testing of parameters does not regress and (b) force all updates to the code which change a parameter name; to also include an update to deprecated parameter list; before build passes.  This setup could then be used to enable   4) Reporting or failing upon presence of clearly obsolete parameters which are result of obvious human error.",Open,Unresolved,,Unassigned,jay vyas,Sun; 18 May 2014 01:45:55 +0000,Sun; 18 May 2014 01:59:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5894
MAPREDUCE-5895,Bug,Major,client,FileAlreadyExistsException was thrown : Temporary Index File can not be cleaned up because OutputStream doesn't close properly,In TaskLog.  Temporary Index File is created by following code.     The code is surrounded by try-finally so if some Exception ERROR is thrown between constructing bos and dos; temporary file is not cleaned up. I met the situation that when a thread ran; OOM was thrown after bos created and temporary file is not cleaned up. At different time; another thread executed same logic and fail because of FileAlreadyExistsException.,Closed,Fixed,,Kousuke Saruta,Kousuke Saruta,Tue; 20 May 2014 08:34:54 +0000,Thu; 12 May 2016 18:24:24 +0000,Thu; 29 May 2014 07:08:38 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5895
MAPREDUCE-5896,Improvement,Major,,InputSplits should indicate which locations have the block cached in memory,nan,Closed,Fixed,,Sandy Ryza,Sandy Ryza,Tue; 20 May 2014 20:41:51 +0000,Fri; 15 Aug 2014 05:47:57 +0000,Wed; 18 Jun 2014 23:33:11 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5896
HADOOP-10623,New Feature,Major,,Provide a utility to be able inspect the config as seen by a hadoop client / daemon ,To ease debugging of config issues it is convenient to be able to generate a config as seen by the job client or a hadoop daemon,Open,Unresolved,,Gera Shegalov,Gera Shegalov,Wed; 21 May 2014 03:55:09 +0000,Sat; 7 Jan 2017 01:57:04 +0000,,,,,,HADOOP-7947;HADOOP-9044;HADOOP-12118,https://issues.apache.org/jira/browse/HADOOP-10623
MAPREDUCE-5898,Bug,Major,distcp,distcp to support preserving HDFS extended attributes(XAttrs),This JIRA to track the distcp support to handle the Xattrs with preserving options. Add new command line argument to support that.,Closed,Fixed,,Yi Liu,Uma Maheswara Rao G,Wed; 21 May 2014 14:32:22 +0000,Thu; 12 May 2016 18:22:26 +0000,Fri; 6 Jun 2014 14:50:12 +0000,,3.0.0-alpha1,,,MAPREDUCE-5922;MAPREDUCE-5920;HDFS-2006,https://issues.apache.org/jira/browse/MAPREDUCE-5898
MAPREDUCE-5899,Improvement,Major,distcp,Support incremental data copy in DistCp,Currently when doing distcp with -update option; for two files with the same file names but with different file length or checksum; we overwrite the whole file. It will be good if we can detect the case where (sourceFile = targetFile + appended_data); and only transfer the appended data segment to the target. This will be very useful if we're doing incremental distcp.,Closed,Fixed,,Jing Zhao,Jing Zhao,Wed; 14 May 2014 02:32:31 +0000,Tue; 8 Sep 2015 18:54:54 +0000,Thu; 22 May 2014 18:50:47 +0000,,,,,MAPREDUCE-6471,https://issues.apache.org/jira/browse/MAPREDUCE-5899
MAPREDUCE-5900,Sub-task,Major,applicationmaster;mr-am;mrv2,Container preemption interpreted as task failures and eventually job failures ,We have Added preemption exit code needs to be incorporated MR needs to recognize the special exit code value of -102 and interpret it as a container being killed instead of a container failure.,Closed,Fixed,,Mayank Bansal,Mayank Bansal,Wed; 21 May 2014 18:06:57 +0000,Tue; 10 Mar 2015 04:30:40 +0000,Thu; 3 Jul 2014 01:48:55 +0000,,2.4.1,,,MAPREDUCE-5848,https://issues.apache.org/jira/browse/MAPREDUCE-5900
MAPREDUCE-5901,New Feature,Major,,Hadoop 2.4 Java execution issue: remotely submission jobs fail ,"I have installed Hadoop 2.4 on remote machine in Single-Mode setting. From another machine (client) I run a Java application that submit a job to a remote Hadoop machine (cluster); I have used the attached code. The problem is that the real execution of the map process is run on my local machine (client) not on the cluster machine. JobConf job = new JobConf(SOF.class); job.setJobName(""SIM-""+sim_id); System.setProperty(""HADOOP_USER_NAME""; ""hadoop""); FileInputFormat.addInputPath(job;new Path(""hdfs: configuration",Resolved,Won't Fix,,Unassigned,michele,Wed; 21 May 2014 19:31:45 +0000,Wed; 21 May 2014 22:39:57 +0000,Wed; 21 May 2014 22:39:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5901
MAPREDUCE-5902,Bug,Major,jobhistoryserver,JobHistoryServer (HistoryFileManager) needs more debug logs; fails to pick up jobs with % characters in the name.,1) JobHistoryServer sometimes skips over certain history files; and ignores serving them as completed.  2) In addition to skipping these files; the JobHistoryServer doesnt effectively log which files are being skipped ; and why.    So In addition to determining why certain types of files are skipped (file name length doesnt appear to be the reason; rather; it appears to be th some stage in the job pipeline.,Open,Unresolved,,Unassigned,jay vyas,Fri; 23 May 2014 04:13:23 +0000,Thu; 29 May 2014 13:21:40 +0000,,,,,,YARN-1728,https://issues.apache.org/jira/browse/MAPREDUCE-5902
MAPREDUCE-5903,Bug,Critical,,If Kerberos Authentication is enabled; MapReduce job is failing on reducer phase,I have 3-node cluster configuration: 1 ResourceManager and 3 NodeManagers; Kerberos is enabled; have hdfs; yarn; mapred principals keytabs. ResourceManager and NodeManager are ran under yarn user; using yarn Kerberos principal.  Use case 1: WordCount; submit job using yarn UGI (i.e. superuser; the one having Kerberos principal on all boxes). Result: job successfully completed. Use case 2: WordCount; submit job using LDAP user impersonation via yarn UGI. Result: Map tasks are completed SUCCESSfully; Reduce task fails with ShuffleError Caused by:  165),Resolved,Invalid,,Unassigned,Victor Kim,Wed; 21 May 2014 21:11:21 +0000,Fri; 29 Jul 2016 09:57:01 +0000,Sat; 9 May 2015 00:53:03 +0000,,2.4.0,shuffle,,,https://issues.apache.org/jira/browse/MAPREDUCE-5903
YARN-2105,Test,Major,,Fix TestFairScheduler after YARN-2012,The following tests fail in trunk:,Closed,Fixed,YARN-2106,Ashwin Shankar,Ted Yu,Mon; 26 May 2014 15:09:31 +0000,Fri; 15 Aug 2014 05:44:50 +0000,Tue; 27 May 2014 23:46:53 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-2105
MAPREDUCE-5905,Bug,Minor,,"CountersStrings.toEscapedCompactStrings outputs unnecessary ""null"" strings","CountersStrings.toEscapedCompactStrings outputs ""null"" strings if a CounterGroup has more than one Counter.  That way there are some ""null"" strings in MRv1(CDH) job history log. https: DISTRO-598",Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Tue; 27 May 2014 05:12:47 +0000,Tue; 30 Aug 2016 01:20:08 +0000,Mon; 4 May 2015 06:04:36 +0000,,2.4.0;2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5905
MAPREDUCE-5906,Improvement,Minor,,"Inconsistent configuration in property ""mapreduce.reduce.shuffle.input.buffer.percent""",In MergeManagerImpl.  the default value of MRJobConfig.SHUFFLE_INPUT_BUFFER_PERCENT (=mapreduce.reduce.shuffle.input.buffer.percent) looks 0.90.   However; the actual default value is 0.70 in mapred-default.xml.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Tue; 27 May 2014 08:50:15 +0000,Mon; 1 Dec 2014 03:11:13 +0000,Thu; 14 Aug 2014 18:08:15 +0000,,2.4.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5906
MAPREDUCE-5907,Improvement,Major,client,Improve getSplits() performance for fs implementations that can utilize performance gains from recursive listing,FileInputFormat (both mapreduce and mapred implementations) use recursive listing while calculating splits. They however do this by doing listing level by level. That means to discover files in  bar to discover their immediate children and so on. This doesn't scale well for object store based fs implementations like s3 and swift because every listStatus call ends up being a webservice call to backend. In cases where large number of files are considered for input; this makes getSplits() call slow.   This patch adds a new set of recursive list apis that gives opportunity to the fs implementations to optimize. The behavior remains the same for other implementations (that is a default implementation is provided for other fs so they don't have to implement anything new). However for objectstore based fs implementations it provides a simple change to include recursive flag as true (as shown in the patch) to improve listing performance.,Patch Available,Unresolved,,Sumit Kumar,Sumit Kumar,Wed; 28 May 2014 19:54:44 +0000,Tue; 21 Nov 2017 11:33:29 +0000,,,2.4.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5907
MAPREDUCE-5908,Bug,Major,mrv2;performance,java.lang.NoSuchMethodError: org.apache.commons.io.IOUtils.closeQuietly(Ljava/io/Closeable;)V, 313),Open,Unresolved,,Unassigned,huangli,Thu; 29 May 2014 11:11:15 +0000,Thu; 29 May 2014 11:11:15 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5908
MAPREDUCE-5909,Bug,Major,,JobStatus contains 0.0 values of mapProgress; reduceProgress; setupProgress; cleanupProgress,When I invoke getAllJobs on a JobClient object; I'm receiving an array of JobStatuses. JobStatus object arrives with fields mapProgress; reduceProgress; setupProgress; cleanupProgress with 0.0 values. So; I'm not able to track the map and reduce job progress through the client.  Seems that because YARN supports variety of applications (not only MR); ApplicationReport object doesn't contain mapProgress and ReduceProgress. Instead it contains just progress. Apparently this led to following code during converting from ApplicationReport to JobStatus object to do following:,Open,Unresolved,,Unassigned,Victor Kim,Thu; 29 May 2014 19:44:12 +0000,Thu; 29 May 2014 19:44:12 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5909
MAPREDUCE-5910,Task,Major,applicationmaster,MRAppMaster should handle Resync from RM instead of shutting down.,The ApplicationMasterService currently sends a resync response to which the AM responds by shutting down. The MRAppMaster behavior is expected to change to calling resyncing with the RM. Resync means resetting the allocate RPC sequence number to 0 and the AM should send its entire outstanding request to the RM. Note that if the AM is making its first allocate call to the RM then things should proceed like normal without needing a resync. The RM will return all containers that have completed since the RM last synced with the AM. Some container completions may be reported more than once.,Closed,Fixed,,Rohith Sharma K S,Rohith Sharma K S,Fri; 30 May 2014 12:42:42 +0000,Mon; 1 Dec 2014 03:08:24 +0000,Thu; 17 Jul 2014 19:02:36 +0000,,,,,YARN-1366,https://issues.apache.org/jira/browse/MAPREDUCE-5910
MAPREDUCE-5911,Bug,Minor,examples,Terasort TeraOutputFormat does not check for output directory existance,The enforcement that the directory must not yet exist is implemented in FileOutputFormat#checkOutputSpecs by throwing FileAlreadyExistsException.  However; terasort uses a specialized output format; TeraOutputFormat; which is a subclass of FileOutputFormat.  The subclass overrides checkOutputSpecs; but does not re-implement the existence check and throw FileAlreadyExistsException.,Resolved,Duplicate,MAPREDUCE-4879,Bruno P. Kinoshita,Ivan Mitic,Fri; 30 May 2014 17:42:59 +0000,Wed; 19 Nov 2014 02:59:20 +0000,Mon; 20 Oct 2014 04:04:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5911
MAPREDUCE-5912,Bug,Major,client,Task.calculateOutputSize does not handle Windows files after MAPREDUCE-5196,causes Windows local output files to be routed through HDFS:,Resolved,Fixed,,Remus Rusanu,Remus Rusanu,Wed; 4 Jun 2014 15:37:03 +0000,Thu; 12 May 2016 18:24:48 +0000,Thu; 12 Jun 2014 20:03:09 +0000,,3.0.0-alpha1,,,HADOOP-10663,https://issues.apache.org/jira/browse/MAPREDUCE-5912
MAPREDUCE-5913,Improvement,Minor,,Unify MapRed(old API) and MapReduce(new API) implementation to remove duplicate functions.,Unify MapRed(old API) and MapReduce(new API) implementation to remove duplicate functions. For example; org.apache.hadoop.mapred.LineRecordReader and org.apache.hadoop.mapreduce.lib.input.LineRecordReader have many duplicate functions.,Open,Unresolved,,Unassigned,zhihai xu,Wed; 4 Jun 2014 21:14:13 +0000,Wed; 4 Jun 2014 22:50:15 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5913
HADOOP-10686,Bug,Major,,Writables are not always configured,Seeing the following exception:    It turns out that WritableComparator does not configure Writable objects :https:   This is during the sort phase for an MR job.,Closed,Fixed,,Abraham Elmahrek,Abraham Elmahrek,Thu; 5 Jun 2014 17:45:02 +0000,Fri; 15 Aug 2014 05:39:45 +0000,Tue; 29 Jul 2014 23:16:04 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/HADOOP-10686
MAPREDUCE-5915,Improvement,Minor,pipes,Pipes ping thread should sleep in intervals to allow for isDone() to be checked,The ping() thread sleeps for 5 seconds at a time causing up to a 5 second delay in testing if the job is finished.,Patch Available,Unresolved,,Unassigned,Joe Mudd,Fri; 6 Jun 2014 11:34:51 +0000,Wed; 6 May 2015 03:27:30 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5915
MAPREDUCE-5916,Bug,Major,pipes,The authenticate response is not sent when password is empty (LocalJobRunner),When running in a mode where there are no credentials associated with the pipes submission and the password is empty; the C++ verifyDigestAndRespond() does not respond to the Java side.,Patch Available,Unresolved,,Unassigned,Joe Mudd,Fri; 6 Jun 2014 12:39:45 +0000,Wed; 6 May 2015 03:27:33 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5916
MAPREDUCE-5917,New Feature,Minor,pipes,Be able to retrieve configuration keys by index,The pipes C++ side does not have a configuration key value pair iterator.  It is useful to be able to iterate through all of the configuration keys without having to expose a C++ map iterator since that is specific to the JobConf internals.,Patch Available,Unresolved,,Unassigned,Joe Mudd,Fri; 6 Jun 2014 13:08:39 +0000,Wed; 6 May 2015 03:27:39 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5917
MAPREDUCE-5918,Bug,Major,,LineRecordReader can return the same decompressor to CodecPool multiple times,LineRecordReader can return the same decompressor to CodecPool multiple times if method close() called multiple times. In this case CodecPool doesn't guarantee that it always return different decompressors. This issue can cause some difficult reproducible and difficult diagnosable bugs in Hadoop based programs.,Closed,Fixed,,Sergey Murylev,Sergey Murylev,Sun; 8 Jun 2014 15:15:33 +0000,Fri; 30 Oct 2015 18:16:10 +0000,Fri; 14 Nov 2014 11:49:42 +0000,,2.3.0,,,SPARK-11424,https://issues.apache.org/jira/browse/MAPREDUCE-5918
MAPREDUCE-5919,Bug,Major,mrv2,Usage of aggregate framework always results in execution of base class ValueAggregatorBaseDescriptor.,The bug was discovered when I was trying to execute aggregatewordcount example in hadoop example jar file. No matter what I did; the output was always the number of lines in the input text file. This is what exactly ValueAggregatorBaseDescriptor class does. So because of this bug; custom aggregation functions are not possible.,Open,Unresolved,,Unassigned,Jithin Justin,Mon; 9 Jun 2014 15:07:42 +0000,Mon; 9 Jun 2014 15:07:42 +0000,,,2.2.0;2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5919
MAPREDUCE-5920,Bug,Minor,distcp;documentation,Add Xattr option in DistCp docs ,nan,Closed,Fixed,MAPREDUCE-5922,Yi Liu,Uma Maheswara Rao G,Tue; 10 Jun 2014 16:41:33 +0000,Thu; 12 May 2016 18:24:30 +0000,Wed; 11 Jun 2014 18:36:40 +0000,,3.0.0-alpha1,,,MAPREDUCE-5898;HDFS-2006,https://issues.apache.org/jira/browse/MAPREDUCE-5920
TEZ-1203,Bug,Major,,TezClient and TezSession doesn't stops/close YarnClient,The org.apache.tez.client.TezClient creates a org.apache.hadoop.yarn.client.api.YarnClient to submit an DAG application to cluster but; no apis exist to stop close the org.apache.hadoop.yarn.client.api.YarnClient object residing inside.  Same is the case with org.apache.tez.client.TezSession which doesn't close the org.apache.hadoop.yarn.client.api.YarnClient  object in stop() call.  From Siddharth Seth: I think this is just an oversight. The YarnClient created by the TezClient could also be shared with the DAGClient that is returned after submitting an application. Eventually; the connection will end up timing out at the RPC level.,Resolved,Duplicate,TEZ-692,Unassigned,Subroto Sanyal,Tue; 10 Jun 2014 22:09:07 +0000,Sat; 26 Jul 2014 01:51:40 +0000,Sat; 26 Jul 2014 01:51:40 +0000,,,,,,https://issues.apache.org/jira/browse/TEZ-1203
MAPREDUCE-5922,Bug,Minor,documentation,Update distcp documentation to mention option for preserving xattrs.,In hadoop-mapreduce-project DistCp.md.vm; let's add a mention of the new distcp option for preserving xattrs.,Resolved,Duplicate,MAPREDUCE-5920,Unassigned,Chris Nauroth,Wed; 11 Jun 2014 17:43:41 +0000,Thu; 12 May 2016 18:23:03 +0000,Wed; 11 Jun 2014 18:20:49 +0000,,3.0.0-alpha1,newbie,,MAPREDUCE-5639;MAPREDUCE-5898,https://issues.apache.org/jira/browse/MAPREDUCE-5922
MAPREDUCE-5923,Bug,Minor,,org.apache.hadoop.mapred.pipes.TestPipeApplication timeouts intermittently,nan,Resolved,Duplicate,MAPREDUCE-5868,Unassigned,Chen He,Thu; 12 Jun 2014 22:08:10 +0000,Tue; 10 Mar 2015 04:30:15 +0000,Thu; 12 Jun 2014 22:11:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5923
MAPREDUCE-5924,Bug,Major,,Windows: Sort Job failed due to 'Invalid event: TA_COMMIT_PENDING at COMMIT_PENDING',The Sort job over 1GB data failed with below error    The JobHistory Url prints job state = ERROR,Closed,Fixed,,Zhijie Shen,Yesha Vora,Fri; 13 Jun 2014 05:02:09 +0000,Fri; 15 Aug 2014 05:47:59 +0000,Wed; 18 Jun 2014 01:00:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5924
MAPREDUCE-5925,Bug,Critical,,NLineInputFormat silently produces garbage on gzipped input,[ Found while investigating the impact of MAPREDUCE-2094 ]  The org.apache.hadoop.mapreduce.lib.input.NLineInputFormat (probably the mapred version too) only makes sense for splittable files.  This inputformat uses the isSplitable from its superclass FileInputFormat (which always returns true) in combination with the LineRecordReader.  When you provide it a gzipped file (non-splittable compression) it will create multiple splits (isSplitable == true) yet the LineRecordReader cannot handle the gzipped file in multiple splits because the GzipCodec does not support this.  Overall effect is that you get incorrect results.  Proposed solution: Add detection for this kind of scenario and let the NLineInputFormat fail hard when someone tries this.   I'm not sure if this should go into the LineRecordReader or only in the NLineInputFormat.,Open,Unresolved,,Unassigned,Niels Basjes,Fri; 13 Jun 2014 09:44:21 +0000,Fri; 13 Jun 2014 09:44:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5925
MAPREDUCE-5926,Improvement,Major,mrv1,Support utf-8 text with BOM (byte order marker) for branch-1,nan,Resolved,Duplicate,MAPREDUCE-5777,zhihai xu,zhihai xu,Sat; 14 Jun 2014 00:29:40 +0000,Tue; 17 Jun 2014 06:37:39 +0000,Tue; 17 Jun 2014 06:09:58 +0000,,,,,MAPREDUCE-5777,https://issues.apache.org/jira/browse/MAPREDUCE-5926
MAPREDUCE-5927,Bug,Blocker,applicationmaster,Getting following error,Hi;  I am getting following error; while running application on cluser -    INFO mapreduce.Job: Counters: 0   Can you please help me in fixing this ?  Thanks; ~Kedar,Resolved,Invalid,,Vinod Kumar Vavilapalli,Kedar Dixit,Mon; 16 Jun 2014 11:07:37 +0000,Thu; 30 Oct 2014 09:40:23 +0000,Mon; 16 Jun 2014 14:44:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5927
MAPREDUCE-5928,Bug,Major,,Deadlock allocating containers for mappers and reducers,"I have a small cluster consisting of 8 desktop class systems (1 master + 7 workers). Due to the small memory of these systems I configured yarn as follows:  yarn.nodemanager.resource.memory-mb = 2200 yarn.scheduler.minimum-allocation-mb = 250 On my client I did  mapreduce.map.memory.mb = 512 mapreduce.reduce.memory.mb = 512 Now I run a job with 27 mappers and 32 reducers. After a while I saw this deadlock occur:  	All nodes had been filled to their maximum capacity with reducers. 	1 Mapper was waiting for a container slot to start in.    I tried killing reducer attempts but that didn't help (new reducer attempts simply took the existing container).  Workaround: I set this value from my job. The default value is 0.05 (= 5%)  mapreduce.job.reduce.slowstart.completedmaps = 0.99f",Resolved,Duplicate,YARN-1680,Unassigned,Niels Basjes,Mon; 16 Jun 2014 13:41:16 +0000,Wed; 18 Jun 2014 15:34:43 +0000,Wed; 18 Jun 2014 15:34:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5928
MAPREDUCE-5929,Bug,Major,,YARNRunner.java; path for jobJarPath not set correctly,"In YARNRunner.  line 357;  Path jobJarPath = new Path(jobConf.get(MRJobConfig.JAR));  This causes the job.jar file to miss scheme; host and port number on distributed file systems other than hdfs.   If we compare line 357 with line 344; there ""job.xml"" is actually set as  Path jobConfPath = new Path(jobSubmitDir;MRJobConfig.JOB_CONF_FILE);  It appears ""jobSubmitDir"" is missing on line 357; which causes this problem. In hdfs; the additional qualify process will correct this problem; but not other generic distributed file systems.  The proposed change is to replace 35 7 with  Path jobJarPath = new Path(jobConf.get(jobSubmitDir;MRJobConfig.JAR));",Patch Available,Unresolved,,Rahul Palamuttam,Chao Tian,Mon; 16 Jun 2014 17:02:09 +0000,Wed; 6 May 2015 03:33:46 +0000,,,2.2.0,BB2015-05-TBR;newbie;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-5929
MAPREDUCE-5930,Improvement,Major,documentation,Document MapReduce metrics,MapReduce-side of HADOOP-6350. Add MapReduce metrics to Metrics document.,Open,Unresolved,,Akira Ajisaka,Akira Ajisaka,Tue; 17 Jun 2014 02:14:03 +0000,Tue; 17 Jun 2014 02:15:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5930
MAPREDUCE-5931,Bug,Minor,test,Validate SleepJob command line parameters,This is a minor issue per se. I had a typo in my script specifying a negative number of reducers for the SleepJob. It results in the exception that is far from the root cause; and appeared as a serious issue with the map-side sort.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Wed; 18 Jun 2014 05:41:15 +0000,Mon; 1 Dec 2014 03:11:04 +0000,Fri; 29 Aug 2014 19:54:50 +0000,,1.2.1;2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5931
MAPREDUCE-5932,Improvement,Major,mrv2,Provide an option to use a dedicated reduce-side shuffle log,For reducers in large jobs our users cannot easily spot portions of the log associated with problems with their code. An example reducer with INFO-level logging generates ~3500 lines   ~700KiB  lines per second. 95% of the log is the client-side of the shuffle org.apache.hadoop.mapreduce.task.reduce.*     Byte percentage breakdown:    While this is information is actually often useful for devops debugging shuffle performance issues; the job users are often lost.   We propose to have a dedicated syslog.shuffle file.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Wed; 18 Jun 2014 06:22:00 +0000,Fri; 24 Apr 2015 23:15:18 +0000,Wed; 3 Dec 2014 17:14:09 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5932
MAPREDUCE-5933,Sub-task,Major,mr-am,Enable MR AM to post history events to the timeline server,Nowadays; MR AM collects the history events and writes it to HDFS for JHS to source. With the timeline server; MR AM can put these events there.,Closed,Fixed,,Robert Kanter,Zhijie Shen,Wed; 18 Jun 2014 08:26:46 +0000,Mon; 1 Dec 2014 03:09:59 +0000,Tue; 28 Oct 2014 03:48:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5933
MAPREDUCE-5934,Sub-task,Major,jobhistoryserver,Make JHS source the timeline server for job history information,After MAPREDUCE-5933; JHS can source the timeline server to get the job history information.,Open,Unresolved,,Zhijie Shen,Zhijie Shen,Wed; 18 Jun 2014 08:49:02 +0000,Thu; 19 Jun 2014 05:51:12 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5934
MAPREDUCE-5935,Bug,Major,test,TestMRServerPorts#testTaskTrackerPorts fails with null pointer exception.,The exception is caused by a race condition. The test case calls Jobtracker.offerservice in a seperate thread JTRunner; which initializes the class variable FileSystem fs. In the main thread it tries to close fs in the finally block of code; but at that point jt.fs might still not be initialized; thus causing the NPE.,Open,Unresolved,,Jinghui Wang,Jinghui Wang,Fri; 20 Jun 2014 01:07:53 +0000,Wed; 23 Sep 2015 20:24:51 +0000,,,1.1.1;1.2.0;1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5935
MAPREDUCE-5936,Bug,Major,mrv1;mrv2,MultipleInputs incorrect output with copied Path,The MultipleInputs class builds a Map with Path objects as keys and mapper-inputformat combinations as values.  This is not correct behavior. If MultipleInputs.addInputPath is called twice with the same Path and (for example) two different Mapper classes; the second addition will silently overwrite the first.  Expected behavior would be that the input file would be processed one time for each call to addInputPath.  This is necessary for applications which are doing join-like operations: joining a file with itself is valid; and it should not be incumbent on the application developer to recognize when the same Path is included twice to work around this bug.  MultipleInputs should be using a multimap or a map with List values.,Open,Unresolved,,Unassigned,Bryan Jacobs,Fri; 20 Jun 2014 15:58:06 +0000,Fri; 20 Jun 2014 15:58:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5936
MAPREDUCE-5937,Bug,Major,,hadoop/mapred job -history <history_file> shows the counters twice in the output.,HiistoryView#printCounters method uses AbstractCounter#getGroupNames; which includes legacy groups can cause duplicates on CLI output.  See attached example output.,Patch Available,Unresolved,,Andres Perez,Jinghui Wang,Fri; 20 Jun 2014 20:40:24 +0000,Fri; 8 Apr 2016 17:58:09 +0000,,,2.2.0;2.7.2,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5937
MAPREDUCE-5938,Bug,Major,,Shuffle port in nodemanager is binding to all IPs ,nodemanager port mapreduce.shuffle.port is listening to all ip,Open,Unresolved,,Naganarasimha G R,Ashutosh Jindal,Mon; 23 Jun 2014 09:10:34 +0000,Fri; 8 Jul 2016 01:06:23 +0000,,,,,,YARN-4119,https://issues.apache.org/jira/browse/MAPREDUCE-5938
MAPREDUCE-5939,Bug,Major,,StartTime showing up as the epoch time in JHS UI after upgrade,After upgrading from 0.23.x to 2.5; the start time of old apps are showing up as the epoch time.  It looks like 2.5 expects start time to be encoded at the end of the jhist file name (....xxxx-timestamp.jhist). It should have been made backward compatible.,Closed,Fixed,,Chen He,Kihwal Lee,Mon; 23 Jun 2014 20:13:48 +0000,Wed; 3 Sep 2014 20:33:53 +0000,Thu; 26 Jun 2014 19:57:59 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5939
YARN-2251,Bug,Major,,Avoid negative elapsed time in JHS/MRAM web UI and services,Recently we observed a rare bug that an elapsed time of a reducer is going to be negative on JHS web UI and via REST APIs. While the real reason for this bug seems to be clock asynchronization on different hosts; the web frontend should have masked the negative values. However; in the current code; org.apache.hadoop.mapreduce.v2.app.webapp.dao.* only check whether the elapsed time is -1 or not.,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Wed; 25 Jun 2014 05:30:17 +0000,Mon; 1 Dec 2014 03:09:13 +0000,Fri; 4 Jul 2014 11:22:49 +0000,,,,,YARN-2327,https://issues.apache.org/jira/browse/YARN-2251
MAPREDUCE-5941,Improvement,Major,mrv2,JobCounter's should be organized in groups  for map and reduce ,JobCounters are currently organized counterintuitively.  We duplicate the same logical counter. For example; there is NUM_FAILED_MAPS and NUM_FAILED_REDUCES instead of NUM_FAILED_TASKS in map group and reduce group.   As a consequence the counters are displayed in two lines in the UI instead of filling the map and reduce column in a single Counter table row.,Open,Unresolved,,Unassigned,Gera Shegalov,Wed; 25 Jun 2014 23:52:33 +0000,Wed; 25 Jun 2014 23:52:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5941
MAPREDUCE-5942,Sub-task,Minor,documentation,Remove MRv1 commands from CommandsManual.apt.vm,There're some old commands such as 'hadoop jobtracker' and 'hadoop tasktracker' in CommandsManual.apt.vm. These commands should be removed.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 26 Jun 2014 18:54:52 +0000,Mon; 1 Dec 2014 03:11:30 +0000,Wed; 13 Aug 2014 19:37:06 +0000,,2.2.0,newbie,,HADOOP-10899;MAPREDUCE-5943,https://issues.apache.org/jira/browse/MAPREDUCE-5942
MAPREDUCE-5943,Improvement,Minor,documentation,Separate mapred commands from CommandsManual.apt.vm,Now that MapReduce is just an application running on YARN; so I think it's better to separate mapred commands from CommandsManual.apt.vm and move these commands into MapReduce section.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 26 Jun 2014 19:16:34 +0000,Mon; 1 Dec 2014 03:11:35 +0000,Wed; 13 Aug 2014 19:36:27 +0000,,2.4.0,newbie,,MAPREDUCE-5942;HADOOP-10899,https://issues.apache.org/jira/browse/MAPREDUCE-5943
MAPREDUCE-5944,Improvement,Major,documentation,Clean up MRv1-specific terms from document,JobTracker and TaskTracker are not used in branch-2; however; these words are now documented in many files. These words should be removed; and use MRv2 terms such as ResourceManager; NodeManager; and ApplicationMaster instead.,Open,Unresolved,,Unassigned,Akira Ajisaka,Thu; 26 Jun 2014 21:32:15 +0000,Mon; 19 Jun 2017 04:26:30 +0000,,,2.2.0,,,HADOOP-14540;HADOOP-11615,https://issues.apache.org/jira/browse/MAPREDUCE-5944
MAPREDUCE-5945,Sub-task,Minor,documentation,Update the description of GenericOptionsParser -jt option,Now -jt option is used to specify the address of ResourceManager but document says -jt option specifies JobTracker. The document should be updated.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Thu; 26 Jun 2014 21:40:30 +0000,Mon; 1 Dec 2014 03:11:39 +0000,Fri; 26 Sep 2014 21:27:07 +0000,,2.4.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5945
MAPREDUCE-5946,Improvement,Major,performance;task,Last spill of map task is not necessary for final merge,In map task; merge starts only after the last spill is completely written to disk. This is not necessary nor efficient because the last spill should to be reloaded soon for merge; probably immediately because spills are merged in the order of their sizes and the last spill is likely smallest. OS page cache is not the answer due to its opportunistic nature.  I'm starting to work on this. Please give me your thoughts.,Open,Unresolved,,jaehoon ko,jaehoon ko,Fri; 27 Jun 2014 00:44:54 +0000,Fri; 27 Jun 2014 01:16:11 +0000,,,2.4.0,newbie;performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-5946
MAPREDUCE-5947,Improvement,Major,performance;task,Map phase merge can better utilize memory,Map phase merge reads spills from disk and writes intermediate results back to disk; and so on. I think it is possible to use memory to store intermediate results; thereby reducing disk IO. Because kvbuffer is nullified right before merge; we have at least io.sort.mb amount of heap available. MAPREDUCE-4511 can be considered as an effort to utilize memory better through read ahead; but number of disk IO is unchanged.  Please give me your thoughts. I'd like to take up this issue.,Open,Unresolved,,jaehoon ko,jaehoon ko,Fri; 27 Jun 2014 01:15:13 +0000,Fri; 27 Jun 2014 01:16:37 +0000,,,2.4.0,newbie;performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-5947
MAPREDUCE-5948,Bug,Critical,,org.apache.hadoop.mapred.LineRecordReader does not handle multibyte record delimiters well,Having defined a recorddelimiter of multiple bytes in a new InputFileFormat sometimes has the effect of skipping records from the input.  This happens when the input splits are split off just after a recordseparator. Starting point for the next split would be non zero and skipFirstLine would be true. A seek into the file is done to start - 1 and the text until the first recorddelimiter is ignored (due to the presumption that this record is already handled by the previous maptask). Since the re ord delimiter is multibyte the seek only got the last byte of the delimiter into scope and its not recognized as a full delimiter. So the text is skipped until the next delimiter (ignoring a full record!!),Closed,Fixed,,Akira Ajisaka,Kris Geusebroek,Tue; 13 Aug 2013 12:33:10 +0000,Fri; 6 Jan 2017 00:46:54 +0000,Mon; 22 Jun 2015 22:01:54 +0000,,0.20.2;0.23.9;2.2.0,,,HADOOP-11445;HADOOP-13192;MAPREDUCE-5656;MAPREDUCE-6481,https://issues.apache.org/jira/browse/MAPREDUCE-5948
MAPREDUCE-5949,Bug,Major,,Tasktracker's java threads hunging,I set up hadoop-1.2.1 (from ports) on FreeBSD-10 stable with openjdk version 1.7.0_60.  On the first glance it is doing well except one annoying thing:  after executing some tasks; tasktracker process starts to eat CPU when idle. Sometimes it is 10-20% (numbers from top(1) output); sometimes it is 100-150%.  In tasktrackers's log I see numerious records like this:  2014-06-09 13:08:29;858 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - injecting delay59 times 2014-06-09 13:08:29;859 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - recreating selector 59 times; canceled keys 944 times 2014-06-09 13:09:29;862 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - injecting delay58 times 2014-06-09 13:09:29;862 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - recreating selector 58 times; canceled keys 928 times 2014-06-09 13:10:29;901 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - injecting delay58 times 2014-06-09 13:10:29;901 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - recreating selector 58 times; canceled keys 928 times ...   The more jobs I run; more  process:,Resolved,Duplicate,MAPREDUCE-2386,Unassigned,Dmitry Sivachenko,Sat; 28 Jun 2014 09:02:53 +0000,Sun; 29 Jun 2014 11:44:22 +0000,Sat; 28 Jun 2014 15:25:33 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5949
MAPREDUCE-5950,Bug,Major,documentation,incorrect description in distcp2 document,"In http: distcp2.html#UpdateAndOverwrite  The first statement of the ""Update and Overwrite"" section says:  -update is used to copy files from source that don't exist at the target; or have different contents. -overwrite overwrites target-files even if they exist at the source; or have the same contents.  The ""Command Line Options"" table says :    -overwrite: Overwrite destination   -update: Overwrite if src size different from dst size  Based on the implementation; making the following modification would be more accurate:  The first statement of the ""Update and Overwrite"" section:    The ""Command Line Options"" table:    Thanks.",Closed,Fixed,,Akira Ajisaka,Yongjun Zhang,Sun; 8 Jun 2014 06:53:19 +0000,Mon; 1 Dec 2014 03:08:23 +0000,Thu; 14 Aug 2014 17:11:12 +0000,,1.2.1;2.4.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5950
MAPREDUCE-5951,New Feature,Major,,Add support for the YARN Shared Cache,Implement the necessary changes so that the MapReduce application can leverage the new YARN shared cache (i.e. YARN-1492).  Specifically; allow per-job configuration so that MapReduce jobs can specify which set of resources they would like to cache (i.e. jobjar; libjars; archives; files).,Resolved,Fixed,MAPREDUCE-6113,Chris Trezzo,Chris Trezzo,Mon; 30 Jun 2014 21:12:28 +0000,Thu; 12 Oct 2017 18:42:31 +0000,Thu; 12 Oct 2017 18:35:11 +0000,,,BB2015-05-TBR,,YARN-5727;MAPREDUCE-6824;MAPREDUCE-6365,https://issues.apache.org/jira/browse/MAPREDUCE-5951
MAPREDUCE-5952,Bug,Blocker,mr-am;mrv2,LocalContainerLauncher#renameMapOutputForReduce incorrectly assumes a single dir for mapOutIndex,The  oc comment for renameMapOutputForReduce incorrectly refers to a single map output directory; whereas this depends on LOCAL_DIRS. mapOutIndex should be set to subMapOutputFile.getOutputIndexFile(),Closed,Fixed,,Gera Shegalov,Gera Shegalov,Mon; 30 Jun 2014 23:08:52 +0000,Fri; 15 Aug 2014 05:47:50 +0000,Wed; 16 Jul 2014 21:34:12 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5952
MAPREDUCE-5953,Improvement,Major,,DBInputFormat forces overly aggressive transaction level of SERIALIZABLE ,We are using DBInputFormat in some of our mapreduce jobs and we found issues in production where other applications writing to the database would cause the hadoop job to fail with a deadlock.   On inspection of the code; we found that the transaction isolation level is set to SERIALIZABLE. This seems like it's too aggressive for most hadoop use cases. At the very minimum; this seems like a more relaxed mode should be allowed through configuration.    Reference stack trace (or part of it; I don't have the full map task logs at hand anymore) when this deadlock occurs:,Open,Unresolved,,Unassigned,Alexandre Normand,Tue; 1 Jul 2014 17:37:35 +0000,Tue; 1 Jul 2014 17:37:35 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5953
MAPREDUCE-5954,Improvement,Major,,Optional exclusion of counters from getTaskReports,MRClientService#getTaskReports returns the set of map or reduce tasks along with their counters; which are quite large. For big jobs; the response could be as large as 0.5 GB. This has a negative impact both on MRAppMaster and the monitoring tool that invokes getTaskReports. This problem has led Pig users to entirely disable getTaskReports for big jobs: https: PIG-4043  Many monitoring tools; including ours; do not need the task counters when invoking getTaskReports. Pig also does not make any use of task counters. Here are the usages of Tasks in pig:   and    GetTaskReportsRequest can be augmented with an optional boolean with which the monitoring tool can request excluding the counters form the response. This minor change is very simple and yet makes many existing monitoring tools more efficient.,Patch Available,Unresolved,,Maysam Yabandeh,Maysam Yabandeh,Wed; 2 Jul 2014 00:14:11 +0000,Wed; 6 May 2015 03:35:45 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5954
YARN-2244,Bug,Critical,fairscheduler,FairScheduler missing handling of containers for unknown application attempts ,We are missing changes in patch MAPREDUCE-3596 in FairScheduler. Among other fixes that were common across schedulers; there were some scheduler specific fixes added to handle containers for unknown application attempts. Without these fair scheduler simply logs that an unknown container was found and continues to let it run.,Closed,Fixed,,Anubhav Dhoot,Anubhav Dhoot,Wed; 2 Jul 2014 00:39:06 +0000,Mon; 1 Dec 2014 03:09:27 +0000,Sat; 19 Jul 2014 00:21:45 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-2244
MAPREDUCE-5956,Sub-task,Blocker,applicationmaster;mrv2,MapReduce AM should not use maxAttempts to determine if this is the last retry,Found this while reviewing YARN-2074. The problem is that after YARN-2074; we don't count AM preemption towards AM failures on RM side; but MapReduce AM itself checks the attempt id against the max-attempt count to determine if this is the last attempt.   This causes issues w.r.t deletion of staging directory etc..,Closed,Fixed,,Wangda Tan,Vinod Kumar Vavilapalli,Wed; 2 Jul 2014 02:58:27 +0000,Mon; 1 Dec 2014 03:10:36 +0000,Wed; 3 Sep 2014 20:21:10 +0000,,2.4.0,,,YARN-2074;YARN-2261,https://issues.apache.org/jira/browse/MAPREDUCE-5956
MAPREDUCE-5957,Bug,Major,,AM throws ClassNotFoundException with job classloader enabled if custom output format/committer is used,With the job classloader enabled; the MR AM throws ClassNotFoundException if a custom output format class is specified.,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Wed; 2 Jul 2014 05:08:06 +0000,Mon; 1 Dec 2014 03:09:26 +0000,Mon; 21 Jul 2014 18:23:15 +0000,,2.4.0,,,MAPREDUCE-5813;MAPREDUCE-5751,https://issues.apache.org/jira/browse/MAPREDUCE-5957
MAPREDUCE-5958,Bug,Minor,,Wrong reduce task progress if map output is compressed,"If the map output is compressed (mapreduce.map.output.compress set to true) then the reduce task progress may be highly underestimated.  In the reduce phase (but also in the merge phase); the progress of a reduce task is computed as the ratio between the number of processed bytes and the number of total bytes. But:   	the number of total bytes is computed by summing up the uncompressed segment sizes (Merger.Segment.getRawDataLength())     	the number of processed bytes is computed by exploiting the position of the current IFile.Reader (using IFile.Reader.getPosition()) but this may refer to the position in the underlying on disk file (which may be compressed)    Thus; if the map outputs are compressed then the progress may be underestimated (e.g.; only 1 map output ondisk file; the compressed file is 25% of its original size; then the reduce task progress during the reduce phase will range between 0 and 0.25 and then artificially jump to 1.0).  Attached there is a patch: the number of processed bytes is now computed by exploiting IFile.Reader.bytesRead (if the the reader is in memory; then getPosition() already returns exactly this field).",Closed,Fixed,,Emilio Coppa,Emilio Coppa,Sat; 5 Jul 2014 16:21:07 +0000,Mon; 1 Dec 2014 03:11:04 +0000,Thu; 6 Nov 2014 21:58:12 +0000,,2.2.0;2.3.0;2.2.1;2.4.0;2.4.1,progress;reduce,,MAPREDUCE-5760,https://issues.apache.org/jira/browse/MAPREDUCE-5958
MAPREDUCE-5959,Bug,Major,,java.lang.ClassCastException during terasort,Hello!  I am running bundled TeraSort program (from hadoop-examples.jar). Sometimes I get the following exception:  2014-07-06 19:40:59;344 INFO  main mapreduce.Job (Job. 162),Open,Unresolved,,Unassigned,Dmitry Sivachenko,Sun; 6 Jul 2014 15:45:35 +0000,Mon; 21 Jul 2014 09:46:41 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5959
MAPREDUCE-5960,Bug,Major,client,JobSubmitter's check whether job.jar is local is incorrect with no authority in job jar path.,nan,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Sun; 6 Jul 2014 23:22:54 +0000,Mon; 15 Dec 2014 23:06:08 +0000,Thu; 6 Nov 2014 15:18:43 +0000,,2.4.0;2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5960
MAPREDUCE-5961,Bug,Minor,jobhistoryserver,"Job start time setting to ""Thu Jan 01 05:29:59 IST 1970""","Induce RM switchover while job is in progress  Observe that  job start time setting to ""Thu Jan 01 05:29:59 IST 1970"" saying below error     AM LOG",Resolved,Duplicate,MAPREDUCE-5939,Unassigned,Nishan Shetty,Mon; 7 Jul 2014 09:54:59 +0000,Mon; 7 Jul 2014 15:21:47 +0000,Mon; 7 Jul 2014 15:21:47 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5961
MAPREDUCE-5962,Improvement,Major,performance;task,Support CRC32C in IFile,Currently; the IFile format used by the MR shuffle checksums all data using the zlib CRC32 polynomial. If we allow use of CRC32C instead; we can get a large reduction in CPU usage by leveraging the native hardware CRC32C implementation (approx half a second of CPU time savings per GB checksummed).,Open,Unresolved,,Todd Lipcon,Todd Lipcon,Mon; 7 Jul 2014 16:56:47 +0000,Sat; 7 Jan 2017 02:00:02 +0000,,,2.5.0,,,HADOOP-10859;MAPREDUCE-2841;HDFS-3528,https://issues.apache.org/jira/browse/MAPREDUCE-5962
MAPREDUCE-5963,Sub-task,Major,,ShuffleHandler DB schema should be versioned with compatible/incompatible changes,ShuffleHandler persist job shuffle info into DB schema; which should be versioned with compatible incompatible changes to support rolling upgrade.,Closed,Fixed,,Junping Du,Junping Du,Wed; 9 Jul 2014 02:58:38 +0000,Mon; 1 Dec 2014 03:10:44 +0000,Tue; 22 Jul 2014 19:38:26 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5963
YARN-2266,Improvement,Major,resourcemanager,Add an application timeout service in RM to kill applications which are not getting resources,Currently ; If an application is submitted to RM; the app keeps waiting until the resources are allocated for AM. Such an application may be stuck till a resource is allocated for AM; and this may be due to over utilization of Queue or User limits etc. In a production cluster; some periodic running applications may have lesser cluster share. So after waiting for some time; if resources are not available; such applications can be made as failed.,Open,Unresolved,,Unassigned,Ashutosh Jindal,Wed; 9 Jul 2014 12:18:30 +0000,Fri; 12 Feb 2016 03:56:34 +0000,,,,,,YARN-3813,https://issues.apache.org/jira/browse/YARN-2266
MAPREDUCE-5965,Bug,Major,,"Hadoop streaming throws error if list of input files is high. Error is: ""error=7; Argument list too long at if number of input file is high""","Hadoop streaming exposes all the key values in job conf as environment variables when it forks a process for streaming code to run. Unfortunately the variable mapreduce_input_fileinputformat_inputdir contains the list of input files; and Linux has a limit on size of environment variables + arguments. Based on how long the list of files and their full path is this could be pretty huge. And given all of these variables are not even used it stops user from running hadoop job with large number of files; even though it could be run.  Linux throws E2BIG if the size is greater than certain size which is error code 7. And  translates that to ""error=7; Argument list too long"". More: http: execve.2.html I suggest skipping variables if it is greater than certain length. That way if user code requires the environment variable it would fail. It should also introduce a config variable to skip long variables; and set it to false by default. That way user has to specifically set it to true to invoke this feature.  Here is the exception:    Hive does a similar trick: HIVE-2372 I have a patch for this; will soon submit a patch.",Resolved,Fixed,,Wilfred Spiegelenburg,Arup Malakar,Thu; 10 Jul 2014 00:08:35 +0000,Tue; 30 Aug 2016 01:19:55 +0000,Thu; 4 Jun 2015 01:46:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5965
MAPREDUCE-5966,Bug,Major,scheduler,MR1 FairScheduler use of custom weight adjuster is not thread safe for comparisons,When comparing JobSchedulables one of the factors is the weight. If someone uses a custom weight adjuster; that may be called multiple times during a sort causing different values to return. That causes a failure in sorting because the weight may change during the sort.  This reproes as,Resolved,Fixed,,Anubhav Dhoot,Anubhav Dhoot,Fri; 11 Jul 2014 00:22:01 +0000,Sat; 26 Jul 2014 19:58:59 +0000,Sat; 26 Jul 2014 19:54:41 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5966
MAPREDUCE-5967,Test,Minor,,TestRecovery fails in trunk,From https: console :,Resolved,Cannot Reproduce,,Unassigned,Ted Yu,Fri; 11 Jul 2014 13:51:53 +0000,Sat; 7 Mar 2015 23:14:39 +0000,Sat; 7 Mar 2015 23:14:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5967
MAPREDUCE-5968,Bug,Major,mrv1,Work directory is not deleted when downloadCacheObject throws IOException,Work directory is not deleted in  DistCache if Exception happen in downloadCacheObject. In downloadCacheObject; the cache file will be copied to temporarily work directory first; then the  work directory will be renamed to the final directory. If IOException happens during the copy; the  work directory will not be deleted. This will cause garbage data left in local disk cache. For example If the MR application use Distributed Cache to send a very large Archive file(50G); if the disk is full during the copy; then the IOException will be triggered; the work directory will be not deleted or renamed and the work directory will occupy a big chunk of disk space.,Resolved,Fixed,,zhihai xu,zhihai xu,Fri; 11 Jul 2014 20:02:04 +0000,Tue; 5 Aug 2014 06:35:08 +0000,Tue; 5 Aug 2014 06:35:08 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5968
MAPREDUCE-5969,Bug,Major,mrv1,Private non-Archive Files' size add twice in Distributed Cache directory size calculation.,"Private non-Archive Files' size add twice in Distributed Cache directory size calculation. Private non-Archive Files list is passed in by ""-files"" command line option. The Distributed Cache directory size is used to check whether the total cache files size exceed the cache size limitation;  the default cache size limitation is 10G. I add log in addCacheInfoUpdate and setSize in TrackerDistributedCacheManager. file size is 2395 byes and wordcount.jar file size is 3865 bytes. The total should be 6260. The log show these files size added twice: add one time before download to local node and add second time after download to local node; so total file number becomes 4 instead of 2: addCacheInfoUpdate size: 6260 num: 2 baseDir:  local In the code; for Private non-Archive File; the first time we add file size is at  getLocalCache:   The second time we add file size is at  setSize:   The fix is not to add the file size for for Private non-Archive File after download(downloadCacheObject).",Patch Available,Unresolved,,zhihai xu,zhihai xu,Tue; 15 Jul 2014 02:06:58 +0000,Wed; 6 May 2015 03:34:01 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-5969
MAPREDUCE-5970,Improvement,Minor,applicationmaster;client,Provide a boolean switch to enable MR-AM profiling,MR task profiling can be enabled with a simple switch mapreduce.task.profile=true. We can analogously have yarn.app.mapreduce.am.profile for MR-AM,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Wed; 16 Jul 2014 03:23:32 +0000,Mon; 1 Dec 2014 03:10:00 +0000,Wed; 15 Oct 2014 17:57:59 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5970
MAPREDUCE-5971,Improvement,Trivial,distcp,Move the default options for distcp -p to DistCpOptionSwitch,The default preserve flags for distcp -p are embedded in the OptionsParser code. Refactor to co-locate them with the actual flag initialization.,Closed,Fixed,,Charles Lamb,Charles Lamb,Wed; 16 Jul 2014 16:09:12 +0000,Tue; 10 Mar 2015 04:30:26 +0000,Wed; 16 Jul 2014 23:43:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5971
MAPREDUCE-5972,Bug,Trivial,,Fix typo 'programatically' in job.xml (and a few other places),In job.xml; there's a typo 'programatically' as the below if a property is set through program.   should be 'programmatically'.,Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Wed; 16 Jul 2014 19:00:12 +0000,Thu; 12 May 2016 18:23:19 +0000,Mon; 8 Sep 2014 20:16:58 +0000,,2.2.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5972
MAPREDUCE-5973,Test,Major,,TestAMWebServices* fails intermittently,The tests can fail because of bind exception.,Resolved,Duplicate,YARN-2304,Unassigned,Tsuyoshi Ozawa,Thu; 17 Jul 2014 05:58:02 +0000,Mon; 21 Jul 2014 15:27:57 +0000,Mon; 21 Jul 2014 15:25:20 +0000,,,,,YARN-2316;YARN-2304,https://issues.apache.org/jira/browse/MAPREDUCE-5973
MAPREDUCE-5974,Sub-task,Major,task,Allow specifying multiple MapOutputCollectors with fallback,Currently we only allow specifying a single MapOutputCollector implementation class in a job. It would be nice to allow a comma-separated list of classes: we should try each collector implementation in the user-specified order until we find one that can be successfully instantiated and initted.  This is useful for cases where a particular optimized collector implementation cannot operate on all key value types; or requires native code. The cluster administrator can configure the cluster to try to use the optimized collector and fall back to the default collector.,Closed,Fixed,,Todd Lipcon,Todd Lipcon,Thu; 17 Jul 2014 16:15:26 +0000,Sun; 14 Dec 2014 04:22:30 +0000,Thu; 21 Aug 2014 17:40:38 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5974
MAPREDUCE-5975,Sub-task,Blocker,task,Fix native-task build on Ubuntu 13.10,I'm having some issues building the native-task branch on my Ubuntu 13.10 box. This JIRA is to figure out and fix whatever's going on.,Resolved,Duplicate,MAPREDUCE-5985,Todd Lipcon,Todd Lipcon,Thu; 17 Jul 2014 17:47:46 +0000,Tue; 22 Jul 2014 20:09:03 +0000,Tue; 22 Jul 2014 20:09:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5975
MAPREDUCE-5976,Sub-task,Major,task,native-task should not fail to build if snappy is missing,Other native parts of Hadoop will automatically disable snappy support if snappy is not present and -Drequire.snappy is not passed. native-task should do the same. (right now; it fails to build if snappy is missing),Resolved,Fixed,,Sean Zhong,Todd Lipcon,Thu; 17 Jul 2014 17:49:27 +0000,Sat; 13 Sep 2014 14:05:24 +0000,Wed; 6 Aug 2014 07:34:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5976
MAPREDUCE-5977,Sub-task,Major,task,Fix or suppress native-task gcc warnings,Currently; building the native task code on gcc 4.8 has a fair number of warnings. We should fix or suppress them so that new warnings are easier to see.,Resolved,Fixed,,Manu Zhang,Todd Lipcon,Thu; 17 Jul 2014 18:00:43 +0000,Sat; 13 Sep 2014 14:05:24 +0000,Wed; 27 Aug 2014 19:29:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5977
MAPREDUCE-5978,Sub-task,Major,task,native-task CompressTest failure on Ubuntu,The MR-2841 branch fails the following unit tests on my box:   CompressTest.testBzip2Compress:84 file compare result: if they are the same ;then return true expected:true but was:false   CompressTest.testDefaultCompress:116 file compare result: if they are the same ;then return true expected:true but was:false  We need to fix these before merging.,Resolved,Fixed,,Manu Zhang,Todd Lipcon,Thu; 17 Jul 2014 21:20:02 +0000,Sat; 13 Sep 2014 14:05:24 +0000,Wed; 6 Aug 2014 07:41:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5978
MAPREDUCE-5979,Bug,Major,scheduler,FairScheduler: zero weight can cause sort failures,When the weight is set to zero (which is possible with a custom weight adjuster) we can get failures in comparing schedulables. This is because when calculating running tasks to weight ratio could result in a 0.0 0.0 which ends up as NaN. Comparisons with NaN are undefined such that (int)Math.signum(NaN - anyNumber) will be 0 causing different criteria to be used in comparison which may not be consistent. This will result in  IllegalArgumentException: Comparison method violates its general contract!,Resolved,Fixed,,Anubhav Dhoot,Anubhav Dhoot,Thu; 17 Jul 2014 23:09:58 +0000,Tue; 22 Jul 2014 23:04:47 +0000,Tue; 22 Jul 2014 23:04:47 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5979
MAPREDUCE-5980,Bug,Minor,,filter empty string in the libjars when submitting jobs,-libjars is used to upload jars into hdfs when submitting jobs. If there is empty string between two comma; the copying processing will try to copy all the subdirs files under current directory. I believe it is not user's expected behavior.,Resolved,Duplicate,HADOOP-10820 ,Bing Jiang,Bing Jiang,Fri; 18 Jul 2014 08:39:30 +0000,Mon; 21 Jul 2014 06:19:49 +0000,Mon; 21 Jul 2014 06:19:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5980
MAPREDUCE-5981,Improvement,Major,,Log levels of certain MR logs can be changed to DEBUG,"Following map reduce logs can be changed to DEBUG log level as they appear too many times in the log file and are not that important for debugging.  1. In org.apache.hadoop.mapreduce.task.reduce.Fetcher#copyFromHost(Fetcher. : 411); below log can be changed to DEBUG  LOG.info(""assigned "" + includedMaps + "" of "" + totalSize + "" to "" +              host + "" to "" + Thread.currentThread().getName());",Resolved,Fixed,,Varun Saxena,Varun Saxena,Fri; 18 Jul 2014 12:20:41 +0000,Tue; 30 Aug 2016 01:19:54 +0000,Fri; 8 May 2015 16:03:09 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5981
MAPREDUCE-5982,Bug,Major,mr-am,Task attempts that fail from the ASSIGNED state can disappear,If a task tempt never existed; but the AM logs show otherwise.,Closed,Fixed,MAPREDUCE-4758,Chang Li,Jason Lowe,Fri; 18 Jul 2014 16:14:13 +0000,Fri; 6 Jan 2017 07:30:52 +0000,Thu; 17 Sep 2015 21:40:59 +0000,,0.23.10;2.2.1;2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5982
MAPREDUCE-5983,Bug,Minor,test,TestCommandLineJobSubmission assumes there is a /tmp dir that can be used for temp data,"the test case in TestCommandLineJobSubmission assumes that it can create stuff in  tmp""));  as well as being unix only; the result is a test case that doesnt work if 1 person is running the test on the same cluster. it should really be driven off the  io.tmpDir property",Open,Unresolved,,Zhang Kun,Steve Loughran,Mon; 7 Jul 2008 13:22:05 +0000,Mon; 14 Sep 2015 09:43:26 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5983
MAPREDUCE-5984,Sub-task,Minor,task,native-task: reuse lz4 sources in hadoop-common,nan,Resolved,Fixed,,Binglin Chang,Binglin Chang,Mon; 21 Jul 2014 04:04:51 +0000,Sat; 13 Sep 2014 14:05:21 +0000,Wed; 6 Aug 2014 06:08:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5984
MAPREDUCE-5985,Sub-task,Minor,task,native-task: Fix build on macosx,nan,Resolved,Fixed,,Binglin Chang,Binglin Chang,Mon; 21 Jul 2014 06:41:15 +0000,Sat; 13 Sep 2014 14:05:21 +0000,Tue; 22 Jul 2014 19:55:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5985
MAPREDUCE-5986,Bug,Major,,make TestMRJobsWithProfiler faster,TestMRJobsWithProfiler occasionally timesout.  MAPREDUCE-5804 submitted a patch that increased the timeout. The test seemed to pass for a while but now it again started timing out occasionally.,Open,Unresolved,,Unassigned,Mit Desai,Mon; 21 Jul 2014 22:18:40 +0000,Mon; 21 Jul 2014 22:18:40 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5986
MAPREDUCE-5987,Sub-task,Minor,task,native-task: Unit test TestGlibCBug fails on ubuntu,On  ubuntu12; glibc: 2.15-0ubuntu10.3; UT TestGlibCBug fails  [ RUN      ] IFile.TestGlibCBug   INFO TestGlibCBug . TestIFile.cc:186: Failure Value of: realKey   Actual: 1127504685 Expected: expectindex Which is: 4102672832 [  FAILED  ] IFile.TestGlibCBug (0 ms) ---------- 2 tests from IFile (240 ms total),Resolved,Cannot Reproduce,,Sean Zhong,Sean Zhong,Tue; 22 Jul 2014 03:21:26 +0000,Mon; 11 Aug 2014 02:13:44 +0000,Mon; 11 Aug 2014 02:13:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5987
MAPREDUCE-5988,Bug,Minor,documentation,Fix dead links to the javadocs in mapreduce project,In http: allclasses-frame.html; some classes are listed; but not documented.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Tue; 22 Jul 2014 08:28:39 +0000,Fri; 10 Apr 2015 20:19:41 +0000,Thu; 5 Feb 2015 01:48:10 +0000,,2.4.1,,,HADOOP-10873,https://issues.apache.org/jira/browse/MAPREDUCE-5988
MAPREDUCE-5989,Improvement,Major,applicationmaster,Add DeletionService in AM,In AM; for graceful cleanup; I propose addition of a DeletionService which will do the following : 1. Cleanup of failed tasks (temporary data need not occupy space till NM's Deletion Service is invoked) 2. Staging directory deletion (During AM shutdown; its better to place staging dir cleanup in Deletion Service: Refer to MAPREDUCE-4841 ),Resolved,Not A Problem,,Varun Saxena,Varun Saxena,Tue; 22 Jul 2014 12:27:53 +0000,Fri; 21 Nov 2014 09:09:53 +0000,Fri; 21 Nov 2014 09:09:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5989
MAPREDUCE-5990,Improvement,Major,examples,If output directory can not be created; error message on stdout does not provide any clue.,In the following wordcount example output directory path can not be created because  temp does not exists and user has not privileges to create output path  org.apache.hadoop.mapred.JobShell.main(JobShell. 68),Open,Unresolved,,Unassigned,Suhas Gogate,Tue; 28 Apr 2009 23:30:16 +0000,Mon; 11 Apr 2016 14:54:35 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-5990
MAPREDUCE-5991,Sub-task,Major,task,native-task should not run unit tests if native profile is not enabled,"Currently; running ""mvn test"" without the 'native' profile enabled causes all of the native-task tests to fail. In order to integrate to trunk; we need to fix this - either using JUnit ""Assume"" commands in each test that depends on native code; or disabling the tests from the pom unless -Pnative is specified",Resolved,Fixed,,Binglin Chang,Todd Lipcon,Tue; 22 Jul 2014 20:16:00 +0000,Sat; 13 Sep 2014 14:05:17 +0000,Thu; 24 Jul 2014 11:46:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5991
MAPREDUCE-5992,Sub-task,Major,task,native-task test logs should not write to console,Most of our unit tests are configured with a log4j.properties test resource so they don't spout a bunch of output to the console. We need to do the same for native-task.,Open,Unresolved,,Unassigned,Todd Lipcon,Tue; 22 Jul 2014 20:17:22 +0000,Wed; 3 Sep 2014 02:29:20 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5992
MAPREDUCE-5993,Sub-task,Major,task,native-task: simplify/remove dead code,The native task code has a bunch of code in it which isn't related to the map output collector. I suspect much if this is dead code. Let's remove it before we merge; so that the amount of code we have to maintain going forward is more limited.,Resolved,Duplicate,MAPREDUCE-6000,Unassigned,Todd Lipcon,Tue; 22 Jul 2014 20:23:43 +0000,Wed; 3 Sep 2014 03:18:03 +0000,Wed; 3 Sep 2014 03:18:03 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5993
MAPREDUCE-5994,Sub-task,Major,task,native-task: TestBytesUtil fails,This class appears to have some bugs. Two tests fail consistently on my system. BytesUtil itself appears to duplicate a lot of code from guava - we should probably just use the Guava functions.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Tue; 22 Jul 2014 20:58:41 +0000,Sat; 13 Sep 2014 14:05:21 +0000,Thu; 24 Jul 2014 06:14:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5994
MAPREDUCE-5995,Sub-task,Minor,task,native-task: revert changes which expose Text internals,The current branch has some changes to the Text writable which allow it to manually set the backing array; capacity; etc. Rather than exposing these internals; we should use the newly-committed facility from HADOOP-10855 to implement this.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 23 Jul 2014 01:01:35 +0000,Sat; 13 Sep 2014 14:05:18 +0000,Sun; 27 Jul 2014 19:15:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5995
MAPREDUCE-5996,Sub-task,Major,task,native-task: Rename system tests into standard directory layout,Currently there are a number of tests in src  system. This confuses IDEs which think that the package should then be system.org.apache.hadoop instead of just org.apache.hadoop.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 23 Jul 2014 01:09:47 +0000,Sat; 13 Sep 2014 14:05:18 +0000,Thu; 24 Jul 2014 06:17:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5996
MAPREDUCE-5997,Sub-task,Minor,task,native-task: Use DirectBufferPool from Hadoop Common,The native task code has its own direct buffer pool; but Hadoop already has an implementation. HADOOP-10882 will move that implementation into Common; and this JIRA is to remove the duplicate code and use that one instead.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 23 Jul 2014 01:34:37 +0000,Sat; 13 Sep 2014 14:05:18 +0000,Thu; 24 Jul 2014 08:20:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-5997
MAPREDUCE-5998,Bug,Minor,documentation,CompositeInputFormat javadoc is broken,In CompositeInputFormat  oc; some part of the description is converted to hyperlink by @see tag.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Wed; 23 Jul 2014 02:01:42 +0000,Mon; 1 Dec 2014 03:08:22 +0000,Thu; 14 Aug 2014 17:19:49 +0000,,2.0.2-alpha,newbie,,HADOOP-10873,https://issues.apache.org/jira/browse/MAPREDUCE-5998
MAPREDUCE-5999,Bug,Minor,documentation,Fix dead link in InputFormat javadoc,In InputFormat  oc; there is a dead link 'mapreduce.input.fileinputformat.split.minsize'.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Wed; 23 Jul 2014 09:12:29 +0000,Mon; 1 Dec 2014 03:11:56 +0000,Thu; 14 Aug 2014 17:56:48 +0000,,2.0.2-alpha,newbie,,HADOOP-10873,https://issues.apache.org/jira/browse/MAPREDUCE-5999
MAPREDUCE-6000,Sub-task,Minor,task,native-task: Simplify ByteBufferDataReader/Writer,"The ByteBufferDataReader and ByteBufferDataWriter class are more complex than necessary:  	several methods related to reading from the native code; it seems unlikely people will want to use these methods in any performance-critical space. So; let's do simpler implementations that are less likely to be buggy; even if they're slightly less performant. 	methods like readLine() are even less likely to be used. Since it's a complex implementation; let's just throw UnsupportedOperationException 	in the test case; we can use Mockito to shorten the amount of new code",Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 23 Jul 2014 18:29:23 +0000,Sat; 13 Sep 2014 14:05:27 +0000,Thu; 24 Jul 2014 08:24:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6000
MAPREDUCE-6001,Improvement,Minor,,Add a 'status' command to mr-jobhistory-daemon.sh script,Adding a 'status' command to mr-jobhistory-daemon.sh will be useful for finding out the status of the jobhistory daemon.  Running the 'status' command should exit with a 0 exit code if the jobhistory daemon is running and non-zero code in case its not.,Open,Unresolved,,Nikunj Bansal,Nikunj Bansal,Wed; 23 Jul 2014 21:38:06 +0000,Sat; 7 Jan 2017 01:59:54 +0000,,,2.2.0;2.3.0;2.2.1;2.4.0;2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6001
MAPREDUCE-6002,Bug,Major,task,MR task should prevent report error to AM when process is shutting down,With MAPREDUCE-5900; preempted MR task should not be treat as failed.  But it is still possible a MR task fail and report to AM when preemption take effect and the AM hasn't received completed container from RM yet. It will cause the task attempt marked failed instead of preempted.  An example is FileSystem has shutdown hook; it will close all FileSystem instance; if at the same time; the FileSystem is in-use (like reading split details from HDFS); MR task will fail and report the fatal error to MR AM. An exception will be raised:    We should prevent this; because it is possible other exceptions happen when shutting down; we shouldn't report any of such exceptions to AM.,Closed,Fixed,,Wangda Tan,Wangda Tan,Thu; 24 Jul 2014 02:49:25 +0000,Thu; 6 Oct 2016 13:58:32 +0000,Sun; 27 Jul 2014 01:45:15 +0000,,2.5.0,,,TEZ-3462,https://issues.apache.org/jira/browse/MAPREDUCE-6002
MAPREDUCE-6003,Bug,Major,jobtracker,Resource Estimator suggests huge map output in some cases,In some cases; ResourceEstimator can return way too large map output estimation. This happens when input size is not correctly calculated.  A typical case is when joining two Hive tables (one in HDFS and the other in HBase). The maps that process the HBase table finish first; which has a 0 length of inputs due to its TableInputFormat. Then for a map that processes HDFS table; the estimated output size is very large because of the wrong input size; causing the map task not possible to be assigned.  There are two possible solutions to this problem: (1) Make input size correct for each case; e.g. HBase; etc. (2) Use another algorithm to estimate the map output; or at least make it closer to reality.  I prefer the second way; since the first would require all possibilities to be taken care of. It is not easy for some inputs such as URIs.  In my opinion; we could make a second estimation which is independent of the input size: estimationB = (completedMapOutputSize   completedMapInputSize  My suggestion is to take minimum of the two estimations: estimation = min(estimationA; estimationB),Patch Available,Unresolved,,Chengbing Liu,Chengbing Liu,Thu; 24 Jul 2014 13:30:42 +0000,Wed; 6 May 2015 03:35:08 +0000,,,1.2.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6003
MAPREDUCE-6004,Sub-task,Major,task,native-task should not fail to build if zlib is missing,zlib is required by Gzip. We need to check for its existence in build and exclude Gzip related codes when zlib is missing. similar to MAPREDUCE-5976,Resolved,Not A Problem,,Unassigned,Manu Zhang,Fri; 25 Jul 2014 02:14:09 +0000,Tue; 5 Aug 2014 03:37:17 +0000,Tue; 5 Aug 2014 03:37:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6004
MAPREDUCE-6005,Sub-task,Major,task,native-task: fix some valgrind errors ,Running test with valgrind shows there are some bugs; this jira try to fix them.,Resolved,Fixed,,Binglin Chang,Binglin Chang,Fri; 25 Jul 2014 03:53:01 +0000,Sat; 13 Sep 2014 14:05:24 +0000,Mon; 4 Aug 2014 06:20:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6005
MAPREDUCE-6006,Sub-task,Minor,task,native-task: add native tests to maven and fix bug in pom.xml,nan,Resolved,Fixed,,Binglin Chang,Binglin Chang,Fri; 25 Jul 2014 08:09:41 +0000,Sat; 13 Sep 2014 14:05:24 +0000,Thu; 14 Aug 2014 04:47:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6006
MAPREDUCE-6007,New Feature,Major,distcp,Add support to distcp to preserve raw.* namespace extended attributes,As part of the Data at Rest Encryption work (HDFS-6134); we need to add support to distcp which preserves raw.* namespace extended attributes when both the src and target pathnames are in the  raw directory hierarchy. See the doc in HDFS-6509 for details.,Closed,Fixed,,Charles Lamb,Charles Lamb,Fri; 25 Jul 2014 16:04:12 +0000,Tue; 30 Jun 2015 07:19:00 +0000,Fri; 8 Aug 2014 01:33:26 +0000,,fs-encryption,,,HDFS-6509;HDFS-6134;HADOOP-10919,https://issues.apache.org/jira/browse/MAPREDUCE-6007
MAPREDUCE-6008,Sub-task,Major,distcp,Update distcp docs to include new option that suppresses preservation of RAW.* namespace extended attributes,Update the docs to include this new option.,Resolved,Not A Problem,,Charles Lamb,Charles Lamb,Fri; 25 Jul 2014 16:22:17 +0000,Fri; 8 Aug 2014 17:50:02 +0000,Fri; 8 Aug 2014 17:50:02 +0000,,fs-encryption,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6008
MAPREDUCE-6009,Bug,Blocker,client;job submission,Map-only job with new-api runs wrong OutputCommitter when cleanup scheduled in a reduce slot,In branch 1 job commit is executed in a JOB_CLEANUP task that may run in either map or reduce slot  in org.apache.hadoop.mapreduce.Job#setUseNewAPI there is a logic setting new-api flag only for reduce-ful jobs.   Therefore; when cleanup runs in a reduce slot; ReduceTask inits using the old API and runs incorrect default OutputCommitter; instead of consulting OutputFormat.,Resolved,Fixed,,Gera Shegalov,Gera Shegalov,Mon; 28 Jul 2014 06:58:35 +0000,Thu; 23 Jul 2015 07:42:30 +0000,Tue; 21 Oct 2014 15:20:48 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6009
MAPREDUCE-6010,Bug,Major,jobhistoryserver,HistoryServerFileSystemStateStore fails to update tokens,When token recovery is enabled and the file system state store is being used then tokens fail to be updated due to a rename destination conflict.,Closed,Fixed,,Jason Lowe,Jason Lowe,Mon; 28 Jul 2014 15:49:12 +0000,Mon; 1 Dec 2014 03:07:33 +0000,Thu; 14 Aug 2014 16:09:58 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6010
MAPREDUCE-6011,Improvement,Major,jobhistoryserver,Improve history server behavior during a recovery error,Currently when the history server encounters an error during recovery it is fatal without specific details on the error (e.g. which token was involved during the recovery error).  We should either allow the history server to proceed past recovery errors or provide more specifics on the offending token involved in the fatal error to aid in manual recovery.,Open,Unresolved,,Unassigned,Jason Lowe,Mon; 28 Jul 2014 16:00:05 +0000,Mon; 28 Jul 2014 18:04:53 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6011
MAPREDUCE-6012,Bug,Major,,DBInputSplit creates invalid ranges on Oracle,"The DBInputFormat on Oracle does not create valid ranges.  The method getSplit line 263 is as follows:            split = new DBInputSplit(i * chunkSize; (i * chunkSize) + chunkSize);  So the first split will have a start value of 0 (0*chunkSize).  However; the OracleDBRecordReader; line 84 is as follows:        if (split.getLength()  0 &amp; split.getStart()  0){  Since the start value of the first range is equal to 0; we will skip the block that partitions the input set. As a result; one of the map task will process the entire data set; rather than the partition.  I'm assuming the fix is trivial and would involve removing the second check in the if block.  Also; I believe the OracleDBRecordReader paging query is incorrect.  Line 92 should read:    query.append("" ) WHERE dbif_rno  "").append(split.getStart());  instead of (note  instead of =)    query.append("" ) WHERE dbif_rno = "").append(split.getStart());  Otherwise some rows will be ignored and some counted more than once.  A map reduce job that counts the number of rows based on a predicate will highlight the incorrect behavior.",Closed,Fixed,,Wei Yan,Julien Serdaru,Wed; 1 May 2013 01:23:00 +0000,Mon; 1 Dec 2014 03:09:10 +0000,Mon; 18 Aug 2014 18:45:48 +0000,,1.2.1;2.4.1,,,HADOOP-8331,https://issues.apache.org/jira/browse/MAPREDUCE-6012
MAPREDUCE-6013,Improvement,Major,scripts,mapred version is missing,'mapred version' is missing.,Resolved,Fixed,,Akira Ajisaka,Allen Wittenauer,Wed; 30 Jul 2014 00:29:49 +0000,Thu; 12 May 2016 18:24:43 +0000,Wed; 20 Aug 2014 18:47:36 +0000,,,scripts,,HADOOP-11010,https://issues.apache.org/jira/browse/MAPREDUCE-6013
MAPREDUCE-6014,Bug,Major,,New task status field in task attempts table can lead to an empty web page ,MAPREDUCE-5550 added a new task attempts field but didn't Javascript-escape the contents.  Tasks with status messages that have newlines or other characters can then break the parsing of the web page and leave the user with a blank page.,Closed,Fixed,,Mit Desai,Mit Desai,Wed; 30 Jul 2014 23:06:25 +0000,Mon; 1 Dec 2014 03:08:50 +0000,Tue; 5 Aug 2014 22:00:50 +0000,,2.5.0,,,MAPREDUCE-5550,https://issues.apache.org/jira/browse/MAPREDUCE-6014
MAPREDUCE-6015,Improvement,Major,applicationmaster,Make MR ApplicationMaster disable loading user's jars firstly ,In most cases; we want to use -Dmapreduce.user.classpath.first=true to pick user's jars ahead of hadoop system's jars; which can make tasks run based upon the customized environment under the circumstance that hadoop system default library contains the different version of dependent jars.  However; using -Dmapreduce.user.classpath.first=true will cause ApplicationMaster failure to launch due to conflicting classes.  In most cases; if users do not customize the ApplicationMaster for MapReduce framework; I believe we can treat MRAppMaster different with MapTask ReduceTask at the point of loading user's jar in classloader.   I believe it can provide  a property of  '-Dmapreduce.am.user.classpath.first=false'  to disable the feature of loading user's jars firstly.,Open,Unresolved,,Unassigned,Bing Jiang,Thu; 31 Jul 2014 03:21:21 +0000,Mon; 4 Aug 2014 10:40:01 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6015
MAPREDUCE-6016,Bug,Minor,mrv2,hadoop yarn mapreduce skip failed records doesn't work,"I am trying to use ""skip failed records"" map-reduce functionality during the map phase. I created special testing file with 8 corrupted records. I am using TextInputFormat and during the processing (of the record) map function fails with unhandled exception (parsing the record into expected structure). Job is using the old mapred api.  My job settings for enabling ""skip failed records feature"":      property         namemapred.skip.mode.enabled reduce funciton",Resolved,Duplicate,MAPREDUCE-6017,Unassigned,Jakub Stransky,Thu; 31 Jul 2014 10:16:09 +0000,Thu; 31 Jul 2014 10:23:29 +0000,Thu; 31 Jul 2014 10:23:29 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6016
MAPREDUCE-6017,Bug,Minor,mrv2,hadoop yarn mapreduce skip failed records doesn't work,"I am trying to use ""skip failed records"" map-reduce functionality during the map phase. I created special testing file with 8 corrupted records. I am using TextInputFormat and during the processing (of the record) map function fails with unhandled exception (parsing the record into expected structure). Job is using the old mapred api.  My job settings for enabling ""skip failed records feature"":      property         namemapred.skip.mode.enabled reduce funciton",Open,Unresolved,,Unassigned,Jakub Stransky,Thu; 31 Jul 2014 10:16:24 +0000,Thu; 31 Jul 2014 10:16:24 +0000,,,2.2.0,features,,,https://issues.apache.org/jira/browse/MAPREDUCE-6017
MAPREDUCE-6018,Sub-task,Major,,Create a framework specific config to enable timeline server,nan,Closed,Fixed,,Robert Kanter,Jonathan Eagles,Thu; 31 Jul 2014 18:24:59 +0000,Mon; 1 Dec 2014 03:11:05 +0000,Tue; 28 Oct 2014 04:10:48 +0000,,,,,YARN-2375,https://issues.apache.org/jira/browse/MAPREDUCE-6018
MAPREDUCE-6019,Bug,Major,,MapReduce changes for exposing YARN/MR endpoints on multiple interfaces.,nan,Closed,Fixed,,Craig Welch,Xuan Gong,Thu; 31 Jul 2014 19:56:24 +0000,Mon; 1 Dec 2014 03:07:42 +0000,Thu; 31 Jul 2014 21:30:48 +0000,,2.6.0,,,YARN-1994,https://issues.apache.org/jira/browse/MAPREDUCE-6019
MAPREDUCE-6020,Improvement,Major,,Too many threads blocking on the global JobTracker lock from getJobCounters; optimize getJobCounters to release global JobTracker lock before access the per job counter in JobInProgress,Too many threads blocking on the global JobTracker lock from getJobCounters; optimize getJobCounters to release global JobTracker lock before access the per job counter in JobInProgress. It may be a lot of JobClients to call getJobCounters in JobTracker at the same time; Current code will lock the JobTracker to block all the threads to get counter from JobInProgress. It is better to unlock the JobTracker when get counter from JobInProgress(job.getCounters(counters)). So all the theads can run parallel when access its own job counter.,Patch Available,Unresolved,,zhihai xu,zhihai xu,Thu; 31 Jul 2014 22:37:48 +0000,Fri; 8 May 2015 07:23:54 +0000,,,0.23.10,BB2015-05-TBR,,YARN-2376,https://issues.apache.org/jira/browse/MAPREDUCE-6020
MAPREDUCE-6021,Bug,Major,mr-am,MR AM should have working directory in LD_LIBRARY_PATH,Tasks implicitly pick up shared libraries added to the job because the task launch context explicitly adds the container working directory to LD_LIBRARY_PATH.  However the same is not done for the AM container which is inconsistent.  User code can run in the AM via output committer; speculator; uber job; etc.; so the AM's LD_LIBRARY_PATH should have the container work directory for consistency with tasks.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 1 Aug 2014 15:10:17 +0000,Thu; 24 Dec 2015 01:09:13 +0000,Thu; 7 Aug 2014 20:30:21 +0000,,2.4.1,,,MAPREDUCE-6588;MAPREDUCE-5799,https://issues.apache.org/jira/browse/MAPREDUCE-6021
MAPREDUCE-6022,Bug,Major,,map_input_file is missing from streaming job environment,When running a streaming job the 'map_input_file' environment variable is not being set.  This property is deprecated; but in the past deprecated properties still appeared in a stream job's environment.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 1 Aug 2014 19:26:10 +0000,Mon; 1 Dec 2014 03:09:27 +0000,Wed; 29 Oct 2014 17:32:04 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6022
MAPREDUCE-6023,Improvement,Minor,,"Fix SuppressWarnings from ""unchecked"" to ""rawtypes"" in O.A.H.mapreduce.lib.input.TaggedInputSplit",nan,Open,Unresolved,,Abhilash Srimat Tirumala Pallerlamudi,Junping Du,Mon; 4 Aug 2014 10:45:24 +0000,Sat; 9 May 2015 00:10:19 +0000,,,,BB2015-05-TBR;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6023
MAPREDUCE-6024,Improvement,Critical,mr-am;task,java.net.SocketTimeoutException in Fetcher caused jobs stuck for more than 1 hour,2014-08-04 21:09:42;356 WARN fetcher#33 org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to fake.host.name:13562 with 2 map outputs  165),Closed,Fixed,,yunjiong zhao,yunjiong zhao,Wed; 6 Aug 2014 06:33:19 +0000,Mon; 1 Dec 2014 03:11:51 +0000,Mon; 18 Aug 2014 18:00:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6024
MAPREDUCE-6025,Sub-task,Major,task,native-task: fix native library distribution,"currently running ""mvn install -Pdist"" fails and nativetask native library is not distributed to hadoop tar",Resolved,Fixed,,Manu Zhang,Manu Zhang,Thu; 7 Aug 2014 01:41:01 +0000,Sat; 13 Sep 2014 14:05:26 +0000,Mon; 18 Aug 2014 02:39:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6025
MAPREDUCE-6026,Sub-task,Minor,task,native-task: fix logging,nativetask should use commons-logging and add log4j.properties in test configuration as per hadoop standard,Resolved,Fixed,,Manu Zhang,Manu Zhang,Thu; 7 Aug 2014 07:05:55 +0000,Sat; 13 Sep 2014 14:05:25 +0000,Thu; 14 Aug 2014 04:53:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6026
MAPREDUCE-6027,Bug,Major,job submission,mr jobs with relative paths can fail,I built hadoop from branch-2 and tried to run terasort as follows:     If I used absolute paths for the input and out directories; the job runs fine. This breakage is due to HADOOP-10876.,Patch Available,Unresolved,,Wing Yew Poon,Wing Yew Poon,Thu; 7 Aug 2014 22:15:05 +0000,Thu; 24 Dec 2015 01:18:41 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6027
MAPREDUCE-6028,Bug,Major,,java.lang.ArithmeticException: / by zero,Run any sql through hive with following  error message: 2014-08-07 10:22:28;061 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201407251033_24476_m_000002_0: Error initializing attempt_201407251033_24476_m_000002_0:  lang.ArithmeticException:   by zero  and after restart hadoop cluster;the problem resolved how to find the root casue for the problem? thks,Resolved,Invalid,,Unassigned,eagle,Fri; 8 Aug 2014 03:14:53 +0000,Fri; 8 Aug 2014 23:34:19 +0000,Fri; 8 Aug 2014 23:34:18 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6028
MAPREDUCE-6029,Bug,Major,,TestCommitterEventHandler fails in trunk,From https: console :,Closed,Fixed,,Mit Desai,Ted Yu,Fri; 8 Aug 2014 15:31:23 +0000,Thu; 12 May 2016 18:24:10 +0000,Tue; 7 Oct 2014 14:14:48 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6029
MAPREDUCE-6030,Bug,Minor,jobhistoryserver,In mr-jobhistory-daemon.sh; some env variables are not affected by mapred-env.sh,In mr-jobhistory-daemon.sh; some env variables are exported before sourcing mapred-env.sh; so these variables don't use values defined in mapred-env.sh.,Patch Available,Unresolved,,Youngjoon Kim,Youngjoon Kim,Sat; 9 Aug 2014 06:15:11 +0000,Wed; 6 May 2015 03:33:31 +0000,,,2.4.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6030
MAPREDUCE-6031,Task,Major,resourcemanager,resourcemanager can not work while there has no any errors,"recently ; while the hadoop cluster are working .Sometime ; there has no any errors in the RM or NM ; but the RM do not assigin resource while remaining much resource in the cluster .The following representation are  1 the command line such as ""yarn node -list "" could execute .The result are all well. 2 all nodes with running containers are all the MRapp container ; no yarnchild process is running .  3 all applications that had been submited to the cluster early are all in the progress of 5%  ;simultanously they will hang forever. the key is that we can not find any error or exception ; but the applications  hung. The temporary solution is to switch the active resourcemanager;but  where is the problem???Could you give some advices?",Open,Unresolved,,llcode,llcode,Mon; 11 Aug 2014 10:59:43 +0000,Mon; 11 Aug 2014 11:14:21 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6031
MAPREDUCE-6032,Bug,Major,jobhistoryserver,Unable to check mapreduce job status if submitted using a non-default namenode,"When MRv2 job container runs in a context of non-default file system JobHistoryUtils. obtains mapreduce.jobhistory.done-dir and  mapreduce.jobhistory.intermediate-done-dir as a non-qualified paths (e.g.  subdir"" which doesn't make sense. However I don't believe it worth fixing; since nobody really case about local file system besides tests. My fix just ensures that all tests run smoothly by ignoring core-default.xml file system in the logic.)",Closed,Fixed,,Benjamin Zhitomirsky,Benjamin Zhitomirsky,Mon; 11 Aug 2014 13:11:52 +0000,Mon; 1 Dec 2014 03:08:27 +0000,Fri; 15 Aug 2014 20:36:11 +0000,,2.0.5-alpha;2.1.1-beta;2.0.6-alpha;2.2.0;2.3.0;2.2.1;2.4.1,,,MAPREDUCE-6044,https://issues.apache.org/jira/browse/MAPREDUCE-6032
MAPREDUCE-6033,Bug,Major,,Users are not allowed to view their own jobs; denied by JobACLsManager,Have a Hadoop 2.4.1 cluster with Yarn ACL enabled; and try to submit jobs as a non-admin user user1. The job could be finished successfully; but the running progress was not displayed correctly on the command-line; and I got following in the corresponding ApplicationMaster log: INFO IPC Server handler 0 on 56717 org.apache.hadoop.ipc.Server: IPC Server handler 0 on 56717; call org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB.getJobReport from 9.30.95.26:61024 Call#59 Retry#0 org.apache.hadoop.security.AccessControlException: User user1 cannot perform operation VIEW_JOB on job_1407456690588_0003   org.apache.hadoop.ipc.Server$Handler.run(Server. 2007),Closed,Fixed,,Yu Gao,Yu Gao,Mon; 11 Aug 2014 22:51:52 +0000,Fri; 12 Sep 2014 01:16:43 +0000,Mon; 18 Aug 2014 17:30:24 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6033
MAPREDUCE-6034,Improvement,Major,client,JobControl: polling interval should not be hard coded,"The JobControl mechanism relies on a polling mechanism which is implemented in JobControl.run().  The polling period is currently hard coded to 5s in the run() method making it almost impossible to tune. However; I believe that it will be good to let the users set this value. Some applications could want it in production and it would speed up the local mode and integration tests a lot. In my current project; nearly half of the time of the test suite is spend in this single line. Pig had the same issue; and decided to ""crazily"" hack the JobControl class rather than fixing it in the upstream (see PIG-2702).  AFAIK it could be easily done by providing a new ctor or a new setter. This change would not break the compatibility. I can provide a patch if this change seems reasonable.",Open,Unresolved,,Unassigned,Cl  ment MATHIEU,Wed; 13 Aug 2014 13:36:43 +0000,Wed; 13 Aug 2014 13:36:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6034
MAPREDUCE-6035,Sub-task,Minor,task,native-task: sources/test-sources jar distribution,nativetask sources jar and test-sources jar should be distributed like other modules under hadoop-mapreduce-project,Resolved,Fixed,,Manu Zhang,Manu Zhang,Thu; 14 Aug 2014 02:13:11 +0000,Sat; 13 Sep 2014 14:05:22 +0000,Thu; 14 Aug 2014 04:56:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6035
MAPREDUCE-6036,Bug,Major,,TestJobEndNotifier fails intermittently in branch-2,I have seen TestJobEndNotifier#testNotificationOnLastRetryUnregistrationFailure failing in branch-2 intermittently. I ran the test on my machine and it fails 3 in 10 times.  This is how the test fails.,Closed,Fixed,,Chang Li,Mit Desai,Fri; 15 Aug 2014 15:31:24 +0000,Mon; 1 Dec 2014 03:10:09 +0000,Mon; 18 Aug 2014 18:19:57 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6036
MAPREDUCE-6037,Bug,Major,mrv2,"webUI ""descriptors"" overwritten in Mini MR Cluster ",Unlike in Hadoop1; Hadoop2 does not use web.xml for webUI. However; the programmatically set Guice descriptors overwrite each other; such that the last component to start ends up owning all web ports (typically NM). This is a regression from Hadoop1.,Open,Unresolved,,Unassigned,Gera Shegalov,Mon; 18 Aug 2014 05:44:25 +0000,Mon; 18 Aug 2014 05:44:25 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6037
MAPREDUCE-6038,Bug,Minor,,A boolean may be set error in the Word Count v2.0 in MapReduce Tutorial,"As a beginner; when I learned about the basic of the mr; I found that I cound't run the WordCount2 using the command ""bin output"" in the Tutorial. The VM throwed the NullPoniterException at the line 47. In the line 45; the returned default value of ""conf.getBoolean"" is true. That is to say  when ""wordcount.skip.patterns"" is not set ;the WordCount2 will continue to execute getCacheFiles.. Then patternsURIs gets the null value. When the ""-skip"" option dosen't exist;  ""wordcount.skip.patterns"" will not be set. Then a NullPointerException come out. At all; the block after the if-statement in line no. 45 shoudn't be executed when the ""-skip"" option dosen't exist in command. Maybe the line 45 should like that  ""if (conf.getBoolean(""wordcount.skip.patterns""; false)) { "" .Just change the boolean.",Resolved,Fixed,,Tsuyoshi Ozawa,Pei Ma,Tue; 19 Aug 2014 03:08:20 +0000,Tue; 30 Aug 2016 01:19:50 +0000,Tue; 7 Jul 2015 17:28:15 +0000,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6038
MAPREDUCE-6039,Bug,Trivial,,mapreduce.v2.hs.webapp.dao.TestJobInfo is using old name of job history file,In the file: org.apache.hadoop.mapreduce.v2.hs.webapp.dao.TestJobInfo. ,Resolved,Not A Problem,,Unassigned,stanley shi,Tue; 19 Aug 2014 06:51:16 +0000,Tue; 17 Mar 2015 05:23:27 +0000,Tue; 17 Mar 2015 05:23:27 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6039
MAPREDUCE-6040,Improvement,Major,distcp,distcp should automatically use /.reserved/raw when run by the superuser,On HDFS-6134; Sanjay Radia asked for distcp to automatically prepend  raw.  The -disablereservedraw flag can be used to disable this option.,Patch Available,Unresolved,,Charles Lamb,Andrew Wang,Wed; 20 Aug 2014 01:59:26 +0000,Thu; 12 May 2016 18:24:35 +0000,,,3.0.0-alpha1,BB2015-05-TBR,,HADOOP-11006;HDFS-6891,https://issues.apache.org/jira/browse/MAPREDUCE-6040
MAPREDUCE-6041,Bug,Major,security,Fix TestOptionsParser,"Error Message  expected:...argetPathExists=true[]} but was:...argetPathExists=true; preserveRawXattrs=false}  Stacktrace  org.junit.ComparisonFailure: expected:...argetPathExists=true[]} but was:...argetPathExists=true; preserveRawXattrs=false} 	at org.junit.Assert.assertEquals(Assert. 361)",Closed,Fixed,,Charles Lamb,Charles Lamb,Tue; 19 Aug 2014 14:06:52 +0000,Tue; 30 Jun 2015 07:18:59 +0000,Tue; 19 Aug 2014 20:44:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6041
MAPREDUCE-6042,Bug,Major,,jaxb classpath conflict,It looks like hadoop includes it's own dependencies for jaxb; which conflict with the jdk 6  7 versions. When I make soap calls out; I get this:,Open,Unresolved,,Unassigned,Shaun A Elliott,Thu; 21 Aug 2014 17:19:59 +0000,Thu; 21 Aug 2014 17:19:59 +0000,,,2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6042
MAPREDUCE-6043,Bug,Major,,Lost messages from RM to MRAppMaster,We have seen various cases that reducer-preemption does not kick in and the scheduled mappers wait behind running reducers forever. Each time there seems to be a different scenario. So far we have tracked down two of such cases and the common element between them is that the variables in RMContainerAllocator go out of sync since they only get updated when completed container is reported by RM. However there are many corner cases that such report is not received from RM and yet the MapReduce app moves forward. Perhaps one possible fix would be to update such variables also after exceptional cases.  The logic for triggering preemption is at RMContainerAllocator::preemptReducesIfNeeded The preemption is triggered if the following is true:    where am: number of assigned mappers; |m| is mapper size; pr is number of reducers being preempted; and |r| is the reducer size. Each of these variables going out of sync will cause the preemption not to kick in. In the following comment; we explain two of such cases.,Resolved,Invalid,,Unassigned,Maysam Yabandeh,Thu; 21 Aug 2014 17:42:23 +0000,Wed; 27 Aug 2014 18:13:02 +0000,Wed; 27 Aug 2014 18:13:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6043
MAPREDUCE-6044,Bug,Major,jobhistoryserver,Fully qualified intermediate done directory will break per-user dir creation on Windows,"After MAPREDUCE-6032; the string of the intermediate done dir will be a fully qualified path.  The following code in JobHistoryUtils tries to concat this path and user name to create a per-user dir path; using File.separator as the seperator (on Windows; it is "" "" with "" ""; and finally FS cannot handle this path correctly: it will take ""done_intermediateuser"" as a single directory name.",Closed,Fixed,,Zhijie Shen,Zhijie Shen,Thu; 21 Aug 2014 21:35:16 +0000,Thu; 12 May 2016 18:24:06 +0000,Fri; 22 Aug 2014 17:08:56 +0000,,2.6.0;3.0.0-alpha1,,,MAPREDUCE-6032,https://issues.apache.org/jira/browse/MAPREDUCE-6044
MAPREDUCE-6045,Bug,Minor,test,need close the DataInputStream after open it in TestMapReduce.java,In TestMapReduce.  we didn't close the DataInputStream after open it in isSequenceFile.,Closed,Fixed,,zhihai xu,zhihai xu,Fri; 22 Aug 2014 05:00:32 +0000,Fri; 24 Apr 2015 23:15:12 +0000,Fri; 19 Dec 2014 20:07:45 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6045
MAPREDUCE-6046,Improvement,Minor,mr-am,Change the class name for logs in RMCommunicator.java,It is little confusing when the logs gets generated with the class name as RMContainerAllocator and not present in RMContainerAllocator.      In the above RMContainerAllocator.class needs to be changed to RMCommunicator.class.,Closed,Fixed,,Sahil Takiar,Devaraj K,Fri; 22 Aug 2014 07:02:31 +0000,Thu; 12 May 2016 18:23:02 +0000,Fri; 12 Dec 2014 06:52:31 +0000,,3.0.0-alpha1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6046
MAPREDUCE-6047,Improvement,Major,,Introduce localization phase for mapreduce jobs,"we have been experienced lots of task timeout due to localization of a large number of files. It would be great if we have an additional phase that keep track of how many files have been localized. Thus for Mappers we had ""localization""; ""map""; ""sort"". For backwards compatibility; we can keep it 0% but still heartbeat to AM with the status string ""5 300 files localized"".",Resolved,Duplicate,NULL,Siqi Li,Siqi Li,Fri; 22 Aug 2014 18:09:47 +0000,Wed; 1 Oct 2014 23:18:43 +0000,Wed; 1 Oct 2014 23:18:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6047
MAPREDUCE-6048,Test,Minor,,TestJavaSerialization fails in trunk build,This happened in builds #1871 and #1872,Closed,Fixed,,Varun Vasudev,Ted Yu,Sat; 23 Aug 2014 16:08:44 +0000,Mon; 1 Dec 2014 03:08:51 +0000,Wed; 5 Nov 2014 04:25:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6048
MAPREDUCE-6049,Bug,Major,applicationmaster;resourcemanager,AM JVM does not exit if MRClientService gracefull shutdown fails,Eventhough job got FAILED; AM process still not exiting  ThreadDump of AM process is below,Closed,Fixed,,Rohith Sharma K S,Nishan Shetty,Mon; 25 Aug 2014 05:58:26 +0000,Fri; 24 Apr 2015 23:15:18 +0000,Tue; 18 Nov 2014 16:42:39 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6049
MAPREDUCE-6050,Bug,Trivial,test,Upgrade JUnit3 TestCase to JUnit 4,There are still test classes that extend from junit.framework.TestCase. upgrade them to JUnit4.,Resolved,Done,,Unassigned,Chen He,Mon; 25 Aug 2014 16:18:36 +0000,Sat; 14 Oct 2017 08:24:43 +0000,Sat; 14 Oct 2017 08:24:43 +0000,,,newbie,MAPREDUCE-6932,HADOOP-14729;HADOOP-12564,https://issues.apache.org/jira/browse/MAPREDUCE-6050
MAPREDUCE-6051,Bug,Trivial,,Fix typos in log messages,There are a bunch of typos in log messages. HADOOP-10946 was initially created; but may have failed due to being in multiple components. Try fixing typos on a per-component basis.,Closed,Fixed,,Ray Chiang,Ray Chiang,Mon; 25 Aug 2014 18:57:28 +0000,Mon; 1 Dec 2014 03:11:04 +0000,Thu; 28 Aug 2014 23:33:15 +0000,,2.5.0,newbie,,HADOOP-10946,https://issues.apache.org/jira/browse/MAPREDUCE-6051
MAPREDUCE-6052,Bug,Major,,Support overriding log4j.properties per job,"For current MR application; the ""log4j.configuration"" is hard coded to container-log4j.properties within each node. We still need flexibility to override it per job like what we do in MRV1.",Closed,Fixed,,Junping Du,Junping Du,Tue; 26 Aug 2014 03:15:35 +0000,Mon; 1 Dec 2014 03:08:51 +0000,Sun; 2 Nov 2014 04:49:15 +0000,,2.5.0,,,MAPREDUCE-6148;MAPREDUCE-6149,https://issues.apache.org/jira/browse/MAPREDUCE-6052
MAPREDUCE-6053,Improvement,Major,job submission,New hadoop API don't allow dynamic key-based names for output files,MultipleTextOutputFormat class removed from new api. MultipleOutputs class forces developer to set names of output files at job configuration time. So with new api I can't create files with names based on keys (I don't know all keys. Therefore I can't set output file names at job configuration time). This is major disadvantage in comparison with old api and force developer to use it.  http: ,Open,Unresolved,,Unassigned,Paul Vasilev,Tue; 26 Aug 2014 11:21:29 +0000,Tue; 26 Aug 2014 11:40:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6053
MAPREDUCE-6054,Sub-task,Major,task,native-task: speed up test runs,Currently the KVTest compatibility test takes so long on my machine that it regularly times out maven. We should speed it up.,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 27 Aug 2014 04:26:41 +0000,Sat; 13 Sep 2014 14:05:27 +0000,Wed; 27 Aug 2014 19:28:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6054
MAPREDUCE-6055,Sub-task,Major,task,native-task: findbugs; interface annotations; and other misc cleanup,"A few items which we need to address before merge:  	fix findbugs errors 	add interface and stability annotations to all public classes 	fix eclipse warnings where possible",Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 27 Aug 2014 05:53:56 +0000,Sat; 13 Sep 2014 14:05:27 +0000,Wed; 3 Sep 2014 19:23:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6055
MAPREDUCE-6056,Sub-task,Minor,task,nativetask: move system test working dir to target dir and cleanup test config xml files,nan,Resolved,Fixed,,Manu Zhang,Binglin Chang,Wed; 27 Aug 2014 10:05:10 +0000,Sat; 13 Sep 2014 14:05:27 +0000,Tue; 2 Sep 2014 08:31:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6056
MAPREDUCE-6057,Improvement,Minor,,Remove obsolete entries from mapred-default.xml,The following properties are defined in mapred-default.xml but no longer exist in MRJobConfig.    map.sort.class   mapred.child.env   mapred.child. opts   mapreduce.app-submission.cross-platform   mapreduce.client.completion.pollinterval   mapreduce.client.output.filter   mapreduce.client.progressmonitor.pollinterval   mapreduce.client.submit.file.replication   mapreduce.cluster.acls.enabled   mapreduce.cluster.local.dir   mapreduce.framework.name   mapreduce.ifile.readahead   mapreduce.ifile.readahead.bytes   mapreduce.input.fileinputformat.list-status.num-threads   mapreduce.input.fileinputformat.split.minsize   mapreduce.input.lineinputformat.linespermap   mapreduce.job.counters.limit   mapreduce.job.max.split.locations   mapreduce.job.reduce.shuffle.consumer.plugin.class   mapreduce.jobhistory.address   mapreduce.jobhistory.admin.acl   mapreduce.jobhistory.admin.address   mapreduce.jobhistory.cleaner.enable   mapreduce.jobhistory.cleaner.interval-ms   mapreduce.jobhistory.client.thread-count   mapreduce.jobhistory.datestring.cache.size   mapreduce.jobhistory.done-dir   mapreduce.jobhistory.http.policy   mapreduce.jobhistory.intermediate-done-dir   mapreduce.jobhistory.joblist.cache.size   mapreduce.jobhistory.keytab   mapreduce.jobhistory.loadedjobs.cache.size   mapreduce.jobhistory.max-age-ms   mapreduce.jobhistory.minicluster.fixed.ports   mapreduce.jobhistory.move.interval-ms   mapreduce.jobhistory.move.thread-count   mapreduce.jobhistory.principal   mapreduce.jobhistory.recovery.enable   mapreduce.jobhistory.recovery.store.class   mapreduce.jobhistory.recovery.store.fs.uri   mapreduce.jobhistory.store.class   mapreduce.jobhistory.webapp.address   mapreduce.local.clientfactory.class.name   mapreduce.map.skip.proc.count.autoincr   mapreduce.output.fileoutputformat.compress   mapreduce.output.fileoutputformat.compress.codec   mapreduce.output.fileoutputformat.compress.type   mapreduce.reduce.skip.proc.count.autoincr   mapreduce.shuffle.connection-keep-alive.enable   mapreduce.shuffle.connection-keep-alive.timeout   mapreduce.shuffle.max.connections   mapreduce.shuffle.max.threads   mapreduce.shuffle.port   mapreduce.shuffle.ssl.enabled   mapreduce.shuffle.ssl.file.buffer.size   mapreduce.shuffle.transfer.buffer.size   mapreduce.shuffle.transferTo.allowed   yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts  Submitting bug for comment feedback about which properties should be kept in mapred-default.xml.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Thu; 28 Aug 2014 05:47:15 +0000,Thu; 12 May 2016 18:24:41 +0000,Mon; 27 Apr 2015 03:31:27 +0000,,2.5.0,newbie,MAPREDUCE-6192,MAPREDUCE-5762,https://issues.apache.org/jira/browse/MAPREDUCE-6057
MAPREDUCE-6058,Sub-task,Minor,task,native-task: KVTest and LargeKVTest should check mr job is sucessful,When running KVTest and LargeKVTest; if the job failed for some reason(lack libhadoop.so etc); both native and normal job failed; and both compare empty output directory; so the test passes without noticing failure.,Resolved,Fixed,,Binglin Chang,Binglin Chang,Thu; 28 Aug 2014 11:55:54 +0000,Sat; 13 Sep 2014 14:05:25 +0000,Fri; 5 Sep 2014 04:24:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6058
MAPREDUCE-6059,Improvement,Major,,Speed up history server startup time,When history server starts up; It scans every history directories and put all history files into a cache; whereas this cache only stores 20K recent history files. Therefore; it is wasting a large portion of time loading old history files into the cache; and the startup time will keep increasing if we don't trim the number of history files. For example; when history server starts up with 2.5M history files in HDFS; it took ~5 minutes.,Closed,Fixed,,Siqi Li,Siqi Li,Mon; 28 Jul 2014 20:58:54 +0000,Fri; 24 Apr 2015 23:15:14 +0000,Thu; 5 Feb 2015 01:36:16 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6059
MAPREDUCE-6060,Improvement,Major,security,shuffle data should be encrypted at rest if the input/output of the job are in an encryption zone,If the input or output of an MR job are within an encryption zone; by default the intermediate data of the job should be encrypted.  Setting the MRJobConfig.MR_ENCRYPTED_INTERMEDIATE_DATA property explicitly should override the default behavior.,Open,Unresolved,,Alejandro Abdelnur,Alejandro Abdelnur,Thu; 28 Aug 2014 17:51:57 +0000,Sat; 7 Jan 2017 01:59:58 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6060
MAPREDUCE-6061,Bug,Trivial,,Fix MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS property in MRJobConfig,"The property MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS is defined as:    MR_PREFIX + ""yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts""  which results in the prefix part showing up twice.  It should be    MR_PREFIX + ""client-am.ipc.max-retries-on-timeouts""",Resolved,Duplicate,MAPREDUCE-6087,Ray Chiang,Ray Chiang,Fri; 29 Aug 2014 03:21:33 +0000,Tue; 11 Nov 2014 19:45:05 +0000,Tue; 11 Nov 2014 19:45:05 +0000,,2.5.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6061
MAPREDUCE-6062,Bug,Major,benchmarks,Use TestDFSIO test random read : job failed,This is log: 2014-09-01 13:57:29;876 WARN main org.apache.hadoop.mapred.YarnChild: Exception running child :  162)  2014-09-01 13:57:29;886 INFO main org.apache.hadoop.mapred.Task: Runnning cleanup for the task 2014-09-01 13:57:29;894 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs: attempt_1409538816633_0005_m_000001_0,Patch Available,Unresolved,,Takuya Fukudome,chongyuanhuang,Mon; 1 Sep 2014 07:01:09 +0000,Wed; 25 May 2016 02:41:47 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6062
MAPREDUCE-6063,Bug,Major,mrv1;mrv2,In sortAndSpill of MapTask.java; size is calculated wrongly when bufend < bufstart.,In sortAndSpill of MapTask. ,Closed,Fixed,,zhihai xu,zhihai xu,Tue; 2 Sep 2014 09:56:16 +0000,Mon; 1 Dec 2014 03:09:25 +0000,Thu; 4 Sep 2014 00:10:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6063
MAPREDUCE-6064,Bug,Major,,Bad links to jobhistory server,"If you run an MR YARN cluster without configuring the jobhistory URL; you get some really bad usability:  	your jobs still produce JobHistory links 	the job history link goes to whichever NM the AM happened to run on    Even if you run the job history server on the same server as the RM; your links will be incorrect unless you've explicitly configured its hostname.  If JobHistory isn't running; we shouldn't produce URLs (or we should by default embed JobHistory inside the RM). If we require a hostname beyond 0.0.0.0; we should refuse to start the JH server with 0.0.0.0 as its configuration.",Open,Unresolved,,Unassigned,Todd Lipcon,Wed; 3 Sep 2014 00:23:14 +0000,Wed; 3 Sep 2014 00:27:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6064
MAPREDUCE-6065,Sub-task,Major,task,native-task: warnings about illegal Progress values,In running terasort tests; I see a few warnings like this: 2014-09-02 18:50:34;623 WARN main org.apache.hadoop.util.Progress: Illegal progress value found; progress is larger than 1. Progress will be changed to 1  It sounds like we're improperly calculating task progress somewhere. We should fix this.,Resolved,Invalid,,Manu Zhang,Todd Lipcon,Wed; 3 Sep 2014 01:51:55 +0000,Wed; 3 Sep 2014 17:16:44 +0000,Wed; 3 Sep 2014 03:16:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6065
MAPREDUCE-6066,Bug,Major,applicationmaster;scheduler,Speculative attempts should not run on the same node as their original attempt,I'm seeing a behavior on trunk with fair scheduler enabled where a speculative reduce attempt is getting run on the same node as its original attempt. This doesn't make sense  the main reason for speculative execution is to deal with a slow node; so scheduling a second attempt on the same node would just make the problem worse if anything.,Open,Unresolved,,Unassigned,Todd Lipcon,Wed; 3 Sep 2014 02:30:27 +0000,Sun; 27 Sep 2015 18:35:17 +0000,,,2.5.0;2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6066
MAPREDUCE-6067,Sub-task,Major,task,native-task: fix some counter issues,After running a terasort; I see the spilled records counter at 5028651606; which is about half what I expected to see. Using the non-native collector I see the expected count of 10000000000. It seems the correct number of records were indeed spilled; because the job's output record count is correct.,Resolved,Fixed,,Binglin Chang,Todd Lipcon,Wed; 3 Sep 2014 02:35:42 +0000,Sat; 13 Sep 2014 14:05:22 +0000,Fri; 5 Sep 2014 07:20:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6067
MAPREDUCE-6068,Bug,Major,mrv2;task,Illegal progress value warnings in map tasks,When running a terasort on latest trunk; I see the following in my task logs:     We should eliminate these warnings.,Resolved,Fixed,,Binglin Chang,Todd Lipcon,Wed; 3 Sep 2014 17:16:27 +0000,Tue; 30 Aug 2016 01:19:49 +0000,Mon; 11 Jan 2016 14:08:48 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6068
MAPREDUCE-6069,Sub-task,Major,task,native-task: Style fixups and dead code removal,"A few more cleanup things we should address:  	fix style issues (eg lines too long; bad indentation; commented-out code blocks; etc) both in Java and C++ 	Found a few pieces of unused code by running a coverage tool. We should remove them",Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Wed; 3 Sep 2014 21:32:23 +0000,Sat; 13 Sep 2014 14:05:21 +0000,Fri; 5 Sep 2014 17:45:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6069
MAPREDUCE-6070,Improvement,Trivial,documentation,yarn.app.am.resource.mb/cpu-vcores affects uber mode but is not documented,We should document the condition when uber mode is enabled. Currently; users need to read following code to understand the condition.,Closed,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Tue; 20 May 2014 07:39:31 +0000,Mon; 1 Dec 2014 03:09:18 +0000,Thu; 11 Sep 2014 16:23:19 +0000,,2.4.0;2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6070
MAPREDUCE-6071,Improvement,Trivial,client,JobImpl#makeUberDecision doesn't log that Uber mode is disabled because of too much CPUs,"JobImpl#makeUberDecision usually logs why the Job cannot be launched as Uber mode(e.g. ""too much RAM;"" or something).  About CPUs; it's not logged currently. We should log it when ""too much CPU"".",Closed,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Tue; 20 May 2014 07:30:05 +0000,Mon; 1 Dec 2014 03:08:33 +0000,Fri; 5 Sep 2014 13:50:41 +0000,,2.4.0;2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6071
MAPREDUCE-6072,Improvement,Minor,documentation,Remove INSTALL document,". INSTALL has become stale. The document shows  	svn as SCM; now we use git 	ant to compile hadoop-mapreduce-examples    The document should be updated to link BUILDING.txt and web docs.",Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Fri; 5 Sep 2014 01:44:14 +0000,Mon; 1 Dec 2014 03:09:20 +0000,Mon; 29 Sep 2014 15:31:31 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6072
MAPREDUCE-6073,Bug,Trivial,documentation,Description of mapreduce.job.speculative.slowtaskthreshold in mapred-default should be moved into description tags,Currently; description of mapreduce.job.speculative.slowtaskthreshold in mapred-default is put outside of description tags. We should move it into description tags.,Closed,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Fri; 5 Sep 2014 16:26:01 +0000,Mon; 1 Dec 2014 03:07:47 +0000,Fri; 26 Sep 2014 18:17:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6073
MAPREDUCE-6074,Sub-task,Major,task,native-task: fix release audit; javadoc; javac warnings,RAT is showing some release audit warnings. They all look spurious - just need to do a little cleanup and add excludes,Resolved,Fixed,,Todd Lipcon,Todd Lipcon,Fri; 5 Sep 2014 20:36:43 +0000,Sat; 13 Sep 2014 14:05:27 +0000,Sat; 6 Sep 2014 02:59:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6074
MAPREDUCE-6075,Bug,Major,jobhistoryserver,HistoryServerFileSystemStateStore can create zero-length files,When the history server state store writes a token file it uses IOUtils.cleanup() to close the file which will silently ignore errors.  This can lead to empty token files in the state store.,Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 5 Sep 2014 20:45:38 +0000,Mon; 1 Dec 2014 03:08:02 +0000,Wed; 10 Sep 2014 22:26:04 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6075
MAPREDUCE-6076,Bug,Major,mrv1,Zero map split input length combine with none zero  map split input length may cause MR1 job hung sometimes. ,Zero map split input length combine with none zero map split input length may cause MR1 job hung sometimes. This problem may happen when use HBASE input split(TableSplit). HBASE split input length can be zero for unknown regions or non-zero for known regions in the following code:   The TableSplit length come from RegionSizeCalculator.getRegionSize.  The job hung is because in MR1; If these zero split input length map tasks are scheduled and completed before all none zero split input length map tasks are scheduled; Scheduling new map task in JobProgress. will be failed to pass the TaskTracker resources check at.   The resource calculation is at   You can see in the calculation: completedMapsInputSize will be a very small number and inputSize *            completedMapsOutputSize  will be a very big number For example; completedMapsInputSize = 1; inputSize = 100MBytes and  completedMapsOutputSize=100MBytes; The estimate will be 5000TB which will be more than most task tracker disk space size.  So I think if the map split input length is 0; it means the split input length is unknown and it is reasonable to use map output size as input size for the calculation in ResourceEstimator. I will upload a fix based on this method.,Resolved,Fixed,,zhihai xu,zhihai xu,Sat; 6 Sep 2014 00:15:09 +0000,Fri; 3 Apr 2015 19:52:40 +0000,Wed; 1 Apr 2015 23:42:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6076
MAPREDUCE-6077,Sub-task,Minor,task,Remove CustomModule examples in nativetask,Currently; we don't need to support custom key types. So; this module can be removed for now.,Resolved,Fixed,,Sean Zhong,Sean Zhong,Sat; 6 Sep 2014 03:02:58 +0000,Sat; 13 Sep 2014 14:05:28 +0000,Sun; 7 Sep 2014 04:26:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6077
MAPREDUCE-6078,Sub-task,Trivial,task,native-task: fix gtest build on macosx,Try compile the HEAD code in macos but failed; looks like MAPREDUCE-5977 separate gtest compile from nttest in order to surpress compile warnings; but it forget to add addition compile flags added to nttest is also required for  gtest build; this patch fix this.,Resolved,Fixed,MAPREDUCE-6106,Binglin Chang,Binglin Chang,Tue; 9 Sep 2014 04:08:03 +0000,Thu; 12 May 2016 18:23:23 +0000,Thu; 25 Sep 2014 14:57:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6078
MAPREDUCE-6079,Improvement,Major,,Rename JobImpl#username to reporterUserName,On MAPREDUCE-6033; we found the bug because of confusing field names userName and username. We should change the names to distinguish them easily.,Resolved,Fixed,,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Tue; 9 Sep 2014 07:50:29 +0000,Tue; 30 Aug 2016 01:19:47 +0000,Fri; 8 May 2015 09:20:39 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6079
MAPREDUCE-6080,Bug,Major,jobhistoryserver;webapps,JHS checks YARN application ACLs to determine user's access to aggregated logs,While JHS uses JobACLsManager to check user's access tot the job history information; it uses ApplicationACLsManager to justify whether the user has access to the aggregated log; because it directly imports AggregatedLogsBlock into the log web page.  In most cases; the two manager can do consistent access control. However we observed case that YARN acls is enabled while MR cluster acls is not. Therefore; the user can view all the job information except accessing the aggregated logs from JHS. It confuses the user.,Open,Unresolved,,Unassigned,Zhijie Shen,Tue; 9 Sep 2014 15:05:38 +0000,Thu; 12 May 2016 18:23:18 +0000,,,2.5.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6080
MAPREDUCE-6081,Improvement,Major,,MapReduce should take cpu into account when doing headroom calculations,Currently the MapReduce AM only uses memory when doing headroom calculation as well calculations about launching reducers. It would be preferable to account for CPU as well if the scheduler on the YARN side is using CPU when scheduling. YARN-2448 lets AMs know what resources are being considered when scheduling.,Resolved,Duplicate,HADOOP-11341,Varun Vasudev,Varun Vasudev,Wed; 10 Sep 2014 18:20:35 +0000,Wed; 10 Sep 2014 18:32:19 +0000,Wed; 10 Sep 2014 18:32:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6081
HADOOP-11085,Bug,Major,,Excessive logging by org.apache.hadoop.util.Progress when value is NaN,"MAPREDUCE-5671 fixed the ""illegal"" progress values that do not fall into (0;1) interval when the progress value is given. Whenever illegal value was encountered; LOG.warn would log that incident.  As  a result; each of the task's syslog will be full of  WARN main org.apache.hadoop.util.Progress: Illegal progress value found; progress is Float.NaN. Progress will be changed to 0  Each input record will contribute to one line of such log; leading to most of the tasks' syslog  1GB.  We will need to change the log level to debug to avoid such excessive logging.",Closed,Fixed,,Mit Desai,Mit Desai,Wed; 10 Sep 2014 21:14:13 +0000,Mon; 1 Dec 2014 03:09:44 +0000,Thu; 11 Sep 2014 19:59:14 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/HADOOP-11085
HADOOP-11286,Bug,Blocker,,Map/Reduce dangerously adds Guava @Beta class to CryptoUtils,See HDFS-7040 for more background details.  In recent 2.6.0-SNAPSHOTs; the use of LimitInputStream was added to CryptoUtils. This is part of the API components of Hadoop; which severely impacts users who were utilizing newer versions of Guava; where the @Beta and @Deprecated class; LimitInputStream; has been removed (removed in version 15 and later); beyond the impact already experienced in 2.4.0 as identified in HDFS-7040.,Closed,Fixed,,Unassigned,Christopher Tubbs,Wed; 10 Sep 2014 22:00:31 +0000,Thu; 29 Jan 2015 06:47:28 +0000,Sun; 9 Nov 2014 13:27:19 +0000,,2.6.0,beta;deprecated;guava,,HDFS-7040;HADOOP-11470;HADOOP-10101,https://issues.apache.org/jira/browse/HADOOP-11286
MAPREDUCE-6084,Bug,Major,,Load MR Configuration from distributed cache rather than individual node,For rolling upgrade YARN  MapReduce component; we already support to submit jobs against different versions of mapreduce jars based on distributed cache (please refer MAPREDUCE-4421). However; this could bring up some potential issues if old jar cannot find a new added class with new configurations that upgrade together with Hadoop components. For details; please refer the proposal in attachments.,Open,Unresolved,,Junping Du,Junping Du,Thu; 11 Sep 2014 03:24:44 +0000,Sat; 7 Jan 2017 01:59:53 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6084
MAPREDUCE-6085,Improvement,Major,,Facilitate processing of text files without key/value split,There is a rather popular type of task: processing of text files line by line without splitting line to key value pair and never joined back; so lines appear in the output unmodified.,Patch Available,Unresolved,,Unassigned,Dmitry Sivachenko,Thu; 11 Sep 2014 15:35:51 +0000,Wed; 6 May 2015 03:35:23 +0000,,,2.4.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6085
MAPREDUCE-6086,Improvement,Major,security,mapreduce.job.credentials.binary should allow all URIs,"Change ""mapreduce.job.credentials.binary"" configuration to handle all URIs properly. The current ""mapreduce.job.credentials.binary"" configuration only support local fs; It would be better to make it support non-local FS URIs.",Closed,Fixed,,zhihai xu,zhihai xu,Fri; 12 Sep 2014 18:53:52 +0000,Mon; 1 Dec 2014 03:08:20 +0000,Thu; 18 Sep 2014 22:56:18 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6086
MAPREDUCE-6087,Bug,Major,,MRJobConfig#MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS config name is wrong,"The config name for MRJobConfig#MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS now has double prefix as ""yarn.app.mapreduce."" + ""yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts""",Closed,Fixed,MAPREDUCE-6061,Akira Ajisaka,Jian He,Fri; 12 Sep 2014 22:33:52 +0000,Tue; 30 Jun 2015 07:14:42 +0000,Sat; 27 Sep 2014 01:06:50 +0000,,2.3.0,newbie,HADOOP-11399,,https://issues.apache.org/jira/browse/MAPREDUCE-6087
MAPREDUCE-6088,Improvement,Major,mrv1;test,TestTokenCache tests should use their own JobConf instances,TestTokenCache in mrv1 (branch-1) depend on the order of test execution. testLocalJobTokenCache will fail if it executed after testTokenCache. The reason is because testLocalJobTokenCache depends on the jConf setup by testTokenCache. The fix is to set up the JobConf separately for testLocalJobTokenCache and testTokenCache.  See the following test result.,Resolved,Fixed,,zhihai xu,zhihai xu,Sat; 13 Sep 2014 01:18:55 +0000,Fri; 19 Sep 2014 22:21:00 +0000,Fri; 19 Sep 2014 19:00:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6088
HADOOP-11125,Test,Major,,Remove redundant tests in TestOsSecureRandom,From https: console :,Closed,Fixed,HADOOP-11362;HADOOP-11424,Masanori Oyama,Ted Yu,Mon; 15 Sep 2014 19:22:35 +0000,Fri; 10 Apr 2015 20:04:29 +0000,Thu; 18 Dec 2014 19:00:21 +0000,,,newbie,,,https://issues.apache.org/jira/browse/HADOOP-11125
MAPREDUCE-6090,Bug,Major,client,mapred hsadmin getGroups fails to connect in some cases,If you do mapred hsadmin -getGroups it works fine (assuming mapreduce.jobhistory.admin.address is set properly in mapred-site.xml).    But if you do mapred hsadmin -getGroups foo_user; it will keep retrying to connect to localhost:,Closed,Fixed,,Robert Kanter,Robert Kanter,Mon; 15 Sep 2014 23:44:26 +0000,Mon; 1 Dec 2014 03:08:09 +0000,Thu; 18 Sep 2014 21:20:40 +0000,,2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6090
MAPREDUCE-6091,Bug,Major,client,YARNRunner.getJobStatus() fails with ApplicationNotFoundException if the job rolled off the RM view,If you query the job status of a job that rolled off the RM view via YARNRunner.getJobStatus(); it fails with an ApplicationNotFoundException. For example;     Prior to 2.1.0; it used to be able to fall back onto the job history server and get the status.  This appears to be introduced by YARN-873. YARN-873 changed ClientRMService to throw an ApplicationNotFoundException on an unknown app id (from returning null). But MR's ClientServiceDelegate was never modified to change its behavior.,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Tue; 16 Sep 2014 01:19:58 +0000,Fri; 17 Feb 2017 23:00:38 +0000,Fri; 19 Sep 2014 20:21:59 +0000,,2.1.0-beta,,,SPARK-19649,https://issues.apache.org/jira/browse/MAPREDUCE-6091
MAPREDUCE-6092,Test,Minor,test,TestJobHistoryParsing#testPartialJob timeouts in some environments,Rebasing the patch in MAPREDUCE-5392; I found TestJobHistoryParsing#testPartialJob timeout in my environments.   We should extend the timeout not to fail the test in slow machines.,Resolved,Duplicate,MAPREDUCE-6104,Akira Ajisaka,Akira Ajisaka,Tue; 16 Sep 2014 08:13:57 +0000,Mon; 1 Dec 2014 10:56:10 +0000,Mon; 1 Dec 2014 10:56:10 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6092
MAPREDUCE-6093,Bug,Trivial,distcp;documentation,minor distcp doc edits,Minor edits to DistCp.md.vm,Closed,Fixed,,Charles Lamb,Charles Lamb,Tue; 16 Sep 2014 16:30:32 +0000,Thu; 12 May 2016 18:22:19 +0000,Thu; 25 Sep 2014 18:34:02 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6093
MAPREDUCE-6094,Bug,Minor,test,TestMRCJCFileInputFormat.testAddInputPath() fails on trunk,nan,Closed,Fixed,MAPREDUCE-6098;MAPREDUCE-6114,Akira Ajisaka,Sangjin Lee,Wed; 17 Sep 2014 01:25:37 +0000,Mon; 1 Dec 2014 03:10:22 +0000,Mon; 29 Sep 2014 18:15:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6094
MAPREDUCE-6095,Bug,Major,applicationmaster;distributed-cache,Enable DistributedCache for uber-mode Jobs,mapreduce.job.cache.local.* is not set for uber-mode jobs. TestUberAM hides the fact that DC files are not available for uber-mode jobs by overriding testDistributedCache with a nop method.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Wed; 17 Sep 2014 10:45:25 +0000,Mon; 1 Dec 2014 03:11:58 +0000,Mon; 22 Sep 2014 15:27:56 +0000,,2.0.5-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6095
MAPREDUCE-6097,Improvement,Major,,Add vcore usage to history information,From MAPREDUCE-5279;  3. We should reflect the vcore usage in history as well; but it may not be the trivial changes. Let's file a separate ticket for it.,Open,Unresolved,,Varun Vasudev,Varun Vasudev,Fri; 19 Sep 2014 10:43:02 +0000,Fri; 19 Sep 2014 10:43:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6097
MAPREDUCE-6098,Bug,Major,test,org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat intermittently failed in trunk,See: https: YARN-611?focusedCommentId=14129761page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14129761 for details,Resolved,Duplicate,MAPREDUCE-6094,Unassigned,Wangda Tan,Fri; 19 Sep 2014 14:48:01 +0000,Tue; 10 Mar 2015 04:30:25 +0000,Fri; 19 Sep 2014 14:58:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6098
MAPREDUCE-6099,Improvement,Critical,client,Adding  getSplits(JobContext job; List<FileStatus> stats) to mapreduce CombineFileInputFormat,Currently we have getSplits(JobContext job) in CombineFileInputFormat.  This api does not give freedom to the client to create a list if file status it self and then create splits on the resultant ListFileStatus stats. The client might be able to perform some filtering on its end on the File sets in the input paths. For the reasons; above it would be a good idea to have getSplits(JobContext; ListFileStatus). Please let me know what you think about this.,Resolved,Won't Fix,,Unassigned,Pankit Thapar,Fri; 19 Sep 2014 17:13:17 +0000,Wed; 11 May 2016 23:39:10 +0000,Wed; 11 May 2016 23:39:10 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6099
MAPREDUCE-6100,Improvement,Trivial,mrv2,"replace ""mapreduce.job.credentials.binary"" with MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY for better readability.","replace ""mapreduce.job.credentials.binary"" with MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY for better readability.",Resolved,Fixed,,zhihai xu,zhihai xu,Sat; 20 Sep 2014 02:07:15 +0000,Tue; 30 Aug 2016 01:19:45 +0000,Tue; 17 Mar 2015 05:39:25 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6100
MAPREDUCE-6101,Improvement,Major,job submission;security,on job submission; if input or output directories are encrypted; shuffle data should be encrypted at rest,Currently setting shuffle data at rest encryption has to be done explicitly to work. If not set explicitly (ON or OFF) but the input or output HDFS directories of the job are in an encrption zone; we should set it to ON.,Open,Unresolved,,Arun Suresh,Alejandro Abdelnur,Sat; 20 Sep 2014 03:08:35 +0000,Mon; 11 Sep 2017 05:08:59 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6101
MAPREDUCE-6103,Improvement,Major,,Adding reservation APIs to resource manager delegate,YARN-1051 introduces the ReservationSystem and the corresponding APIs for create delete ops. The MR resource manager delegate needs to to be updated with the APIs.,Resolved,Fixed,,Subru Krishnan,Subru Krishnan,Mon; 22 Sep 2014 21:24:12 +0000,Sat; 4 Oct 2014 15:11:28 +0000,Thu; 25 Sep 2014 01:18:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6103
MAPREDUCE-6104,Bug,Major,,TestJobHistoryParsing.testPartialJob fails in branch-2,TestJobHistoryParsing.testPartialJob intermittently fails with the following timeout error.,Closed,Fixed,MAPREDUCE-6092,Mit Desai,Mit Desai,Tue; 23 Sep 2014 20:34:52 +0000,Mon; 1 Dec 2014 10:56:10 +0000,Wed; 24 Sep 2014 16:11:50 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6104
MAPREDUCE-6105,Improvement,Trivial,,Inconsistent configuration in property mapreduce.reduce.shuffle.merge.percent,Similar to MAPREDUCE-5906; In MergeManagerImpl.  the default value of MRJobConfig.SHUFFLE_MERGE_PERCENT(mapreduce.reduce.shuffle.merge.percent) should be 0.66  According to official doc. https: mapred-default.xml,Resolved,Fixed,,Ray Chiang,Dongwook Kwon,Wed; 24 Sep 2014 05:08:24 +0000,Tue; 30 Aug 2016 01:19:43 +0000,Mon; 16 Mar 2015 20:59:25 +0000,,2.4.0;2.4.1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6105
MAPREDUCE-6106,Bug,Major,,hadoop-mapreduce-client-nativetask fails to compile on OS X,gtest isn't able to use it's built-in version of tuple.  See comments.,Resolved,Duplicate,MAPREDUCE-6078,Unassigned,Allen Wittenauer,Wed; 24 Sep 2014 16:33:24 +0000,Thu; 25 Sep 2014 03:12:10 +0000,Thu; 25 Sep 2014 03:12:10 +0000,,,,,MAPREDUCE-2841,https://issues.apache.org/jira/browse/MAPREDUCE-6106
MAPREDUCE-6107,Bug,Major,jobhistoryserver,Job history server becomes unresponsive due to stuck thread in epollWait,About once every week; we see job history server becomes unresponsive on one of our 2000 node hadoop cluster. Looking at the thread dump; I see that multiple threads are blocked on locks acquired by couple of threads; which in turn are endlessly stuck in epollWait while talking to hdfs to get a history file. When the number of blocked threads touches the thread pool size; JHS becomes unresponsive to new clients requests. Thread dump attached.  Has anyone seen this before ?  Here is the thread stuck at epollWait.,Open,Unresolved,,Unassigned,Ashwin Shankar,Wed; 24 Sep 2014 19:26:34 +0000,Wed; 11 Feb 2015 22:35:57 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6107
MAPREDUCE-6108,Bug,Critical,,ShuffleError OOM while reserving memory by MergeManagerImpl,Shuffle has OOM issue from time to time.    Such as this email reported. http: %3CCABWXXjNK-on0XTrMuriJD8SDGJjTAMSvQW2CZpm3oEkJ3YM8YQ@mail.gmail.com%3E,Resolved,Cannot Reproduce,,Unassigned,Dongwook Kwon,Wed; 24 Sep 2014 23:45:14 +0000,Fri; 13 May 2016 21:00:54 +0000,Fri; 13 May 2016 21:00:53 +0000,,2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6108
MAPREDUCE-6109,Bug,Trivial,distcp,Fix minor typo in distcp -p usage text,"In the distcp usage for -p there needs to be a space added after ""-p"":   the -p flag.Refer to the DistCp documentation for",Closed,Fixed,,Charles Lamb,Charles Lamb,Thu; 25 Sep 2014 14:51:56 +0000,Mon; 1 Dec 2014 03:11:59 +0000,Thu; 25 Sep 2014 18:25:21 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6109
MAPREDUCE-6110,Bug,Minor,jobhistoryserver,JobHistoryServer CLI throws NullPointerException with job ids that do not exist,When using JobHistoryServer CLI to query a job id th org.apache.hadoop.mapred.JobClient.main(JobClient. 1237)  Similar symptoms also appear with -list-attempt-ids; but were fine with -status and -set-priority.   I traced back to CLI.listEvents; and line 487 is:   The job object is obtained from JobID.forName(jobid)) (line 316); which will return null if the job does not exist on server.   Maybe we want to have some behaviors consistent with -status here; by simply reporting jobId does not exist?,Resolved,Fixed,,Kai Sasaki,Li Lu,Thu; 25 Sep 2014 21:11:11 +0000,Tue; 30 Aug 2016 01:19:40 +0000,Tue; 22 Mar 2016 21:32:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6110
MAPREDUCE-6111,Bug,Major,mrv2,Hadoop users' staging directories should be under a user folder,Right now; Hadoop puts all users' staging directories under  .staging.,Patch Available,Unresolved,,Unassigned,Jian Fang,Fri; 26 Sep 2014 18:27:56 +0000,Wed; 6 May 2015 03:35:41 +0000,,,2.5.0;2.4.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6111
MAPREDUCE-6112,Bug,Major,mrv2,Negative shuffle time on History UI,"Just running a simple ""pi"" job; with 10 mappers and 100 iterations. See screenshot.",Open,Unresolved,,Unassigned,Andrew Or,Fri; 26 Sep 2014 18:32:40 +0000,Tue; 2 Feb 2016 22:59:52 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6112
MAPREDUCE-6113,Improvement,Minor,client;distributed-cache,An ability to override LocalResourceVisibility for public resources,Currently it is impossible to specify APPLICATION level for files in distributed cache in YARN. For applications with big common data it is very crucial to have ability to share data only for application and do not spam public cache. Moreover; public localiser is limited for parallel downloads; so applications with big caches affect application startup of other applications. Current logic is complicated and based on file permissions. Making proposed changes; user can override public level to any level (PUBLIC PRIVATE) without breaking anything; and ever not need to bother with permission; if private cache is needed.,Resolved,Duplicate,MAPREDUCE-5951,Andrey Stepachev,Andrey Stepachev,Mon; 29 Sep 2014 10:03:39 +0000,Thu; 19 Mar 2015 11:22:28 +0000,Thu; 19 Mar 2015 11:11:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6113
MAPREDUCE-6114,Test,Minor,,TestMRCJCFileInputFormat#testAddInputPath fails in trunk,This can be reproduced locally:,Resolved,Duplicate,MAPREDUCE-6094,Unassigned,Ted Yu,Mon; 29 Sep 2014 17:21:29 +0000,Mon; 29 Sep 2014 17:58:09 +0000,Mon; 29 Sep 2014 17:58:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6114
MAPREDUCE-6115,Test,Minor,,TestPipeApplication#testSubmitter fails in trunk,This can be reproduced locally:,Closed,Fixed,MAPREDUCE-6120,Binglin Chang,Ted Yu,Mon; 29 Sep 2014 17:25:11 +0000,Tue; 31 Mar 2015 17:18:05 +0000,Mon; 13 Oct 2014 16:08:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6115
MAPREDUCE-6116,Bug,Major,nodemanager,Start container with auxiliary service data race condition,This shares the same symptoms as MAPREDUCE-2947; which is supposedly fixed. The stack trace I ran into is very similar:    What I was doing in my application is calling `ContainerLaunchContext#setServiceData` with my custom shuffle secret. This exception happens only frequently but not always; which leads me to conjecture that it's a race condition. After seeing MAPREDUCE-2947; I manually synchronized all of my calls to `NMClient#startContainer`; and I never ran into this issue again. I suspect that there is still a race condition in the AuxiliaryService code even after MAPREDUCE-2947.,Open,Unresolved,,Unassigned,Andrew Or,Wed; 1 Oct 2014 02:11:21 +0000,Mon; 8 Feb 2016 13:54:09 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6116
MAPREDUCE-6117,Bug,Major,client;task,Hadoop ignores yarn.nodemanager.hostname for RPC listeners,The RPC listeners for an application are using the hostname of the node as the binding address of the listener;  They ignore yarn.nodemanager.hostname for this.  In our setup we want all communication between nodes to be done via the network addresses we specify in yarn.nodemanager.hostname on each node.   TaskAttemptListenerImpl. are two places I have found where the default address is used rather that NM_host.   The node Manager hostname should be used for all communication between nodes including the RPC listeners.,Patch Available,Unresolved,,Waldyn Benbenek,Waldyn Benbenek,Thu; 2 Oct 2014 21:42:17 +0000,Mon; 11 Sep 2017 05:11:01 +0000,,,2.2.1;2.4.1;2.5.1,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-6117
MAPREDUCE-6118,Bug,Minor,,Uber-mode decision does not consider -Xmx,Current the decision on using uber-mode is based on the mapper container size and the AM container size. However the actual memory at AM is limited by -Xmx options passed via yarn.app.mapreduce.am.command-opts.  For example: AM memory: 4G; yarn.app.mapreduce.am.command-opts=-Xmx2048GB; mapper memory: 3GB. Here the uber job could face OOM whereas a non-uber execution would not.  We faced this problem recently and forced to disable uber-mode to circumvent the problem. One idea; although a bit ugly; is to parse jvm opts; extract Xmx; and take it into account for uber-mode decision.,Open,Unresolved,,Unassigned,Maysam Yabandeh,Thu; 2 Oct 2014 21:57:01 +0000,Fri; 3 Oct 2014 07:13:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6118
MAPREDUCE-6119,Improvement,Major,mr-am,Ability to disable node update processing in MR AM,nan,Open,Unresolved,,Jason Lowe,Jason Lowe,Fri; 3 Oct 2014 22:06:39 +0000,Sat; 7 Jan 2017 01:59:53 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6119
MAPREDUCE-6120,Test,Major,,TestPipeApplication fails on trunk,TestPipeApplication asserts following case:    The current shell script outputs not ResourceManager:port but resourcemanager:port.,Resolved,Duplicate,MAPREDUCE-6115,Tsuyoshi Ozawa,Tsuyoshi Ozawa,Sun; 5 Oct 2014 04:19:28 +0000,Sun; 5 Oct 2014 06:33:55 +0000,Sun; 5 Oct 2014 05:45:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6120
MAPREDUCE-6121,Bug,Major,mrv2,JobResourceUpdater#compareFs() doesn't handle HA namespaces,Looking at the JobSubmitter.compareFs it doesn't look like it properly handles HA namespaces.  The code tries to lookup the hostname using InetAddress.getByName; but if you are using namespaces this is going to fail and its going to copy the file when it doesn't need to.   Edit: JobSubmitter was updated to JobResourceUpdater in MAPREDUCE-6267.,Resolved,Fixed,,Ray Chiang,Thomas Graves,Mon; 6 Oct 2014 14:10:15 +0000,Tue; 30 Aug 2016 01:19:39 +0000,Tue; 30 Jun 2015 23:54:07 +0000,,2.5.0,,HADOOP-12159,,https://issues.apache.org/jira/browse/MAPREDUCE-6121
MAPREDUCE-6122,Bug,Trivial,test,TestLineRecordReader may fail due to test data files checked out of git with incorrect line endings.,TestLineRecordReader uses several test input files at src *.txt.  Some of the tests expect a specific length for the files; such as dealing with a record that spans multiple splits.  If they get checked out of git with CRLF line endings by mistake; then the test assertions will fail.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Mon; 6 Oct 2014 18:50:08 +0000,Mon; 1 Dec 2014 03:07:55 +0000,Fri; 10 Oct 2014 05:34:44 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6122
MAPREDUCE-6123,Bug,Trivial,test,TestCombineFileInputFormat incorrectly starts 2 MiniDFSCluster instances.,TestCombineFileInputFormat#testGetSplitsWithDirectory starts 2 MiniDFSCluster instances; one right after the other; using the exact same configuration.  There is no need for 2 clusters in this test.,Closed,Fixed,,Chris Nauroth,Chris Nauroth,Mon; 6 Oct 2014 19:03:43 +0000,Mon; 1 Dec 2014 03:11:46 +0000,Fri; 10 Oct 2014 05:42:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6123
MAPREDUCE-6124,Sub-task,Major,,Make MR setup the timeline domain and put entities into it,After YARN-2102; we should make MR client optionally define an domain; and put its generated entities into this domain.,Open,Unresolved,,Unassigned,Zhijie Shen,Tue; 7 Oct 2014 18:22:50 +0000,Tue; 7 Oct 2014 18:22:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6124
MAPREDUCE-6125,Bug,Major,test,TestContainerLauncherImpl sometimes fails,nan,Closed,Fixed,,Mit Desai,Mit Desai,Wed; 1 Oct 2014 14:32:11 +0000,Mon; 1 Dec 2014 03:09:34 +0000,Mon; 13 Oct 2014 15:17:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6125
MAPREDUCE-6126,Bug,Major,,"(Rumen) Rumen tool returns error ""ava.lang.IllegalArgumentException: JobBuilder.process(HistoryEvent): unknown event type""", 186),Closed,Fixed,,Junping Du,Junping Du,Thu; 9 Oct 2014 15:51:14 +0000,Mon; 1 Dec 2014 03:09:39 +0000,Wed; 22 Oct 2014 17:59:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6126
HADOOP-11202,Bug,Major,fs/s3,SequenceFile crashes with client-side encrypted files that are shorter than FileSystem.getStatus(path),"Encrypted files are often padded to allow for proper encryption on a 2^n-bit boundary.  As a result; the encrypted file might be a few bytes bigger than the unencrypted file.  We have a case where an encrypted files is 2 bytes bigger due to padding.  When we run a HIVE job on the file to get a record count (select count from table) it runs org.apache.hadoop.mapred.SequenceFileRecordReader and loads the file in through a custom FS InputStream. The InputStream decrypts the file  as it gets read in.  Splits are properly handled as it extends both Seekable and Positioned Readable.  When the org.apache.hadoop.io.SequenceFile class intializes it reads in the file size from the FileMetadata which returns the file size of the encrypted file on disk (or in this case in S3). However; the actual file size is 2 bytes less; so the InputStream will return EOF (-1) before the SequenceFile thinks it's done. As a result; the SequenceFile$Reader tried to run the next-readRecordLength after the file has been closed and we get a crash.  The SequenceFile class SHOULD; instead; pay  org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader. 274) 	... 15 more Sample stack dump:",Open,Unresolved,,Unassigned,Corby Wilson,Sat; 11 Oct 2014 19:00:24 +0000,Tue; 21 Nov 2017 10:13:18 +0000,,,2.2.0,,,HADOOP-13887,https://issues.apache.org/jira/browse/HADOOP-11202
MAPREDUCE-6128,Improvement,Major,client,Automatic addition of bundled jars to distributed cache ,On the client side; JDK adds Class-Path elements from the job jar manifest on the classpath. In theory there could be many bundled jars in many directories such that adding them manually via libjars or similar means to task classpaths is cumbersome. If this property is enabled; the same jars are added to the task classpaths automatically.,Open,Unresolved,,Gera Shegalov,Gera Shegalov,Wed; 15 Oct 2014 08:35:45 +0000,Sat; 7 Jan 2017 01:59:57 +0000,,,2.5.1,,,HADOOP-11309,https://issues.apache.org/jira/browse/MAPREDUCE-6128
MAPREDUCE-6129,Bug,Major,applicationmaster,Job failed due to counter out of limited in MRAppMaster,Lots of of cluster's job use more than 120 counters; those kind of jobs  failed with exception like below    The class org.apache.hadoop.mapreduce.counters.Limits load the mapred-site.xml on nodemanager node for JobConf if it hasn't been inited.  If the mapred-site.xml on nodemanager node is not exist or the mapreduce.job.counters.max hasn't been defined on that file; Class org.apache.hadoop.mapreduce.counters.Limits will just  use the default value 120.   Instead; we should read user job's conf file rather than config files on nodemanager for checking counters limits.  I will submitt a patch later.,Resolved,Duplicate,MAPREDUCE-5875,Unassigned,Min Zhou,Thu; 16 Oct 2014 00:01:44 +0000,Thu; 12 May 2016 18:22:43 +0000,Thu; 16 Oct 2014 20:26:47 +0000,,2.3.0;2.5.0;2.4.1;2.5.1;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6129
MAPREDUCE-6130,Bug,Major,,Mapreduce tests fail with IllegalArgumentException in trunk,From https: console :   A lot of tests failed due to 'Illegal capacity' exception,Resolved,Done,,Wangda Tan,Ted Yu,Fri; 17 Oct 2014 19:41:44 +0000,Tue; 13 Jan 2015 22:25:05 +0000,Tue; 13 Jan 2015 22:25:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6130
MAPREDUCE-6131,Bug,Major,,Integer overflow in RMContainerAllocator results in starvation of applications,"When processing large datasets; Hadoop encounters a scenario where all  containers run reduce tasks and no map tasks are scheduled. The  application does not fail but rather remains in this state without making  any forward progress. It then has to be manually terminated.   This bug is due to integer overflow in scheduleReduces() of  RMContainerAllocator. The variable netScheduledMapMem overflows for  large data sizes; takes negative value; and results in a large  finalReduceMemLimit and a large rampup value. In almost all cases; this  large rampup value is greater than the total number of reduce tasks.  Therefore; the AM tries to assign all reduce tasks. And if the total number  of reduce tasks is greater than the total container slots; then all slots are  taken up by reduce tasks; leaving none for maps.   With 128MB block size and 2GB map container size; overflow occurs with 128 TB data size. An example scenario for the reproduction is:    	Input data size of 32TB; block size 128MB; Map container size = 10GB; reduce container size = 10GB; #reducers = 50;  cluster mem capacity =  7 x 40GB; slowstart=0.0    Better resolution might be to change the variables used in  RMContainerAllocator from int to long. A simpler fix instead would be to  only change the local variables of scheduleReduces() to long data types.  Patch is attached for 2.2.0.",Resolved,Invalid,,Unassigned,Kamal Kc,Fri; 17 Oct 2014 23:49:29 +0000,Thu; 21 Jul 2016 03:45:55 +0000,Thu; 21 Jul 2016 03:45:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6131
MAPREDUCE-6132,Bug,Minor,tools/rumen,Rumen unable to accept hdfs as scheme,while running;   186),Resolved,Not A Problem,,Unassigned,Mayank Mishra,Sat; 18 Oct 2014 08:06:15 +0000,Wed; 4 Feb 2015 03:01:31 +0000,Wed; 4 Feb 2015 03:01:31 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6132
MAPREDUCE-6133,Bug,Major,tools/rumen,Rumen is not generating json for .hist file,Rumen is creating a blank json for .hist file.Please find below command that is being run :  -cp hadoop-2.4.1 job_1413468876912_0002-1413563166476-impadmin-word+count-1413563185844-1-1-SUCCEEDED-default-1413563171610.jhist,Reopened,Unresolved,,Unassigned,ARPAN BHANDARI,Sat; 18 Oct 2014 09:10:59 +0000,Fri; 12 Dec 2014 23:51:44 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6133
MAPREDUCE-6134,Sub-task,Major,jobhistoryserver,Add entity-level info or primary filters to facilitate job history data query,Per discussion in MAPREDUCE-5933; we may need to add some properties in the events to MR job or task entity's otherInfo or primaryFilter to support some particular query.  For example; getting all the tasks of one MR job:     By adding {PARENT_JOB:job_1413998833197_0001} to the primary filter of each task entity of job_1413998833197_0001 is going to significantly shorten the time to search the target task entities.,Open,Unresolved,,Unassigned,Zhijie Shen,Wed; 22 Oct 2014 21:23:01 +0000,Wed; 22 Oct 2014 21:23:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6134
MAPREDUCE-6135,Bug,Major,,Job staging directory remains if MRAppMaster is OOM,"If MRAppMaster attempts run out of memory; it won't go through the normal job clean up process to move history files to history server location. When customers try to find out why the job failed; the data won't be available on history server webUI.  The work around is to extract the container id and NM id from the jhist file in the job staging directory; then use ""yarn logs"" command to get the AM logs.  It would be great the platform can take care of it by moving these hist files automatically to history server if AM attempts don't exit properly.  We discuss ideas on how to address this and would like get suggestions from others. Not sure if timeline server design covers this scenario.  1. Define some protocol for YARN to tell AppMaster ""you have exceeded AM max attempt; please clean up"". For example; YARN can launch AppMaster one more time after AM max attempt and MRAppMaster use that as the indication this is clean-up-only attempt.  2. Have some program periodically check job statuses and move files from job staging directory to history server for those finished jobs.",Resolved,Duplicate,MAPREDUCE-5502,Unassigned,Ming Ma,Thu; 23 Oct 2014 01:07:55 +0000,Thu; 23 Oct 2014 21:36:23 +0000,Thu; 23 Oct 2014 21:36:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6135
MAPREDUCE-6136,Bug,Major,applicationmaster,MRAppMaster doesn't shutdown file systems,"When MRAppMaster exit it doesn't call close on its open file systems instances.  MAPREDUCE-3614 sets conf.setBoolean(""fs.automatic.close""; false); in MRAppMaster::main and then called FileSystem.closeAll() in MRAppMasterShutdownHook.  However; MAPREDUCE-4205 removed the call to FileSystem.closeAll() MRAppMasterShutdownHook but left `fs.automatic.close` set to false.  Removing `conf.setBoolean(""fs.automatic.close""; false);` worked for me; but it wasn't clear if this had other implications.",Closed,Fixed,,Brahma Reddy Battula,Noah Watkins,Thu; 23 Oct 2014 01:10:21 +0000,Fri; 10 Apr 2015 20:19:41 +0000,Thu; 5 Mar 2015 05:23:09 +0000,,2.4.1;2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6136
MAPREDUCE-6137,Bug,Blocker,,Unable to run start-all.sh script; getting error,"Present working Shell:  hadoop-config.sh: Syntax error: word unexpected (expecting "")"")  Kindly help.  Regards Jagadeesh A Y",Resolved,Won't Fix,,Unassigned,Jagadeesh A Y,Thu; 23 Oct 2014 12:48:59 +0000,Sun; 8 Feb 2015 18:20:01 +0000,Sun; 8 Feb 2015 18:20:01 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6137
MAPREDUCE-6138,Bug,Blocker,,Unable to run start-all.sh script; getting error,"Present working Shell:  hadoop-config.sh: Syntax error: word unexpected (expecting "")"")  Kindly help.  Regards Jagadeesh A Y",Resolved,Invalid,,Unassigned,Jagadeesh A Y,Thu; 23 Oct 2014 12:50:12 +0000,Thu; 23 Oct 2014 18:37:54 +0000,Thu; 23 Oct 2014 18:37:54 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6138
YARN-2857,Bug,Critical,,ConcurrentModificationException in ContainerLogAppender,"Context:   	Hadoop-2.3.0 	Using Oozie 4.0.1 	Pig version 0.11.x    The job is submitted by Oozie to launch Pig script.   The following exception traces were found on MR task log:  In syslog:    in stderr:",Closed,Fixed,,Mohammad Kamrul Islam,Mohammad Kamrul Islam,Fri; 24 Oct 2014 20:47:51 +0000,Fri; 10 Apr 2015 20:10:12 +0000,Fri; 14 Nov 2014 20:49:46 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-2857
MAPREDUCE-6140,Bug,Minor,mrv2,TestMRJobsWithProfiler uses unsupported profiler argument,TestMRJobsWithProfiler passes -Xprof to reducer tasks; but this option is not supported by IBM JDK,Open,Unresolved,,David Villegas,David Villegas,Tue; 28 Oct 2014 22:37:19 +0000,Tue; 28 Oct 2014 22:37:43 +0000,,,2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6140
MAPREDUCE-6141,Improvement,Major,jobhistoryserver,History server leveldb recovery store,It would be nice to have a leveldb option to the job history server recovery store.  Leveldb would provide some benefits over the existing filesystem store such as better support for atomic operations; fewer I O ops per state update; and far fewer total files on the filesystem.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 29 Oct 2014 01:09:03 +0000,Fri; 24 Apr 2015 23:15:17 +0000,Mon; 26 Jan 2015 16:33:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6141
MAPREDUCE-6142,Sub-task,Critical,,Test failure in TestJobHistoryEventHandler and TestMRTimelineEventHandling,nan,Closed,Fixed,,Zhijie Shen,Zhijie Shen,Wed; 29 Oct 2014 06:25:46 +0000,Mon; 1 Dec 2014 03:09:16 +0000,Wed; 29 Oct 2014 17:00:50 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6142
MAPREDUCE-6143,Improvement,Major,mrv2,add configuration for  mapreduce speculative execution in MR2,add configuration for  mapreduce speculative execution in MR2. Currently mapreduce.job.speculative.speculativecap and mapreduce.job.speculative.slownodethreshold are not used for MR2 mapreduce speculative execution any more.  We should make the following hardcode constants in DefaultSpeculator configurable for MR2 Map Reduce speculative execution:  private static final long SOONEST_RETRY_AFTER_NO_SPECULATE = 1000L * 1L; private static final long SOONEST_RETRY_AFTER_SPECULATE = 1000L * 15L; private static final double PROPORTION_RUNNING_TASKS_SPECULATABLE = 0.1; private static final double PROPORTION_TOTAL_TASKS_SPECULATABLE = 0.01; private static final int MINIMUM_ALLOWED_SPECULATIVE_TASKS = 10;,Closed,Fixed,,zhihai xu,zhihai xu,Thu; 30 Oct 2014 04:20:59 +0000,Fri; 24 Apr 2015 23:15:15 +0000,Mon; 2 Feb 2015 21:54:45 +0000,,2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6143
MAPREDUCE-6144,Bug,Major,mrv2,DefaultSpeculator always add both MAP and REDUCE Speculative task even MAP_SPECULATIVE or REDUCE_SPECULATIVE is disabled.,DefaultSpeculator always add both MAP and REDUCE Speculative task even MAP_SPECULATIVE or REDUCE_SPECULATIVE is disabled. If both MAP_SPECULATIVE and REDUCE_SPECULATIVE are disabled;  DefaultSpeculator won't start. The issue will happen if only one of MAP_SPECULATIVE and REDUCE_SPECULATIVE is enabled; both MAP and REDUCE Speculative task  are generate.,Resolved,Not A Problem,,zhihai xu,zhihai xu,Thu; 30 Oct 2014 04:34:06 +0000,Tue; 25 Nov 2014 08:25:14 +0000,Tue; 25 Nov 2014 08:25:14 +0000,,2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6144
MAPREDUCE-6145,Bug,Trivial,,No space in an error output message,nzhdusr@nhga0007 ~$ hadoop job -history ~ historydoes not exist,Resolved,Not A Problem,,Dasha Boudnik,Anton Balashov,Mon; 20 Jan 2014 05:59:01 +0000,Tue; 17 Mar 2015 09:58:25 +0000,Tue; 17 Mar 2015 09:58:25 +0000,,1.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6145
MAPREDUCE-6146,Improvement,Critical,build,Reduce tar ball size for MR over distributed cache,"The current tar ball built from ""mvn package -Pdist -DskipTests -Dtar"" is over 160M in size. We need more smaller tar ball pieces for feature like MR over distributed cache to support Rolling update of cluster.",Open,Unresolved,,Junping Du,Junping Du,Wed; 8 Oct 2014 17:27:34 +0000,Thu; 12 May 2016 21:22:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6146
MAPREDUCE-6147,Bug,Minor,mrv1,Support mapreduce.input.fileinputformat.split.maxsize,support mapreduce.input.fileinputformat.split.maxsize in MR1 mapred. Hive use mapred API; Hive expects mapred.max.split.size and mapreduce.input.fileinputformat.split.maxsize should be equivalent in MR1.,Resolved,Fixed,,zhihai xu,zhihai xu,Fri; 31 Oct 2014 23:00:40 +0000,Mon; 3 Nov 2014 23:57:56 +0000,Mon; 3 Nov 2014 23:55:59 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6147
MAPREDUCE-6148,Bug,Major,client,Consolidate copying regular files/jars; log4j file and tar ball files,There're code duplication among copying regular files jars; log4j file and tar ball files. We need to consolidate them.,Open,Unresolved,,Junping Du,Zhijie Shen,Sat; 1 Nov 2014 07:54:07 +0000,Sat; 1 Nov 2014 07:54:30 +0000,,,,,,MAPREDUCE-6052,https://issues.apache.org/jira/browse/MAPREDUCE-6148
MAPREDUCE-6149,Improvement,Major,documentation,Document override log4j.properties in MR job,This new feature comes from MAPREDUCE-6052; some documentation requirements from Vinod below:     Document the new config in mapred-default.xml     Mention in that documentation that if no-scheme is given in the path; it defaults to a log4j file on the local FS.     Modify the documentation of log-level configs to say that if you override to have your own log4j.properties file; the log-level configs may not work.,Closed,Fixed,,Junping Du,Junping Du,Sun; 2 Nov 2014 04:44:48 +0000,Fri; 24 Apr 2015 23:15:15 +0000,Tue; 30 Dec 2014 17:44:27 +0000,,,,,MAPREDUCE-6052,https://issues.apache.org/jira/browse/MAPREDUCE-6149
MAPREDUCE-6150,Improvement,Minor,documentation,Update document of Rumen,nan,Closed,Fixed,,Masatake Iwasaki,Masatake Iwasaki,Sat; 27 Sep 2014 10:33:33 +0000,Fri; 24 Apr 2015 23:15:13 +0000,Thu; 29 Jan 2015 22:18:56 +0000,,,,,HADOOP-10954,https://issues.apache.org/jira/browse/MAPREDUCE-6150
MAPREDUCE-6151,Improvement,Minor,documentation,Update document of GridMix,nan,Closed,Fixed,,Masatake Iwasaki,Masatake Iwasaki,Sat; 27 Sep 2014 10:32:05 +0000,Fri; 24 Apr 2015 23:15:17 +0000,Fri; 30 Jan 2015 19:09:31 +0000,,,,,HADOOP-10954,https://issues.apache.org/jira/browse/MAPREDUCE-6151
MAPREDUCE-6152,Test,Minor,,TestUberAM occasionally fails in trunk,From https: console :,Resolved,Cannot Reproduce,,Unassigned,Ted Yu,Thu; 6 Nov 2014 15:15:44 +0000,Sun; 1 Feb 2015 01:59:35 +0000,Sun; 1 Feb 2015 01:59:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6152
MAPREDUCE-6153,Improvement,Major,applicationmaster,Apply `mapreduce.admin.user.env' to AM,Would be nice to be able to manipulate the AM's library path to include snappy. The `mapreduce.admin.user.env' seems perfect for this; except that it only affects the tasks. I think it's useful to have it apply to the AM as well.  Use case: I have a job that uses the output committer (which runs in the AM) to read the output file of the reducer; which is compressed using snappy.,Resolved,Not A Problem,,Unassigned,bc Wong,Thu; 6 Nov 2014 23:34:51 +0000,Thu; 13 Nov 2014 16:29:59 +0000,Thu; 13 Nov 2014 16:29:59 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6153
MAPREDUCE-6154,Bug,Major,client,mapreduce.job.maps is reset to splits by JobSubmitter with using new-api. Value of mapreduce.job.maps should be used if it's less than splits as using old-api.,nan,Open,Unresolved,,Unassigned,PENG Yongyi,Tue; 11 Nov 2014 06:28:23 +0000,Tue; 10 Mar 2015 04:30:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6154
MAPREDUCE-6155,Bug,Major,,MapFiles are not always correctly detected by SequenceFileInputFormat,"MapFiles are not correctly detected by SequenceFileInputFormat.  This is because the listStatus method only detects a MapFile correctly if the path it checks is a directory - it then replaces it by the path of the data file.  This is likely to fail if the data file does not exist; i.e.; if the input path is a directory; but does not belong to a MapFile; or if recursion is turned on and the input format comes across a file (not a directory) which is indeed part of a MapFile.  The listStatus method should be changed to detect these cases correctly:  	if the current candidate is a file and its name is ""index"" or ""data""; check if its corresponding other file exists; and if the key types of both files match and if the value type of the index file is LongWritable 	If the current candidate is a directory; it is only a MapFile if (and only if) an index and a data file exist; they are both SequenceFiles and their key types match (and the index value type is LongWritable)",Patch Available,Unresolved,,Unassigned,Jens Rabe,Tue; 11 Nov 2014 15:57:53 +0000,Wed; 6 May 2015 03:27:21 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6155
MAPREDUCE-6156,Bug,Blocker,,Fetcher - connect() doesn't handle connection refused correctly ,"The connect() function in the fetcher assumes that whenever an IOException is thrown; the amount of time passed equals ""connectionTimeout"" ( see code snippet below ). This is incorrect. For example; in case the NM is down; an ConnectException is thrown immediately - and the catch block assumes a minute has passed when it is not the case.",Closed,Fixed,MAPREDUCE-6157,Junping Du,Sidharta Seethana,Wed; 12 Nov 2014 01:41:19 +0000,Mon; 1 Dec 2014 03:07:28 +0000,Thu; 13 Nov 2014 16:02:05 +0000,,,,,MAPREDUCE-5891,https://issues.apache.org/jira/browse/MAPREDUCE-6156
MAPREDUCE-6157,Bug,Critical,,Connect failed in shuffle (due to NM down) could break current retry logic to tolerant NM restart.,The connection failure log during NM restart is as following:   We have some code to handle the retry logic for connection with a timeout (as below). But if connection get refused quickly; we only try very limited times and it get failed also quickly.    We should fix this to make retry can continue until timeout.,Resolved,Duplicate,MAPREDUCE-6156,Junping Du,Junping Du,Wed; 12 Nov 2014 05:24:51 +0000,Wed; 12 Nov 2014 14:33:39 +0000,Wed; 12 Nov 2014 06:30:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6157
MAPREDUCE-6158,Bug,Major,jobhistoryserver;mrv2,No log of JobHistory found in every logs.,"I intend to dig into 'mapreduce.jobhistory.intermediate-done-dir' argument; the position of which is at `JHAdminConfig:73`; to get some comprehension on history server. This argument is referenced at `JobHistoryEventHandler.moveToDoneNow()`; where history server moves job summary file from ""${yarn.app.mapreduce.am.staging-dir} ${user}"".   Since the following code snippet in `moveToDoneNow()` will definitely write some logs out to log file; but I can found no any sign of it in all logs in $HADOOP_LOG_DIR via command `grep ""Copied to done location"" *`.     if (copied)         LOG.info(""Copied to done location: "" + toPath);     else          LOG.info(""copy failed"");  Is there anything that I missed?",Open,Unresolved,,Unassigned,JasonZhu,Wed; 12 Nov 2014 08:14:55 +0000,Wed; 12 Nov 2014 08:14:55 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6158
MAPREDUCE-6159,Bug,Major,jobhistoryserver;mrv2,No log of JobHistory found in all logs files,"I intend to dig into 'mapreduce.jobhistory.intermediate-done-dir' argument; the position of which is at `JHAdminConfig:73`; to get some comprehension on history server. This argument is referenced at `JobHistoryEventHandler.moveToDoneNow()`; where history server moves job summary file  from ""$yarn.app.mapreduce.am.staging-dir $user"".   The following code snippet in `moveToDoneNow()` will definitely write some logs out to log file; but I can found no any sign of it in all logs in $HADOOP_LOG_DIR via command `grep ""Copied to done location"" *`.     if (copied)         LOG.info(""Copied to done location: "" + toPath);     else          LOG.info(""copy failed"");  Is there anything that I missed?",Resolved,Invalid,,Unassigned,JasonZhu,Wed; 12 Nov 2014 08:15:08 +0000,Wed; 12 Nov 2014 14:36:29 +0000,Wed; 12 Nov 2014 14:36:29 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6159
MAPREDUCE-6160,Bug,Major,,Potential NullPointerException in MRClientProtocol interface implementation.,In the implementation of MRClientProtocol; many methods can throw NullPointerExceptions. Instead of NullPointerExceptions; better to throw IOException with proper message.  In the HistoryClientService class and MRClientService class has #verifyAndGetJob() method that return job object as null.,Closed,Fixed,,Rohith Sharma K S,Rohith Sharma K S,Wed; 12 Nov 2014 09:37:05 +0000,Fri; 24 Apr 2015 23:15:14 +0000,Mon; 1 Dec 2014 22:41:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6160
MAPREDUCE-6161,Bug,Major,scripts,mapred hsadmin command missing from trunk,The hsadmin subcommand of the mapred script is no longer present in trunk. It is present in branch-2.,Resolved,Fixed,,Allen Wittenauer,Jason Lowe,Thu; 13 Nov 2014 18:58:59 +0000,Thu; 12 May 2016 18:22:46 +0000,Fri; 14 Nov 2014 21:12:02 +0000,,,,,HADOOP-11010,https://issues.apache.org/jira/browse/MAPREDUCE-6161
MAPREDUCE-6162,Bug,Blocker,jobhistoryserver,mapred hsadmin fails on a secure cluster,"Attempts to use mapred hsadmin fail on a secure cluster for a couple of reasons. The HSAdmin client isn't configuring the principal config key for the protocol; resulting in a ""Failed to specify server's Kerberos principal name"" error.  The principal can be specified manually on the command-line via -Dhadoop.security.service.user.name.key; but then it results in a ""Protocol interface ... is not known"" error because HSAdminServer is not registering an appropriately configured policy provider when authorization is enabled.",Closed,Fixed,,Jason Lowe,Jason Lowe,Fri; 14 Nov 2014 16:42:11 +0000,Fri; 10 Apr 2015 20:19:41 +0000,Mon; 17 Nov 2014 23:02:41 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6162
HADOOP-11309,Bug,Blocker,,System class pattern package.Foo should match package.Foo$Bar; too,Currently when job classloader is enabled and the user specifies package.Foo as a system class explicitly; nested classes are not considered system classes.,Closed,Fixed,,Gera Shegalov,Gera Shegalov,Sun; 16 Nov 2014 07:03:04 +0000,Fri; 10 Apr 2015 20:04:45 +0000,Tue; 18 Nov 2014 17:25:56 +0000,,2.5.0;2.6.0,,,MAPREDUCE-6128,https://issues.apache.org/jira/browse/HADOOP-11309
MAPREDUCE-6164,Bug,Major,,mapreduce.reduce.shuffle.fetch.retry.timeout-ms should be set to 3 minutes instead of 30 seconds by default to be consistent with other retry timeout ,"In MAPREDUCE-5891; we are adding retry logic to MAPREDUCE shuffle stage for fetcher can be survival during NM downtime (with shuffle service down as well). In many places; we are setting the default timeout to be 3 minutes (connection timeout; etc.) to tolerant possible more time for NM down; but we are making ""mapreduce.reduce.shuffle.fetch.retry.timeout-ms"" to be 30 seconds which is not consistent here. We should change this to 180 seconds.",Resolved,Won't Fix,,Junping Du,Junping Du,Mon; 17 Nov 2014 12:23:36 +0000,Sat; 3 Dec 2016 01:29:53 +0000,Sat; 3 Dec 2016 01:29:53 +0000,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6164
MAPREDUCE-6165,Bug,Minor,,[JDK8] TestCombineFileInputFormat failed on JDK8,The error msg:,Resolved,Fixed,,Akira Ajisaka,Wei Yan,Tue; 18 Nov 2014 20:09:15 +0000,Thu; 7 Dec 2017 23:30:22 +0000,Tue; 5 May 2015 01:25:13 +0000,,,,,HADOOP-11090;MAPREDUCE-6292,https://issues.apache.org/jira/browse/MAPREDUCE-6165
MAPREDUCE-6166,Bug,Major,mrv2,Reducers do not validate checksum of map outputs when fetching directly to disk,In very large map reduce jobs (50000 maps; 2500 reducers); the intermediate map partition output gets corrupted on disk on the map side. If this corrupted map output is too large to shuffle in memory; the reducer streams it to disk without validating the checksum. In jobs this large; it could take hours before the reducer finally tries to read the corrupted file and fails. Since retries of the failed reduce attempt will also take hours; this delay in discovering the failure is multiplied greatly.,Closed,Fixed,,Eric Payne,Eric Payne,Wed; 19 Nov 2014 15:54:35 +0000,Tue; 30 Aug 2016 01:19:35 +0000,Tue; 16 Dec 2014 03:29:44 +0000,,2.6.0,2.6.1-candidate,,,https://issues.apache.org/jira/browse/MAPREDUCE-6166
MAPREDUCE-6167,Bug,Major,,Prior 2.4 MR has compatibility issue because o.a.h.http.HttpConfig.setPolicy is removed,a. In the following scenarios:  1. Either insecure or secure; 2. MR 2.2 with either old or new shuffle handler on NM; 3. Submitting via new client.  We will see the following console exception:     b. In the following scenarios:  1. Either insecure or secure; 2. MR 2.2 with old shuffle on NM; 3. Submitting via old client.  We will see the following exception in the AM Log:     The two exceptions are actually the same problem; but using the old client prevents it happening during app submission.  o.a.h.http.HttpConfig.setPolicy is removed by YARN-1553 in 2.4. It could be a hadoop-common issue; but keep it in MR now.,Open,Unresolved,YARN-1553,Unassigned,Zhijie Shen,Wed; 19 Nov 2014 20:26:14 +0000,Wed; 19 Nov 2014 20:29:04 +0000,,,,,,YARN-2879,https://issues.apache.org/jira/browse/MAPREDUCE-6167
MAPREDUCE-6168,Bug,Blocker,,Old MR client is still broken when receiving new counters from MR job,In the following scenarios:  1. Either insecure or secure; 2. MR 2.2 with new shuffle on NM; 3. Submitting via old client.  We will see the following console exception:    The problem is supposed to be fixed by MAPREDUCE-5831; however; it seems that we haven't cover all the problematic code path.,Resolved,Won't Fix,,Junping Du,Zhijie Shen,Wed; 19 Nov 2014 20:34:46 +0000,Mon; 1 Dec 2014 13:17:28 +0000,Mon; 1 Dec 2014 13:17:28 +0000,,,,,YARN-2879;MAPREDUCE-5831,https://issues.apache.org/jira/browse/MAPREDUCE-6168
MAPREDUCE-6169,Improvement,Major,mrv2,MergeQueue should release reference to the current item from key and value at the end of the iteration to save memory.,MergeQueue should release reference to the current item from key and value at the end of the iteration to save memory. these buffers referenced by key and value can be large; which may cause an OOM error.,Closed,Fixed,,zhihai xu,zhihai xu,Thu; 20 Nov 2014 01:16:45 +0000,Fri; 24 Apr 2015 23:15:16 +0000,Thu; 20 Nov 2014 23:39:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6169
MAPREDUCE-6170,Bug,Major,contrib/streaming,TestUlimit failure on JDK8,TestUlimit#testCommandLine fails on JDK8; because the map task JVM fails to launch. We're setting the virtual memory limit too low; and the JVM errors out with: Could not allocate metaspace,Resolved,Fixed,,bc Wong,bc Wong,Thu; 20 Nov 2014 21:55:38 +0000,Thu; 20 Nov 2014 23:14:26 +0000,Thu; 20 Nov 2014 23:14:26 +0000,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6170
MAPREDUCE-6171,Bug,Major,security,The visibilities of the distributed cache files and archives should be determined by both their permissions and if they are located in HDFS encryption zone,"The visibilities of the distributed cache files and archives are currently determined by the permission of these files or archives.  The following is the logic of method isPublic() in class ClientDistributedCacheManager:   At NodeManager side; it will use ""yarn"" user to download public files and use the user who submits the job to download private files. In normal cases; there is no problem with this. However; if the files are located in an encryption zone(HDFS-6134) and yarn user are configured to be disallowed to fetch the DataEncryptionKey(DEK) of this encryption zone by KMS; the download process of this file will fail.   You can reproduce this issue with the following steps (assume you submit job with user ""testUser""):   	create a clean cluster which has HDFS cryptographic FileSystem feature 	create directory "" "" in HDFS and make it as an encryption zone with keyName ""testKey"" 	configure KMS to only allow user ""testUser"" can decrypt DEK of key ""testKey"" in KMS   	execute job ""teragen"" with user ""testUser"":   	execute job ""terasort"" with user ""testUser"":      You will see logs like this at the job submitter's console:    The initial idea to solve this issue is to modify the logic in ClientDistributedCacheManager.isPublic to consider also whether this file is in an encryption zone. If it is in an encryption zone; this file should be considered as private. Then at NodeManager side; it will use user who submits the job to fetch the file.",Closed,Duplicate,HADOOP-11341,Unassigned,Dian Fu,Mon; 24 Nov 2014 10:15:44 +0000,Tue; 30 Jun 2015 07:18:57 +0000,Tue; 2 Dec 2014 06:01:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6171
MAPREDUCE-6172,Bug,Minor,test,TestDbClasses timeouts are too aggressive,Some of the TestDbClasses test timeouts are only 1 second; and some of those tests perform disk I O which could easily exceed the test timeout if the disk is busy or there's some other hiccup on the system at the time.  We should increase these timeouts to something more reasonable (i.e.: 10 or 20 seconds).,Closed,Fixed,,Varun Saxena,Jason Lowe,Mon; 24 Nov 2014 22:29:48 +0000,Fri; 10 Apr 2015 20:19:39 +0000,Mon; 1 Dec 2014 21:53:55 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6172
MAPREDUCE-6173,Improvement,Major,distributed-cache;documentation,Document the configuration of deploying MR over distributed cache with enabling wired encryption at the same time,Use the current documented configuration (specified in http: EncryptedShuffle.html) will cause the job failed with exception below:   This is due to ssl-client.xml is not included in MR tar ball when we deploy it over distributed cache. Putting the ssl-client.xml on CLASSPATH of MR job can resolve the problem and we should document it.,Closed,Fixed,,Junping Du,Junping Du,Tue; 25 Nov 2014 15:33:33 +0000,Fri; 24 Apr 2015 23:15:14 +0000,Tue; 13 Jan 2015 18:10:59 +0000,,2.6.0,,,MAPREDUCE-4421,https://issues.apache.org/jira/browse/MAPREDUCE-6173
MAPREDUCE-6174,Improvement,Major,mrv2,Combine common stream code into parent class for InMemoryMapOutput and OnDiskMapOutput.,Per MAPREDUCE-6166; both InMemoryMapOutput and OnDiskMapOutput will be doing similar things with regards to IFile streams.  In order to make it explicit that InMemoryMapOutput and OnDiskMapOutput are different from 3rd-party implementations; this JIRA will make them subclass a common class (see https: MAPREDUCE-6166?focusedCommentId=14223368page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14223368),Resolved,Fixed,,Eric Payne,Eric Payne,Wed; 26 Nov 2014 15:25:25 +0000,Tue; 30 Aug 2016 01:19:34 +0000,Thu; 4 Jun 2015 00:06:02 +0000,,2.6.0;3.0.0-alpha1,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-6174
YARN-2909,Bug,Major,,RM failover lead to failure to recognize previously running application attempt,Seeing this from client side (Hive job):  2014-11-25 10:00:50;179 Stage-3 map = 100%;  reduce = 99%; Cumulative CPU 136560.72 sec 2014-11-25 10:00:54;776 Stage-3 map = 100%;  reduce = 0%; Cumulative CPU 42627.6 sec 2014-11-25 10:01:20;097 Stage-3 map = 0%;  reduce = 0% 2014-11-25 10:02:20;348 Stage-3 map = 0%;  reduce = 0% 2014-11-25 10:02:30;702 Stage-3 map = 1%;  reduce = 0%; Cumulative CPU 1511.98 sec     Seeing this on resource manager (rm2):  14:16:hadoop@phxaishdc20en0008-be:logs# grep container_1416845430616_0009_01_000001 * hadoop-hadoop-resourcemanager.log.2014-11-25-10:2014-11-25 10:01:09;757 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: received container statuses on node manager register :[ContainerStatus: ContainerId: container_1416845430616_0009_01_000001; State: COMPLETE; Diagnostics: ; ExitStatus: 0; ; ContainerStatus: [ContainerId: container_1416845430616_0014_01_000241; State: COMPLETE; Diagnostics: Container Killed by ResourceManager  Seeing this in container log (Logs for container_1416845430616_0009_01_000001) 2014-11-25 10:59:17;839 INFO IPC Server handler 2 on 36552 org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt tempt_1416845430616_0009_r_000000_1 TaskAttempt Transitioned from NEW to UNASSIGNED 2014-11-25 11:00:52;958 INFO Thread-3928 org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:414 CompletedReds:0 ContAlloc:827 ContRel:411 HostLocal:298 RackLocal:108 2014-11-25 11:00:52;961 INFO Thread-3928 org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Skipping cleaning up the staging dir. assuming AM will be retried. 2014-11-25 11:00:52;962 INFO Thread-3928 org.apache.hadoop.ipc.Server: Stopping server on 36552 2014-11-25 11:00:52;968 INFO IPC Server listener on 36552 org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 36552 2014-11-25 11:00:52;968 INFO IPC Server Responder org.apache.hadoop.ipc.Server: Stopping IPC Server Responder 2014-11-25 11:00:52;968 INFO TaskHeartbeatHandler PingChecker org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted,Resolved,Won't Fix,,Unassigned,Cindy Li,Wed; 26 Nov 2014 23:02:22 +0000,Fri; 1 May 2015 22:02:23 +0000,Fri; 1 May 2015 22:02:23 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-2909
MAPREDUCE-6176,New Feature,Major,mr-am;mrv2,To limit the map task number or reduce task number of an application,As MapReduce is a batch framework of calculation; so people may want to run application A as well as application B  C; and a limit resource be put on A. A good way to do so is that we can limit the number of application's map task or reduce task. If we set mapreduce.map.num.max as M; then the map task number will not exceed M. At the same time; if we set mapreduce.map.num.max as R; then the reduce task number will not exceed R,Resolved,Duplicate,MAPREDUCE-5583,Yang Hao,Yang Hao,Thu; 27 Nov 2014 08:41:45 +0000,Thu; 9 Apr 2015 09:16:53 +0000,Thu; 9 Apr 2015 09:16:52 +0000,,2.4.0;2.5.0;2.4.1;2.5.1;2.5.2,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-6176
MAPREDUCE-6177,Bug,Trivial,documentation,Minor typo in the EncryptedShuffle document about ssl-client.xml,The installation documentation for Hadoop MapReduce EncryptedShuffle document has some error entry(http: Fetcher) Configuration: section   the The mapred user should own the ssl-server.xml file and it should have default permissions.  should be The mapred user should own the ssl-client.xml file and it should have default permissions.,Closed,Fixed,,wyp,wyp,Wed; 3 Dec 2014 03:57:59 +0000,Fri; 24 Apr 2015 23:15:17 +0000,Mon; 8 Dec 2014 10:30:39 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6177
MAPREDUCE-6178,Bug,Major,,MRAppBenchmark.benchmark1() error,"when running the test; it ouputs an exception:"" lang.NullPointerException""",Resolved,Cannot Reproduce,,Yang Hao,Yang Hao,Wed; 3 Dec 2014 09:08:49 +0000,Fri; 3 Apr 2015 13:32:50 +0000,Fri; 3 Apr 2015 13:32:50 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6178
MAPREDUCE-6179,Bug,Major,mrv2,Running any MapReduce jobs is throwing Heap Error,"I have a hadoop distribution installed on a cluster with 1 namenode and 2 data nodes. I have been trying to run the default mapreduce example included in the hadoop package and its been throwing the following error :  ""Error occurred during initialization of VM Could not reserve enough space for object heap""  The complete message test is as following :  192769@hawq  hadoop-mapreduce-examples-2.2.0-gphd-3.0.1.0.jar pi 10 100 Number of Maps  = 10 Samples per Map = 100 Wrote input for Map #0 Wrote input for Map #1 Wrote input for Map #2 Wrote input for Map #3 Wrote input for Map #4 Wrote input for Map #5 Wrote input for Map #6 Wrote input for Map #7 Wrote input for Map #8 Wrote input for Map #9 Starting Job   INFO client.RMProxy: Connecting to ResourceManager   606)  Please help understand what is causing this error as all installation steps were followed to the word.",Resolved,Invalid,,Unassigned,Ketan Deshmukh,Thu; 4 Dec 2014 13:12:53 +0000,Wed; 3 Jun 2015 11:18:20 +0000,Wed; 3 Jun 2015 11:18:20 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6179
HADOOP-11354,Bug,Major,,ThrottledInputStream doesn't perform effective throttling,This was first reported in HBASE-12632 by Tobi Vollebregt :  I just transferred a ton of data using ExportSnapshot with bandwidth throttling from one Hadoop cluster to another Hadoop cluster; and discovered th for big enough buffer sizes; ThrottledInputStream will be throttling only the number of read calls to 20 per second; disregarding the number of bytes read.,Closed,Fixed,,Ted Yu,Ted Yu,Fri; 5 Dec 2014 00:03:35 +0000,Fri; 24 Apr 2015 22:48:59 +0000,Mon; 8 Dec 2014 19:11:43 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-11354
MAPREDUCE-6181,Improvement,Trivial,,WordCount.java in mapreduce-examples.jar uses deprecated job object creation API,In the trunk branch the mapreduce-examples.jar contains a WordCount class. In which deprecated Job object has been used. So this Jira is to fix the deprecation warning.,Resolved,Duplicate,MAPREDUCE-5800,Arijit Chattopadhyay,sachin,Sat; 6 Dec 2014 20:31:11 +0000,Tue; 10 Mar 2015 04:30:19 +0000,Sun; 8 Feb 2015 23:54:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6181
MAPREDUCE-6182,Bug,Major,contrib/gridmix,Fix findbugs warnings in gridmix,Work on MAPREDUCE-5800 has exposed some findbugs warnings. https: newPatchFindbugsWarningshadoop-gridmix.html,Resolved,Not A Problem,,Varun Saxena,Akira Ajisaka,Mon; 8 Dec 2014 05:55:48 +0000,Tue; 9 Dec 2014 06:37:19 +0000,Tue; 9 Dec 2014 06:37:19 +0000,,,findbugs;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6182
MAPREDUCE-6183,Bug,Major,examples,Fix findbugs warnings in mapreduce-examples,Work on MAPREDUCE-5800 has exposed some findbugs warnings.  https: newPatchFindbugsWarningshadoop-mapreduce-examples.html,Resolved,Not A Problem,,Rohith Sharma K S,Akira Ajisaka,Mon; 8 Dec 2014 05:57:49 +0000,Tue; 9 Dec 2014 06:36:01 +0000,Tue; 9 Dec 2014 06:36:01 +0000,,,findbugs;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6183
MAPREDUCE-6184,Bug,Major,,Fix findbugs warnings in mapreduce-client-core,Work on MAPREDUCE-5800 has exposed some findbugs warnings. https: newPatchFindbugsWarningshadoop-mapreduce-client-core.html,Resolved,Not A Problem,,Varun Saxena,Akira Ajisaka,Mon; 8 Dec 2014 06:00:13 +0000,Tue; 9 Dec 2014 06:38:27 +0000,Tue; 9 Dec 2014 06:38:05 +0000,,,findbugs;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6184
MAPREDUCE-6185,Bug,Minor,jobhistoryserver,YARN M/R may return NaN for reducer progress after Job completion,nan,Resolved,Cannot Reproduce,,Weiwei Yang,sam liu,Mon; 8 Dec 2014 08:46:14 +0000,Fri; 28 Aug 2015 05:22:14 +0000,Fri; 28 Aug 2015 05:21:21 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6185
MAPREDUCE-6186,Bug,Minor,jobhistoryserver,Redundant call to requireJob() while displaying the conf page,There are multiple calls to requireJob() in AppController. conf()  The duplicate call seems to be introduced by mistake in https: fe1cf3b0aca5f4d7a8af02a915b218f9b1de0fa6,Closed,Fixed,,Rohit Agarwal,Rohit Agarwal,Mon; 8 Dec 2014 20:11:38 +0000,Fri; 24 Apr 2015 23:15:16 +0000,Thu; 5 Feb 2015 20:14:35 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6186
MAPREDUCE-6187,Bug,Major,,DBInputFormat can't pick driver class from *-job.jar/lib,Assume package structure:     Where: MyProcess.class sets up DbInputFormat.  If I call:    I will get ClassNotFoundException when DBConfiguration does     The fix may be:    As suggested by Shixiong Zhu: http: %3CCADHSSLM-aE0JsAwJPmwmuEUTWL98_iYsqrYxZn+ft-8X_pNakA@mail.gmail.com%3E,Open,Unresolved,,Unassigned,Dzianis Sokal,Tue; 9 Dec 2014 12:41:36 +0000,Tue; 9 Dec 2014 12:41:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6187
MAPREDUCE-6188,Bug,Major,,"LocalJobRunner getJobStatus is returning ""null"" for the submitted jobs ","LocalJobRunner getJobStatus method is returning ""null"" status when Oozie is trying to get status of submitted local Hadoop jobs. This issue has blocked some of the critical test cases of Falcon to execute.",Open,Unresolved,,Unassigned,Peeyush Bishnoi,Wed; 10 Dec 2014 11:59:45 +0000,Wed; 10 Dec 2014 14:47:19 +0000,,,2.5.0;2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6188
MAPREDUCE-6189,Test,Major,,TestMRTimelineEventHandling fails in trunk,From https: :,Resolved,Duplicate,HADOOP-11815;MAPREDUCE-6202,Unassigned,Ted Yu,Wed; 10 Dec 2014 17:33:55 +0000,Mon; 13 Apr 2015 15:11:40 +0000,Mon; 13 Apr 2015 15:11:14 +0000,,,,MAPREDUCE-6327,HADOOP-11815;YARN-2637,https://issues.apache.org/jira/browse/MAPREDUCE-6189
MAPREDUCE-6190,Bug,Major,,MR Job is stuck because of one mapper stuck in STARTING,Trying to figure out a weird issue we started seeing on our CDH5.1.0 cluster with map reduce jobs on YARN.  We had a job stuck for hours because one of the mappers never started up fully. Basically; the map task had 2 attempts; the first one failed and the AM tried to schedule a second one and the second attempt was stuck on STATE: STARTING; STATUS: NEW. A node never got assigned and the task along with the job was stuck indefinitely.  The AM logs had this being logged again and again:     On killing the task manually; the AM started up the task again; scheduled and ran it successfully completing the task and the job with it.  Some quick code grepping led us here: http: RMContainerAllocator. 397  But still dont quite understand why this would happen once in a while and why the job would suddenly be ok once the stuck task is manually killed.  Note: Other jobs succeed on the cluster while this job is stuck.,Open,Unresolved,,Unassigned,Ankit Malhotra,Wed; 10 Dec 2014 20:29:20 +0000,Wed; 27 Jan 2016 21:20:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6190
MAPREDUCE-6191,Test,Minor,test,TestJavaSerialization fails with getting incorrect MR job result,"TestJavaSerialization#testMapReduceJob() fails with getting incorrect MR job result: ""junit.framework.ComparisonFailure: expected:a 1 but was:0 11""",Closed,Fixed,,sam liu,sam liu,Thu; 11 Dec 2014 03:21:36 +0000,Fri; 6 Jan 2017 01:52:03 +0000,Tue; 16 Dec 2014 03:40:58 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6191
MAPREDUCE-6192,Improvement,Minor,,Create unit test to automatically compare MR related classes and mapred-default.xml,Create a unit test that will automatically compare the fields in the various MapReduce related classes and mapred-default.xml. It should throw an error if a property is missing in either the class or the file.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Fri; 12 Dec 2014 20:04:06 +0000,Tue; 30 Aug 2016 01:19:32 +0000,Tue; 5 May 2015 21:50:39 +0000,,2.6.0,supportability,MAPREDUCE-6358;MAPREDUCE-6057;HADOOP-11399,HDFS-7559,https://issues.apache.org/jira/browse/MAPREDUCE-6192
MAPREDUCE-6193,Bug,Major,mrv2,Hadoop 2.x MapReduce Job Counter Data Local Maps Lower than Hadoop 1.x,"I run the MapReduce job  the same priority request ; the Scheudler will get NPE ;and the ResourceManager will exit immediately   see this  public synchronized int getTotalRequiredResources(Priority) { 	return getResourceRequest(priority;RMNode.ANY).getNumContainers(); }   Anyone has ideas for those issues please comment.",Open,Unresolved,,Unassigned,Xu Chen,Sat; 13 Dec 2014 07:51:14 +0000,Sat; 7 Jan 2017 01:59:58 +0000,,,2.4.0,DataLocal;JobCounter;MAPREDUCE;YARN,,,https://issues.apache.org/jira/browse/MAPREDUCE-6193
MAPREDUCE-6194,Improvement,Minor,task,Bubble up final exception in failures during creation of output collectors,"MAPREDUCE-5974 added in ability to instantiate multiple OCs; but if none of them are able to load it ""throws"" only a final a generic message: ""Unable to initialize any output collector""  The older behaviour was to throw the actual instantiation exception back; so it makes it to client logs with an actual meaningful error.  Now the clients need to go take a look at the task's logs to find the WARNs that represent the failure in instantiation.",Closed,Fixed,,Varun Saxena,Harsh J,Sun; 14 Dec 2014 04:21:26 +0000,Fri; 24 Apr 2015 23:15:18 +0000,Mon; 15 Dec 2014 08:58:58 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6194
MAPREDUCE-6195,Improvement,Minor,,AM UI does not show splits/locality info ,The AM UI currently shows the tasks without indicating the locality or speculation of a task.  This information is available by reading it out of the logs later; but while tracking a slow straggler task; this is invaluable in finding separating the locality misses from other data-sensitive slow-downs or skews.,Open,Unresolved,,Unassigned,Gopal V,Thu; 11 Apr 2013 10:00:54 +0000,Mon; 15 Dec 2014 17:18:14 +0000,,,,usability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6195
MAPREDUCE-6196,Bug,Minor,,Fix BigDecimal ArithmeticException in PiEstimator,Certain combinations of arguments to PiEstimator cause the following exception:   208)  The calls to the BigDecimal methods should have some large default precision to prevent this exception.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Mon; 15 Dec 2014 18:50:39 +0000,Tue; 16 Dec 2014 01:57:58 +0000,Tue; 16 Dec 2014 01:57:58 +0000,,1.2.1,pi_example;supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6196
MAPREDUCE-6197,Bug,Major,,Cache MapOutputLocations in ShuffleHandler,ShuffleHandler currently seems to create a map of mapId - mapInfo (file.out   index file is performed twice per mapId within a request. In populateHeaders - once in the call to getMapOutputInfo; and then directly in the method.  For an invocation where we do end up with more than 1000 (default) mapIds in a single call; and don't cache them in the map - the path constructed for such entries will be invalid. This is highly unlikely to be the case though; until there's proper caching.,Resolved,Fixed,,Junping Du,Siddharth Seth,Tue; 16 Dec 2014 01:07:39 +0000,Tue; 30 Aug 2016 01:19:30 +0000,Tue; 21 Jun 2016 21:26:46 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6197
MAPREDUCE-6198,Bug,Major,mrv1,NPE from JobTracker#resolveAndAddToTopology in MR1 cause initJob and heartbeat failure.,NPE from JobTracker#resolveAndAddToTopology in MR1 cause initJob and heartbeat failure. The NPE is caused by dnsToSwitchMapping.resolve return null at the following:   I check the code in MR2; MR2 handle it correctly in coreResolve  of RackResolver.    We should do the same in MR1; if dnsToSwitchMapping.resolve return null; use NetworkTopology.DEFAULT_RACK.,Resolved,Fixed,,zhihai xu,zhihai xu,Thu; 18 Dec 2014 01:29:37 +0000,Fri; 19 Dec 2014 21:45:38 +0000,Fri; 19 Dec 2014 19:40:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6198
MAPREDUCE-6199,Bug,Major,,AbstractCounters are not reset completely on deserialization,AbstractCounters are partially reset on deserialization. This patch completely resets them.,Resolved,Won't Fix,HADOOP-10934;MAPREDUCE-2557,Anubhav Dhoot,Anubhav Dhoot,Fri; 19 Dec 2014 04:36:14 +0000,Mon; 31 Jul 2017 21:30:20 +0000,Mon; 31 Jul 2017 21:30:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6199
HADOOP-12730,Bug,Major,documentation,Hadoop streaming -mapper and -reducer options are wrongly documented as required,-reducer is listed as a Required option; but is a -reducer still required if the Streaming job is Map only?  http: streaming.html#Specifying+Map-Only+Jobs  -reducer should not be listed as a Required option.,Resolved,Fixed,,Kengo Seki,DeepakVohra,Fri; 19 Dec 2014 15:09:17 +0000,Tue; 30 Aug 2016 01:19:53 +0000,Fri; 22 Jan 2016 12:13:32 +0000,,,newbie;streaming,,,https://issues.apache.org/jira/browse/HADOOP-12730
MAPREDUCE-6201,Bug,Major,,TestNetworkedJob fails on trunk,Currently; TestNetworkedJob is failing on trunk:,Resolved,Fixed,,Peter Bacsko,Robert Kanter,Fri; 19 Dec 2014 23:37:46 +0000,Mon; 17 Apr 2017 15:42:15 +0000,Fri; 7 Apr 2017 00:45:00 +0000,,,,,MAPREDUCE-6508,https://issues.apache.org/jira/browse/MAPREDUCE-6201
MAPREDUCE-6202,Bug,Major,,TestMRTimelineEventHandling fails on trunk,Currently; TestMRTimelineEventHandling is failing on trunk:,Resolved,Duplicate,MAPREDUCE-6189,Zhijie Shen,Robert Kanter,Fri; 19 Dec 2014 23:37:47 +0000,Tue; 7 Apr 2015 17:36:53 +0000,Tue; 7 Apr 2015 17:36:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6202
MAPREDUCE-6203,Bug,Minor,jobhistoryserver,if log-aggregation is enable and run some MR job; the AM log will be aggregated.then disable it;then in MR JobHistoryServer and YARN RM UI link;the AM log cannot be visible,as the Summary description; I think for the MR JobHistory Server; should not let  yarn.log-aggregation-enable  affect the history job;even  yarn.log-aggregation-enable  is false.,Resolved,Not A Problem,,Unassigned,huangyitian,Mon; 22 Dec 2014 11:32:28 +0000,Wed; 18 Feb 2015 14:56:11 +0000,Wed; 18 Feb 2015 14:54:45 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6203
MAPREDUCE-6204,Test,Minor,test,TestJobCounters should use new properties instead of JobConf.MAPRED_TASK_JAVA_OPTS,nan,Resolved,Fixed,,sam liu,sam liu,Tue; 23 Dec 2014 03:45:03 +0000,Tue; 30 Aug 2016 01:19:26 +0000,Fri; 22 May 2015 14:31:47 +0000,,2.6.0,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-6204
MAPREDUCE-6205,Bug,Minor,mrv2,"Update the value of the new version properties of the deprecated property ""mapred.child.java.opts""","In current hadoop code; the old property ""mapred.child. opts""; otherwise it might bring some imcompatible issues.",Patch Available,Unresolved,,sam liu,sam liu,Wed; 24 Dec 2014 04:40:06 +0000,Wed; 6 May 2015 03:27:20 +0000,,,,BB2015-05-TBR,,MAPREDUCE-5130,https://issues.apache.org/jira/browse/MAPREDUCE-6205
MAPREDUCE-6206,Bug,Critical,,TestAggregatedTransferRate fails on non-US systems,When running the test TestAggregatedTransferRate from org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler on a non-US system (or; to be more precise; a system which does not use the point as a decimal separator); the test fails.  E.g. on a German system; the progress message is: copy task(attempt_test_0000_m_000000_0 succeeded at 1;00 MB s)  which causes it to fail.,Closed,Fixed,MAPREDUCE-6207,Jens Rabe,Jens Rabe,Thu; 25 Dec 2014 16:53:54 +0000,Fri; 24 Apr 2015 23:15:12 +0000,Tue; 6 Jan 2015 23:41:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6206
MAPREDUCE-6207,Bug,Critical,,TestAggregatedTransferRate fails on non-US systems,When running the test TestAggregatedTransferRate from org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler on a non-US system (or; to be more precise; a system which does not use the point as a decimal separator); the test fails.  E.g. on a German system; the progress message is: copy task(attempt_test_0000_m_000000_0 succeeded at 1;00 MB s)  which causes it to fail.,Resolved,Duplicate,MAPREDUCE-6206,Jens Rabe,Jens Rabe,Thu; 25 Dec 2014 16:54:07 +0000,Tue; 10 Mar 2015 04:30:46 +0000,Thu; 25 Dec 2014 16:55:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6207
MAPREDUCE-6208,Improvement,Major,,There should be an input format for MapFiles which can be configured so that only a fraction of the input data is used for the MR process,In some cases there are large amounts of data organized in MapFiles; e.g.; from previous MapReduce tasks; and only a fraction of the data is to be processed in a MR task. The current approach; as I understand; is to re-organize the data in a suitable partition using folders on HDFS; and only use relevant folders as input paths; and maybe doing some additional filtering in the Map task. However; sometimes the input data cannot be easily partitioned that way. For example; when processing large amounts of measured data where additional data on a time period already in HDFS arrives later.  There should be an input format that accepts folders with MapFiles; and there should be an option to specify the input key range so that only fitting InputSplits are generated.,Patch Available,Unresolved,,Jens Rabe,Jens Rabe,Sat; 27 Dec 2014 10:49:43 +0000,Wed; 6 May 2015 03:27:21 +0000,,,,BB2015-05-TBR;inputformat;mapfile,,,https://issues.apache.org/jira/browse/MAPREDUCE-6208
MAPREDUCE-6209,Improvement,Major,applicationmaster,Implement a heuristic to auto-size Java heap of MRAppMaster container proportional to the job size,The size of Java heap required by the AM is linearly proportional to the size of the MR job (number of mappers splits and reducers). it would be nice if users did not have to adjust the AM container size when transitioning from testing job on a small sample to a production job on a full-scale dataset.,Open,Unresolved,,Unassigned,Gera Shegalov,Sat; 3 Jan 2015 00:36:11 +0000,Wed; 21 Jan 2015 11:14:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6209
MAPREDUCE-6210,Bug,Minor,applicationmaster,Use getApplicationAttemptId() instead of getApplicationID() for logging AttemptId in RMContainerAllocator.java,It's confusing in the following codes of RMContainerAllocator. .      Here should be getApplicationAttemptId() instead of getApplicationID().,Closed,Fixed,,Leitao Guo,Leitao Guo,Mon; 5 Jan 2015 02:45:01 +0000,Fri; 10 Apr 2015 20:19:43 +0000,Wed; 14 Jan 2015 08:52:52 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6210
MAPREDUCE-6211,Bug,Major,,Update the MapReduce documentation post-shell rewrite,Post HADOOP-9902; the mapreduce command documentation is out of date.,Resolved,Duplicate,NULL,Unassigned,Allen Wittenauer,Mon; 5 Jan 2015 20:40:46 +0000,Fri; 13 Feb 2015 16:27:23 +0000,Fri; 13 Feb 2015 16:27:23 +0000,,,,,HADOOP-10908;HADOOP-11010,https://issues.apache.org/jira/browse/MAPREDUCE-6211
MAPREDUCE-6212,Bug,Major,security,UnsatisfiedLinkError: org.apache.hadoop.security.JniBasedUnixGroupsMapping.anchorNative() happened when starting MRAppMaster,"I have just started to work with Hadoop 2.  After installing with basic configs; I always failed to run any examples. Has anyone seen this problem and please help me?  This is the log  2015-01-08 01:52:01;599 INFO main org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1420648881673_0004_000001 2015-01-08 01:52:01;764 FATAL main org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster  io.tmpdir=$HADOOP_PREFIX tmp""",Resolved,Invalid,,Hoang-Mai Dinh,Hoang-Mai Dinh,Wed; 7 Jan 2015 17:00:16 +0000,Thu; 8 Jan 2015 20:39:45 +0000,Thu; 8 Jan 2015 20:39:45 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6212
MAPREDUCE-6213,Bug,Minor,applicationmaster,NullPointerException caused by job history server addr not resolvable,When DNS failed for a time; all MapReduce jobs which completed during that time got failed. Log as below:,Resolved,Fixed,,Peng Zhang,Peng Zhang,Thu; 8 Jan 2015 08:25:49 +0000,Tue; 30 Aug 2016 01:19:25 +0000,Sat; 21 Mar 2015 21:16:05 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6213
MAPREDUCE-6214,Bug,Major,task,MultipleOutputs output folders are not deleted when a task fails ,MultipleOutputs output directory not getting deleted before the next task attempt after a task fails. This in turn will cause the failure of subsequent tasks resulting in job failure.,Open,Unresolved,,Alwin James,Alwin James,Fri; 9 Jan 2015 12:05:28 +0000,Mon; 12 Jan 2015 06:21:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6214
MAPREDUCE-6215,Bug,Major,mrv1;mrv2,Map is not cleared in SortedMapWritable.readFields(DataInput in),The readFields(DataInput in) in SortedMapWritable doesn't reset the internally used SortedMap. If this Writable object is reused then entries will get accumulated in the map with every call of readFields().  I have seen this behavior when using SequenceFileInputFormat. See  SequenceFileRecordReader. and SequenceFile.Reader.,Open,Unresolved,,Ahmed Radwan,Ahmed Radwan,Tue; 13 Jan 2015 07:23:30 +0000,Sat; 7 Jan 2017 02:00:00 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6215
MAPREDUCE-6216,Bug,Critical,,"Seeking backwards in MapFiles does not always correctly sync the underlying SequenceFile; resulting in ""File is corrupt"" exceptions","In some occasions; when reading MapFiles which were generated by MapFileOutputFormat with BZIP2 BLOCK compression; using getClosest(key; value; true) on the MapFile reader causes an IOException to be thrown with the message ""File is corrupt!"" When doing ""hdfs fsck""; it shows that everything is OK; and the underlying data and index files can also be read correctly if read with a SequenceFile.Reader.  The exception happens in the readBlock() method of the SequenceFile.Reader class.  My guess is that; since MapFile.Reader's seekInternal() method does ""seek()"" instead of ""sync()""; it is not correctly checked if the cursor is really positioned at a valid location.",Open,Unresolved,,Unassigned,Jens Rabe,Thu; 15 Jan 2015 10:20:13 +0000,Thu; 15 Jan 2015 10:44:51 +0000,,,2.4.1,mapfile;sequencefile,,,https://issues.apache.org/jira/browse/MAPREDUCE-6216
MAPREDUCE-6217,Bug,Major,,DistCp return success even if it is killed,When a distcp job is killed by yarn application -kill; it does not report a failure to distcp caller.  This is due to: return DistCpConstants.SUCCESS; instead of the return code of the underlying job.,Open,Unresolved,,Unassigned,Mathieu Chataigner,Fri; 16 Jan 2015 16:50:57 +0000,Fri; 16 Jan 2015 17:19:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6217
HADOOP-11561,Improvement,Minor,,Join multiple files on the fly and read the records in order with a client,In a scenario where there are many files which all share the same key value types; e.g.; when dealing with measured data from sensors; it should be possible to join multiple files. That means; there should be a reader which can be supplied with one or more directories containing files; and it should be possible to read the records of all files in order.,Patch Available,Unresolved,,Jens Rabe,Jens Rabe,Sun; 18 Jan 2015 13:58:43 +0000,Wed; 6 May 2015 03:26:43 +0000,,,,BB2015-05-TBR;composite,,,https://issues.apache.org/jira/browse/HADOOP-11561
MAPREDUCE-6219,Bug,Minor,,Reduce memory required for FileInputFormat located status optimization,MAPREDUCE-1981 introduced an optimization to drastically reduce the number of namenode operations required to compute input splits when processing a directory.  However it requires more memory to perform this optimization as it retains the full LocatedFileStatus object for all input files while computing the splits.  This can lead to odd situations for users where using a directory as input can run the job client out of heap space but using directory * as the input spec allows it to run within the original heap space.,Open,Unresolved,,Unassigned,Jason Lowe,Tue; 20 Jan 2015 21:30:10 +0000,Sat; 7 Jan 2017 01:59:55 +0000,,,2.1.1-beta,,,MAPREDUCE-1981,https://issues.apache.org/jira/browse/MAPREDUCE-6219
MAPREDUCE-6220,Improvement,Major,mrv2,Provide option to suppress stdout of MapReduce task,System.out is a ugly way to print log; and many times it would do harm to Hadoop cluster. So we can provide an option to forbid it,Resolved,Won't Fix,,Yang Hao,Yang Hao,Thu; 22 Jan 2015 11:21:06 +0000,Fri; 24 Apr 2015 23:31:12 +0000,Fri; 24 Apr 2015 15:20:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6220
MAPREDUCE-6221,Bug,Minor,,Stringifier is left unclosed in Chain#getChainElementConf(),stringifier is not closed upon return from the method.,Closed,Fixed,,Ted Yu,Ted Yu,Thu; 22 Jan 2015 17:54:14 +0000,Fri; 24 Apr 2015 23:15:15 +0000,Thu; 12 Feb 2015 17:31:37 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6221
MAPREDUCE-6222,Sub-task,Major,jobhistoryserver,Add server-side pagination to JobHistoryServer tasks page,I'm encountering an issue with the Mapreduce HistoryServer processing the history files for large jobs.  This has come up several times with for jobs with around 60000 total tasks.  When the HistoryServer loads the .jhist file from HDFS for a job of that size (which is usually around 500 Mb); the HistoryServer's CPU usage spiked and the UI became unresponsive.  After about 10 minutes I restarted the HistoryServer and it was behaving normally again.  The cluster is running CDH 5.3 (2.5.0-cdh5.3.0).  I've attached the output of jstack from a time this was occurring.,Resolved,Won't Fix,,Ray Chiang,Andrew Johnson,Fri; 23 Jan 2015 21:37:28 +0000,Tue; 21 Jun 2016 21:25:38 +0000,Tue; 21 Jun 2016 21:25:38 +0000,,2.7.0,BB2015-05-TBR;supportability,,MAPREDUCE-6376,https://issues.apache.org/jira/browse/MAPREDUCE-6222
MAPREDUCE-6223,Bug,Major,test,TestJobConf#testNegativeValueForTaskVmem failures,nan,Resolved,Fixed,,Varun Saxena,Gera Shegalov,Sat; 24 Jan 2015 01:03:54 +0000,Fri; 13 May 2016 05:02:27 +0000,Thu; 26 Feb 2015 22:38:11 +0000,,3.0.0-alpha1,,,MAPREDUCE-6234,https://issues.apache.org/jira/browse/MAPREDUCE-6223
MAPREDUCE-6224,Improvement,Major,mrv1,resolve the hosts in DNSToSwitchMapping before inter tracker server start to avoid IPC timeout in Task Tracker heartbeat,Resolve the hosts to fill up the cache in CachedDNSToSwitchMapping before inter tracker server start to avoid IPC timeout in Task Tracker heartbeat. We saw IPC timeout happen in Task Tracker heartbe call resolveAndAddToTopology; it will get the result from the cache instead of running topology script.,Patch Available,Unresolved,,zhihai xu,zhihai xu,Sun; 25 Jan 2015 06:27:09 +0000,Wed; 6 May 2015 03:26:29 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6224
MAPREDUCE-6225,Bug,Major,,Fix new findbug warnings in hadoop-mapreduce-client-core,Recent precommit builds in hadoop-mapreduce-client-core are flagging findbug warnings that appear to be new with the recent findbugs upgrade.  These need to be cleaned up.,Closed,Fixed,MAPREDUCE-6226;MAPREDUCE-6236,Varun Saxena,Jason Lowe,Mon; 26 Jan 2015 16:21:58 +0000,Fri; 10 Apr 2015 20:19:39 +0000,Mon; 16 Feb 2015 17:26:41 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6225
MAPREDUCE-6226,Bug,Major,,Findbugs warnings in mapreduce-client-core,Found findbugs warnings reported for mapreduce-client-core while fixing MAPREDUCE-6223,Resolved,Duplicate,MAPREDUCE-6225,Varun Saxena,Varun Saxena,Mon; 26 Jan 2015 17:59:34 +0000,Tue; 27 Jan 2015 08:59:45 +0000,Tue; 27 Jan 2015 08:59:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6226
MAPREDUCE-6227,New Feature,Major,benchmarks;test,DFSIO for truncate,Create a benchmark and a test for truncate within the framework of TestDFSIO.,Closed,Fixed,,Konstantin Shvachko,Konstantin Shvachko,Mon; 26 Jan 2015 21:03:42 +0000,Fri; 10 Apr 2015 20:19:40 +0000,Sun; 8 Feb 2015 03:41:08 +0000,,2.7.0,,,HDFS-3107,https://issues.apache.org/jira/browse/MAPREDUCE-6227
MAPREDUCE-6228,New Feature,Major,benchmarks;test,Add truncate operation to SLive,Add truncate into the mix of operations for SLive test.,Closed,Fixed,,Plamen Jeliazkov,Konstantin Shvachko,Mon; 26 Jan 2015 21:06:07 +0000,Fri; 10 Apr 2015 20:19:39 +0000,Thu; 19 Feb 2015 08:20:59 +0000,,,,,HDFS-3107,https://issues.apache.org/jira/browse/MAPREDUCE-6228
MAPREDUCE-6229,Bug,Major,,finished MapReduce tasks will be re executed when AM fails on recovery process,"MapReduce AM failovers; and suddently it is killed during recovery. Next time when the AM failovers again; the progress will lose for that it only parses previous history file. As a result;  	many tasks will be reexecuted. 	users will not see the history; such as the tasks killed or finished at the first attempt.",Open,Unresolved,,Unassigned,Yang Hao,Tue; 27 Jan 2015 09:59:03 +0000,Wed; 28 Jan 2015 00:53:40 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6229
MAPREDUCE-6230,Bug,Blocker,mr-am,MR AM does not survive RM restart if RM activated a new AMRM secret key,"A MapReduce AM will fail to reconnect to an RM that performed restart in the following scenario:   	MapReduce job launched with AMRM token generated from AMRM secret X 	RM rolls new AMRM secret Y and activates the new key 	RM performs a work-preserving restart 	MapReduce job AM now unable to connect to RM with ""Invalid AMRMToken"" exception",Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 27 Jan 2015 16:13:39 +0000,Tue; 30 Aug 2016 01:19:23 +0000,Wed; 28 Jan 2015 23:52:59 +0000,,,2.6.1-candidate,,MAPREDUCE-6324;YARN-3103,https://issues.apache.org/jira/browse/MAPREDUCE-6230
MAPREDUCE-6231,Bug,Major,examples,Grep example job is not working on a fully-distributed cluster,Grep. is missing Job.setJarByClass; so grep example job is not working on a fully-distributed cluster. This issue was originally reported at user ML. http: %3C54C8E6AE.1010507%40sql-ag.de%3E,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Wed; 28 Jan 2015 18:09:22 +0000,Fri; 10 Apr 2015 20:19:40 +0000,Thu; 29 Jan 2015 16:13:39 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6231
MAPREDUCE-6232,Bug,Major,task,Task state is running when all task attempts fail,When task attempts fails; the task's state is still  running. A clever way is to check the task attempts's state; if none of the attempts is running; then the task state should not be running,Patch Available,Unresolved,,Yang Hao,Yang Hao,Thu; 29 Jan 2015 08:10:24 +0000,Fri; 22 May 2015 15:24:51 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6232
MAPREDUCE-6233,Bug,Major,test,org.apache.hadoop.mapreduce.TestLargeSort.testLargeSort failed in trunk,https: ,Closed,Fixed,,zhihai xu,Yongjun Zhang,Thu; 29 Jan 2015 21:53:19 +0000,Fri; 24 Apr 2015 23:15:16 +0000,Thu; 5 Feb 2015 22:36:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6233
MAPREDUCE-6234,Bug,Major,contrib/gridmix;mrv2,TestHighRamJob fails due to the change in MAPREDUCE-5785,TestHighRamJob fails by this.,Resolved,Fixed,,Masatake Iwasaki,Masatake Iwasaki,Fri; 30 Jan 2015 01:26:30 +0000,Thu; 12 May 2016 18:24:25 +0000,Tue; 17 Feb 2015 22:38:57 +0000,,3.0.0-alpha1,,,MAPREDUCE-6223,https://issues.apache.org/jira/browse/MAPREDUCE-6234
MAPREDUCE-6235,Improvement,Minor,distributed-cache;mrv2,Bundle and compress files passed with -libjars prior to uploading and distributing,To improve performance; we should upload jars flagged by -libjars as a single bundle and expand on arrival instead of uploading the jars one by one.   This would also reduce network overhead of using the -libjars option.,Resolved,Invalid,,Dustin Cote,Dustin Cote,Fri; 30 Jan 2015 16:19:28 +0000,Thu; 5 Feb 2015 13:04:20 +0000,Thu; 5 Feb 2015 13:04:20 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6235
MAPREDUCE-6236,Bug,Minor,client,Fix findbugs warnings in hadoop-mapreduce-client-core,nan,Resolved,Duplicate,MAPREDUCE-6225,Masatake Iwasaki,Masatake Iwasaki,Sat; 31 Jan 2015 00:09:49 +0000,Mon; 2 Feb 2015 21:35:37 +0000,Mon; 2 Feb 2015 21:35:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6236
MAPREDUCE-6237,Bug,Major,mrv2,Multiple mappers with DBInputFormat don't work because of reusing conections,DBInputFormat.createDBRecorder is reusing JDBC connections across instances of DBRecordReader. This is not a good idea. We should be creating separate connection. If performance is a concern; then we should be using connection pooling instead.  I looked at DBOutputFormat.getRecordReader. It actually creates a new Connection object for each DBRecordReader. So can we just change DBInputFormat to create new Connection every time? The connection reuse code was added as part of connection leak bug in MAPREDUCE-1443. Any reason for caching the connection?  We observed this issue in a customer setup where they were reading data from MySQL using Pig. As per customer; the query is returning two records which causes Pig to create two instances of DBRecordReader. These two instances are sharing the database connection instance. The first DBRecordReader runs to extract the first record from MySQL just fine; but then closes the shared connection instance. When the second DBRecordReader runs; it tries to execute a query to retrieve the second record on the closed shared connection instance; which fail. If we set mapred.map.tasks to 1; the query will be successful.,Closed,Fixed,,Kannan Rajah,Kannan Rajah,Sat; 31 Jan 2015 00:11:36 +0000,Tue; 30 Aug 2016 01:19:22 +0000,Mon; 9 Feb 2015 18:59:02 +0000,,2.5.0;2.6.0,2.6.1-candidate,,,https://issues.apache.org/jira/browse/MAPREDUCE-6237
MAPREDUCE-6238,Bug,Critical,mrv2,MR2 can't run local jobs with -libjars command options which is a regression from MR1,MR2 can't run local jobs with -libjars command options which is a regression from MR1.  When run MR2 job with -jt local and -libjars; the job fails with  try to add the destination file to DistributedCache which introduce a bug for local job.   Because new Path(newPath.toUri().getPath()) will lose the filesystem information from newPath; the file added to DistributedCache will use the default Uri filesystem hdfs based on the following code. This causes the   FileNotFoundException when we access the file later at   determineTimestampsAndCacheVisibilities    Compare to the following MR1 code:   You will see why MR1 doesn't have this issue. because it passes the local filesystem into  DistributedCache#addFileToClassPath instead of using the default Uri filesystem hdfs. 2. Another incompatible change in MR2 is in LocalDistributedCacheManager#setup   Similar code from MR1 is at TaskDistributedCacheManager#makeCacheFiles   I think we don't need call remoteFS.resolvePath to get the class path and We can use the  class path from DistributedCache.getFileClassPaths directly. Also p.toUri().getPath().toString() will remove the filesystem information(scheme) and only keySet of classpaths is used(ValueSet of classpaths is not used). It is better to do the same in MR2 to maintain backward compatible with MR1.,Closed,Fixed,MAPREDUCE-6289,zhihai xu,zhihai xu,Sat; 31 Jan 2015 08:51:07 +0000,Fri; 6 Jan 2017 00:44:53 +0000,Mon; 20 Apr 2015 21:15:43 +0000,,,2.6.1-candidate,,,https://issues.apache.org/jira/browse/MAPREDUCE-6238
MAPREDUCE-6239,Improvement,Minor,client,Consolidate TestJobConf classes in hadoop-mapreduce-client-jobclient and hadoop-mapreduce-client-core,nan,Resolved,Fixed,,Varun Saxena,Varun Saxena,Mon; 2 Feb 2015 08:43:06 +0000,Tue; 30 Aug 2016 01:19:18 +0000,Sat; 21 Mar 2015 20:51:52 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6239
MAPREDUCE-6240,Bug,Major,client,Hadoop client displays confusing error message,"Hadoop client often throws exception  with "" io.IOException: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses"".  This is a misleading and generic message for any cluster initialization problem. It takes a lot of debugging hours to identify the root cause. The correct error message could resolve this problem quickly.  In one such instance; Oozie log showed the following exception  while the root cause was CNF  that Hadoop client didn't return in the exception.",Resolved,Fixed,,Gera Shegalov,Mohammad Kamrul Islam,Tue; 3 Feb 2015 01:40:11 +0000,Tue; 30 Aug 2016 01:19:15 +0000,Wed; 8 Jun 2016 20:59:38 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6240
MAPREDUCE-6241,Bug,Major,build,Native compilation fails for Checksum.cc due to an  incompatibility of assembler register constraint for PowerPC,"Issue when using assembler code for performance optimization on the powerpc platform (compiled for 32bit)  mvn compile -Pnative -DskipTests  exec  Checksum.cc:611:14: error: impossible register constraint in  asm  -- ""popl %%ebx"" : ""=a"" (eax); ebx ""=r""(ebx); ""=c""(ecx); ""=d""(edx) : ""a"" (eax_in) : ""cc""); --",Patch Available,Unresolved,,Binglin Chang,Stephan Drescher,Tue; 3 Feb 2015 09:50:53 +0000,Wed; 11 Oct 2017 23:44:12 +0000,,,2.6.0;3.0.0-alpha1,BB2015-05-TBR;features,,,https://issues.apache.org/jira/browse/MAPREDUCE-6241
MAPREDUCE-6242,Bug,Major,applicationmaster,Progress report log is incredibly excessive in application master,We saw incredibly excessive logs in application master for a long running one with many task tempt_1422985365246_0001_m_000001_0 is : 0.21723115  Looks like the report interval is controlled by a hard-coded variable PROGRESS_INTERVAL as 3 seconds in class org.apache.hadoop.mapred.Task. We should allow users to set the appropriate progress interval for their applications.,Resolved,Fixed,,Varun Saxena,Jian Fang,Tue; 3 Feb 2015 19:05:45 +0000,Tue; 30 Aug 2016 01:19:14 +0000,Mon; 23 Mar 2015 17:24:42 +0000,,2.4.0,,,MAPREDUCE-5124,https://issues.apache.org/jira/browse/MAPREDUCE-6242
MAPREDUCE-6243,Bug,Minor,tools/rumen,Fix findbugs warnings in hadoop-rumen,There are 7 findbugs warnings in hadoop-rumen modules.,Closed,Fixed,,Masatake Iwasaki,Akira Ajisaka,Wed; 4 Feb 2015 05:51:15 +0000,Fri; 10 Apr 2015 20:19:43 +0000,Wed; 4 Feb 2015 17:29:15 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6243
MAPREDUCE-6244,Improvement,Minor,,Hadoop examples when run without an argument; gives ERROR instead of just usage info,Hadoop sort example should not give an ERROR and only should display usage when run with no parameters.,Open,Unresolved,,Abhishek Kapoor,Robert Justice,Fri; 21 Sep 2012 14:40:59 +0000,Mon; 9 Feb 2015 19:00:19 +0000,,,0.23.0;trunk-win;2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6244
MAPREDUCE-6245,Bug,Major,,Fixed split shuffling.,nan,Open,Unresolved,,lbkzman,lbkzman,Thu; 5 Feb 2015 14:43:20 +0000,Sat; 7 Jan 2017 01:59:53 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6245
MAPREDUCE-6246,Bug,Major,mrv1;mrv2,DBOutputFormat.java appending extra semicolon to query which is incompatible with DB2,DBoutputform already built on top of this default setting (OFF) so by turning ON this feature make them error prone.,Resolved,Fixed,,Gergely Nov  k,ramtin,Mon; 9 Feb 2015 18:54:45 +0000,Fri; 7 Jul 2017 21:25:42 +0000,Fri; 7 Jul 2017 21:25:33 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6246
MAPREDUCE-6247,Improvement,Minor,mrv2,Use DBCP connection pooling in DBInputFormat,As part of MAPREDUCE-6237; we removed caching of DB connection. Gera Shegalov and Tsuyoshi Ozawa suggested that we use DBCP connection pooling.,Open,Unresolved,,Kannan Rajah,Kannan Rajah,Mon; 9 Feb 2015 19:54:22 +0000,Thu; 19 Mar 2015 06:50:57 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6247
MAPREDUCE-6248,Improvement,Major,distcp,Allow users to get the MR job information for distcp,Currently the DistCp is acting as a tool and the corresponding MapReduce Job  is created and used inside of its execute method. It is thus difficult for external services to query its progress and counters. It may be helpful to persist the job id into a file inside its staging directory.,Closed,Fixed,,Jing Zhao,Jing Zhao,Tue; 10 Feb 2015 01:40:02 +0000,Fri; 10 Apr 2015 20:19:45 +0000,Wed; 4 Mar 2015 00:30:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6248
MAPREDUCE-6249,Bug,Major,contrib/streaming,Streaming task will not untar tgz uploaded with -archives,"when writing hadoop streaming task. i used -archives to upload a tgz from local machine to hdfs task working directory; but it has not been untarred as the document says. I've searched a lot without any luck.  Here is the hadoop streaming task starting command with hadoop-2.5.2  hadoop jar  test.tgz  but what desired may be like this  rw-rr- 1 hadoop hadoop 5 Feb  8 23:25 test.1.txt rw-rr- 1 hadoop hadoop 5 Feb  8 23:25 test.2.txt  so; why test.tgz has not been untarred automatically as document says; and or there is actually another way makes the ""tgz"" being untarred",Resolved,Not A Problem,,Unassigned,Liu Xiao,Tue; 10 Feb 2015 04:00:13 +0000,Wed; 11 Feb 2015 03:43:13 +0000,Tue; 10 Feb 2015 14:45:24 +0000,,2.5.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6249
MAPREDUCE-6250,Improvement,Major,scripts,deprecate sbin/mr-jobhistory-daemon.sh,Functionality has been moved to bin mapred.,Resolved,Fixed,,Allen Wittenauer,Allen Wittenauer,Tue; 10 Feb 2015 20:18:55 +0000,Thu; 12 May 2016 18:23:17 +0000,Thu; 12 Feb 2015 21:49:09 +0000,,,,,YARN-2796,https://issues.apache.org/jira/browse/MAPREDUCE-6250
MAPREDUCE-6251,Bug,Major,jobhistoryserver;mrv2,JobClient needs additional retries at a higher level to address not-immediately-consistent dfs corner cases,"The JobClient is used to get job status information for running and completed jobs.  Final state and history for a job is communicated from the application master to the job history server via a distributed file system - where the history is uploaded by the application master to the dfs and then scanned loaded by the jobhistory server.  While HDFS has strong consistency guarantees not all Hadoop DFS's do.  When used in conjunction with a distributed file system which does not have this guarantee there will be cases where the history server may not see an uploaded file; resulting in the dreaded ""no such job"" and a null value for the RunningJob in the client.",Closed,Fixed,,Craig Welch,Craig Welch,Tue; 10 Feb 2015 21:47:10 +0000,Fri; 6 Jan 2017 01:19:17 +0000,Tue; 12 May 2015 19:16:57 +0000,,2.6.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6251
MAPREDUCE-6252,Bug,Major,jobhistoryserver,JobHistoryServer should not fail when encountering a missing directory,The JobHistoryServer maintains a cache of job serial number parts to dfs paths which it uses when seeking a job it no longer has in its memory cache; multiple directories for a given serial number differentiated by time stamp.  At present the jobhistory server will fail any time it attempts to find a job in a directory which no longer exists based on that cache - even though the job may well exist in a different directory for the serial number.  Typically this is not an issue; but the history cleanup process removes the directory from dfs before removing it from the cache which leaves a window of time where a directory may be missing from dfs which is present in the cache; resulting in failure.  For some dfs's it appears that the top level directory may become unavailable some time before the full deletion of the tree completes which extends what might otherwise be a brief period of failure to a more extended period.  Further; this also places the service at the mercy of outside processes which might remove those directories.  The proposal is simply to make the server resistant to this state such that encountering this missing directory is not fatal and the process will continue on to seek it elsewhere.,Closed,Fixed,,Craig Welch,Craig Welch,Tue; 10 Feb 2015 22:05:48 +0000,Tue; 30 Aug 2016 01:19:02 +0000,Mon; 27 Apr 2015 09:34:59 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6252
MAPREDUCE-6253,Improvement,Minor,,Update use of Iterator to Iterable,Found these using the IntelliJ Findbugs-IDEA plugin; which uses findbugs3.,Closed,Fixed,,Ray Chiang,Ray Chiang,Wed; 11 Feb 2015 22:13:37 +0000,Fri; 24 Apr 2015 23:15:16 +0000,Thu; 12 Feb 2015 08:21:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6253
HDFS-7780,Improvement,Minor,,Update use of Iterator to Iterable in DataXceiverServer and SnapshotDiffInfo,Found these using the IntelliJ Findbugs-IDEA plugin; which uses findbugs3.,Closed,Fixed,,Ray Chiang,Ray Chiang,Wed; 11 Feb 2015 22:52:57 +0000,Fri; 10 Apr 2015 20:29:54 +0000,Tue; 17 Feb 2015 22:50:37 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/HDFS-7780
MAPREDUCE-6255,Improvement,Minor,client,Fix JobCounter's format to use grouping separator,MRv2 Job Counter has not been comma format; this is hard to see.,Closed,Fixed,,Ryu Kobayashi,Ryu Kobayashi,Thu; 12 Feb 2015 05:41:30 +0000,Fri; 10 Apr 2015 20:19:39 +0000,Fri; 13 Feb 2015 07:13:14 +0000,,2.6.0;2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6255
MAPREDUCE-6256,Improvement,Minor,,Removed unused private methods in o.a.h.mapreduce.Job.java,These below methods are not used any where in the code and these can be removed.,Closed,Fixed,,Naganarasimha G R,Devaraj K,Thu; 12 Feb 2015 14:05:33 +0000,Fri; 10 Apr 2015 20:19:42 +0000,Sun; 15 Feb 2015 01:14:53 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6256
MAPREDUCE-6257,Bug,Major,security,Document encrypted spills,Encrypted spills appear to be completely undocumented.,Resolved,Fixed,,Bibin A Chundatt,Allen Wittenauer,Thu; 12 Feb 2015 22:52:39 +0000,Thu; 12 May 2016 18:24:13 +0000,Thu; 6 Aug 2015 17:13:34 +0000,,,,,MAPREDUCE-5890,https://issues.apache.org/jira/browse/MAPREDUCE-6257
MAPREDUCE-6258,New Feature,Major,applicationmaster,add support to back up JHS files from application master,In hadoop two; job history files are stored on HDFS with a default retention period of one week. In a cloud environment; these HDFS files are actually stored on the disks of ephemeral instances that could go away once the instances are terminated. Users may want to back up the job history files for issue investigation and performance analysis before and after the cluster is terminated.    A centralized backup mechanism could have a scalability issue for big and busy Hadoop clusters where there are probably tens of thousands of jobs every day. As a result; it is preferred to have a distributed way to back up the job history files in this case. To achieve this goal; we could add a new feature to back up the job history files in Application master. More specifically; we could copy the job history files to a backup path when they are moved from the temporary staging directory to the intermediate_done path in application master. Since application masters could run on any slave nodes on a Hadoop cluster; we could achieve a better scalability by backing up the job history files in a distributed fashion.  Please be aware; the backup path should be managed by the Hadoop users based on their needs. For example; some Hadoop users may copy the job history files to a cloud storage directly and keep them there forever. While some other users may want to store the job history files on local disks and clean them up from time to time.,Patch Available,Unresolved,,Unassigned,Jian Fang,Thu; 12 Feb 2015 23:44:11 +0000,Wed; 6 May 2015 03:26:51 +0000,,,2.4.1,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6258
MAPREDUCE-6259,Bug,Major,jobhistoryserver,IllegalArgumentException due to missing job submit time,-1 job submit time cause IllegalArgumentException when parse the Job history file name and JOB_INIT_FAILED cause -1 job submit time in JobIndexInfo. We found the following job history file name which cause IllegalArgumentException when parse the job statu,Closed,Fixed,,zhihai xu,zhihai xu,Fri; 13 Feb 2015 03:20:41 +0000,Fri; 6 Jan 2017 00:57:45 +0000,Mon; 4 May 2015 20:44:27 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6259
MAPREDUCE-6260,Improvement,Major,documentation,Convert site documentation to markdown,nan,Resolved,Fixed,,Masatake Iwasaki,Allen Wittenauer,Fri; 13 Feb 2015 06:03:02 +0000,Thu; 12 May 2016 18:23:51 +0000,Tue; 17 Feb 2015 16:52:39 +0000,,3.0.0-alpha1,,,HADOOP-11633,https://issues.apache.org/jira/browse/MAPREDUCE-6260
MAPREDUCE-6261,Bug,Major,mrv2,NullPointerException if MapOutputBuffer.flush invoked twice,MapOutputBuffer.flush will throw an NPE if it is invoked twice; since it blindly assumes kvbuffer is not null yet sets kvbuffer to null towards the end of the method.,Closed,Fixed,,Tsuyoshi Ozawa,Jason Lowe,Fri; 13 Feb 2015 20:39:22 +0000,Fri; 10 Apr 2015 20:19:37 +0000,Wed; 18 Feb 2015 19:29:42 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6261
MAPREDUCE-6262,Improvement,Major,,Factor OSType out from Shell: changes in mapreduce,nan,Open,Unresolved,,Yongjun Zhang,Yongjun Zhang,Sun; 15 Feb 2015 04:54:21 +0000,Sun; 15 Feb 2015 05:11:01 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6262
MAPREDUCE-6263,Bug,Major,client,Configurable timeout between YARNRunner terminate the application and forcefully kill.,YARNRunner connects to the AM to send the kill job command then waits a hardcoded 10 seconds for the job to enter a terminal state.  If the job fails to enter a terminal state in that time then YARNRunner will tell YARN to kill the application forcefully.  The latter type of kill usually results in no job history; since the AM process is killed forcefully.  Ten seconds can be too short for large jobs in a large cluster; as it takes time to connect to all the nodemanagers; process the state machine events; and copy a large jhist file.  The timeout should be more lenient or configurable.,Closed,Fixed,,Eric Payne,Jason Lowe,Wed; 18 Feb 2015 23:15:22 +0000,Fri; 10 Apr 2015 20:19:41 +0000,Tue; 10 Mar 2015 13:10:34 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6263
MAPREDUCE-6264,Task,Major,,Remove httpclient dependency from hadoop-mapreduce-client,Sub-task of HADOOP-10105. Remove httpclient dependency from TestAMWebApp. ,Closed,Fixed,,Brahma Reddy Battula,Akira Ajisaka,Thu; 19 Feb 2015 00:38:55 +0000,Fri; 24 Apr 2015 23:15:14 +0000,Tue; 24 Feb 2015 19:37:47 +0000,,,,,HADOOP-10105,https://issues.apache.org/jira/browse/MAPREDUCE-6264
MAPREDUCE-6265,Improvement,Major,mrv2,Make ContainerLauncherImpl.INITIAL_POOL_SIZE configurable to better control to launch/kill containers,make INITIAL_POOL_SIZE in ContainerLauncherImpl configurable to better control the thread pool size to launch kill containers Currently INITIAL_POOL_SIZE in ContainerLauncherImpl is hard-coded at    We should make it configurable because the thread pool size will be decided by INITIAL_POOL_SIZE; limitOnPoolSize and number of node used by the AM. Since we already made limitOnPoolSize configurable; it make senses to also make INITIAL_POOL_SIZE configurable to better manage the thread pool size. We saw some issue due to the small thread pool size when some node is down. The recovery from a shutdown node take very long time due to all the ContainerLauncher threads are blocked by IPC client connection to the shutdown node.,Closed,Fixed,,zhihai xu,zhihai xu,Mon; 23 Feb 2015 08:46:59 +0000,Fri; 24 Apr 2015 23:15:15 +0000,Sat; 14 Mar 2015 07:50:39 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6265
MAPREDUCE-6266,Bug,Minor,,Job#getTrackingURL should consistently return a proper URL,When a job is running; Job#getTrackingURL returns a proper URL like:      http: job_1424910897258_0004,Resolved,Fixed,,Ray Chiang,Ray Chiang,Thu; 26 Feb 2015 18:15:38 +0000,Tue; 30 Aug 2016 01:18:47 +0000,Thu; 9 Apr 2015 20:49:39 +0000,,2.6.0,supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6266
MAPREDUCE-6267,Improvement,Minor,,Refactor JobSubmitter#copyAndConfigureFiles into it's own class,Refactor the uploading logic in JobSubmitter#copyAndConfigureFiles into it's own class. This makes the JobSubmitter class more readable and isolates the logic that is actually uploading the job resources to HDFS.,Closed,Fixed,,Chris Trezzo,Chris Trezzo,Thu; 26 Feb 2015 18:54:54 +0000,Tue; 30 Aug 2016 01:18:46 +0000,Wed; 4 Mar 2015 22:50:49 +0000,,,2.6.1-candidate,,,https://issues.apache.org/jira/browse/MAPREDUCE-6267
MAPREDUCE-6268,Bug,Minor,,Fix typo in Task Attempt API's URL,Task Attempt API's URL is typo. attempt is wrong,Closed,Fixed,,Ryu Kobayashi,Ryu Kobayashi,Tue; 3 Mar 2015 07:05:05 +0000,Fri; 10 Apr 2015 20:19:44 +0000,Tue; 3 Mar 2015 07:25:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6268
MAPREDUCE-6269,Improvement,Major,client,improve JobConf to add option to not reference same credentials between jobs.,Improve JobConf to add constructor to avoid sharing Credentials between jobs. By default the Credentials will be shared to keep the backward compatibility. We can add a new constructor with a new parameter to decide whether to share Credentials. Some issues reported in cascading is due to corrupted credentials at https: 45b33bb864172486ac43782a4d13329312d01c0e  If we add this support in JobConf; it will benefit all job clients.,Patch Available,Unresolved,,zhihai xu,zhihai xu,Wed; 4 Mar 2015 00:48:29 +0000,Sat; 9 May 2015 17:11:00 +0000,,,,BB2015-05-RFC,,,https://issues.apache.org/jira/browse/MAPREDUCE-6269
MAPREDUCE-6270,Bug,Trivial,documentation,Doc typo,Disregard; wrong project.,Resolved,Invalid,,Hari Sekhon,Hari Sekhon,Mon; 9 Mar 2015 18:08:52 +0000,Mon; 9 Mar 2015 18:14:36 +0000,Mon; 9 Mar 2015 18:10:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6270
MAPREDUCE-6271,Bug,Major,client,org.apache.hadoop.mapreduce.Cluster GetJob() display warn log,"When using getJob() with MapReduce 2.7; warn log caused by configuration loaded twice is displayed every time. And when job completed; this function will display warn log of "" io.FileNotFoundException""  And I think this is related with MAPREDUCE-5875; the change in GetJob() seems to be not needed; cause it's only for test.",Patch Available,Unresolved,,Peng Zhang,Peng Zhang,Tue; 10 Mar 2015 03:32:22 +0000,Wed; 6 May 2015 03:28:17 +0000,,,2.7.0,BB2015-05-TBR,MAPREDUCE-6288,MAPREDUCE-5875,https://issues.apache.org/jira/browse/MAPREDUCE-6271
HADOOP-11764,Bug,Major,,Hadoop should have the option to use directory other than tmp for extracting and loading leveldbjni, tmp.,Resolved,Won't Fix,,Anubhav Dhoot,Anubhav Dhoot,Tue; 10 Mar 2015 19:31:10 +0000,Fri; 11 Sep 2015 17:18:40 +0000,Wed; 29 Jul 2015 14:47:35 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-11764
MAPREDUCE-6273,Bug,Minor,jobhistoryserver,HistoryFileManager should check whether summaryFile exists to avoid FileNotFoundException causing HistoryFileInfo into MOVE_FAILED state,HistoryFileManager should check whether summaryFile exists to avoid FileNotFoundException causing HistoryFileInfo into MOVE_FAILED state; I saw the following error message:   We should avoid this error by checking whether summaryFile exists before call getJobSummary; otherwise we will see this error happen every time scanIntermediateDirectory is called.,Closed,Fixed,,zhihai xu,zhihai xu,Thu; 12 Mar 2015 05:03:26 +0000,Thu; 1 Dec 2016 23:22:19 +0000,Fri; 15 May 2015 07:06:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6273
MAPREDUCE-6274,Bug,Major,tools/rumen,[Rumen] Support compact property description in configuration XML,HADOOP-6964 made it possible to define configuration properties using XML attributes; but Rumen has own configuration parsers and they don t recognize XML attributes. So it would be better to support the new description.  We can simply apply the same modification as HADOOP-6964 to Rumen; but it might be worth considering making the parse function in common (also with a part of o.a.h.conf.Configuration.loadResource(); if possible); because Rumen has similar codes in JobConfigurationParser and ParsedConfigFile.,Open,Unresolved,,Shen Yinjie,Kengo Seki,Sat; 14 Mar 2015 14:06:40 +0000,Sat; 16 Jul 2016 01:30:50 +0000,,,,newbie;rumen,,,https://issues.apache.org/jira/browse/MAPREDUCE-6274
MAPREDUCE-6275,Bug,Critical,,Race condition in FileOutputCommitter v2 for user-specified task output subdirs,nan,Closed,Fixed,,Gera Shegalov,Siqi Li,Mon; 16 Mar 2015 21:18:23 +0000,Fri; 10 Apr 2015 20:19:40 +0000,Thu; 19 Mar 2015 21:45:59 +0000,,2.7.0,,,MAPREDUCE-6280;MAPREDUCE-4815,https://issues.apache.org/jira/browse/MAPREDUCE-6275
MAPREDUCE-6276,Bug,Blocker,,Error in encrypted shuffle,Hey Guys;  After enabling wire encryption my UIs are working fine; I'm able to read write to hdfs securely however encrypted shuffle is not working. I'm getting below error; could you please help me ?  Note - mappers are getting finished successfully however job gets failed during shuffle.     Please find attached full log for more details.  Thanks; Kuldeep,Resolved,Invalid,,Unassigned,Kuldeep Kulkarni,Tue; 17 Mar 2015 10:51:48 +0000,Wed; 18 Mar 2015 00:36:50 +0000,Wed; 18 Mar 2015 00:36:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6276
MAPREDUCE-6277,Bug,Major,mr-am,Job can post multiple history files if attempt loses connection to the RM,Related to a fixed issue MAPREDUCE-6230 which cause a Job to get into error state. In that situation Job's second or some later attempt could succeed but those later attempts' history file will all be lost. Because the first attempt in error state will copy its history file to intermediate dir while mistakenly think of itself as lastattempt. Jobhistory server will later move the history file of that error attempt from intermediate dir to done dir while ignore the rest of that job attempt's later history files in intermediate dir.,Closed,Fixed,,Chang Li,Chang Li,Wed; 11 Mar 2015 19:36:14 +0000,Fri; 10 Apr 2015 20:19:43 +0000,Wed; 18 Mar 2015 19:33:14 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6277
MAPREDUCE-6278,Bug,Major,,Multithreaded maven build breaks in hadoop-mapreduce-client-core,As reported on the mailing list.  The following breaks: mvn -e package -DskipTests -Dmaven. oc.skip -Dtar -Pdist;native -T5  ...    Dmitry Siminov appears to be building on Windows. I'm using Linux.,Open,Unresolved,,Unassigned,Ewan Higgs,Wed; 18 Mar 2015 13:57:06 +0000,Thu; 12 May 2016 18:24:37 +0000,,,2.4.0;2.5.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6278
MAPREDUCE-6279,Improvement,Major,,AM should explicity exit JVM after all services have stopped,"Occasionally the MapReduce AM can ""get stuck"" trying to shut down.  MAPREDUCE-6049 and MAPREDUCE-5888 were specific instances that have been fixed; but this can also occur with uber jobs if the task code inadvertently leaves non-daemon threads lingering.  We should explicitly shutdown the JVM after the MapReduce AM has unregistered and all services have been stopped.",Resolved,Fixed,,Eric Payne,Jason Lowe,Wed; 18 Mar 2015 18:08:44 +0000,Tue; 30 Aug 2016 01:18:42 +0000,Thu; 7 May 2015 22:08:14 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6279
MAPREDUCE-6280,Bug,Major,mrv2,Reject directory vs file path conflict resolution in FileOutputCommitter ,If one task commits a directory foo; and then another task commits file foo; the directory foo with potentially many files will be wiped out. While this is a very unlikely scenario; due to tasks being homogeneous in nature; it's so much more important to alert the user by failing the commit. This came up in Jason Lowe's review for MAPREDUCE-6275 and seems to be the behavior in branch-1 as well.,Open,Unresolved,,Unassigned,Gera Shegalov,Wed; 18 Mar 2015 22:01:48 +0000,Wed; 18 Mar 2015 22:08:30 +0000,,,2.6.0,,,MAPREDUCE-6275,https://issues.apache.org/jira/browse/MAPREDUCE-6280
MAPREDUCE-6281,Bug,Trivial,,Fix javadoc in Terasort,Nothing fancy     probably leftover from the Hadoop 1.0 - 2.0 transition.,Resolved,Fixed,,Albert Chu,Albert Chu,Thu; 19 Mar 2015 13:24:07 +0000,Tue; 30 Aug 2016 01:18:41 +0000,Thu; 19 Mar 2015 16:01:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6281
MAPREDUCE-6282,Improvement,Trivial,jobhistoryserver,Reuse historyFileAbsolute.getFileSystem in CompletedJob#loadFullHistoryData for code optimization.,Reuse historyFileAbsolute.getFileSystem in CompletedJob#loadFullHistoryData for code optimization.,Resolved,Fixed,,zhihai xu,zhihai xu,Fri; 20 Mar 2015 01:19:28 +0000,Tue; 30 Aug 2016 01:18:38 +0000,Fri; 20 Mar 2015 20:13:31 +0000,,,optimization,,,https://issues.apache.org/jira/browse/MAPREDUCE-6282
MAPREDUCE-6283,Improvement,Major,jobhistoryserver,MRHistoryServer log files management optimization,"In some heavy computation clusters; user may continually submit lots of jobs; in our scenario; there are 240k jobs per day. On average; 5 nodes will participate in running a job. All these job's log file will be aggregated on the hdfs. That is a big load for namenode. The total number of generated log files in the default cleaning period (1 week) can be calculated as follows: AM logs per week: 7 days * 240;000 jobs node = 8400;000 files There will be more than 10 million log files generated in one week. Even worse; some environments have to keep the logs for potential issues tracking for longer time. In general; these small log files will occupy about 12G heap size of Namenode; and impact the response speed of Namenode.  For optimizing the log management of history server; the main goals are: 1)	Reduce the total count of files in HDFS. 2)	Compatible with the former history server operation.  As per the goals above; we can mine the detail demands as follows:  1)	Merge log files into bigger ones in HDFS periodically. 2)	Optimized design should inherits from the original architecture to make the merged logs transparent to be browsed. 3)	Merged logs should be aged periodically just like the common logs.  The whole  life cycle of the AM logs: 1.Created by Application Master in intermediate-done-dir. 2.Moved to done-dir after the job is done. 3.Archived to archived-dir  periodically. 4.Cleaned when all the logs in harball are expired.  The whole  life cycle of the App logs: 1.Created by Applications in local-dirs. 2.Aggregated to remote-app-log-dir after the job is done. 3.Archived to archived-dir  periodically. 4.Cleaned when all the logs in harball are expired.",In Progress,Unresolved,,Varun Saxena,Zhang Wei,Fri; 20 Mar 2015 03:34:14 +0000,Thu; 2 Jul 2015 23:16:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6283
MAPREDUCE-6284,New Feature,Minor,,Add Task Attempt State API to MapReduce Application Master REST API,It want to 'task attempt state' on the 'App state' similarly REST API. GET http: state,Resolved,Fixed,,Ryu Kobayashi,Ryu Kobayashi,Fri; 20 Mar 2015 06:13:18 +0000,Tue; 30 Aug 2016 01:18:36 +0000,Fri; 8 May 2015 07:02:12 +0000,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6284
MAPREDUCE-6285,Bug,Major,,ClientServiceDelegate should not retry upon AuthenticationException,ClientServiceDelegate tries really hard to getJobStatus from a job through retries. However; if an AuthorizationException occurs; it will always continue to fail no matter how many retries it makes. AuthorizationException is also thrown when mapred job -status is call on unsupported services like tez jobs. This jira will limit the negative effect on AMs in both scenarios.  Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): Protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB is not known.,Closed,Fixed,,Jonathan Eagles,Jonathan Eagles,Fri; 20 Mar 2015 22:26:20 +0000,Fri; 10 Apr 2015 20:19:38 +0000,Tue; 24 Mar 2015 15:58:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6285
MAPREDUCE-6286,Bug,Major,client,A typo in HistoryViewer makes some code useless; which causes counter limits are not reset correctly.,A typo in HistoryViewer makes some code useless and it causes counter limits are not reset correctly. The typo is Limits.reset(conf); We should use jobConf instead of conf. With the typo; the following code becomes useless:   The code wants to load the configuration from the Job configuration file and reset the Limits based on the new configuration loaded from the Job configuration file. But with the typo; the Limits are reset with the old configuration. So this typo is apparent.,Resolved,Won't Fix,,zhihai xu,zhihai xu,Sat; 21 Mar 2015 06:14:01 +0000,Mon; 31 Jul 2017 21:29:06 +0000,Mon; 31 Jul 2017 21:28:59 +0000,,2.6.0,,,MAPREDUCE-5875,https://issues.apache.org/jira/browse/MAPREDUCE-6286
MAPREDUCE-6287,Improvement,Minor,examples,Deprecated methods in org.apache.hadoop.examples.Sort,org.apache.hadoop.examples.Sort is still using deprecated methods like Path#makeQualified and DistributedCache. It is better to replace them.,Resolved,Fixed,,Chao Zhang,Chao Zhang,Sat; 21 Mar 2015 14:56:25 +0000,Tue; 30 Aug 2016 01:18:32 +0000,Sun; 22 Mar 2015 22:19:49 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6287
MAPREDUCE-6288,Bug,Blocker,,mapred job -status fails with AccessControlException ,After MAPREDUCE-5875; we're seeing this Exception when trying to do mapred job -status job_1427080398288_0001,Resolved,Done,MAPREDUCE-6886,Unassigned,Robert Kanter,Mon; 23 Mar 2015 23:24:44 +0000,Mon; 14 Aug 2017 18:49:11 +0000,Mon; 31 Jul 2017 21:20:16 +0000,,2.8.0,,MAPREDUCE-6271,MAPREDUCE-6886;MAPREDUCE-6924,https://issues.apache.org/jira/browse/MAPREDUCE-6288
MAPREDUCE-6289,Bug,Major,distributed-cache,libjars are assumed to be in the DistributedCache but are never added in pseudo distributed mode,"Used version:    Having a pseudo-distributed setup with the worker node on the same machine as the master; no libjars are ever copied on the DFS but the following code assumes so resulting in FileNotFoundException s:  The issue starts in org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job; Path; short) in this block:     	For ""local files"" - as all libjars are in a pseudo-distributed setup copyRemoteFiles returns the path itself - including the file: hbase-client-1.0.0.jar - whereas it was never uploaded by copyRemoteFiles .  During verification afterwards this causes a FileNotFoundException :",Resolved,Duplicate,MAPREDUCE-6238,Unassigned,Sebastian Just,Tue; 24 Mar 2015 01:10:40 +0000,Tue; 24 Mar 2015 13:46:05 +0000,Tue; 24 Mar 2015 13:46:05 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6289
MAPREDUCE-6290,Bug,Major,,job.setJar not working for jars on hdfs,"when I used job.setJar(""hdfs: mrjob-0.0.1.jar"") to start MR job on remote hadoop cluster; I got errors saying class not found. However I noticed comments said ""If the job jar is already in fs; we don't need to copy it from local fs""; so I think by design setJar method should work for jars that exist on HDFS.",Open,Unresolved,,Unassigned,Jiahongchao,Tue; 24 Mar 2015 10:34:11 +0000,Tue; 24 Mar 2015 10:37:36 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6290
MAPREDUCE-6291,Improvement,Minor,client,Correct mapred queue usage command,Currently it is like following..   Usage: JobQueueClient command args   It should be   Usage: queue command args   For more Details check following,Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Wed; 25 Mar 2015 02:46:44 +0000,Tue; 30 Aug 2016 01:18:31 +0000,Fri; 10 Apr 2015 08:35:22 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6291
MAPREDUCE-6292,Improvement,Minor,test,Use org.junit package instead of junit.framework in TestCombineFileInputFormat,o.a.h.mapreduce.lib.inputTestCombineFileInputFormat now uses both packages. We should replace junit.framework package with org.junit package.,Closed,Fixed,,Akira Ajisaka,Akira Ajisaka,Wed; 25 Mar 2015 06:34:04 +0000,Fri; 24 Apr 2015 23:15:13 +0000,Wed; 25 Mar 2015 10:05:01 +0000,,2.6.0,,,MAPREDUCE-6165,https://issues.apache.org/jira/browse/MAPREDUCE-6292
MAPREDUCE-6293,Bug,Major,mr-am,Set job classloader on uber-job's LocalContainerLauncher event thread,An uberized job fails if the job classloader is enabled and the job needs to use the thread context classloader to load a class. Some example error in the log:   2015-03-23 23:28:34;675 INFO [main] org.apache.hadoop.mapreduce.v2.util.MRApps: Creating job classloader ... 2015-03-23 23:28:42;096 ERROR [uber-SubtaskRunner] cascading.provider.ServiceLoader: unable to find service class: cascading.tuple.hadoop.collect.HadoopTupleMapFactory; with exception:  lang.ClassNotFoundException: cascading.tuple.hadoop.collect.HadoopTupleMapFactory,Resolved,Fixed,,Sangjin Lee,Sangjin Lee,Wed; 25 Mar 2015 18:52:42 +0000,Tue; 30 Aug 2016 01:18:31 +0000,Tue; 21 Apr 2015 21:30:56 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6293
MAPREDUCE-6294,Bug,Trivial,,Remove an extra parameter described in Javadoc of TockenCache,    static void obtainTokensForNamenodesInternal(FileSystem fs;        Credentials credentials; Configuration conf) throws IOException {,Resolved,Fixed,,Brahma Reddy Battula,Chen He,Fri; 27 Mar 2015 00:16:59 +0000,Tue; 30 Aug 2016 01:18:30 +0000,Fri; 27 Mar 2015 15:10:22 +0000,,2.6.0;3.0.0-alpha1,newbie++,,,https://issues.apache.org/jira/browse/MAPREDUCE-6294
MAPREDUCE-6295,Bug,Critical,,Fix MR resource counter to handle negative value for getting memory resource after YARN-3304,After YARN-3304; we will get negative value for memory resource if resource data is unavailable. MR resource counter shouldn't put negative value there so a simple fix is required.,Closed,Duplicate,YARN-3304,Junping Du,Junping Du,Sat; 28 Mar 2015 14:31:54 +0000,Fri; 10 Apr 2015 20:19:43 +0000,Tue; 31 Mar 2015 17:50:36 +0000,,,,,YARN-3304,https://issues.apache.org/jira/browse/MAPREDUCE-6295
MAPREDUCE-6296,Improvement,Major,,A better way to deal with InterruptedException on waitForCompletion,Some code in method waitForCompletion of Job class is     but a better way to deal with InterruptException is,Patch Available,Unresolved,,Yang Hao,Yang Hao,Mon; 30 Mar 2015 03:06:06 +0000,Tue; 24 Oct 2017 12:27:49 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6296
MAPREDUCE-6297,Improvement,Minor,jobhistoryserver,Task Id of the failed task in diagnostics should link to the task page,Currently we have to copy it and search in the task list.,Resolved,Fixed,,Siqi Li,Siqi Li,Mon; 30 Mar 2015 17:43:57 +0000,Tue; 30 Aug 2016 01:18:29 +0000,Tue; 21 Apr 2015 21:38:57 +0000,,2.6.0,,,MAPREDUCE-6382,https://issues.apache.org/jira/browse/MAPREDUCE-6297
MAPREDUCE-6298,Bug,Minor,,Job#toString throws an exception when not in state RUNNING,Job#toString calls ensureState(JobState.RUNNING); as the very first thing. That method causes an Exception to be thrown which is not nice.  One thing this breaks is usage of Job on the Scala (e.g. Spark) REPL as that calls toString after every invocation and that fails every time.  I'll attach a patch that checks state and if it's RUNNING prints the original message and if not prints something else.,Open,Unresolved,,Lars Francke,Lars Francke,Mon; 30 Mar 2015 21:53:21 +0000,Tue; 26 May 2015 04:15:31 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6298
MAPREDUCE-6299,Bug,Critical,mrv2,bzip2 codec read duplicate rows,select count from bzip_table shows 36 rows count when there are 18 actual rows in bzip_table. Create table bzip_table2 as select * from bzip_table results in 36 rows in bzip_table2 and so on.,Open,Unresolved,,Unassigned,Kiet Ly,Tue; 31 Mar 2015 00:42:43 +0000,Mon; 6 Apr 2015 22:09:57 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6299
MAPREDUCE-6300,Bug,Minor,,Task list sort by task id broken,If you go to the MapReduce ApplicationMaster or HistoryServer UI and open the list of tasks; then try to sort by the task name id; it does nothing. Note that if you go to the task attempts; that seem to sort fine.,Closed,Fixed,MAPREDUCE-6301,Siqi Li,Siqi Li,Tue; 31 Mar 2015 17:21:14 +0000,Tue; 30 Aug 2016 01:18:25 +0000,Thu; 16 Apr 2015 15:20:38 +0000,,2.6.0,2.6.1-candidate,,MAPREDUCE-6319,https://issues.apache.org/jira/browse/MAPREDUCE-6300
MAPREDUCE-6301,Bug,Major,webapps,Task UI; sort by name doesn't work,If you go to the MapReduce ApplicationMaster or HistoryServer UI and open the list of tasks; then try to sort by the task name id; it does nothing.  Note that if you go to the task attempts; that seem to sort fine.,Resolved,Duplicate,MAPREDUCE-6300,Brahma Reddy Battula,Thomas Graves,Mon; 22 Sep 2014 15:51:02 +0000,Fri; 10 Apr 2015 16:39:24 +0000,Fri; 10 Apr 2015 16:38:51 +0000,,2.6.0;2.5.1,,,MAPREDUCE-6309,https://issues.apache.org/jira/browse/MAPREDUCE-6301
MAPREDUCE-6302,Bug,Critical,,Preempt reducers after a configurable timeout irrespective of headroom,I submit a  big job; which has 500 maps and 350 reduce; to a queue(fairscheduler) with 300 max cores. When the big mapreduce job is running 100% maps; the 300 reduces have occupied 300 max cores in the queue. And then; a map fails and retry; waiting for a core; while the 300 reduces are waiting for failed map to finish. So a deadlock occur. As a result; the job is blocked; and the later job in the queue cannot run because no available cores in the queue. I think there is the similar issue for memory of a queue .,Closed,Fixed,,Karthik Kambatla,mai shurong,Mon; 30 Mar 2015 04:26:32 +0000,Tue; 30 Aug 2016 01:18:23 +0000,Fri; 9 Oct 2015 14:58:15 +0000,,2.6.0,,,YARN-1680;YARN-3446;MAPREDUCE-6501;MAPREDUCE-6513;YARN-3485;MAPREDUCE-5844,https://issues.apache.org/jira/browse/MAPREDUCE-6302
MAPREDUCE-6303,Bug,Blocker,,Read timeout when retrying a fetch error can be fatal to a reducer,If a reducer encounters an error trying to fetch from a node then encounters a read timeout when trying to re-establish the connection then the reducer can fail.  The read timeout exception can leak to the top of the Fetcher thread which will cause the reduce task to teardown.  This type of error can repeat across reducer attempts causing jobs to fail due to a single bad node.,Closed,Fixed,,Jason Lowe,Jason Lowe,Wed; 1 Apr 2015 21:32:10 +0000,Wed; 13 Sep 2017 22:17:11 +0000,Thu; 2 Apr 2015 19:00:46 +0000,,2.6.0,2.6.1-candidate,,,https://issues.apache.org/jira/browse/MAPREDUCE-6303
MAPREDUCE-6304,New Feature,Major,job submission,Specifying node labels when submitting MR jobs,Per the discussion on YARN-796; we need a mechanism in MAPREDUCE to specify node labels when submitting MR jobs.,Resolved,Fixed,,Naganarasimha G R,Jian Fang,Wed; 1 Apr 2015 23:12:41 +0000,Mon; 28 Aug 2017 17:40:29 +0000,Thu; 18 May 2017 07:31:04 +0000,,,mapreduce,,YARN-796;YARN-3490;MAPREDUCE-6890;YARN-796;YARN-2492,https://issues.apache.org/jira/browse/MAPREDUCE-6304
MAPREDUCE-6305,Improvement,Major,,AM/Task log page should be able to link back to the job,nan,Resolved,Fixed,,Siqi Li,Siqi Li,Thu; 2 Apr 2015 18:41:19 +0000,Tue; 30 Aug 2016 01:18:16 +0000,Sat; 20 Jun 2015 19:50:09 +0000,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6305
YARN-3447,Bug,Major,,Dodgy code Warnings in  org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender,"Dodgy code Warnings   UrF	Unread public newPatchFindbugsWarningshadoop-yarn-common.html",Resolved,Duplicate,YARN-2901,Brahma Reddy Battula,Brahma Reddy Battula,Fri; 3 Apr 2015 16:30:46 +0000,Sun; 12 Apr 2015 02:59:49 +0000,Sun; 12 Apr 2015 02:59:49 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-3447
MAPREDUCE-6307,Improvement,Minor,,Remove property mapreduce.tasktracker.taskmemorymanager.monitoringinterval,mapreduce.tasktracker.taskmemorymanager.monitoringinterval is not used anywhere. We should remove the property.,Resolved,Fixed,MAPREDUCE-6308,J.Andreina,Akira Ajisaka,Mon; 6 Apr 2015 02:00:33 +0000,Tue; 30 Aug 2016 01:18:16 +0000,Fri; 10 Apr 2015 11:26:14 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6307
MAPREDUCE-6308,Improvement,Minor,,Remove mapreduce.tasktracker.taskmemorymanager.monitoringinterval from trunk,mapreduce.tasktracker.taskmemorymanager.monitoringinterval is not used anywhere; should be removed.,Resolved,Duplicate,MAPREDUCE-6307,J.Andreina,Akira Ajisaka,Mon; 6 Apr 2015 02:01:34 +0000,Fri; 10 Apr 2015 08:40:11 +0000,Fri; 10 Apr 2015 08:39:03 +0000,,2.6.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6308
MAPREDUCE-6309,Improvement,Minor,webapps,Sort by Elapsed Time doesn't work properly in Task UI,Sort by elapsed time does not work properly because 3sec is regarded greater than 10sec.,Resolved,Invalid,,J.Andreina,Akira Ajisaka,Mon; 6 Apr 2015 07:49:16 +0000,Fri; 10 Apr 2015 16:02:43 +0000,Fri; 10 Apr 2015 16:02:43 +0000,,2.6.0,,,MAPREDUCE-6301,https://issues.apache.org/jira/browse/MAPREDUCE-6309
MAPREDUCE-6310,Bug,Blocker,,Add jdiff support to MapReduce,Previously we used jdiff for Hadoop common and HDFS. Now we're extending the support of jdiff to YARN. Probably we'd like to do similar things with MapReduce?,Resolved,Fixed,,Li Lu,Li Lu,Mon; 6 Apr 2015 23:14:13 +0000,Tue; 30 Aug 2016 01:18:14 +0000,Sat; 20 Aug 2016 00:07:04 +0000,,,,HADOOP-13250;HADOOP-13156,HADOOP-13423;YARN-3426;HADOOP-13428;HDFS-10692;HADOOP-11776,https://issues.apache.org/jira/browse/MAPREDUCE-6310
HADOOP-11815,Bug,Blocker,,HttpServer2 should destroy SignerSecretProvider when it stops,It is observed that MRAppMaster JVM hungs after unregistered with ResourceManager.,Closed,Fixed,MAPREDUCE-6189,Rohith Sharma K S,Rohith Sharma K S,Tue; 7 Apr 2015 06:47:53 +0000,Mon; 13 Apr 2015 15:11:14 +0000,Thu; 9 Apr 2015 17:58:55 +0000,,2.7.0,,,MAPREDUCE-6189,https://issues.apache.org/jira/browse/HADOOP-11815
MAPREDUCE-6312,Bug,Major,client,Hive fails due to stale proxy in ClientServiceDelegate,ClientServiceDelegate initializes its realProxy field to AMProxy for a new or running job. Later when the job finishes it will not update this proxy to query history server and AM will not return valid data for this job.  We found this while investigating https: done_intermediate).   Note that Hive queries can succeed if there is a timing where HDFS performs actual file delete with a delay.  We can try to write a patch if there is an agreement that this should be fixed.,Open,Unresolved,,Unassigned,Radim Kubacki,Tue; 7 Apr 2015 14:01:36 +0000,Mon; 4 May 2015 19:17:19 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6312
MAPREDUCE-6313,Test,Major,,Audit/optimize tests in hadoop-mapreduce-client-jobclient,The tests in this package take an extremely long time to run; with some tests taking 15-20 minutes on their own.  It would be worthwhile to verify and optimize any tests in this package in order to reduce patch testing time or perhaps even splitting the package up.,Open,Unresolved,,nijel,Allen Wittenauer,Fri; 10 Apr 2015 03:35:11 +0000,Sat; 16 Jul 2016 01:30:44 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6313
MAPREDUCE-6314,Bug,Major,test,TestPipeApplication fails on trunk,MAPREDUCE-6291 causes the TestPipeApplication#testSubmitter test to fail.,Resolved,Fixed,,Varun Vasudev,Varun Vasudev,Fri; 10 Apr 2015 05:29:29 +0000,Tue; 30 Aug 2016 01:18:12 +0000,Fri; 10 Apr 2015 08:34:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6314
MAPREDUCE-6315,Improvement,Critical,client;mr-am,Implement retrieval of logs for crashed MR-AM via jhist in the staging directory,When all AM attempts crash; there is no record of them in JHS. Thus no easy way to get the logs. This JIRA automates the procedure by utilizing the jhist file in the staging directory.,Open,Unresolved,,Unassigned,Gera Shegalov,Mon; 13 Apr 2015 20:08:50 +0000,Mon; 9 Oct 2017 21:14:46 +0000,,,2.7.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6315
MAPREDUCE-6316,Improvement,Major,,Task Attempt List entries should link to the task overview,Typical workflow is to click on the list of failed attempts. Then you want to look at the counters; or the list of attempts of just one task in general. If each entry task attempt id linked the task id portion of it back to the task; we would not have to go through the list of tasks to search for the task.,Resolved,Fixed,,Siqi Li,Siqi Li,Mon; 13 Apr 2015 23:36:59 +0000,Tue; 30 Aug 2016 01:18:10 +0000,Sat; 20 Jun 2015 19:01:21 +0000,,,BB2015-05-TBR,MAPREDUCE-6319,,https://issues.apache.org/jira/browse/MAPREDUCE-6316
MAPREDUCE-6317,Bug,Minor,applicationmaster;mr-am,Invalid Resource Exception could be handled properly when cores not available,Configure yarn.nodemanager.resource.cpu-vcores=2 for NM Set mapreduce.map.cpu.vcores=5 while running sleep job n client      Rm communication timeout is thrown and fails after 2 app attempts Invalid resource exception not handled in RM container allocator    RMContainerAllocator should handle invalid resource exception and wait till new nodemanager added with expected resource,Resolved,Duplicate,MAPREDUCE-5279,Bibin A Chundatt,Bibin A Chundatt,Fri; 10 Apr 2015 15:24:50 +0000,Sat; 11 Jul 2015 19:05:38 +0000,Sat; 11 Jul 2015 19:05:38 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6317
MAPREDUCE-6318,Sub-task,Major,jobhistoryserver,Refactor JobHistoryEventHandler for handling events in ATS v1,Per discussion in YARN-3046; we need to refactor the process flow for timeline events (ATS v1) in JobHistoryEventHandler. The refactor work should get happen after YARN-2928 merged into trunk and branch-2.,Open,Unresolved,,Junping Du,Junping Du,Wed; 15 Apr 2015 01:32:26 +0000,Sat; 19 Aug 2017 16:28:16 +0000,,,,,,MAPREDUCE-6327,https://issues.apache.org/jira/browse/MAPREDUCE-6318
MAPREDUCE-6319,Improvement,Minor,webapps,Get rid of the usage of parseHadoopAttemptID in HsTaskPage for consistency,Per Gera Shegalov's comment in MAPREDUCE-6300:  parseHadoopAttemptID function in yarn.plugin.dt.js is used only by HsTaskPage for sorting MapReduce attempt id by numerical. On the other hand; others are calling parseHadoopID function for sorting various ids (including MapReduce attempt id) by string. We can get rid of parseHadoopAttemptID and replace with parseHadoopID for consistency.,Open,Unresolved,,Brahma Reddy Battula,Akira Ajisaka,Thu; 16 Apr 2015 15:50:27 +0000,Sat; 7 Jan 2017 01:59:52 +0000,,,,,MAPREDUCE-6316,MAPREDUCE-6300,https://issues.apache.org/jira/browse/MAPREDUCE-6319
MAPREDUCE-6320,Bug,Major,,Configuration of retrieved Job via Cluster is not properly set-up,"When getting a Job via the Cluster API; it is not correctly configured.  To reproduce this:   	Submit a MR job; and set some arbitrary parameter to its configuration   	Get the job in a client:   	Get its ""foo"" entry   	Expected: s is ""bar""; But: s is null.    The reason is that the job's configuration is stored on HDFS (the Configuration has a resource with a hdfs: ...); which does not exist; and thus the configuration is not populated.  The bug happens in the Cluster class; where JobConfs are created from status.getJobFile(). A quick fix would be to copy this job file to a temporary file in the local file system and populate the JobConf from this file.",Patch Available,Unresolved,,Jens Rabe,Jens Rabe,Fri; 17 Apr 2015 12:26:41 +0000,Wed; 6 May 2015 03:29:30 +0000,,,,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6320
MAPREDUCE-6321,Improvement,Critical,mrv2,Map tasks take a lot of time to start up,I have noticed repeatedly that the map tasks take a lot of time to startup on YARN clusters. This is not the scheduling part; this is after the actual container is launched containing the Map task. Take for example; the sample log from a mapper of a Pi job that I launched. The command I used to launch the Pi job was:     This is the sample job from one of the mappers which took 14 seconds to complete. If you notice from the logs; most of the time taken by this job is during the start up. I notice that the most mappers take anywhere between 7 to 15 seconds during start up and have seen this behavior consistent across mapreduce jobs. This really affects the performance of short running mappers.  I run a hadoop2   yarn cluster on a 4-5 node m1.xlarge cluster; and the mapper memory is always specified as 2048m and so on.  Log:,Open,Unresolved,,Unassigned,Rajat Jain,Sat; 18 Apr 2015 06:57:52 +0000,Mon; 18 Jul 2016 18:52:07 +0000,,,2.6.0,performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-6321
MAPREDUCE-6322,Bug,Major,,MapReduce Integration tests with mini cluster fail on Jenkins when path to workspace contains characters which need to be escaped in shell scripts,When building a project with Jenkins which contains integration tests for Map Reduce jobs; the tests fail when the path to the workspace Jenkins builds in contains characters which need to be escaped in shell scripts; like whitespaces or parentheses.  Example output:    The script default_container_executor.sh should be generated in a way that such characters are escaped.,Open,Unresolved,,Unassigned,Jens Rabe,Mon; 20 Apr 2015 10:31:37 +0000,Mon; 20 Apr 2015 10:31:37 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6322
MAPREDUCE-6323,Improvement,Minor,mrv2;performance,Support pass-by-reference for ChainMapper/ChainReducer,ChainMapper and ChainReducer using the new mapreduce API always copy the (key;value) pair between chain elements. It actually looks the copy is done twice; once when queueing; and once when dequeuing!  When transferred objects are immutable (or not reused); this is a waste of resource (especially when passing big records),Open,Unresolved,,Unassigned,Laurent Goujon,Tue; 21 Apr 2015 15:44:12 +0000,Tue; 21 Apr 2015 15:44:12 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6323
MAPREDUCE-6324,Bug,Blocker,mr-am,Uber jobs fail to update AMRM token when it rolls over,When the RM rolls a new AMRM master key the AMs are supposed to receive a new AMRM token on subsequent heartbeats between the time when the new key is rolled and when it is activated.  This is not occurring for uber jobs.  If the connection to the RM needs to be re-established after the new key is activated (e.g.: RM restart or network hiccup) then the uber job AM will be unable to reconnect to the RM.,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 21 Apr 2015 19:56:31 +0000,Fri; 6 Jan 2017 00:42:37 +0000,Mon; 27 Apr 2015 22:01:59 +0000,,2.6.0,2.6.1-candidate,,MAPREDUCE-6230,https://issues.apache.org/jira/browse/MAPREDUCE-6324
MAPREDUCE-6325,New Feature,Minor,applicationmaster,Support use of ephemeral client ports for shuffle/etc.,Forking out from MAPREDUCE-5036.  Please see comments https: MAPREDUCE-5036?focusedCommentId=14384339page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14384339 onwards for more discussion details that lead to this JIRA.,Open,Unresolved,,Unassigned,Harsh J,Tue; 21 Apr 2015 20:02:59 +0000,Tue; 21 Apr 2015 20:03:58 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6325
YARN-3523,Bug,Major,client;resourcemanager,Cleanup ResourceManagerAdministrationProtocol interface audience,I noticed ResourceManagerAdministrationProtocol has @Private audience for the class and @Public audience for methods. It doesn't make sense to me. We should make class audience and methods audience consistent.,Resolved,Fixed,,Naganarasimha G R,Wangda Tan,Tue; 21 Apr 2015 22:40:28 +0000,Tue; 30 Aug 2016 01:23:50 +0000,Thu; 7 May 2015 12:22:22 +0000,,,newbie,,,https://issues.apache.org/jira/browse/YARN-3523
MAPREDUCE-6327,Sub-task,Major,,[Event producers] Implement MapReduce AM writing MR events/counters to v2 ATS,Per design in YARN-2928; select a handful of MR metrics (e.g. HDFS bytes written) and have the MR AM write the framework-specific metrics to ATS.,Resolved,Fixed,,Junping Du,Sangjin Lee,Tue; 13 Jan 2015 00:53:40 +0000,Sat; 21 Oct 2017 06:29:12 +0000,Tue; 21 Apr 2015 23:36:02 +0000,,,,MAPREDUCE-6189,MAPREDUCE-6318;YARN-3488;YARN-3334,https://issues.apache.org/jira/browse/MAPREDUCE-6327
MAPREDUCE-6328,Bug,Major,,NPE in TaskAttemptContextImpl.java,yarn jar .. TESTBBP    INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead; use mapreduce.task.output.dir  136),Open,Unresolved,,Brahma Reddy Battula,Brahma Reddy Battula,Wed; 22 Apr 2015 02:06:07 +0000,Thu; 23 Apr 2015 01:49:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6328
YARN-3535,Bug,Critical,capacityscheduler;fairscheduler;resourcemanager,Scheduler must re-request container resources when RMContainer transitions from ALLOCATED to KILLED,During rolling update of NM; AM start of container on NM failed.  And then job hang there. Attach AM logs.,Closed,Fixed,,Peng Zhang,Peng Zhang,Wed; 22 Apr 2015 06:01:59 +0000,Thu; 1 Dec 2016 23:28:31 +0000,Fri; 17 Jul 2015 11:33:53 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/YARN-3535
MAPREDUCE-6330,Bug,Minor,documentation,Fix typo in Task Attempt API's URL in documentations,Some Task Attempt API's URL is typo. attempt is wrong,Resolved,Fixed,,Ryu Kobayashi,Ryu Kobayashi,Wed; 22 Apr 2015 09:41:52 +0000,Tue; 30 Aug 2016 01:18:05 +0000,Wed; 22 Apr 2015 18:30:16 +0000,,2.7.0,,,HADOOP-11854,https://issues.apache.org/jira/browse/MAPREDUCE-6330
MAPREDUCE-6331,New Feature,Major,,[Umbrella] Make MapReduce work with Timeline Service Nextgen (YARN-2928),Tracking umbrella for all MR changes to make it work with Timeline Service Nextgen - YARN-2928.,Resolved,Fixed,,Sangjin Lee,Vinod Kumar Vavilapalli,Wed; 22 Apr 2015 17:08:20 +0000,Sat; 21 Oct 2017 06:31:04 +0000,Mon; 11 Jul 2016 03:46:24 +0000,,,,,MAPREDUCE-6732;MAPREDUCE-5858,https://issues.apache.org/jira/browse/MAPREDUCE-6331
MAPREDUCE-6332,New Feature,Major,,Provide facility to users for writting custom MergeManager implementation when custom shuffleconsumerPluggin is used,MR provides ability to the user for plugin custom ShuffleConsumerPlugin using mapreduce.job.reduce.shuffle.consumer.plugin.class.  When the user is allowed to use this configuration as plugin; user also interest in implementing his own MergeManagerImpl.   But now ; user is forced to use MR provided MergeManagerImpl instead of custom MergeManagerImpl when user is using shuffle.consumer.plugin class. There should be well defined API's in MergeManager that can be used for any implementation without much effort to user for custom implementation.,Open,Unresolved,,Rohith Sharma K S,Rohith Sharma K S,Wed; 22 Apr 2015 19:33:38 +0000,Sat; 7 Jan 2017 02:00:00 +0000,,,,,,MAPREDUCE-4808,https://issues.apache.org/jira/browse/MAPREDUCE-6332
MAPREDUCE-6333,Bug,Major,,TestEvents;TestAMWebServicesTasks;TestAppController are broken due to MAPREDUCE-6297,For some reason; tests in MAPREDUCE-6297 are all passed,Resolved,Fixed,,Siqi Li,Siqi Li,Wed; 22 Apr 2015 20:55:49 +0000,Tue; 30 Aug 2016 01:18:03 +0000,Sat; 25 Apr 2015 00:43:52 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6333
MAPREDUCE-6334,Bug,Blocker,,Fetcher#copyMapOutput is leaking usedMemory upon IOException during InMemoryMapOutput shuffle handler,"We are seeing this happen when  	an NM's disk goes bad during the creation of map output(s) 	the reducer's fetcher can read the shuffle header and reserve the memory 	but gets an IOException when trying to shuffle for InMemoryMapOutput 	shuffle fetch retry is enabled",Closed,Fixed,MAPREDUCE-6351,Eric Payne,Eric Payne,Thu; 23 Apr 2015 20:22:08 +0000,Thu; 5 Jan 2017 22:38:52 +0000,Tue; 28 Apr 2015 20:21:23 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6334
MAPREDUCE-6335,Sub-task,Major,,convert load test driver to timeline service v.2,This subtask covers the work for converting the proposed patch for the load test driver (YARN-2556) to work with the timeline service v.2.,Resolved,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 2 Apr 2015 17:19:36 +0000,Sat; 21 Oct 2017 06:29:23 +0000,Wed; 29 Apr 2015 02:48:34 +0000,,,,,MAPREDUCE-6546;YARN-2556,https://issues.apache.org/jira/browse/MAPREDUCE-6335
MAPREDUCE-6336,Improvement,Major,mrv2,Enable v2 FileOutputCommitter by default,This JIRA is to propose making new FileOutputCommitter behavior from MAPREDUCE-4815 enabled by default in trunk; and potentially in branch-2.,Resolved,Fixed,,Siqi Li,Gera Shegalov,Fri; 24 Apr 2015 00:23:04 +0000,Thu; 12 May 2016 18:22:46 +0000,Wed; 27 May 2015 22:49:05 +0000,,2.7.0,BB2015-05-TBR,,,https://issues.apache.org/jira/browse/MAPREDUCE-6336
MAPREDUCE-6337,Sub-task,Major,,add a mode to replay MR job history files to the timeline service,The subtask covers the work on top of YARN-3437 to add a mode to replay MR job history files to the timeline service storage.,Resolved,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 2 Apr 2015 17:21:39 +0000,Sat; 21 Oct 2017 06:29:34 +0000,Thu; 14 May 2015 22:32:04 +0000,,,,,YARN-3562;YARN-3634,https://issues.apache.org/jira/browse/MAPREDUCE-6337
MAPREDUCE-6338,Bug,Major,mr-am;mrv2,MR AppMaster does not honor ephemeral port range,The MR AppMaster should only use port ranges defined in the yarn.app.mapreduce.am.job.client.port-range property.  On initial startup of the MRAppMaster; it does use the port range defined in the property.  However; it also opens up a listener on a random ephemeral port.  This is not the Jetty listener.  It is another listener opened by the MRAppMaster via another thread and is recognized by the RM.  Other nodes will try to communicate to it via that random port.  With firewall settings on; the MR job will fail because the random port is not opened.  This problem has caused others to have all OS ephemeral ports opened to have MR jobs run.  This is related to MAPREDUCE-4079,Resolved,Fixed,,Frank Nguyen,Frank Nguyen,Fri; 24 Apr 2015 05:02:22 +0000,Mon; 6 Feb 2017 03:59:03 +0000,Mon; 6 Feb 2017 03:36:11 +0000,,2.6.0,,,HADOOP-12097;MAPREDUCE-6404,https://issues.apache.org/jira/browse/MAPREDUCE-6338
MAPREDUCE-6339,Bug,Critical,mrv2,Job history file is not flushed correctly because isTimerActive flag is not set true when flushTimerTask is scheduled.,Job history file is not flushed correctly because isTimerActive flag is not set true when flushTimerTask is scheduled. It looks like we should set isTimerActive to true when flushTimerTask is scheduled. Otherwise if a new qualified event comes before the current flush timer is expired;  flushTimerTask will be canceled and rescheduled. Also I didn't find any code which set isTimerActive flag to true; So isTimerActive is useless in current code.,Closed,Fixed,MAPREDUCE-6348,zhihai xu,zhihai xu,Mon; 27 Apr 2015 04:14:45 +0000,Fri; 6 Jan 2017 00:45:27 +0000,Thu; 30 Apr 2015 07:13:58 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6339
HDFS-8349,Bug,Minor,,Remove .xml and documentation references to dfs.webhdfs.enabled,HDFS-7985 removed any references in the code to the dfs.webhdfs.enabled property.  The property should also be removed from hdfs-default.xml as well as other places.  As mentioned in HDFS-7985; this is an incompatible change with branch-2; so this fix should be limited to trunk.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Mon; 27 Apr 2015 13:52:26 +0000,Thu; 12 May 2016 18:17:20 +0000,Fri; 8 May 2015 06:59:05 +0000,,3.0.0-alpha1,supportability,,HDFS-7985,https://issues.apache.org/jira/browse/HDFS-8349
MAPREDUCE-6341,Bug,Trivial,,Fix typo in mapreduce tutorial,There are some typos in the converted tutorial in markdown.,Resolved,Fixed,,John Michael Luy,John Michael Luy,Mon; 27 Apr 2015 11:22:49 +0000,Tue; 30 Aug 2016 01:17:58 +0000,Wed; 17 Feb 2016 05:20:11 +0000,,,,,HADOOP-11854,https://issues.apache.org/jira/browse/MAPREDUCE-6341
MAPREDUCE-6342,Bug,Minor,build,Make POM project names consistent,This is track MR changes for POM changes  by name,Resolved,Fixed,,Rohith Sharma K S,Rohith Sharma K S,Mon; 27 Apr 2015 17:51:07 +0000,Tue; 30 Aug 2016 01:17:58 +0000,Fri; 8 May 2015 09:53:14 +0000,,,,,YARN-2784,https://issues.apache.org/jira/browse/MAPREDUCE-6342
MAPREDUCE-6343,Bug,Major,,JobConf.parseMaximumHeapSizeMB() fails to parse value greater than 2GB expressed in bytes,It currently tries to parse the value as an integer; which blows up whenever the value is greater than 2GB and expressed in bytes.,Resolved,Fixed,,Hao Xia,Hao Xia,Mon; 27 Apr 2015 22:53:55 +0000,Thu; 12 May 2016 18:24:27 +0000,Tue; 28 Apr 2015 21:06:16 +0000,,3.0.0-alpha1,,,MAPREDUCE-5785,https://issues.apache.org/jira/browse/MAPREDUCE-6343
MAPREDUCE-6344,Bug,Major,,Inconsistent classpath/classloading from DistributedCache archives,We recently upgraded to MRv2 on YARN and have been noticing very inconsistent classloading between the job submission client and the tasks as they start up.   I've tracked the issue to this method:  https:  L270,Patch Available,Unresolved,,Unassigned,Preston Koprivica,Tue; 28 Apr 2015 18:51:16 +0000,Tue; 17 Nov 2015 22:38:14 +0000,,,2.5.0;2.6.0;2.7.0;2.5.1;2.5.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6344
MAPREDUCE-6345,Bug,Trivial,documentation,Documentation fix for when CRLA is enabled for MRAppMaster logs,CRLA is enabled for the ApplicationMaster when both yarn.app.mapreduce.am.container.log.limit.kb (not mapreduce.task.userlog.limit.kb) and yarn.app.mapreduce.am.container.log.backups are greater than zero.  This was changed in MAPREDUCE-5773.,Resolved,Fixed,,Rohit Agarwal,Rohit Agarwal,Wed; 29 Apr 2015 09:38:37 +0000,Tue; 30 Aug 2016 01:17:54 +0000,Sat; 2 May 2015 02:28:43 +0000,,2.4.0;2.5.0;2.6.0;2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6345
MAPREDUCE-6346,Bug,Major,,mapred.nativetask.kvtest.KVTest crashes on PPC64LE,"Test org.apache.hadoop.mapred.nativetask.kvtest.KVTest (and 5 or 6 other tests) crashes on PPC64LE .  ....   INFO Mid-spill:  { id: 4; collect: 245 ms; in-memory sort: 32 ms; in-memory records: 48202; mergespill: 80 ms; uncompressed size: 5031451; real size: 3739319 path:  hs_error.log :   	C  libnativetask.so.1.0.0+0x58e50  NativeTask::WritableUtils::ReadVLongInner(char const*; unsigned int)+0x40",Resolved,Duplicate,MAPREDUCE-6459,Ayappan,Tony Reix,Wed; 29 Apr 2015 13:17:17 +0000,Tue; 16 May 2017 15:42:26 +0000,Tue; 16 May 2017 15:42:26 +0000,,3.0.0-alpha1,,,MAPREDUCE-6459,https://issues.apache.org/jira/browse/MAPREDUCE-6346
MAPREDUCE-6347,Test,Major,,TestBinaryTokenFile (and others) fail,Seeing the following stack trace and the unit test goes into a infinite loop:  2013-06-24 17:03:58;316 ERROR LocalizerRunner for container_1372118631537_0001_01_000001 security.UserGroupInformation (UserGroupInformation. 859),Resolved,Cannot Reproduce,YARN-874,Unassigned,Kam Kasravi,Tue; 25 Jun 2013 00:07:47 +0000,Fri; 1 May 2015 11:49:57 +0000,Fri; 1 May 2015 11:49:57 +0000,,2.0.4-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6347
MAPREDUCE-6348,Bug,Minor,jobhistoryserver,JobHistoryEventHandler could not flush every 30 secondes,JobHistoryEventHandler could not flush the event every 30 seconds. cause the var isTimerActive is never set to true.,Resolved,Duplicate,MAPREDUCE-6339,Unassigned,qus-jiawei,Wed; 24 Jul 2013 04:08:19 +0000,Mon; 4 May 2015 10:00:37 +0000,Mon; 4 May 2015 10:00:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6348
MAPREDUCE-6349,Bug,Minor,,Fix typo in property org.apache.hadoop.mapreduce.lib.chain.Chain.REDUCER_INPUT_VALUE_CLASS,Ran across this typo in a property.  It doesn't look like it's used anywhere externally.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Fri; 1 May 2015 19:18:47 +0000,Tue; 30 Aug 2016 01:17:52 +0000,Mon; 4 May 2015 06:38:08 +0000,,2.7.0,BB2015-05-TBR;newbie,,HADOOP-11854,https://issues.apache.org/jira/browse/MAPREDUCE-6349
MAPREDUCE-6350,Bug,Critical,jobhistoryserver,JobHistory doesn't support fully-functional search,job history server will only output the first 50 characters of the job names in webUI.,Resolved,Fixed,,Siqi Li,Siqi Li,Fri; 17 Jan 2014 20:38:59 +0000,Tue; 30 Aug 2016 01:17:50 +0000,Wed; 10 Jun 2015 07:18:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6350
MAPREDUCE-6351,Bug,Major,mrv2,Reducer hung in copy phase.,"Problem Reducer gets stuck in copy phase and doesn't make progress for very long time. After killing this task for couple of times manually; it gets completed.   Observations  	Verfied gc logs. Found no memory related issues. Attached the logs. 	Verified thread dumps. Found no thread related problems. 	On verification of logs; fetcher threads are not copying the map outputs and they are just waiting for merge to happen. 	Merge thread is alive and in wait state.     Analysis  On careful observation of logs; thread dumps and code; this looks to me like a classic case of multi-threading issue. Thread goes to wait state after it has been notified.   Here is the suspect code flow. Thread #1 Fetcher thread - notification comes first org.apache.hadoop.mapreduce.task.reduce.MergeThread.startMerge(SetT)    Thread #2 Merge Thread - goes to wait state (Notification goes unconsumed) org.apache.hadoop.mapreduce.task.reduce.MergeThread.run()",Resolved,Duplicate,MAPREDUCE-6334,Laxman,Laxman,Sat; 2 May 2015 16:51:08 +0000,Wed; 16 Sep 2015 08:09:34 +0000,Wed; 16 Sep 2015 08:09:34 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6351
HADOOP-11904,Test,Critical,test,test-patch.sh goes into an infinite loop on non-maven builds,If post HADOOP-11746 test patch is given a non-maven-based build; it goes into an infinite loop looking for modules pom.xml.  There should be an escape clause after switching branches to see if it is maven based. If it is not maven based; then test-patch should either abort or re-exec using that version's test-patch script.,Resolved,Fixed,,Allen Wittenauer,Allen Wittenauer,Sat; 2 May 2015 17:59:29 +0000,Tue; 30 Aug 2016 01:28:53 +0000,Tue; 5 May 2015 18:08:26 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-11904
MAPREDUCE-6353,Bug,Major,mr-am,Divide by zero error in MR AM when calculating available containers,When running a sleep job with zero CPU vcores i see the following exception  2015-04-30 06:41:06;954 ERROR RMCommunicator Allocator org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM.   745),Resolved,Fixed,,Anubhav Dhoot,Anubhav Dhoot,Sun; 3 May 2015 14:10:44 +0000,Tue; 30 Aug 2016 01:17:49 +0000,Sat; 9 May 2015 21:47:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6353
MAPREDUCE-6354,Improvement,Major,,ShuffleHandler should be able to log shuffle connections,currently; shuffle handler only log connection info in debug mode; we want to log that info in a more concise way,Resolved,Fixed,,Chang Li,Chang Li,Mon; 4 May 2015 17:07:44 +0000,Tue; 30 Aug 2016 01:17:48 +0000,Fri; 5 Jun 2015 22:40:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6354
MAPREDUCE-6355,Bug,Major,,2.5 client cannot communicate with 2.5 job on 2.6 cluster,Trying to run a job on a Hadoop 2.6 cluster from a Hadoop 2.5 client submitting a job that uses Hadoop 2.5 jars results in a job that succeeds but the client cannot communicate with the AM while the job is running.,Resolved,Won't Fix,,Unassigned,Jason Lowe,Mon; 4 May 2015 21:36:00 +0000,Fri; 27 Nov 2015 17:51:18 +0000,Tue; 3 Nov 2015 23:51:20 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6355
MAPREDUCE-6356,Bug,Minor,test,Misspelling of threshold in log4j.properties for tests,"log4j.properties file for test contains misspelling ""log4j.threshhold"". We should use ""log4j.threshold"" correctly.",Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Tue; 5 May 2015 13:32:46 +0000,Tue; 30 Aug 2016 01:17:47 +0000,Thu; 7 May 2015 10:44:21 +0000,,2.7.0,,,HADOOP-11854;HADOOP-10387,https://issues.apache.org/jira/browse/MAPREDUCE-6356
MAPREDUCE-6357,Bug,Major,documentation,MultipleOutputs.write() API should document that output committing is not utilized when input path is absolute,After spending the afternoon debugging a user job where reduce tasks were failing on retry with the below exception; I think it would be worthwhile to add a note in the MultipleOutputs.write() documentation; saying that absolute paths may cause improper execution of tasks on retry or when MR speculative execution is enabled.      As discussed in MAPREDUCE-3772; when the baseOutputPath passed to MultipleOutputs.write() is an absolute path (or more precisely a path that resolves outside of the job output-dir); the concept of output committing is not utilized.   In this case; the user read thru the MultipleOutputs docs and was assuming that everything will be working fine; as there are blog posts saying that MultipleOutputs does handle output commit.,Resolved,Fixed,,Dustin Cote,Ivan Mitic,Tue; 5 May 2015 18:11:38 +0000,Tue; 30 Aug 2016 01:17:42 +0000,Fri; 21 Aug 2015 01:45:30 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6357
MAPREDUCE-6358,Bug,Major,documentation;mrv2;test,Document missing properties in mapred-default.xml,The following properties are currently not defined in mapred-default.xml. These properties should either be A) documented in mapred-default.xml OR B) listed as an exception (with comments; e.g. for internal use) in the TestMapreduceConfigFields unit test,Open,Unresolved,,Ray Chiang,Ray Chiang,Thu; 7 May 2015 05:30:28 +0000,Tue; 23 Jun 2015 21:38:40 +0000,,,2.7.0,supportability;test,MAPREDUCE-6192,HDFS-8356;YARN-3069,https://issues.apache.org/jira/browse/MAPREDUCE-6358
MAPREDUCE-6359,Bug,Minor,,"RM HA setup; ""Cluster"" tab links populated with AM hostname instead of RM ",In RM HA setup ( e.g. http: cluster ).  The port details for secure and unsecure cluster is given below :-   8088 ( DEFAULT_RM_WEBAPP_PORT = 8088 )   8090  ( DEFAULT_RM_WEBAPP_HTTPS_PORT = 8090 )  Ideally; it should have pointed to resourcemanager hostname instead of AM hostname.,Resolved,Fixed,YARN-3560,yunjiong zhao,Aroop Maliakkal,Tue; 31 Mar 2015 08:57:00 +0000,Thu; 26 Oct 2017 13:22:12 +0000,Sat; 9 May 2015 12:55:51 +0000,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6359
MAPREDUCE-6360,Bug,Major,,TestMapreduceConfigFields is placed in wrong dir; introducing compile error,MAPREDUCE-6192 has introduced a Test file {{TestMapreduceConfigFields }} which was committed in package org.apache.hadoop.mapred But the package declaration  inside file is org.apache.hadoop.mapreduce.  By surprise; this is not giving any compile errors in maven build. But eclipse catches it. So move TestMapreduceConfigFields }} to correct package  {{org.apache.hadoop.mapreduce,Resolved,Fixed,,Mohammad Arshad,Vinayakumar B,Mon; 11 May 2015 09:55:30 +0000,Tue; 30 Aug 2016 01:17:40 +0000,Tue; 12 May 2015 07:40:43 +0000,,,,,HDFS-8362,https://issues.apache.org/jira/browse/MAPREDUCE-6360
MAPREDUCE-6361,Bug,Critical,,NPE issue in shuffle caused by concurrent issue between copySucceeded() in one thread and copyFailed() in another thread on the same host,The failure in log: 2015-05-08 21:00:00;513 WARN main org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#25           org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 193),Closed,Fixed,,Junping Du,Junping Du,Mon; 11 May 2015 15:36:10 +0000,Fri; 6 Jan 2017 00:48:45 +0000,Tue; 12 May 2015 15:30:47 +0000,,2.7.0,2.6.1-candidate,,,https://issues.apache.org/jira/browse/MAPREDUCE-6361
MAPREDUCE-6362,Bug,Major,,History Plugin should be updated,As applications complete; the RM tracks their IDs in a completed list. This list is routinely truncated to limit the total number of application remembered by the RM.  When a user clicks the History for a job; either the browser is redirected to the application's tracking link obtained from the stored application instance. But when the application has been purged from the RM; an error is displayed.  In very busy clusters the rate at which applications complete can cause applications to be purged from the RM's internal list within hours; which breaks the proxy URLs users have saved for their jobs.  We would like the RM to provide valid tracking links persist so that users are not frustrated by broken links.  With the current plugin in place; redirections for the Mapreduce jobs works but we need the add functionality for tez jobs,Patch Available,Unresolved,,Mit Desai,Mit Desai,Mon; 11 May 2015 18:27:29 +0000,Fri; 15 Dec 2017 20:31:15 +0000,,,2.6.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6362
MAPREDUCE-6363,Bug,Critical,benchmarks,[NNBench] Lease mismatch error when running with multiple mappers,Command :  . file_linux-214__0 owned by DFSClient_attempt_1371782327901_0001_m_000048_0_1383437860_1 but is accessed by DFSClient_attempt_1371782327901_0001_m_000084_0_1880545303_1   org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation. 1232),Closed,Fixed,HADOOP-15020,Bibin A Chundatt,Brahma Reddy Battula,Mon; 24 Jun 2013 13:15:10 +0000,Wed; 8 Nov 2017 04:40:25 +0000,Tue; 22 Mar 2016 16:46:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6363
MAPREDUCE-6364,New Feature,Minor,applicationmaster,"Add a ""Kill"" link to Task Attempts page","Add a ""Kill"" link to Task Attempts page; calling REST API by pushing the link.",Resolved,Fixed,,Ryu Kobayashi,Ryu Kobayashi,Tue; 12 May 2015 06:56:29 +0000,Tue; 30 Aug 2016 01:17:34 +0000,Tue; 26 May 2015 15:07:09 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6364
MAPREDUCE-6365,Improvement,Minor,,Refactor JobResourceUploader#uploadFilesInternal,JobResourceUploader#uploadFilesInternal is a large method and there are similar pieces of code that could probably be pulled out into separate methods.  This refactor would improve readability of the code.,Resolved,Fixed,,Chris Trezzo,Chris Trezzo,Wed; 13 May 2015 01:48:26 +0000,Tue; 30 Aug 2016 01:17:31 +0000,Wed; 20 Jul 2016 03:20:00 +0000,,,,,MAPREDUCE-5951,https://issues.apache.org/jira/browse/MAPREDUCE-6365
MAPREDUCE-6366,Bug,Trivial,examples,mapreduce.terasort.final.sync configuration in TeraSort  doesn't work,"A TeraOutputFormat's field; finalSync; is always set ""true"". Therefore TeraSort 's  mapreduce.terasort.final.sync option doesn't work.",Resolved,Fixed,,Takuya Fukudome,Takuya Fukudome,Wed; 13 May 2015 02:00:42 +0000,Tue; 30 Aug 2016 01:17:28 +0000,Wed; 13 May 2015 07:47:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6366
MAPREDUCE-6367,Bug,Minor,,UniformSizeInputFormat skews left over bytes to last split,In UniformSizeInputFormat it is trying to get equal amount of bytes to every split. But the logic today will result in every split having a little less then the perfect amount and that left over from every split will be put into the last split.  Resulting in a large skew for the last split.  Below if the area of the code that is affected:  https:  L98  The fix would be to change the following line:  currentSplitSize += srcFileStatus.getLen();  to  currentSplitSize += srcFileStatus.getLen() + (currentSplitSize - nBytesPerSplit);,Resolved,Invalid,,Theodore michael Malaska,Theodore michael Malaska,Fri; 15 May 2015 20:39:30 +0000,Mon; 18 May 2015 00:39:40 +0000,Mon; 18 May 2015 00:39:40 +0000,,2.6.0;2.5.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6367
MAPREDUCE-6368,Bug,Minor,mrv2,Unreachable Java code,Reference Class: org.apache.hadoop.mapreduce.lib.partition.InputSampler Method: writePartitionFile Line: 337  The issue exists in the following code loop  as well (it's worth checking).  Thanks  Regards; Dhiraj,Resolved,Invalid,,Dhiraj Nilange,Dhiraj Nilange,Sun; 17 May 2015 13:40:29 +0000,Mon; 28 Sep 2015 20:43:25 +0000,Mon; 28 Sep 2015 20:43:25 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6368
MAPREDUCE-6369,Bug,Major,,MR compile shouldn't depend on nodemanager,Dependency analysis shows MR depends on nodemanager. If possible; MR shouldn't depend on any yarn-server APIs at all. This might require some changes in Yarn.,Open,Unresolved,,Unassigned,Karthik Kambatla,Tue; 19 May 2015 16:52:55 +0000,Wed; 20 May 2015 02:18:11 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6369
MAPREDUCE-6370,Sub-task,Major,,Timeline service v2 load generator needs to write event id,We need to write a sample event id in SimpleEntityWriter so that both HBase and Phoenix writers can actually write the timeline event. For now the Phoenix implementation will throw exceptions and the HBase will skip storing the timeline event.,Resolved,Fixed,,Li Lu,Li Lu,Thu; 21 May 2015 23:49:38 +0000,Sat; 21 Oct 2017 06:29:43 +0000,Fri; 22 May 2015 07:01:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6370
MAPREDUCE-6371,Bug,Minor,jobhistoryserver,HTML tag shown in Diagnostics field of JobHistoryPage,Diagnostics shown wrong in Jobhistory page Incase of failed task     Please check the image for detail,Resolved,Duplicate,MAPREDUCE-6382,J.Andreina,Bibin A Chundatt,Tue; 26 May 2015 15:37:03 +0000,Tue; 9 Jun 2015 06:25:21 +0000,Tue; 9 Jun 2015 05:56:17 +0000,,2.8.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6371
MAPREDUCE-6372,Sub-task,Major,,clean up several issues with TimelineServicePerformance,We found a few issues with the TimelineServicePerformanceV2 test driver while running it for the performance tests. Filing this JIRA to fix those issues.,Resolved,Resolved,,Sangjin Lee,Sangjin Lee,Wed; 27 May 2015 01:16:54 +0000,Sat; 21 Oct 2017 06:29:52 +0000,Mon; 21 Mar 2016 22:54:57 +0000,,YARN-2928,yarn-2928-1st-milestone,,,https://issues.apache.org/jira/browse/MAPREDUCE-6372
MAPREDUCE-6373,Bug,Trivial,,The logger reports total input paths but it is referring to input files,The log message in the FileInputFormat is misleading :       There is only 1 input path and 6 input files so the log message should be :,Resolved,Fixed,,Bibin A Chundatt,Andi Chirita Amdocs,Wed; 27 May 2015 07:47:52 +0000,Tue; 30 Aug 2016 01:17:28 +0000,Thu; 18 Jun 2015 06:18:17 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6373
MAPREDUCE-6374,Bug,Major,,Distributed Cache File visibility should check permission of full path,should do full ancestor permission check for a relative cache file input,Resolved,Fixed,,Chang Li,Chang Li,Wed; 27 May 2015 22:20:47 +0000,Tue; 30 Aug 2016 01:17:27 +0000,Wed; 3 Jun 2015 20:21:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6374
MAPREDUCE-6375,Bug,Major,,Modify the JHS to be able to read the ConcatenatableAggregatedLogFormat,When serving logs; the JHS needs to be able to read the ConcatenatableAggregatedLogFormat or the AggregatedLogFormat transparently.  (see YARN-2942),Resolved,Won't Fix,,Robert Kanter,Robert Kanter,Thu; 28 May 2015 02:24:31 +0000,Mon; 17 Oct 2016 21:47:31 +0000,Mon; 17 Oct 2016 21:47:27 +0000,,2.8.0,,,YARN-2942,https://issues.apache.org/jira/browse/MAPREDUCE-6375
MAPREDUCE-6376,Sub-task,Major,jobhistoryserver,Add avro binary support for jhist files,When you click on a Job link in the JHS Web UI; it loads the .jhist file.  For jobs which have a large number of tasks; the load time can break UI responsiveness.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Thu; 28 May 2015 18:45:55 +0000,Tue; 30 Aug 2016 01:17:26 +0000,Wed; 1 Jul 2015 16:08:27 +0000,,2.7.0,supportability,MAPREDUCE-6388,MAPREDUCE-6613;MAPREDUCE-6222;MAPREDUCE-6394,https://issues.apache.org/jira/browse/MAPREDUCE-6376
MAPREDUCE-6377,Bug,Minor,jobhistoryserver,JHS sorting on state column not working in webUi,Steps to reproduce ================ 1. Install and setup HA cluster with JHS 2.Create state in in JHS where few jobs are killed and Success  Check sorting State in JHS WebUI  Actual ===== Sorting on state column  not working in JHS  Expected ====== Sorting on state column should be working,Closed,Fixed,,zhihai xu,Bibin A Chundatt,Fri; 29 May 2015 07:23:52 +0000,Fri; 2 Dec 2016 00:29:59 +0000,Fri; 5 Jun 2015 10:36:37 +0000,,2.7.0,,,MAPREDUCE-5052,https://issues.apache.org/jira/browse/MAPREDUCE-6377
MAPREDUCE-6378,Bug,Major,,convergence error in hadoop-streaming during mvn install,Running mvn install in the hadoop-tools hadoop-streaming directory results in a convergence error.  See comments.,Reopened,Unresolved,,Unassigned,Allen Wittenauer,Fri; 29 May 2015 19:06:32 +0000,Mon; 1 Jun 2015 05:19:12 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6378
MAPREDUCE-6379,Bug,Minor,mr-am,@taskid@ in yarn.app.mapreduce.am.command-opts can't be replaced by current taskid,"In this document; http: mapred-default.xml; we can find the parameter ""yarn.app.mapreduce.am.command-opts"" is described as @taskid@ in yarn.app.mapreduce.am.command-opts can be replaced by current taskid. But I checked the code in 2.7.0; there is no logic to replace it.",Open,Unresolved,,Varun Saxena,Zhang Wei,Mon; 1 Jun 2015 03:33:52 +0000,Mon; 4 Jan 2016 23:29:12 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6379
MAPREDUCE-6380,Bug,Trivial,jobhistoryserver,AggregatedLogDeletionService will throw exception when there are some other directories in remote-log-dir,"AggregatedLogDeletionService will throw FileNotFoundException when there are some extraneous directories put in remote-log-dir. The deletion function will try to listStatus against the ""extraneous-dir + suffix""  dir.  I think it would be better  if  the function can ignore these directories.",Patch Available,Unresolved,,Kai Sasaki,Zhang Wei,Mon; 1 Jun 2015 06:43:35 +0000,Fri; 22 Jul 2016 13:52:28 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6380
MAPREDUCE-6381,Improvement,Major,client,Some of MapReduce Commands opreations should have audit log printed,Below mapred commands are important operations that should also have audit logs recorded like 'yarn' commands.  Mapred commands:,Open,Unresolved,,Unassigned,Bob.zhao,Mon; 1 Jun 2015 09:10:24 +0000,Mon; 1 Jun 2015 09:13:52 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6381
MAPREDUCE-6382,Bug,Major,,Don't escape HTML links in Diagnostics in JHS job overview,for some reason; links are working properly in 2.4; but they are escaped in 2.6,Resolved,Fixed,MAPREDUCE-6371,Siqi Li,Siqi Li,Tue; 2 Jun 2015 22:17:49 +0000,Tue; 30 Aug 2016 01:17:21 +0000,Thu; 4 Jun 2015 06:58:09 +0000,,2.8.0,,,MAPREDUCE-6297,https://issues.apache.org/jira/browse/MAPREDUCE-6382
MAPREDUCE-6383,Improvement,Major,examples,Pi job (QuasiMonteCarlo) should not try to read the results file if its job fails,Currently it tries to read the standard result path and logs a failure a second time.,Resolved,Fixed,,Harsh J,Harsh J,Wed; 3 Jun 2015 11:31:21 +0000,Tue; 30 Aug 2016 01:17:20 +0000,Fri; 5 Jun 2015 15:56:18 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6383
MAPREDUCE-6384,Improvement,Major,,Add the last reporting reducer info for too many fetch failure diagnostics,nan,Resolved,Fixed,,Chang Li,Chang Li,Wed; 3 Jun 2015 19:18:02 +0000,Tue; 30 Aug 2016 01:17:18 +0000,Tue; 30 Jun 2015 21:26:42 +0000,,,,,TEZ-3394,https://issues.apache.org/jira/browse/MAPREDUCE-6384
TEZ-2537,Bug,Major,,mapreduce.map.env and mapreduce.reduce.env need to fall back to mapred.child.env for compatibility,nan,Closed,Fixed,,Rohini Palaniswamy,Jonathan Eagles,Wed; 3 Jun 2015 22:52:43 +0000,Tue; 30 Jun 2015 04:53:11 +0000,Thu; 4 Jun 2015 20:28:23 +0000,,,,,,https://issues.apache.org/jira/browse/TEZ-2537
MAPREDUCE-6387,Bug,Minor,,Serialize the recently added Task#encryptedSpillKey field at the end,There was a recent addition of an encryptedSpillKey to the Task object. And when serialized; this field was written out somewhere in the middle. This caused deployments that do not use DistributedCache to push job jars before running the job to fail rolling upgrade.  Although deploying via Distributed Cache is the recommended method; there might still be deployments that use the node local classpath to pick up the MR framework classes (eg. for efficiency purposes; since this does not require the jar being copied to hdfs and then to all the nodes)  Ensuring that it is the last field written and read when the Task object is serialized would alleviate this issue.,Closed,Fixed,,Arun Suresh,Arun Suresh,Thu; 4 Jun 2015 16:49:52 +0000,Fri; 6 Jan 2017 07:39:29 +0000,Fri; 5 Jun 2015 16:22:36 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6387
MAPREDUCE-6388,Task,Minor,jobhistoryserver,Remove deprecation warnings from JobHistoryServer classes,There are a ton of deprecation warnings in the JobHistoryServer classes.  This is affecting some modifications I'm making since a single line move shifts all the deprecation warnings.  I'd like to get these fixed to prevent minor changes from generating a ton of warnings in test-patch.,Resolved,Fixed,,Ray Chiang,Ray Chiang,Fri; 5 Jun 2015 23:29:27 +0000,Tue; 30 Aug 2016 01:17:16 +0000,Mon; 8 Jun 2015 22:10:37 +0000,,2.7.0,supportability,MAPREDUCE-6376,,https://issues.apache.org/jira/browse/MAPREDUCE-6388
MAPREDUCE-6389,Bug,Trivial,,Fix BaileyBorweinPlouffe CLI usage message ,The usage message from code does not match with the command helpline option.    usage from command line      usage from code,Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Sat; 6 Jun 2015 19:55:17 +0000,Tue; 30 Aug 2016 01:17:15 +0000,Wed; 10 Jun 2015 15:40:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6389
MAPREDUCE-6390,New Feature,Major,build,Improve Solaris support in Hadoop Map/Reduce,At present the Hadoop Map Reduce performance on Solaris wherever possible.,Open,Unresolved,,Alan Burlison,Alan Burlison,Mon; 8 Jun 2015 12:27:49 +0000,Sat; 20 Jun 2015 09:31:34 +0000,,,,,,HADOOP-11985;HDFS-8478;YARN-3719,https://issues.apache.org/jira/browse/MAPREDUCE-6390
MAPREDUCE-6391,Sub-task,Major,build,util/Timer.cc completely misunderstands _POSIX_CPUTIME,util c_c_tip_how_measure_cpu_time_benchmarking (code examples are CC licensed so should be no taint issues),Resolved,Fixed,,Alan Burlison,Alan Burlison,Mon; 8 Jun 2015 12:54:21 +0000,Thu; 12 May 2016 18:24:43 +0000,Tue; 27 Oct 2015 19:08:13 +0000,,3.0.0-alpha1,,,YARN-3719,https://issues.apache.org/jira/browse/MAPREDUCE-6391
MAPREDUCE-6392,Improvement,Major,documentation,Document mapred class path options,--global; --jar options are not documented.     current document:    http: MapredCommands.html#classpath,Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Mon; 8 Jun 2015 16:30:23 +0000,Tue; 30 Aug 2016 01:17:13 +0000,Mon; 8 Jun 2015 23:23:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6392
MAPREDUCE-6393,Bug,Major,,Application Master and Task Tracker timeouts are applied incorrectly,"I am running a streaming job which requires a big (~50GB) data file to run (file is attached via hadoop jar ... -file BigFile.dat).  Most likely this command will fail as follows (note th time; not just generic ""timeout expired"".  Better solution would be not to account time spent for data files distribution.",Open,Unresolved,,Unassigned,Dmitry Sivachenko,Tue; 9 Jun 2015 15:32:54 +0000,Tue; 9 Jun 2015 16:38:56 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6393
MAPREDUCE-6394,Sub-task,Major,jobhistoryserver,Speed up Task processing loop in HsTasksBlock#render(),In HsTasksBlock#render(); there is a loop to create a Javascript table which slows down immensely on jobs with a large number of tasks (200k or more).,Resolved,Fixed,,Ray Chiang,Ray Chiang,Wed; 10 Jun 2015 21:43:25 +0000,Tue; 30 Aug 2016 01:17:12 +0000,Fri; 31 Jul 2015 18:20:56 +0000,,2.7.0,supportability,,MAPREDUCE-6376,https://issues.apache.org/jira/browse/MAPREDUCE-6394
MAPREDUCE-6395,Improvement,Major,applicationmaster,Improve the commit failure messages in MRAppMaster recovery,"There are typos; and pluralis majestatis (royal we) or user-including ""we"" messages that are confusing to the users:",Resolved,Fixed,,Brahma Reddy Battula,Gera Shegalov,Fri; 12 Jun 2015 17:06:58 +0000,Tue; 30 Aug 2016 01:17:10 +0000,Fri; 19 Jun 2015 09:36:17 +0000,,2.7.0,noob,,,https://issues.apache.org/jira/browse/MAPREDUCE-6395
MAPREDUCE-6396,Bug,Major,test,TestPipeApplication fails by NullPointerException,TestPipeApplication#testApplication and TestPipeApplication#testRunner fail on trunk.,Resolved,Fixed,,Brahma Reddy Battula,Akira Ajisaka,Sat; 13 Jun 2015 16:20:42 +0000,Thu; 12 May 2016 18:22:21 +0000,Mon; 15 Jun 2015 22:30:29 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6396
MAPREDUCE-6397,Sub-task,Major,build,MAPREDUCE makes many endian-dependent assumptions,MAPREDUCE native code contains multiple uses of the bswap and bswap64 assembler functions (from hadoop-mapreduce-project primitives.h).  primitives.h contains neither a sparc implementation of bswap nor a platform-independent C fallback implementation. In addition; byte swaps are nearly always made without checking if the platform is big or little endian; the assumption hard-coded throughout the source seems to be that the platform is little-endian. This most likely means that the MAPREDUCE native is currently code non-portable to big-endian platforms. The code needs to be examined carefully to determine which byte swaps are correct on all platforms and which are endian-dependent.,Open,Unresolved,,Alan Burlison,Alan Burlison,Sun; 14 Jun 2015 20:56:14 +0000,Thu; 10 Dec 2015 14:19:09 +0000,,,2.7.0,,,MAPREDUCE-6417;HADOOP-11505,https://issues.apache.org/jira/browse/MAPREDUCE-6397
MAPREDUCE-6398,Bug,Major,resourcemanager,Two RMNodes for the same NodeId are used in RM sometimes after NM is reconnected.,Two RMNodes for the same NodeId are used in RM sometimes after NM is reconnected. Scheduler and RMContext use different RMNode reference for the same NodeId sometimes after NM is reconnected; which is not correct. Scheduler and RMContext should always use same RMNode reference for the same NodeId.,Resolved,Duplicate,YARN-3802,zhihai xu,zhihai xu,Sun; 14 Jun 2015 22:35:15 +0000,Sun; 14 Jun 2015 22:37:21 +0000,Sun; 14 Jun 2015 22:37:21 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6398
MAPREDUCE-6399,Improvement,Minor,,UI Improvement - Counters Statistics Page,Current; the 'counters' page on the web UI will show totals for each counter; and clicking on a counter gets individual values from each task.  For the purposes of job performance tuning; it would be very helpful to be able to quickly see statistic aggregations on the counter. Specifically; I'm thinking a view where; for each counter; we get: MAX; MIN; MEAN; MEDIAN; MODE; STDEV (or some subset of those)  The max and min values could include links to corresponding task(s) counters.,Open,Unresolved,,Unassigned,Kevin J. Price,Mon; 15 Jun 2015 15:03:26 +0000,Mon; 15 Jun 2015 21:49:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6399
MAPREDUCE-6400,Bug,Blocker,task,Multiple shuffle transfer fails because input is closed too early,TestReduceFetchFromPartialMem fails.,Resolved,Fixed,,Brahma Reddy Battula,Akira Ajisaka,Mon; 15 Jun 2015 23:58:50 +0000,Tue; 30 Aug 2016 01:17:08 +0000,Wed; 24 Jun 2015 15:31:22 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6400
MAPREDUCE-6401,Bug,Minor,nodemanager,Container-launch failure gives no debugging output,MR jobs are failing on my cluster with Stack trace: ExitCodeException exitCode=7 but little else in terms of debugging information. Can we please improve the debugging info? Log file is attached.,Open,Unresolved,,Unassigned,Hari Sekhon,Tue; 16 Jun 2015 17:14:02 +0000,Thu; 21 Jul 2016 03:55:58 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6401
MAPREDUCE-6402,Bug,Major,applicationmaster,Application Master listens on all IPs,The application master listening on all IPs; which may cause security problems. Similar issue: MAPREDUCE-5938,Open,Unresolved,,Varun Saxena,Peter Shi,Wed; 17 Jun 2015 03:02:42 +0000,Tue; 26 Jul 2016 19:40:24 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6402
MAPREDUCE-6403,Bug,Trivial,documentation,Fix typo in the usage of NNBench,Fix typo 'becnhmarks'.,Resolved,Fixed,,Jagadesh Kiran N,Akira Ajisaka,Wed; 17 Jun 2015 05:07:38 +0000,Tue; 30 Aug 2016 01:17:06 +0000,Mon; 22 Jun 2015 06:36:45 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6403
MAPREDUCE-6404,Improvement,Major,applicationmaster,Allow AM to specify a port range for starting its webapp,Allow AM to specify a port range for starting its webapp,Resolved,Fixed,MAPREDUCE-6739,Varun Saxena,Varun Saxena,Wed; 17 Jun 2015 12:54:16 +0000,Tue; 7 Feb 2017 11:46:04 +0000,Tue; 7 Feb 2017 09:49:45 +0000,,,,,MAPREDUCE-6338,https://issues.apache.org/jira/browse/MAPREDUCE-6404
MAPREDUCE-6405,Bug,Major,,NullPointerException in App Attempts page,nan,Resolved,Fixed,,Siqi Li,Siqi Li,Wed; 17 Jun 2015 18:12:23 +0000,Tue; 30 Aug 2016 01:17:05 +0000,Sat; 20 Jun 2015 05:12:13 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6405
MAPREDUCE-6406,Bug,Minor,mrv2,Update FileOutputCommitter.FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT to match mapred-default.xml,MAPREDUCE-6336 updated the default version for the property mapreduce.fileoutputcommitter.algorithm.version to 2.  Should the FileOutputCommitter class default be updated to match?,Resolved,Fixed,,Ray Chiang,Ray Chiang,Thu; 18 Jun 2015 17:54:17 +0000,Thu; 12 May 2016 18:23:30 +0000,Tue; 23 Jun 2015 04:56:06 +0000,,,newbie;supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6406
MAPREDUCE-6407,Sub-task,Major,build,Migrate MAPREDUCE nativetask build to new CMake framework,As per HADOOP-12036; the CMake infrastructure should be refactored and made common across all Hadoop components. This bug covers the migration of MAPREDUCE to the new CMake infrastructure. This change will also add support for building MAPREDUCE Native components on Solaris.,Resolved,Fixed,,Alan Burlison,Alan Burlison,Thu; 18 Jun 2015 18:09:20 +0000,Thu; 12 May 2016 18:23:31 +0000,Tue; 30 Jun 2015 23:17:26 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6407
MAPREDUCE-6408,Improvement,Major,applicationmaster,Queue name and user name should be printed on the job page,Sometimes; users just give us a job link; and from there we don't which user submits this job and which queue was used. Currently we have go through the confs to find that out.,Resolved,Fixed,,Siqi Li,Siqi Li,Fri; 19 Jun 2015 22:49:48 +0000,Tue; 30 Aug 2016 01:17:04 +0000,Mon; 22 Jun 2015 21:52:29 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6408
YARN-3842,Bug,Critical,,NMProxy should retry on NMNotYetReadyException,Consider the following scenario: 1. RM assigns a container on node N to an app A. 2. Node N is restarted 3. A tries to launch container on node N.  3 could lead to an NMNotYetReadyException depending on whether NM N has registered with the RM. In MR; this is considered a task attempt failure. A few of these could lead to a task job failure.,Closed,Fixed,,Robert Kanter,Karthik Kambatla,Tue; 16 Jun 2015 22:49:45 +0000,Fri; 6 Jan 2017 00:51:46 +0000,Tue; 23 Jun 2015 00:52:39 +0000,,2.7.0,,,YARN-3839,https://issues.apache.org/jira/browse/YARN-3842
MAPREDUCE-6410,Bug,Critical,,Aggregated Logs Deletion doesnt work after refreshing Log Retention Settings in secure cluster,GSSException is thrown everytime log aggregation deletion is attempted after executing bin mapred hsadmin -refreshLogRetentionSettings in a secure cluster.  The problem can be reproduced by following steps: 1. startup historyserver in secure cluster. 2. Log deletion happens as per expectation.  3. execute mapred hsadmin -refreshLogRetentionSettings command to refresh the configuration value. 4. All the subsequent attempts of log deletion fail with GSSException  Following exception can be found in historyserver's log if log deletion is enabled.,Closed,Fixed,,Varun Saxena,Zhang Wei,Thu; 4 Jun 2015 06:34:33 +0000,Fri; 6 Jan 2017 00:52:38 +0000,Tue; 23 Jun 2015 18:44:37 +0000,,2.7.0,historyserver,,,https://issues.apache.org/jira/browse/MAPREDUCE-6410
MAPREDUCE-6411,Bug,Major,,Change the scope of all instance variables to private in JobInfo,nan,Patch Available,Unresolved,,Siqi Li,Siqi Li,Mon; 22 Jun 2015 19:32:20 +0000,Mon; 22 Jun 2015 20:49:55 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6411
MAPREDUCE-6412,Sub-task,Major,build,Make hadoop-mapreduce-client Native code -Wall-clean,nan,Resolved,Fixed,,Alan Burlison,Alan Burlison,Tue; 23 Jun 2015 15:24:23 +0000,Thu; 12 May 2016 18:24:11 +0000,Tue; 27 Oct 2015 19:15:34 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6412
MAPREDUCE-6413,Bug,Major,test,TestLocalJobSubmission is failing with unknown host,ThestLocalJobSubmission.testLocalJobLibjarsOption is failing with  net.UnknownHostException: testcluster,Closed,Fixed,,zhihai xu,Jason Lowe,Tue; 23 Jun 2015 16:02:42 +0000,Tue; 30 Aug 2016 01:17:02 +0000,Thu; 25 Jun 2015 19:53:52 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6413
MAPREDUCE-6414,Improvement,Major,distcp,Distcp command very slow to enumerate files needing,When copying large amounts of data using distcp utility (100's of TBs); the distcp utility takes a large time to enumerate all of the files that have changed.  In my system; this corresponds to 14-16 hours before the actual copying of data begins.,Open,Unresolved,,Unassigned,Tyler Hale,Tue; 23 Jun 2015 20:29:40 +0000,Tue; 23 Jun 2015 20:29:40 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6414
MAPREDUCE-6415,New Feature,Major,,Create a tool to combine aggregated logs into HAR files,While we wait for YARN-2942 to become viable; it would still be great to improve the aggregated logs problem.  We can write a tool that combines aggregated log files into a single HAR file per application; which should solve the too many files and too many blocks problems.  See the design document for details.  See YARN-2942 for more context.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Wed; 24 Jun 2015 23:19:31 +0000,Mon; 18 Dec 2017 14:36:36 +0000,Thu; 10 Sep 2015 00:56:46 +0000,,2.8.0,,,MAPREDUCE-7027;MAPREDUCE-6480;MAPREDUCE-6494;MAPREDUCE-6495;MAPREDUCE-6503;MAPREDUCE-6550;MAPREDUCE-7023;YARN-2942;MAPREDUCE-6970;YARN-4946;YARN-4086,https://issues.apache.org/jira/browse/MAPREDUCE-6415
MAPREDUCE-6416,Sub-task,Major,build,Not all platforms have d_type in struct dirent,list() in hadoop-mapreduce-project FileSystem.cc assumes that struct dirent always contains a d_type field which can be used to determine the type of the directory entry. This field is non-POSIX and is not available on all platforms. On platforms where it is not available; stat() should be used instead to determine the type of the directory entry.,Resolved,Fixed,,Alan Burlison,Alan Burlison,Thu; 25 Jun 2015 15:56:20 +0000,Thu; 12 May 2016 18:22:29 +0000,Tue; 27 Oct 2015 19:22:29 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6416
MAPREDUCE-6417,Sub-task,Blocker,client,MapReduceClient's primitives.h is toxic and should be extirpated,"MapReduceClient's primitives.h attempts to provide optimised versions of standard library memory copy and comparison functions. It has been the subject of several portability-related bugs:   	HADOOP-11505 hadoop-mapreduce-client-nativetask uses bswap where be32toh is needed; doesn't work on non-x86 	HADOOP-11665 Provide and unify cross platform byteorder support in native code 	MAPREDUCE-6397 MAPREDUCE makes many endian-dependent assumptions 	HADOOP-11484 hadoop-mapreduce-client-nativetask fails to build on ARM AARCH64 due to x86 asm statements    At present it only works on x86 and ARM64 as it lacks definitions for bswap and bswap64 for any platforms other than those.  However it has even more serious problems on non-x86 architectures; for example on SPARC simple_memcpy simply doesn't work at all:    That's because simple_memcpy does pointer fiddling that results in misaligned accesses; which are illegal on SPARC.  fmemcmp is also broken. Even if a definition of bswap is provided; on big-endian architectures the result is simply wrong because of its unconditional use of bswap:     And in addition fmemcmp suffers from the same misalignment issues as simple_memcpy and coredumps on SPARC when asked to compare odd-sized buffers.  primitives.h provides the following functions:   	bswap - used in 12 files in MRC but as HADOOP-11505 points out; mostly incorrectly as it takes no account of platform endianness 	bswap64 - used in 4 files in MRC; same comments as per bswap apply 	simple_memcpy - used in 3 files in MRC; should be replaced with the standard memcpy 	fmemcmp - used in 1 file; should be replaced with the standard memcmp 	fmemeq - used in 1 file; should be replaced with the standard memcmp 	frmemeq - not used at all; should just be removed    Summary: primitives.h should simply be deleted and replaced with the standard memory copy  compare functions; or with thin wrappers around them where the APIs are different.",Patch Available,Unresolved,,Alan Burlison,Alan Burlison,Fri; 26 Jun 2015 10:47:46 +0000,Thu; 12 May 2016 18:24:18 +0000,,,3.0.0-alpha1,,,MAPREDUCE-6397;HADOOP-11505;HADOOP-11665;HADOOP-11484,https://issues.apache.org/jira/browse/MAPREDUCE-6417
MAPREDUCE-6418,Bug,Major,test,MRApp should not shutdown LogManager during shutdown,Tests in TestRecovery. lost their logs after recovery due to the change of MAPREDUCE-5694. MRApp should overwrite those changes to allow log after am recover to be shown.,Resolved,Fixed,,Chang Li,Chang Li,Fri; 26 Jun 2015 22:13:40 +0000,Tue; 30 Aug 2016 01:16:57 +0000,Wed; 1 Jul 2015 18:02:55 +0000,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6418
MAPREDUCE-6419,Bug,Major,webapps,JobHistoryServer doesn't sort properly based on Job ID when Job id's exceed 9999,When Job id's exceed 9999; JobHistoryServer is not sorting properly based on the Job ID. It is mixing the jobs having  9999 with other jobs considering only the first four digits of the job id. The same problem could exist for Job Map tasks and Reduce tasks table as well.   It is similar to the issue YARN-3840 exists for YARN.,Resolved,Fixed,,Mohammad Shahid Khan,Devaraj K,Mon; 29 Jun 2015 10:58:33 +0000,Tue; 30 Aug 2016 01:16:55 +0000,Thu; 24 Dec 2015 06:34:33 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6419
MAPREDUCE-6420,Bug,Major,,Interrupted Exception in LocalContainerLauncher should be logged in warn/info level,Interrupted Exception in LocalContainerLauncher should be logged in warn info levle instead of error because it won't fail the job. Otherwise it will cause some confusions during debugging,Resolved,Fixed,,Chang Li,Chang Li,Mon; 29 Jun 2015 20:54:28 +0000,Tue; 30 Aug 2016 01:16:53 +0000,Wed; 1 Jul 2015 17:51:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6420
MAPREDUCE-6421,Bug,Major,,Fix findbugs warning in RMContainerAllocator.reduceNodeLabelExpression,The actual error message is:    Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceNodeLabelExpression; locked 66% of time  The full URL for the findbugs is at:    https: trunkFindbugsWarningshadoop-mapreduce-client-app.html  I haven't looked to see if this message is in error or if findbugs is correct.,Resolved,Fixed,,Brahma Reddy Battula,Ray Chiang,Mon; 29 Jun 2015 23:16:21 +0000,Tue; 30 Aug 2016 01:16:51 +0000,Mon; 13 Jul 2015 05:31:52 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6421
MAPREDUCE-6422,New Feature,Major,,Add REST API for getting all attempts for all the tasks,Web UI has the feature where one can get all attempts for all map tasks or reduce tasks.  REST api seems to be missing it.  Should we add this in both HsWebService and AMWebService ?    We might also add queryparam on state to filter by succeeded attempts etc. Thoughts ?,Patch Available,Unresolved,,Lavkesh Lahngir,Lavkesh Lahngir,Wed; 1 Jul 2015 11:24:31 +0000,Thu; 23 Jul 2015 14:56:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6422
MAPREDUCE-6423,Improvement,Minor,,MapOutput Sampler,Need a sampler based on the MapOutput Keys. Current InputSampler implementation has a major drawback which is input and output of a mapper should be same; generally this isn't the case.  approach: 1. Create a Sampler which samples the data based on the input. 2. Run a small map reduce in uber task mode using the original job mapper and identity reducer to generate required MapOutputSample keys 3. Optionally; we can input the input file to be sample. For example inputs files A; B; we should be able to specify to use only file A for sampling.,Open,Unresolved,,Ram Manohar Bheemana,Ram Manohar Bheemana,Wed; 1 Jul 2015 14:08:11 +0000,Sat; 12 Sep 2015 20:08:03 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6423
MAPREDUCE-6424,Sub-task,Major,,Store MR counters as timeline metrics instead of event,In MAPREDUCE-6327; we make map reduce counters get encoded from JobFinishedEvent as timeline events with counters details in JSON format.  We need to store framework specific counters as metrics in timeline service to support query; aggregation; etc.,Resolved,Fixed,,Naganarasimha G R,Junping Du,Thu; 2 Jul 2015 22:38:41 +0000,Sat; 21 Oct 2017 06:30:01 +0000,Sun; 1 May 2016 11:51:57 +0000,,,yarn-2928-1st-milestone,,YARN-3401;YARN-4173,https://issues.apache.org/jira/browse/MAPREDUCE-6424
MAPREDUCE-6425,Bug,Major,mrv2;nodemanager,"ShuffleHandler passes wrong ""base"" parameter to getMapOutputInfo if mapId is not in the cache.",ShuffleHandler passes wrong base parameter to getMapOutputInfo if mapId is not in the cache. getMapOutputInfo expected the base parameter is getBaseLocation(jobId; user) + mapId When it is called inside populateHeaders; the base parameter is set correctly   When  it is called outside populateHeaders; the base parameter is set wrongly to outputBasePathStr after number of mapId cached exceeds mapOutputMetaInfoCacheSize.,Closed,Fixed,,zhihai xu,zhihai xu,Fri; 3 Jul 2015 01:42:02 +0000,Fri; 6 Jan 2017 01:40:46 +0000,Mon; 6 Jul 2015 08:23:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6425
MAPREDUCE-6426,Bug,Major,test,TestShuffleHandler#testGetMapOutputInfo is failing,https: ,Closed,Fixed,,zhihai xu,Devaraj K,Tue; 7 Jul 2015 14:56:11 +0000,Fri; 6 Jan 2017 01:40:15 +0000,Thu; 9 Jul 2015 09:40:03 +0000,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6426
MAPREDUCE-6427,Bug,Minor,,Fix typo in JobHistoryEventHandler,JobHistoryEventHandler#processEventForTimelineServer       should be like below.,Resolved,Fixed,,Ray Chiang,Brahma Reddy Battula,Wed; 8 Jul 2015 03:11:11 +0000,Tue; 30 Aug 2016 01:16:46 +0000,Tue; 14 Jul 2015 22:06:30 +0000,,,,,HADOOP-11854,https://issues.apache.org/jira/browse/MAPREDUCE-6427
MAPREDUCE-6428,Bug,Major,,Job History can be lost if there is any issue in writing jhist file while AM shuts down job,We found that while job succeeds (can be seen as successful in RM); but as writing of jhist file fails; job cant be seen in JobHistory.     We can probably mark the job as failure and inform RM if this happens. Thoughts ?,Open,Unresolved,,Varun Saxena,Varun Saxena,Wed; 8 Jul 2015 11:59:02 +0000,Wed; 8 Jul 2015 12:45:21 +0000,,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6428
MAPREDUCE-6429,Improvement,Minor,mrv2,running M/R tasks under a security policy,When running M R tasks under a security policy without the ' lang.reflect.ReflectPermission suppressAccessChecks' granted to the user code; we are unable to instantiate new keys for a WritableComparator. This patch wraps the WritableComparator#newKey in a doPrivileged block handling non-public key constructors. Please see attached file.,Open,Unresolved,,Unassigned,Purvesh Patel,Wed; 8 Jul 2015 18:00:23 +0000,Tue; 14 Jul 2015 15:17:31 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6429
HADOOP-12224,Improvement,Minor,util,new method to ReflectionUtils to test if the item is already public,It's noticed that it is common practice to call setAccessible on a method whether it is required or not. This patch provides a new method to ReflectionUtils to test if the item is already public and only call setAccessible if it is not public. Please see attached file.,Open,Unresolved,,Unassigned,Purvesh Patel,Wed; 8 Jul 2015 18:05:31 +0000,Fri; 15 Apr 2016 01:00:54 +0000,,,2.5.0,,,,https://issues.apache.org/jira/browse/HADOOP-12224
MAPREDUCE-6431,Improvement,Major,,JobClient should be an AutoClosable,Since the new target version if Java is 7; it would be great if JobClient could implement the  e tryResourceClose.html,Resolved,Fixed,,Haibo Chen,Andr   Kelpe,Fri; 10 Jul 2015 14:32:54 +0000,Tue; 30 Aug 2016 01:16:44 +0000,Thu; 28 Jan 2016 01:15:11 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6431
MAPREDUCE-6432,Task,Minor,,Fix typos in hadoop-mapreduce-project module,Fix a bunch of typos in comments; strings; variable names; and method names in the hadoop-mapreduce-project module.,Patch Available,Unresolved,,Neelesh Srinivas Salian,Ray Chiang,Fri; 10 Jul 2015 18:16:24 +0000,Tue; 5 Sep 2017 17:21:00 +0000,,,2.7.1,supportability,,HADOOP-11854,https://issues.apache.org/jira/browse/MAPREDUCE-6432
MAPREDUCE-6433,Bug,Major,jobhistoryserver;mrv2,launchTime may be negative,Under extremely rare conditions (.0017% in our sample size); launchTime in the jhist files may be set to -1.,Resolved,Fixed,,zhihai xu,Allen Wittenauer,Mon; 13 Jul 2015 21:42:36 +0000,Mon; 26 Jun 2017 16:27:28 +0000,Mon; 26 Jun 2017 08:41:07 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6433
MAPREDUCE-6434,Improvement,Major,,Add support for PartialFileOutputCommiter when checkpointing is an option during preemption,Finish up some renaming work related to the annotation @Preemptable (it should be @Checkpointable now) and help in the splitting of patch in MAPREDUCE-5269 that is too large for being reviewed or accepted by Jenkins CI scripts.,Patch Available,Unresolved,,Augusto Souza,Augusto Souza,Wed; 15 Jul 2015 23:27:25 +0000,Mon; 31 Aug 2015 20:00:54 +0000,,,,,,MAPREDUCE-6444;MAPREDUCE-5176,https://issues.apache.org/jira/browse/MAPREDUCE-6434
MAPREDUCE-6435,Sub-task,Major,client,MapReduce client assumes the world is x86,hadoop-mapreduce-project Checksum.cc contains x86-only code and assumes it's going to work by default. The logic should be inverted so that it only uses the x86 code when built on x86 and otherwise defaults to the architecture-independent code. That will prevent changes having to be made for each new architecture.,Resolved,Fixed,,Alan Burlison,Alan Burlison,Thu; 16 Jul 2015 23:02:02 +0000,Thu; 12 May 2016 18:22:44 +0000,Tue; 27 Oct 2015 19:29:59 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6435
MAPREDUCE-6436,Improvement,Blocker,,JobHistory cache issue,"Problem:  HistoryFileManager.addIfAbsent produces large amount of logs if number of cached entries whose age is less than mapreduce.jobhistory.max-age-ms becomes larger than mapreduce.jobhistory.joblist.cache.size by far.  Example: For example; if the cache contains 50000 entries in total and 10;000 entries newer than mapreduce.jobhistory.max-age-ms where mapreduce.jobhistory.joblist.cache.size is 20000; HistoryFileManager.addIfAbsent method produces 50000 - 20000 = 30000 lines of ""Waiting to remove key from JobListCache because it is not in done yet"" message.  It will attach a stacktrace.  Impact: In addition to large disk consumption; this issue blocks JobHistory.getJob long time and slows job execution down significantly because getJob is called by RPC such as HistoryClientService.HSClientProtocolHandler.getJobReport. This impact happens because HistoryFileManager.UserLogDir.scanIfNeeded eventually calls HistoryFileManager.addIfAbsent in a synchronized block. When multiple threads call scanIfNeeded simultaneously; one of them acquires lock and the other threads are blocked until the first thread completes long-running HistoryFileManager.addIfAbsent call.  Solution:   	Reduce amount of logs so that HistoryFileManager.addIfAbsent doesn't take too long time. 	Good to have if possible: HistoryFileManager.UserLogDir.scanIfNeeded skips   scanning if another thread is already scanning. This changes semantics of   some HistoryFileManager methods (such as getAllFileInfo and getFileInfo)   because scanIfNeeded keep outdated state. 	Good to have if possible: Make scanIfNeeded asynchronous so that RPC calls are   not blocked by a loop at scale of tens of thousands.    This patch implemented the first item.",Closed,Fixed,,Kai Sasaki,Ryu Kobayashi,Fri; 17 Jul 2015 06:24:23 +0000,Tue; 30 Aug 2016 01:16:40 +0000,Tue; 15 Dec 2015 09:30:12 +0000,,,,,MAPREDUCE-6684;MAPREDUCE-6573,https://issues.apache.org/jira/browse/MAPREDUCE-6436
MAPREDUCE-6437,Bug,Major,,Add retry on some connection exception on job commit phase,Check the code; there is no chance to make another application master attempt if it encounters the issue of connection. So could we identify the exception; and make another retry or kick off another AM attempt?,Resolved,Duplicate,MAPREDUCE-5485,Unassigned,Bing Jiang,Tue; 21 Jul 2015 10:07:58 +0000,Wed; 22 Feb 2017 23:10:05 +0000,Wed; 22 Feb 2017 23:10:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6437
MAPREDUCE-6438,Bug,Major,mrv2,mapreduce fails with job.jar does not exist,I have a hortonworks distribution(2.2.6.0-2800) of hadoop which runs mapreduce job based on yarn; and i have a simple map reduce job which reads compressed data files from hdfs; does some processing over it and then this data is saved in hbase with bulk load  Here is my program that does it    This should be a very simple thing to run but i am facing this exception while running the job     Also attached are the core-site.xml; mapred-site.xml; hdfs-site.xml and yarn-site.xml,Open,Unresolved,,Unassigned,Raghvendra Singh,Fri; 24 Jul 2015 23:32:10 +0000,Fri; 24 Jul 2015 23:34:12 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6438
MAPREDUCE-6439,Bug,Critical,,AM may fail instead of retrying if RM shuts down during the allocate call,We are seeing cases where MR AM gets a YarnRuntimeException thats thrown in RM and gets sent back to AM causing it to think that it has exhausted the number of retries. Copying the error which causes the heartbeat thread to quit.,Closed,Fixed,,Anubhav Dhoot,Anubhav Dhoot,Thu; 30 Jul 2015 20:31:00 +0000,Fri; 2 Dec 2016 00:35:19 +0000,Sat; 15 Aug 2015 07:59:07 +0000,,2.7.1,,,YARN-4021;MAPREDUCE-6449;YARN-4646,https://issues.apache.org/jira/browse/MAPREDUCE-6439
MAPREDUCE-6440,Bug,Minor,jobhistoryserver,Duplicate Key in Json Output for Job details,"Duplicate key in Json Output for Job details for the url :  http: attempts  If the task type is ""REDUCE"" the json output for this url contains duplicate key for ""type"".",Open,Unresolved,,Unassigned,Anushri,Fri; 31 Jul 2015 14:40:55 +0000,Thu; 27 Oct 2016 03:56:39 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6440
MAPREDUCE-6441,Bug,Major,,Improve temporary directory name generation in LocalDistributedCacheManager for concurrent processes,Kicking off many sqoop processes in different threads results in:     If two are kicked off in the same second. The issue is the following lines of code in the org.apache.hadoop.mapred.LocalDistributedCacheManager class:      and,Patch Available,Unresolved,MAPREDUCE-6685;MAPREDUCE-6992,Ray Chiang,William Watson,Fri; 1 Aug 2014 20:23:38 +0000,Thu; 26 Oct 2017 18:45:07 +0000,,,,,,MAPREDUCE-6766;YARN-2624,https://issues.apache.org/jira/browse/MAPREDUCE-6441
MAPREDUCE-6442,Bug,Major,client,Stack trace is missing when error occurs in client protocol provider's constructor,when provider creation fail dump the stack trace rather than just print out the message,Closed,Fixed,,Chang Li,Chang Li,Fri; 31 Jul 2015 22:21:17 +0000,Fri; 2 Dec 2016 00:41:34 +0000,Sat; 5 Sep 2015 02:28:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6442
MAPREDUCE-6443,Improvement,Major,jobhistoryserver,Add JvmPauseMonitor to Job History Server,We should add the JvmPauseMonitor from HADOOP-9618 to the Job History Server.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Tue; 4 Aug 2015 22:44:58 +0000,Tue; 30 Aug 2016 01:16:34 +0000,Thu; 6 Aug 2015 14:07:21 +0000,,2.8.0,,,YARN-4019;HADOOP-9618,https://issues.apache.org/jira/browse/MAPREDUCE-6443
MAPREDUCE-6444,Improvement,Major,,Add a checkpointable version of shuffle and reduce context supported by a checkpoint manager which uses the HDFS,Patch to add classes to provide a checkpointable version of shuffle and reduce context. Also; add a classe which makes possible to save a checkpoint of a task in HDFS. Those classes are respectively: CheckpointableShuffle; CheckpointableReduceContextImpl and TaskCheckpointManager.  This improvement also helps in the splitting of patch in MAPREDUCE-5269 that is too large for being reviewed or accepted by Jenkins CI scripts.,Patch Available,Unresolved,,Augusto Souza,Augusto Souza,Wed; 5 Aug 2015 22:52:23 +0000,Fri; 28 Aug 2015 05:54:49 +0000,,,,,,MAPREDUCE-6434,https://issues.apache.org/jira/browse/MAPREDUCE-6444
MAPREDUCE-6445,Bug,Major,,Shuffle hang,Scale cluster has run for months with 2.6.0. 2 of 200 reduces hang on shuffle  instance 1 log seems like loop on 1 map output:    node 2 log seems like loop on 5 map output:,Resolved,Cannot Reproduce,,Unassigned,Peng Zhang,Thu; 6 Aug 2015 13:57:45 +0000,Wed; 22 Jun 2016 22:51:55 +0000,Wed; 16 Sep 2015 07:47:43 +0000,,2.6.0,,,MAPREDUCE-6721,https://issues.apache.org/jira/browse/MAPREDUCE-6445
MAPREDUCE-6446,Improvement,Minor,resourcemanager,Support SSL for AM webapp,Application URL in Application CLI wrong  Steps to reproduce ========================== 1. Start HA setup insecure mode 2.Configure HTTPS_ONLY 3.Submit application to cluster 4.Execute command . ,Reopened,Unresolved,,Unassigned,Bibin A Chundatt,Fri; 15 May 2015 08:45:55 +0000,Fri; 7 Aug 2015 06:35:36 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6446
MAPREDUCE-6447,Bug,Minor,,"reduce shuffle throws ""java.lang.OutOfMemoryError: Java heap space""",2015-08-11 14:03:54;550 WARN main org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#10   org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 193),Open,Unresolved,,shuzhangyao,shuzhangyao,Tue; 11 Aug 2015 09:36:29 +0000,Thu; 31 Aug 2017 03:56:32 +0000,,,2.5.0;2.6.0;2.5.1;2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6447
MAPREDUCE-6448,Bug,Critical,,interrupted waiting to send rpc request to server,Pyton scripts execute HQL process stuck; CPU has been above 100%; hive in the background the background error below; can you tell me how to solve Thank you so much 2015-08-05 06:30:51;986 WARN  Thread-854: ipc.Client (Client. 336)         ... 17 more,Open,Unresolved,,duyanlong,duyanlong,Tue; 11 Aug 2015 13:32:26 +0000,Tue; 11 Aug 2015 13:32:26 +0000,,,2.5.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6448
MAPREDUCE-6449,Bug,Major,,MR Code should not throw and catch YarnRuntimeException to communicate internal exceptions,In discussion of MAPREDUCE-6439 we discussed how throwing and catching YarnRuntimeException in MR code is incorrect and we should instead use some MR specific exception.,Patch Available,Unresolved,,Neelesh Srinivas Salian,Anubhav Dhoot,Tue; 11 Aug 2015 23:25:57 +0000,Fri; 23 Oct 2015 14:06:14 +0000,,,,mapreduce,,MAPREDUCE-6439,https://issues.apache.org/jira/browse/MAPREDUCE-6449
MAPREDUCE-6450,Bug,Minor,,mapreduce.job.log4j-properties-file does not work for files on classpath,JobSubmitter.addLog4jToDistributedCache checks whether MRJobConfig.MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE is set; and tries to put it in the distributed cache if it is set:     This throws an exception inside JobSubmitter.validateFilePath if the file does not exist on the local filesystem; but is instead on the classpath.  This is unnecessarily restrictive; because later on in MRApps.addLog4jSystemProperties; the actual configuration of -Dlog4j.configuration works fine if the file is on the classpath and not a physical file:     (the default file container-log4j.properties is on the classpath anyway)  This is a nuisance because we have a bunch of projects and it's much easier to distribute shared configuration files via jars and dependencies than raw files.  It's not a blocker because I'm able to work around it by setting -Dlog4j.configuration in yarn.app.mapreduce.am.command-opts; but it's certainly hackier.,Open,Unresolved,,Ajith S,Ben Podgursky,Thu; 13 Aug 2015 13:21:51 +0000,Thu; 13 Aug 2015 14:36:21 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6450
MAPREDUCE-6451,Bug,Major,distcp,DistCp has incorrect chunkFilePath for multiple jobs when strategy is dynamic,DistCp when used with dynamic strategy does not update the chunkFilePath and other static variables any time other than for the first job. This is seen when DistCp::run() is used.   A single copy succeeds but multiple jobs finish successfully without any real copying.,Closed,Fixed,,Kuhu Shukla,Kuhu Shukla,Thu; 13 Aug 2015 14:46:13 +0000,Fri; 6 Jan 2017 07:38:26 +0000,Fri; 30 Oct 2015 20:01:23 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6451
MAPREDUCE-6452,Bug,Major,,NPE when intermediate encrypt enabled for LocalRunner,Enable the below properties try running mapreduce job  mapreduce.framework.name=local mapreduce.job.encrypted-intermediate-data=true     Jobs are failing always,Resolved,Fixed,,zhihai xu,Bibin A Chundatt,Fri; 14 Aug 2015 12:22:27 +0000,Tue; 30 Aug 2016 01:16:32 +0000,Fri; 28 Aug 2015 19:27:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6452
MAPREDUCE-6453,New Feature,Minor,,Repeatable Input File Format,We are interested in running the training process of deep learning architectures on Hadoop clusters. We developed an algorithm th require going over the data multiple times before reducing.,Open,Unresolved,,AbdulRahman AlHamali,AbdulRahman AlHamali,Mon; 17 Aug 2015 16:59:43 +0000,Mon; 17 Aug 2015 16:59:43 +0000,,,,deeplearning;inputfileformat;newbie;repeatable,,,https://issues.apache.org/jira/browse/MAPREDUCE-6453
MAPREDUCE-6454,Bug,Critical,,MapReduce doesn't set the HADOOP_CLASSPATH for jar lib in distributed cache.,We already set lib jars on distributed-cache to CLASSPATH. However; in some corner cases (like: MR local mode; Hive Map side local join; etc.); we need these jars on HADOOP_CLASSPATH so hadoop scripts can take it in launching runjar process.,Closed,Fixed,,Junping Du,Junping Du,Tue; 18 Aug 2015 16:27:57 +0000,Fri; 6 Jan 2017 00:56:44 +0000,Fri; 21 Aug 2015 00:43:03 +0000,,,,,MAPREDUCE-4740;MAPREDUCE-6619;MAPREDUCE-5490,https://issues.apache.org/jira/browse/MAPREDUCE-6454
HADOOP-12362,Bug,Major,,Set hadoop.tmp.dir and hadoop.log.dir in pom,There are some compelling features in later version of surefire which lets one exclude ; file);  This could simply be addressed with,Resolved,Fixed,,Charlie Helin,Charlie Helin,Tue; 18 Aug 2015 19:38:59 +0000,Tue; 30 Aug 2016 01:23:40 +0000,Thu; 27 Aug 2015 17:18:05 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/HADOOP-12362
MAPREDUCE-6456,Improvement,Major,,Support configurable log aggregation policy,"YARN-221 provides a way for a YARN application to specify log aggregation policy via LogAggregationContext.  This jira covers the necessary changes in MR to use that feature so that any MR job can specify its log aggregation policy via job configuration. That includes:   	Have MR define its own configurations to config these policies. 	Make code change at YarnRunner to retrieve these configurations and set the values via LogAggregationContext.",Open,Unresolved,,Ming Ma,Ming Ma,Wed; 19 Aug 2015 06:54:28 +0000,Fri; 21 Aug 2015 17:02:45 +0000,,,,,,YARN-221,https://issues.apache.org/jira/browse/MAPREDUCE-6456
MAPREDUCE-6457,Bug,Major,applicationmaster;mrv2,kill task before the task is truely runing on a slave node,I happned to find this bug. When I am doing some development based on Hadoop-2.6.0.  I happend to send to T_KILL signal to one of maptask before this task is register to TaskAttemptListener. Because the attempt is not assigned with a container yet. It may lead to a lot of errors.,Open,Unresolved,,Unassigned,Wei Chen,Wed; 19 Aug 2015 17:20:56 +0000,Wed; 19 Aug 2015 19:04:46 +0000,,,2.6.0;2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6457
MAPREDUCE-6458,Bug,Major,,Figure out the way to pass build-in classpath (files in distributed cache; etc.) from parent to spawned shells,In MAPREDUCE-6454 (target for branch-2.x); we provide a way with constraints to pass built-in classpath from parent to child shell; via HADOOP_CLASSPATH; so jars in distributed cache can still work in child tasks. In trunk; we may think some way different; like: involve additional env var to safely pass build-in classpath.,Patch Available,Unresolved,,Dustin Cote,Junping Du,Fri; 21 Aug 2015 01:03:18 +0000,Tue; 14 Nov 2017 19:37:09 +0000,,,,,MAPREDUCE-6504,,https://issues.apache.org/jira/browse/MAPREDUCE-6458
MAPREDUCE-6459,Bug,Major,,Native task crashes when merging spilled file on ppc64,when running native task on ppc64 merging spilled files fails since we could not deserialize local spill file correctly. Function readVLong in WritableUtils.h and Buffers.h; we try to compare a char with a number and convert a char to int64_t. It does not work correctly on ppc64 since char definition is different between ppc64 and x86 platform. On x86 platform char is defined as signed number while on ppc64 char is unsigned. As a result; we write EOF marker -1; -1 at the end of spill partition; but deserialize chars as 255; 255.,Resolved,Fixed,MAPREDUCE-6346,Tao Jie,Tao Jie,Fri; 21 Aug 2015 10:21:50 +0000,Wed; 17 May 2017 13:14:25 +0000,Wed; 17 May 2017 13:13:51 +0000,,2.6.0,,,MAPREDUCE-6346,https://issues.apache.org/jira/browse/MAPREDUCE-6459
MAPREDUCE-6460,Bug,Major,test,TestRMContainerAllocator.testAttemptNotFoundCausesRMCommunicatorException fails,TestRMContainerAllocator.testAttemptNotFoundCausesRMCommunicatorException fails with the following logs: -------------------------------------------------------  T E S T S ------------------------------------------------------- Running org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator Tests run: 24; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 94.525 sec &lt; FAILURE! - in org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator testAttemptNotFoundCausesRMCommunicatorException(org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator)  Time elapsed: 2.606 sec  &lt; FAILURE!  103)   Results :  Failed tests:    TestRMContainerAllocator.testAttemptNotFoundCausesRMCommunicatorException Expected exception: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocationException  Tests run: 24; Failures: 1; Errors: 0; Skipped: 0,Closed,Fixed,,zhihai xu,zhihai xu,Sat; 22 Aug 2015 01:17:59 +0000,Tue; 30 Aug 2016 01:16:31 +0000,Sat; 19 Sep 2015 07:21:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6460
MAPREDUCE-6461,Wish,Minor,mrv2,An implementation of RecordReader/FileInputFormat for generic binary data,It would be nice to have a RecordReader implementation designed for binary data for ETL processing (especially for mainframe encodings like EBCDIC).  Currently; we have: http: FixedLengthInputFormat.html  This is great for fix length fields; but it would be even better if we could delimit records by a byte string dynamically.,Open,Unresolved,,Unassigned,Dustin Cote,Mon; 24 Aug 2015 13:32:34 +0000,Tue; 25 Aug 2015 14:40:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6461
MAPREDUCE-6462,Improvement,Minor,jobhistoryserver,JobHistoryServer to support JvmPauseMonitor as a service,As JvmPauseMonitor is made as an AbstractService; subsequent method changes are needed in all places which uses the monitor.,Resolved,Duplicate,NULL,Sunil G,Sunil G,Mon; 24 Aug 2015 17:51:53 +0000,Tue; 30 Aug 2016 00:05:05 +0000,Tue; 30 Aug 2016 00:05:03 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6462
MAPREDUCE-6463,Bug,Major,,AM should register RM using IP address instead of hostname,I copied hadoop direcotry to a host which is not in cluster; and ran a streaming job on it. I encountered following error:     The exception is because AM register RM with hostname 'szsk-ad-serving-10-222-7-204' and client could not resolve it.,Resolved,Won't Fix,,Jun Gong,Jun Gong,Tue; 25 Aug 2015 10:52:37 +0000,Wed; 2 Sep 2015 01:12:13 +0000,Tue; 1 Sep 2015 12:47:13 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6463
MAPREDUCE-6464,Bug,Minor,,mapred queue <args> is throwing the NPE in case of the local framework,mapred queue args is throwing the NPE in case of the local framework. local framework does not support the same; so instead of throwing the NPE better we can give a meaning message.  stack trace,Patch Available,Unresolved,,Mohammad Shahid Khan,Mohammad Shahid Khan,Wed; 26 Aug 2015 04:59:18 +0000,Thu; 27 Oct 2016 10:49:12 +0000,,,2.7.1;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6464
MAPREDUCE-6465,Bug,Major,,NNBench result wrong when number of reducers greater than 1,Currently NNBench#analyzeResults consider only the part-0000 for analysis     Should consider all part files for output. or disable reduces option,Resolved,Duplicate,MAPREDUCE-6363,Bibin A Chundatt,Bibin A Chundatt,Thu; 27 Aug 2015 12:04:58 +0000,Thu; 14 Jan 2016 04:24:24 +0000,Thu; 14 Jan 2016 04:24:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6465
MAPREDUCE-6466,Improvement,Major,,NNBench map task should create files in separate folder,"In case of NNBench  with current implementation  all files created using different maps are created in same directory.  In this JIRA will provide a flag to create files in same folder or separate folder for each task.  dfs.namenode.fs-limits.max-directory-items cannot be set to more than 6;400;000 as i understand  Advantage   	For scenarios like creating fsimage with large size NNBench can be used 	Creation of multiple files of same size using NNBench folder based.    No need to run NNBench multiple time to create FSImage of large size.",Resolved,Duplicate,MAPREDUCE-6666,Bibin A Chundatt,Bibin A Chundatt,Tue; 1 Sep 2015 12:25:33 +0000,Fri; 13 May 2016 16:43:05 +0000,Fri; 13 May 2016 16:43:04 +0000,,,,,MAPREDUCE-6666,https://issues.apache.org/jira/browse/MAPREDUCE-6466
MAPREDUCE-6467,Bug,Minor,job submission,Submitting streaming job is not thread safe,The submission of the streaming job is not thread safe.  That is because the class StreamJob is using the OptionBuilder which is itself not thread safe.   This can cause super tricky bugs.   An easy fix would be to simply create instances of Option through the normal constructor and decorate the object if necessary.   This fix should be applied on the functions createOption and createBoolOption.,Patch Available,Unresolved,,Ivo Udelsmann,jeremie simon,Tue; 1 Sep 2015 17:09:08 +0000,Tue; 14 Nov 2017 19:37:08 +0000,,,2.7.1,easyfix;streaming;thread-safety,,,https://issues.apache.org/jira/browse/MAPREDUCE-6467
HADOOP-12428,Improvement,Minor,,Fix inconsistency between log-level guards and statements,Developers use logs to do in-house debugging. These log statements are later demoted to less severe levels and usually are guarded by their matching severity levels. However; we do see inconsistencies in trunk. A log statement like      doesn't make much sense because the log message is actually only printed out in DEBUG-level. We do see previous issues tried to correct this inconsistency. I am proposing a comprehensive correction over trunk.  Doug Cutting pointed it out in HADOOP-312: https: 1); which gives cleaner code and slightly higher performance.,Resolved,Fixed,,Jagadesh Kiran N,Jackie Chang,Thu; 26 Sep 2013 03:36:47 +0000,Tue; 30 Aug 2016 01:23:10 +0000,Tue; 22 Sep 2015 03:57:00 +0000,,,BB2015-05-TBR,,HDFS-1611,https://issues.apache.org/jira/browse/HADOOP-12428
MAPREDUCE-6469,Bug,Blocker,,libnativetask lacks header files and documentation,The MR native task library appears to have no header files included in the maven package and no documentation generated for mvn site.,Open,Unresolved,,Unassigned,Allen Wittenauer,Sun; 6 Sep 2015 08:01:48 +0000,Thu; 12 May 2016 18:23:01 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6469
MAPREDUCE-6470,Bug,Major,applicationmaster;resourcemanager;scheduler,ApplicationMaster may fail to preempt Reduce task,In my hadoop cluster the nodemanagers have different resource capacity.  Recently; when the yarn cluster ran out of resources and there are some big jobs running; the AM cannot preempt reduce task.   The scenario could be simplified as below: Say; there are 5 nodemanagers in my hadoop cluster with FairScheduler strategy enabled.  NodeManager Capacity :  namenode1 1024 memory; 1 cpu-vcores namenode1 4096 memory; 1 cpu-vcores namenode1 4096 memory; 1 cpu-vcores namenode1 1024 memory; 4 cpu-vcores namenode1 1024 memory; 4 cpu-vcores  Start one job including 10 maps and 10 reduces with following conf : yarn.app.mapreduce.am.resource.mb=1024m yarn.app.mapreduce.am.resource.cpu-vcores=1 mapreduce.map.memory.mb=1024m mapreduce.reduce.memory.mb=1024m mapreduce.map.cpu.vcores=1 mapreduce.reduce.cpu.vcores=1  After some map tasks finished; 4 reduce tasks started; but there are still some map tasks in scheduledRequests. At this time; the 5 nodemanagers resource usage is blow. NodeManager; Memory Used; Vcores Used; Memory Avail; Vcore Abail namenode1;     1024m;          1;          0;           0 namenode2;     1024m;          1;          3072m;       0 namenode3;     1024m;          1;          3072m;       0 namenode4;     1024m;          1;          0;           3 namenode5;     1024m;          1;          0;           3  So AM try to start the rest map tasks.  In RMContainerAllocator the availableResources got from ApplicationMasterService is 6144m; 6 cpu-vcores. Then RMContainerAllocator thinks there is enough resource to start one map task; so it will not try to preempt the reduce task. But in fact there isn't any single nodemanager has enough resource available to run one map task. In this case; AM will fail to obtain the container to start the rest map tasks. And since reduce tasks will not be preempted; the resource will never been released; then the job hangs forever.  I think the problem is that the overall resource headroom is not enough to help AM made the right decision on whether to preempt the reduce task or not. We need to provide more information to AM; e.g. adds a new api in AllocateResponse to get available resource list on all nodemanagers. But this approaching might cost too much overhead.   Any ideas?,Open,Unresolved,,Unassigned,NING DING,Tue; 8 Sep 2015 01:58:17 +0000,Tue; 8 Sep 2015 02:49:41 +0000,,,2.7.1,,,YARN-4125,https://issues.apache.org/jira/browse/MAPREDUCE-6470
MAPREDUCE-6471,Improvement,Major,distcp,Document distcp incremental copy ,MAPREDUCE-5899 added distcp support for incremental copy with a new append flag.  It should be documented.,Resolved,Fixed,,Neelesh Srinivas Salian,Arpit Agarwal,Tue; 8 Sep 2015 18:53:53 +0000,Tue; 30 Aug 2016 01:16:27 +0000,Mon; 28 Sep 2015 07:45:30 +0000,,2.7.1,newbie,,MAPREDUCE-5899,https://issues.apache.org/jira/browse/MAPREDUCE-6471
MAPREDUCE-6472,Bug,Major,mr-am,MapReduce AM should have java.io.tmpdir=./tmp to be consistent with tasks,MapReduceChildJVM.getVMCommand ensures that all tasks have -D io.tmpdir setting.  It should also use the same tmpdir setting to avoid cases where the AM JVM wants to place files in  tmp by default.,Closed,Fixed,MAPREDUCE-6576,Naganarasimha G R,Jason Lowe,Tue; 8 Sep 2015 19:19:18 +0000,Fri; 6 Jan 2017 01:48:22 +0000,Tue; 15 Sep 2015 19:46:17 +0000,,2.6.0,,,OOZIE-2209,https://issues.apache.org/jira/browse/MAPREDUCE-6472
MAPREDUCE-6473,Improvement,Major,performance,Job submission can take a long time during Cluster initialization,During initialization in Cluster.  the framework provider classes are loaded inside a sync block which can considerably increase job submission time when the number of submissions are high. The motive is to reduce time spent in this sync block safely to improve performance.,Resolved,Fixed,,Kuhu Shukla,Kuhu Shukla,Wed; 9 Sep 2015 21:49:53 +0000,Tue; 30 Aug 2016 01:16:25 +0000,Wed; 13 Jan 2016 00:00:27 +0000,,,,,MAPREDUCE-6761,https://issues.apache.org/jira/browse/MAPREDUCE-6473
MAPREDUCE-6474,Bug,Major,mrv2;nodemanager,ShuffleHandler can possibly exhaust nodemanager file descriptors,The async nature of the shufflehandler can cause it to open a huge number of file descriptors; when it runs out it crashes.  Scenario: Job with 6K reduces; slow start set to 0.95; about 40 map outputs per node. Let's say all 6K reduces hit a node at about same time asking for their outputs. Each reducer will ask for all 40 map outputs over a single socket in a single request (not necessarily all 40 at once; but with coalescing it is likely to be a large number).  sendMapOutput() will open the file for random reading and then perform an async transfer of the particular portion of this file(). This will theoretically happen 6000*40=240000 times which will run the NM out of file descriptors and cause it to crash.  The algorithm should be refactored a little to not open the fds until they're actually needed.,Closed,Fixed,,Kuhu Shukla,Nathan Roberts,Tue; 12 Aug 2014 15:56:00 +0000,Fri; 6 Jan 2017 07:31:40 +0000,Thu; 10 Sep 2015 16:10:57 +0000,,2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6474
MAPREDUCE-6475,Bug,Minor,test,test failing: TestRMContainerAllocator,Jenkins is failing on trunk on the test {{org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator testAttemptNotFoundCausesRMCommunicatorException}}  This is replicable locally.,Resolved,Won't Fix,,Steve Loughran,Steve Loughran,Sun; 13 Sep 2015 18:30:01 +0000,Thu; 12 May 2016 18:22:20 +0000,Mon; 23 Nov 2015 13:53:26 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6475
YARN-4582,Improvement,Major,scheduler,Label-related invalid resource request exception should be able to properly handled by application,"Steps to reproduce =============== Submit  mapreduce job   	map to label x 	reduce to label y    Precondition  	Queue b to which reduce is submitted not having access to label specified    Impact  	Jobs fail only of the RM-AM comunication timeout (About 10 mins i think)    Should kill the job immediately when InvalidResourceException is received on RMContainerRequestor#makeRemoteRequest Logs",Resolved,Fixed,,Bibin A Chundatt,Bibin A Chundatt,Mon; 14 Sep 2015 06:23:40 +0000,Tue; 30 Aug 2016 01:07:21 +0000,Tue; 12 Jan 2016 04:57:06 +0000,,,,,YARN-2492,https://issues.apache.org/jira/browse/YARN-4582
MAPREDUCE-6477,Task,Major,,Replace usage of deprecated NameNode.DEFAULT_PORT in TestFileSystem,The NameNode.DEFAULT_PORT static attribute is stale as we use HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT config value. Jira HDFS-9010 marks it as @Deprecated and refactored its usages in hadoop-hdfs module. This jira tracks the effort of replacing its usage in org.apache.hadoop.fs.TestFileSystem.,Resolved,Fixed,,Mingliang Liu,Mingliang Liu,Mon; 14 Sep 2015 20:51:25 +0000,Tue; 30 Aug 2016 01:16:21 +0000,Wed; 16 Sep 2015 20:08:57 +0000,,,,,HDFS-9010,https://issues.apache.org/jira/browse/MAPREDUCE-6477
MAPREDUCE-6478,Improvement,Major,,Add an option to skip cleanupJob stage or ignore cleanup failure during commitJob().,In some of our test cases for MR on public cloud scenario; a very big MR job with hundreds or thousands of reducers cannot finish successfully because of Job Cleanup failures which is caused by different scale resource cost.  We should allow user to have this option (ignore failure or skip job cleanup stage completely) especially when user know the cleanup failure is not due to HDFS abnormal status but other FS' different performance trade-off.,Resolved,Fixed,,Junping Du,Junping Du,Tue; 15 Sep 2015 22:14:52 +0000,Mon; 5 Dec 2016 13:53:22 +0000,Fri; 18 Sep 2015 17:36:27 +0000,,,,,SPARK-18512;MAPREDUCE-5485,https://issues.apache.org/jira/browse/MAPREDUCE-6478
MAPREDUCE-6479,Improvement,Major,documentation,Add missing mapred job command options in mapreduce document,As per initial analysis the following command details are not added in http: MapredCommands.html#job     Please let me know it is intentionally skipped ? if not i will update a patch to add.,Resolved,Fixed,,nijel,nijel,Wed; 16 Sep 2015 12:20:12 +0000,Tue; 30 Aug 2016 01:16:17 +0000,Fri; 9 Oct 2015 02:06:49 +0000,,,,,MAPREDUCE-6502,https://issues.apache.org/jira/browse/MAPREDUCE-6479
MAPREDUCE-6480,Bug,Major,,archive-logs tool may miss applications,"MAPREDUCE-6415 added a tool to archive aggregated logs into HAR files.  It seeds the initial list of applications to process based on apps which have finished aggregated; according to the RM.  However; the RM doesn't remember completed applications forever (e.g. failover); so it's possible for the tool to miss applications if they're no longer in the RM.    Instead; we should do the following:  	Seed the initial list of apps based on the aggregated log directories 	Make the RM not consider applications ""complete"" until their log aggregation has reached a terminal state (i.e. DISABLED; SUCCEEDED; FAILED; TIME_OUT).    #2 will allow #1 to assume that any apps not found in the RM are done aggregating.  #1 on it's own should cover most cases though",Resolved,Fixed,,Robert Kanter,Robert Kanter,Thu; 17 Sep 2015 00:11:45 +0000,Tue; 30 Aug 2016 01:16:15 +0000,Fri; 25 Sep 2015 22:03:24 +0000,,2.8.0,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-6480
MAPREDUCE-6481,Bug,Critical,mrv2,LineRecordReader may give incomplete record and wrong position/key information for uncompressed input sometimes.,"LineRecordReader may give incomplete record and wrong position key information.    The first issue only happens for Custom Delimiter; which is caused by the following code at LineReader#readCustomLine:   If appendLength is 0 and ambiguousByteCount is not 0; this bug will be triggered. For example; input is ""123456789aab""; Custom Delimiter is ""ab""; bufferSize is 10 and splitLength is 12; the correct record should be ""123456789a"" with length 10; but we get incomplete record ""123456789"" with length 9 from current code.  The second issue can happen for both Custom Delimiter and Default Delimiter; which is caused by the code in UncompressedSplitLineReader#readLine. UncompressedSplitLineReader#readLine may report wrong size information at some corner cases. The reason is unusedBytes in the following code:   If the last bytes read (bufferLength) is less than bufferSize; the previous unusedBytes will be wrong; which should be bufferLength - bufferPosn instead of bufferSize - bufferPosn. It will return larger value. For example; input is ""1234567890ab12ab345""; Custom Delimiter is ""ab""; bufferSize is 10 and two splits:first splitLength is 15 and second splitLength 4: the current code will give the following result: First record: Key:0 Value:""1234567890"" Second record: Key:12 Value:""12"" Third Record: Key:21 Value:""345"" You can see the Key for the third record is wrong; it should be 16 instead of 21. It is due to wrong unusedBytes. fillBuffer read 10 bytes for the first time; for the second times; it only read 5 bytes; which is 5 bytes less than the bufferSize. That is why the key we get is 5 bytes larger than the correct one.",Closed,Fixed,,zhihai xu,zhihai xu,Thu; 17 Sep 2015 05:52:03 +0000,Fri; 6 Jan 2017 00:55:54 +0000,Thu; 17 Sep 2015 14:33:42 +0000,,2.7.0,,,MAPREDUCE-5948;MAPREDUCE-6549,https://issues.apache.org/jira/browse/MAPREDUCE-6481
MAPREDUCE-6482,Bug,Major,,Since jvm reuse is not supported in hadoop 2.x; why I still find mapreduce.job.jvm.numtasks in mapre-default.xml,nan,Resolved,Invalid,,Unassigned,Wei Chen,Thu; 17 Sep 2015 16:04:26 +0000,Thu; 21 Jul 2016 04:03:03 +0000,Thu; 21 Jul 2016 04:03:02 +0000,,2.6.0;2.7.0;2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6482
MAPREDUCE-6483,Task,Major,test,Replace deprecated method NameNode.getUri() with DFSUtilClient.getNNUri() in TestMRCredentials,Test TestMRCredentials uses the NameNode.getUri() method which is deprecated in HDFS-9022. We should use DFSUtilClient.getNNUri() instead to get the name node URI given NN address. To make the Jenkins pass unit tests; jira HDFS-9022 focuses on changes in hadoop-hdfs module.  This jira tracks the effort of replacing usage of NameNode.getUri() with DFSUtilClient.getNNUri() in TestMRCredentials.  This patch will remove the newly brought   getUri(InetSocketAddress) in NameNode has been deprecated.,Resolved,Fixed,,Mingliang Liu,Mingliang Liu,Thu; 17 Sep 2015 17:50:53 +0000,Tue; 30 Aug 2016 01:16:11 +0000,Fri; 18 Sep 2015 20:38:20 +0000,,,,HDFS-9022,,https://issues.apache.org/jira/browse/MAPREDUCE-6483
MAPREDUCE-6484,Bug,Major,client;security,Yarn Client uses local address instead of RM address as token renewer in a secure cluster when RM HA is enabled.,"Yarn Client uses local address instead of RM address as token renewer in a secure cluster when RM HA is enabled. This will cause HDFS token renew failure for renewer ""nobody""  if the rules from hadoop.security.auth_to_local exclude the client address in HDFS DelegationTokenIdentifier. The reason why the local address is returned is: When HA is enabled; ""yarn.resourcemanager.address"" may not be set;  if HOSTNAME_PATTERN(""_HOST"") is used in ""yarn.resourcemanager.principal""; the default address ""0.0.0.0:8032"" will be used;  Based on the following code at SecurityUtil.  the local address will be used to replace ""0.0.0.0"".   The following is the exception which cause the job fail:",Resolved,Fixed,,zhihai xu,zhihai xu,Fri; 18 Sep 2015 23:31:02 +0000,Wed; 14 Sep 2016 20:50:05 +0000,Thu; 24 Sep 2015 15:26:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6484
MAPREDUCE-6485,Bug,Critical,applicationmaster,MR job hanged forever because all resources are taken up by reducers and the last map attempt never get resource to run,The scenarios is like this: With configuring mapreduce.job.reduce.slowstart.completedmaps=0.8; reduces will take resource and  start to run when all the map have not finished.  But It could happened that when all the resources are taken up by running reduces; there is still one map not finished.  Under this condition ; the last map have two task tempt request have lower priority than reduces; so preemption would not happened. As a result all reduces would not finished because of there is one map left. and the last map hanged there because of no resource available. so; the job would never finish.,Resolved,Fixed,,Xianyin Xin,Bob.zhao,Sat; 19 Sep 2015 06:59:31 +0000,Fri; 18 Aug 2017 09:39:07 +0000,Fri; 2 Oct 2015 15:08:49 +0000,,2.4.1;2.6.0;2.7.1;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6485
MAPREDUCE-6486,Bug,Major,mrv2;task,File{Input|Output}Format counters not updated when using viewfs,MapReduce tasks rely on filesystem stats to update FileInputFormatCounter and FileOutputFormatCounter bytes counters.  But if the filesystem is viewfs; stats are not updated and counters are zero. However the resolved filesystem for the input and output paths have their stats updated; and should be used by the framework (which could be done by resolving the path first).,Open,Unresolved,,Unassigned,Laurent Goujon,Mon; 21 Sep 2015 20:51:00 +0000,Mon; 12 Dec 2016 09:49:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6486
MAPREDUCE-6487,Bug,Major,task,TaskCounter.MAP_OUTPUT_BYTES is 0 for map-only jobs,It looks like DirectMapOutputCollector (used by Map-only jobs) doesn't update TaskCounter.MAP_OUTPUT_BYTES although it updates TaskCounter.MAP_OUTPUT_RECORDS.,Open,Unresolved,,nijel,Laurent Goujon,Mon; 21 Sep 2015 20:57:07 +0000,Sat; 10 Oct 2015 05:38:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6487
MAPREDUCE-6488,Improvement,Major,,Make buffer size in PipeMapRed configurable,Default value of buffer size is 128K in PipeMapRed.  When mapper input record is large enough that it won't fit in buffer; MapRunner blocks until written. If child process and input reader are both slow (due to calculation and decompress); then process of decoding and reading will rarely overlap with each other; hurting performance.  I suppose we should make the buffer size configurable.,Resolved,Invalid,,He Tianyi,He Tianyi,Tue; 22 Sep 2015 02:25:29 +0000,Fri; 2 Oct 2015 13:02:24 +0000,Fri; 2 Oct 2015 13:02:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6488
MAPREDUCE-6489,Improvement,Major,task,Fail fast rogue tasks that write too much to local disk,Tasks of the rogue jobs can write too much to local disk; negatively affecting the jobs running in collocated containers. Ideally YARN will be able to limit amount of local disk used by each task: YARN-4011. Until then; the mapreduce task can fail fast if the task is writing too much (above a configured threshold) to local disk.  As we discussed here the suggested approach is that the MapReduce task checks for BYTES_WRITTEN counter for the local disk and throws an exception when it goes beyond a configured value.  It is true that written bytes is larger than the actual used disk space; but to detect a rogue task the exact value is not required and a very large value for written bytes to local disk is a good indicative that the task is misbehaving.,Resolved,Fixed,,Maysam Yabandeh,Maysam Yabandeh,Wed; 23 Sep 2015 15:45:20 +0000,Fri; 8 Dec 2017 01:30:34 +0000,Wed; 21 Oct 2015 14:12:39 +0000,,2.7.1,,,TEZ-3821;MAPREDUCE-7022,https://issues.apache.org/jira/browse/MAPREDUCE-6489
MAPREDUCE-6490,Task,Major,,Facilitate the application life time out in mapreduce applications.,This task is to add the configurations related to application life time out and set in application submission context.,Open,Unresolved,,nijel,nijel,Thu; 24 Sep 2015 12:00:49 +0000,Thu; 24 Sep 2015 12:02:11 +0000,,,,,,YARN-3813,https://issues.apache.org/jira/browse/MAPREDUCE-6490
MAPREDUCE-6491,Bug,Major,,Environment variable handling assumes values should be appended,When processing environment variables for a container context the code assumes that the value should be appended to any pre-existing value in the environment.  This may be desired behavior for handling path-like environment variables such as PATH; LD_LIBRARY_PATH; CLASSPATH; etc. but it is a non-intuitive and harmful way to handle any variable that does not have path-like semantics.,Patch Available,Unresolved,,Dustin Cote,Jason Lowe,Tue; 29 Jul 2014 13:45:58 +0000,Mon; 18 Sep 2017 20:52:53 +0000,,,2.2.0,,,YARN-4789,https://issues.apache.org/jira/browse/MAPREDUCE-6491
MAPREDUCE-6492,Bug,Critical,,AsyncDispatcher exit with NPE on TaskAttemptImpl#sendJHStartEventForAssignedFailTask,For TaskAttemptImpl#DeallocateContainerTransition sendJHStartEventForAssignedFailTask is send for TaskAttemptStateInternal.UNASSIGNED also .   Causing NPE on taskAttempt.container.getNodeHttpAddress()       Log aggregation fail for mapreduce application.,Closed,Fixed,,Bibin A Chundatt,Bibin A Chundatt,Mon; 28 Sep 2015 10:16:44 +0000,Fri; 6 Jan 2017 00:54:15 +0000,Mon; 28 Sep 2015 22:14:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6492
MAPREDUCE-6493,Improvement,Major,,Keep the split information of the job after job completion in HDFS,Currently the split information will be available only till the job completes On completion this gets deleted  Can this file kept in HDFS for future analysis purpose. This helps a lot in analyzing the issues. if we keep in history server; it might fail to parse it. we need to skip this file. I will look into code and update the changes.  Please give your thoughts.,Open,Unresolved,,nijel,nijel,Mon; 28 Sep 2015 11:03:30 +0000,Mon; 28 Sep 2015 11:03:30 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6493
MAPREDUCE-6494,Bug,Major,,Permission issue when running archive-logs tool as different users,If the tool is run as user A; it creates  archive-logs-work when exiting.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Mon; 28 Sep 2015 20:57:12 +0000,Tue; 30 Aug 2016 01:16:03 +0000,Thu; 1 Oct 2015 00:34:56 +0000,,2.8.0,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-6494
MAPREDUCE-6495,Bug,Major,documentation,Docs for archive-logs tool,Write documentation for the 'mapred archive-logs' tool added in MAPREDUCE-6415.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Tue; 29 Sep 2015 00:22:26 +0000,Tue; 30 Aug 2016 01:16:01 +0000,Wed; 21 Oct 2015 00:35:52 +0000,,2.8.0,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-6495
HADOOP-12465,Bug,Minor,documentation,Incorrect javadoc in WritableUtils.java,"Documentation for writeVLong in WritableUtils states that ""For  -112 = i = 127; only one byte is used""  Documentation for writeVInt states that ""For -120 = i = 127; only one byte is used""  writeVInt calls internally writeVLong; so the ranges are the same for both functions.  After examining the code; I see that the documentation that is at writeVLong is correct. Documentation for writeVInt is therefore incorrect and should be fixed.",Closed,Fixed,,Jagadesh Kiran N,Martin Petricek,Tue; 29 Sep 2015 12:33:46 +0000,Fri; 6 Jan 2017 07:40:29 +0000,Wed; 7 Oct 2015 21:11:31 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/HADOOP-12465
MAPREDUCE-6497,Bug,Major,,Fix wrong value of JOB_FINISHED event in JobHistoryEventHandler,"It seems that ""MAP_COUNTER_GROUPS"" values use total_counter value. We should fix to use map_counter value.",Closed,Fixed,,Shinichi Yamashita,Shinichi Yamashita,Tue; 29 Sep 2015 13:18:59 +0000,Fri; 6 Jan 2017 07:33:55 +0000,Thu; 1 Oct 2015 09:27:42 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6497
MAPREDUCE-6498,Bug,Major,,ClientServiceDelegate should not retry upon AccessControlException,MapReduce client will retry forever when remote AM throw AccessControlException:      This issue is similar to MAPREDUCE-6285 which only handled AuthenticationException subclass of AccessControlException.,Patch Available,Unresolved,,Peng Zhang,Peng Zhang,Wed; 30 Sep 2015 04:01:48 +0000,Mon; 11 Sep 2017 07:42:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6498
MAPREDUCE-6499,Improvement,Major,webapps,Add elapsed time for retired job in JobHistoryServer WebUI,Now in  JobHistory Main Page show too little information about finished jobs;even don't have the job's running total time;only startTime;finishedTime.So;in jobHistory main page;we can add more informations about jobs; that we can better analyze jobs.,Resolved,Fixed,,Yiqun Lin,Yiqun Lin,Wed; 30 Sep 2015 10:19:43 +0000,Tue; 30 Aug 2016 01:15:58 +0000,Tue; 17 Nov 2015 06:20:07 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6499
MAPREDUCE-6500,Test,Minor,distcp,DynamicInputChunk and DynamicRecordReader class has no unit tests,The Dynamic strategy of DistCp has test coverage only for its InputFormat class. It would be nice to have coverage for DynamicRecordReader and DynamicInputChunk classes as well,Open,Unresolved,,Kuhu Shukla,Kuhu Shukla,Fri; 2 Oct 2015 19:01:21 +0000,Sat; 7 Jan 2017 02:00:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6500
MAPREDUCE-6501,Improvement,Major,applicationmaster,Improve reducer preemption,"As discussed on MAPREDUCE-6302; we could improve the reducer preemption as follows:  	preempt enough reducers so there are enough mappers to match slowstart 	prioritize preempting reducers that are still in SHUFFLE phase 	add an option to not preempt reducers that are past SHUFFLE phase irrespective of slowstart as long as one mapper can run    We could do it all in one patch or create subtasks as necessary.",Open,Unresolved,,Peter Bacsko,Karthik Kambatla,Mon; 5 Oct 2015 07:00:09 +0000,Wed; 24 May 2017 14:10:32 +0000,,,2.7.1,,,MAPREDUCE-6302,https://issues.apache.org/jira/browse/MAPREDUCE-6501
MAPREDUCE-6502,Improvement,Major,,"Support listing of black listed Nodemanagers in ""mapred job"" interface","As of now (in Mrv2) ""mapred job -list-blacklisted-trackers""  is not implemented and it always returns an empty list.    This can be implemented by taking the job-id and display the black listed nodes (node managers) for this job application.   Marking as incompatible since this require change in the command syntax.",Open,Unresolved,,nijel,nijel,Tue; 6 Oct 2015 06:00:13 +0000,Wed; 7 Oct 2015 21:36:37 +0000,,,,incompatible,,MAPREDUCE-6479,https://issues.apache.org/jira/browse/MAPREDUCE-6502
MAPREDUCE-6503,Bug,Major,,archive-logs tool should use HADOOP_PREFIX instead of HADOOP_HOME,The archive-logs tool currently uses HADOOP_HOME in the distributed shell job.  It should instead use HADOOP_PREFIX due to HADOOP-12451 HADOOP-12456.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Tue; 6 Oct 2015 20:27:30 +0000,Tue; 30 Aug 2016 01:15:58 +0000,Tue; 6 Oct 2015 23:55:51 +0000,,2.8.0,,,HADOOP-12456;HADOOP-12451;MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-6503
MAPREDUCE-6504,Task,Major,,take HADOOP_CLASSPATH off of the appendable list for trunk,Per MAPREDUCE-6491; the property called mapreduce.application.appendable.env.variables should have HADOOP_CLASSPATH removed from the default.  This dependent on  MAPREDUCE-6458,Patch Available,Unresolved,,Dustin Cote,Dustin Cote,Tue; 6 Oct 2015 21:14:51 +0000,Wed; 7 Oct 2015 00:09:29 +0000,,,,,MAPREDUCE-6458,,https://issues.apache.org/jira/browse/MAPREDUCE-6504
HADOOP-12564,Test,Trivial,test, Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io package,Migrating just the io test cases,Resolved,Fixed,,Dustin Cote,Dustin Cote,Thu; 8 Oct 2015 16:07:15 +0000,Tue; 30 Aug 2016 01:21:38 +0000,Wed; 18 Nov 2015 16:40:58 +0000,,,,,MAPREDUCE-6050,https://issues.apache.org/jira/browse/HADOOP-12564
MAPREDUCE-6506,Task,Critical,applicationmaster,Make the reducer-preemption configs consistent in how they handle defaults,mapreduce.job.reducer.preempt.delay.sec and mapreduce.job.reducer.unconditional-preempt.delay.sec are two configs related to reducer preemption. These configs are not consistent in how they handle non-positive values. Also; the way to disable them is different.   It would be nice to make them consistent somehow; and change the behavior of former if need be.,Resolved,Not A Problem,,Gerg   P  sztor,Karthik Kambatla,Thu; 8 Oct 2015 23:24:35 +0000,Thu; 2 Feb 2017 23:28:04 +0000,Thu; 2 Feb 2017 23:28:04 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6506
YARN-4686,Bug,Major,test,MiniYARNCluster.start() returns before cluster is completely started,TestRMNMInfo fails intermittently. Below is trace for the failure,Closed,Fixed,MAPREDUCE-6623,Eric Badger,Rohith Sharma K S,Fri; 9 Oct 2015 09:52:11 +0000,Fri; 6 Jan 2017 07:32:17 +0000,Mon; 21 Mar 2016 15:16:48 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-4686
MAPREDUCE-6508,Bug,Major,test,TestNetworkedJob fails consistently due to delegation token changes on RM.,nan,Resolved,Fixed,,Akira Ajisaka,Rohith Sharma K S,Fri; 9 Oct 2015 09:54:34 +0000,Tue; 30 Aug 2016 01:15:57 +0000,Fri; 8 Jan 2016 02:39:13 +0000,,,,,HADOOP-12693;MAPREDUCE-6201,https://issues.apache.org/jira/browse/MAPREDUCE-6508
YARN-4247,Bug,Blocker,fairscheduler;resourcemanager,Deadlock in FSAppAttempt and RMAppAttemptImpl causes RM to stop processing events,We see this deadlock in our testing where events do not get processed and we see this in the logs before the RM dies of OOM,Resolved,Cannot Reproduce,,Anubhav Dhoot,Anubhav Dhoot,Fri; 9 Oct 2015 17:20:48 +0000,Tue; 15 Dec 2015 02:13:42 +0000,Mon; 12 Oct 2015 02:16:07 +0000,,,,,YARN-2005,https://issues.apache.org/jira/browse/YARN-4247
MAPREDUCE-6510,Bug,Critical,,TestRMContainerAllocator is failing,Trace,Resolved,Duplicate,YARN-4250,Brahma Reddy Battula,Brahma Reddy Battula,Sun; 11 Oct 2015 07:34:22 +0000,Thu; 15 Oct 2015 03:31:51 +0000,Thu; 15 Oct 2015 03:31:51 +0000,,,,,YARN-4250,https://issues.apache.org/jira/browse/MAPREDUCE-6510
MAPREDUCE-6511,Bug,Major,applicationmaster;scheduler,MRAppMaster second attempt starting on the same node as a previously failed MRAppMaster attempt,Scenario: MRAppMaster attempt one executed on node that experience hardware issue.  Now the second attempt of the Application Master was scheduled on the same node. Section from RM log for first APP Master attempt:  2015-10-09 05:54:10;857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): YARN label is enabled with AM labels CORE 2015-10-09 05:54:10;859 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): appattempt_1444369886652_0001_000001 State change from SUBMITTED to SCHEDULED 2015-10-09 05:54:10;942 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue (ResourceManager Event Processor): assignContainers: node=ip-172-31-39-137.us-west-2.compute.internal application=1 priority=0 request= {Priority: 0; Capability: memory:15104; vCores:1; # Containers: 1; Labels: CORE; Location: *; Relax Locality: true}  type=OFF_SWITCH 2015-10-09 05:54:10;973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl (ResourceManager Event Processor): container_1444369886652_0001_01_000001 Container Transitioned from NEW to ALLOCATED 2015-10-09 05:54:10;973 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger (ResourceManager Event Processor): USER=hadoop OPERATION=AM Allocated Container        TARGET=SchedulerApp     RESULT=SUCCESS  APPID=application_1444369886652_0001    CONTAINERID=container_1444369886652_0001_01_000001   Section from RM log for second APP Master attempt:  2015-10-09 07:29:10;483 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): YARN label is enabled with AM labels CORE 2015-10-09 07:29:10;483 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): appattempt_1444369886652_0001_000002 State change from SUBMITTED to SCHEDULED 2015-10-09 07:29:10;498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue (ResourceManager Event Processor): assignContainers: node=ip-172-31-39-137.us-west-2.compute.internal application=1 priority=0 request= {Priority: 0; Capability: memory:15104; vCores:1; # Containers: 1; Labels: CORE; Location: *; Relax Locality: true}  type=OFF_SWITCH 2015-10-09 07:29:10;499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl (ResourceManager Event Processor): container_1444369886652_0001_02_000001 Container Transitioned from NEW to ALLOCATED 2015-10-09 07:29:10;499 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger (ResourceManager Event Processor): USER=hadoop OPERATION=AM Allocated Container        TARGET=SchedulerApp     RESULT=SUCCESS  APPID=application_1444369886652_0001    CONTAINERID=container_1444369886652_0001_02_000001,Resolved,Duplicate,YARN-2005,Unassigned,Neil Jonkers,Mon; 12 Oct 2015 20:09:21 +0000,Wed; 28 Oct 2015 17:54:54 +0000,Tue; 13 Oct 2015 08:40:26 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6511
MAPREDUCE-6512,Bug,Major,,FileOutputCommitter tasks unconditionally create parent directories,"If the output directory is deleted then subsequent tasks should fail. Instead they blindly create the missing parent directories; leading the job to be ""succesful"" despite potentially missing almost all of the output. Task attempts should fail if the parent app attempt directory is missing when they go to create their task attempt directory.",Resolved,Won't Fix,,Chang Li,Chang Li,Wed; 14 Oct 2015 21:33:18 +0000,Mon; 11 Apr 2016 21:36:17 +0000,Mon; 11 Apr 2016 21:36:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6512
MAPREDUCE-6513,Bug,Critical,applicationmaster;resourcemanager,MR job got hanged forever when one NM unstable for some time,when job is in-progress which is having more tasks;one node became unstable due to some OS issue.After the node became unstable; the map on this node status changed to KILLED state.   Currently maps which were running on unstable node are rescheduled; and all are in scheduled state and wait for RM assign container.Seen ask requests for map till Node is good (all those failed); there are no ask request after this. But AM keeps on preempting the reducers (it's recycling).  Finally reducers are waiting for complete mappers and mappers did n't get container..  My Question Is: ============ why map requests did not sent AM ;once after node recovery.?,Closed,Fixed,,Varun Saxena,Bob.zhao,Thu; 15 Oct 2015 15:32:26 +0000,Tue; 30 Aug 2016 01:15:56 +0000,Fri; 13 May 2016 21:56:24 +0000,,2.7.0,,,MAPREDUCE-5507;MAPREDUCE-6514;MAPREDUCE-6302;MAPREDUCE-6541,https://issues.apache.org/jira/browse/MAPREDUCE-6513
MAPREDUCE-6514,Bug,Blocker,applicationmaster,Job hangs as ask is not updated after ramping down of all reducers,In RMContainerAllocator#preemptReducesIfNeeded; we simply clear the scheduled reduces map and put these reducers to pending. This is not updated in ask. So RM keeps on assigning and AM is not able to assign as no reducer is scheduled(check logs below the code). If this is updated immediately; RM will be able to schedule mappers immediately which anyways is the intention when we ramp down reducers. Scheduler need not allocate for ramped down reducers This if not handled can lead to map starvation as pointed out in MAPREDUCE-6513,Closed,Fixed,,Varun Saxena,Varun Saxena,Sat; 17 Oct 2015 06:22:34 +0000,Fri; 6 Jan 2017 00:43:24 +0000,Fri; 6 May 2016 03:47:00 +0000,,,,,MAPREDUCE-6513,https://issues.apache.org/jira/browse/MAPREDUCE-6514
MAPREDUCE-6515,Bug,Major,applicationmaster,Update Application priority in AM side from AM-RM heartbeat,After YARN-4170; Application Priority is available via heartbeat call. Update this information in AM sothat client can fetch this information via JobStatus (JobReport) call.  This is as per the discussion happened in MAPREDUCE-5870.,Resolved,Fixed,,Sunil G,Sunil G,Mon; 19 Oct 2015 02:41:48 +0000,Tue; 30 Aug 2016 01:15:51 +0000,Thu; 29 Oct 2015 18:06:58 +0000,,,,,MAPREDUCE-5870,https://issues.apache.org/jira/browse/MAPREDUCE-6515
MAPREDUCE-6516,Improvement,Major,,JVM reuse in Yarn,Dear All;  Recently; we identified an issue inside Yarn with MapReduce. There is a significant amount of time spent in libjvm.so and most of which is compilation.   Attached is a flame graph (visual call graph) of a query running for about 8 mins. Most of the yellow bars represent  libjvm.so  functions while the  functions are colored in red. Data show that more than 40% of overall execution time is spent in compilation itself; but still a lot of code ran in the interpreter mode by looking inside the JVM themselves. In the ideal case; we want everything runs with compiled code over and over again. However in reality; mappers and reducers are long died before the compilation benefits kick in. In other word; we take the performance hit from both compilation and interpreter. JVM reuse feature in MapReduce 1.0 addressed this issue; but it was removed in Yarn. We are right now working on a bunch of JVM parameters to minimize the impact of the performance; but still think it would be good to open a discussion here to seek for more permanent solutions since it ties to the nature of how Yarn works.   We are wondering if any of you have seen this issue before or if there is any on-going project already happening to address this?   Data for this graph was collected across the entire system with multiple JVMs running. The workload we use is BigBench workload (https: Big-Data-Benchmark-for-Big-Bench).  Thanks; Yingqi Lu,Open,Unresolved,,Unassigned,Yingqi Lu,Tue; 20 Oct 2015 21:10:53 +0000,Thu; 22 Oct 2015 05:54:37 +0000,,,,performance,,,https://issues.apache.org/jira/browse/MAPREDUCE-6516
YARN-4285,Improvement,Major,resourcemanager,Display resource usage as percentage of queue and cluster in the RM UI,Currently; we display the memory and vcores allocated to an app in the RM UI. It would be useful to display the resources consumed as a %of the queue and the cluster to identify apps that are using a lot of resources.,Resolved,Fixed,,Varun Vasudev,Varun Vasudev,Wed; 21 Oct 2015 09:20:29 +0000,Tue; 5 Dec 2017 05:34:56 +0000,Mon; 26 Oct 2015 20:15:16 +0000,,,,,YARN-7608,https://issues.apache.org/jira/browse/YARN-4285
MAPREDUCE-6518,Bug,Major,mrv2;nodemanager,Set SO_KEEPALIVE on shuffle connections,Shuffle handler does not set SO_KEEPALIVE so we've seen cases where FDs sockets get stuck in ESTABLISHED state indefinitely because the server did not see the client leave (network cut or otherwise).,Closed,Fixed,,Chang Li,Nathan Roberts,Thu; 13 Aug 2015 17:02:25 +0000,Fri; 6 Jan 2017 07:38:13 +0000,Wed; 21 Oct 2015 21:47:54 +0000,,2.7.1,,,HDFS-8894,https://issues.apache.org/jira/browse/MAPREDUCE-6518
MAPREDUCE-6519,Task,Major,,Avoid unsafe split and append on fields that might be IPv6 literals,mapreduce portion of patch in HADOOP-12122 that couldn't run due to number of components touched.,Resolved,Fixed,,Nemanja Matkovic,Nemanja Matkovic,Wed; 21 Oct 2015 17:46:52 +0000,Wed; 4 Nov 2015 21:04:41 +0000,Wed; 4 Nov 2015 21:04:40 +0000,,,ipv6,YARN-4283,HADOOP-11890,https://issues.apache.org/jira/browse/MAPREDUCE-6519
MAPREDUCE-6520,Sub-task,Trivial,test,Migrate MR Client test cases part 1,Migrate the mr client test cases from JUnit3 part 1.  This will be a 3 part exercise.  Files in this JIRA will be: hadoop-mapreduce-project TestTeraSort.java,Resolved,Fixed,,Dustin Cote,Dustin Cote,Wed; 21 Oct 2015 20:57:35 +0000,Tue; 30 Aug 2016 01:15:46 +0000,Fri; 11 Mar 2016 14:02:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6520
MAPREDUCE-6521,Bug,Major,test,MiniMRYarnCluster should not create /tmp/hadoop-yarn/staging on local filesystem in unit test,MiniMRYarnCluster create  done by default. It should be under testWorkDir if the file system is localFs in order to make it to be removed by mvn clean. It would also avoid issues under parallel unit testing.,Patch Available,Unresolved,,Masatake Iwasaki,Masatake Iwasaki,Thu; 22 Oct 2015 08:28:09 +0000,Tue; 1 Aug 2017 19:10:05 +0000,,,,,,MAPREDUCE-6674,https://issues.apache.org/jira/browse/MAPREDUCE-6521
HADOOP-12510,Improvement,Major,security,Need improved WARN or ERROR when token based auth fails for kmsclient request,When token based authentication fails; it would be helpful to have a WARN event of the failure; as well as a WARN event that alternative forms of authentication are being attempted.  For example if token based authentication has failed; it appears that there is a fallback to attempting kerberos authentication.   At that point the most prominent logging is a kerberos GSS error; when the actual issue was a failure at the token evaluation of a client access request to an HDFS encrypted zone.   In the example below we are presented with a kerberos error; but the actual error was a failure of token authorization in an unexpected way.,Open,Unresolved,,Unassigned,Todd Grayson,Fri; 23 Oct 2015 00:20:39 +0000,Fri; 1 Apr 2016 10:56:26 +0000,,,,,,,https://issues.apache.org/jira/browse/HADOOP-12510
MAPREDUCE-6523,Task,Major,,hadoop-yarn Avoid unsafe split and append on fields that might be IPv6 literals,Yarn changes needed for IPv6 support for work It seems I cannot assign JIRA under YARN (see YARN-4283) so creating under mapreduce,Resolved,Duplicate,YARN-4283;YARN-4283,Nemanja Matkovic,Nemanja Matkovic,Fri; 23 Oct 2015 19:20:41 +0000,Sat; 24 Oct 2015 16:58:25 +0000,Sat; 24 Oct 2015 16:58:25 +0000,,,ipv6,,HADOOP-11890,https://issues.apache.org/jira/browse/MAPREDUCE-6523
MAPREDUCE-6524,Bug,Minor,test,Fix intermittent test failure of TestMRJobsWithHistoryService.testJobHistoryData,The historyClient tried to connect to port 0 and failed.,Resolved,Duplicate,MAPREDUCE-6525,Masatake Iwasaki,Masatake Iwasaki,Tue; 27 Oct 2015 01:49:40 +0000,Tue; 27 Oct 2015 16:29:50 +0000,Tue; 27 Oct 2015 09:32:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6524
MAPREDUCE-6525,Bug,Minor,test,Fix test failure of TestMiniMRClientCluster.testRestart,MiniMRYarnClusterAdapter#restart creates new MiniMRYarnCluster with configuration of existing MiniMRYarnCluster but the address of HistoryServer is properly set.,Resolved,Fixed,MAPREDUCE-6524,Masatake Iwasaki,Masatake Iwasaki,Tue; 27 Oct 2015 01:50:10 +0000,Thu; 12 May 2016 18:23:16 +0000,Mon; 2 Nov 2015 16:51:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6525
MAPREDUCE-6526,Improvement,Blocker,,Remove usage of metrics v1 from hadoop-mapreduce,LocalJobRunnerMetrics and ShuffleClientMetrics are still using metrics v1. We should remove these metrics or rewrite them to use metrics v2.,Resolved,Fixed,HADOOP-9281,Akira Ajisaka,Akira Ajisaka,Wed; 28 Oct 2015 10:38:41 +0000,Wed; 5 Apr 2017 08:48:03 +0000,Tue; 3 May 2016 01:50:59 +0000,,,,HADOOP-12504,,https://issues.apache.org/jira/browse/MAPREDUCE-6526
MAPREDUCE-6527,Bug,Major,,Data race on field org.apache.hadoop.mapred.JobConf.credentials,I am running the test suite against a dynamic race detector called RV-Predict. Here is a race report that I got:     In the source code of org.apache.hadoop.mapreduce.JobStatus.submitJob function; we have the following lines:   It looks a bit suspicious: Job extends thread and at the end of its constructor it starts a new thread which creates a new instance of JobContextImpl which reads credentials. However; the first thread concurrently sets credentials after a creating the Job instance.,Patch Available,Unresolved,,Unassigned,Ali Kheradmand,Wed; 28 Oct 2015 22:55:12 +0000,Mon; 19 Jun 2017 20:36:48 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6527
MAPREDUCE-6528,Bug,Critical,jobhistoryserver,Memory leak for HistoryFileManager.getJobSummary(),We meet memory leak issues for JHS in a large cluster which is caused by code below doesn't release FSDataInputStream in exception case. MAPREDUCE-6273 should fix most cases that exceptions get thrown. However; we still need to fix the memory leak for occasional case.,Closed,Fixed,,Junping Du,Junping Du,Thu; 29 Oct 2015 13:20:17 +0000,Fri; 6 Jan 2017 00:53:55 +0000,Fri; 30 Oct 2015 15:35:33 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6528
MAPREDUCE-6529,Improvement,Major,mr-am,AppMaster will not retry to request resource if AppMaster happens to decide to not use the resource,I am viewing code in RMContainerAllocator.  SetResourceRequest ask  is used to ask resource from ResourceManager. I found each container could only be requested once. It mean ask can be filled by addResourceRequestToAsk(ResourceRequest remoteRequest[]); but it can only added for once for each container. If we give up one assigned container; It will never request again,Open,Unresolved,,Unassigned,Wei Chen,Thu; 29 Oct 2015 22:01:06 +0000,Tue; 3 Nov 2015 14:33:57 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6529
MAPREDUCE-6530,Bug,Blocker,,Jobtracker is slow when more JT UI requests,"JobTracker is slow when there are huge number of Jobs running and 30 connections were established to info port to view Job status and counters.  hadoop job -list took 4m22.412s  We took Jstack traces and found most of the server threads waiting on JobTracker object and the thread which has the lock on JobTracker waits for ResourceBundle object.          ""retireJobs"" prio=10 tid=0x00007f2345200800 nid=0x11c1 waiting for monitor entry 0x00007f22e3499000     lang.Thread.State: BLOCKED (on object monitor)          a time.  Is there any workaround like JT UI caching or offloading some part in JT UI frontpage when load is heavy.",Open,Unresolved,,Unassigned,Prabhu Joseph,Fri; 30 Oct 2015 03:48:27 +0000,Fri; 27 Nov 2015 11:16:33 +0000,,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6530
MAPREDUCE-6531,New Feature,Major,,CLONE - Mumak: Map-Reduce Simulator,Vision:  We want to build a Simulator to simulate large-scale Hadoop clusters; applications and workloads. This would be invaluable in furthering Hadoop by providing a tool for researchers and developers to prototype features (e.g. pluggable block-placement for HDFS; Map-Reduce schedulers etc.) and predict their behaviour and performance with reasonable amount of confidence; there-by aiding rapid innovation.    First Cut: Simulator for the Map-Reduce Scheduler  The Map-Reduce Scheduler is a fertile area of interest with at least four schedulers; each with their own set of features; currently in existence: Default Scheduler; Capacity Scheduler; Fairshare Scheduler  Priority Scheduler.  Each scheduler's scheduling decisions are driven by many factors; such as fairness; capacity guarantee; resource availability; data-locality etc.  Given that; it is non-trivial to accurately choose a single scheduler or even a set of desired features to predict the right scheduler (or features) for a given workload. Hence a simulator which can predict how well a particular scheduler works for some specific workload by quickly iterating over schedulers and o; network topology) etc.,Resolved,Won't Fix,,Hong Tang,GD,Fri; 30 Oct 2015 10:28:33 +0000,Wed; 4 Nov 2015 20:25:31 +0000,Wed; 4 Nov 2015 20:25:31 +0000,,0.21.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6531
MAPREDUCE-6532,Sub-task,Major,contrib/mumak,CLONE - Create Fake Log from Hadoop,Version 1 of Mumak supports simulation of Map-Reduce jobs from the logs generated by original job run. Our main aim to run the job even without submitting it. So this task concerns to generate fake log file of Map-Reduce task; convert that into JSON by Rumen and run those files in Mumak.,Open,Unresolved,,Unassigned,GD,Fri; 30 Oct 2015 10:28:34 +0000,Fri; 30 Oct 2015 10:28:34 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6532
MAPREDUCE-6533,Bug,Major,,testDetermineCacheVisibilities of TestClientDistributedCacheManager is broken,nan,Resolved,Fixed,,Chang Li,Chang Li,Sat; 31 Oct 2015 07:25:38 +0000,Tue; 30 Aug 2016 01:15:43 +0000,Wed; 11 Nov 2015 17:28:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6533
MAPREDUCE-6534,Bug,Major,,Sorting based on attempt not working in JHS,Steps to reproduce ===============  1.Submit application with 1100 maps 2.Check successful maps in JHS 3.Try sorting based on attempt   SUCCESSFUL,Resolved,Duplicate,MAPREDUCE-6419,Mohammad Shahid Khan,Bibin A Chundatt,Wed; 4 Nov 2015 07:22:19 +0000,Thu; 24 Dec 2015 06:51:28 +0000,Thu; 24 Dec 2015 06:51:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6534
MAPREDUCE-6535,Bug,Major,mrv2,TaskID default constructor results in NPE on toString(),"This code will reproduce the issue:     The issue is that the default constructor leaves the type null.  The get() in CharTaskTypesMaps.getRepresentingCharacter() then throws an NPE on the null type key.  The simplest solution would be to only call the get() on line 288 of TaskID. if type is not null and return some other literal otherwise.  Since no part of the code is tripping on the NPE; what we choose for the literal shouldn't matter.  How about ""x""?",Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Wed; 4 Nov 2015 22:30:09 +0000,Tue; 30 Aug 2016 01:15:42 +0000,Fri; 25 Mar 2016 20:10:56 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6535
MAPREDUCE-6536,Bug,Blocker,pipes,hadoop-pipes doesn't use maven properties for openssl,hadoop-common has some maven properties that are used to define where OpenSSL lives.  hadoop-pipes should also use them so we can enable automated testing.,Resolved,Fixed,MAPREDUCE-4769,Allen Wittenauer,Allen Wittenauer,Tue; 27 Oct 2015 20:26:32 +0000,Thu; 29 Jun 2017 01:01:23 +0000,Thu; 29 Jun 2017 00:34:30 +0000,,3.0.0-alpha1,,HADOOP-12651,YETUS-138;MAPREDUCE-6539,https://issues.apache.org/jira/browse/MAPREDUCE-6536
MAPREDUCE-6537,Bug,Blocker,pipes,Include hadoop-pipes examples in the release tarball,Hadoop pipes examples are built but never packaged.,Resolved,Fixed,,Kai Sasaki,Allen Wittenauer,Mon; 7 Sep 2015 03:27:28 +0000,Tue; 30 Aug 2016 01:15:24 +0000,Mon; 2 May 2016 22:36:27 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6537
MAPREDUCE-6538,Wish,Minor,pipes,Deprecate hadoop-pipes,Development appears to have stopped on hadoop-pipes upstream for the last few years; aside from very basic maintenance.  Hadoop streaming seems to be a better alternative; since it supports more programming languages and is better implemented.  There were no responses to a message on the mailing list asking for users of Hadoop pipes... and in my experience; I have never seen anyone use this.  We should remove it to reduce our maintenance burden and build times.,Resolved,Won't Fix,,Colin P. McCabe,Colin P. McCabe,Tue; 3 Nov 2015 19:32:37 +0000,Fri; 6 Nov 2015 22:43:02 +0000,Fri; 6 Nov 2015 22:43:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6538
MAPREDUCE-6539,Sub-task,Major,pipes,Make hadoop-tools/hadoop-pipes Native code -Wall-clean,As we specify -Wall as a default compilation flag; it would be helpful if the Native code was -Wall-clean,Patch Available,Unresolved,,Alan Burlison,Alan Burlison,Tue; 23 Jun 2015 15:27:37 +0000,Tue; 15 Mar 2016 16:02:01 +0000,,,2.7.0,,,MAPREDUCE-6536;YETUS-138,https://issues.apache.org/jira/browse/MAPREDUCE-6539
MAPREDUCE-6540,Bug,Major,test,TestMRTimelineEventHandling fails,TestMRTimelineEventHandling fails after YARN-2859 is merged because it changed the port the AHS binds to in a mini cluster.,Closed,Fixed,,Sangjin Lee,Sangjin Lee,Fri; 6 Nov 2015 17:16:05 +0000,Fri; 6 Jan 2017 01:44:50 +0000,Thu; 12 Nov 2015 00:53:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6540
MAPREDUCE-6541,Bug,Major,,Exclude scheduled reducer memory when calculating available mapper slots from headroom to avoid deadlock ,"We saw a MR deadlock recently:   	When NM restarted by framework without enable recovery; containers running on these nodes will be identified as ""ABORTED""; and MR AM will try to reschedule ""ABORTED"" mapper containers. 	Since such lost mappers are ""ABORTED"" container; MR AM gives normal mapper priority (priority=20) to such mapper requests. If there's any pending reducer (priority=10) at the same time; mapper requests need to wait for reducer requests satisfied. 	In our test; one mapper needs 700+ MB; reducer needs 1000+ MB; and RM available resource = mapper-request = (700+ MB); only one job was running in the system so scheduler cannot allocate more reducer containers AND MR-AM thinks there're enough headroom for mapper so reducer containers will not be preempted.    MAPREDUCE-6302 can solve most of the problems; but in the other hand; I think we may need to exclude scheduled reducers resource when calculating #available-mapper-slots from headroom. Which we can avoid excessive reducer preemption.",Resolved,Fixed,,Varun Saxena,Wangda Tan,Fri; 6 Nov 2015 21:47:14 +0000,Fri; 6 Jan 2017 08:09:00 +0000,Thu; 27 Oct 2016 12:43:57 +0000,,2.7.1,,,MAPREDUCE-6513,https://issues.apache.org/jira/browse/MAPREDUCE-6541
MAPREDUCE-6542,Bug,Major,jobhistoryserver,HistoryViewer uses SimpleDateFormat; but SimpleDateFormat is not threadsafe,I use SimpleDateFormat to Parse the JobHistory File before      But I find I query the SubmitTime and LaunchTime in hive and compare JobHistory File time ; I find that the submitTime  and launchTime was wrong.  Finally;I change to use the FastDateFormat to parse the time format and the time become right,Resolved,Fixed,,zhangyubiao,zhangyubiao,Mon; 9 Nov 2015 13:08:32 +0000,Tue; 30 Aug 2016 01:15:20 +0000,Mon; 27 Jun 2016 22:21:05 +0000,,2.2.0;2.7.1,,,MAPREDUCE-6717,https://issues.apache.org/jira/browse/MAPREDUCE-6542
MAPREDUCE-6543,Sub-task,Trivial,test,Migrate MR Client test cases part 2,Migrate the second half of the MR client test cases.  The files included will be: hadoop-mapreduce-project TestNonExistentJob.java,Resolved,Fixed,,Dustin Cote,Dustin Cote,Wed; 11 Nov 2015 17:30:45 +0000,Tue; 30 Aug 2016 01:15:18 +0000,Tue; 29 Mar 2016 09:26:05 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6543
YARN-4345,Sub-task,Critical,graceful;resourcemanager,yarn rmadmin -updateNodeResource doesn't work,"YARN-313 add CLI to update node resource. It works fine for batch mode update. However; for single node update ""yarn rmadmin -updateNodeResource"" failed to work because resource is not set properly in sending request.",Resolved,Fixed,,Junping Du,Sushmitha Sreenivasan,Wed; 11 Nov 2015 17:55:16 +0000,Tue; 30 Aug 2016 01:14:26 +0000,Thu; 12 Nov 2015 14:50:34 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/YARN-4345
MAPREDUCE-6545,Improvement,Major,,Test committer.commitJob() behavior during committing when MR AM get failed.,In MAPREDUCE-5485; we are adding additional API (isCommitJobRepeatable) to allow job commit can tolerate AM failure in some cases (like FileOutputCommitter in v2 algorithm). Although we have unit test to cover most of flows; we may want a completed end to end test to verify the whole work flow. The scenario include: 1. For FileOutputCommitter (or some sub class); emulate a MR AM failure or restart during commitJob() in progress 2. Check different behavior for v1 and v2 (support isCommitJobRepeatable() or not),Open,Unresolved,,Junping Du,Junping Du,Wed; 11 Nov 2015 18:49:56 +0000,Tue; 24 Nov 2015 13:08:42 +0000,,,,,,MAPREDUCE-5485,https://issues.apache.org/jira/browse/MAPREDUCE-6545
MAPREDUCE-6546,Sub-task,Minor,,reconcile the two versions of the timeline service performance tests,The trunk now has a version of the timeline service performance test (YARN-2556). The timeline service v.2 (YARN-2928) also has a performance test; and these two versions are quite similar (by design).  We need to reconcile the two.,Resolved,Fixed,,Sangjin Lee,Sangjin Lee,Thu; 12 Nov 2015 02:02:30 +0000,Sat; 21 Oct 2017 06:30:12 +0000,Wed; 9 Mar 2016 05:53:04 +0000,,YARN-2928,yarn-2928-1st-milestone,,MAPREDUCE-6335;YARN-2556,https://issues.apache.org/jira/browse/MAPREDUCE-6546
MAPREDUCE-6547,Bug,Major,,package org.apache.hadoop.streaming.mapreduce missing in <=2.7.1,org.apache.hadoop.streaming.mapreduce package is missing  only old API based classes StreamInputFormat; StreamXmlRecordReader are available,Open,Unresolved,,Unassigned,Martin Kraemer,Thu; 12 Nov 2015 11:43:27 +0000,Thu; 12 Nov 2015 11:43:27 +0000,,,2.7.1;2.6.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6547
MAPREDUCE-6548,Improvement,Major,job submission,Jobs executed can be configurated with specific users and time hours,In recent hadoop versions;the system has no limitation for users to execute their jobs if you don't configurate ACL.And I find that the ACL is only called in IPC; isn't operated in job submissions.And this condition can't satisfied with this case that I have a very important job; and I am prepared to execute this job in 0 to 9 o'clock.In order to let this job executed quickly; I am not allowed other user's job to execute in these time. So I can see the result in tomorrow morning.So may be we can let jobs executed with specific users in specific time hours.,Resolved,Invalid,,Yiqun Lin,Yiqun Lin,Sat; 14 Nov 2015 16:11:26 +0000,Tue; 17 Nov 2015 11:16:04 +0000,Tue; 17 Nov 2015 11:16:04 +0000,,2.7.1,,,YARN-1051,https://issues.apache.org/jira/browse/MAPREDUCE-6548
MAPREDUCE-6549,Bug,Major,mrv1;mrv2,multibyte delimiters with LineRecordReader cause duplicate records,"LineRecorderReader currently produces duplicate records under certain scenarios such as:  1) input string: ""abc++defghi+""  delimiter string: ""+++""  test passes with all sizes of the split  2) input string: ""abc+def+ghi+""  delimiter string: ""+++""  test fails with a split size of 4  2) input string: ""abc++defghi+""  delimiter string: ""++""  test fails with a split size of 5  3) input string ""abc++defghij+""  delimiter string: ""++""  test fails with a split size of 4  4) input string ""abc+def+ghi+""  delimiter string: ""++""  test fails with a split size of 9",Closed,Fixed,MAPREDUCE-6891,Wilfred Spiegelenburg,Dustin Cote,Sat; 14 Nov 2015 21:32:44 +0000,Tue; 23 May 2017 11:54:11 +0000,Thu; 26 Nov 2015 01:06:00 +0000,,2.7.2,,,MAPREDUCE-6481;MAPREDUCE-6558,https://issues.apache.org/jira/browse/MAPREDUCE-6549
MAPREDUCE-6550,Bug,Major,,archive-logs tool changes log ownership to the Yarn user when using DefaultContainerExecutor,The archive-logs tool added in MAPREDUCE-6415 leverages the Distributed Shell app.  When using the DefaultContainerExecutor; this means that the job will actually run as the Yarn user; so the resulting har files are owned by the Yarn user instead of the original owner. The permissions are also now world-readable.  In the below example; the archived logs are owned by 'yarn' instead of 'paul' and are now world-readable:,Resolved,Fixed,,Robert Kanter,Robert Kanter,Wed; 18 Nov 2015 02:08:42 +0000,Tue; 30 Aug 2016 01:15:15 +0000,Thu; 26 Nov 2015 01:15:37 +0000,,2.8.0,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-6550
MAPREDUCE-6551,Improvement,Major,task,Dynamic adjust mapTaskAttempt memory size,I found a scenario that the map tasks cost so much resource of cluster.This scenario will be happened that if there are many small file blokcs (even some are not reach 1M);and this will lead to many map task to read.And in gengeral;a map task attempt will use the default config MRJobConfig#MAP_MEMORY_MB to set its resourceCapcity's memory to deal with their datas.And this will cause a problem that map tasks cost so much memory resource and target data is small.So I have a idea that wherther we can dynamic set mapTaskAttempt memory size by its inputDataLength.And this value can be provided by TaskSplitMetaInfo#getInputDataLength methods.Besides that;we should provided a standard unit dataLength for a standard memory size.,Patch Available,Unresolved,,Yiqun Lin,Yiqun Lin,Wed; 18 Nov 2015 13:10:31 +0000,Wed; 18 Nov 2015 14:34:31 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6551
MAPREDUCE-6552,Improvement,Major,webapps,Add job search button in JobHistoryServer WebUI,In jobhistory webui; it's not convenient to direct search the specific retired job when there are only few job records in page.And if you want to show more jobs in page(so that you can find your target job); the main page will be opened slowly.Because the renderd page will be large;and the browser will be cost much time to download this page.So we can add a search job button ; and by inputing a specific jobid and clicking the button; we can jump its job page.,Resolved,Invalid,,Yiqun Lin,Yiqun Lin,Thu; 19 Nov 2015 15:00:38 +0000,Fri; 12 Feb 2016 08:41:31 +0000,Fri; 12 Feb 2016 08:41:31 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6552
MAPREDUCE-6553,Bug,Minor,jobhistoryserver,Replace '\u2b05' with '<-' in rendering job configuration,"U+2B05 (leftwards black arrow) is not supported in some browsers; so we should replace it with ""-"".",Resolved,Fixed,,Gabor Liptak,Akira Ajisaka,Fri; 20 Nov 2015 06:47:49 +0000,Tue; 30 Aug 2016 01:15:13 +0000,Wed; 25 Nov 2015 07:36:33 +0000,,2.7.1,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6553
MAPREDUCE-6554,Bug,Critical,,MRAppMaster servicestart failing  with NPE in MRAppMaster#parsePreviousJobHistory,Create scenario so that MR app master gets preempted. On next MRAppMaster launch tried to recover previous job history file MRAppMaster#parsePreviousJobHistory      EventReader(EventReader stream),Closed,Fixed,,Bibin A Chundatt,Bibin A Chundatt,Sat; 21 Nov 2015 07:34:31 +0000,Fri; 6 Jan 2017 00:55:17 +0000,Fri; 15 Jan 2016 17:06:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6554
MAPREDUCE-6555,Bug,Major,,TestMRAppMaster fails on trunk,Observed in QA report of YARN-3840,Resolved,Fixed,,Junping Du,Varun Saxena,Sat; 21 Nov 2015 10:09:50 +0000,Thu; 12 May 2016 18:23:46 +0000,Wed; 25 Nov 2015 16:03:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6555
MAPREDUCE-6556,Bug,Major,client,It will failed to submit a job when dfs.permissions set false in hdfe-site.xml; but  current user do not have permission of hdfs path,"1. ""dfs.permissions"" have been set false in hdfs-site.xml 2. user aa don't have permitssion of hadoop path of  ""yarn.app.mapreduce.am.staging-dir"" 3. submit a job by user aa will throw Exception as following:  org.apache.hadoop.security.AccessControlException: Permission denied: user=aa; access=EXECUTE; inode="" hadoop"":mr:users:drwxr-x---          org.apache.hadoop.util.RunJar.main(RunJar. 212)",Open,Unresolved,,lachisis,lachisis,Mon; 23 Nov 2015 06:34:18 +0000,Tue; 24 Nov 2015 01:06:26 +0000,,,2.5.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6556
MAPREDUCE-6557,Bug,Blocker,build,Some tests in mapreduce-client-app are writing outside of target,There is a staging directory appearing. It should not.,Resolved,Fixed,MAPREDUCE-6559,Akira Ajisaka,Allen Wittenauer,Mon; 23 Nov 2015 18:47:09 +0000,Tue; 30 Aug 2016 01:15:11 +0000,Wed; 25 Nov 2015 17:13:44 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6557
MAPREDUCE-6558,Bug,Major,mrv1;mrv2,multibyte delimiters with compressed input files generate duplicate records,This is the follow up for MAPREDUCE-6549. Compressed files cause record duplications as shown in different junit tests. The number of duplicated records changes with the splitsize:  Unexpected number of records in split (splitsize = 10) Expected: 41051 Actual: 45062  Unexpected number of records in split (splitsize = 100000) Expected: 41051 Actual: 41052  Test passes with splitsize = 147445 which is the compressed file length.The file is a bzip2 file with 100k blocks and a total of 11 blocks,Closed,Fixed,,Wilfred Spiegelenburg,Wilfred Spiegelenburg,Tue; 24 Nov 2015 10:41:12 +0000,Tue; 30 Aug 2016 01:15:09 +0000,Fri; 13 May 2016 14:40:04 +0000,,2.7.2,,,MAPREDUCE-6549,https://issues.apache.org/jira/browse/MAPREDUCE-6558
MAPREDUCE-6559,Bug,Major,,TestMRAppMaster should use test.build.data for test directory,TestMRAppMaster creates intermediate files other than test.build.data; so the files are checked by Apache Rat and Jenkins reports license warnings. https: patch-asflicense-problems.txt,Resolved,Duplicate,MAPREDUCE-6557,Unassigned,Akira Ajisaka,Wed; 25 Nov 2015 05:50:03 +0000,Wed; 25 Nov 2015 06:05:04 +0000,Wed; 25 Nov 2015 06:05:04 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6559
MAPREDUCE-6560,Bug,Major,,ClientServiceDelegate doesn't handle retries during AM restart as intended,In the invoke() method; I found the following code:     When we create the AM proxy; we set the flag to true.  If we fail to connect; the impact of the flag being true is that the code will try one extra time; giving it 400ms instead of just 300ms.  I can't imagine that's the intended behavior.  After any failure; the flag will forever more be false; but fortunately (?!?) the flag is otherwise unused.  Looks like I need to do some archeology to figure out how we ended up here.,Resolved,Invalid,,Daniel Templeton,Daniel Templeton,Wed; 25 Nov 2015 18:45:20 +0000,Wed; 31 Aug 2016 23:22:31 +0000,Wed; 31 Aug 2016 23:22:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6560
MAPREDUCE-6561,Bug,Trivial,jobhistoryserver,Lack of confirmation of debug log enabled in HistoryFileManager,Debug log in scanIntermediateDirectory lacks the confirmation of debug mode is enabled or not.,Resolved,Not A Problem,,Kai Sasaki,Kai Sasaki,Wed; 2 Dec 2015 05:45:42 +0000,Thu; 3 Dec 2015 00:57:19 +0000,Wed; 2 Dec 2015 17:20:10 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6561
MAPREDUCE-6562,Bug,Major,mrv2,Monotonic Clock can be used in MR instead of Clock,MRApp and MRAppMaster are using SystemClock. Its better to use MonotonicClock here for safety. YARN-4403 gives a framework for this.,Open,Unresolved,,Sunil G,Sunil G,Thu; 3 Dec 2015 04:04:06 +0000,Thu; 3 Dec 2015 15:27:47 +0000,,,,,,YARN-4403,https://issues.apache.org/jira/browse/MAPREDUCE-6562
MAPREDUCE-6563,Bug,Trivial,documentation,Streaming documentation contains a stray '%' character.,We have an unneeded '%' character above the title in this page.  http: HadoopStreaming.html,Resolved,Fixed,,Chris Nauroth,Chris Nauroth,Fri; 4 Dec 2015 22:40:12 +0000,Tue; 30 Aug 2016 01:15:07 +0000,Thu; 28 Jan 2016 22:48:35 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6563
MAPREDUCE-6564,Improvement,Major,distcp,distcp creates missing perent directories which is inconsistent with fs -cp,fs -cp will fail if the destination parent directory does not exist.   However; distcp will not fail.  It creates the missing parent directory.,Open,Unresolved,,Unassigned,Tsz Wo Nicholas Sze,Sat; 5 Dec 2015 00:27:22 +0000,Mon; 7 Dec 2015 19:18:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6564
MAPREDUCE-6565,Bug,Major,,Configuration to use host name in delegation token service is not read from job.xml during MapReduce job execution.,By default; the service field of a delegation token is populated based on server IP address.  Setting hadoop.security.token.service.use_ip to false changes this behavior to use host name instead of IP address.  However; this configuration property is not read from job.xml.  Instead; it's read from a separate Configuration instance created during static initialization of SecurityUtil.  This does not work correctly with MapReduce jobs if the framework is distributed by setting mapreduce.application.framework.path and the mapreduce.application.classpath is isolated to avoid reading core-site.xml from the cluster nodes.  MapReduce tasks will fail to authenticate to HDFS; because they'll try to find a delegation token based on the NameNode IP address; even though at job submission time the tokens were generated using the host name.,Resolved,Fixed,HADOOP-13173,Li Lu,Chris Nauroth,Sat; 5 Dec 2015 01:03:11 +0000,Sat; 10 Dec 2016 01:57:43 +0000,Wed; 30 Nov 2016 00:55:20 +0000,,,,,HADOOP-12954;HADOOP-13206;HADOOP-7733,https://issues.apache.org/jira/browse/MAPREDUCE-6565
MAPREDUCE-6566,Improvement,Major,,Add retry support to mapreduce CLI tool,MAPREDUCE-6251 added support for retries to JobClient. However the MR CLI class doesn't use the JobClient. It would be useful to add support for retries to the CLI class as well.,Resolved,Fixed,,Varun Vasudev,Varun Vasudev,Mon; 7 Dec 2015 12:59:53 +0000,Tue; 30 Aug 2016 01:15:04 +0000,Fri; 5 Feb 2016 00:31:29 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6566
MAPREDUCE-6567,Bug,Minor,documentation,mapreduce ACLs documentation shows incorrect syntax,"The description of the mapreduce.job.acl-* in the mapred-default.xml shows the wrong syntax.    For specifying a list of users and groups the format to use is ""user1;user2 group1;group"". If set to '*'; it allows all users groups to modify this job.  The difference being that to make all members of a group have permissions for an ACL; the specification must be '* group' not just 'group'.",Resolved,Invalid,,Dustin Cote,Dustin Cote,Mon; 7 Dec 2015 20:19:31 +0000,Mon; 14 Dec 2015 19:09:17 +0000,Mon; 14 Dec 2015 19:09:17 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6567
MAPREDUCE-6568,Bug,Minor,contrib/streaming,Streaming Tasks dies when Environment Variable value longer than 100k,For some jobs I use mapred.input.format.class=org.apache.hadoop.mapred.lib.DelegatingInputFormat which also requires mapred.input.dir.formats  input reader class per each record; sometimes this list becomes very huge and job starts failing due to size of environment variable.  I added 100k limitation to org.apache.hadoop.streaming.PipeMapRed to addJobConfToEnvironment; but it doesn't seem a good solution due to different limitation on different platforms (Windows; Linux; etc)  I'm sure there should be better way to detect system limits and make this fix more flexible,Open,Unresolved,,Unassigned,Eugene A Slusarev,Tue; 8 Dec 2015 10:10:09 +0000,Tue; 8 Dec 2015 10:11:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6568
MAPREDUCE-6569,Bug,Major,applicationmaster,ApplicationMaster Stuck 10 min  And RM kill the AM,ApplicationMaster Stuck 10 min   and printLogs 2015-12-09 02:45:04;160 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 30634 for container- id container_1449229056278_297586_01_000001: 1.1 GB of 3 GB physical memory used; 3.5 GB of 9.3 GB virtual memory used 2015-12-09 02:45:07;527 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 30634 for container- id container_1449229056278_297586_01_000001: 1.1 GB of 3 GB physical memory used; 3.5 GB of 9.3 GB virtual memory used 2015-12-09 02:45:10;888 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 30634 for container- id container_1449229056278_297586_01_000001: 1.1 GB of 3 GB physical memory used; 3.5 GB of 9.3 GB virtual memory used 2015-12-09 02:45:14;274 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 30634 for container- id container_1449229056278_297586_01_000001: 1.1 GB of 3 GB physical memory used; 3.5 GB of 9.3 GB virtual memory used 2015-12-09 02:45:17;625 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 30634 for container- id container_1449229056278_297586_01_000001: 1.1 GB of 3 GB physical memory used; 3.5 GB of 9.3 GB virtual memory used And RM kill the AM,Open,Unresolved,,Unassigned,zhangyubiao,Wed; 9 Dec 2015 03:40:37 +0000,Fri; 18 Dec 2015 07:34:00 +0000,,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6569
MAPREDUCE-6570,Bug,Major,applicationmaster,logs in  MRAppMasterShutdownHook can not be output; beacuse Hook of Tasklog will be called to shutdown LogManager previously,priority of MRAppMasterShutdownHook  is 30; while priority of TaskLogHook is 50.  when a applicationMaster received a signal to shutdown; actually TaskLogHook  will be called first. Then when MRAppMasterShutdownHook  be called next; no logs can be output.,Patch Available,Unresolved,,lachisis,lachisis,Fri; 11 Dec 2015 09:27:35 +0000,Fri; 18 Dec 2015 08:03:42 +0000,,,2.5.0;2.6.0;2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6570
MAPREDUCE-6571,Bug,Minor,applicationmaster,JobEndNotification info logs are missing in AM container syslog,JobEndNotification logs are not written by MRAppMaster and JobEndNotifier classes even though Log.info is present. The reason was  MRAppMaster.this.stop() has been called before the JobEndNotification and hence somewhere during the stop log appenders also made null.  AM container syslog is not having below logs from JobEndNotifier     Job end notification trying + urlToNotify    Job end notification to + urlToNotify + succeeded   failed,Resolved,Fixed,,Haibo Chen,Prabhu Joseph,Wed; 9 Dec 2015 20:17:10 +0000,Tue; 6 Dec 2016 21:40:39 +0000,Tue; 6 Dec 2016 21:11:50 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6571
MAPREDUCE-6572,Bug,Major,,Improved incremental data copy of distcp for truncated file,"MAPREDUCE-5899 improves distcp by supporting incremental data copy. That is; if a file is only appended since it was copied last time; only new data need to be copied.   This improvement was done before HDFS truncate feature (HDFS-3107) was implemented. Since we support truncate; if a large file is truncated a little bit; the whole file will still need to be copied; even with the solution of MAPREDUCE-5899.  Creating this jira to improve the situation; by possibly remembering the smallest truncated size; so there is chance to only append from that size on.  HDFS tasks  	Add field minTruncateLength to FileWithSnapshotFeature; default to file size. 	Whenever a file is truncated; update the field. 	Pass the field to HDFS client in MODIFY entry of SnapshotDiffReport. 	When a snapshot is deleted; minTruncateLenght(s+1) = min(minTruncateLenght(s+1); minTruncateLenght(s))    CopyMapper tasks  	If minTruncateLength  target_file_length; CopyMapper should perform a truncate(target_file_length - minTruncateLength) operation. 	If minTruncateLength  source_file_length; CopyMapper should perform an append(source_file_length - minTruncateLength) operation.    In some cases; CopyMapper may perform a truncate followed by an append.",Open,Unresolved,,John Zhuge,Yongjun Zhang,Mon; 14 Dec 2015 19:42:14 +0000,Tue; 12 Jan 2016 22:32:52 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6572
MAPREDUCE-6573,Improvement,Minor,jobhistoryserver,Reduce the time of calling scanIntermediateDirectory in getFileInfo,In getFileInfo of HistorFileManager; scanIntermediateDirectory is called multiple times. It can have an impact on periodic directory scan task. We can optimize to reducing the calling time.,Open,Unresolved,,Kai Sasaki,Kai Sasaki,Wed; 16 Dec 2015 02:38:25 +0000,Tue; 17 May 2016 17:06:03 +0000,,,,,,MAPREDUCE-6436;MAPREDUCE-6684,https://issues.apache.org/jira/browse/MAPREDUCE-6573
MAPREDUCE-6574,Bug,Major,,MR AM should print host of failed tasks.,Something tasks failed because of issues on NMs. For example; bad disk network could cause reducer fetching failure and mappers need to be re-scheduled.  It will be very helpful to identify such issues if we could print host of failed tasks; which we can simply grep MR AM's log to see what happened.,Resolved,Fixed,,Mohammad Shahid Khan,Wangda Tan,Wed; 16 Dec 2015 18:21:47 +0000,Tue; 30 Aug 2016 01:15:02 +0000,Mon; 28 Dec 2015 19:10:53 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6574
YARN-5575,Improvement,Major,,Many classes use bare yarn. properties instead of the defined constants,MAPREDUCE-5870 introduced the following line:     It should instead be:,Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Wed; 16 Dec 2015 20:30:53 +0000,Wed; 26 Oct 2016 07:03:04 +0000,Wed; 26 Oct 2016 06:37:48 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-5575
MAPREDUCE-6576,Improvement,Major,,AM java.io.tmpdir should be set to $PWD/tmp,For tasks it is already done by MapReduceChildJVM      Need to do this in AM as well; so that running in uber mode does not go to default  io.tmpdir of  tmp and fill up task nodes and not be cleanedup.,Resolved,Duplicate,MAPREDUCE-6472,Unassigned,Rohini Palaniswamy,Wed; 16 Dec 2015 20:34:57 +0000,Wed; 16 Dec 2015 20:53:57 +0000,Wed; 16 Dec 2015 20:53:57 +0000,,,newbie,,OOZIE-2260,https://issues.apache.org/jira/browse/MAPREDUCE-6576
MAPREDUCE-6577,Bug,Critical,mr-am,MR AM unable to load native library without MR_AM_ADMIN_USER_ENV set,If yarn.app.mapreduce.am.admin.user.env (or yarn.app.mapreduce.am.env) is not configured to set LD_LIBRARY_PATH; MR AM will fail to load the native library:     As a result; any code that needs the hadoop native library in the MR AM will fail. For example; an uber-AM with lz4 compression for the mapper task will fail:,Closed,Fixed,MAPREDUCE-5799;MAPREDUCE-6590,Sangjin Lee,Sangjin Lee,Thu; 17 Dec 2015 06:46:30 +0000,Fri; 6 Jan 2017 07:58:47 +0000,Wed; 6 Jan 2016 00:08:44 +0000,,2.6.0,,,HADOOP-13684,https://issues.apache.org/jira/browse/MAPREDUCE-6577
MAPREDUCE-6578,New Feature,Major,,Add support for HDFS heterogeneous storage testing to TestDFSIO,HDFS heterogeneous storage allows user to store data blocks to different storage medias according to predefined storage policies. Only 'Default' policy is supported in current TestDFSIO implementation. This is going to add an new option to enable tests of other storage polices.,Resolved,Fixed,,Wei Zhou,Wei Zhou,Thu; 17 Dec 2015 13:40:22 +0000,Wed; 24 Aug 2016 14:40:16 +0000,Wed; 24 Aug 2016 14:26:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6578
MAPREDUCE-6579,Bug,Blocker,test,JobStatus#getFailureInfo should not output diagnostic information when the job is running,From https: patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-jobclient-jdk1.8.0_66.txt TestNetworkedJob are failed intermittently.,Resolved,Fixed,MAPREDUCE-6623,Akira Ajisaka,Rohith Sharma K S,Fri; 18 Dec 2015 05:38:45 +0000,Tue; 30 Aug 2016 01:14:58 +0000,Wed; 16 Mar 2016 00:33:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6579
MAPREDUCE-6580,Bug,Major,,Test failure : TestMRJobsWithProfiler,From https: patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-jobclient-jdk1.8.0_66.txt TestMRJobsWithProfiler fails intermittently,Closed,Fixed,,Eric Badger,Rohith Sharma K S,Fri; 18 Dec 2015 05:40:19 +0000,Tue; 30 Aug 2016 01:14:57 +0000,Wed; 23 Mar 2016 04:27:52 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6580
MAPREDUCE-6581,Bug,Blocker,,Shuffle failure incase of NativeMapOutputCollectorDelegator with intermediate-data encrypt,"Steps to reproduce   	Create data with teragen 	Run terasort on data prepared using teragen    Commands used   . Teraout12",Open,Unresolved,,Unassigned,Bibin A Chundatt,Fri; 18 Dec 2015 17:53:05 +0000,Thu; 21 Jul 2016 04:12:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6581
MAPREDUCE-6582,Bug,Major,client,A number of inconsistent default configuration values,In MapReduce; a list of default configuration values in the source code are inconsistent with what is specified in mapred-default.xml; (https: )  I suppose the inconsistency are caused by obsoleteness (either the code or the xml); and #2 is more like a bug...    1. mapreduce.reduce.shuffle.fetch.retry.timeout-ms In mapred-default.xml; the value is 30000; while it is 180000 in the code;       2. mapreduce.shuffle.ssl.file.buffer.size In mapred-default.xml; the value is 65536; while it is 61440 in the code;     This one looks quite weird; because normally it should be 64 * 1024 (i.e.; 65536). I don't know whether it's a typo...    3. mapreduce.reduce.shuffle.merge.percent In mapred-default.xml; the value is 0.66; while it is 0.9 in the code;      4. mapreduce.task.timeout In mapred-default.xml; the value is 600000; while it is 300000 in the code;      5. mapreduce.task.io.sort.factor In mapred-default.xml; the value is 10; while it is 100 in the code;         6. mapreduce.input.fileinputformat.split.minsize In mapred-default.xml; the value is 0; while it is 1 in the code;         7. mapreduce.job.end-notification.max.attempts In mapred-default.xml; the value is 5; while it is 1 in the code;      8. mapreduce.job.end-notification.retry.interval In mapred-default.xml; the value is 1000. In the code; the default value is 30000. (actually the two usages are even not the same...),Patch Available,Unresolved,,Unassigned,Tianyin Xu,Sat; 19 Dec 2015 21:38:45 +0000,Thu; 24 Dec 2015 23:37:10 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6582
MAPREDUCE-6583,Bug,Minor,documentation,Clarify confusing sentence in MapReduce tutorial document,The current MapReduce tutorial has the following statement which is confusing:   Overall; Mapper implementations are passed the Job for the job via the Job.setMapperClass(Class) method.  The sentence seems to contradict itself.   The code shows the mapper getting passed to the job.  However; the working suggests that the job is passed to the mapper?  https: MapReduceTutorial.html#Mapper,Closed,Fixed,,Kai Sasaki,chris snow,Thu; 8 Oct 2015 13:33:48 +0000,Tue; 30 Aug 2016 01:14:56 +0000,Sun; 20 Dec 2015 15:20:46 +0000,,,,,YETUS-260,https://issues.apache.org/jira/browse/MAPREDUCE-6583
MAPREDUCE-6584,Improvement,Major,documentation,Remove trailing whitespaces from mapred-default.xml,In MAPREDUCE-6583; test-patch reported that mapred-default.xml has many trailing whitespaces.,Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Sun; 20 Dec 2015 15:30:17 +0000,Tue; 30 Aug 2016 01:14:56 +0000,Tue; 29 Dec 2015 16:06:50 +0000,,,,,YETUS-260,https://issues.apache.org/jira/browse/MAPREDUCE-6584
MAPREDUCE-6585,Bug,Minor,,The configration about Counters don't work in MR job; which is setted by user,In org.apache.hadoop.mapreduce.monitorAndPrintJob(); maybe cause org.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120.  Because getCounters() only use client Configuration rather than user Configration.,Patch Available,Unresolved,,YuanBo Peng,YuanBo Peng,Tue; 22 Dec 2015 06:51:46 +0000,Thu; 24 Dec 2015 02:43:46 +0000,,,2.3.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6585
MAPREDUCE-6586,Bug,Major,webapps,TaskAttempt Page should reset the progress to 0 when its state is failed,The progress of taskAttempt is not correctly showing when the taskAttempt is failed. The value is 100.00; but actually the taskAttempt is failed. And I found the reason is following:    When the taskAttempt is completed; the progress will always return 1.0 whenever the result is failed or succeed. This will let users confused. May be it should be reset to 0 better. I attach a screen shot of this case.,Patch Available,Unresolved,,Yiqun Lin,Yiqun Lin,Tue; 22 Dec 2015 08:59:42 +0000,Tue; 22 Dec 2015 09:06:47 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6586
MAPREDUCE-6587,Improvement,Minor,,Remove unused params in connection-related methods of Fetcher,There are some unused params in Fecther#openConnectionWithRetry.The code is following:   we can see that the param remaing and host is not be used in this method. So we need to remove these param and update the method params which invoke this method.,Resolved,Fixed,,Yiqun Lin,Yiqun Lin,Wed; 23 Dec 2015 03:37:52 +0000,Tue; 30 Aug 2016 01:14:53 +0000,Tue; 23 Aug 2016 08:14:11 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6587
MAPREDUCE-6588,Bug,Major,mr-am,default values for PATH for tasks are not quite correct on Windows,"There are several issues with the way PATH are handled for MR tasks and AMs on Windows.   	it does not get the PWD as part of the path; unlike the non-Windows case (see MAPREDUCE-6021) 	the MR AM doesn't get the Hadoop's bin directory in the path explicitly through mapred configuration; rather; it implicitly inherits it from the node manager (see MAPREDUCE-6577) 	the default value for the MR task PATH uses ""%...%"" macros which may be expanded on the client side prematurely; this is probably OK for tasks (as it's done by the AM); but not OK for AMs; the late-binding cross-platform macros should be used    I took a stab at addressing these as part of MAPREDUCE-6577; but I realized that it would be a bigger issue than the fix for MAPREDUCE-6577 itself. Thus; I'm filing a separate JIRA to address the Windows side of things.  On a related note; there are quite a few brittle tests on testing these (TestMiniMRChildTask; TestMiniMRClientCluster; etc.) which are built in such a way that the tests pass against the current behavior but don't provide a lot of robust test value. We should also update those tests to make them more robust.",Open,Unresolved,,Unassigned,Sangjin Lee,Thu; 24 Dec 2015 01:08:20 +0000,Wed; 6 Jan 2016 00:19:24 +0000,,,2.6.0,,,MAPREDUCE-6021,https://issues.apache.org/jira/browse/MAPREDUCE-6588
MAPREDUCE-6589,Bug,Major,test,TestTaskLog outputs a log under directory other than target/test-dir,In MAPREDUCE-6584; Jenkins reported license error for location test-dir and remove the file after the test.,Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Fri; 25 Dec 2015 13:39:31 +0000,Tue; 30 Aug 2016 01:14:51 +0000,Tue; 29 Dec 2015 16:36:11 +0000,,,,,HADOOP-12984,https://issues.apache.org/jira/browse/MAPREDUCE-6589
MAPREDUCE-6590,Bug,Major,mr-am,Update MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV value for loading correct navite lib when using ubertask feature,By default; the MR AM unable to load native library without MR_AM_ADMIN_USER_ENV set. If yarn.app.mapreduce.am.admin.user.env (or yarn.app.mapreduce.am.env) is not configured to set LD_LIBRARY_PATH; MR AM will fail to load the native library; then you can find the error message as below.   I found the patch in https: native path.  I suggest MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV should be defined as below.    Please see my patch.,Resolved,Duplicate,MAPREDUCE-6577,NING DING,NING DING,Sun; 27 Dec 2015 01:24:52 +0000,Tue; 5 Jan 2016 21:55:30 +0000,Tue; 5 Jan 2016 21:55:30 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6590
MAPREDUCE-6591,Bug,Major,test,TestJobHistoryEventHandler#testTimelineEventHandling failing in trunk,org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testTimelineEventHandling failing in trunk      https: ,Resolved,Duplicate,MAPREDUCE-6593,Bibin A Chundatt,Bibin A Chundatt,Mon; 28 Dec 2015 04:25:21 +0000,Tue; 29 Dec 2015 11:46:59 +0000,Tue; 29 Dec 2015 03:10:18 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6591
MAPREDUCE-6592,Improvement,Minor,,MR ApplicationMaster is not supposed to resolve rack locality! It should ask RM or NN about the topology,"While working on configuring Rack Awareness (following HDP Documentation); we realized that this does not work for MR applications; unless the rack topology resolution script is installed on the node managers where the application masters reside. Otherwise; the AM will thrown an IOException: Cannot run program "" rack_topology.sh"".   This is contradictory to the documentations which states it makes sense to have the scripts that resolve the rack and node names on the Resource Manager and Name Node.   It is clearly not scalable to require to install these scripts on all the node managers!",Resolved,Duplicate,YARN-435,Harsh J,Babak Behzad,Mon; 28 Dec 2015 22:45:40 +0000,Tue; 29 Dec 2015 10:14:45 +0000,Tue; 29 Dec 2015 10:14:45 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6592
MAPREDUCE-6593,Bug,Major,,TestJobHistoryEventHandler.testTimelineEventHandling fails on trunk because of NPE,https: ,Resolved,Fixed,MAPREDUCE-6591;YARN-4521,Naganarasimha G R,Tsuyoshi Ozawa,Thu; 24 Dec 2015 10:45:18 +0000,Tue; 30 Aug 2016 01:14:48 +0000,Mon; 4 Jan 2016 07:46:27 +0000,,,test,,,https://issues.apache.org/jira/browse/MAPREDUCE-6593
MAPREDUCE-6594,Improvement,Major,webapps,JobHistory WebUI add jobName-filtered searching function ,In JobHistory main page; it can't search those jobs which are not displayed in main page.So if you want to search earlier job; you should set the job-cache size bigger. And this will let the main page opening slowly due to the large of job records. We should provider a way to search these jobs not depending on the displayed jobs on page.,Patch Available,Unresolved,,Yiqun Lin,Yiqun Lin,Tue; 29 Dec 2015 15:01:26 +0000,Tue; 29 Dec 2015 16:32:08 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6594
MAPREDUCE-6595,Bug,Major,,Fix findbugs warnings in OutputCommitter and FileOutputCommitter,There are 2 findbugs warnings in hadoop-mapreduce-client-core module. https: branch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core-warnings.html,Resolved,Fixed,MAPREDUCE-6606,Akira Ajisaka,Akira Ajisaka,Tue; 29 Dec 2015 16:28:33 +0000,Tue; 30 Aug 2016 01:14:46 +0000,Thu; 28 Jan 2016 14:12:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6595
MAPREDUCE-6596,Bug,Major,mrv2,MultipleInputs does not escape Path characters,Filenames containing commas or semicolons cause MultipleInputs to break since these characters are used for joining and storing the path names.  MultipleInputs stores mapreduce.input.multipleinputs.dir.formats as:  path;inputFormatClass;path2;inputFormatClass2; ...  If a filename contains one of the characters used for joining the data then getInputFormatMap and getMapperTypeMap will fail.  Looking at FileInputFormat.addInputPath() it uses escapeString and unescapeString from StringUtils. I took the same approach for escaping in MultipleInputs.,Patch Available,Unresolved,,Unassigned,Zac Hopkinson,Wed; 30 Dec 2015 19:12:37 +0000,Thu; 7 Jan 2016 14:40:42 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6596
MAPREDUCE-6597,Improvement,Minor,distcp,Distcp should move the path to trash when delete missing path from source,For now; when we use the distcp with the delete option; the path will be deleted when missing in the source. We should add the option skipTrash to control the behavior. if  skipTrash missing; we will move the path to the trash first rather than delete them directly.,Patch Available,Unresolved,,jeanlyn,jeanlyn,Tue; 5 Jan 2016 03:22:10 +0000,Tue; 5 Jan 2016 09:25:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6597
MAPREDUCE-6598,Improvement,Minor,mrv2,"LineReader enhencement to support text records contains ""\n""","We have billions of XML message records stored on text files need to be parsed parallel by Spark. By default; Spark open a Hadoop text file using LineReader which provides a single line of text as a record.   The XML messages contains "" n"" and I believe it is a common scenario - many users have cross-line records. Currently; the solution is to the extend the interface RecordReader.  To reduce the repeat work; I wrote a class named MessageRecordReader to extend the interface RecordReader; user can set a string as record delimiter; then MessageRecordReader provides a multiple line record to user.   I would like to contribute the code to community. Please let me know if you are interested in this simple but useful implementation.   Thank you very much and happy new year!",Resolved,Not A Problem,,Unassigned,cloudyarea,Tue; 5 Jan 2016 11:25:19 +0000,Tue; 13 Dec 2016 16:23:24 +0000,Tue; 13 Dec 2016 16:23:24 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6598
YARN-4546,Bug,Critical,resourcemanager,ResourceManager crash due to scheduling opportunity overflow,If a resource request lingers long enough unsatisfied then the scheduling opportunities count for the request can overflow and cause an RM crash.,Closed,Fixed,,Jason Lowe,Jason Lowe,Tue; 5 Jan 2016 21:59:27 +0000,Tue; 30 Aug 2016 01:08:08 +0000,Wed; 6 Jan 2016 14:12:52 +0000,,2.6.1,,,,https://issues.apache.org/jira/browse/YARN-4546
MAPREDUCE-6600,Improvement,Major,test,Split findbugs-exclude.xml into submodules,Now findbugs-exclude.xml is in hadoop-mapreduce-project module but the  source code is in other modules. The mismatch of the modules causes build failure (see YETUS-271); so the findbugs-exclude.xml should be splitted into submodules.,Open,Unresolved,,Akira Ajisaka,Akira Ajisaka,Thu; 7 Jan 2016 05:12:36 +0000,Fri; 10 Jun 2016 09:52:12 +0000,,,,,,YETUS-271,https://issues.apache.org/jira/browse/MAPREDUCE-6600
MAPREDUCE-6601,Bug,Trivial,,Fix typo in Job#setUseNewAPI,"compatability - ""compatibility""",Resolved,Fixed,,Kai Sasaki,Kai Sasaki,Sat; 9 Jan 2016 03:05:32 +0000,Tue; 30 Aug 2016 01:14:45 +0000,Thu; 14 Jan 2016 15:46:09 +0000,,,client;typo,,,https://issues.apache.org/jira/browse/MAPREDUCE-6601
YARN-4575,Bug,Major,,ApplicationResourceUsageReport should return ALL  reserved resource,ApplicationResourceUsageReport reserved resource report  is only of default parition should be of all partitions,Patch Available,Unresolved,,Bibin A Chundatt,Bibin A Chundatt,Mon; 11 Jan 2016 06:12:43 +0000,Thu; 27 Oct 2016 18:37:13 +0000,,,,oct16-easy,,YARN-2695,https://issues.apache.org/jira/browse/YARN-4575
MAPREDUCE-6603,Improvement,Minor,,Add counters for failed task attempts,The counters for failed task attempts are currently unavailable and would be nice to have for troubleshooting whilst not including them in the aggregate counters at task or job level. One should be able to view them at attempt level.,Open,Unresolved,,Kuhu Shukla,Kuhu Shukla,Mon; 11 Jan 2016 14:50:21 +0000,Tue; 23 Feb 2016 15:06:08 +0000,,,2.7.1;2.6.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6603
MAPREDUCE-6604,Improvement,Minor,documentation,Show quoting examples that do not work in streaming docs,"The hadoop streaming docs here should be improved to include examples where ""complicated quoting is can introduce bugs"".  The line including this text should read something like:   The ""-file shellMapper.sh"" part isn't entirely necessary. You can simply use a clause like ""-mapper 'sed | grep | awk'"" or some such but complicated quoting can introduce bugs. As an example; ""-mapper 'grep ""text""'"" will not work. Wrapping the job in a shell script eliminates some of these issues; but quoting should be avoided where possible.",Open,Unresolved,,Unassigned,Dustin Cote,Mon; 11 Jan 2016 16:32:25 +0000,Mon; 11 Jan 2016 16:32:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6604
MAPREDUCE-6605,Bug,Major,documentation,Fix typos mapreduce.map.skip.proc.count.autoincr and mapreduce.reduce.skip.proc.count.autoincr in mapred-default.xml,"As the default configuration file shows; https: mapred-default.xml   we can configure options mapreduce.map.skip.proc.count.autoincr mapreduce.reduce.skip.proc.count.autoincr in the mapred-default.xml. But they do not work because the expected keys in org.apache.hadoop.mapreduce.MRJobConfig.  new DeprecationDelta(""mapred.skip.map.auto.incr.proc.count"";         MRJobConfig.MAP_SKIP_INCR_PROC_COUNT); new DeprecationDelta(""mapred.skip.reduce.auto.incr.proc.count"";         MRJobConfig.REDUCE_SKIP_INCR_PROC_COUNT);  we can change them to mapreduce.map.skip.proc-count.auto-incr and mapreduce.reduce.skip.proc-count.auto-incr in the default configuration file.",Resolved,Fixed,,Kai Sasaki,Dong Zhen,Wed; 13 Jan 2016 14:03:19 +0000,Tue; 30 Aug 2016 01:14:43 +0000,Fri; 22 Jan 2016 09:41:50 +0000,,2.7.1,,,MAPREDUCE-6614,https://issues.apache.org/jira/browse/MAPREDUCE-6605
MAPREDUCE-6606,Bug,Major,,Findbug issue in org.apache.hadoop.mapred.OutputCommitter,https: branch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core-warnings.html#Warnings_BAD_PRACTICE,Resolved,Duplicate,MAPREDUCE-6595,Unassigned,Bibin A Chundatt,Wed; 13 Jan 2016 17:03:20 +0000,Thu; 14 Jan 2016 15:23:10 +0000,Thu; 14 Jan 2016 15:23:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6606
MAPREDUCE-6607,Bug,Minor,applicationmaster,Enable regex pattern matching when mapreduce.task.files.preserve.filepattern is set,"if either of the following configs are set; then .staging dir is not cleaned up:  	mapreduce.task.files.preserve.failedtask 	mapreduce.task.files.preserve.filepattern    The former was supposed to keep only .staging of failed tasks and the latter was supposed to be used only if that task name matches against the specified regular expression.",Resolved,Fixed,,Kai Sasaki,Maysam Yabandeh,Thu; 14 Jan 2016 18:55:04 +0000,Tue; 30 Aug 2016 01:14:41 +0000,Sun; 22 May 2016 22:27:07 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6607
MAPREDUCE-6608,Bug,Major,,Work Preserving AM Restart for MapReduce,Providing a framework for work preserving AM is achieved in YARN-1489.  We would like to take advantage of this for MapReduce(MR) applications.  There are some challenges which have been described in the attached document and few options discussed.  We solicit feedback from the community.,Open,Unresolved,,Srikanth Sampath,Srikanth Sampath,Fri; 24 Jul 2015 13:40:40 +0000,Tue; 7 Jun 2016 15:17:15 +0000,,,,,,YARN-4602;YARN-1489;YARN-4758,https://issues.apache.org/jira/browse/MAPREDUCE-6608
MAPREDUCE-6609,Sub-task,Major,task,NativeTask::MCollectorOutputHandler::handleInput causes misaligned memory access coredumps,NativeTask::MCollectorOutputHandler::handleInput coredumps becasue of misaligned memory accesses. Details below:,Open,Unresolved,,Alan Burlison,Alan Burlison,Mon; 18 Jan 2016 13:26:56 +0000,Mon; 18 Jan 2016 13:26:56 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6609
MAPREDUCE-6610,Bug,Trivial,,JobHistoryEventHandler should not swallow timeline response,As discussed in YARN-4596; JobHistoryEventHandler should process and log timeline put errors after the timeline put call.,Resolved,Fixed,,Li Lu,Li Lu,Tue; 19 Jan 2016 04:47:14 +0000,Tue; 30 Aug 2016 01:14:40 +0000,Tue; 26 Jan 2016 07:02:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6610
MAPREDUCE-6611,Improvement,Major,,Localization timeout diagnostic for taskattempts,When a container takes too long to localize it manifests as a timeout; and there's no indication that localization was the issue. We need diagnostics for timeouts to indicate the container was still localizing when the timeout occurred. Dependent upon YARN-4589,Patch Available,Unresolved,,Chang Li,Chang Li,Tue; 19 Jan 2016 17:52:17 +0000,Wed; 28 Jun 2017 20:46:54 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6611
MAPREDUCE-6612,Bug,Major,mrv2,Compressing map output error,I used gzip compressionor to compress map output;but there is error occurrence.my hadoop version 2.7.1 Configuration conf = getConf(); conf.setBoolean(Job.MAP_OUTPUT_COMPRESS; true); conf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC; GzipCodec.class; CompressionCodec.class);  error info: 2016-01-21 15:02:23 org.apache.hadoop.mapred.LocalJobRunner-INFO reduce  copy 2016-01-21 15:02:23 org.apache.hadoop.mapred.LocalJobRunner-WARN job_local1329832043_0001  85) 2016-01-21 15:02:23 org.apache.hadoop.mapred.LocalJobRunner-INFO reduce  copy 2016-01-21 15:02:23 org.apache.hadoop.mapred.LocalJobRunner-INFO reduce  copy 2016-01-21 15:02:24 org.apache.hadoop.mapred.LocalJobRunner-INFO reduce  copy,Open,Unresolved,,Unassigned,wangjiayou,Thu; 21 Jan 2016 06:59:44 +0000,Mon; 25 Jan 2016 04:18:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6612
MAPREDUCE-6613,New Feature,Minor,,Change mapreduce.jobhistory.jhist.format default from json to binary,"MAPREDUCE-6376 added a configuration setting to set up .jhist internal format:  mapreduce.jobhistory.jhist.format  Currently; the default is ""json"".  Changing the default to ""binary"" allows faster parsing; but with the downside of making the file not output friendly by using ""hadoop fs cat"".",Resolved,Fixed,,Ray Chiang,Ray Chiang,Fri; 22 Jan 2016 00:43:47 +0000,Thu; 12 May 2016 18:22:57 +0000,Sat; 20 Feb 2016 01:16:21 +0000,,2.8.0,,,MAPREDUCE-6376,https://issues.apache.org/jira/browse/MAPREDUCE-6613
MAPREDUCE-6614,Test,Minor,test,Remove unnecessary code in TestMapreduceConfigFields,In branch-2; the following code can be removed because these parameters are in both mapred-default.xml and MRJobConfig. ,Resolved,Fixed,,Kai Sasaki,Akira Ajisaka,Fri; 22 Jan 2016 10:21:14 +0000,Mon; 25 Jan 2016 02:53:59 +0000,Mon; 25 Jan 2016 02:42:53 +0000,,,newbie,,MAPREDUCE-6605,https://issues.apache.org/jira/browse/MAPREDUCE-6614
MAPREDUCE-6615,Improvement,Minor,performance,Remove useless boxing/unboxing code (Hadoop MapReduce),There are lots of places where useless boxing unboxing occur. To avoid performance issue; let's remove them.,Patch Available,Unresolved,,Kousuke Saruta,Kousuke Saruta,Fri; 22 Jan 2016 19:30:49 +0000,Thu; 12 May 2016 18:24:47 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6615
MAPREDUCE-6616,Bug,Major,jobhistoryserver,Fail to create jobhistory file if there are some multibyte characters in the job name,When creating jobhistory file; job name is trimmed within 50 characters by default; and the name is URL-encoded after the job name is trimmed. Therefore; if there are some multibyte characters in the job name; the encoded job name can be longer than 50 characters. Eventually it can break the limit of the file name (Usually 255 characters).,Resolved,Fixed,,Kousuke Saruta,Akira Ajisaka,Mon; 25 Jan 2016 08:21:57 +0000,Tue; 30 Aug 2016 01:14:36 +0000,Fri; 29 Jan 2016 07:21:59 +0000,,,i18n,,,https://issues.apache.org/jira/browse/MAPREDUCE-6616
MAPREDUCE-6617,Bug,Major,mrv2,flushTimer in JobHistoryEventHandler should purge canceled flushTimerTask,In JobHistoryEventHandler; flushTask is not purged after it's canceled so GC never sweep flushTask. It can cause memory leak.,Open,Unresolved,,Kousuke Saruta,Kousuke Saruta,Mon; 25 Jan 2016 17:41:56 +0000,Thu; 12 May 2016 18:22:28 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6617
MAPREDUCE-6618,Bug,Major,,YarnClientProtocolProvider leaking the YarnClient thread. ,YarnClientProtocolProvider creates YarnRunner which includes ResourceMgrDelegate. In ResourceMgrDelegate; we would initiate and start yarnclient. The yarnClient thread would be leaked due to    in YarnClientProtocolProvider,Closed,Fixed,,Xuan Gong,Xuan Gong,Tue; 26 Jan 2016 00:30:15 +0000,Fri; 6 Jan 2017 01:47:49 +0000,Mon; 1 Feb 2016 16:14:23 +0000,,,,,MAPREDUCE-6621;YARN-5309,https://issues.apache.org/jira/browse/MAPREDUCE-6618
MAPREDUCE-6619,Bug,Major,mrv2,HADOOP_CLASSPATH is overwritten in MR container,Previously env variable HADOOP_CLASSPAH in MR containers inherit from defaults of the worker node. MAPREDUCE-6454 introduced change to overwrite HADOOP_CLASSPATH completely. This caused regression. We need to add additional entries to HADOOP_CLASSPATH instead of completely replacing it.,Closed,Fixed,,Junping Du,shanyu zhao,Tue; 26 Jan 2016 05:15:21 +0000,Thu; 25 Aug 2016 22:55:13 +0000,Wed; 27 Jan 2016 21:24:26 +0000,,2.8.0;2.7.2,,,MAPREDUCE-6454,https://issues.apache.org/jira/browse/MAPREDUCE-6619
MAPREDUCE-6620,Bug,Major,jobhistoryserver,Jobs that did not start are shown as starting in 1969 in the JHS web UI,If a job fails; its start time is stored as -1.  The RM UI correctly handles negative start times.  The JHS UI does not; blindly converting it into a date in 1969.,Resolved,Fixed,,Haibo Chen,Daniel Templeton,Thu; 28 Jan 2016 21:24:27 +0000,Fri; 2 Dec 2016 21:09:26 +0000,Tue; 2 Feb 2016 23:23:41 +0000,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6620
MAPREDUCE-6621,Bug,Major,,Memory Leak in JobClient#submitJobInternal(),In JobClient:   We will replace the cluster object with the cluster object from Job; but the previous old cluster object would never be closed.,Closed,Fixed,,Xuan Gong,Xuan Gong,Fri; 29 Jan 2016 01:47:26 +0000,Fri; 6 Jan 2017 01:47:32 +0000,Tue; 2 Feb 2016 19:34:12 +0000,,,,,YARN-5309;MAPREDUCE-6618,https://issues.apache.org/jira/browse/MAPREDUCE-6621
MAPREDUCE-6622,Improvement,Critical,jobhistoryserver,Add capability to set JHS job cache to a task-based limit,When setting the property mapreduce.jobhistory.loadedjobs.cache.size the jobs can be of varying size.  This is generally not a problem when the jobs sizes are uniform or small; but when the job sizes can be very large (say greater than 250k tasks); then the JHS heap size can grow tremendously.  In cases; where multiple jobs are very large; then the JHS can lock up and spend all its time in GC.  However; since the cache is holding on to all the jobs; not much heap space can be freed up.  By setting a property that sets a cap on the number of tasks allowed in the cache and since the total number of tasks loaded is directly proportional to the amount of heap used; this should help prevent the JHS from locking up.,Closed,Fixed,,Ray Chiang,Ray Chiang,Fri; 29 Jan 2016 04:10:36 +0000,Fri; 6 Jan 2017 07:59:29 +0000,Sat; 27 Feb 2016 02:01:39 +0000,,2.7.2,supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6622
MAPREDUCE-6623,Bug,Major,,TestRMNMInfo and TestNetworkedJob fails in trunk,TestRMNMInfo:    TestNetworkedJob    JDK version: JDK v1.8.0_66,Resolved,Duplicate,MAPREDUCE-6579;YARN-4686,Eric Badger,Xuan Gong,Fri; 29 Jan 2016 20:17:36 +0000,Mon; 1 Feb 2016 17:04:10 +0000,Mon; 1 Feb 2016 17:04:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6623
MAPREDUCE-6624,Wish,Minor,examples,Include TeraChecksum in Hadoop mapreduce examples driver,In the mapreduce examples driver; you can run TeraGen; TeraSort; and TeraValidate.  To my surprise; TeraChecksum wasn't included in the examples driver.  I think it'd be nice to include.  It can be used to compare the checksum of the input  output.  It's worth noting that TeraValidate calculates the checksum as well.  Patch to be posted shortly.  I tested against 2.7.1 branch but couldn't against master.  I am including patches for both.  Patch also includes TeraChecksum test case addition.,Patch Available,Unresolved,,Unassigned,Albert Chu,Fri; 29 Jan 2016 22:40:14 +0000,Mon; 1 Feb 2016 20:30:42 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6624
MAPREDUCE-6625,Bug,Major,test,TestCLI#testGetJob fails occasionally,Lately TestCLI has been failing sometimes in precommit builds:,Resolved,Fixed,,Haibo Chen,Jason Lowe,Tue; 2 Feb 2016 19:07:01 +0000,Tue; 30 Aug 2016 01:14:27 +0000,Tue; 12 Jul 2016 22:53:37 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6625
MAPREDUCE-6626,Improvement,Minor,performance,Reuse ObjectMapper instance in MapReduce,Now in MapReduce; there are some places creating a new ObjectMapper instance every time. In wiki of ObjectMapper; it suggested:   http: JacksonFAQ+cd=4hl=jact=clnkgl=jp; it's similar to HDFS-9724.,Resolved,Fixed,,Yiqun Lin,Yiqun Lin,Wed; 3 Feb 2016 06:05:49 +0000,Tue; 30 Aug 2016 01:14:26 +0000,Tue; 9 Feb 2016 18:06:59 +0000,,2.7.1,,,HDFS-9768;YARN-4668,https://issues.apache.org/jira/browse/MAPREDUCE-6626
MAPREDUCE-6627,Improvement,Major,client,Add machine-readable output to mapred job -history command,It would be great if we could add a machine-readable output format; say JSON; to the mapred job -history [all] jobHistoryFile command so that it's easier for programs to consume that information and do further processing on it.  At the same time; we should keep the existing API and formatting intact for backwards compatibility.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Thu; 4 Feb 2016 01:24:42 +0000,Tue; 30 Aug 2016 01:14:25 +0000,Fri; 19 Feb 2016 02:05:25 +0000,,2.9.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6627
MAPREDUCE-6628,Bug,Major,security,Potential memory leak in CryptoOutputStream,There is a potential memory leak in CryptoOutputStream. as well to pass the ownership flag mentioned above.  I can post a patch for either of the above.  I welcome any other ideas from developers to fix this issue.,Resolved,Fixed,,Mariappan Asokan,Mariappan Asokan,Sun; 7 Feb 2016 20:08:09 +0000,Fri; 9 Sep 2016 19:50:17 +0000,Fri; 9 Sep 2016 18:14:04 +0000,,2.6.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6628
YARN-4678,Bug,Major,,Cluster used capacity is > 100 when container reserved ,"Scenario:    	Start cluster with Three NM's each having 8GB (cluster memory:24GB). 	Configure queues with elasticity and userlimitfactor=10. 	disable pre-emption. 	run two job with different priority in different queue at the same time 	 		yarn jar hadoop-mapreduce-examples-2.7.2.jar pi -Dyarn.app.priority=LOW -Dmapreduce.job.queuename=QueueA -Dmapreduce.map.memory.mb=4096 -Dyarn.app.mapreduce.am.resource.mb=1536 -Dmapreduce.job.reduce.slowstart.completedmaps=1.0 10 1000000000000 		yarn jar hadoop-mapreduce-examples-2.7.2.jar pi -Dyarn.app.priority=HIGH -Dmapreduce.job.queuename=QueueB -Dmapreduce.map.memory.mb=4096 -Dyarn.app.mapreduce.am.resource.mb=1536 3 1000000000000 	 	     	observe the cluster capacity which was used in RM web UI",Open,Unresolved,,Sunil G,Brahma Reddy Battula,Mon; 8 Feb 2016 05:02:30 +0000,Sun; 3 Apr 2016 16:18:05 +0000,,,,,,,https://issues.apache.org/jira/browse/YARN-4678
HADOOP-12792,Bug,Minor,security;test,TestUserGroupInformation#testGetServerSideGroups fails in chroot,Bug fixed by HADOOP-7811 broken by HADOOP-8562. Need to re-introduce the fix.,Closed,Fixed,,Eric Badger,Eric Badger,Mon; 8 Feb 2016 17:47:20 +0000,Fri; 6 Jan 2017 07:42:15 +0000,Wed; 10 Feb 2016 22:02:23 +0000,,2.1.0-beta,,,,https://issues.apache.org/jira/browse/HADOOP-12792
MAPREDUCE-6631,Improvement,Major,nodemanager,shuffle handler would benefit from per-local-dir threads,Jason Lowe and I discussed this while investigating I O starvation we have been seeing on our clusters lately (possibly amplified by increased tez workloads).   If a particular disk is being slow; it is very likely that all shuffle netty threads will be blocked on the read side of sendfile(). (sendfile() is asynchronous on the outbound socket side; but not on the read side.) This causes the entire shuffle subsystem to slow down.   It seems like we could make the netty threads more asynchronous by introducing a small set of threads per local-dir that are responsible for the actual sendfile() invocations.  This would not only improve shuffles that span drives; but also improve situations where there is a single large shuffle from a single local-dir. It would allow other drives to continue serving shuffle requests; AND avoid a large number of readers (2X number_of_cores by default) all fighting for the same drive; which becomes unfair to everything else on the system.,Open,Unresolved,,Unassigned,Nathan Roberts,Mon; 8 Feb 2016 18:38:24 +0000,Fri; 20 Oct 2017 21:30:19 +0000,,,2.7.2;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6631
MAPREDUCE-6632,Improvement,Minor,applicationmaster,Master.getMasterAddress() should be updated to use YARN-4629,The new YarnClientUtil.getRmPrincipal() method can replace most of the Master.getMasterAddress() method and should to reduce redundancy and improve servicability.,Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Wed; 10 Feb 2016 19:32:25 +0000,Fri; 23 Sep 2016 00:10:58 +0000,Thu; 22 Sep 2016 23:38:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6632
MAPREDUCE-6633,Bug,Major,,AM should retry map attempts if the reduce task encounters commpression related errors.,When reduce task encounters compression related errors; AM  doesn't retry the corresponding map task. In one of the case we encountered; here is the stack trace.   In this case; the node on which the map task ran had a bad drive. If the AM had retried running that map task somewhere else; the job definitely would have succeeded.,Closed,Fixed,,Rushabh S Shah,Rushabh S Shah,Wed; 10 Feb 2016 21:12:09 +0000,Fri; 10 Nov 2017 21:23:58 +0000,Sat; 9 Apr 2016 19:21:27 +0000,,2.7.2,,,TEZ-3833,https://issues.apache.org/jira/browse/MAPREDUCE-6633
MAPREDUCE-6634,Improvement,Major,,Log uncaught exceptions/errors in various thread pools in mapreduce,For a detailed description; please see HADOOP-12748,Resolved,Fixed,,Sidharta Seethana,Sidharta Seethana,Fri; 12 Feb 2016 19:37:44 +0000,Thu; 19 Oct 2017 14:20:39 +0000,Thu; 18 Feb 2016 08:51:09 +0000,,,,HADOOP-12749,,https://issues.apache.org/jira/browse/MAPREDUCE-6634
MAPREDUCE-6635,Bug,Critical,,Unsafe long to int conversion in UncompressedSplitLineReader and IndexOutOfBoundsException,LineRecordReader creates the unsplittable reader like so:   Split length goes to   At some point when reading the first line; fillBuffer does this:   which will be a negative number for large splits; and the subsequent dfs read will fail with a boundary check.   This has been reported here: https: SDC-2229; also happens in Hive if very large text files are forced to be read in a single split (e.g. via header-skipping feature; or via set mapred.min.split.size=9999999999999999),Closed,Fixed,,Junping Du,Sergey Shelukhin,Wed; 17 Feb 2016 00:44:49 +0000,Tue; 30 Aug 2016 01:14:20 +0000,Tue; 23 Feb 2016 09:18:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6635
MAPREDUCE-6636,Improvement,Major,client,Clean up argument parsing in mapred CLI,org.apache.hadoop.mapreduce.tools.CLI manually parses arguments; which has a number of downsides including (a) requiring strict ordering of arguments by the user and (b) it's hard for devs to add new arguments.  We should replace all of this with a CLI parsing library like org.apache.commons.cli.CommandLineParser; which is used in a number of other places already.,Open,Unresolved,,Unassigned,Robert Kanter,Thu; 18 Feb 2016 01:02:26 +0000,Thu; 31 Aug 2017 15:51:45 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6636
MAPREDUCE-6637,Bug,Major,test,Testcase Failure : TestFileInputFormat.testSplitLocationInfo,Following testcase is failing after HADOOP-12810,Closed,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Fri; 19 Feb 2016 09:38:03 +0000,Fri; 6 Jan 2017 01:46:51 +0000,Sat; 20 Feb 2016 00:38:14 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6637
MAPREDUCE-6638,Improvement,Major,applicationmaster,Do not attempt to recover progress from previous job attempts if spill encryption is enabled,"Post the fix to CVE-2015-1776; jobs with ecrypted spills enabled cannot be recovered if the AM fails. We should store the key some place safe so they can actually be recovered. If there is no ""safe"" place; at least we should restart the job by re-running all mappers reducers.",Resolved,Fixed,MAPREDUCE-6669,Haibo Chen,Karthik Kambatla,Fri; 19 Feb 2016 16:28:02 +0000,Mon; 3 Oct 2016 17:42:04 +0000,Mon; 3 Oct 2016 17:35:02 +0000,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6638
MAPREDUCE-6639,Bug,Major,mrv2,Process hangs in LocatedFileStatusFetcher if FileSystem.get throws,ListLocatedFileStatusFetcher uses a thread pool; but one of the Callable thread functions; ProcessInitialInputPathCallable; doesn't catch exceptions (the callbacks do). When an exception is thrown; the thread exists and doesn't signal the error to the calling thread; which continues waiting to be signaled. This can happen when a FS implementation cannot be found.,Resolved,Fixed,,Ryan Blue,Ryan Blue,Fri; 19 Feb 2016 17:29:23 +0000,Tue; 30 Aug 2016 01:14:16 +0000,Thu; 12 May 2016 18:02:28 +0000,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6639
MAPREDUCE-6640,Improvement,Major,client,mapred job -history command should be able to take Job ID,The mapred job -history command currently accepts only a jobHistoryFile.  It would be much easier for the user if it could also accept a Job ID so the user doesn't have to go and find the jhist file.  It would also be more consistent with the other commands; which generally take a Job ID.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Fri; 19 Feb 2016 21:59:46 +0000,Tue; 30 Aug 2016 01:14:14 +0000,Wed; 24 Feb 2016 01:43:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6640
MAPREDUCE-6641,Bug,Major,test,TestTaskAttempt fails in trunk,nan,Resolved,Fixed,,Haibo Chen,Tsuyoshi Ozawa,Sun; 21 Feb 2016 01:32:10 +0000,Tue; 29 Aug 2017 18:02:54 +0000,Tue; 29 Aug 2017 18:02:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6641
MAPREDUCE-6642,Improvement,Minor,test,Move the constructor to a method in HadoopTestCase,After migrating to JUnit4;     the above constructor can be changed to a configure method and call it from @BeforeClass method of the subclasses. That way we can make the test more simple.,Open,Unresolved,,Dustin Cote,Akira Ajisaka,Mon; 22 Feb 2016 07:08:45 +0000,Thu; 25 Feb 2016 21:08:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6642
HADOOP-13270,Bug,Critical,,BZip2CompressionInputStream finds the same compression marker twice in corner case; causing duplicate data blocks,Unit test TestTextInputFormat.testSplitableCodecs() failed when the seed is  1313094493.  Stacktrace  223),Closed,Fixed,,Kai Sasaki,Haibo Chen,Wed; 24 Feb 2016 01:41:50 +0000,Wed; 4 Oct 2017 20:26:25 +0000,Tue; 14 Jun 2016 01:29:47 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/HADOOP-13270
MAPREDUCE-6644,Improvement,Major,documentation,Use doxia macro to generate in-page TOC of MapReduce site documentation,Since maven-site-plugin 3.5 was released; we can use toc macro in Markdown.,Resolved,Fixed,,Masatake Iwasaki,Masatake Iwasaki,Wed; 2 Mar 2016 05:11:09 +0000,Wed; 1 Feb 2017 16:53:31 +0000,Wed; 1 Feb 2017 16:28:17 +0000,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6644
MAPREDUCE-6645,Bug,Major,test,TestWordStats outputs logs under directories other than target/test-dir,nan,Closed,Fixed,,Gabor Liptak,Akira Ajisaka,Wed; 2 Mar 2016 06:50:56 +0000,Tue; 30 Aug 2016 01:14:12 +0000,Thu; 17 Mar 2016 09:14:58 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6645
HADOOP-13110,Sub-task,Major,,add a streaming subcommand to mapred,Is there any reason why there shouldn't be a 'mapred streaming' command?,Resolved,Fixed,,Allen Wittenauer,Allen Wittenauer,Wed; 2 Mar 2016 19:46:25 +0000,Tue; 17 May 2016 00:58:07 +0000,Fri; 6 May 2016 21:02:27 +0000,,3.0.0-alpha1,,,HADOOP-12857,https://issues.apache.org/jira/browse/HADOOP-13110
MAPREDUCE-6647,Bug,Major,,MR usage counters use the resources requested instead of the resources allocated,As can be seen in the following snippet; the MR counters for usage use the resources requested instead of the resources allocated. The scheduler increment-allocation-mb configs could lead to these values not being the same. We could change the counters to use the allocated resources in order to account for this.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Wed; 2 Mar 2016 23:11:06 +0000,Thu; 29 Jun 2017 19:59:56 +0000,Thu; 7 Apr 2016 00:16:46 +0000,,,,,MAPREDUCE-6677,https://issues.apache.org/jira/browse/MAPREDUCE-6647
MAPREDUCE-6648,Improvement,Trivial,documentation,Add yarn.app.mapreduce.am.log.level to mapred-default.xml,nan,Resolved,Fixed,MAPREDUCE-6949,Harsh J,Harsh J,Sat; 5 Mar 2016 08:49:24 +0000,Wed; 30 Aug 2017 20:21:11 +0000,Mon; 7 Mar 2016 07:46:50 +0000,,2.9.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6648
MAPREDUCE-6649,Bug,Major,,getFailureInfo not returning any failure info,The following command does not produce any failure info as to why the job failed.         To contrast; here is a command and associated command line output to show a failed job that gives the correct failiure info.,Resolved,Fixed,,Eric Badger,Eric Badger,Mon; 7 Mar 2016 16:37:13 +0000,Tue; 30 Aug 2016 01:14:07 +0000,Mon; 18 Apr 2016 13:18:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6649
MAPREDUCE-6650,Improvement,Major,,Surface error histograms from the AM,Job tasks are constantly probing the cluster. So if there are some issues in the cluster then jobs would be the first to notice that. If we can make these observations surface to the user then we could quickly identify cluster issues.  Lets say a set of bad machines got added to the cluster and tasks started seeing shuffle errors from those machines. This can slow down or hang the job. If the AM can surface increased errors counts from source and destination machines then that could pin point the bad machines vs having to arrive at those machines from first principles and log searching.,Open,Unresolved,,Unassigned,Bikas Saha,Mon; 14 Mar 2016 19:31:06 +0000,Mon; 14 Mar 2016 19:31:06 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6650
MAPREDUCE-6651,Sub-task,Major,client,MCollectorOutputHandler.cc makes misaligned accesses; coredumps ensue,MCollectorOutputHandler.cc casts a misaligned byte pointer to a KVBufferWithParititionId; which causes coredumps on any platform with alignment constraints; such as SPARC. The misaligned structure needs to be copied into a local; aligned structure and the data referenced from there.,Patch Available,Unresolved,,Alan Burlison,Alan Burlison,Tue; 15 Mar 2016 14:22:14 +0000,Wed; 16 Mar 2016 13:15:13 +0000,,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6651
MAPREDUCE-6652,Improvement,Major,jobhistoryserver,Add configuration property to prevent JHS from loading jobs with a task count greater than X,Jobs with large number of tasks can have job history files that are large in size and resource-consuming(mainly memory) to parse in Job History Server. If there are many such jobs; the job history server can very easily hang.  It would be a good usability feature if we added a new config property that could be set to X; where the JHS wouldn't load the details for a job with more than X tasks. The job would still show up on the list of jobs page; but clicking on it would give a warning message that the job is too big; instead of actually loading the job. This way we can prevent users from loading a job that's way too big for the JHS; which currently makes the JHS hang. The default value can be -1 so that it's disabled.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Wed; 16 Mar 2016 16:51:08 +0000,Tue; 30 Aug 2016 01:14:05 +0000,Fri; 15 Jul 2016 20:38:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6652
MAPREDUCE-6653,New Feature,Major,applicationmaster;client,JobSubmitter with unmanaged MRApplicationMaster  ,Long living DAG applications (pig; hive; etc) may launch many mapreduce jobs. Since we already have to allocate resources for these clients; we could reduce the latency of monitoring AM's; the overall number of network RPC's; the number of containers running on YARN cluster by embedding the MRAppMaster with the submitter.,Open,Unresolved,,Unassigned,Gera Shegalov,Fri; 18 Mar 2016 06:10:38 +0000,Fri; 18 Mar 2016 20:07:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6653
MAPREDUCE-6654,Bug,Critical,,Possible NPE in JobHistoryEventHandler#handleEvent,I have seen NPE thrown from JobHistoryEventHandler#handleEvent:   In the version this exception is thrown; the line is:    IMHO; this may be caused by an exception in a previous step. Specifically; in the kerberized environment; when creating event writer which calls to decrypt EEK; the connection to KMS failed. Exception below:    We should better handle this scenario and not throw an NPE.,Patch Available,Unresolved,,Junping Du,Xiao Chen,Fri; 18 Mar 2016 07:18:38 +0000,Mon; 9 Oct 2017 21:17:22 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6654
MAPREDUCE-6655,Bug,Trivial,documentation,Fix a typo (STRICT_IE6) in Encrypted Shuffle,Found a typo in Encrypted Shuffle documentation (STRICT_I6 -- STRICT_IE6). The typo also appears in core-default.xml,Resolved,Fixed,,Wei-Chiu Chuang,Wei-Chiu Chuang,Fri; 18 Mar 2016 17:29:46 +0000,Tue; 30 Aug 2016 01:14:03 +0000,Mon; 28 Mar 2016 12:32:43 +0000,,2.7.2,typo,,,https://issues.apache.org/jira/browse/MAPREDUCE-6655
MAPREDUCE-6656,Bug,Blocker,,[NNBench] OP_DELETE operation isn't working after MAPREDUCE-6363,After the fix of MAPREDUCE-6363; in NNBench OP_DELETE Operation isn't working.,Closed,Fixed,,J.Andreina,J.Andreina,Tue; 22 Mar 2016 11:00:43 +0000,Tue; 30 Aug 2016 01:14:01 +0000,Wed; 23 Mar 2016 14:30:39 +0000,,2.6.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6656
MAPREDUCE-6657,Bug,Major,jobhistoryserver,job history server can fail on startup when NameNode is in start phase,"Job history server will try to create a history directory in HDFS on startup. When NameNode is in safe mode; it will keep retrying for a configurable time period.  However; it should also keeps retrying if the name node is in start state. Safe mode does not happen until the NN is out of the startup phase.   A RetriableException with the text ""NameNode still not started"" is thrown when the NN is in its internal service startup phase. We should add the check for this specific exception in isBecauseSafeMode() to account for that.",Resolved,Fixed,,Haibo Chen,Haibo Chen,Tue; 22 Mar 2016 20:58:27 +0000,Tue; 30 Aug 2016 01:13:58 +0000,Tue; 17 May 2016 21:53:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6657
YARN-4938,Bug,Major,test,MiniYarnCluster should not request transitionToActive to RM on non-HA environment,TestMRJobs#testJobWithChangePriority fails.,Closed,Fixed,,Eric Badger,Akira Ajisaka,Wed; 23 Mar 2016 06:33:57 +0000,Tue; 30 Aug 2016 01:03:15 +0000,Sun; 10 Apr 2016 16:38:08 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-4938
MAPREDUCE-6659,Bug,Major,mr-am,Mapreduce App master waits long to kill containers on lost nodes.,MR Application master waits for very long time to cleanup and relaunch the tasks on lost nodes. Wait time is actually 2.5 hours (ipc.client.connect.max.retries * ipc.client.connect.max.retries.on.timeouts * ipc.client.connect.timeout = 10 * 45 * 20 = 9000 seconds = 2.5 hours)  Some similar issue related in RM-AM rpc protocol is fixed in YARN-3809. As fixed in YARN-3809; we may need to introduce new configurations to control this RPC retry behavior.  Also; I feel this total retry time should honor and capped maximum to global task time out (mapreduce.task.timeout = 600000 default),Open,Unresolved,MAPREDUCE-6982,Nicolas Fraison,Laxman,Thu; 24 Mar 2016 12:01:08 +0000,Wed; 8 Nov 2017 15:05:21 +0000,,,2.6.0,,,YARN-3809,https://issues.apache.org/jira/browse/MAPREDUCE-6659
MAPREDUCE-6660,New Feature,Major,,Add MR Counters for bytes-read-by-network-distance FileSystem metrics,This is the MR part of the change which is to consume bytes-read-by-network-distance metrics generated by https: HDFS-9579.,Patch Available,Unresolved,,Ming Ma,Ming Ma,Thu; 24 Mar 2016 15:57:11 +0000,Sat; 16 Apr 2016 03:34:14 +0000,,,,,,HADOOP-13031;HDFS-9579,https://issues.apache.org/jira/browse/MAPREDUCE-6660
MAPREDUCE-6661,Bug,Critical,,hostLocalAssigned remains zero after scheduling ,In the AM log file I see that the hostLocalAssigned in org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator remains zero even after scheduling; but the rackLocalAssigned gets updated (I run it in one rack),Open,Unresolved,,Unassigned,Sultan Alamro,Thu; 24 Mar 2016 16:54:35 +0000,Thu; 21 Jul 2016 04:29:35 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6661
MAPREDUCE-6662,Bug,Minor,,Clear ASF Warnings on test data files,In all MAPREDUCE QA runs; '14 ASF Warnings' will mark the entire QA result as '-1 Overall'. These warnings are from the files generated in tests.  It will be good to see green +1s in QA report than RED -1(s).,Resolved,Fixed,,Vinayakumar B,Vinayakumar B,Fri; 25 Mar 2016 02:08:31 +0000,Thu; 5 Jan 2017 09:54:57 +0000,Tue; 29 Mar 2016 02:38:34 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6662
MAPREDUCE-6663,Improvement,Major,,[NNBench] Refactor nnbench as a Tool implementation.,Refactor NNBench as a tool to accept generic command line option; and add a regression test.,Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Wed; 21 Jan 2015 08:10:39 +0000,Tue; 30 Aug 2016 01:13:55 +0000,Wed; 30 Mar 2016 05:04:40 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6663
MAPREDUCE-6664,Bug,Major,,Default value and the  explanation in javadoc is misleading for JobConf#getNumMapTasks,1.  As per mapred-default.xml ; default value for number of map task per job is 2; but in JobConf#getNumMapTasks() it is 1    2. Javadoc for getNumMapTasks() is misleading; as it explains about number of reduce task,Patch Available,Unresolved,,J.Andreina,J.Andreina,Tue; 29 Mar 2016 04:19:20 +0000,Tue; 29 Mar 2016 08:38:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6664
MAPREDUCE-6665,Bug,Minor,,Failed/Running/Killed tasks view not working on running jobs (webui),When a job is running clicking any of the links within the box marked below:   Results in an empty view like the following:,Open,Unresolved,,Unassigned,Johan Gustavsson,Tue; 29 Mar 2016 02:02:39 +0000,Wed; 30 Mar 2016 02:12:17 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6665
MAPREDUCE-6666,Improvement,Major,,Support MultiThreads in a Map and Distribution of files in NNBench,Support Distribution of files to multiple directories generated by NNBench.,Patch Available,Unresolved,,Brahma Reddy Battula,Brahma Reddy Battula,Tue; 29 Mar 2016 06:27:35 +0000,Fri; 10 Jun 2016 04:17:59 +0000,,,,,,MAPREDUCE-6466,https://issues.apache.org/jira/browse/MAPREDUCE-6666
MAPREDUCE-6667,Sub-task,Minor,test,Migrate MR test cases part 3,Migrate the following to JUnit4  .  public class TestSizedWritable extends TestCase {,Resolved,Duplicate,HADOOP-14729,Unassigned,Dustin Cote,Wed; 30 Mar 2016 15:15:42 +0000,Sat; 14 Oct 2017 08:22:34 +0000,Sat; 14 Oct 2017 08:22:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6667
MAPREDUCE-6668,Improvement,Minor,mr-am,AM of no uber job does not need local resources.,if specify -libjar -files -archive on command line or set below properties     MapReduce framework will configure  LocalResources for map reduce container.,Patch Available,Unresolved,,KWON BYUNGCHANG,KWON BYUNGCHANG,Mon; 4 Apr 2016 07:56:35 +0000,Thu; 28 Apr 2016 13:39:43 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6668
MAPREDUCE-6669,Bug,Critical,mr-am,Jobs with encrypted spills don't tolerate AM failures,The key used for encrypting intermediate data is not persisted anywhere; and hence can't be recovered the same way other MR jobs can be. We should support recovering these jobs as well; hopefully without having to re-run completed tasks.,Resolved,Duplicate,MAPREDUCE-6638,Haibo Chen,Karthik Kambatla,Tue; 5 Apr 2016 06:08:38 +0000,Thu; 21 Jul 2016 17:42:14 +0000,Thu; 21 Jul 2016 17:42:14 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6669
MAPREDUCE-6670,Bug,Minor,test,TestJobListCache#testEviction sometimes fails on Windows with timeout,TestJobListCache#testEviction often needs more than 1000 ms to finish in Windows environment. Increasing the timeout solves the issue.,Closed,Fixed,,Gergely Nov  k,Gergely Nov  k,Tue; 5 Apr 2016 14:59:37 +0000,Fri; 6 Jan 2017 08:42:27 +0000,Wed; 6 Apr 2016 15:38:47 +0000,,2.7.0;2.8.0;2.7.1;2.7.2;2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6670
MAPREDUCE-6671,Improvement,Major,,Incorrect error message while setting dfs.block.size to wrong value,Execute in Hive     See logs     We need to have more informative error message here,Patch Available,Unresolved,,Oleksiy Sayankin,Oleksiy Sayankin,Fri; 8 Apr 2016 15:57:22 +0000,Fri; 8 Apr 2016 16:18:48 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6671
MAPREDUCE-6672,Bug,Minor,test,TestTeraSort fails on Windows,"TestTeraSort testcase fails on Windows.  The test case uses the build directory as test working directory. Under Windows the build directory starts with a drive definition ( ""C:"" ); which is interpreted as (an invalid) URI scheme.   The fix is trivial: Add URI scheme to the beginning of the working directory.  Error message:",Resolved,Fixed,,Tibor Kiss,Tibor Kiss,Sun; 10 Apr 2016 09:24:14 +0000,Tue; 30 Aug 2016 01:13:53 +0000,Fri; 29 Apr 2016 18:40:27 +0000,,2.8.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6672
MAPREDUCE-6673,Improvement,Major,test,Add a test example job that grows in memory usage over time,While working on YARN-1011; I needed to put together an example that would have tasks increase their resource usage deterministically over time. It would be useful for any other utilization related work or stress tests.,Resolved,Fixed,,Karthik Kambatla,Karthik Kambatla,Tue; 12 Apr 2016 01:13:09 +0000,Mon; 17 Apr 2017 16:42:40 +0000,Sat; 15 Apr 2017 00:44:54 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6673
MAPREDUCE-6674,Test,Critical,test,configure parallel tests for mapreduce-client-jobclient,mapreduce-client-jobclient takes almost an hour and a half.  Configuring parallel-tests would greatly reduce this run time.,Patch Available,Unresolved,,Unassigned,Allen Wittenauer,Tue; 12 Apr 2016 18:23:11 +0000,Fri; 27 Oct 2017 00:57:49 +0000,,,3.0.0-alpha1,,,HADOOP-14724;MAPREDUCE-6521;MAPREDUCE-6758;MAPREDUCE-4980,https://issues.apache.org/jira/browse/MAPREDUCE-6674
MAPREDUCE-6675,Bug,Major,mrv2,TestJobImpl.testUnusableNode failed ,TestJobImpl#testUnusableNodeTransition is flaky.  2016-02-13 09:16:42 Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl 2016-02-13 09:16:50 Tests run: 17; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 8.324 sec &lt; FAILURE! - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl 2016-02-13 09:16:50 testUnusableNodeTransition(org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl)  Time elapsed: 5.165 sec  &lt; FAILURE! 2016-02-13 09:16:50  lang.AssertionError: expected:SUCCEEDED but was:ERROR 2016-02-13 09:16:50  tempts and  transition to Committing state before the taskAttemptKill event is handled by the dispatcher. Committing jobs will reject later JobTaskEvents received; transition to InternalError state and cause the test to fail.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Thu; 14 Apr 2016 23:30:34 +0000,Thu; 5 Jan 2017 01:10:44 +0000,Thu; 5 May 2016 05:44:13 +0000,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6675
MAPREDUCE-6676,Bug,Major,,NNBench should Throw IOException when rename and delete fails,Throw IOException when rename;delete fails; currently it's unknown to user when rename and delte fails..,Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Fri; 15 Apr 2016 07:09:09 +0000,Wed; 7 Jun 2017 17:14:29 +0000,Wed; 7 Jun 2017 16:41:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6676
MAPREDUCE-6677,Bug,Major,mr-am,LocalContainerAllocator doesn't specify resource of the containers allocated.,nan,Resolved,Fixed,,Haibo Chen,Haibo Chen,Fri; 15 Apr 2016 16:18:59 +0000,Tue; 30 Aug 2016 01:13:49 +0000,Thu; 5 May 2016 05:40:02 +0000,,,,,MAPREDUCE-6647;MAPREDUCE-6681,https://issues.apache.org/jira/browse/MAPREDUCE-6677
MAPREDUCE-6678,Improvement,Major,nodemanager,Allow ShuffleHandler readahead without drop-behind,Currently mapreduce.shuffle.manage.os.cache enables disables readahead based on mapreduce.shuffle.readahead.bytes==0; leaving mapreduce.shuffle.manage.os.cache controlling only the drop-behind.,Resolved,Fixed,,Nathan Roberts,Nathan Roberts,Fri; 15 Apr 2016 18:15:42 +0000,Tue; 30 Aug 2016 01:13:47 +0000,Tue; 10 May 2016 16:10:11 +0000,,2.7.2;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6678
MAPREDUCE-6679,Improvement,Minor,mrv2,on node failure; only restart mappers whose output is not copied,When we detect a bad node; we reschedule all succeeded map tasks on th offer spot preemptible instances. As long as reducers are running to continually fetch mapper outputs; the job can make progress as long as the preemptible instances stay up long enough for a map task to complete.,Open,Unresolved,,Unassigned,Alvin Chyan,Fri; 15 Apr 2016 19:38:32 +0000,Thu; 21 Jul 2016 08:04:00 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6679
MAPREDUCE-6680,Bug,Major,jobhistoryserver,JHS UserLogDir scan algorithm sometime could skip directory with update in CloudFS (Azure FileSystem; S3; etc.),"In our cluster based on a Cloud FileSystem; we notice JHS sometimes could skip directory with .jhist file in scanning. The behavior is like: First round scan; doesn't found .jhist file:    Then; we see ""Scan not needed of ..."" for the same directory every 3 minutes until application failed as timeout.  From our analysis; we found the root cause is: most of Cloud File System (Azure FS; S3; etc.) is truncating file thread.jspa?messageID=476615).   So if the time sequence is happen to be: latest non .jhist file modification on directory happens at T1; directory scanning happens at T2; .jhist file added to directory at T3. If we have T1 T2  T3 and T1 is equal to T3 after truncating to seconds; this issue could appear.",Closed,Fixed,,Junping Du,Junping Du,Mon; 18 Apr 2016 14:05:46 +0000,Tue; 30 Aug 2016 01:13:45 +0000,Thu; 21 Apr 2016 02:04:52 +0000,,,Azure;S3,,,https://issues.apache.org/jira/browse/MAPREDUCE-6680
MAPREDUCE-6681,Bug,Major,test,TestUberAM  fails intermittently ,PreCommit Build   https: ,Resolved,Fixed,,Haibo Chen,Brahma Reddy Battula,Tue; 19 Apr 2016 01:22:59 +0000,Thu; 5 May 2016 19:30:05 +0000,Thu; 5 May 2016 19:30:05 +0000,,,,,MAPREDUCE-6677,https://issues.apache.org/jira/browse/MAPREDUCE-6681
MAPREDUCE-6682,Bug,Major,test,TestMRCJCFileOutputCommitter fails intermittently,PreCommit Report  https: ,Resolved,Fixed,,Akira Ajisaka,Brahma Reddy Battula,Tue; 19 Apr 2016 01:24:47 +0000,Fri; 6 Jan 2017 18:56:55 +0000,Thu; 4 Aug 2016 06:00:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6682
MAPREDUCE-6683,Bug,Minor,mrv2,Execute hadoop 1.0.1 application in hadoop 2.6.0 cause Output directory not set execption,The application can run normally in Hadoop 1.0.1 but can't run in 2.6.0 even though adapt to use new mapreduce API.   org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.    745),Resolved,Invalid,,Unassigned,Han Gao,Tue; 19 Apr 2016 23:24:59 +0000,Wed; 20 Apr 2016 18:58:33 +0000,Wed; 20 Apr 2016 18:57:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6683
MAPREDUCE-6684,Bug,Critical,jobhistoryserver,High contention on scanning of user directory under immediate_done in Job History Server,HistoryFileManager.scanIntermediateDirectory() in JHS acquires a lock on each user directory it tries to scan (move or delete files under the user directory as necessary). This method is called in a thread in JobHistory that performs periodical scanning of intermediate directory; and can also be called by web server threads for each Web API call made by a JHS client. In cases where there are many concurrent Web API calls connections to JHS; all but one thread are blocked on the lock on the user directory. Eventually; client connects will time out; but the threads in JHS will not be killed and leave a lot of TCP connections in CLOSE_WAIT state.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Wed; 20 Apr 2016 21:25:31 +0000,Wed; 19 Oct 2016 11:50:31 +0000,Tue; 10 May 2016 16:17:53 +0000,,2.7.0,,,MAPREDUCE-6573;MAPREDUCE-6436;MAPREDUCE-6797;MAPREDUCE-6698,https://issues.apache.org/jira/browse/MAPREDUCE-6684
MAPREDUCE-6685,Bug,Major,,LocalDistributedCacheManager can have overlapping filenames,LocalDistributedCacheManager has this setup:  AtomicLong uniqueNumberGenerator = new AtomicLong(System.currentTimeMillis());  to create this temporary filename:  new FSDownload(localFSFileContext; ugi; conf; new Path(destPath;  Long.toString(uniqueNumberGenerator.incrementAndGet())); resource);  when using LocalJobRunner.  When two or more start on the same machine; then it's possible to end up having the same timestamp or a large enough overlap that two successive timestamps may not be sufficiently far apart.  Given the assumptions:  1) Assume timestamp is the same. Then the most common starting random seed will be the same. 2) Process ID will very likely be unique; but will likely be close in value. 3) Thread ID is not guaranteed to be unique.  A unique ID based on PID as a seed (in addition to the timestamp) should be a better unique identifier for temporary filenames.,Resolved,Duplicate,MAPREDUCE-6441,Ray Chiang,Ray Chiang,Tue; 26 Apr 2016 18:46:41 +0000,Wed; 24 Aug 2016 16:04:40 +0000,Wed; 1 Jun 2016 05:34:32 +0000,,3.0.0-alpha1,,,MAPREDUCE-6766,https://issues.apache.org/jira/browse/MAPREDUCE-6685
MAPREDUCE-6686,Improvement,Major,client,Add a way to download the job config from the mapred CLI,It would be convenient if there was a way to easily grab the job configuration via the CLI instead of having to find and go to the specific HDFS location to grab it.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Tue; 26 Apr 2016 19:55:18 +0000,Tue; 30 Aug 2016 01:13:41 +0000,Wed; 18 May 2016 19:21:17 +0000,,2.9.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6686
MAPREDUCE-6687,New Feature,Minor,applicationmaster,Allow specifing java home via job configuration,Suggest allowing user to use a preferred JVM implementation (or version) by specifying  home via JobConf; to launch Map B tests on real workload or benchmark between JVM implementations.,Resolved,Implemented,,Unassigned,He Tianyi,Wed; 27 Apr 2016 05:03:08 +0000,Thu; 21 Jul 2016 01:36:51 +0000,Thu; 21 Jul 2016 01:36:50 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6687
MAPREDUCE-6688,Sub-task,Major,applicationmaster,Store job configurations in Timeline Service v2,We already have configuration field in HBase schema for application entity. We need to make sure AM write it out when it get launched.,Resolved,Fixed,,Varun Saxena,Junping Du,Wed; 22 Jul 2015 21:06:27 +0000,Sat; 21 Oct 2017 06:30:22 +0000,Tue; 3 May 2016 16:21:08 +0000,,YARN-2928,yarn-2928-1st-milestone,,YARN-3401,https://issues.apache.org/jira/browse/MAPREDUCE-6688
MAPREDUCE-6689,Bug,Blocker,,MapReduce job can infinitely increase number of reducer resource requests,"We have seen this issue from one of our clusters: when running terasort map-reduce job; some mappers failed after reducer started; and then MR AM tries to preempt reducers to schedule these failed mappers.  After that; MR AM enters an infinite loop; for every RMContainerAllocator#heartbeat run; it:   	In preemptReducesIfNeeded; it cancels all scheduled reducer requests. (total scheduled reducers = 1024) 	Then; in scheduleReduces; it ramps up all reducers (total = 1024).    As a result; we can see total #requested-containers increased 1024 for every MRAM-RM heartbeat (1 sec per heartbeat). The AM is hanging for 18+ hours; so we get 18 * 3600 * 1024 ~ 66M+ requested containers in RM side.  And this bug also triggered YARN-4844; which makes RM stop scheduling anything.  Thanks to Sidharta Seethana for helping with analysis.",Closed,Fixed,,Wangda Tan,Wangda Tan,Thu; 5 May 2016 00:38:25 +0000,Tue; 30 Aug 2016 01:13:39 +0000,Fri; 6 May 2016 22:41:05 +0000,,,,,YARN-4844,https://issues.apache.org/jira/browse/MAPREDUCE-6689
MAPREDUCE-6690,New Feature,Major,,Limit the number of resources a single map reduce job can submit for localization,"Users will sometimes submit a large amount of resources to be localized as part of a single map reduce job. This can cause issues with YARN localization that destabilize the cluster and potentially impact other user jobs. These resources are specified via the files; libjars; archives and jobjar command line arguments or directly through the configuration (i.e. distributed cache api). The resources specified could be too large in multiple dimensions:  	Total size 	Number of files 	Size of an individual resource (i.e. a large fat jar)    We would like to encourage good behavior on the client side by having the option of enforcing resource limits along the above dimensions.  There should be a separate effort to enforce limits at the YARN layer on the server side; but this jira is only covering the map reduce layer on the client side. In practice; having these client side limits will get us a long way towards preventing these localization anti-patterns.",Resolved,Fixed,,Chris Trezzo,Chris Trezzo,Fri; 6 May 2016 20:14:28 +0000,Thu; 9 Mar 2017 23:30:06 +0000,Wed; 17 Aug 2016 16:25:56 +0000,,,,,YARN-5192,https://issues.apache.org/jira/browse/MAPREDUCE-6690
MAPREDUCE-6691,Test,Major,scripts;test,move the shell code out of hadoop-mapreduce-project,We need to move the shell code out of hadoop-mapreduce-project so that we can properly build test code.,Open,Unresolved,,Unassigned,Allen Wittenauer,Mon; 9 May 2016 20:20:26 +0000,Mon; 9 May 2016 20:20:46 +0000,,,,,MAPREDUCE-6699,,https://issues.apache.org/jira/browse/MAPREDUCE-6691
YARN-5068,Improvement,Major,,Expose scheduler queue to application master,The AM needs to know the queue name in which it was launched.,Resolved,Duplicate,YARN-1623,Harish Jaiprakash,Harish Jaiprakash,Tue; 10 May 2016 06:10:06 +0000,Fri; 17 Mar 2017 09:07:39 +0000,Wed; 1 Mar 2017 19:32:07 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-5068
MAPREDUCE-6693,Bug,Critical,,ArrayIndexOutOfBoundsException occurs when the length of the job name is equal to mapreduce.jobhistory.jobname.limit,Job history entry missing when JOB name is of mapreduce.jobhistory.jobname.limit character     Looks like 50 character check is going wrong,Resolved,Fixed,,Ajith S,Bibin A Chundatt,Tue; 10 May 2016 11:30:38 +0000,Mon; 5 Sep 2016 12:05:03 +0000,Tue; 17 May 2016 11:24:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6693
MAPREDUCE-6694,Improvement,Major,,Make AM more resilient to potential lost of any completed container notification,YARN tries to guarantee any completed container notification is delivered to AM under any circumstance; YARN-1372 is an example to make sure for the case of RM restart. However; under some corner cases; it is still possible a completed container notifications is lost or significantly delayed. For example; if NM host becomes dead when RM fails over.  AM won't preempt reducers if it thought there is at least one mapper running.    Instead of completely depending on notification from RM; it can use TaskUmbilicalProtocol to help to decide if there is any mapper running. That will make AM more resilient to any bugs in YARN.,Open,Unresolved,,Unassigned,Ming Ma,Wed; 11 May 2016 00:54:29 +0000,Wed; 11 May 2016 00:54:29 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6694
MAPREDUCE-6695,Bug,Major,jobtracker,Problem accessing /jobtracker.jsp,Problem accessing  jobtracker.jsp. Reason:      Too many counters: 121 max=120  Caused by:  org.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120   org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder. 511),Resolved,Invalid,,Unassigned,Mina Samir Yacoub,Sat; 14 May 2016 13:23:32 +0000,Tue; 17 May 2016 09:32:12 +0000,Mon; 16 May 2016 19:26:45 +0000,,2.4.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6695
MAPREDUCE-6696,Improvement,Major,job submission,Add a configuration to limit the number of map tasks allowed per job.,"Add a configuration ""mapreduce.job.max.map"" to limit the number of map tasks allowed per job. It will be useful for Hadoop admin to save Hadoop cluster resource by preventing users from submitting big mapreduce jobs. A mapredeuce job with too many mappers may fail with OOM after running for long time. It will be a big waste.",Resolved,Fixed,,zhihai xu,zhihai xu,Mon; 16 May 2016 07:47:19 +0000,Tue; 30 Aug 2016 01:13:33 +0000,Fri; 20 May 2016 02:26:14 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6696
MAPREDUCE-6697,Bug,Major,mrv2,Concurrent task limits should only be applied when necessary,The concurrent task limit feature should only adjust the ANY portion of the AM heartbeat ask when a limit is truly necessary; otherwise extraneous containers could be allocated by the RM to the AM adding some overhead to both.  Specifying a concurrent task limit that is beyond the total number of tasks in the job should be the same as asking for no limit.,Resolved,Fixed,,Nathan Roberts,Jason Lowe,Mon; 16 May 2016 19:52:54 +0000,Thu; 13 Jul 2017 21:40:29 +0000,Thu; 13 Jul 2017 21:40:29 +0000,,2.7.0,,,MAPREDUCE-5583,https://issues.apache.org/jira/browse/MAPREDUCE-6697
MAPREDUCE-6698,Bug,Major,jobhistoryserver,Increase timeout on TestUnnecessaryBlockingOnHistoryFileInfo.testTwoThreadsQueryingDifferentJobOfSameUser,The timeout on TestUnnecessaryBlockingOnHistoryFileInfo.testTwoThreadsQueryingDifferentJobOfSameUser is added to verify the fix of MAPREDUCE-6684 works. When two thread are requesting different jobs owned by the same user; one thread request jobA should not be blocked by the other that is processing a large job jobB. The timeout exception; if happened; should ideally indicate the fix does not work. But the timeout period is set too aggressive; so the test always fails  on slow VMs.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Tue; 17 May 2016 00:17:12 +0000,Tue; 30 Aug 2016 01:13:30 +0000,Tue; 17 May 2016 15:07:28 +0000,,2.8.0,,,MAPREDUCE-6684,https://issues.apache.org/jira/browse/MAPREDUCE-6698
MAPREDUCE-6699,Test,Major,scripts;test,hadoop-mapred unit tests for dynamic commands,This is a hold over from HADOOP-12930; dynamic sub commands.  Currently there are no unit tests for this in mapred and there really should be.,Open,Unresolved,,Unassigned,Allen Wittenauer,Wed; 4 May 2016 22:48:05 +0000,Tue; 17 May 2016 01:01:40 +0000,,,,,MAPREDUCE-6691,,https://issues.apache.org/jira/browse/MAPREDUCE-6699
MAPREDUCE-6700,Bug,Blocker,,Jobhistory server attempt and task table not loading maps/reduce,"Browser ======= Chrome  Steps to reproduce ==============  	Submit mapreduce application with 20 maps 	Wait till completion of mapreduce application 	Check maps attempts page jobhistory m page    Actual ===== Table not loading. Sort based on any column other than attempt contents are loaded.  Column 0 is of natural sorting and not working. So waiting for ever to be sorted.",Resolved,Implemented,,Bibin A Chundatt,Bibin A Chundatt,Tue; 17 May 2016 12:40:58 +0000,Thu; 19 May 2016 11:55:07 +0000,Thu; 19 May 2016 11:55:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6700
MAPREDUCE-6701,Bug,Critical,jobhistoryserver,application master log can not be available when clicking jobhistory's am logs link,"In history server webapp; application master logs link is wrong. it shows ""No logs available for container container_1462419429440_0003_01_000001"".  It direct to a wrong nodemanager http port instead of a node manager' container managerment port. I think YARN-4701 brought this bug",Resolved,Fixed,,Haibo Chen,chenyukang,Thu; 5 May 2016 04:23:09 +0000,Tue; 30 Aug 2016 05:57:20 +0000,Tue; 17 May 2016 14:57:39 +0000,,2.9.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6701
MAPREDUCE-6702,Bug,Major,client,TestMiniMRChildTask.testTaskEnv and TestMiniMRChildTask.testTaskOldEnv are failing,-------------------------------------------------------  T E S T S ------------------------------------------------------- Running org.apache.hadoop.mapred.TestMiniMRChildTask Tests run: 3; Failures: 2; Errors: 0; Skipped: 0; Time elapsed: 92.48 sec &lt; ,Resolved,Fixed,,Akira Ajisaka,Daniel Templeton,Tue; 17 May 2016 22:11:38 +0000,Mon; 27 Jun 2016 14:30:23 +0000,Tue; 7 Jun 2016 22:47:09 +0000,,3.0.0-alpha1,,,MAPREDUCE-6704,https://issues.apache.org/jira/browse/MAPREDUCE-6702
MAPREDUCE-6703,Bug,Major,,Add flag to allow MapReduce AM to request for OPPORTUNISTIC containers,YARN-2882 and YARN-4335 introduces the concept of container ExecutionTypes and specifically OPPORTUNISTIC containers. The default ExecutionType is GUARANTEED. This JIRA proposes to allow users to provide hints via config to the MR framework as to the number of containers it would like to schedule as OPPORTUNISTIC.,Resolved,Fixed,,Arun Suresh,Arun Suresh,Tue; 17 May 2016 22:37:14 +0000,Tue; 30 Aug 2016 01:13:27 +0000,Wed; 25 May 2016 02:48:40 +0000,,,,YARN-5110,,https://issues.apache.org/jira/browse/MAPREDUCE-6703
MAPREDUCE-6704,Bug,Blocker,documentation,Update the documents to run MapReduce application,Container fail to launch for mapred application. As part for launch script HADOOP_MAPRED_HOME default value is not set .After https: 9d4d30243b0fc9630da51a2c17b543ef671d035c   HADOOP_MAPRED_HOME is not able to get from builder.environment() since DefaultContainerExecutor#buildCommandExecutor sets inherit to false.,Resolved,Fixed,MAPREDUCE-6783,Bibin A Chundatt,Bibin A Chundatt,Mon; 2 May 2016 13:18:25 +0000,Tue; 22 Aug 2017 18:38:21 +0000,Thu; 22 Dec 2016 19:50:49 +0000,,,,,MAPREDUCE-6941;MAPREDUCE-6702;YARN-5877,https://issues.apache.org/jira/browse/MAPREDUCE-6704
MAPREDUCE-6705,Bug,Blocker,,Task failing continuously on trunk,Task attempt failing continuously. Submit any mapreduce application  Run the job as below,Resolved,Duplicate,MAPREDUCE-6706,Kai Zheng,Bibin A Chundatt,Fri; 27 May 2016 15:27:29 +0000,Sat; 17 Sep 2016 00:53:17 +0000,Sat; 17 Sep 2016 00:53:15 +0000,,,,,MAPREDUCE-6706,https://issues.apache.org/jira/browse/MAPREDUCE-6705
MAPREDUCE-6706,Improvement,Major,,Update TaskUmbilicalProtocol to use ProtobufRPCEngine,Currently; TaskUmbilicalProtocol still uses WritableRPCEngine; which should be moved to ProtocolRPCEngine so that the former can be deprecated as tracked by HADOOP-12579,Open,Unresolved,,Wei Zhou,Arun Suresh,Mon; 30 May 2016 20:04:58 +0000,Tue; 27 Sep 2016 22:07:35 +0000,,,,,,MAPREDUCE-6705,https://issues.apache.org/jira/browse/MAPREDUCE-6706
MAPREDUCE-6707,Bug,Major,,Running a mapreduce Job for updating Hbase table. data we are getting from txt/csv file 1.1 gb from hdfs location,"I am trying to read 1.1 gb file which has data and i am reading this file and based on the data doing a put to Hbase table ; mapper is working fine but reducer is doing till 85% and fails with following error   opts""; ""-Xmx10g"");  I try reducing the file size by using some split logic. what i have notice if the file size is 350 Mb Mapreduce work file without issue; but if it is more than 350 Mb we will be getting OOM exception.  can some one please let us know what configuration is am missing or changes is required to run Mapreduce Job",Open,Unresolved,,Unassigned,Neemesh,Tue; 31 May 2016 12:20:58 +0000,Tue; 31 May 2016 12:36:04 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6707
MAPREDUCE-6708,Bug,Major,,when the preempt reduce happen; map  resources priority should be higher,in our cluster; i found job hang long time; When the cluster resources nervous many reduce were killed;  map no resources to run i think when the preempt reduce happen; map  resources priority should be higher,Open,Unresolved,,Unassigned,tangshangwen,Wed; 1 Jun 2016 03:57:30 +0000,Wed; 1 Jun 2016 04:31:00 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6708
MAPREDUCE-6709,Bug,Major,,Add configurable flag to allow MapReduce AM to specify the 'ensureExecutionType' of a Request,MAPREDUCE-6703 allows users to configure the ratio of Map tasks to be requested as OPPORTUNISTIC. This JIRA proposes to expose configuration to allow users to additionally specify the value ensureExecutionType flag (introduced in YARN-5180) as well.,Open,Unresolved,,Arun Suresh,Arun Suresh,Wed; 1 Jun 2016 05:48:09 +0000,Wed; 1 Jun 2016 05:48:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6709
MAPREDUCE-6710,Bug,Major,applicationmaster,Job CommitterEventHandler waitForValidCommitWindow may wait forever,The callBack Runnable may run after runOnNextHeartbeat but before wait(); if that happens; it will wait forever.  So I think the wait() must set timeout.  CommitterEventHandler#waitForValidCommitWindow while (now - lastHeartbeatTime  commitWindowMs) {         rmHeartbeatHandler.runOnNextHeartbeat(new Runnable() {           @Override           public void run() {             synchronized (EventProcessor.this)  {               EventProcessor.this.notify();             }           }         });          wait();         lastHeartbeatTime = rmHeartbeatHandler.getLastHeartbeatTime();         now = context.getClock().getTime();       },Patch Available,Unresolved,,Unassigned,ChenFolin,Fri; 3 Jun 2016 10:54:39 +0000,Fri; 3 Jun 2016 11:19:00 +0000,,,2.5.0;2.6.1;2.8.0;3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6710
MAPREDUCE-6711,Bug,Major,,JobImpl fails to handle preemption events on state COMMITTING,When a MR app being preempted on COMMITTING state; we saw the following exceptions in its log:   and     Seems like we need to handle those preemption related events when the job is being committed?,Resolved,Fixed,,Prabhu Joseph,Li Lu,Tue; 7 Jun 2016 18:06:12 +0000,Sun; 8 Jan 2017 06:34:32 +0000,Sun; 8 Jan 2017 06:18:11 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6711
MAPREDUCE-6712,Improvement,Minor,contrib/streaming,Support grouping values for reducer on java-side,In hadoop streaming; with TextInputWriter; reducer program will receive each line representing a (k; v) tuple from stdin; in which values with identical key is not grouped. This brings some inefficiency; especially for runtimes based on interpreter (e.g. cpython); coming from: A. user program has to compare key with previous one (but on  side; records already come to reducer in groups); B. user program has to perform read; then find or split on each record. even if there are multiple values with identical key; C. if length of key is large; apparently this introduces inefficiency for caching;  Suppose we need another InputWriter. But this is not enough; since the interface of InputWriter defined writeKey and writeValue; not writeValues. Though we can compare key in custom InputWriter and group them; but this is also inefficient. Some other changes are also needed.,Open,Unresolved,,Unassigned,He Tianyi,Wed; 8 Jun 2016 06:12:36 +0000,Fri; 17 Jun 2016 20:50:25 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6712
MAPREDUCE-6713,Bug,Major,distcp,Distcp doesn't provide any option to override the default staging directory,"Current state and shortcoming ======================= By default; distcp writes temporary files into $TARGET_PATH tmp directory. Current distcp also creates versioning for staging directory which can contain a lot of temporary files. If user can override this path by a non-versioned S3 path for staging; it will make things cleaner.  Proposed solution ============== Provide a new option(-stage) where user can optionally provide a path from target FS. Distcp mapper tasks will write distcp temporary files into that directory.   Possible Confusions  ================= There is another distcp option (-tmp) which can be assumed to serve the same purpose. But this option works only with ""-atomic"" option which has a different meaning of temporary files. Another confusion could be the staging directory used by mapreduce framework. The proposed temp directory is for distcp specific.  Working on a patch to upload.",Open,Unresolved,,Mohammad Kamrul Islam,Mohammad Kamrul Islam,Thu; 9 Jun 2016 19:41:17 +0000,Thu; 29 Sep 2016 16:07:15 +0000,,,2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6713
MAPREDUCE-6714,Improvement,Major,,Refactor UncompressedSplitLineReader.fillBuffer(),MAPREDUCE-6635 made this change:     The result is one more comparison than necessary and code that's a little convoluted.  The code can be simplified as:     The comparison will auto promote maxBytesToRead; making it safe.,Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Fri; 10 Jun 2016 00:57:00 +0000,Tue; 30 Aug 2016 01:13:26 +0000,Fri; 10 Jun 2016 10:18:22 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6714
MAPREDUCE-6715,Bug,Major,,Fix Several Unsafe Practices,nan,Resolved,Fixed,,Yufei Gu,Yufei Gu,Wed; 15 Jun 2016 22:03:39 +0000,Fri; 6 Jan 2017 17:38:08 +0000,Fri; 6 Jan 2017 02:05:39 +0000,,2.9.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6715
MAPREDUCE-6716,Bug,Minor,client,"Add ""-h"" option for ""mapred job -list"" and ""map queue -info xxx -showJobs"" to show user-frendly time format","when client excute shell ""mapred job -list"";     the result shows  StartTime  is a long type which is not user-friendly. and command ""mapred queue -info -showJobs"" has common problem.",Patch Available,Unresolved,,Shen Yinjie,Shen Yinjie,Fri; 17 Jun 2016 07:11:09 +0000,Thu; 13 Apr 2017 01:44:23 +0000,,,2.6.0;2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6716
MAPREDUCE-6717,Improvement,Minor,,Remove deprecated StringUtils.getFormattedTimeWithDiff,MAPREDUCE-6542 deprecated StringUtils.getFormattedTimeWithDiff(DateFormat; long; long); so it should be removed later. This method can be removed in branch-2 because StringUtils is not @Public.,Resolved,Fixed,,Shen Yinjie,Akira Ajisaka,Fri; 17 Jun 2016 08:03:02 +0000,Tue; 30 Aug 2016 01:13:25 +0000,Thu; 7 Jul 2016 18:20:46 +0000,,,newbie,,MAPREDUCE-6542,https://issues.apache.org/jira/browse/MAPREDUCE-6717
MAPREDUCE-6718,Improvement,Minor,jobhistoryserver,add progress log to JHS during startup,lWhen the JHS starts up; it initializes the internal caches and storage via the HistoryFileManager. If we have a large number of existing finished jobs then we could spent minutes in this startup phase without logging progress: 2016-03-14 10:56:01;444 INFO org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system hdfs: hadoopcdh.itnas01.ieee.org:8020 2016-03-14 10:56:11;455 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Initializing Existing Jobs... 2016-03-14 12:01:36;926 INFO org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage: CachedHistoryStorage Init This makes it really difficult to assess if things are working correctly (it looks hung). We can add logs to notify users of progress.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Sun; 19 Jun 2016 01:52:25 +0000,Wed; 28 Sep 2016 23:17:32 +0000,Wed; 28 Sep 2016 23:05:00 +0000,,,supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6718
MAPREDUCE-6719,Improvement,Critical,distributed-cache,The list of -libjars archives should be replaced with a wildcard in the distributed cache to reduce the application footprint in the state store,"When using the -libjars option to add classes to the classpath; every library so added is explicitly listed in the ContainerLaunchContext's local resources even though they're all uploaded to the same directory in HDFS. When using tools like Crunch without an uber JAR or when trying to take advantage of the shared cache; the number of libraries can be quite large. We've seen many cases where we had to turn down the max number of applications to prevent ZK from running out of heap because of the size of the state store entries. This JIRA proposes to allow for wildcards both in the internal processing of the -libjars switch and in paths added through the Job and DistributedCache classes. Rather than listing all files independently; this JIRA proposes to replace the complete list of libdir files with the wildcarded libdir directory; e.g. ""libdir *"". This behavior is the same as the current behavior when using -libjars; but avoids explicitly listing every file. This capability will also be exposed by the DistributedCache.addCacheFile() method. See YARN-4958 for the NM side of the implementation and additional discussion.",Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Mon; 20 Jun 2016 14:07:01 +0000,Tue; 30 Aug 2016 01:13:24 +0000,Tue; 21 Jun 2016 18:30:08 +0000,,2.8.0,,,YARN-5388,https://issues.apache.org/jira/browse/MAPREDUCE-6719
MAPREDUCE-6720,Sub-task,Major,applicationmaster,Inconsistent values of counters across tasks and job reported to timeline service.,"While testing found below issue. For some of the task counters; we do not have consistent values. This is not the case with every counter though. Consider the case of counter ""org.apache.hadoop.mapreduce.FileSystemCounter:FILE_BYTES_WRITTEN"".  I found that its value for a flow I ran; was 936018 bytes. For the 3 apps associated with this flow run; the values were 312006 bytes each (which equals to value for a flow run i.e. 3 * 312006 = 936018). Drilling further down I found though that for one of the apps; the 4 tasks(2 mappers and 2 reducers) had values as 155918 bytes each for the 2 reducers and 156003 bytes each for the 2 mappers.  This means the value reported for the app should be (2 * 156003 + 2* 155918) or 623842 bytes but it is only 312006 bytes which indicates that only counter value of mappers is being picked up.",Resolved,Fixed,,Varun Saxena,Varun Saxena,Mon; 20 Jun 2016 19:24:08 +0000,Sat; 21 Oct 2017 06:30:33 +0000,Thu; 23 Jun 2016 03:48:55 +0000,,YARN-2928,yarn-2928-1st-milestone,,,https://issues.apache.org/jira/browse/MAPREDUCE-6720
MAPREDUCE-6721,Improvement,Major,mrv2;task,mapreduce.reduce.shuffle.memory.limit.percent=0.0 should be legal to enforce shuffle to disk,We are potentially hitting an in-memory-shuffle-related reservation starvation resembling MAPREDUCE-6445. To work it around; we wanted to disable in memory shuffle via mapreduce.reduce.shuffle.memory.limit.percent=0.0 that turned out to be disallowed by the current logic. So we had to resort to another small float value such as 0.0001. However; zero is more logical imo.,Resolved,Fixed,,Gera Shegalov,Gera Shegalov,Wed; 22 Jun 2016 07:18:39 +0000,Tue; 30 Aug 2016 01:13:22 +0000,Thu; 23 Jun 2016 00:24:03 +0000,,2.6.4,,,MAPREDUCE-6445,https://issues.apache.org/jira/browse/MAPREDUCE-6721
MAPREDUCE-6722,Improvement,Trivial,jobhistoryserver,"JobHistory page should add column for ""Application Priority""",priority has been an important feature for app in yarn ;we wish JobHistory page contain column for it;so that we can do some job-analysis for better management.,Open,Unresolved,,Unassigned,Shen Yinjie,Wed; 22 Jun 2016 09:33:45 +0000,Wed; 22 Jun 2016 09:33:45 +0000,,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6722
MAPREDUCE-6723,Test,Major,,Turn log level to Debug in test,The current log level in test enviroment for all mapreduce projects is info. Often in case where we are investigating intermittent test failures; DEBUG level messages in log file can be very useful to identify problems.,Resolved,Won't Fix,,Haibo Chen,Haibo Chen,Thu; 23 Jun 2016 00:40:43 +0000,Tue; 16 Aug 2016 20:41:01 +0000,Tue; 16 Aug 2016 20:41:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6723
MAPREDUCE-6724,Bug,Major,mrv2,Single shuffle to memory must not exceed Integer#MAX_VALUE,When shuffle is done in memory; MergeManagerImpl converts the requested size to an int to allocate an instance of InMemoryMapOutput. This results in an overflow if the requested size is bigger than Integer.MAX_VALUE and eventually causes the reducer to fail.,Resolved,Fixed,MAPREDUCE-6805,Haibo Chen,Haibo Chen,Thu; 23 Jun 2016 00:52:17 +0000,Fri; 28 Oct 2016 14:51:26 +0000,Tue; 2 Aug 2016 06:56:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6724
MAPREDUCE-6725,Bug,Minor,client;documentation,Javadoc for CLI#listEvents() contains no-existent param,Comment for CLI#listEvents() contains @param jobid;  but this method doesn't has the parameter;it  may be some jira changed the method and forgot to change the comment  So I made a simple fix.,Resolved,Fixed,,Shen Yinjie,Shen Yinjie,Thu; 23 Jun 2016 10:22:00 +0000,Tue; 30 Aug 2016 01:13:18 +0000,Fri; 24 Jun 2016 15:29:10 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6725
MAPREDUCE-6726,Sub-task,Major,applicationmaster,YARN Registry based AM discovery with retry and in-flight task persistent via JHS,Several tasks will be achieved in this JIRA based on the demo patch in MAPREDUCE-6608: 1. AM discovery base on YARN register service. Could be replaced by YARN-4758 later due to scale up issue. 2. Retry logic for TaskUmbilicalProtocol RPC connection 3. In-flight task recover after AM restart via JHS 4. Configuration to control the behavior compatible with previous when not enable this feature (by default). All security related issues and other concerns discussed in MAPREDUCE-6608 will be addressed in follow up JIRAs.,Patch Available,Unresolved,,Srikanth Sampath,Junping Du,Fri; 24 Jun 2016 06:22:16 +0000,Tue; 15 Nov 2016 17:22:43 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6726
MAPREDUCE-6727,Improvement,Major,job submission,Add a configuration to limit the input size of the MapReduce job.,Add a configuration to limit the input size of the MapReduce job. It will be useful for Hadoop admin to save Hadoop cluster resource by preventing users from submitting bad mapreduce jobs or bad hive queries. The default behavior is no limit.,Patch Available,Unresolved,,zhihai xu,zhihai xu,Sun; 26 Jun 2016 06:35:11 +0000,Sun; 26 Jun 2016 09:24:27 +0000,,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6727
MAPREDUCE-6728,Improvement,Major,mrv2,Give fetchers hint when ShuffleHandler rejects a shuffling connection,If # of open shuffle connection to a node goes over the max; ShuffleHandler closes the connection immediately without giving fetchers any hint of the reason; which causes fetchers to fail due to exceptions     Such failures are counted as fetcher failures,Resolved,Fixed,,Haibo Chen,Haibo Chen,Tue; 5 Jul 2016 16:48:43 +0000,Fri; 20 Jan 2017 00:17:26 +0000,Fri; 20 Jan 2017 00:17:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6728
MAPREDUCE-6729,Improvement,Minor,benchmarks;performance;test,Accurately compute the test execute time in DFSIO,When doing DFSIO test as a distributed i TestDFSIO.java,Resolved,Fixed,,mingleizhang,mingleizhang,Wed; 6 Jul 2016 09:15:19 +0000,Fri; 9 Dec 2016 02:38:38 +0000,Sat; 30 Jul 2016 13:18:47 +0000,,2.9.0,performance;test,,,https://issues.apache.org/jira/browse/MAPREDUCE-6729
MAPREDUCE-6730,Improvement,Minor,,Use StandardCharsets instead of String overload in TextOutputFormat,In TextOutputFormat.  instead of:    Let's do something like:,Resolved,Fixed,,Sahil Kang,Sahil Kang,Mon; 11 Jul 2016 04:15:49 +0000,Tue; 30 Aug 2016 01:13:16 +0000,Thu; 4 Aug 2016 11:19:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6730
MAPREDUCE-6731,Bug,Major,test,TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling() may fail for concurrent tests,TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling() uses the default file-system storage directory; and is brittle against concurrent tests.  We should use a unique storage directory for the tests.,Resolved,Fixed,,Sangjin Lee,Sangjin Lee,Mon; 11 Jul 2016 16:42:17 +0000,Tue; 12 Jul 2016 15:44:07 +0000,Tue; 12 Jul 2016 15:17:10 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6731
MAPREDUCE-6732,New Feature,Major,,mapreduce tasks for YARN Timeline Service v.2: alpha 2,This s an umbrella JIRA to capture all mapreduce tasks for YARN Timeline Service v.2 alpha 2.  This is developed on feature branches: YARN-5355 for the trunk-based development and YARN-5355-branch-2 to maintain backports to branch-2. Any subtask work on this JIRA will be committed to those 2 branches.,Resolved,Fixed,,Vrushali C,Sangjin Lee,Mon; 11 Jul 2016 17:05:37 +0000,Sat; 21 Oct 2017 06:32:22 +0000,Sat; 21 Oct 2017 06:32:22 +0000,,,,,MAPREDUCE-6943;YARN-2928;YARN-5355;MAPREDUCE-6331,https://issues.apache.org/jira/browse/MAPREDUCE-6732
MAPREDUCE-6733,Bug,Critical,test,"MapReduce JerseyTest tests failing with ""java.net.BindException: Address already in use""",Similar to YARN-2912   YARN-3433; MR JerseyTests fail when port 9998 is in external use. We should fix the MR tests too similar to YARN-2912.,Resolved,Fixed,,Vinod Kumar Vavilapalli,Vinod Kumar Vavilapalli,Fri; 15 Jul 2016 16:52:57 +0000,Tue; 30 Aug 2016 01:13:13 +0000,Fri; 15 Jul 2016 18:36:40 +0000,,,,,YARN-3433;YARN-2912,https://issues.apache.org/jira/browse/MAPREDUCE-6733
MAPREDUCE-6734,Improvement,Major,distcp,Add option to distcp to preserve file path structure of source files at the destination,When copying files using distcp with globbed source files; all the matched files in the glob are copied in a single flat directory.  This causes problems when the file structure at the source is important.  It also is an issue when there are two files matched in the glob with the same name because it causes a duplicate file error at the target.  I'd like to have an option to preserve the file structure of the source files when globbing inputs.,Patch Available,Unresolved,,Unassigned,Frederick Tucker,Mon; 18 Jul 2016 18:37:23 +0000,Tue; 14 Nov 2017 19:37:10 +0000,,,3.0.0-alpha2,distcp;newbie;patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-6734
MAPREDUCE-6735,Bug,Major,,Performance degradation caused by MAPREDUCE-5465 and HADOOP-12107,Two commits; MAPREDUCE-5465 and HADOOP-12107 are making Terasort on YARN 10% slower.  Reduce phase with those commits ~5 mins Reduce phase without ~3.5 mins  Average Reduce is taking 4mins; 16sec with those commits compared to 3mins; 48sec without.,Open,Unresolved,,Unassigned,Alexandr Balitsky,Tue; 19 Jul 2016 09:03:35 +0000,Wed; 20 Jul 2016 16:25:19 +0000,,,,,,HADOOP-12107;MAPREDUCE-5465,https://issues.apache.org/jira/browse/MAPREDUCE-6735
MAPREDUCE-6736,Bug,Blocker,applicationmaster;mrv2,import hive table from parquet files; there is no 'job.splitmetainfo' file message,same issue : https: job_1468834620182_0036 2016-07-20 17:57:30;628 INFO Thread-55 org.apache.hadoop.ipc.Server: Stopping server on 41561 2016-07-20 17:57:30;629 INFO IPC Server listener on 41561 org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 41561 2016-07-20 17:57:30;629 INFO IPC Server Responder org.apache.hadoop.ipc.Server: Stopping IPC Server Responder 2016-07-20 17:57:30;629 INFO TaskHeartbeatHandler PingChecker org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted 2016-07-20 17:57:30;629 INFO Ping Checker org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: TaskAttemptFinishingMonitor thread interrupted,Open,Unresolved,,Unassigned,Ha; Hun Cheol,Wed; 20 Jul 2016 09:51:09 +0000,Wed; 20 Jul 2016 10:02:05 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6736
MAPREDUCE-6737,Bug,Major,jobhistoryserver,HS: job history recovery fails with NumericFormatException if the job wasn't initted properly,"The problem shows itself while recovering old apps information: 2016-07-18 16:08:35;031 WARN org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils: Unable to parse start time from job history file job_1468716177837_21790-1468845880296-username-applicationname-1468845889100-0-0-FAILED-root.queuename--1.jhist :  class in the following part of code:   initialize the launchTime in the JobIndexInfo of MetaInfo       if(event.getHistoryEvent().getEventType() == EventType.JOB_INITED ){         JobInitedEvent jie = (JobInitedEvent) event.getHistoryEvent();         mi.getJobIndexInfo().setJobStartTime(jie.getLaunchTime());  Because of job was not initialized properly; the 'if' statement takes value 'false' and .setJobStartTime() is not called.  In JobIndexInfo constructor; we have a default value for jobStartTime: this.jobStartTime = -1;  When history server recovers any application's info; it passes all parameters to array of strings jobDetails: String[] jobDetails = fileName.split(DELIMITER);  Please note; DELIMETER is initialized in the following way: static final String DELIMITER = ""-"";  So; jobDetails array has 10 elements - job ID; submit time; username; job name; finish time; number of maps; number of reducers; job status; queue; and start time). If jobStartTime = -1; the minus symbol is considered as delimeter and the code will assign an empty string """" as a value for 9-th element in jobDetails array.  In org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils class a NumberFormatException will appear while trying to parse empty string to long type. Long.parseLong(decodeJobHistoryFileName(jobDetailsJOB_START_TIME_INDEX)));  The most simple fix is to change the value this.jobStartTime to 0 in JobIndexInfo constructor.",Patch Available,Unresolved,,Unassigned,Roman Gavryliuk,Wed; 20 Jul 2016 09:55:21 +0000,Wed; 10 Aug 2016 14:50:51 +0000,,,2.7.0;2.5.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6737
MAPREDUCE-6738,Test,Minor,,TestJobListCache.testAddExisting failed intermittently in slow VM testbed,Kick off Jenkins test which occasionally failed for this test with stack trace below:  org.apache.hadoop.mapreduce.v2.hs.TestJobListCache.testAddExisting   42),Resolved,Fixed,,Junping Du,Junping Du,Wed; 20 Jul 2016 18:50:43 +0000,Tue; 30 Aug 2016 01:13:12 +0000,Thu; 21 Jul 2016 18:39:31 +0000,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6738
MAPREDUCE-6739,Improvement,Major,mr-am,allow specifying range on the port that MR AM web server binds to,MR AM web server binds itself to an arbitrary port.  This means if the RM web proxy lives outside of a cluster; the whole port range needs to be wide open. It'd be nice to reuse yarn.app.mapreduce.am.job.client.port-range to place a port range restriction on MR AM web server; so that connection from outside the cluster can be restricted within a range of ports.,Resolved,Duplicate,MAPREDUCE-6404,Haibo Chen,Haibo Chen,Wed; 20 Jul 2016 22:04:24 +0000,Wed; 25 Jan 2017 03:18:45 +0000,Wed; 25 Jan 2017 03:18:45 +0000,,2.7.2,supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6739
MAPREDUCE-6740,Bug,Minor,mr-am,Enforce mapreduce.task.timeout to be at least mapreduce.task.progress-report.interval,MAPREDUCE-6242 makes task status update interval configurable to ease the pressure on MR AM to process status updates; but it did not ensure that mapreduce.task.timeout is no smaller than the configured value of task report interval.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Wed; 20 Jul 2016 22:47:49 +0000,Thu; 6 Oct 2016 07:16:08 +0000,Thu; 6 Oct 2016 07:16:08 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6740
MAPREDUCE-6741,Improvement,Major,mrv2,add MR support to redact job conf properties,JHS today displays all Job conf properties in Web UI directly. Users may have some credentials or any sensitive information they added to the job conf but do not want to be shown in Web UI. It'd be nice if we can allow users to specify a set of properties which JHS will filter out when Job conf is displayed.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Thu; 21 Jul 2016 19:15:15 +0000,Wed; 12 Oct 2016 23:50:59 +0000,Wed; 5 Oct 2016 15:34:45 +0000,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6741
MAPREDUCE-6742,Bug,Major,,Test,nan,Resolved,Not A Problem,,Unassigned,Prashanth G B,Fri; 22 Jul 2016 10:36:18 +0000,Fri; 22 Jul 2016 15:43:01 +0000,Fri; 22 Jul 2016 15:43:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6742
MAPREDUCE-6743,Test,Major,nativetask,nativetask unit tests need to provide usable output; fix link errors during mvn test,Currently; hadoop-mapreduce-client-nativetask creates a nttest binary which provides an binary exit code to determine failure.  This means there is no output generated by the Jenkins run to actually debug or provide hints as to what failed.  Given that nttest is written with gtest; it should be configured to either spit out junit or TAP which can then be used to provide further analysis.,Resolved,Fixed,,Allen Wittenauer,Allen Wittenauer,Fri; 22 Jul 2016 15:46:08 +0000,Mon; 28 Nov 2016 23:40:31 +0000,Mon; 28 Nov 2016 23:24:54 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6743
MAPREDUCE-6744,Bug,Major,,Increase timeout on TestDFSIO tests,The timeout on these tests is only 3 seconds and so one of the tests in the suite will fail on a regular basis.,Resolved,Fixed,,Eric Badger,Eric Badger,Fri; 22 Jul 2016 16:20:04 +0000,Tue; 30 Aug 2016 01:13:10 +0000,Mon; 25 Jul 2016 22:03:18 +0000,,,,,MAPREDUCE-5525,https://issues.apache.org/jira/browse/MAPREDUCE-6744
MAPREDUCE-6745,Bug,Blocker,mr-am,Job directories should be clean in staging directorg /tmp/hadoop-yarn/staging after MapReduce job finish successfully,"If MapReduce client set mapreduce.task.files.preserve.failedtasks=true; temporary job directory will not be deleted in staging directory  .staging is exceeded: limit=1048576 items=1048576 	  org.apache.hadoop.ipc.Server$Handler.run(Server. 2082)   The official instructions for the configuration mapreduce.task.files.preserve.failedtasks is below:     Should the files for failed tasks be kept. This should only be used on jobs that are failing; because the storage is never reclaimed.      It also prevents the map outputs from being erased from the reduce directory as they are consumed.  According to the instructions; I think the temporary files for successful tasks shouldn't be kept.",Open,Unresolved,,Unassigned,liuxiaoping,Fri; 29 Jul 2016 02:13:56 +0000,Thu; 1 Sep 2016 11:51:25 +0000,,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6745
MAPREDUCE-6746,Improvement,Minor,,Replace org.apache.commons.io.Charsets with java.nio.charset.StandardCharsets,MapReduce side of HADOOP-13444. IO-422 deprecated org.apache.commons.io.Charsets in commons-io 2.5. We should use  nio.charset.StandardCharsets instead.,Resolved,Fixed,,Vincent Poon,Vincent Poon,Fri; 29 Jul 2016 21:56:45 +0000,Tue; 30 Aug 2016 01:13:08 +0000,Sat; 30 Jul 2016 02:48:38 +0000,,,,,HDFS-10707;HADOOP-13444,https://issues.apache.org/jira/browse/MAPREDUCE-6746
MAPREDUCE-6747,Bug,Minor,,TestMapReduceJobControl#testJobControlWithKillJob times out in trunk,TestMapReduceJobControl#testJobControlWithKillJob seems to time out while waiting for all jobs to complete. This seems to only happen if the test is run with the other tests in the class (specifically testJobControlWithFailJob). If testJobControlWithKillJob is run by itself; the test passes.  Looking into the test logs; when run with another test from the class; the test runs into an issue while setting permissions on the local file system:    Conversely; when the test is run by itself; this issue is not hit.,Open,Unresolved,,Unassigned,Chris Trezzo,Fri; 5 Aug 2016 20:11:23 +0000,Fri; 5 Aug 2016 23:10:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6747
MAPREDUCE-6748,Improvement,Minor,,Enhance logging for Cluster.java around InetSocketAddress,"We need to add more logging for cluster. class around "" initialize(InetSocketAddress jobTrackAddr; Configuration conf) "" method to give better logging like about the source of the property.",Resolved,Fixed,,Vrushali C,sarun singla,Fri; 29 Jul 2016 18:12:32 +0000,Tue; 30 Aug 2016 01:13:07 +0000,Mon; 8 Aug 2016 16:24:59 +0000,,,YARN,,,https://issues.apache.org/jira/browse/MAPREDUCE-6748
MAPREDUCE-6749,Improvement,Major,applicationmaster;mrv2,MR AM should reuse containers for Map/Reduce Tasks,It is with the continuation of MAPREDUCE-3902; MR AM should reuse containers for Map Reduce Tasks similar to the JVM Reuse feature we had in MRv1.,Open,Unresolved,,Devaraj K,Devaraj K,Mon; 8 Aug 2016 18:00:06 +0000,Tue; 18 Oct 2016 14:02:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6749
MAPREDUCE-6750,Bug,Minor,test,TestHSAdminServer.testRefreshSuperUserGroups is failing,HADOOP-13442 changed AccessControlList to call getGroups() instead of getGroupNames(). It should work if the mocks are updated to stub the right method and return the right type.,Resolved,Fixed,,Kihwal Lee,Kihwal Lee,Tue; 9 Aug 2016 15:50:38 +0000,Fri; 8 Sep 2017 18:32:44 +0000,Tue; 9 Aug 2016 18:15:07 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6750
MAPREDUCE-6751,Improvement,Minor,client;mrv1;mrv2,Add debug log message when splitting is not possible due to unsplittable compression,There should be a message logged in case of the mapreduce will only spam one mapper since the source file is compressed with an unsplitable algorithm,Resolved,Fixed,,Peter Vary,Peter Vary,Thu; 11 Aug 2016 00:03:08 +0000,Tue; 30 Aug 2016 01:13:02 +0000,Tue; 16 Aug 2016 19:21:07 +0000,,3.0.0-alpha1,supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6751
MAPREDUCE-6752,Bug,Major,client,Bad logging practices in mapreduce,Similar to previous issue HADOOP-3029; in the file: hadoop-rel-release-2.7.2  line 253; the whole method is for debugging purpose; therefore the log:   should be set to debug level instead of info level to avoid redundant information.,Open,Unresolved,,Unassigned,Nemo Chen,Thu; 11 Aug 2016 02:17:41 +0000,Mon; 30 Oct 2017 02:20:40 +0000,,,2.7.2,easyfix;easytest;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6752
MAPREDUCE-6753,Bug,Major,client,Variable in byte printed directly in mapreduce client,Similar to the fix for HBASE-623; in file:  hadoop-rel-release-2.7.2   in line 61; the system out print a byte variable secretValue.,Resolved,Fixed,,Kai Sasaki,Nemo Chen,Thu; 11 Aug 2016 17:57:30 +0000,Wed; 7 Jun 2017 22:25:08 +0000,Fri; 3 Mar 2017 07:16:26 +0000,,2.7.2,easyfix;easytest,,,https://issues.apache.org/jira/browse/MAPREDUCE-6753
MAPREDUCE-6754,Sub-task,Major,,Container Ids for an yarn application should be monotonically increasing in the scope of the application,Currently across application tempt with the latest containerId (instead of 0).   I can provide the patch if it helps.  It currently exists in MAPREDUCE-6726,Open,Unresolved,,Srikanth Sampath,Srikanth Sampath,Fri; 12 Aug 2016 07:38:11 +0000,Thu; 25 Aug 2016 12:30:10 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6754
MAPREDUCE-6755,Improvement,Minor,nativetask,Report correct spill/output size for map in nativetask,Currently nativetask always report '-1' as size when calling methods in MapOutputFile. This is an obstacle for custom MapOutputFile implementations where size matters (e.g. determine which disk to use).  The issue propose to estimate spill index size in nativetask like  implementation does.,Open,Unresolved,,Unassigned,He Tianyi,Tue; 16 Aug 2016 02:49:04 +0000,Tue; 16 Aug 2016 02:49:04 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6755
MAPREDUCE-6756,Improvement,Major,nativetask,native map output collector should be able to handle KV larger than io.sort.mb,Currently exception is thrown if kvLength  io.sort.mb. In rare cases this can occur; especially for hive queries.  Maybe we could implement a 'spill single record' function.,Open,Unresolved,,Unassigned,He Tianyi,Tue; 16 Aug 2016 03:45:20 +0000,Tue; 16 Aug 2016 03:45:20 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6756
MAPREDUCE-6757,Bug,Major,nativetask,Multithreaded mapper corrupts buffer pusher in nativetask,Multiple threads could be calling collect method of the same NativeMapOutputCollectorDelegator instance at the same time. In this case; buffer can be corrupted. This may occur when executing Hive queries with custom script.  Adding 'synchronized' keyword to collect method would solve the problem.,Patch Available,Unresolved,,Unassigned,He Tianyi,Tue; 16 Aug 2016 10:06:02 +0000,Tue; 16 Aug 2016 10:22:50 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6757
MAPREDUCE-6758,Improvement,Major,test,TestDFSIO should parallelize its creation of control files on setup,TestDFSIO currently performs a sequential for-loop to create nrFiles control files in the controlDir which is a subdirectory of the overall test.build.data directory; which may be a non-HDFS FileSystem implementation:     When testing in an object-store based filesystem with higher round-trip latency than HDFS (like S3 or GCS); this means job setup that might only take seconds in HDFS ends up taking minutes or even tens of minutes against the object stores if the test is using thousands of control files. In the same vein as other JIRAs in https: QPS.,Open,Unresolved,,Unassigned,Dennis Huo,Wed; 17 Aug 2016 01:56:47 +0000,Tue; 1 Aug 2017 17:06:24 +0000,,,,,,MAPREDUCE-6674,https://issues.apache.org/jira/browse/MAPREDUCE-6758
MAPREDUCE-6759,Improvement,Major,job submission,JobSubmitter/JobResourceUploader should parallelize upload of -libjars; -files; -archives,During job submission; the JobResourceUploader currently iterates over for-loops of -libjars; -files; and -archives sequentially; which can significantly slow down job startup time when a large number of files need to be uploaded; especially if staging the files to a cloud object-store based FileSystem implementation like S3; GCS; WABS; etc.; where round-trip latencies may be higher than HDFS despite having good throughput when parallelized:      Parallelizing the upload of these files would improve job submission time.,Open,Unresolved,,Unassigned,Dennis Huo,Wed; 17 Aug 2016 17:38:53 +0000,Wed; 17 Aug 2016 17:38:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6759
MAPREDUCE-6760,Improvement,Major,mrv2,LocatedFileStatusFetcher to use listFiles(recursive),LocatedFileStatusFetcher does parallelized path listing; but it does make recursive calls on every subdir.  If we could switch it to use FileSystem.listFiles(recursive); object stores that have high-performance implementations of that operation would see significant speedup.  HADOOP-13208 implements that for S3A; Azure; swift c can do the same.,Open,Unresolved,,Unassigned,Steve Loughran,Thu; 18 Aug 2016 09:23:11 +0000,Tue; 5 Sep 2017 09:22:56 +0000,,,2.8.0,,,HIVE-14165,https://issues.apache.org/jira/browse/MAPREDUCE-6760
MAPREDUCE-6761,Bug,Major,mrv2,Regression when handling providers - invalid configuration ServiceConfiguration causes Cluster initialization failure,When a rogue org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider defines a provider that is not on classpath; then the initialization is failed with the following exception:   455)  This regression is caused by MAPREDUCE-6473,Resolved,Fixed,,Peter Vary,Peter Vary,Fri; 19 Aug 2016 01:03:55 +0000,Tue; 30 Aug 2016 01:13:01 +0000,Wed; 24 Aug 2016 14:44:41 +0000,,3.0.0-alpha2,supportability,,MAPREDUCE-6473,https://issues.apache.org/jira/browse/MAPREDUCE-6761
MAPREDUCE-6762,Bug,Major,,ControlledJob#toString failed with NPE when job status is not successfully updated,This issue was found from a cluster where Pig query occasionally failed on NPE. Pig uses JobControl API to track MR job status; but sometimes Job History Server failed to flush job meta files to HDFS which caused the status update failed. Then we get NPE in org.apache.hadoop.mapreduce.Job.getJobName. The result of this situation is quite confusing: Pig query failed; job history is missing; but the job status on Yarn is succeed.,Resolved,Fixed,,Weiwei Yang,Weiwei Yang,Fri; 19 Aug 2016 04:07:32 +0000,Tue; 30 Aug 2016 01:12:59 +0000,Sun; 21 Aug 2016 16:22:47 +0000,,2.7.2,,,PIG-4967,https://issues.apache.org/jira/browse/MAPREDUCE-6762
MAPREDUCE-6763,Bug,Major,mrv2,Shuffle server listen queue is too small,ShuffleHandler doesn't specify a listen queue length for the server port; so it ends up getting the default listen queue length of 50.  This is too small to handle bursts of shuffle traffic on large clusters.  It's also inconsistent with the default Hadoop uses for RPC servers (default=128).,Resolved,Fixed,,Jason Lowe,Jason Lowe,Fri; 19 Aug 2016 17:48:35 +0000,Tue; 30 Aug 2016 01:12:58 +0000,Fri; 19 Aug 2016 22:50:08 +0000,,,,,TEZ-3415,https://issues.apache.org/jira/browse/MAPREDUCE-6763
MAPREDUCE-6764,Bug,Minor,examples,Teragen LOG initialization bug,nan,Resolved,Fixed,,Yufei Gu,Yufei Gu,Mon; 22 Aug 2016 06:20:23 +0000,Thu; 25 Aug 2016 17:20:17 +0000,Thu; 25 Aug 2016 17:04:48 +0000,,3.0.0-alpha1,reviewed,,,https://issues.apache.org/jira/browse/MAPREDUCE-6764
MAPREDUCE-6765,Bug,Minor,mr-am,MR should not schedule container requests in cases where reducer or mapper containers demand resource larger than the maximum supported,When mapper or reducer containers request resource larger than the maxResourceRequest in the cluster; job is to be killed. In such cases; it is unnecessary to still schedule container requests.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Tue; 23 Aug 2016 17:52:18 +0000,Wed; 2 Nov 2016 04:13:49 +0000,Wed; 2 Nov 2016 03:51:47 +0000,,2.7.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6765
MAPREDUCE-6766,Bug,Major,,Concurrent local job failures due to uniqueNumberGenerator = new AtomicLong(System.currentTimeMillis()),"I am seeing the following exception when attempting to execute multiple Hadoop Local Jobs with Druid.     From a quick look at the Hadoop code base; it seems that the uniqueNumberGenerator for the LocalDistributedCacheManager is based on the System time; and this appears to cause problems for concurrent jobs.      I am pretty sure the following line of code is responsible; and this seems to exist in latter versions of such as 2.7.1:   	Hadoop 2.3.0 - LocalDistributedCacheManager. L96     Full Stack Trace",Open,Unresolved,,Unassigned,Mark S,Wed; 24 Aug 2016 16:00:54 +0000,Mon; 31 Oct 2016 16:34:24 +0000,,,2.3.0;2.7.1,,,MAPREDUCE-6685;MAPREDUCE-6441,https://issues.apache.org/jira/browse/MAPREDUCE-6766
MAPREDUCE-6767,Bug,Major,,TestSlive fails after a common change,It looks like this was broken after HADOOP-12726.,Resolved,Fixed,,Daniel Templeton,Kihwal Lee,Wed; 24 Aug 2016 20:02:19 +0000,Sat; 22 Jul 2017 17:46:37 +0000,Thu; 25 Aug 2016 01:57:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6767
MAPREDUCE-6768,Bug,Major,mrv2,TestRecovery.testSpeculative failed with NPE,1 tests failed. REGRESSION:  org.apache.hadoop.mapreduce.v2.app.TestRecovery.testSpeculative  Error Message: null  Stack Trace:  1201),Resolved,Fixed,,Haibo Chen,Haibo Chen,Fri; 26 Aug 2016 00:15:36 +0000,Tue; 30 Aug 2016 01:12:56 +0000,Mon; 29 Aug 2016 20:03:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6768
MAPREDUCE-6769,Bug,Minor,scripts,"Fix forgotten conversion from ""slave"" to ""worker"" in mapred script","In HADOOP-13209 (commit 23c3ff85a9e73d8f0755e14f12cc7c89b72acddd); ""slaves"" was replaced with ""workers"" including the function name change from hadoop_common_slave_mode_execute to hadoop_common_worker_mode_execute and environment variable name change from HADOOP_SLAVE_MODE to HADOOP_WORKER_MODE.  It appears this change was forgotten in hadoop-mapred-project mapred.  Github pull request with fix to be sent shortly.",Resolved,Duplicate,HADOOP-13564,Albert Chu,Albert Chu,Fri; 26 Aug 2016 18:23:47 +0000,Tue; 25 Oct 2016 08:51:30 +0000,Tue; 25 Oct 2016 08:47:42 +0000,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6769
YARN-5567,Bug,Major,nodemanager,Fix script exit code checking in NodeHealthScriptRunner#reportHealthStatus,In case of FAILED_WITH_EXIT_CODE; health status should be false.    should be,Resolved,Fixed,,Yufei Gu,Yufei Gu,Fri; 26 Aug 2016 22:24:33 +0000,Fri; 16 Jun 2017 20:20:54 +0000,Sun; 11 Sep 2016 13:25:02 +0000,,2.8.0;3.0.0-alpha1,,,YARN-5595;YARN-6715,https://issues.apache.org/jira/browse/YARN-5567
MAPREDUCE-6771,Bug,Major,mrv2,RMContainerAllocator sends container diagnostics event after corresponding completion event,Task containers can go over their resource limit; and killed by Node Manager. Then MR AM gets notified of the container status and diagnostics information through its heartbeat with RM.  However; it is possible that the diagnostics information never gets into .jhist file; so when the job completes; the diagnostics information associated with the failed task attempts is empty.  This makes it hard for users to root cause job failures that are often caused by memory leak.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Sat; 27 Aug 2016 00:06:30 +0000,Thu; 29 Sep 2016 16:23:35 +0000,Thu; 29 Sep 2016 16:06:56 +0000,,2.7.3,,,MAPREDUCE-4955,https://issues.apache.org/jira/browse/MAPREDUCE-6771
MAPREDUCE-6772,Sub-task,Major,applicationmaster;mrv2,Add MR Job Configurations for Containers reuse,This task adds configurations required for MR AM Container reuse feature.,Resolved,Fixed,,Devaraj K,Devaraj K,Thu; 1 Sep 2016 05:18:24 +0000,Tue; 25 Oct 2016 00:21:25 +0000,Mon; 24 Oct 2016 23:22:23 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6772
MAPREDUCE-6773,Sub-task,Major,applicationmaster;mrv2,Implement RM Container Reuse Requestor to handle the reuse containers for resource requests,Add RM Container Reuse Requestor which handles the reuse containers against the Job reource requests.,Resolved,Fixed,,Devaraj K,Devaraj K,Thu; 1 Sep 2016 06:26:08 +0000,Sun; 27 Nov 2016 15:43:19 +0000,Sun; 27 Nov 2016 15:43:17 +0000,,MR-6749,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6773
MAPREDUCE-6774,New Feature,Major,,Add support for HDFS erasure code policy to TestDFSIO,HDFS erasure code policy allows user to store directory and file to predefined erasure code policies. Currently only 3x replication is supported in TestDFSIO implementation. This is going to add an new option to enable tests of files with erasure code policy enabled.,Resolved,Fixed,,SammiChen,SammiChen,Tue; 6 Sep 2016 13:02:40 +0000,Sun; 18 Sep 2016 07:39:33 +0000,Sat; 17 Sep 2016 01:07:54 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6774
MAPREDUCE-6775,Bug,Major,,Fix MapReduce failures caused by default RPC engine changing,HADOOP-13218 changed the default RPC engine; which isn't inappropriate because MAPREDUCE-6706 isn't solved yet; supporting TaskUmbilicalProtocol to use ProtobufRPCEngine.  Jason Lowe reported the following errors:,Resolved,Invalid,,Kai Zheng,Kai Zheng,Wed; 7 Sep 2016 20:32:43 +0000,Wed; 7 Sep 2016 21:56:29 +0000,Wed; 7 Sep 2016 21:56:29 +0000,,3.0.0-alpha2,,,HADOOP-13218,https://issues.apache.org/jira/browse/MAPREDUCE-6775
MAPREDUCE-6776,Improvement,Major,client,yarn.app.mapreduce.client.job.max-retries should have a more useful default,The default is 0; so any communication failure results in a client failure.  Oozie doesn't like that.  If the RM is failing over and Oozie gets a communication failure; it assumes the target job has failed.  I propose raising the default to something modest like 3 or 5.  The default retry interval is 2s.,Resolved,Fixed,,Miklos Szegedi,Daniel Templeton,Mon; 12 Sep 2016 20:39:28 +0000,Fri; 7 Oct 2016 22:00:04 +0000,Fri; 7 Oct 2016 21:52:56 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6776
MAPREDUCE-6777,Bug,Trivial,,Typos in 4 log messages,"I am conducting research on log related bugs. I tried to make a tool to fix repetitive yet simple patterns of bugs that are related to logs. Typos in log messages are one of the reoccurring bugs. Therefore; I made a tool find typos in log statements. During my experiments; I managed to find the following typos in Hadoop MapReduce:  In file    LOG.info(""Storing state DB schedma version info "" + getCurrentVersion());  schedma should be schema",Resolved,Fixed,,Mehran Hassani,Mehran Hassani,Tue; 13 Sep 2016 14:58:29 +0000,Sat; 17 Sep 2016 05:23:31 +0000,Sat; 17 Sep 2016 04:52:56 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6777
MAPREDUCE-6778,Improvement,Minor,nodemanager,Provide way to limit MRJob's stdout/stderr size,"We can run job with huge amount of stdout stderr and causing undesired consequence.  The possible solution is to redirect Stdout's and Stderr's output to log4j in YarnChild. main method. In this case System.out and System.err streams will be redirected to log4j logger with  appender that will direct output in to stderr or stdout files with needed size limitation. Thereby we are able to limit log's size on the fly; having one backup rolling file (thanks to ContainerRollingLogAppender).  One of the syslog's size limitation approaches works the same way.  So; we can set limitation via new properties in mapred-site.xml: mapreduce.task.userlog.stderr.limit.kb mapreduce.task.userlog.stdout.limit.kb  Advantages of such solution:  	it allows us to restrict file sizes during job execution. 	we can see logs during job execution.    Disadvantages:  	It will work only for MRs jobs.    Is it appropriate solution for solving this problem; or is there something better?",Open,Unresolved,YARN-2231,Unassigned,Aleksandr Balitsky,Wed; 14 Sep 2016 07:59:19 +0000,Thu; 15 Sep 2016 14:03:43 +0000,,,2.7.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6778
HADOOP-13620,Bug,Blocker,,Mapreduce job failure on submission,Configure Hibench Try running Enhanced TestDFSIO     mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).  Job jar is not getting set and not uploaded to staging dir,Resolved,Resolved,,Sangjin Lee,Bibin A Chundatt,Thu; 15 Sep 2016 12:56:09 +0000,Mon; 31 Oct 2016 22:30:42 +0000,Thu; 15 Sep 2016 18:39:02 +0000,,3.0.0-alpha1,,,HADOOP-13776,https://issues.apache.org/jira/browse/HADOOP-13620
MAPREDUCE-6780,Task,Major,,Add support for striping files in benchmarking of TeraGen and TeraSort,So far; HDFS file with erasure code policy doesn't support hflush and hsync operation. This task is going to find a way to support writing data to erasure code policy files in TeraGen and TeraSort.,Resolved,Fixed,,SammiChen,SammiChen,Wed; 21 Sep 2016 07:39:47 +0000,Sun; 9 Oct 2016 09:59:35 +0000,Sun; 9 Oct 2016 09:35:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6780
MAPREDUCE-6781,Sub-task,Major,applicationmaster;mrv2,YarnChild should wait for another task when reuse is enabled,nan,Open,Unresolved,,Devaraj K,Devaraj K,Thu; 22 Sep 2016 06:11:13 +0000,Thu; 22 Sep 2016 06:14:42 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6781
MAPREDUCE-6782,Bug,Major,jobhistoryserver,JHS task page search based on each individual column not working,Submit mapreduce pi job with 10 maps In Jobs history server selection completed job Select maps to Task Page for job Search in individual column fields   Expected Search should be working fine in task page for individual columns  Actual Search not working for individual column in task page In Attempts page the same search is working fine,Resolved,Fixed,,Ajith S,Bibin A Chundatt,Fri; 23 Sep 2016 06:33:54 +0000,Tue; 8 Nov 2016 09:40:14 +0000,Tue; 8 Nov 2016 09:33:41 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6782
MAPREDUCE-6783,Bug,Major,nodemanager,Default setting 'inheritParentEnv=false' caused mr executor failed to initialize,"MR default classpath depend on the ""HADOOP_MAPRED_HOME"" ; defined at MRJobConfig#DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH. On 3.0.0.alpha1 ; contain ""Remove parent's env vars from child processes "" which commit by Robert Kanter ;but it's seem not found in jira or release note. DefaultContainerExecutor  DefaultLinuxContinerExecutor default the 'inheritParentEnv' as false;there is no any approach to set the ""HADOOP_MAPRED_HOME"" ;the AM failed by ""Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster""",Resolved,Duplicate,MAPREDUCE-6704,Unassigned,DENG FEI,Wed; 28 Sep 2016 11:51:41 +0000,Fri; 30 Sep 2016 02:54:41 +0000,Fri; 30 Sep 2016 02:54:41 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6783
MAPREDUCE-6784,Sub-task,Major,applicationmaster;mrv2,JobImpl state changes for containers reuse,Add JobImpl state changes for supporting reusing of containers.,Open,Unresolved,,Devaraj K,Devaraj K,Wed; 28 Sep 2016 17:38:31 +0000,Sat; 26 Nov 2016 05:33:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6784
MAPREDUCE-6785,Sub-task,Major,applicationmaster;mrv2,ContainerLauncherImpl support for reusing the containers,Add support to Container Launcher for reuse of the containers.,Resolved,Fixed,,Naganarasimha G R,Devaraj K,Wed; 28 Sep 2016 17:41:37 +0000,Tue; 4 Apr 2017 23:05:26 +0000,Tue; 4 Apr 2017 23:05:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6785
MAPREDUCE-6786,Sub-task,Major,applicationmaster;mrv2,TaskAttemptImpl state changes for containers reuse,Update TaskAttemptImpl to support the reuse of containers.,Open,Unresolved,,Naganarasimha G R,Devaraj K,Wed; 28 Sep 2016 17:43:41 +0000,Tue; 29 Nov 2016 15:31:09 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6786
MAPREDUCE-6787,Improvement,Major,jobhistoryserver,Allow job_conf.xml to be downloadable on the job overview page in JHS,The job overview page in JHS provides the path to the job.xml file; but it is not a link that users can click on to download the job xml file directly from JHS. We could provide a download link in JHS for better usability.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Thu; 29 Sep 2016 03:21:39 +0000,Wed; 29 Mar 2017 22:21:21 +0000,Fri; 2 Dec 2016 01:32:01 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6787
MAPREDUCE-6788,Bug,Major,,core-site settings do not propagate correctly when running an MR job.,Trying to run a sleep job with DEBUG logs on produces the following error:    DEBUG impl.TimelineClientImpl: Cannot load customized ssl related configuration. Fallback to system-generic settings.  jar:  conf   (Migrated from AMBARI-14205),Open,Unresolved,,Unassigned,David Tucker,Thu; 29 Sep 2016 17:11:31 +0000,Thu; 10 Nov 2016 17:26:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6788
MAPREDUCE-6789,Bug,Major,test,Fix TestAMWebApp failure,TestAMWebApp.testMRWebAppRedirection fails.,Resolved,Fixed,,Daniel Templeton,Akira Ajisaka,Tue; 4 Oct 2016 12:09:12 +0000,Thu; 6 Oct 2016 07:28:17 +0000,Thu; 6 Oct 2016 06:59:57 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6789
MAPREDUCE-6790,Improvement,Major,build,Update jackson from 1.9.13 to 2.x in hadoop-mapreduce,Sub-task of HADOOP-13332.,Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Tue; 4 Oct 2016 06:47:09 +0000,Mon; 7 Nov 2016 02:40:18 +0000,Mon; 7 Nov 2016 02:21:00 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6790
MAPREDUCE-6791,Bug,Minor,mrv2,remove unnecessary dependency from hadoop-mapreduce-client-jobclient to hadoop-mapreduce-client-shuffle,nan,Resolved,Fixed,,Haibo Chen,Haibo Chen,Tue; 11 Oct 2016 17:43:22 +0000,Thu; 12 Jan 2017 00:37:17 +0000,Wed; 19 Oct 2016 01:00:52 +0000,,3.0.0-alpha1,Incompatible,,,https://issues.apache.org/jira/browse/MAPREDUCE-6791
MAPREDUCE-6792,Improvement,Major,client,Allow user's full principal name as owner of MapReduce staging directory in JobSubmissionFiles#JobStagingDir(),Background -  Currently; JobSubmissionFiles#JobStagingDir() assumes that file owner returned as part of FileSystem#getFileStatus() is always user's short principal name; which is true for HDFS. But; some file systems which are HDFS compatible like Azure Data Lake Store (ADLS)  and work in multi tenant environment can have users with same names belonging to different domains. For example; user1@company1.com and user1@company2.com. It will be ambiguous; if FileSystem#getFileStatus() returns only the user's short principal name (without domain name) as the owner of the file directory.   The following code block allows only short user principal name as owner. It simply fails saying that ownership on the staging directory is not as expected; if owner returned by the FileStatus#getOwner() is not equal to short principal name of the current user.   The proposal is to remove the strict restriction on short principal name by allowing the user's full principal name as owner of staging area directory in JobSubmissionFiles#JobStagingDir().,Resolved,Fixed,,Santhosh G Nayak,Santhosh G Nayak,Thu; 13 Oct 2016 07:10:11 +0000,Tue; 25 Oct 2016 18:40:36 +0000,Tue; 25 Oct 2016 18:19:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6792
MAPREDUCE-6793,Bug,Trivial,task,io.sort.factor code default and mapred-default.xml values inconsistent,The actual default value in mapred-default.xml:    However; MapTask and MergeManagerImpl; are coded with:,Resolved,Fixed,,Prabhu Joseph,Gera Shegalov,Fri; 14 Oct 2016 22:02:20 +0000,Tue; 22 Nov 2016 00:10:02 +0000,Mon; 21 Nov 2016 16:43:55 +0000,,2.6.5;3.0.0-alpha1,noob,,,https://issues.apache.org/jira/browse/MAPREDUCE-6793
MAPREDUCE-6794,Improvement,Major,,Remove unused properties from TTConfig.java,There are many unused properties in TTConfig.  Let's remove them.,Patch Available,Unresolved,,Akira Ajisaka,Akira Ajisaka,Mon; 17 Oct 2016 04:39:44 +0000,Tue; 14 Nov 2017 19:37:09 +0000,,,,,,MAPREDUCE-6795;MAPREDUCE-6796,https://issues.apache.org/jira/browse/MAPREDUCE-6794
MAPREDUCE-6795,Improvement,Major,documentation,Update the document for JobConf#setNumReduceTasks,The following document is for MRv1. We should update the document for MapReduce on YARN.,Resolved,Fixed,,Yiqun Lin,Akira Ajisaka,Mon; 17 Oct 2016 05:11:23 +0000,Wed; 2 Nov 2016 12:44:03 +0000,Tue; 1 Nov 2016 11:53:35 +0000,,,,,MAPREDUCE-6794,https://issues.apache.org/jira/browse/MAPREDUCE-6795
MAPREDUCE-6796,Improvement,Major,,Remove unused properties from JTConfig.java,JobTracker-side of MAPREDUCE-6794. There are many unused properties in JTConfig.  Let's remove them.,Resolved,Fixed,,Haibo Chen,Akira Ajisaka,Mon; 17 Oct 2016 09:14:47 +0000,Fri; 4 Nov 2016 19:35:11 +0000,Fri; 4 Nov 2016 18:51:28 +0000,,,,,MAPREDUCE-6794,https://issues.apache.org/jira/browse/MAPREDUCE-6796
MAPREDUCE-6797,Bug,Critical,jobhistoryserver,Job history server scans can become blocked on a single; slow entry,There is one more piece of code in HistoryFileManager where Synchronized keyword on HistoryFileInfo need to be removed. The JobHistoryServer contention issue is hit on our environment where stacktrace (attached) shows the HistoryFileManager$JobListCache.addIfAbsent unnecessarily waiting to lock on HistoryFileInfo.  Synchronized on isMovePending and didMoveFail has been removed by Mapreduce-6684.,Resolved,Fixed,,Prabhu Joseph,Prabhu Joseph,Wed; 19 Oct 2016 11:39:20 +0000,Mon; 14 Nov 2016 20:40:47 +0000,Mon; 14 Nov 2016 20:37:48 +0000,,2.4.0;2.8.0,,,MAPREDUCE-6684,https://issues.apache.org/jira/browse/MAPREDUCE-6797
MAPREDUCE-6798,Bug,Major,jobhistoryserver,Fix intermittent failure of TestJobHistoryParsing.testJobHistoryMethods(),TestJobHistoryParsing.testJobHistoryMethods() failed.  expected:1 but was:0  779),Resolved,Fixed,,Haibo Chen,Haibo Chen,Wed; 19 Oct 2016 19:38:54 +0000,Thu; 27 Oct 2016 15:24:15 +0000,Thu; 27 Oct 2016 10:16:00 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6798
MAPREDUCE-6799,Improvement,Minor,documentation;jobhistoryserver,Document mapreduce.jobhistory.webapp.https.address in mapred-default.xml,The default port number is 19890 but it is not documented.,Resolved,Fixed,,Yiqun Lin,Akira Ajisaka,Fri; 21 Oct 2016 07:33:04 +0000,Mon; 31 Oct 2016 06:40:40 +0000,Mon; 31 Oct 2016 06:20:03 +0000,,,newbie;supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-6799
MAPREDUCE-6800,Improvement,Minor,mrv2,FileInputFormat.singleThreadedListStatus to use listFiles(recursive),"FileInputFormat.singleThreadedListStatus does recursive directory walks to pick files to scan. This is very inefficient on object stores; and can be bypassed if listFiles(recursive=true) can be used instead.  Based on the experience of SPARK-2984; it should also be resilient to a source file going away during the iteration; downgrading an FNFE to a ""skip that nonexistent path""",Open,Unresolved,,Unassigned,Steve Loughran,Mon; 24 Oct 2016 14:39:47 +0000,Mon; 24 Oct 2016 14:48:07 +0000,,,2.7.3,,,SPARK-2984,https://issues.apache.org/jira/browse/MAPREDUCE-6800
MAPREDUCE-6802,Bug,Major,mrv2,TestKill.testKillJob() fails intermittently on Power,Running org.apache.hadoop.mapreduce.v2.app.TestKill Tests run: 5; Failures: 1; Errors: 0; Skipped: 0; Time elapsed: 9.86 sec &lt; FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestKill testKillJob(org.apache.hadoop.mapreduce.v2.app.TestKill)  Time elapsed: 0.377 sec  &lt; FAILURE!  99)   Results :  Failed tests:  TestKill.testKillJob:99 Task state not correct expected:KILLED but was:NEW  Tests run: 5; Failures: 1; Errors: 0; Skipped: 0,Resolved,Duplicate,MAPREDUCE-6801,Unassigned,Yussuf Shaikh,Thu; 27 Oct 2016 05:48:14 +0000,Wed; 16 Nov 2016 22:59:58 +0000,Wed; 16 Nov 2016 22:59:58 +0000,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6802
MAPREDUCE-6803,Improvement,Major,applicationmaster,MR AppMaster should assign container that is closest to the data,Currently; given a Container request for a host; ResourceManager allocates a Container with following priorities (RMContainerAllocator. performs exact matching on rack id to find a rack local host. Alternatively; we can perform longest-prefix matching to find a closest host. Using the same network architecture as above; with longest-prefix matching; hosts are selected with the following priorities:  h1  h2  h3 or h4  h5 or h6 or h7 or h8,Patch Available,Unresolved,,Unassigned,jaehoon ko,Fri; 26 Jun 2015 07:03:04 +0000,Thu; 3 Nov 2016 12:59:20 +0000,,,,oct16-medium,,,https://issues.apache.org/jira/browse/MAPREDUCE-6803
MAPREDUCE-6804,Test,Minor,test,Add timeout when starting JobHistoryServer in MiniMRYarnCluster,This JIRA is to follow up a TODO in MiniMRYarnCluster.  TODO Add a timeout. State.STOPPED check ? I think State.STOPPED check is not needed. I do not see the value to check STOPPED state here.,Resolved,Fixed,,Andras Bokor,Andras Bokor,Thu; 26 May 2016 12:24:04 +0000,Fri; 18 Nov 2016 14:25:11 +0000,Wed; 16 Nov 2016 15:30:22 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6804
MAPREDUCE-6805,Bug,Minor,mrv2,Negative Array Exception while reducer fetch mapper output,MapReduce job stuck with a Negative Array Size exception thrown by the reducer;lead to MR job failed stack trace:  2016-10-28 08:01:16;882 WARN main org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:web_vr (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3 2016-10-28 08:01:16;883 WARN main org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3   org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 193),Resolved,Duplicate,MAPREDUCE-6724,Unassigned,shenxianqiang,Fri; 28 Oct 2016 05:13:42 +0000,Fri; 28 Oct 2016 14:38:44 +0000,Fri; 28 Oct 2016 14:38:43 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6805
MAPREDUCE-6806,Bug,Minor,contrib/gridmix,Trim configuration values in gridmix/DistributedCacheEmulator.java,The current implementation of DistributedCacheEmulator. in gridmix does not follow the practice of trimming configuration values. This leads to errors if users set values containing space or newline.  see the previous commits as reference (just list a few): HADOOP-6578. Configuration should trim whitespace around a lot of value types HADOOP-6534. Trim whitespace from directory lists initializing Patch is available against trunk HDFS-9708. FSNamesystem.initAuditLoggers() doesn't trim classnames HDFS-2799. Trim fs.checkpoint.dir values. YARN-3395. FairScheduler: Trim whitespaces when using username for queuename. YARN-2869. CapacityScheduler should trim sub queue names when parse configuration.  Patch is available against trunk (tested):,Patch Available,Unresolved,,Unassigned,Tianyin Xu,Tue; 1 Nov 2016 05:21:10 +0000,Tue; 1 Nov 2016 05:55:23 +0000,,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6806
MAPREDUCE-6807,Bug,Trivial,client;mrv1,mapred pipes usage is non-standard and redundant,"Running ""mapred pipes"" returns:     No Hadoop CLI uses  Linux man page styling:    It should be look like this since the comments are really redundant:     then the parameters can be expanded upon in the section below.",Open,Unresolved,,Ajith S,Grant Sohn,Thu; 3 Nov 2016 21:06:53 +0000,Tue; 8 Nov 2016 08:37:36 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6807
MAPREDUCE-6808,Bug,Major,,Log map attempts as part of shuffle handler audit log,With the introduction tez; multiple unrelated reducers in the same job will have the same id. The audit log won't be able to distinguish which map attempt the reduce was fetching. This jira is to discuss the  possibility to add map attempts logging to distinguish between the two.,Resolved,Fixed,,Gerg   P  sztor,Jonathan Eagles,Mon; 7 Nov 2016 20:59:30 +0000,Tue; 19 Sep 2017 14:10:50 +0000,Wed; 25 Jan 2017 22:34:00 +0000,,3.0.0-alpha1,,,TEZ-3532,https://issues.apache.org/jira/browse/MAPREDUCE-6808
MAPREDUCE-6809,Sub-task,Major,applicationmaster;mrv2,Create ContainerRequestor interface and refactor RMContainerRequestor to use it,As per the discussion in MAPREDUCE-6773; create a ContainerRequestor interface and refactor RMContainerRequestor to use this interface.,Resolved,Fixed,,Devaraj K,Devaraj K,Tue; 8 Nov 2016 05:25:58 +0000,Sat; 12 Nov 2016 07:03:31 +0000,Sat; 12 Nov 2016 07:01:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6809
MAPREDUCE-6810,Task,Major,,hadoop-mapreduce-client-nativetask compilation broken on GCC-6.2.1,I recently upgraded from Fedora 22 to Fedora 25 (I'm assuming this means the latest and greatest compilers; cmake etc.) My trunk build failed with this error:    https: sect-Changes_in_Version_3.0-GCC.html This applies to any string literal followed without white space by some macro. To fix this; add some white space between the string literal and the macro name.,Resolved,Fixed,,Ravi Prakash,Ravi Prakash,Tue; 15 Nov 2016 22:07:05 +0000,Wed; 30 Nov 2016 19:01:03 +0000,Wed; 30 Nov 2016 18:48:33 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6810
MAPREDUCE-6811,Bug,Major,test,TestPipeApplication#testSubmitter fails after HADOOP-13802,Reference   https: ,Resolved,Fixed,,Brahma Reddy Battula,Brahma Reddy Battula,Wed; 16 Nov 2016 14:26:11 +0000,Thu; 17 Nov 2016 01:52:03 +0000,Wed; 16 Nov 2016 19:41:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6811
YARN-5892,Improvement,Major,capacityscheduler,Support user-specific minimum user limit percentage in Capacity Scheduler,Currently; in the capacity scheduler; the minimum-user-limit-percent property is per queue. A cluster admin should be able to set the minimum user limit percent on a per-user basis within the queue.  This functionality is needed so that when intra-queue preemption is enabled (YARN-4945   YARN-2113); some users can be deemed as more important than other users; and resources from VIP users won't be as likely to be preempted.  For example; if the getstuffdone queue has a MULP of 25 percent; but user jane is a power user of queue getstuffdone and needs to be guaranteed 75 percent; the properties for getstuffdone and jane would look like this:,Resolved,Fixed,,Eric Payne,Eric Payne,Wed; 16 Nov 2016 20:32:17 +0000,Fri; 1 Sep 2017 14:00:50 +0000,Fri; 28 Jul 2017 14:41:18 +0000,,,,,YARN-5889,https://issues.apache.org/jira/browse/YARN-5892
YARN-5913,Improvement,Minor,resourcemanager,"Consolidate ""resource"" and ""amResourceRequest"" in ApplicationSubmissionContext",Usage of these two variables overlaps and causes confusion.,Open,Unresolved,,Unassigned,Yufei Gu,Fri; 18 Nov 2016 17:46:14 +0000,Tue; 12 Sep 2017 12:12:18 +0000,,,,newbie,,,https://issues.apache.org/jira/browse/YARN-5913
MAPREDUCE-6814,Improvement,Minor,,mapred's FileAlreadyExistsException should be deprecated in favor of hadoop-common's one.,Mapred's FileAlreadyExistsException was deprecated with MAPREDUCE-963 but later on it was un-deprecate with MAPREDUCE-1735 MAPREDUCE-3771 Mapred 1 API (including FAEE) was un-deprecated. Since FAEE was deprecated regardless of point 2 it shouldn't have been un-deprecated.,Open,Unresolved,,Andras Bokor,Andras Bokor,Tue; 22 Nov 2016 10:10:03 +0000,Fri; 24 Feb 2017 16:03:01 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6814
MAPREDUCE-6815,Bug,Major,mrv2,Fix flaky TestKill.testKillTask(),Error Message Job state is not correct (timedout) expected:SUCCEEDED but was:ERROR Stacktrace  124),Resolved,Fixed,MAPREDUCE-6898,Haibo Chen,Haibo Chen,Fri; 2 Dec 2016 00:30:37 +0000,Fri; 16 Jun 2017 19:52:15 +0000,Fri; 2 Dec 2016 17:31:00 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6815
MAPREDUCE-6816,Bug,Blocker,webapps,Progress bars in Web UI always at 100% ,"YARN web UI always shows progress bars at 100% (see screenshot; progress of the reduce step is roughly at 40.00%). I opened the HTML source code to check (also see screenshot); and it seems the problem is that it uses ""%%"" ;which cannot be recognized. This is due to the output of StringUtils.format() contains '%'; while in *Block. use  join() add an extra '%'.",Resolved,Fixed,,Shen Yinjie,Shen Yinjie,Fri; 2 Dec 2016 07:57:00 +0000,Tue; 6 Dec 2016 22:00:12 +0000,Tue; 6 Dec 2016 21:47:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6816
MAPREDUCE-6817,Bug,Major,jobhistoryserver,The format of job start time in JHS is different from those of submit and finish time,nan,Resolved,Fixed,,Haibo Chen,Haibo Chen,Fri; 2 Dec 2016 20:44:23 +0000,Wed; 7 Dec 2016 22:00:15 +0000,Wed; 7 Dec 2016 21:40:11 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6817
MAPREDUCE-6818,Sub-task,Major,,Remove direct reference to TimelineClientImpl,Sangjin Lee's quick audit shows that things that are referencing TimelineClientImpl directly today:  JobHistoryFileReplayMapperV1 (MR) SimpleEntityWriterV1 (MR) TestDistributedShell (DS) TestDSAppMaster (DS) TestNMTimelinePublisher (node manager) TestTimelineWebServicesWithSSL (AHS)  This is not the right way to use TimelineClient and we should avoid direct reference to TimelineClientImpl as much as possible.   Any newcomers to the community are more than welcome to take this. If this remains unassigned for ~24hrs I'll jump in and do a quick fix.,Resolved,Fixed,,Li Lu,Li Lu,Tue; 6 Dec 2016 21:34:37 +0000,Sat; 21 Oct 2017 06:28:29 +0000,Fri; 9 Dec 2016 02:20:39 +0000,,,newbie++,,YARN-4675,https://issues.apache.org/jira/browse/MAPREDUCE-6818
MAPREDUCE-6819,Improvement,Minor,test,Replace UTF8 with Text in MRBench,UTF8 class has been deprecated for a long time. We can use Text class instead of UTF8 in MRBench. ,Resolved,Fixed,,Peter Bacsko,Akira Ajisaka,Fri; 9 Dec 2016 05:57:17 +0000,Tue; 17 Jan 2017 09:46:08 +0000,Tue; 17 Jan 2017 09:00:03 +0000,,,newbie,,HADOOP-13878,https://issues.apache.org/jira/browse/MAPREDUCE-6819
MAPREDUCE-6820,Bug,Minor,documentation,Fix dead links in Job relevant classes,There are some dead links in Job relevant classes. For example in class JobConf     Here the link is not correct. We should make a fix.,Resolved,Fixed,,Yiqun Lin,Yiqun Lin,Fri; 9 Dec 2016 09:52:38 +0000,Sat; 10 Dec 2016 03:38:56 +0000,Sat; 10 Dec 2016 01:58:08 +0000,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6820
MAPREDUCE-6821,Bug,Minor,,Fix javac warning related to the deprecated APIs after upgrading Jackson,We should update the deprecated APIs after Jackson upgraded. This issue is similar to HDFS-11233. In MAPREDUCE; there is just one place using deprecated API. We can updated the code here.,Resolved,Fixed,,Yiqun Lin,Yiqun Lin,Mon; 12 Dec 2016 05:19:08 +0000,Tue; 13 Dec 2016 18:02:25 +0000,Tue; 13 Dec 2016 05:22:54 +0000,,3.0.0-alpha2,,,HDFS-11233,https://issues.apache.org/jira/browse/MAPREDUCE-6821
MAPREDUCE-6822,Bug,Major,scripts,should set HADOOP_JOB_HISTORYSERVER_HEAPSIZE only if it's empty on branch2,In mapred-env; set HADOOP_JOB_HISTORYSERVER_HEAPSIZE 1000 by default; That is incorrect. We should set it 1000 by default only if it's empty.  Because if you run  'HADOOP_JOB_HISTORYSERVER_HEAPSIZE =512 $HADOOP_HOME mr-jobhistory-daemon.sh start historyserver'; HADOOP_JOB_HISTORYSERVER_HEAPSIZE  will be set 1000; rather than 512.,Resolved,Fixed,,Unassigned,Fei Hui,Tue; 13 Dec 2016 02:45:27 +0000,Wed; 14 Dec 2016 02:18:14 +0000,Tue; 13 Dec 2016 21:10:08 +0000,,2.9.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6822
MAPREDUCE-6823,Bug,Major,mrv2,FileOutputFormat to support configurable PathOutputCommitter factory,"In HADOOP-13786 I'm adding a custom subclass for FileOutputFormat; one which can talk direct to the S3A Filesystem for more efficient operations; better failure modes; and; most critically; as part of HADOOP-13345; atomic commit of output. The normal committer relies on directory rename() being atomic for this; for S3 we don't have that luxury.  To support a custom committer; we need to be able to tell FileOutputFormat (and implicitly; all subclasses which don't have their own custom committer); to use our new S3AOutputCommitter.  I propose:    	FileOutputFormat takes a factory to create committers. 	The factory to take a URI and TaskAttemptContext and return a committer 	the default implementation always returns a FileOutputCommitter 	A configuration option allows a new factory to be named 	An S3AOutputCommitterFactory to return a  FileOutputCommitter or new S3AOutputCommitter depending upon the URI of the destination.    Note that MRv1 already supports configurable committers; this is only the V2 API",Resolved,Fixed,,Steve Loughran,Steve Loughran,Wed; 14 Dec 2016 16:25:55 +0000,Wed; 22 Nov 2017 17:40:44 +0000,Wed; 22 Nov 2017 17:40:44 +0000,,3.0.0-alpha2,,,MAPREDUCE-6961,https://issues.apache.org/jira/browse/MAPREDUCE-6823
MAPREDUCE-6824,Bug,Trivial,,TaskAttemptImpl#createCommonContainerLaunchContext is longer than 150 lines,.  752: private static ContainerLaunchContext createCommonContainerLaunchContext(:3: Method length is 172 lines (max allowed is 150).  TaskAttemptImpl#createCommonContainerLaunchContext is longer than 150 lines and needs to be refactored.,Resolved,Fixed,,Chris Trezzo,Chris Trezzo,Fri; 16 Dec 2016 21:34:53 +0000,Mon; 17 Apr 2017 15:40:14 +0000,Wed; 5 Apr 2017 07:46:54 +0000,,,newbie,,MAPREDUCE-5951,https://issues.apache.org/jira/browse/MAPREDUCE-6824
MAPREDUCE-6825,Bug,Trivial,,YARNRunner#createApplicationSubmissionContext method is longer than 150 lines,.  341: public ApplicationSubmissionContext createApplicationSubmissionContext(:3: Method length is 249 lines (max allowed is 150).  YARNRunner#createApplicationSubmissionContext is longer than 150 lines and needs to be refactored.,Resolved,Fixed,,Gergely Nov  k,Chris Trezzo,Fri; 16 Dec 2016 21:37:09 +0000,Thu; 23 Feb 2017 00:32:22 +0000,Wed; 22 Feb 2017 23:44:24 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6825
MAPREDUCE-6826,Bug,Major,,Job fails with InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SUCCEEDED,This happens if a container is preempted by scheduler after job starts committing. And this exception in turn leads to application being marked as FAILED in YARN. I think we can probably ignore JOB_TASK_COMPLETED event while JobImpl state is COMMITTING or SUCCEEDED as job is in the process of finishing. Also is there any point in attempting to scheduler another task attempt if job is already in COMMITTING or SUCCEEDED state.,Open,Unresolved,,Varun Saxena,Varun Saxena,Fri; 23 Dec 2016 06:48:28 +0000,Fri; 10 Mar 2017 18:32:27 +0000,,,2.7.2,,,MAPREDUCE-5400,https://issues.apache.org/jira/browse/MAPREDUCE-6826
MAPREDUCE-6827,Bug,Major,task,Failed to traverse Iterable values the second time in reduce() method,Failed to traverse Iterable values the second time in reduce() method  The following code is a reduce() method (of WordCount):    After running it; we got the result that all sums were zero!  After debugging; it was found that the second foreach-loop was not executed; and the root cause was the returned value of Iterable.iterator(); it returned the same instance in the two calls called by foreach-loop. In general; Iterable.iterator() should return a new instance in each call; such as ArrayList.iterator().,Resolved,Not A Problem,,Unassigned,javaloveme,Fri; 30 Dec 2016 11:57:39 +0000,Wed; 4 Jan 2017 11:12:33 +0000,Tue; 3 Jan 2017 18:33:17 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6827
MAPREDUCE-6828,Bug,Minor,test,TestMiniMRChildTask is failing in branch-2 and branch-2.8 on mac,nan,Open,Unresolved,,Unassigned,Akira Ajisaka,Thu; 5 Jan 2017 08:39:47 +0000,Thu; 5 Jan 2017 08:58:47 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6828
MAPREDUCE-6829,Improvement,Major,mrv2,Add peak memory usage counter for each task,Each task has counters PHYSICAL_MEMORY_BYTES and VIRTUAL_MEMORY_BYTES; which are snapshots of memory usage of that task. They are not sufficient for users to understand peak memory usage by that task; e.g. in order to diagnose task failures; tune job parameters or change application design. This new feature will add two more counters for each task: PHYSICAL_MEMORY_BYTES_MAX and VIRTUAL_MEMORY_BYTES_MAX.  This JIRA has the same feature from MAPREDUCE-4710.  I file this new YARN JIRA since MAPREDUCE-4710 is pretty old one from MR 1.x era; it more or less assumes a branch-1 architecture; should be close at this point.,Resolved,Fixed,MAPREDUCE-6922,Miklos Szegedi,Yufei Gu,Thu; 5 May 2016 16:44:16 +0000,Mon; 31 Jul 2017 21:49:48 +0000,Thu; 26 Jan 2017 19:14:56 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6829
YARN-6061,Improvement,Major,resourcemanager,Add an UncaughtExceptionHandler for critical threads in RM,There are several threads in fair scheduler. The thread will quit when there is a runtime exception inside it. We should bring down the RM when that happens. Otherwise; there may be some weird behavior in RM.,Resolved,Fixed,,Yufei Gu,Yufei Gu,Fri; 6 Jan 2017 01:04:54 +0000,Fri; 21 Apr 2017 21:34:24 +0000,Tue; 14 Feb 2017 21:44:38 +0000,,,,,,https://issues.apache.org/jira/browse/YARN-6061
MAPREDUCE-6831,Test,Major,mrv2,Flaky test TestJobImpl.testKilledDuringKillAbort,The test case TestJobImpl.testKilledDuringKillAbort() is flaky.  Example of a failure:            Reproduction: insert a Thread.sleep(50); after job.handle(new JobStartEvent(jobId));,Resolved,Fixed,,Peter Bacsko,Peter Bacsko,Mon; 9 Jan 2017 15:19:21 +0000,Wed; 7 Jun 2017 22:29:36 +0000,Tue; 17 Jan 2017 16:06:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6831
MAPREDUCE-6832,Bug,Critical,,Counter name is truncated regardless the configuration,For now I have hadoop job which creates counters with pretty big name. For example; the following one: stats.counters.server-name.job.job-name.mapper.site.site-name.qualifier.qualifier-name.super-long-string-which-is-not-quantity-within-standard-limits. This counter is truncated on web interface and is returned truncated by getName() method. I've found out that hadoop have limitations on the counter max name and mapreduce.job.counters.counter.name.max is for configuring this limit. So I incremented this to 500 and web interface now shows full counter name. But getName() of the counter still returns truncated name. This seems like a bug as result of getName() call should be consistent.,Open,Unresolved,,Unassigned,Vladimir Tarasov,Wed; 18 Jan 2017 09:09:18 +0000,Mon; 30 Jan 2017 09:06:03 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6832
MAPREDUCE-6833,Sub-task,Major,applicationmaster;mrv2,Display only corresponding Task logs for each task attempt in AM and JHS Web UI,When the container gets reused for multiple tasks; Logs get generated in the same container log file. At present Task Attempt log is linked to Container log; In UI for each attempt it shows the whole  container log file. This task is to handle the display of the corresponding Task logs for each task attempt in AM and JHS Web UI.,Open,Unresolved,,Devaraj K,Devaraj K,Thu; 19 Jan 2017 18:35:33 +0000,Thu; 19 Jan 2017 18:35:33 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6833
MAPREDUCE-6834,Bug,Critical,resourcemanager;yarn,"MR application fails with ""No NMToken sent"" exception after MRAppMaster recovery","Steps to reproduce: 1) Submit MR application (for example PI app with 50 containers) 2) Find MRAppMaster process id for the application  3) Kill MRAppMaster by kill -9 command  Expected: ResourceManager launch new MRAppMaster container and MRAppAttempt and application finish correctly  Actually: After launching new MRAppMaster and MRAppAttempt the application fails with the following exception:     Problem: When RMCommunicator sends ""registerApplicationMaster"" request to RM; RM generates NMTokens for new RMAppAttempt. Those new NMTokens are transmitted to RMCommunicator in RegisterApplicationMasterResponse  (getNMTokensFromPreviousAttempts method). But we don't handle these tokens in RMCommunicator.register method. RM don't transmit tese tokens again for other allocated requests; but we don't have these tokens in NMTokenCache. Accordingly we get ""No NMToken sent for node"" exception.  I have found that this issue appears after changes from the https: 9b272ccae78918e7d756d84920a9322187d61eed   I tried to do the same scenario without the commit and application completed successfully after RMAppMaster recovery",Open,Unresolved,,Aleksandr Balitsky,Aleksandr Balitsky,Thu; 22 Dec 2016 15:44:31 +0000,Fri; 17 Mar 2017 17:11:37 +0000,,,2.7.0,,,YARN-3112,https://issues.apache.org/jira/browse/MAPREDUCE-6834
MAPREDUCE-6835,Bug,Major,,WARN io.ReadaheadPool: Failed readahead on ifile,"Whenever a MapReduce job is executed; the warning of Bad file desciptor is displayed. This mostly happens when the Combiner Reducer is running. This bug is resulting in incorrect results for the reducers where the warning is shown.  The following is the entire job execution log.   INFO mapreduce.Job: Counters: 35 	File System Counters 		FILE: Number of bytes read=34276 		FILE: Number of bytes written=1980499 		FILE: Number of read operations=0 		FILE: Number of large read operations=0 		FILE: Number of write operations=0 		HDFS: Number of bytes read=2482554234 		HDFS: Number of bytes written=16 		HDFS: Number of read operations=61 		HDFS: Number of large read operations=0 		HDFS: Number of write operations=8 	Map-Reduce Framework 		Map input records=5683048 		Map output records=5683047 		Map output bytes=73879611 		Map output materialized bytes=105 		Input split bytes=625 		Combine input records=5683047 		Combine output records=5 		Reduce input groups=1 		Reduce shuffle bytes=105 		Reduce input records=5 		Reduce output records=1 		Spilled Records=10 		Shuffled Maps =5 		Failed Shuffles=0 		Merged Map outputs=5 		GC time elapsed (ms)=2068 		Total committed heap usage (bytes)=2224029696 	Shuffle Errors 		BAD_ID=0 		CONNECTION=0 		IO_ERROR=0 		WRONG_LENGTH=0 		WRONG_MAP=0 		WRONG_REDUCE=0 	File Input Format Counters  		Bytes Read=570167997 	File Output Format Counters  		Bytes Written=16",Open,Unresolved,,Unassigned,Krishna Kumar Nanjundaprasad,Tue; 24 Jan 2017 12:15:09 +0000,Tue; 11 Apr 2017 11:38:58 +0000,,,2.7.3,,,YARN-4322,https://issues.apache.org/jira/browse/MAPREDUCE-6835
MAPREDUCE-6836,Bug,Minor,webapps,exception thrown when accessing the job configuration web UI,When I navigate the MR job web UI and click the configuration link; the AM shows an exception:    The web page itself renders fine.,Resolved,Fixed,,Haibo Chen,Sangjin Lee,Wed; 25 Jan 2017 22:40:58 +0000,Thu; 30 Mar 2017 18:19:18 +0000,Thu; 30 Mar 2017 17:57:24 +0000,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6836
MAPREDUCE-6837,Improvement,Major,mrv2,Add an equivalent to Crunch's Pair class,Crunch has this great Pair class (https: Pair.html) that saves one from constantly implementing composite writables.  It seems silly that we still don't have an equivalent in MR.  I would like to see a new class with the following API:     With such a class; implementing a secondary sort would mean just implementing a custom grouping comparator.  That comparator could also be implemented as part of this JIRA:     Or some such.  Crunch also provides Tuple3; Tuple4; and TupleN classes; but I don't think we need to add equivalents.  If someone really wants that capability; they can nest composite keys.  Don't forget to add unit tests!,Patch Available,Unresolved,,Peter Cseh,Daniel Templeton,Thu; 26 Jan 2017 15:09:49 +0000,Thu; 21 Sep 2017 15:24:40 +0000,,,,newbie++,,,https://issues.apache.org/jira/browse/MAPREDUCE-6837
MAPREDUCE-6838,Sub-task,Major,,[ATSv2 Security] Add timeline delegation token received in allocate response to UGI,nan,Resolved,Fixed,,Varun Saxena,Varun Saxena,Mon; 30 Jan 2017 12:23:07 +0000,Sat; 21 Oct 2017 06:31:17 +0000,Tue; 22 Aug 2017 05:28:01 +0000,,,yarn-5355-merge-blocker,,,https://issues.apache.org/jira/browse/MAPREDUCE-6838
MAPREDUCE-6839,Bug,Major,test,TestRecovery.testCrashed failed,TestRecovery#testCrashed is a flaky test.  Error Message:  Reduce Task state not correct expected:RUNNING but was:SCHEDULED  Stack Trace:  164),Resolved,Fixed,,Gerg   P  sztor,Gerg   P  sztor,Mon; 30 Jan 2017 17:57:08 +0000,Tue; 7 Mar 2017 22:21:04 +0000,Tue; 7 Mar 2017 21:43:13 +0000,,,,,MAPREDUCE-6856,https://issues.apache.org/jira/browse/MAPREDUCE-6839
MAPREDUCE-6840,Improvement,Minor,distcp,Distcp to support cutoff time,To ensure consistency in the datasets on HDFS;  some projects like file formats on Hive do HDFS operations in a particular order.  For example; if a file form cutoff time.,Open,Unresolved,,Zheng Shao,Zheng Shao,Fri; 3 Feb 2017 00:28:25 +0000,Mon; 27 Mar 2017 12:59:53 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6840
MAPREDUCE-6841,Bug,Minor,documentation,Fix dead link in MapReduce tutorial document,input should be output.,Resolved,Fixed,,Victor Nee,Akira Ajisaka,Fri; 3 Feb 2017 04:52:54 +0000,Wed; 7 Jun 2017 22:25:07 +0000,Mon; 27 Feb 2017 10:49:56 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6841
MAPREDUCE-6842,Improvement,Minor,documentation,Update the links in PiEstimator document,"In the package-info.html; There are links to   	http: hadoop-computes-the-10-15-1st-bit-of-%CF%80",Resolved,Fixed,,Jung Yoo,Akira Ajisaka,Fri; 3 Feb 2017 05:56:56 +0000,Tue; 7 Feb 2017 22:11:12 +0000,Tue; 7 Feb 2017 21:07:44 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6842
YARN-6148,Bug,Major,,NM node count reported to AM in Allocate Response should consider requested node label partitions.,nan,Patch Available,Unresolved,,Varun Saxena,Varun Saxena,Mon; 6 Feb 2017 09:55:51 +0000,Fri; 10 Mar 2017 09:24:08 +0000,,,,,,YARN-6156;YARN-6209,https://issues.apache.org/jira/browse/YARN-6148
MAPREDUCE-6844,Bug,Major,jobhistoryserver,JobHistoryServer: Create table as statement failed but Job is shown on job history server,"Executed one hive script ""Create table tableName1 as select * from tableName2"". hive script execution resulted in an error as tableName1 is of 1000 characters long. Expectations: Since Job history server only shows successful MR jobs; It should not show this job. Actual: I am able to see the executed MR job on job history server.  Hive log: FAILED: Execution Error; return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask",Open,Unresolved,,Unassigned,amit gupta,Tue; 7 Feb 2017 10:42:12 +0000,Tue; 7 Feb 2017 14:16:07 +0000,,,1.2.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6844
MAPREDUCE-6845,Bug,Major,,Job history server requires admin permission when accessing container log in secure environment; which is not correct,"A typical url of container log in job history server is like this:   When accessing it in secure environment; it requires authorization. Because the parent path  logs"" in job history server.",Resolved,Not A Problem,,Unassigned,Yuanbo Liu,Wed; 8 Feb 2017 06:34:46 +0000,Thu; 9 Feb 2017 03:20:02 +0000,Thu; 9 Feb 2017 03:20:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6845
MAPREDUCE-6846,Bug,Minor,,Fragments specified for libjar paths are not handled correctly,If a user specifies a fragment for a libjars path via generic options parser; the client crashes with a FileNotFoundException:    This is actually inconsistent with the behavior for files and archives. Here is a table showing the current behavior for each type of path and resource:,Resolved,Fixed,,Chris Trezzo,Chris Trezzo,Wed; 8 Feb 2017 22:04:35 +0000,Thu; 7 Sep 2017 15:03:33 +0000,Thu; 6 Apr 2017 00:33:20 +0000,,2.6.0;2.7.3;3.0.0-alpha2,,,MAPREDUCE-6952;MAPREDUCE-6862,https://issues.apache.org/jira/browse/MAPREDUCE-6846
MAPREDUCE-6847,Improvement,Major,jobhistoryserver,Job history server should release jobs from cache after a fixed duration,We found history server is consuming a lot of memory when there are large jobs (with more than 100k of tasks in a single job). Currently JHS cache only evicts entries with size; it's better to add the time expiration as well to reduce heap usage if job has no one accessing for sometime.,Resolved,Won't Fix,,Weiwei Yang,Weiwei Yang,Wed; 15 Feb 2017 10:27:03 +0000,Wed; 22 Feb 2017 02:11:38 +0000,Wed; 22 Feb 2017 02:10:04 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6847
MAPREDUCE-6848,Improvement,Trivial,mrv2,MRApps.setMRFrameworkClasspath() unnecessarily declares that it throws IOException,nan,Open,Unresolved,,Wendy Turner,Daniel Templeton,Thu; 16 Feb 2017 00:06:33 +0000,Tue; 28 Mar 2017 16:46:28 +0000,,,2.8.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6848
MAPREDUCE-6849,Bug,Major,applicationmaster,Preemption by container priority can be problematic for MapReduce,A MapReduce job with thousands of reducers and just a couple of maps left to go was running in a preemptable queue.  Periodically other queues would get busy and the RM would preempt some resources from the job; but it always picked the job's map tasks first because they use the lowest priority containers.  Even though the reducers had a shorter running time; most were spared but the maps were always shot.  Since the map tasks ran for a longer time than the preemption period; the job was in a perpetual preemption loop.,Open,Unresolved,,Unassigned,Jason Lowe,Tue; 14 Feb 2017 21:36:30 +0000,Wed; 22 Feb 2017 23:52:15 +0000,,,,,,YARN-3054;MAPREDUCE-5269,https://issues.apache.org/jira/browse/MAPREDUCE-6849
MAPREDUCE-6850,Bug,Major,,Shuffle Handler keep-alive connections are closed from the server side,When performance testing tez shuffle handler (TEZ-3334); it was noticed the keep-alive connections are closed from the server-side. The client silently recovers and logs the connection as keep-alive; despite reestablishing a connection. This jira aims to remove the close from the server side; fixing the bug preventing keep-alive connections.,Resolved,Fixed,,Jonathan Eagles,Jonathan Eagles,Thu; 23 Feb 2017 15:24:38 +0000,Wed; 7 Jun 2017 22:25:09 +0000,Thu; 30 Mar 2017 16:17:08 +0000,,,,,MAPREDUCE-5787;TEZ-3633,https://issues.apache.org/jira/browse/MAPREDUCE-6850
MAPREDUCE-6851,Bug,Major,examples,Terasort does not work with S3 FileSystem,Terasort currently writes a partition list file in the output directory and add it to distributed cache. If a S3 bucket is used as the output directory; the job may fail because the partition list file will be localized by NMs which may not have the s3 credentials.,Open,Unresolved,,Unassigned,Haibo Chen,Fri; 24 Feb 2017 17:31:17 +0000,Tue; 14 Nov 2017 19:37:09 +0000,,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6851
MAPREDUCE-6852,Bug,Major,,Job#updateStatus() failed with NPE due to race condition,"Like MAPREDUCE-6762; we found this issue in a cluster where Pig query occasionally failed on NPE - ""Pig uses JobControl API to track MR job status; but sometimes Job History Server failed to flush job meta files to HDFS which caused the status update failed."" Beside NPE in o.a.h.mapreduce.Job.getJobName; we also get NPE in Job.updateStatus() and the exception is as following:   We found state here is null. However; we already check the job state to be RUNNING as code below:   The only possible reason here is two threads are calling here for the same time: ensure state first; then one thread update the state to null while the other thread hit NPE issue here. We should fix this NPE exception.",Resolved,Fixed,,Junping Du,Junping Du,Tue; 28 Feb 2017 20:42:23 +0000,Thu; 2 Mar 2017 19:20:13 +0000,Thu; 2 Mar 2017 19:00:15 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6852
YARN-6263,Bug,Major,yarn,NMTokenSecretManagerInRM.createAndGetNMToken is not thread safe,NMTokenSecretManagerInRM.createAndGetNMToken modifies values of a ConcurrentHashMap; which are of type HashSet; but it only acquires read lock.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Thu; 2 Mar 2017 00:44:36 +0000,Wed; 7 Jun 2017 21:40:55 +0000,Fri; 3 Mar 2017 14:25:15 +0000,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/YARN-6263
MAPREDUCE-6854,Improvement,Major,distcp,Each map task should create a unique temporary name that includes an object name,"Consider an example: a local file "" a.txt  The way distcp works is th object names were copied. 3. Different systems may expect ""a.txt.distcp.tmp.attempt_local2036034928_0001_m_000000_0"" and extract value prior ""distcp.tmp"" thus getting destination object name.",Patch Available,Unresolved,,Unassigned,Gil Vernik,Thu; 2 Mar 2017 11:57:42 +0000,Tue; 14 Nov 2017 19:37:07 +0000,,,3.0.0-alpha2,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-6854
MAPREDUCE-6855,Bug,Minor,,Specify charset when create String in CredentialsTestJob,should be,Resolved,Fixed,,Kai Sasaki,Akira Ajisaka,Fri; 3 Mar 2017 07:20:10 +0000,Wed; 7 Jun 2017 22:25:08 +0000,Tue; 7 Mar 2017 04:14:37 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6855
MAPREDUCE-6856,Bug,Major,,TestRecovery.testSpeculative fails if testCrashed fails,The test testSpeculative in org.apache.hadoop.mapreduce.v2.app.TestRecovery is unstable.  Based on my findings; the test itself is not problematic. It only fails if testCrashed in the same class fails before it.  The reason is not completely clear to me; but I whenever I explicitly stop the MRAppMaster in testCrashed in a finally block; then the issue disappears. I think the reason is that both tests uses the same folder for staging.  Solution: wrap logic in testCrashed in a try-finally block and then stop the MRAppMaster.,Resolved,Fixed,,Peter Bacsko,Peter Bacsko,Fri; 3 Mar 2017 16:50:17 +0000,Wed; 8 Mar 2017 16:25:34 +0000,Wed; 8 Mar 2017 16:25:05 +0000,,,,,MAPREDUCE-6839,https://issues.apache.org/jira/browse/MAPREDUCE-6856
MAPREDUCE-6857,Improvement,Major,distcp,Reduce number of exists() calls on the target object,CopyMapper.map(..) calls targetStatus = targetFS.getFileStatus(target). Few steps later RetriableFileCopyCommand.promoteTmpToTarget(..) will call again exists(target) and delete if present.  The second exists() is useless; since if targetStatus==null it can be easily seen  if overwrite mode is activated and so target object can be deleted.  The propose of this patch is to delete target object by using targetStatus and thus avoid calling exists() method.,Open,Unresolved,,Unassigned,Gil Vernik,Mon; 6 Mar 2017 11:25:22 +0000,Tue; 14 Nov 2017 19:37:09 +0000,,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6857
MAPREDUCE-6858,Bug,Major,jobhistoryserver,HistoryFileManager thrashing due to high volume jobs ,"JHS log shows that it tried to move the same *.jhist twice; and the second moving causes FileNotFoundException's.   	JHS scans ""done_intermediate"" dir for files to process and adds them to a thread pool 	Thread pool starts processing these files to move them to ""done"" dir 	JHS scans ""done_intermediate"" again for files to process and adds them to a thread pool 	 		If we have enough jobs where the thread pool can't keep up with the scanning interval; they'll get added twice (or more). If this keeps compounding;  jobs end up would pile up and not getting processed for quite some time and getting lots of FileNotFoundException's. 	 	    By default; it looks like the thread pool only has 3 threads in it (mapreduce.jobhistory.move.thread-count). And the scan interval is 3 minutes (mapreduce.jobhistory.move.interval-ms). Perhaps we should increase these?",Open,Unresolved,,Unassigned,Yufei Gu,Tue; 7 Mar 2017 19:12:58 +0000,Wed; 8 Mar 2017 19:40:55 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6858
MAPREDUCE-6859,Bug,Minor,client,hadoop-mapreduce-client-jobclient.jar sets a main class that isn't in the JAR,The manifest for hadoop-mapreduce-client-jobclient.jar points to org.apache.hadoop.test.MapredTestDriver; which is in the test JAR.  Without the test JAR in the class path; running the jobclient JAR will fail with a class not found exception.,Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Tue; 7 Mar 2017 21:12:35 +0000,Wed; 8 Mar 2017 16:54:20 +0000,Wed; 8 Mar 2017 16:29:24 +0000,,3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6859
MAPREDUCE-6860,Bug,Major,,User intermediate-done-dir permissions should use history permissions configuration,nan,Resolved,Not A Bug,,Unassigned,Jonathan Hung,Wed; 8 Mar 2017 02:37:33 +0000,Thu; 9 Mar 2017 23:45:24 +0000,Thu; 9 Mar 2017 23:32:06 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6860
MAPREDUCE-6861,Bug,Major,,Add metrics tags for ShuffleClientMetrics,Metrics tags were unintentionally removed by MAPREDUCE-6526. Let's add them back.,Open,Unresolved,,Unassigned,Akira Ajisaka,Wed; 8 Mar 2017 08:20:35 +0000,Tue; 14 Nov 2017 19:37:06 +0000,,,3.0.0-alpha1,newbie++,,,https://issues.apache.org/jira/browse/MAPREDUCE-6861
MAPREDUCE-6862,Bug,Minor,,Fragments are not handled correctly by resource limit checking,If a user specifies a fragment for a libjar; files; archives path via generic options parser and resource limit checking is enabled; the client crashes with a FileNotFoundException:,Resolved,Fixed,,Chris Trezzo,Chris Trezzo,Thu; 9 Mar 2017 23:29:16 +0000,Thu; 30 Mar 2017 01:15:42 +0000,Thu; 30 Mar 2017 00:46:20 +0000,,2.9.0;3.0.0-alpha1,,,MAPREDUCE-6846,https://issues.apache.org/jira/browse/MAPREDUCE-6862
MAPREDUCE-6863,Bug,Minor,applicationmaster;resourcemanager,job finish  but yarn list status is accepted and  applicationmaster is hang on Waiting for application to be successfully unregistered,applicationmaster process log is loop on  Waiting for application to be successfully unregistered.   ApplicationMaster log,Open,Unresolved,,Unassigned,         ,Mon; 13 Mar 2017 04:35:00 +0000,Tue; 11 Jul 2017 06:43:08 +0000,,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6863
MAPREDUCE-6864,Bug,Major,mrv2,Hadoop streaming creates 2 mappers when the input has only one block,If a streaming job is run against input that is less than 2 blocks; 2 mappers will be created; both operating on the same split; both producing (duplicate) output.  In some cases the second mapper will consistently fail.  I've not seen the failure with input less than 10 bytes or more than a couple MB.  I have seen it with a 4kB input.,Open,Unresolved,,Unassigned,Daniel Templeton,Fri; 17 Mar 2017 20:27:03 +0000,Mon; 11 Sep 2017 05:12:18 +0000,,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6864
MAPREDUCE-6865,Improvement,Trivial,,Fix typo in javadoc for DistributedCache ,"There are some typos in the  oc for DistributedCache. For example:  DistributedCache.addCacheArchive(new URI("" map.zip""); job);",Resolved,Fixed,,Attila Sasvari,Attila Sasvari,Sun; 19 Mar 2017 15:41:54 +0000,Mon; 20 Mar 2017 03:04:52 +0000,Mon; 20 Mar 2017 03:04:22 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6865
MAPREDUCE-6866,Bug,Minor,documentation,Fix getNumMapTasks() documentation in JobConf,The original description of the getNumMapTasks() method in JobConf was invalid; because it referenced to the number of reducer tasks instead of the map tasks.   from: Get configured the number of reduce tasks for this job.   to: Get the configured number of map tasks for this job.  It was maybe the result of a tricky copy-paste   Github PR: https: 205,Resolved,Fixed,,Joe M  sz  ros,Joe M  sz  ros,Fri; 24 Mar 2017 09:45:19 +0000,Wed; 7 Jun 2017 22:25:09 +0000,Mon; 27 Mar 2017 04:54:01 +0000,,,easyfix;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6866
MAPREDUCE-6867,Bug,Major,applicationmaster,ApplicationMaster hung on OOM Error,Whenever OOM Error is thown; YarnUncaughtExceptionHandler will call ExitUtil.halt(-1).But while halting; OOM might occur which is not handled.   We came across a scenario where in when we submit mapreduce application ;OOM error occured in committerEventProcessor and then AM did not halt and did not log the following.Finally AM got hang since it's not thrown to main thread.      org.apache.hadoop.util.ExitUtil.halt(int; String),Patch Available,Unresolved,,Bilwa S T,Bilwa S T,Sat; 25 Mar 2017 08:25:04 +0000,Mon; 10 Apr 2017 02:28:46 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6867
MAPREDUCE-6868,Bug,Major,build,License check for jdiff output files should be ignored,"The following commits added jdiff output for Hadoop 2.8.0 but ASF license header is missing.  	https: d174c06b01e1f743d3111b9b760a9824d8106b86    hadoop-mapreduce-project module does not have a setting to ignore the jdiff output files; so the license check fails.",Resolved,Fixed,,Akira Ajisaka,Akira Ajisaka,Mon; 27 Mar 2017 01:35:39 +0000,Wed; 7 Jun 2017 22:25:08 +0000,Mon; 27 Mar 2017 06:20:22 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6868
MAPREDUCE-6869,Bug,Minor,mrv2;yarn,org.apache.hadoop.mapred.ShuffleHandler: Shuffle error in populating headers :,nodemanager log 2017-03-25 21:07:03;071 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error in populating headers : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find usercache file.out.index in any of the configured local directories          org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher. 193),Resolved,Not A Bug,,Unassigned,         ,Mon; 27 Mar 2017 08:40:09 +0000,Tue; 28 Mar 2017 15:02:20 +0000,Tue; 28 Mar 2017 15:02:20 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6869
MAPREDUCE-6870,Improvement,Major,,Add configuration for MR job to finish when all reducers are complete (even with unfinished mappers),Even with MAPREDUCE-5817; there could still be cases where mappers get scheduled before all reducers are complete; but those mappers run for long time; even after all reducers are complete. This could hurt the performance of large MR jobs.  In some cases; mappers don't have any materialize-able outcome other than providing intermediate data to reducers. In that case; the job owner should have the config option to finish the job once all reducers are complete.,Resolved,Fixed,,Peter Bacsko,Zhe Zhang,Tue; 28 Mar 2017 18:45:23 +0000,Mon; 11 Sep 2017 21:22:52 +0000,Thu; 10 Aug 2017 22:29:19 +0000,,2.6.1,,,MAPREDUCE-6939;MAPREDUCE-5817;MAPREDUCE-6937,https://issues.apache.org/jira/browse/MAPREDUCE-6870
MAPREDUCE-6871,New Feature,Major,client,Allow users to specify racks and nodes for strict locality for AMs,"YARN-6050 fixed the YARN API to allow multiple ResourceRequest's when submitting an AM so that you can actually do rack or node locality.  We should allow MapReduce users to take advantage of this by exposing this functionality in some way.  The raw YARN API allows for a lot of flexibility (e.g. different resources per request; etc); but we don't necessarily want to allow the user to do too much here so they don't shoot themselves in the foot and we don't make this overly complicated.    I propose we allow users to specify racks and nodes for strict locality.  This would allow users to restrict an MR AM to specific racks and rack1; relaxLocality=false; capability=X;Y 	resourceName=node1; relaxLocality=true; capability=X;Y    By default; the property would be unset; and you'd get the normal ANY ResourceRequest.",Resolved,Fixed,,Robert Kanter,Robert Kanter,Wed; 29 Mar 2017 18:02:57 +0000,Tue; 2 May 2017 12:01:50 +0000,Fri; 21 Apr 2017 23:17:36 +0000,,,,,OOZIE-2874;YARN-6050,https://issues.apache.org/jira/browse/MAPREDUCE-6871
YARN-6409,Bug,Major,resourcemanager,RM does not blacklist node for AM launch failures,Currently; node blacklisting upon AM failures only handles failures that happen after AM container is launched (see RMAppAttemptImpl.shouldCountTowardsNodeBlacklisting()).  However; AM launch can also fail if the NM; where the AM container is allocated; goes unresponsive.  Because it is not handled; scheduler may continue to allocate AM containers on that same NM for the following app attempts.,Patch Available,Unresolved,,Haibo Chen,Haibo Chen,Wed; 29 Mar 2017 19:44:52 +0000,Tue; 14 Nov 2017 19:34:21 +0000,,,3.0.0-alpha2,,,YARN-4576,https://issues.apache.org/jira/browse/YARN-6409
MAPREDUCE-6873,Bug,Minor,mrv2,MR Job Submission Fails if MR framework application path not on defaultFS,JobSubmitter#addMRFrameworkPathToDistributedCache() assumes that mapreduce.framework.application.path has a FS which matches fs.defaultFS which may not always be true. This is just a consequence of using FileSystem.get(Configuration) instead of FileSystem.get(URI; Configuration).,Resolved,Fixed,,Erik Krogen,Erik Krogen,Thu; 30 Mar 2017 02:48:15 +0000,Wed; 7 Jun 2017 22:28:20 +0000,Thu; 30 Mar 2017 05:36:47 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6873
MAPREDUCE-6874,New Feature,Major,,Make DistributedCache check if the content of a directory has changed,DistributedCache does not check recursively if the content a directory has changed when adding files to it with DistributedCache.addCacheFile().   Background I have an Oozie workflow on HDFS:   Executed the workflow; then made some changes in subsub.sh. Replaced the file on HDFS. When I re-ran the workflow; DistributedCache did not notice the changes as the timestamp on the components directory did not change. As a result; the old script was materialized.  This behaviour might be related to determineTimestamps() . In order to use the new script during workflow execution; I had to update the whole components directory.   Some more info: In Oozie; DistributedCache.addCacheFile()  is used to add files to the distributed cache.,Resolved,Won't Fix,,Unassigned,Attila Sasvari,Mon; 3 Apr 2017 10:37:56 +0000,Mon; 3 Apr 2017 13:45:08 +0000,Mon; 3 Apr 2017 13:45:08 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6874
MAPREDUCE-6875,Bug,Minor,build,Rename mapred-site.xml.template to mapred-site.xml,mapred-site.xml file needs a license.,Resolved,Fixed,,Yuanbo Liu,Allen Wittenauer,Wed; 5 Apr 2017 23:57:45 +0000,Mon; 17 Apr 2017 19:49:51 +0000,Mon; 17 Apr 2017 19:28:57 +0000,,3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6875
MAPREDUCE-6876,Improvement,Major,,FileInputFormat.listStatus should not fetch delegation tokens,FileInputFormat.listStatus fetches delegation tokens: https:  L213  AFAICT; this is unnecessary.  listStatus doesn't delegate those tokens to another process.  This is causing issues described in the attached Spark Kerberos ticket; because TokenCache.obtainTokensForNameNodes; which is used to fetch the delegation tokens; assumes that certain MapReduce configuration variables are set; which isn't true in the Spark calling code.  This is a separate problem; but nonetheless it wouldn't have arisen if listStatus weren't fetching delegation tokens.,Open,Unresolved,,Unassigned,Michael Gummelt,Thu; 13 Apr 2017 23:38:38 +0000,Fri; 14 Apr 2017 21:01:35 +0000,,,,,,SPARK-20328,https://issues.apache.org/jira/browse/MAPREDUCE-6876
MAPREDUCE-6877,Improvement,Major,,Assign map task preferentially to the data node where the split is on faster storage type,It would be good to use SSD in HDFS to improve reading writing performance. However; SSD costs more than HDD; so there is a tradeoff policy ONE-SSD to balance the performance and cost. But there occurs a problem whether applications will read the replication on SSD or not. If applications wouldn t preferentially read the replication on SSD; the advantage of SSD wouldn t be fully utilized. The current MapReduce only assign tasks according to data locality. The storage types of all the replications of each split should also be taken into consideration in order to assign map task preferentially to a node where its split is located on a faster storage type.,Open,Unresolved,,Tim Yao,Tim Yao,Tue; 18 Apr 2017 08:48:26 +0000,Tue; 18 Apr 2017 09:01:32 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6877
MAPREDUCE-6878,Improvement,Minor,mrv2,Method length of MRAppMaster #serviceInit() is too long,Reported by style checking: Method length is 216 lines (max allowed is 150). MethodLength,Open,Unresolved,,Unassigned,Yufei Gu,Wed; 19 Apr 2017 18:17:38 +0000,Wed; 19 Apr 2017 18:22:02 +0000,,,,newbie++,,,https://issues.apache.org/jira/browse/MAPREDUCE-6878
MAPREDUCE-6879,Bug,Minor,benchmarks,TestDFSIO#sequentialTest throws java.lang.NullPointerException due to uninitialized IOStream,When I use  -seq  arg to write files; TestDFSIO#sequentialTest throws  lang.NullPointerException due to uninitialized stream inherited from IOMapperBase:,Patch Available,Unresolved,,Unassigned,Wenxin He,Thu; 20 Apr 2017 08:34:44 +0000,Wed; 7 Jun 2017 06:24:02 +0000,,,2.7.3;3.0.0-alpha2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6879
HADOOP-14343,Bug,Minor,,Wrong pid file name in error message when starting secure daemon,It will log datanode's pid file instead of JSVC's pid file.,Resolved,Fixed,,Andras Bokor,Andras Bokor,Fri; 21 Apr 2017 12:52:31 +0000,Tue; 1 Aug 2017 08:33:15 +0000,Tue; 1 Aug 2017 03:04:45 +0000,,,,,,https://issues.apache.org/jira/browse/HADOOP-14343
MAPREDUCE-6881,Bug,Major,,Fix warnings from Spotbugs in hadoop-mapreduce,Fix warnings from Spotbugs in hadoop-mapreduce since switched from findbugs to spotbugs.,Resolved,Fixed,,Weiwei Yang,Weiwei Yang,Fri; 21 Apr 2017 02:56:12 +0000,Thu; 27 Apr 2017 07:59:53 +0000,Thu; 27 Apr 2017 06:46:47 +0000,,,,,HADOOP-14336,https://issues.apache.org/jira/browse/MAPREDUCE-6881
MAPREDUCE-6882,Bug,Major,,Increase MapReduce test timeouts from 1 second to 10 seconds,1 second test timeouts are susceptible to failure on overloaded or otherwise slow machines,Resolved,Fixed,,Eric Badger,Eric Badger,Wed; 3 May 2017 15:35:32 +0000,Wed; 10 May 2017 16:45:21 +0000,Wed; 10 May 2017 14:59:58 +0000,,,,,HDFS-11745;YARN-6552;HADOOP-14377,https://issues.apache.org/jira/browse/MAPREDUCE-6882
MAPREDUCE-6883,Improvement,Minor,client,AuditLogger and TestAuditLogger are dead code,The AuditLogger and TestAuditLogger classes appear to be dead code.  I can't find anything that uses or references AuditLogger.  No one has touched the code 2011.  I think it's safe to remove.,Resolved,Fixed,,Vrushali C,Daniel Templeton,Wed; 3 May 2017 21:56:32 +0000,Tue; 9 May 2017 17:32:30 +0000,Tue; 9 May 2017 17:32:30 +0000,,2.8.0,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6883
YARN-6558,Bug,Major,yarn,YARN ContainerLocalizer logs are missing,YARN LCE ContainerLocalizer runs as a separate process and the logs   error messages are not captured. We need to redirect them to a stdout or separate log file which helps to debug Localization issues.,Resolved,Duplicate,YARN-5422,Unassigned,Prabhu Joseph,Thu; 4 May 2017 06:19:46 +0000,Thu; 4 May 2017 16:20:25 +0000,Thu; 4 May 2017 16:20:25 +0000,,2.7.1,,,,https://issues.apache.org/jira/browse/YARN-6558
MAPREDUCE-6885,Bug,Major,,JobHistory event handling does not complete if handling event throws exception on shutdown,If eventHandlingThread handles an event which causes it to throw an exception (e.g. if it is unable to flush an event to HDFS); the thread dies. The events are enqueued and eventually handled when JobHistoryEventHandler stops. If handling these events also throws an exception; the remaining events are lost. This can for example cause moving job history files to mapreduce.jobhistory.done-dir to not occur.  There should be some fail-proof logic here to prevent these events from being lost. Should also be careful that the same exception is not thrown for each event to prevent the logs from being cluttered with the same stacktrace. Perhaps we can set a configurable number of failed handleEvent calls before finally giving up a clean shutdown.,Open,Unresolved,,Unassigned,Jonathan Hung,Sat; 6 May 2017 00:33:11 +0000,Fri; 15 Dec 2017 20:29:16 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6885
MAPREDUCE-6886,Bug,Major,,Job History File Permissions configurable,Currently the mapreduce job history files are written with 770 permissions which can be accessed by job user or other user part of hadoop group. Customers has users who are not part of the hadoop group but want to access these history files. We can make it configurable like 770 (Strict) or 755 (All) permissions with default 770.,Resolved,Duplicate,MAPREDUCE-6288,Unassigned,Prabhu Joseph,Thu; 11 May 2017 08:44:21 +0000,Mon; 22 May 2017 16:07:23 +0000,Mon; 22 May 2017 16:07:23 +0000,,2.7.1,,,MAPREDUCE-6288,https://issues.apache.org/jira/browse/MAPREDUCE-6886
MAPREDUCE-6887,Bug,Minor,,Modifier 'static' is redundant for inner enums,Java enumeration type is a static constant; implicitly modified with static final;Modifier 'static' is redundant for inner enums less.So I suggest deleting the 'static' modifier.,Resolved,Fixed,,ZhangBing Lin,ZhangBing Lin,Fri; 12 May 2017 02:26:17 +0000,Tue; 30 May 2017 06:48:04 +0000,Tue; 30 May 2017 05:50:16 +0000,,3.0.0-alpha4,,,HADOOP-14456;YARN-6646,https://issues.apache.org/jira/browse/MAPREDUCE-6887
MAPREDUCE-6888,Bug,Minor,,Error message of ShuffleHandler should show the exact cause,exceptionCaught shows the exact cause of given ExceptionEvent. But it is not properly shown in case of internal server error.,Patch Available,Unresolved,,Kai Sasaki,Kai Sasaki,Fri; 12 May 2017 12:49:48 +0000,Tue; 27 Jun 2017 13:57:11 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6888
MAPREDUCE-6889,Bug,Major,,Add Job#close API to shutdown MR client services.,ATS1.5 uses FileSystemTimelineWriter which creates FS object on every writer initialization. If writer is not closed; then there is possibility of OOM see YARN-5438 fixes closing FS object.   TimelineClient is used by YarnClient. So all the user who uses YarnClient with ATS1.5 need to stop service properly. Otherwise there is big chance of FS object leak.   Of course MR uses YARN client submit job. If MR do not stop YarnClient then there is FS object leak.   JobClient provides a API to stop all these service using JobClient#close. But many MR clients uses Job object to submit a job. But  do not stop started services by default.   So; provide a API Job#close to shutdown MR client services. This API can be utilized by caller explicitly to stop service which avoids FS leak.,Resolved,Fixed,,Rohith Sharma K S,Rohith Sharma K S,Mon; 15 May 2017 06:14:11 +0000,Mon; 17 Jul 2017 08:29:02 +0000,Mon; 17 Jul 2017 08:14:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6889
MAPREDUCE-6890,New Feature,Major,,Backport MAPREDUCE-6304 to branch 2.7: Specifying node labels when submitting MR jobs,As per discussussion in mailling list backport MAPREDUCE-6304 to branch-2.7.,Resolved,Duplicate,MAPREDUCE-6304,Unassigned,Vinitha Reddy Gankidi,Thu; 18 May 2017 02:30:51 +0000,Thu; 18 May 2017 07:44:14 +0000,Thu; 18 May 2017 07:36:31 +0000,,,,,MAPREDUCE-6304,https://issues.apache.org/jira/browse/MAPREDUCE-6890
MAPREDUCE-6891,Bug,Major,,TextInputFormat: duplicate records with custom delimiter,When using a custom delimiter for TextInputFormat; the resulting blocks are not correct under some circumstances. It happens that the total number of records is wrong and some entries are duplicated.  I have created a reproducible test case:   Generate a File     Java-Test to reproduce the error    This example fails with the error    lang.AssertionError: expected:10000000 but was:10042616  when commenting out the Assert about the size of the collection; my log output ends like this:   main INFO  edu.udo.cs.schaefer.testspark.Main  - Correct value for index 663244: expected 663245 - got 663245 main ERROR edu.udo.cs.schaefer.testspark.Main  - Wrong value for index 663245: expected 663246 - got 660111  After the the wrong value for index 663245 the values are sorted again an a continuing with 660112; 660113; ....  The error is not reproducible with  n as delimiter; i.e. when not using a custom delimiter.,Resolved,Duplicate,MAPREDUCE-6549,Unassigned,Till Sch  fer,Mon; 22 May 2017 16:43:25 +0000,Tue; 23 May 2017 11:54:11 +0000,Tue; 23 May 2017 11:54:11 +0000,,2.2.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6891
MAPREDUCE-6892,Bug,Major,client;jobhistoryserver,Issues with the count of failed/killed tasks in the jhist file,Recently we encountered some issues with the value of failed tasks. After parsing the jhist file; JobInfo.getFailedMaps() returned 0; but actually there were failures.   Another minor thing is that you cannot get the number of killed tasks (although this can be calculated).  The root cause is that JobUnsuccessfulCompletionEvent contains only the successful map reduce task counts. Number of failed (or killed) tasks are not stored.,Resolved,Fixed,,Peter Bacsko,Peter Bacsko,Wed; 24 May 2017 09:43:25 +0000,Thu; 28 Sep 2017 17:23:27 +0000,Wed; 30 Aug 2017 17:12:20 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6892
MAPREDUCE-6893,Improvement,Minor,,MultipleOutputs to have configuration overrides for a named output,"To support the use-cases where we have to give different config for different named output. one use case may be that  we need different schemas for different named output and schema is passed as config in Record Writer.    or example:  we have two named output  ""schema1"" and ""schema2""  for schema1 we want the value of key ""schema"" as ""int"" while for  schema2 it should be ""string"".  so we can provide config as ""multioutput.overrideKeys= schema"" ""multioutput. schema1.schema=int"" ""multioutput. schema2.schema=string""  and while creating context in getContext  config for schema1 will resolved to  ""schema=int"" and for  schema2 it will  be ""schema=string""",Open,Unresolved,,Unassigned,piyush mukati,Thu; 25 May 2017 07:15:35 +0000,Tue; 5 Sep 2017 05:14:27 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6893
MAPREDUCE-6894,Bug,Major,,License error in TestMRCredentials.java,license is not at the top of the class.,Resolved,Duplicate,YARN-6584,lixinglong,lixinglong,Wed; 10 May 2017 02:57:25 +0000,Thu; 25 May 2017 07:51:26 +0000,Thu; 25 May 2017 07:51:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6894
MAPREDUCE-6895,Bug,Major,applicationmaster,Job end notification not send due to YarnRuntimeException,MRAppMaster.this.stop() throw out YarnRuntimeException as below log shows; it caused job end notification not send.  2017-05-24 12:14:02;165 WARN Thread-693 org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Graceful stop failed org.apache.hadoop.yarn.exceptions.YarnRuntimeException:  520)         ... 11 more 2017-05-24 12:14:02;165 INFO Thread-693 org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Exiting MR AppMaster..GoodBye!,Resolved,Fixed,,yunjiong zhao,yunjiong zhao,Thu; 25 May 2017 21:07:48 +0000,Wed; 14 Jun 2017 04:58:52 +0000,Wed; 14 Jun 2017 04:53:06 +0000,,2.4.1;2.8.0;2.7.3,,,MAPREDUCE-6897,https://issues.apache.org/jira/browse/MAPREDUCE-6895
MAPREDUCE-6896,Bug,Major,documentation,Document wrong spelling in usage of MapredTestDriver tools.,When the user run performance test of MapredTestDriver; a spelling mistake seems exposed to user:   . hadoop org.apache.hadoop.test.MapredTestDriver An example program must be given as the first argument. Valid program names are: ...... timelineperformance: A job that launches mappers to test timline service performance.,Resolved,Fixed,,LiXin Ge,LiXin Ge,Wed; 7 Jun 2017 07:55:01 +0000,Wed; 14 Jun 2017 01:08:35 +0000,Tue; 13 Jun 2017 20:24:12 +0000,,3.0.0-alpha3,easyfix,,,https://issues.apache.org/jira/browse/MAPREDUCE-6896
MAPREDUCE-6897,Bug,Minor,,Add Unit Test to make sure Job end notification get sent even appMaster stop get YarnRuntimeException,In MAPREDUCE-6895; we fix the issue that Job end notification not send due to YarnRuntimeException throw in appMaster stop. We need to add unit test to make sure we won't run into the same issue again in future.,Resolved,Fixed,,Gergely Nov  k,Junping Du,Wed; 14 Jun 2017 04:50:27 +0000,Fri; 16 Jun 2017 21:57:07 +0000,Fri; 16 Jun 2017 21:27:45 +0000,,2.9.0;3.0.0-alpha4,newbie++,,MAPREDUCE-6895,https://issues.apache.org/jira/browse/MAPREDUCE-6897
MAPREDUCE-6898,Bug,Major,client;test,TestKill.testKillTask is flaky,TestKill.testKillTask() can fail if the async dispatcher thread is slower than the test's thread.     We have to wait until the job's internal state is JobInternalState.RUNNING and not JobInternalState.SETUP.,Resolved,Duplicate,MAPREDUCE-6815,Peter Bacsko,Peter Bacsko,Wed; 14 Jun 2017 15:11:59 +0000,Fri; 16 Jun 2017 20:13:11 +0000,Fri; 16 Jun 2017 19:52:49 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6898
MAPREDUCE-6899,Bug,Major,,Unable to see logs for Job end notification,Hi; I have set mapreduce.job.end-notification.url and I am able to get the notification correctly.  But I am unable to see log lines from class org.apache.hadoop.mapreduce.v2.app.MRAppMaster regarding job end notification. When I was trying out different notification urls (before stabilizing my app); I didn't have any way to look at the logs and wasted a lot of time figuring out actual issue. It would be good if these logs are also included in syslog for container.   relevant code    Is it because we are shutting down all services including JobHistoryEventHandler in MRAppMaster.this.stop(); ?,Open,Unresolved,,Unassigned,Satish Subhashrao Saley,Mon; 12 Jun 2017 22:06:45 +0000,Thu; 15 Jun 2017 14:22:07 +0000,,,2.8.0,applicationmaster;mapreduce,,,https://issues.apache.org/jira/browse/MAPREDUCE-6899
MAPREDUCE-6900,Bug,Minor,,Terasort replication factor hard-coded for partition file (partFile),When running terasort on a cluster with less than 10 nodes; I get the following:    ERROR terasort.TeraSort: Requested replication factor of 10 exceeds maximum of 4 for   and rebuild to get it to work. This should be configurable.,Open,Unresolved,,Unassigned,Hazem Mahmoud,Thu; 15 Jun 2017 20:38:24 +0000,Thu; 15 Jun 2017 21:02:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6900
MAPREDUCE-6901,Sub-task,Major,distributed-cache,Remove @deprecated tags from DistributedCache,Doing this as part of Hadoop 3 cleanup.  DistributedCache has been marked as deprecated forever to the point where the change that did it isn't in Git.  I don't really have a preference for whether we remove it or not; but I'd like to have a discussion and have it properly documented as a release not for Hadoop 3 before we hit final release.  At the very least we can have a Release Note that will sum up whatever discussion we have here.,Open,Unresolved,,Ray Chiang,Ray Chiang,Fri; 16 Jun 2017 20:36:15 +0000,Tue; 14 Nov 2017 19:37:10 +0000,,,3.0.0-alpha3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6901
MAPREDUCE-6902,Task,Major,,[Umbrella] API related cleanup for Hadoop 3,Creating this umbrella JIRA for tracking various API related issues that need to be properly tracked; adjusted; or documented before Hadoop 3 release.,Open,Unresolved,,Ray Chiang,Ray Chiang,Fri; 16 Jun 2017 20:41:48 +0000,Fri; 16 Jun 2017 21:21:11 +0000,,,,,,YARN-6717;HADOOP-14534,https://issues.apache.org/jira/browse/MAPREDUCE-6902
MAPREDUCE-6903,Bug,Major,test,NPE occured when run MapredTestDriver's testcase,When runing the timelineperformance test from MapredTestDriver without input parameter; an NPE was throwed:  . hadoop org.apache.hadoop.test.MapredTestDriver timelineperformance ... 2017-06-08 09:32:13;194 ERROR mapreduce.SimpleEntityWriterV1: writing to the timeline service failed  745) That's better to add a protection of NULL pointer check.,Patch Available,Unresolved,,LiXin Ge,LiXin Ge,Thu; 22 Jun 2017 09:22:51 +0000,Tue; 14 Nov 2017 19:37:07 +0000,,,3.0.0-alpha4,easyfix,,,https://issues.apache.org/jira/browse/MAPREDUCE-6903
MAPREDUCE-6904,Bug,Critical,scripts,HADOOP_JOB_HISTORY_OPTS should be HADOOP_JOB_HISTORYSERVER_OPTS in mapred-config.sh,After HADOOP-13341; HADOOP_JOB_HISTORY_OPTS is deprecated in favor of MAPRED_HISTORYSERVER_OPTS; but still works.  However; the property is actually supposed to be HADOOP_JOB_HISTORYSERVER_OPTS.,Resolved,Fixed,,Robert Kanter,Robert Kanter,Thu; 22 Jun 2017 19:44:45 +0000,Tue; 27 Jun 2017 00:59:18 +0000,Tue; 27 Jun 2017 00:36:11 +0000,,3.0.0-alpha1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6904
MAPREDUCE-6905,Bug,Major,tools/rumen,Fix meaningless operations in TestDFSIO in some situation.,When run TestDFSIO in write mode with 2 million nrFiles; it will takes hours to create control files and get IOException as last because of directory item limit is exceeded. And; it will leave over 1 million useless files which will be deleted when run TestDFSIO again with acceptable nrFiles.       INFO fs.TestDFSIO: creating control file: 1024 bytes; 2000000 files  126)  In brief; we'd better check the parameter of nrFiles before it waste our time and hurt our feelings.,Resolved,Fixed,,LiXin Ge,LiXin Ge,Mon; 26 Jun 2017 08:18:01 +0000,Mon; 28 Aug 2017 18:35:12 +0000,Sun; 2 Jul 2017 11:08:59 +0000,,3.0.0-alpha4,patch,,,https://issues.apache.org/jira/browse/MAPREDUCE-6905
OOZIE-2971,Improvement,Major,,Print out current tokens in LauncherAM,We should print out the list of available tokens in the LauncherAM; similar to what MapReduce does: https:  L1709,Open,Unresolved,,Unassigned,Peter Cseh,Tue; 27 Jun 2017 13:42:57 +0000,Tue; 27 Jun 2017 14:01:57 +0000,,,,,,,https://issues.apache.org/jira/browse/OOZIE-2971
MAPREDUCE-6907,Bug,Major,,"Hadoop ""Spill failed"" with custom ArrayWritable and data type - ""java.lang.Exception: java.lang.NegativeArraySizeException""","When I run a MapReduce program which uses a custom ArrayWritable based on a custom data type; I get this error:       1532)  When I used Google I saw this is a bug with MapReduce. It says this bug was ""fixed"" but apparently not for a custom ArrayWritable with a WritableComparable. Is this a problem with my code or with Hadoop?",Open,Unresolved,,Unassigned,Neel Chauhan,Tue; 27 Jun 2017 19:12:27 +0000,Tue; 27 Jun 2017 19:12:27 +0000,,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6907
MAPREDUCE-6908,Improvement,Trivial,client,Remove Superfluous Collection Allocations From CombineFileInputFormat,Remove superfluous collection creations from org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormatK; V  Use StringBuilder instead of synchronized StringBuffer,Patch Available,Unresolved,,Unassigned,BELUGA BEHR,Wed; 28 Jun 2017 23:19:02 +0000,Thu; 29 Jun 2017 02:16:35 +0000,,,3.0.0-alpha3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6908
MAPREDUCE-6909,Bug,Blocker,client,LocalJobRunner fails when run on a node from multiple users,MAPREDUCE-5762 removed mapreduce.jobtracker.staging.root.dir from mapred-default.xml but the property is still being used by LocalJobRunner and the code default value does not match the value that was removed from mapred-default.xml.  This broke the use case where multiple users are running local mode jobs on the same node; since they now default to the same directory in  tmp.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Fri; 30 Jun 2017 15:03:09 +0000,Wed; 5 Jul 2017 22:15:11 +0000,Tue; 4 Jul 2017 06:29:22 +0000,,2.8.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6909
MAPREDUCE-6910,Bug,Major,jobhistoryserver,MapReduceTrackingUriPlugin can not return the right URI of history server with HTTPS,When the MapReduceTrackingUriPlugin enabled; the URI requests from proxy server or RM UI which are also out of yarn.resourcemanager.max-completed-applications should be redirect to the history server URI. But when I access a HTTPS history server with the properties:       property         namemapreduce.jobhistory.http.policy property,Resolved,Fixed,,Lantao Jin,Lantao Jin,Sat; 1 Jul 2017 10:24:50 +0000,Mon; 17 Jul 2017 17:20:29 +0000,Mon; 17 Jul 2017 17:20:29 +0000,,2.7.3;2.8.1;3.0.0-alpha3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6910
MAPREDUCE-6911,Bug,Major,,TestMapreduceConfigFields.testCompareXmlAgainstConfigurationClass fails consistently,nan,Resolved,Fixed,,Eric Badger,Eric Badger,Wed; 5 Jul 2017 22:14:21 +0000,Thu; 6 Jul 2017 14:27:08 +0000,Thu; 6 Jul 2017 14:27:08 +0000,,2.9.0;2.8.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6911
MAPREDUCE-6912,Bug,Major,mrv2,CompletedMapTask contains failed and killed will lead mapreduce.job.reduce.slowstart.completedmaps not work properly,if the conf is set to 1; is about to make reduce task to be scheduled only after all map task success,Open,Unresolved,,Unassigned,SuYan,Thu; 6 Jul 2017 03:16:41 +0000,Thu; 6 Jul 2017 03:17:25 +0000,,,2.6.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6912
MAPREDUCE-6913,Bug,Major,benchmarks,TestDFSIO: error if file size is >= 2G for random read,For the TestDFSIO benchmark; if the test file created are 2G or larger:  hadoop jar $HADOOP_HOME  skipSize  0                                                                                                                                                                                                                                                  return (current  0) ? Math.max(0; fileSize - bufferSize) :                              Math.max(0; current + skipSize);     }   },Open,Unresolved,,Unassigned,Edwina Lu,Fri; 14 Jul 2017 21:39:59 +0000,Fri; 14 Jul 2017 21:39:59 +0000,,,2.7.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6913
MAPREDUCE-6914,Improvement,Minor,test,Tests use assertTrue(....equals(...)) instead of assertEquals(),nan,Resolved,Fixed,,Daniel Templeton,Daniel Templeton,Mon; 17 Jul 2017 18:49:48 +0000,Thu; 3 Aug 2017 19:25:56 +0000,Thu; 3 Aug 2017 18:51:31 +0000,,2.8.1;3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6914
YARN-6833,Bug,Blocker,resourcemanager,On branch-2 ResourceManager failed to start,On build against branch-2; ResourceManager get failed to start because of following failures:,Open,Unresolved,,Unassigned,Junping Du,Mon; 17 Jul 2017 21:20:00 +0000,Mon; 28 Aug 2017 18:34:34 +0000,,,2.9.0,,,,https://issues.apache.org/jira/browse/YARN-6833
MAPREDUCE-6916,Bug,Major,jobhistoryserver,History server scheduling tasks at fixed rate can be problematic when those tasks are slow,The job history server currently schedules both the task of moving jobs from intermediate to done and the task of cleaning jobs at a fixed rate.  If those tasks take longer than the rate period to execute then a backlog of to-be-scheduled tasks can build up and cause a long storm of them to execute later when the blockage clears.,Open,Unresolved,,Unassigned,Jason Lowe,Tue; 18 Jul 2017 20:53:58 +0000,Tue; 18 Jul 2017 20:58:12 +0000,,,2.7.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6916
MAPREDUCE-6917,Bug,Minor,distcp,DistCp does not clean staging folder if class extends DistCp,My code extends Distcp class and for some reason if distcp fails staging folder is not delete and this staging folder piles up occupying space on hdfs.  After checking the code i found that cleanup() function is private. Making the cleanup() method as public; user should be able to invoke the cleanup if job fails.  This works fine with command line argument. But fails only if we extend Distcp class.,Open,Unresolved,,Unassigned,Lawrence Andrews,Thu; 20 Jul 2017 19:38:26 +0000,Thu; 20 Jul 2017 19:39:36 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6917
MAPREDUCE-6918,Bug,Major,mrv2,ShuffleMetrics.ShuffleConnections Gauge Metric Climbs Infinitely,We recently noticed that the mapred.ShuffleMetrics.ShuffleConnections metric seems to climb infinitely; up to many millions (see attached graph); despite being supposedly a gauge measure of the number of open connections:     It seems that shuffleConnections gets incremented once for every map fetched; but only decremented once for every request. It seems to me it should be modified to only be incremented once for every request rather than for every map fetched; but I'm not familiar with the original intent.,Resolved,Duplicate,MAPREDUCE-6919,Unassigned,Erik Krogen,Tue; 25 Jul 2017 23:42:23 +0000,Fri; 27 Oct 2017 17:15:59 +0000,Fri; 27 Oct 2017 17:15:59 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6918
MAPREDUCE-6919,Bug,Major,mrv2,ShuffleMetrics.ShuffleConnections Gauge Metric Rises Infinitely,We recently noticed that the mapred.ShuffleMetrics.ShuffleConnections metric rises indefinitely (see attached graph); despite supposedly being a gauge measuring the number of currently open connections:     It seems this is because the metric is incremented once for each map file sent; but decremented once for each request. Thus a request which fetches multiple map files permanently increments shuffleConnections by (mapsFetched - 1).,Open,Unresolved,MAPREDUCE-6918,Unassigned,Erik Krogen,Tue; 25 Jul 2017 23:45:20 +0000,Fri; 27 Oct 2017 17:15:59 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6919
MAPREDUCE-6920,Bug,Minor,,Cannot find the effect of mapreduce.job.speculative.slowtaskthreshold parameter,The description of parameter mapreduce.job.speculative.slowtaskthreshold is as below.    But from the source code I find it has no effect for starting speculative task. The call stack is as below. DefaultSpeculator.speculationValue - StartEndTimesBase.thresholdRuntime - DataStatistics.outlier           The StartEndTimesBase.contextualize read mapreduce.job.speculative.slowtaskthreshold parameter value; then use it as outlier method parameter sigma value.     I think the outlier return value is hard to be Long.MAX_VALUE no matter what the mapreduce.job.speculative.slowtaskthreshold parameter value is. Then it cannot affect the return value of DefaultSpeculator.speculationValue method. Then I run a test for this parameter. Test source code is as below.         The input path has 10 files in hdfs. Only one file has 10 lines and other files has one line. The mapper task processing that file has 10 lines must be slow and cause speculative task attempt. The test result is the speculative task start time has no obviouse difference for mapreduce.job.speculative.slowtaskthreshold=1 and mapreduce.job.speculative.slowtaskthreshold=10.  If any one find the same issue. Or I misunderstand mapreduce.job.speculative.slowtaskthreshold parameter.,Open,Unresolved,,Unassigned,NING DING,Wed; 26 Jul 2017 04:05:57 +0000,Wed; 26 Jul 2017 16:19:04 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6920
MAPREDUCE-6921,Bug,Major,,TestUmbilicalProtocolWithJobToken#testJobTokenRpc fails,The test fails consistently without the error below :,Resolved,Fixed,,Sonia Garudi,Sonia Garudi,Fri; 28 Jul 2017 04:24:21 +0000,Tue; 1 Aug 2017 06:28:43 +0000,Tue; 1 Aug 2017 06:07:01 +0000,,3.0.0-beta1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6921
MAPREDUCE-6922,Bug,Blocker,,MapReduce jobs may fail during rolling upgrade due to MAPREDUCE-6829,MAPREDUCE-6829 should be reverted from branch-2 because rolling upgrade fails.,Resolved,Duplicate,MAPREDUCE-6829;MAPREDUCE-6978,Miklos Szegedi,Miklos Szegedi,Mon; 31 Jul 2017 21:19:53 +0000,Tue; 10 Oct 2017 02:32:06 +0000,Mon; 31 Jul 2017 21:50:12 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6922
MAPREDUCE-6923,Improvement,Major,,Optimize MapReduce Shuffle I/O for small partitions,When a job configuration results in small partitions read by each reducer from each mapper (e.g. 65 kilobytes as in my setup: a TeraSort of 256 gigabytes using 2048 mappers and reducers each); and setting     then the default setting of     results in almost 100% overhead in reads during shuffle in YARN; because for each 65K needed; 128K are read.  I propose a fix in FadvisedFileRegion. as follows:     e.g. here. This sets the shuffle buffer size to the minimum value of the shuffle buffer size specified in the configuration (128K by default); and the actual partition size (65K on average in my setup). In my benchmarks this reduced the read overhead in YARN from about 100% (255 additional gigabytes as described above) down to about 18% (an additional 45 gigabytes). The runtime of the job remained the same in my setup.,Resolved,Fixed,,Robert Schmidtke,Robert Schmidtke,Mon; 31 Jul 2017 21:28:25 +0000,Thu; 10 Aug 2017 17:19:27 +0000,Wed; 9 Aug 2017 22:42:42 +0000,,,,,MAPREDUCE-5791,https://issues.apache.org/jira/browse/MAPREDUCE-6923
MAPREDUCE-6924,Bug,Major,,Revert MAPREDUCE-6199 MAPREDUCE-6286 and MAPREDUCE-5875,Filing this JIRA so the reverts show up in the changelog.,Resolved,Fixed,,Junping Du,Andrew Wang,Mon; 31 Jul 2017 21:43:08 +0000,Mon; 31 Jul 2017 21:43:58 +0000,Mon; 31 Jul 2017 21:43:58 +0000,,3.0.0-alpha1,,,MAPREDUCE-6288,https://issues.apache.org/jira/browse/MAPREDUCE-6924
MAPREDUCE-6925,Bug,Major,applicationmaster;client;task,CLONE - Make Counter limits consistent across JobClient; MRAppMaster; and YarnChild,"Currently; counter limits ""mapreduce.job.counters.*"" handled by org.apache.hadoop.mapreduce.counters.Limits are initialized asymmetrically: on the client side; and on the AM; job.xml is ignored whereas it's taken into account in YarnChild.  It would be good to make the Limits job-configurable; such that max counters groups is only increased when needed. With the current Limits implementation relying on static constants; it's going to be challenging for tools that submit jobs concurrently  without resorting to class loading isolation.  The patch that I am uploading is not perfect but demonstrates the issue.",Open,Unresolved,,Gera Shegalov,Gera Shegalov,Mon; 31 Jul 2017 22:00:44 +0000,Fri; 29 Sep 2017 20:56:29 +0000,,,2.4.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6925
MAPREDUCE-6926,Task,Major,mrv2,Allow MR jobs to opt out of oversubscription,nan,Resolved,Fixed,,Haibo Chen,Haibo Chen,Tue; 1 Aug 2017 17:47:58 +0000,Wed; 10 Jan 2018 22:50:37 +0000,Wed; 10 Jan 2018 22:47:48 +0000,,3.0.0-alpha3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6926
MAPREDUCE-6927,Bug,Major,,MR job should only set tracking url if history was successfully written,Currently the RMCommunicator will set the tracking url during unregistration once a job has finished; regardless of whether it actually wrote history or not. If the write to history failed for whatever reason; we should leave the tracking url as null so that we get redirected to the AHS instead of getting a job not found on the JHS.,Resolved,Fixed,,Eric Badger,Eric Badger,Tue; 1 Aug 2017 21:53:46 +0000,Tue; 8 Aug 2017 22:20:22 +0000,Tue; 8 Aug 2017 20:09:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6927
MAPREDUCE-6928,Improvement,Minor,mrv2,BackupStore Should Checksum Files Persisted To Disk,The class org.apache.hadoop.mapred.BackupStore persists data to memory or disk.  Like the IFile format that this class works in tandem with; the data in BackupStore should be under a check sum to prevent otherwise good data from becoming corrupt.,Open,Unresolved,,Unassigned,BELUGA BEHR,Wed; 2 Aug 2017 18:52:40 +0000,Wed; 2 Aug 2017 18:52:40 +0000,,,2.8.1;3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6928
MAPREDUCE-6929,Improvement,Major,mr-am,TimelineV2Client hangs MR AM,I happened to misconfigure ATSv2 settings; that is; I enabled emitting to ATSv2 in MR and did not start YARN with ATSv2. The job was stuck after it finished all its work.   Noticed that in MRAppMaster; TimelineClient is never added as a service; which I think is why the AM was hanging.,Resolved,Not A Problem,,Unassigned,Haibo Chen,Wed; 2 Aug 2017 20:55:40 +0000,Thu; 3 Aug 2017 20:36:48 +0000,Thu; 3 Aug 2017 20:36:48 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6929
MAPREDUCE-6930,Bug,Major,mrv2,mapreduce.map.cpu.vcores and mapreduce.reduce.cpu.vcores are both present twice in mapred-default.xml,The second set should be deleted.,Open,Unresolved,,Unassigned,Daniel Templeton,Wed; 2 Aug 2017 23:34:48 +0000,Thu; 3 Aug 2017 15:08:31 +0000,,,2.7.4;2.8.1;3.0.0-alpha4,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6930
MAPREDUCE-6931,Bug,Critical,benchmarks;test,"Remove TestDFSIO ""Total Throughput"" calculation","The new ""Total Throughput"" line added in https: 1000x the actual value:     The different calculated fields can also use toMB and a shared milliseconds-to-seconds conversion to make it easier to keep units consistent.",Resolved,Fixed,,Dennis Huo,Dennis Huo,Thu; 3 Aug 2017 00:33:39 +0000,Fri; 1 Sep 2017 21:59:22 +0000,Wed; 30 Aug 2017 22:13:39 +0000,,2.8.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6931
MAPREDUCE-6932,Test,Major,test,Upgrade JUnit from 4 to 5 in hadoop-mapreduce,nan,Open,Unresolved,,Unassigned,Akira Ajisaka,Thu; 3 Aug 2017 09:02:43 +0000,Thu; 3 Aug 2017 09:03:48 +0000,,,,,MAPREDUCE-6050,HADOOP-14693,https://issues.apache.org/jira/browse/MAPREDUCE-6932
MAPREDUCE-6933,Bug,Major,mrv2,Invalid event: TA_CONTAINER_LAUNCH_FAILED at KILLED,When I run a job on 0.23.1; I found a InvalidStateTransitonException:    After I manually analyse the code of 3.0.0;I think this error may still exists.,Resolved,Duplicate,MAPREDUCE-5409;MAPREDUCE-3932,Unassigned,lujie,Fri; 4 Aug 2017 08:47:27 +0000,Fri; 4 Aug 2017 13:36:21 +0000,Fri; 4 Aug 2017 13:36:21 +0000,,0.23.1;3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6933
MAPREDUCE-6934,Bug,Minor,pipes,downlink.data is written to CWD,When using Pipes; the downlink.data stream is written to the current working directory.  This is a big of a problem when running MR jobclient tests in parallel as the file is written outside of target.,Open,Unresolved,,Unassigned,Allen Wittenauer,Sat; 5 Aug 2017 04:27:49 +0000,Sat; 5 Aug 2017 04:27:49 +0000,,,3.0.0-beta1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6934
MAPREDUCE-6935,Sub-task,Major,,Allow multiple active timeline clients ,In order to migrate smoothly from timeline service v1 to v2; it would be useful to be able to run both services at the same time for a period of time.,Open,Unresolved,,Unassigned,Aaron Gresch,Thu; 10 Aug 2017 14:09:08 +0000,Sat; 19 Aug 2017 16:29:02 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6935
MAPREDUCE-6936,Bug,Major,mrv2,Remove unnecessary dependency of hadoop-yarn-server-common from hadoop-mapreduce-client-common ,The dependency of hadoop-yarn-server-common in hadoop-mapreduce-client-common seems unnecessary; as  it is not using as of the classes from hadoop-yarn-server-common.,Resolved,Fixed,,Haibo Chen,Haibo Chen,Thu; 10 Aug 2017 19:15:15 +0000,Wed; 16 Aug 2017 23:52:59 +0000,Wed; 16 Aug 2017 23:21:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6936
MAPREDUCE-6937,Improvement,Major,,Backport MAPREDUCE-6870 to branch-2 while preserving compatibility,To maintain compatibility we need to disable this by default per discussion on MAPREDUCE-6870.  Using a separate JIRA to correctly track incompatibilities.,Resolved,Fixed,,Peter Bacsko,Zhe Zhang,Mon; 14 Aug 2017 16:34:04 +0000,Mon; 11 Sep 2017 20:15:50 +0000,Thu; 31 Aug 2017 16:31:14 +0000,,,,,MAPREDUCE-6870,https://issues.apache.org/jira/browse/MAPREDUCE-6937
MAPREDUCE-6938,Task,Minor,,Question,I need 2 helps.  1) need a Java map reducer sample program where multiple parameters  are passed from mapper to reducer. 2) need a Java map reducer program where there is a write to a file inside  hdfs filesystem as well as a read from a file inside hdfs other than  the normal input file and output file mentioned in the mapper and reducer.,Resolved,Invalid,,Unassigned,Remil,Tue; 15 Aug 2017 13:46:38 +0000,Tue; 15 Aug 2017 15:56:26 +0000,Tue; 15 Aug 2017 15:56:26 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6938
MAPREDUCE-6939,Bug,Minor,client,Follow-up on MAPREDUCE-6870,"Some minor changes should be made after MAPREDUCE-6870 was committed upstream:  1. Fix JavaDoc in JobImpl. 2. Correct the description of the method; that is; it might not be entirely clear what the ""improvement"" is or what it really improves 3. Small typo in the name of the new testcase",Open,Unresolved,,Peter Bacsko,Peter Bacsko,Tue; 15 Aug 2017 16:48:47 +0000,Tue; 15 Aug 2017 16:49:45 +0000,,,,,,MAPREDUCE-6870,https://issues.apache.org/jira/browse/MAPREDUCE-6939
MAPREDUCE-6940,Bug,Minor,,Copy-paste error in the TaskAttemptUnsuccessfulCompletionEvent constructor,This constructor seems to be copy-pasted from another one; but it doesn't pass allSplits parameter as expected.  Lines 126-133:,Resolved,Fixed,,Oleg Danilov,Oleg Danilov,Wed; 16 Aug 2017 13:08:31 +0000,Wed; 16 Aug 2017 22:01:08 +0000,Wed; 16 Aug 2017 21:38:42 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6940
MAPREDUCE-6941,Bug,Blocker,,The default setting doesn't work for MapReduce job,On the deployment of hadoop 3 cluster (based on current trunk branch) with default settings; the MR job will get failed as following exceptions:    This is because mapreduce related jar are not added into yarn setup by default. To make MR job run successful; we need to add following configurations to yarn-site.xml now:   But this config is not necessary for previous version of Hadoop. We should fix this issue before beta release otherwise it will be a regression for configuration changes.  This could be more like a YARN issue (if so; we should move); depends on how we fix it finally.,Resolved,Not A Problem,,Unassigned,Junping Du,Wed; 16 Aug 2017 20:24:15 +0000,Wed; 6 Sep 2017 01:23:02 +0000,Wed; 6 Sep 2017 00:36:00 +0000,,3.0.0-beta1,,,MAPREDUCE-6704,https://issues.apache.org/jira/browse/MAPREDUCE-6941
MAPREDUCE-6942,Improvement,Minor,,Add descriptions for jobhistory.done-dir configs,The following two configs    in mapred-default.xml do not have descpritions. It would be more friendly for developers if add the descpritions,Patch Available,Unresolved,,Unassigned,Yeliang Cang,Thu; 17 Aug 2017 04:54:15 +0000,Thu; 17 Aug 2017 05:56:52 +0000,,,3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6942
MAPREDUCE-6943,New Feature,Major,,Mapreduce tasks for YARN Timeline Service v.2: beta 1,nan,Open,Unresolved,,Varun Saxena,Varun Saxena,Sat; 19 Aug 2017 16:25:59 +0000,Sat; 19 Aug 2017 16:27:30 +0000,,,,,,MAPREDUCE-6732,https://issues.apache.org/jira/browse/MAPREDUCE-6943
MAPREDUCE-6944,Bug,Critical,applicationmaster;resourcemanager,MR job got hanged forever when some NMs unstable for some time,We encountered several jobs in the production environment due to the fact that some of the NM unstable cause one MAP of the job to be stuck there; and the job can't finish properly. However; the problems we encountered were different from those mentioned in https: MAPREDUCE-6513.  Because in our scenario; all of MR REDUCEs does not start executing. But when I manually kill the hanged MAP; the job will be finished normally.,Open,Unresolved,,Unassigned,YunFan Zhou,Mon; 21 Aug 2017 07:17:54 +0000,Sun; 27 Aug 2017 15:05:58 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6944
MAPREDUCE-6945,Bug,Minor,,TestMapFileOutputFormat missing @after annotation,TestMapFileOutputFormat missing @after annotation.,Resolved,Fixed,,Ajay Kumar,Ajay Kumar,Mon; 21 Aug 2017 18:13:18 +0000,Sun; 27 Aug 2017 22:47:08 +0000,Sun; 27 Aug 2017 22:23:53 +0000,,,,,HADOOP-14729,https://issues.apache.org/jira/browse/MAPREDUCE-6945
MAPREDUCE-6946,Improvement,Major,,Moving logging APIs over to slf4j in hadoop-mapreduce,MapReduce side of YARN-6712. This is an umbrella jira for MapReduce.,Open,Unresolved,,Unassigned,Akira Ajisaka,Thu; 24 Aug 2017 04:34:48 +0000,Fri; 29 Sep 2017 20:56:12 +0000,,,,,,HADOOP-12956,https://issues.apache.org/jira/browse/MAPREDUCE-6946
MAPREDUCE-6947,Sub-task,Major,, Moving logging APIs over to slf4j in hadoop-mapreduce-examples,nan,Resolved,Fixed,,Gergely Nov  k,Gergely Nov  k,Fri; 25 Aug 2017 12:09:23 +0000,Fri; 22 Sep 2017 04:51:50 +0000,Fri; 22 Sep 2017 04:31:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6947
MAPREDUCE-6948,Bug,Major,,TestJobImpl.testUnusableNodeTransition failed,Error Message expected:SUCCEEDED but was:ERROR  Stacktrace  615)   Standard out,Open,Unresolved,,Jim Brennan,Haibo Chen,Wed; 30 Aug 2017 16:22:15 +0000,Fri; 15 Dec 2017 22:38:42 +0000,,,3.0.0-alpha4,unit-test,,,https://issues.apache.org/jira/browse/MAPREDUCE-6948
MAPREDUCE-6949,Bug,Minor,documentation,yarn.app.mapreduce.am.log.level is not documented in mapred-default.xml,nan,Resolved,Duplicate,MAPREDUCE-6648,Haibo Chen,Haibo Chen,Wed; 30 Aug 2017 20:02:21 +0000,Wed; 30 Aug 2017 20:21:11 +0000,Wed; 30 Aug 2017 20:21:11 +0000,,3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6949
MAPREDUCE-6950,Improvement,Major,mr-am,Error Launching job : java.io.IOException: Unknown Job job_xxx_xxx,some job report error; like this:    I found the am container log; like below. Here we know error happened in pipeline; maybe some dn error. And I also found some other reason which close the JobHistoryEventHandler. So MR AM can't write the information for JH. So client counldn't know whether the appplication is finished.      This problem is serious ; especially for hive. Job must rerun meaninglessly!  So I think we need to retry the operation of writing history event.,Open,Unresolved,,Unassigned,zhengchenyu,Fri; 1 Sep 2017 03:54:02 +0000,Fri; 15 Dec 2017 20:38:36 +0000,,,2.7.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6950
MAPREDUCE-6951,Bug,Major,applicationmaster,Improve exception message when mapreduce.jobhistory.webapp.address is in wrong format,MapReduce jobs fails with below exception when mapreduce.jobhistory.webapp.address is in wrong format instead of host:port; example user has set to 19888,Resolved,Fixed,,Prabhu Joseph,Prabhu Joseph,Thu; 7 Sep 2017 14:00:12 +0000,Wed; 11 Oct 2017 09:55:30 +0000,Wed; 11 Oct 2017 09:53:49 +0000,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6951
MAPREDUCE-6952,Bug,Major,client,Using DistributedCache.addFileToClasspath with a rename fragment fails during job submit,Calling DistributedCache.addFileToClasspath with a Path that specifies a URI fragment; used to rename the file during localization; causes job submission to fail with a FileNotFoundException.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 7 Sep 2017 14:55:19 +0000,Thu; 7 Sep 2017 15:03:34 +0000,,,2.7.4;2.8.1,,,MAPREDUCE-6846,https://issues.apache.org/jira/browse/MAPREDUCE-6952
MAPREDUCE-6953,Test,Major,client,Skip the testcase testJobWithChangePriority if FairScheduler is used,We run the unit tests with Fair Scheduler downstream. FS does not support priorities at the moment; so TestMRJobs#testJobWithChangePriority fails.  Just add Assume.assumeFalse(usingFairScheduler); and JUnit will skip the test.,Resolved,Fixed,,Peter Bacsko,Peter Bacsko,Fri; 8 Sep 2017 11:15:37 +0000,Thu; 28 Sep 2017 17:43:14 +0000,Fri; 8 Sep 2017 20:22:02 +0000,,,,,YARN-2098,https://issues.apache.org/jira/browse/MAPREDUCE-6953
MAPREDUCE-6954,Improvement,Major,client,Disable erasure coding for files that are uploaded to the MR staging area,Depending on the encoder decoder used and the type or MR workload; EC might negatively affect the performance of an MR job if too many files are localized.  In such a scenario; users might want to disable EC in the staging area to speed up the execution.,Resolved,Fixed,,Peter Bacsko,Peter Bacsko,Fri; 8 Sep 2017 12:58:25 +0000,Tue; 12 Dec 2017 22:45:14 +0000,Fri; 15 Sep 2017 19:07:31 +0000,,3.0.0-alpha4,,,HDFS-12919,https://issues.apache.org/jira/browse/MAPREDUCE-6954
MAPREDUCE-6955,Bug,Major,,remove unnecessary dependency from hadoop-mapreduce-client-app to hadoop-mapreduce-client-shuffle,nan,Resolved,Not A Problem,,Haibo Chen,Haibo Chen,Fri; 8 Sep 2017 16:26:24 +0000,Fri; 8 Sep 2017 16:32:47 +0000,Fri; 8 Sep 2017 16:32:47 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6955
MAPREDUCE-6956,Improvement,Minor,mrv2,FileOutputCommitter to gain abstract superclass PathOutputCommitter,This is the initial step of MAPREDUCE-6823; which proposes a factory behind FileOutputForm factory is done; for it to be switched to easily. And I'd like this in branch-3 from the outset; so existing code which calls FileOutputFormat.getCommitter() to get a FileOutputCommitter just to call getWorkPath() can move to the new interface across all of Hadoop 3.,Resolved,Fixed,,Steve Loughran,Steve Loughran,Fri; 8 Sep 2017 18:05:57 +0000,Tue; 19 Sep 2017 09:46:40 +0000,Fri; 15 Sep 2017 16:01:44 +0000,,3.0.0-beta1,,,MAPREDUCE-6961,https://issues.apache.org/jira/browse/MAPREDUCE-6956
MAPREDUCE-6957,Bug,Major,mrv2,shuffle hangs after a node manager connection timeout,After a connection failure from the reducer to the node manager; shuffles started to hang with the following message:     There are two problems that leads to the hang.  Problem 1. When a reducer has an issue connecting to the node manager; copyFromHost may call putBackKnownMapOutput on the same task attempt multiple times.  There are two call sites of putBackKnownMapOutput in copyFromHost since MAPREDUCE-6303: 1. In the finally block of copyFromHost 2. In the catch block of openShuffleUrl.  When openShuffleUrl fails to connect from the catch block in copyFromHost; it returns null. By the time openShuffleUrl returns null; putBackKnownMapOutput would have been called already for all remaining map outputs. However; the finally block calls putBackKnownMapOutput one more time on the map outputs.  Problem 2. Problem 1 causes a leak in MergeManager. The problem occurs when multiple fetchers get the same set of map attempt outputs to fetch. Different fetchers reserves memory from MergeManager in Fetcher.copyMapOutput for the same map outputs. When the fetch succeeds; only the first map output gets committed through ShuffleSchedulerImpl.copySucceeded - InMemoryMapOutput.commit; because commit() is gated by !finishedMapsmapIndex. This may lead to a condition where usedMemory  memoryLimit; while commitMemory  mergeThreshold. This gets the MergeManager into a deadlock where a merge is never triggered while MergeManager cannot reserve additional space for map outputs.,Resolved,Fixed,,Jooseong Kim,Jooseong Kim,Mon; 11 Sep 2017 18:19:41 +0000,Thu; 14 Sep 2017 19:58:19 +0000,Wed; 13 Sep 2017 22:34:21 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6957
MAPREDUCE-6958,Improvement,Minor,,Shuffle audit logger should log size of shuffle transfer,The shuffle audit logger currently logs the job ID and reducer ID but nothing about the size of the requested transfer.  It calculates this as part of the HTTP response headers; so it would be trivial to log the response size.  This would be very valuable for debugging network traffic storms from the shuffle handler.,Resolved,Fixed,,Jason Lowe,Jason Lowe,Thu; 14 Sep 2017 21:53:06 +0000,Tue; 19 Sep 2017 15:27:36 +0000,Tue; 19 Sep 2017 15:27:36 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6958
MAPREDUCE-6959,Wish,Trivial,,Understanding on process to start contribution,I was trying to find process jira issue and start woking on it?  Any direction would be really appreciated!  Thanks; Mehul,Resolved,Invalid,,Unassigned,Mehul Garnara (MG),Mon; 18 Sep 2017 17:36:53 +0000,Mon; 18 Sep 2017 18:49:57 +0000,Mon; 18 Sep 2017 18:27:55 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6959
MAPREDUCE-6960,Bug,Major,,Shuffle Handler prints disk error stack traces for every read failure.,In cases where the read from a disk fails and throws a DiskErrorException; the shuffle handler prints the entire stack trace for each and every one of the failures causing the nodemanager logs to quickly fill up the disk.,Resolved,Fixed,,Kuhu Shukla,Kuhu Shukla,Mon; 18 Sep 2017 20:16:03 +0000,Thu; 28 Sep 2017 17:43:31 +0000,Tue; 19 Sep 2017 16:11:40 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6960
MAPREDUCE-6961,Improvement,Minor,mrv2,Pull up FileOutputCommitter.getOutputPath to PathOutputCommitter,SPARK-21549 has shown that downstream code is relying on the internal property   if we pulled FileOutputCommitter.getOutputPath to the PathOutputCommitter of MAPREDUCE-6956; then there'd be a public stable way to get this. Admittedly; it does imply that the committer will always have some output path; but FileOutputFormat depends on that anyway.,Open,Unresolved,,Steve Loughran,Steve Loughran,Tue; 19 Sep 2017 09:46:05 +0000,Tue; 14 Nov 2017 19:37:08 +0000,,,3.0.0-beta1,,,MAPREDUCE-6823;SPARK-21549;MAPREDUCE-6956,https://issues.apache.org/jira/browse/MAPREDUCE-6961
MAPREDUCE-6962,Bug,Minor,,Remove unused settings from log4j.properties,hadoop.tasklog.noKeepSplits; purgeLogSplits; and logsRetainHours are not used anywhere and can be removed. These parameters were removed by HADOOP-1553 10 years ago.,Resolved,Fixed,HADOOP-7308,Unassigned,Akira Ajisaka,Wed; 20 Sep 2017 11:43:20 +0000,Wed; 20 Sep 2017 12:05:03 +0000,Wed; 20 Sep 2017 12:05:03 +0000,,,newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6962
MAPREDUCE-6963,Bug,Major,mr-am,MR Map or Reduce specified node label is missing due to concurrent task limits,In RMContainerAllocator#applyConcurrentTaskLimits; we limit the degree of task parallelism but not consider the node label specified for the ResourceRequest.   Then we call the applyRequestLimits in RMContainerAllocator#makeRemoteRequest to apply the request limits. When the req.getNumContainers()  limit conditions are met the original ResourceRequest(ask) will be replaced by the reqLimit which was generated by the above.,Open,Unresolved,,Unassigned,wei,Thu; 21 Sep 2017 03:07:56 +0000,Thu; 21 Sep 2017 03:07:56 +0000,,,2.8.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6963
MAPREDUCE-6964,Bug,Minor,examples,BaileyBorweinPlouffe should use Time.monotonicNow for measuring durations,nan,Resolved,Fixed,,Chetna Chaudhari,Chetna Chaudhari,Wed; 20 Sep 2017 03:28:27 +0000,Thu; 21 Sep 2017 19:39:06 +0000,Thu; 21 Sep 2017 14:44:23 +0000,,,,,HADOOP-14713,https://issues.apache.org/jira/browse/MAPREDUCE-6964
MAPREDUCE-6965,Bug,Minor,examples,QuasiMonteCarlo should use Time.monotonicNow for measuring durations,nan,Resolved,Fixed,,Chetna Chaudhari,Chetna Chaudhari,Wed; 20 Sep 2017 03:17:18 +0000,Fri; 22 Sep 2017 21:11:48 +0000,Fri; 22 Sep 2017 14:37:57 +0000,,,,,HADOOP-14713,https://issues.apache.org/jira/browse/MAPREDUCE-6965
MAPREDUCE-6966,Bug,Minor,,DistSum should use Time.monotonicNow for measuring durations,Sub-task for HADOOP-14713,Resolved,Fixed,,Chetna Chaudhari,Chetna Chaudhari,Wed; 20 Sep 2017 03:28:44 +0000,Fri; 22 Sep 2017 21:11:23 +0000,Fri; 22 Sep 2017 06:12:19 +0000,,,,,HADOOP-14713,https://issues.apache.org/jira/browse/MAPREDUCE-6966
MAPREDUCE-6967,Bug,Minor,,gridmix/SleepReducer should use Time.monotonicNow for measuring durations,nan,Resolved,Fixed,,Chetna Chaudhari,Chetna Chaudhari,Wed; 20 Sep 2017 03:29:03 +0000,Fri; 22 Sep 2017 21:10:35 +0000,Fri; 22 Sep 2017 20:31:39 +0000,,,,,HADOOP-14713,https://issues.apache.org/jira/browse/MAPREDUCE-6967
MAPREDUCE-6968,Bug,Major,client,Staging directory erasure coding config property has a typo,"TestMapreduceConfigFields has been failing since MAPREDUCE-6954. MRJobConfig#MR_AM_STAGING_DIR_ERASURECODING_ENABLED is defined as ""yarn.app.mapreduce.am.staging-direrasurecoding.enabled""  but the property is listed as ""yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled"" in mapred-default.xml.",Resolved,Fixed,,Jason Lowe,Jason Lowe,Tue; 26 Sep 2017 17:48:08 +0000,Tue; 26 Sep 2017 20:14:35 +0000,Tue; 26 Sep 2017 19:54:24 +0000,,3.0.0-beta1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6968
YARN-7257,Bug,Major,log-aggregation,AggregatedLogsBlock reports a bad 'end' value as a bad 'start' value,TestHSWebApp has been failing recently:,Resolved,Fixed,,Jason Lowe,Jason Lowe,Tue; 26 Sep 2017 21:03:07 +0000,Wed; 27 Sep 2017 23:05:52 +0000,Wed; 27 Sep 2017 23:04:49 +0000,,2.9.0;3.0.0-beta1,,,,https://issues.apache.org/jira/browse/YARN-7257
MAPREDUCE-6970,Improvement,Major,,archive-logs tool should throttle container requests,The mapred archive-logs command currently has no way to throttle the number of requested containers.  For example; we recently saw a busy cluster where the tool hadn't been run for a while and there were about 20;000 apps to process.  This meant that the tool tried to request 20;000 containers and got a ton of GC and then OOM trying to handle that.  This problem can be mitigated by setting -maxEligibleApps to a more reasonable value; but doing so would require running the tool multiple times; plus; the default value is -1 (all).  We should add a way to throttle the max number of concurrently running containers that the tool manages.  Something like -concurrency n where it would only allow up to n containers at a time.,Open,Unresolved,,Unassigned,Robert Kanter,Wed; 27 Sep 2017 00:28:59 +0000,Wed; 27 Sep 2017 00:29:25 +0000,,,2.8.0;3.0.0-alpha1,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-6970
MAPREDUCE-6971,Sub-task,Major,,Moving logging APIs over to slf4j in hadoop-mapreduce-client-app,nan,Resolved,Fixed,,Jinjiang Ling,Jinjiang Ling,Wed; 27 Sep 2017 05:13:29 +0000,Tue; 3 Oct 2017 03:32:22 +0000,Tue; 3 Oct 2017 03:16:25 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6971
MAPREDUCE-6972,Improvement,Major,,Enable try-with-resources for RecordReader,org.apache.hadoop.mapred.RecordReader has a close method; but doesn't implement closeable; it would be nice to add that - it would enable to use:     ...supporting t-w-r makes it easier to throw exceptions more safely,Resolved,Fixed,,Zoltan Haindrich,Zoltan Haindrich,Fri; 29 Sep 2017 07:28:33 +0000,Wed; 18 Oct 2017 02:43:09 +0000,Wed; 18 Oct 2017 02:20:10 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6972
MAPREDUCE-6973,Bug,Trivial,documentation,"Comment refers to ""_done"" file instead of ""_SUCCESS"" file","I went through couple of old JIRA issues and understood that earlier app was creating ""_done"" file on job has completed successfully. After some conversation by group decided to create ""_SUCCESS"" instead of ""_done"". However; while learning the code; I found there is one comment has reference of ""_done"" and would like to start with small contribution to fix it.   Note: I would like to work on this trivial issue so can get opportunity to follow standard process of contribution steps; that will myself to come on track quickly for future contribution that I would like to do.",Open,Unresolved,,Mehul Garnara (MG),Mehul Garnara (MG),Fri; 29 Sep 2017 16:48:02 +0000,Tue; 14 Nov 2017 19:37:08 +0000,,,3.0.0-beta1,easyfix;newbie,,,https://issues.apache.org/jira/browse/MAPREDUCE-6973
MAPREDUCE-6974,Improvement,Minor,job submission;performance,Add standard configuration keys for HTrace values; propagate across to MR committers if set,HDFS c support HTrace logging; HBase sets up spans.  What doesn't do spans is MR jobs or other frameworks with use the MR committers.  That can be addressed by defining some standard configuration keys for HTrace hi low numbers; setting them in job submission; then passing them over the wire in the Configuration; where setupJob and setupTask can extract them  use for the tracing span. They could also add their own span for taskCommit and jobCommit for performance measurement there.  Although the core code would be in MR; I'd propose putting the keys into Hadoop common;  with some code in org.apache.hadoop.tracing.TraceUtils; to set it up. That way its possible to use more broadly.,Open,Unresolved,,Unassigned,Steve Loughran,Tue; 3 Oct 2017 15:55:02 +0000,Wed; 13 Dec 2017 10:53:54 +0000,,,3.0.0-beta1,,,HADOOP-13786,https://issues.apache.org/jira/browse/MAPREDUCE-6974
MAPREDUCE-6975,Improvement,Major,task,Logging task counters ,Logging counters for each task at the end of it's syslog will make debug easier with just application logs.,Resolved,Fixed,,Prabhu Joseph,Prabhu Joseph,Thu; 5 Oct 2017 13:15:39 +0000,Mon; 6 Nov 2017 13:54:59 +0000,Mon; 6 Nov 2017 11:20:42 +0000,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6975
MAPREDUCE-6976,Bug,Minor,,mapred job -set-priority claims to set priority higher than yarn.cluster.max-application-priority,With yarn.cluster.max-application-priority set to 20 and job_1507226760578_0002 running at priority 0; run the following command:   The above commands sets job_1507226760578_0002 to priority 20. If job_1507226760578_0002 is already at 20; the command does nothing.  Compare this behavior to running the yarn application -updatePriority command:,Open,Unresolved,,Unassigned,Eric Payne,Thu; 5 Oct 2017 18:29:23 +0000,Thu; 5 Oct 2017 18:29:23 +0000,,,2.9.0;2.8.1;3.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6976
MAPREDUCE-6977,Sub-task,Major,client,Moving logging APIs over to slf4j in hadoop-mapreduce-client-common,committed to trunk; slight merge conflict in imports of MRApps. to resolve; nothing significant. did a clean rebuilt to make sure all was well,Resolved,Fixed,,Jinjiang Ling,Jinjiang Ling,Mon; 9 Oct 2017 05:52:01 +0000,Fri; 27 Oct 2017 10:03:28 +0000,Fri; 27 Oct 2017 10:03:28 +0000,,3.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6977
MAPREDUCE-6978,Improvement,Major,mr-am;task,MR task counters deserialized through RPC throws OutOfBoundsException if Counter enum class version not match,Environment: NM1 TaskCounter.class old version;  NM2 TaskCounter.class new version (new Enumeration values appended);   Result: When an MR app's AM running on NM1; and it's containers on NM2; the containers on NM2 will all failed; AM cause OutOfBoundsException;  Reason: When app running; containers will report their counters to AM through RPC; while the Container with new version TaskCounter.class will write more Counter values to RPC; however; the AM with old version TaskCounter.class which can not read them correctly from RPC.,Resolved,Duplicate,MAPREDUCE-6922,Unassigned,rangjiaheng,Mon; 9 Oct 2017 17:10:41 +0000,Tue; 10 Oct 2017 14:45:24 +0000,Mon; 9 Oct 2017 17:53:15 +0000,,3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6978
MAPREDUCE-6979,Improvement,Major,mr-am;task,CLONE - MR task counters deserialized through RPC throws OutOfBoundsException if Counter enum class version not match,Environment: NM1 TaskCounter.class old version;  NM2 TaskCounter.class new version (new Enumeration values appended);   Result: When an MR app's AM running on NM1; and it's containers on NM2; the containers on NM2 will all failed; AM cause OutOfBoundsException;  Reason: When app running; containers will report their counters to AM through RPC; while the Container with new version TaskCounter.class will write more Counter values to RPC; however; the AM with old version TaskCounter.class which can not read them correctly from RPC.,Resolved,Duplicate,NULL,Unassigned,rangjiaheng,Tue; 10 Oct 2017 02:26:11 +0000,Tue; 10 Oct 2017 02:29:48 +0000,Tue; 10 Oct 2017 02:28:26 +0000,,3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6979
MAPREDUCE-6980,Improvement,Minor,nativetask;performance,Add support of ARM64 hardware crc instructions for nativetask,CRC instructions are introduced since ARM64V8 ISA. With this extension Arm supports CRC32(0x04C11DB7) and CRC32C(0x1EDC6F41) checksum hardware computation. This patch enables support on such arm64 platform; similiar as HADOOP-11660. Benchmark is done on a A57 platform using nttest (hadoop-mapreduce-project s [       OK ] Perf.CRC (77 ms),Patch Available,Unresolved,,Unassigned,Jun He,Wed; 11 Oct 2017 05:08:44 +0000,Fri; 17 Nov 2017 09:41:52 +0000,,,3.0.0-alpha3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6980
MAPREDUCE-6981,Bug,Minor,distcp,Map Progress is misleading for Distcp job,The Progress displayed by client when running Distcp job is misleading. The Map Progress reaches 100% earlier than the map tasks finishes. The issue reproduced by just running Distcp with multiple huge files.   JobImpl returns progress 1.0 when either task finishes or task progress is 1.0. The MapTask of Distcp gets the progress from SequenceFileRecordReader which looks like updates the progress after reading the list of files and which does not account the time taken to copy the files into Destination.     The MapTask Progress 100% is displayed at   whereas the last map task finishes at 2017-10-11 13:34:45     Attaching the client and application logs.,Open,Unresolved,,Unassigned,Prabhu Joseph,Wed; 11 Oct 2017 14:00:38 +0000,Wed; 11 Oct 2017 14:02:21 +0000,,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6981
MAPREDUCE-6982,Bug,Minor,mr-am,Containers on lost nodes are considered failed after a too long time.,"Containers on lost nodes (nodemanager being unavailable or server being unavailable) are considered failed after a too long time. This is due to the AppMaster trying to cleanup the container on the unavailable node. The proposed path will limit the impact of this timeout by managing NodeManager lost events on AM as described below:  	on nodemanager service unavailibility (crash; oom ...):     When receiving lost NodeManager events; it failed the impacted attempt and do not go through the cleanup stage. 	on nodemanager server unavailibility with default settings AM detect first that the attempt is in timeout and try to cleanup the attempt: When receiving lost NodeManager events; it stop the cleanup process on the impacted container and failed the attempt.    This reduce the duration of the timeout to the timeout for detecting a NodeManager down.  Similar issue than MAPREDUCE-6659 on which I can't attached the patch.",Resolved,Duplicate,MAPREDUCE-6659,Unassigned,Nicolas Fraison,Fri; 13 Oct 2017 09:59:10 +0000,Fri; 13 Oct 2017 13:15:21 +0000,Fri; 13 Oct 2017 13:15:21 +0000,,2.6.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6982
MAPREDUCE-6983,Sub-task,Major,,Moving logging APIs over to slf4j in hadoop-mapreduce-client-core,nan,Resolved,Fixed,,Jinjiang Ling,Jinjiang Ling,Tue; 17 Oct 2017 07:28:51 +0000,Thu; 2 Nov 2017 15:30:38 +0000,Thu; 2 Nov 2017 08:44:46 +0000,,3.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6983
MAPREDUCE-6984,Improvement,Major,applicationmaster,MR AM to clean up temporary files from previous attempt,When the MR AM restarts; the outputDir appAttemptNumber directory remains on HDFS; even though this directory is not used during the next attempt if the restart has been done without recovery. So if recovery is not used for the AM restart; then the deletion of this directory can be done earlier (at the start of the next attempt). The benefit is that more free HDFS space is available for the next attempt.,Patch Available,Unresolved,,Gergo Repas,Gergo Repas,Tue; 17 Oct 2017 11:14:46 +0000,Mon; 8 Jan 2018 12:18:37 +0000,,,3.0.0-beta1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6984
MAPREDUCE-6985,Bug,Critical,,MapReduce native optimization does not work properly due to a shuffle error (LocalJobRunner),Reported by Shingo Furuyama:  We confirmed that MapReduce native optimization (MAPREDUCE-2841) of Hadoop-3.0.0-beta1 does not work properly due to a shuffle error.     My build and run environment is below: CentOS: 7.3 cmake: 3.6.3 Maven: 3.5.0 Java: 1.8.0_131 Hadoop: 3.0.0-beta1 mode: LocalJobRunner,Open,Unresolved,,Unassigned,Takanobu Asanuma,Thu; 19 Oct 2017 05:52:34 +0000,Fri; 20 Oct 2017 02:03:26 +0000,,,3.0.0-beta1,,,MAPREDUCE-2841,https://issues.apache.org/jira/browse/MAPREDUCE-6985
MAPREDUCE-6986,Bug,Trivial,,Fail to set job configuration by -D option in example WordMedian ,I tried to submit mr example job wordmedian and specify queue by -D option: bin output6. This option did not work in wordmedian while it works in other example jobs such Terasort; Wordcount. The cause is there is unnecessary setConf(new Configuration()) in run() method; which would override Configuration with properties by -D options.,Patch Available,Unresolved,,Tao Jie,Tao Jie,Thu; 19 Oct 2017 08:17:12 +0000,Thu; 19 Oct 2017 08:24:10 +0000,,,2.8.1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6986
MAPREDUCE-6987,Bug,Critical,jobhistoryserver,JHS Log Scanner and Cleaner blocked,Both threads waiting on FutureTask.get() for infinite time after first execution,Resolved,Duplicate,HADOOP-14966,Bibin A Chundatt,Bibin A Chundatt,Thu; 19 Oct 2017 10:26:43 +0000,Tue; 31 Oct 2017 19:47:39 +0000,Tue; 31 Oct 2017 19:47:39 +0000,,2.9.0;3.0.0-alpha1,,HADOOP-14966,,https://issues.apache.org/jira/browse/MAPREDUCE-6987
MAPREDUCE-6988,Improvement,Minor,jobhistoryserver,Let JHS support different file systems for intermediate_done and done,Currently JHS uses filecontext to move files from intermediate_done to done folder. Since filecontext limits the use to 1 filesystem it makes it harder to use s3 as a storage for jhist files. By moving this to filesystem interface we can set hdfs for intermediate storage and s3 as long term storage therefore reducing the number of puts to s3 and removing the need for all M R containers to carry a s3 sdk.,Patch Available,Unresolved,,Unassigned,Johan Gustavsson,Mon; 23 Oct 2017 08:46:02 +0000,Fri; 5 Jan 2018 01:54:50 +0000,,,2.7.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6988
MAPREDUCE-6989,Improvement,Major,,[Umbrella] Uploader tool for Distributed Cache Deploy of the mapreduce framework and dependencies,The proposal is to create a tool that collects all available jars in the Hadoop classpath and adds them to a single tarball file. It then uploads the resulting archive to an HDFS directory. This saves the cluster administrator from having to set this up manually for Distributed Cache Deploy.,Open,Unresolved,,Miklos Szegedi,Miklos Szegedi,Mon; 23 Oct 2017 22:31:08 +0000,Tue; 2 Jan 2018 19:30:08 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6989
MAPREDUCE-6990,Bug,Major,,FileInputStream.skip function can return 0 when the file is corrupted; causing an infinite loop,When file is corrupted; for example; bad encoding; Yarn-2724; the FileInputStream can return 0; causing the while loop in TaskLog$Reader become infinite.     Similar bugs are Hadoop-8614; Yarn-2905; Yarn-163,Open,Unresolved,,Unassigned,John Doe,Tue; 24 Oct 2017 21:18:57 +0000,Mon; 4 Dec 2017 03:34:12 +0000,,,0.23.0;2.5.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6990
MAPREDUCE-6991,Bug,Major,,getRogueTaskPID and testProcessTree hangs when the file creation failed,When writing to file failed; in the following thread; due to disk full; hardware error; etc;    The getRogueTaskPID() and testProcessTree() get stuck waiting until the file is created or get interrupted.,Open,Unresolved,,Unassigned,John Doe,Tue; 24 Oct 2017 21:47:42 +0000,Tue; 24 Oct 2017 21:47:42 +0000,,,0.23.0;2.0.0-alpha,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6991
MAPREDUCE-6992,Bug,Major,,Race for temp dir in LocalDistributedCacheManager.java,"When localizing distributed cache files in ""local"" mode; LocalDistributedCacheManager. L912).",Resolved,Duplicate,MAPREDUCE-6441,Unassigned,Philip Zeyliger,Thu; 26 Oct 2017 18:14:55 +0000,Thu; 26 Oct 2017 18:45:19 +0000,Thu; 26 Oct 2017 18:45:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6992
MAPREDUCE-6993,Bug,Major,,Provide additional aggregated task stats at the Map / Reduce level,MapReduce ApplicationMaster can log aggregated tasks stats for Map   Reduce stage like below which will make debugging easier. Similar to what Tez provides TEZ-930  firstTaskStartTime; firstTasksToStart lastTaskFinishTime lastTasksToFinish minTaskDuration maxTaskDuration  avgTaskDuration numSuccessfulTasks shortestDurationTasks longestDurationTasks numFailedTaskAttempts numKilledTaskAttempts numCompletedTasks numSucceededTasks numKilledTasks numFailedTasks,Open,Unresolved,,Unassigned,Prabhu Joseph,Fri; 27 Oct 2017 12:19:36 +0000,Fri; 27 Oct 2017 12:19:36 +0000,,,2.7.3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6993
MAPREDUCE-6994,Sub-task,Major,,Uploader tool for Distributed Cache Deploy code changes,The proposal is to create a tool that collects all available jars in the Hadoop classpath and adds them to a single tarball file. It then uploads the resulting archive to an HDFS directory. This saves the cluster administrator from having to set this up manually for Distributed Cache Deploy.,Resolved,Fixed,,Miklos Szegedi,Miklos Szegedi,Fri; 27 Oct 2017 22:01:00 +0000,Fri; 1 Dec 2017 20:42:35 +0000,Fri; 1 Dec 2017 20:13:24 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6994
MAPREDUCE-6995,Sub-task,Major,,Uploader tool for Distributed Cache Deploy documentation,nan,Open,Unresolved,,Miklos Szegedi,Miklos Szegedi,Fri; 27 Oct 2017 22:03:37 +0000,Fri; 27 Oct 2017 22:03:37 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6995
MAPREDUCE-6996,Bug,Minor,,FileInputFormat#getBlockIndex should include file name in the exception.,When the file is open for writing; the last.getLength() and last.getOffset() will be zero and we see the following exception stack trace.   Its difficult to debug which file was open. So creating this ticket to include the filename in the exception. Since FileInputFormat#getBlockIndex is protected; we can't change the signature of that method and add file name to arguments. The only way I can think to fix this is:     Have a try-catch block around the above code chunk and catch IllegalArgumentException and check for message Offset 0 is outside of file (0..-1). If yes; add the file name and rethrow IllegalArgumentException.,Open,Unresolved,,Unassigned,Rushabh S Shah,Wed; 1 Nov 2017 15:40:00 +0000,Wed; 1 Nov 2017 15:40:00 +0000,,,2.6.0,newbie++,,,https://issues.apache.org/jira/browse/MAPREDUCE-6996
MAPREDUCE-6997,Sub-task,Major,,Moving logging APIs over to slf4j in hadoop-mapreduce-client-hs,nan,Resolved,Fixed,,Gergely Nov  k,Akira Ajisaka,Thu; 2 Nov 2017 08:52:19 +0000,Wed; 8 Nov 2017 10:49:01 +0000,Wed; 8 Nov 2017 10:25:28 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6997
MAPREDUCE-6998,Sub-task,Major,,Moving logging APIs over to slf4j in hadoop-mapreduce-client-jobclient,nan,Resolved,Fixed,,Gergely Nov  k,Akira Ajisaka,Thu; 2 Nov 2017 08:52:47 +0000,Thu; 7 Dec 2017 07:53:12 +0000,Thu; 7 Dec 2017 07:22:43 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6998
MAPREDUCE-6999,Bug,Trivial,,"Fix typo ""onf"" in DynamicInputChunk.java","Modify the wrong word ""onf"" to ""on""",Resolved,Fixed,,fang zhenyi,fang zhenyi,Wed; 1 Nov 2017 15:09:10 +0000,Fri; 3 Nov 2017 13:47:51 +0000,Thu; 2 Nov 2017 09:35:36 +0000,,3.0.0-alpha3,,,,https://issues.apache.org/jira/browse/MAPREDUCE-6999
MAPREDUCE-7000,Sub-task,Minor,,Moving logging APIs over to slf4j in hadoop-mapreduce-client-nativetask,nan,Resolved,Fixed,,Jinjiang Ling,Jinjiang Ling,Sat; 4 Nov 2017 02:32:50 +0000,Thu; 7 Dec 2017 07:53:13 +0000,Thu; 7 Dec 2017 07:27:51 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7000
MAPREDUCE-7001,Sub-task,Trivial,,Moving logging APIs over to slf4j in hadoop-mapreduce-client-shuffle,nan,Resolved,Fixed,,Jinjiang Ling,Jinjiang Ling,Sat; 4 Nov 2017 02:46:50 +0000,Wed; 8 Nov 2017 11:09:41 +0000,Wed; 8 Nov 2017 10:29:46 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7001
MAPREDUCE-7002,Improvement,Minor,task,Shows processed record count with _SUCCESS file,"I'm using spark jobs for processing files and found requirement for getting number of records process after spark submit ran successfully. After analyze it we realized spark using hadoop underline where hadoop is generating the _SUCCESS file as an indicator of the successful completion. I would like to propose requirement for adding number of count with the file name; for example for 100 record processed it would generate like ""100_SUCCESS"" this will give ability to know how many records get processed on completion of job.",Open,Unresolved,,Mehul Garnara (MG),Mehul Garnara (MG),Sun; 5 Nov 2017 06:35:33 +0000,Tue; 14 Nov 2017 19:37:06 +0000,,,3.0.0-beta1,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7002
MAPREDUCE-7003,Bug,Major,jobhistoryserver,Indefinite retries of getJobSummary() if a job summary file is corrupt,"Having a corrupt job summary file in the   rename it) 	detach debugger 	examine JHS log files",Open,Unresolved,,Unassigned,Attila Sasvari,Mon; 6 Nov 2017 09:37:31 +0000,Mon; 6 Nov 2017 09:37:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7003
MAPREDUCE-7004,Sub-task,Major,,Uploader tool for Distributed Cache Implementation on Windows,The proposal is to create a tool that collects all available jars in the Hadoop classpath and adds them to a single tarball file. It then uploads the resulting archive to an HDFS directory. This saves the cluster administrator from having to set this up manually for Distributed Cache Deploy. This jira is about applying the tool code to Windows.,Open,Unresolved,,Unassigned,Miklos Szegedi,Fri; 10 Nov 2017 01:46:33 +0000,Fri; 10 Nov 2017 01:47:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7004
YARN-7475,Bug,Major,,Fix Container log link in new YARN UI,Container log link is broken,Resolved,Fixed,,Sunil G,Sunil G,Sat; 11 Nov 2017 12:27:15 +0000,Mon; 13 Nov 2017 03:19:05 +0000,Sun; 12 Nov 2017 17:56:37 +0000,,2.9.0;3.0.0-beta1,,,,https://issues.apache.org/jira/browse/YARN-7475
MAPREDUCE-7006,Sub-task,Major,,mapreduce.application.framework.path localizes into the private directory,Mapreduce has a feature to localize the entire framework into distributed cache from HDFS using mapreduce.application.framework.path. This tarball should be public and not private as it is now.,Resolved,Not A Problem,,Miklos Szegedi,Miklos Szegedi,Mon; 13 Nov 2017 19:56:54 +0000,Mon; 13 Nov 2017 21:50:16 +0000,Mon; 13 Nov 2017 21:50:16 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7006
MAPREDUCE-7007,Improvement,Minor,,Add LOG.isDebugEnabled() guard for each LOG.debug(),"I am conducting research on log related bugs. I tried to make a tool to fix repetitive yet simple patterns of bugs that are related to logs. In these files; there are debug level logging statements containing multiple string concatenation without the if statement before them:   hadoop-mapreduce-project   LOG.debug(""splits&quot;+j+&#93;=""splits.get(j)"" count="" + count);; 244  Would you be interested in adding the if before these logging statements?",Open,Unresolved,,Unassigned,Mehran Hassani,Mon; 13 Nov 2017 20:18:33 +0000,Mon; 13 Nov 2017 21:37:44 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7007
MAPREDUCE-7008,Bug,Critical,contrib/streaming;performance;yarn,Partitioner need to get input as comand also instead of only java class.,Streaming allows both commands and Java classes to be specified as mapper; reducer; and combiner; but the -partitioner option is still limited to Java classes only. Allowing commands to be specified as partitioner as well would greatly improve the flexibility of Streaming programs.,Open,Unresolved,,Unassigned,Devendra Bhat,Fri; 17 Nov 2017 05:09:48 +0000,Fri; 17 Nov 2017 05:09:48 +0000,,,2.7.4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7008
MAPREDUCE-7009,Improvement,Critical,,Ensure Job Configuration File is loadable for Task,In a production environment; we encountered several situations where dataloss due to a configuration file being unloaded.,Open,Unresolved,,Unassigned,DENG FEI,Mon; 20 Nov 2017 05:18:22 +0000,Mon; 20 Nov 2017 05:20:38 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7009
MAPREDUCE-7010,Improvement,Major,,Make Job History File Permissions configurable,Currently the mapreduce job history files are written with 770 permissions which can be accessed by job user or other user part of hadoop group. There might be users who are not part of the hadoop group but want to access these history files. We should provide ability to change the default permissions for staging files. The default should remain 770.,Open,Unresolved,,Gergely Nov  k,Andras Bokor,Fri; 17 Nov 2017 12:10:16 +0000,Fri; 1 Dec 2017 13:34:24 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7010
MAPREDUCE-7011,Test,Trivial,,TestClientDistributedCacheManager::testDetermineCacheVisibilities assumes all parent dirs set other exec,TestClientDistributedCacheManager sets up some local directories to check the visibility set for dependencies; given their filesystem permissions. However; if it is run in an environment where the scratch directory is not itself PUBLIC (ClientDistributedCacheManager::isPublic); then it will fail.,Resolved,Fixed,,Chris Douglas,Chris Douglas,Tue; 21 Nov 2017 18:36:26 +0000,Wed; 22 Nov 2017 16:44:13 +0000,Wed; 22 Nov 2017 04:44:32 +0000,,,,,MAPREDUCE-7013,https://issues.apache.org/jira/browse/MAPREDUCE-7011
HADOOP-15059,Bug,Blocker,security,3.0 deployment cannot work with old version MR tar ball which breaks rolling upgrade,"I tried to deploy 3.0 cluster with 2.9 MR tar ball. The MR job is failed because following error:   I think it is due to token incompatiblity change between 2.9 and 3.0. As we claim ""rolling upgrade"" is supported in Hadoop 3; we should fix this before we ship 3.0 otherwise all MR running applications will get stuck during after upgrade.",Resolved,Fixed,,Jason Lowe,Junping Du,Tue; 21 Nov 2017 20:54:52 +0000,Wed; 13 Dec 2017 01:04:51 +0000,Fri; 8 Dec 2017 16:05:30 +0000,,,,,HADOOP-13123;HDFS-12920,https://issues.apache.org/jira/browse/HADOOP-15059
MAPREDUCE-7013,Test,Major,,Tests of internal logic should not use the local FS as scratch space,MapReduce often manipulates files permissions to ensure splits; dependencies; and other user data are consistently managed. Unit tests of these internal methods sometimes set up temporary hierarchies in a scratch directory on the local FS to exercise these modules. However; dev environment quirks (e.g.; umask) can cause these tests to fail spuriously. Instead; this logic should be validated by mocking the filesystem.,Open,Unresolved,,Unassigned,Chris Douglas,Wed; 22 Nov 2017 16:43:20 +0000,Wed; 22 Nov 2017 16:44:46 +0000,,,,,,MAPREDUCE-7011,https://issues.apache.org/jira/browse/MAPREDUCE-7013
MAPREDUCE-7014,Bug,Major,,Fix java doc errors in jdk1.8,Trunk compilation fails with Java Doc errors.,Resolved,Fixed,,Steve Loughran,Rohith Sharma K S,Mon; 27 Nov 2017 05:11:00 +0000,Mon; 27 Nov 2017 17:01:23 +0000,Mon; 27 Nov 2017 16:36:24 +0000,,3.1.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7014
MAPREDUCE-7015,Bug,Major,jobhistoryserver,Possible race condition in JHS if the job is not loaded,There could be a race condition inside JHS. In our build environment; TestMRJobClient.testJobClient() failed with this exception:     Root cause: 1. MapReduce job completes 2. CLI calls cluster.getJob(jobid) 3. The job is finished and the client side gets redirected to JHS 4. The job data is missing from CachedHistoryStorage so JHS tries to find the job 5. First it scans the intermediate directory and finds the job 6. The call moveToDone() is scheduled for execution on a separate thread inside moveToDoneExecutor and it starts to run immediately 7. RPC invocation returns with the path pointing to  done_intermediate 8. The call to moveToDone() completes which moves the contents of done_intermediate to done 9. Hadoop CLI tries to download the config file from done_intermediate but it's no longer there  Usually step #6 is slow enough to complete after #7; but sometimes it's faster; causing this race condition.,Open,Unresolved,,Peter Bacsko,Peter Bacsko,Mon; 27 Nov 2017 15:06:17 +0000,Wed; 10 Jan 2018 20:52:49 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7015
MAPREDUCE-7016,Improvement,Major,,Avoid making separate RPC calls for FileStatus and block locations in FileInputFormat,FileInputFormat::getSplits uses FileSystem::globStatus to determine its inputs. When the glob returns directories; each is traversed and LocatedFileStatus instances are returned with the block locations. However; when the glob returns files; this is a FileStatus that requires a second RPC to obtain its locations.,Open,Unresolved,,Unassigned,Chris Douglas,Tue; 28 Nov 2017 23:54:21 +0000,Wed; 29 Nov 2017 06:07:53 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7016
MAPREDUCE-7017,Improvement,Major,mr-am,Too many times of meaningless invocation in TaskAttemptImpl#resolveHosts,MRAppMaster uses TaskAttemptImpl::resolveHosts to determine the dataLocalHosts for each task when the location of data split is IP; which will call a lot of times ( taskNum * dfsReplication) of function InetAddress::getByName and most of the funcition calls are redundant.  When the job has a great number of tasks and the speed of DNS resolution is not fast enough; it will take a lot of time at this stage before the job running.,Patch Available,Unresolved,,jiayuhan-it,jiayuhan-it,Mon; 4 Dec 2017 08:13:32 +0000,Fri; 12 Jan 2018 20:25:34 +0000,,,3.0.0-alpha4,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7017
MAPREDUCE-7018,Sub-task,Major,,Apply erasure coding properly to framework tarball and support plain tar,nan,Resolved,Fixed,,Miklos Szegedi,Miklos Szegedi,Mon; 4 Dec 2017 21:08:07 +0000,Mon; 11 Dec 2017 22:21:11 +0000,Mon; 11 Dec 2017 22:01:02 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7018
MAPREDUCE-7019,Bug,Major,,java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2,nan,Resolved,Invalid,,Unassigned,shrutika sarda,Tue; 5 Dec 2017 10:33:26 +0000,Fri; 8 Dec 2017 16:15:32 +0000,Fri; 8 Dec 2017 16:15:32 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7019
MAPREDUCE-7020,Bug,Major,mr-am,Task timeout in uber mode can crash AM,TestUberAM is failing   https: ,Open,Unresolved,,Peter Bacsko,Akira Ajisaka,Thu; 7 Dec 2017 07:18:35 +0000,Mon; 15 Jan 2018 14:37:15 +0000,,,3.1.0;3.0.1;2.10.0;2.9.1;2.8.4;2.7.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7020
MAPREDUCE-7021,Sub-task,Major,,Remove logger dependencies other than org.slf4j in hadoop-mapreduce,We moved logging APIs over to slf4j; however; the dependency is left. We need to cut the dependency.,Patch Available,Unresolved,,Akira Ajisaka,Akira Ajisaka,Thu; 7 Dec 2017 07:32:47 +0000,Mon; 15 Jan 2018 11:11:55 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7021
MAPREDUCE-7022,Improvement,Major,task,Fast fail rogue jobs based on task scratch dir size,With the introduction of MAPREDUCE-6489 there are some options to kill rogue tasks based on writes to local disk writes. In our environment are we mainly run Hive based jobs we noticed that this counter and the size of the local scratch dirs were very different. We had tasks where BYTES_WRITTEN counter were at 300Gb and where it was at 10Tb both producing around 200Gb on local disk; so it didn't help us much. So to extend this feature tasks should monitor local scratchdir size and fail if they pass the limit. In these cases the tasks should not be retried either but instead the job should fast fail.,Patch Available,Unresolved,,Johan Gustavsson,Johan Gustavsson,Fri; 8 Dec 2017 00:56:28 +0000,Mon; 15 Jan 2018 12:23:06 +0000,,,2.7.0;2.8.0;2.9.0,,,MAPREDUCE-6489,https://issues.apache.org/jira/browse/MAPREDUCE-7022
MAPREDUCE-7023,Bug,Minor,test,TestHadoopArchiveLogs.testCheckFilesAndSeedApps fails on rerun,"Since the test doesn't clean up the created ""logs"" dir; when rerunning it fails on this line:",Patch Available,Unresolved,,Gergely Nov  k,Gergely Nov  k,Thu; 14 Dec 2017 11:59:04 +0000,Mon; 18 Dec 2017 14:36:36 +0000,,,,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-7023
YARN-7663,Bug,Minor,resourcemanager,RMAppImpl:Invalid event: START at KILLED,Send kill to application; the RM log shows:      if insert sleep before where the START event was created; this bug will deterministically reproduce.,Resolved,Fixed,,lujie,lujie,Fri; 15 Dec 2017 01:52:46 +0000,Wed; 10 Jan 2018 03:03:22 +0000,Tue; 9 Jan 2018 16:10:34 +0000,,2.8.0,patch,,,https://issues.apache.org/jira/browse/YARN-7663
MAPREDUCE-7025,Improvement,Major,,Avg and Max of memory could be record in TaskCount,MapReduce Counter is very helpful tool to do statistics; analysis and tuning in industry. One popular way is analysing job historical status of running to optimise continuously. But when the job completed; the memory usage in counter is a snapshot value PHYSICAL_MEMORY_BYTES. So if we can also record the average value and the max value instead of only the last snapshot value; it could be much helpful.  If you think it' ok. I will contribute the code.,Resolved,Duplicate,MAPREDUCE-6829,Lantao Jin,Lantao Jin,Mon; 18 Dec 2017 08:38:39 +0000,Mon; 18 Dec 2017 08:51:58 +0000,Mon; 18 Dec 2017 08:51:58 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7025
MAPREDUCE-7026,Bug,Major,task,Shuffle Fetcher does not log the actual error message thrown by ShuffleHandler,A job is failing with reduce tasks failed to fetch map output and the NodeManager ShuffleHandler failed to serve the map outputs with some IOException like below. ShuffleHandler sends the actual error message in response inside sendError() but the Fetcher does not log this message.  Logs from NodeManager ShuffleHandler:     Fetcher Logs below without the actual error message:,Open,Unresolved,,Unassigned,Prabhu Joseph,Mon; 18 Dec 2017 10:22:24 +0000,Mon; 18 Dec 2017 10:26:06 +0000,,,2.7.3,supportability,,,https://issues.apache.org/jira/browse/MAPREDUCE-7026
MAPREDUCE-7027,Bug,Critical,mrv2,HadoopArchiveLogs shouldn't delete the original logs if the HAR creation fails,If the hadoop archive command fails for any reason (for example because of an OutOfMemoryError) the HadoopArchiveLogs tool will still delete the original log files; so all the logs will be lost.,Open,Unresolved,,Gergely Nov  k,Gergely Nov  k,Mon; 18 Dec 2017 14:18:06 +0000,Tue; 19 Dec 2017 13:27:36 +0000,,,,,,MAPREDUCE-6415,https://issues.apache.org/jira/browse/MAPREDUCE-7027
MAPREDUCE-7028,Bug,Blocker,mr-am,Concurrent task progress updates causing NPE in Application Master,Concurrent task progress updates can cause a NullPointerException in the Application Master (stack trace is with code tempt_1513780867907_0001_m_000002_0 is : 0.02677883 2017-12-20 06:49:42;386 INFO AsyncDispatcher ShutDown handler org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting; bbye..  This happened naturally in several big wordcount runs; and I could reproduce this reliably by artificially making task updates more frequent.,Resolved,Fixed,,Gergo Repas,Gergo Repas,Wed; 20 Dec 2017 15:33:20 +0000,Wed; 3 Jan 2018 17:41:05 +0000,Wed; 3 Jan 2018 17:23:37 +0000,,3.1.0;3.0.1;2.10.0;2.9.1;2.8.4;2.7.6,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7028
MAPREDUCE-7029,Improvement,Minor,,FileOutputCommitter#commitTask should delete task directory,"I ran a Spark job that outputs thousands of parquet files (aka there are thousands of reducers); and it hung for several minutes in the driver after all tasks were complete. Here is a very simple repro of the job (to be run in a spark-shell):     Spark actually calls into Mapreduce's FileOuputCommitter. Job committing (specifically cleanupJob()) recursively deletes the job temporary directory; which is something like ""gs: task1""). On HDFS; this is O(1) per task; so this is very little overhead per task. On GCS (and other HCFSs); this adds parallelism for deleting the job temp directory.  With the attached patch; the repro above went from taking ~10 minutes to taking ~5 minutes; and task time did not significantly change.  Side note: I found this issue with Spark; but I assume it applies to a Mapreduce job with thousands of reducers as well.",Patch Available,Unresolved,,Unassigned,Karthik Palaniappan,Thu; 28 Dec 2017 00:02:15 +0000,Fri; 12 Jan 2018 22:24:17 +0000,,,2.8.2,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7029
MAPREDUCE-7030,Sub-task,Minor,,Uploader tool should ignore symlinks to the same directory,nan,Resolved,Fixed,,Miklos Szegedi,Miklos Szegedi,Thu; 28 Dec 2017 17:47:41 +0000,Fri; 12 Jan 2018 22:46:10 +0000,Fri; 12 Jan 2018 22:19:19 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7030
MAPREDUCE-7031,Improvement,Trivial,client,JobControl Class Review,"Use ArrayList instead of LinkedList for performance 	Remove tab characters 	Fix spacing issues 	Use SLF4J parameterized logging",Patch Available,Unresolved,,Unassigned,BELUGA BEHR,Thu; 28 Dec 2017 17:51:19 +0000,Fri; 29 Dec 2017 18:04:50 +0000,,,3.0.0,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7031
MAPREDUCE-7032,Sub-task,Major,,Add the ability to specify a delayed replication count,Setting the delayed replication count is more robust,Patch Available,Unresolved,,Miklos Szegedi,Miklos Szegedi,Thu; 11 Jan 2018 17:54:32 +0000,Sat; 13 Jan 2018 02:51:31 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7032
MAPREDUCE-7033,Bug,Major,mrv2,Map outputs implicitly rely on permissive umask for shuffle,Map tasks do not explicitly set the permissions of their output files for shuffle.  In a secure cluster the shuffle service is running as a different user than the map task; so the output files require group readability in order to serve up the data during the shuffle phase.  If the user's UNIX umask is too restrictive (e.g.: 077) then the map task's file.out and file.out.index permissions can be too restrictive to allow the shuffle handler to access them.,Open,Unresolved,,Unassigned,Jason Lowe,Thu; 11 Jan 2018 19:23:07 +0000,Thu; 11 Jan 2018 19:23:07 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7033
MAPREDUCE-7034,Sub-task,Major,,Moving logging APIs over to slf4j the rest of all in hadoop-mapreduce,It seems there are some left.,Resolved,Fixed,,Takanobu Asanuma,Takanobu Asanuma,Fri; 12 Jan 2018 01:58:14 +0000,Mon; 15 Jan 2018 06:58:01 +0000,Mon; 15 Jan 2018 06:39:31 +0000,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7034
MAPREDUCE-7035,Bug,Minor,client,Fix javadoc issues in hadoop-mapreduce-client,Auto-generated code in map-reduce client throws many  oc warnings.  The warnings are thrown for the following auto-generated sources,Patch Available,Unresolved,,Unassigned,Mukul Kumar Singh,Mon; 15 Jan 2018 08:59:47 +0000,Mon; 15 Jan 2018 10:41:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7035
MAPREDUCE-7036,Test,Minor,test,ASF License warning in hadoop-mapreduce-client,it occurred in MAPREDUCE-7021 and MAPREDUCE-7034.,Open,Unresolved,,Takanobu Asanuma,Takanobu Asanuma,Mon; 15 Jan 2018 11:09:07 +0000,Mon; 15 Jan 2018 11:09:50 +0000,,,,,,,https://issues.apache.org/jira/browse/MAPREDUCE-7036
